COMPUTER SYSTEMS Programmer’s Perspective Bryant  O’HallaronComputer Systems Programmer’s PerspectiveThis page intentionally left blank Computer Systems Programmer’s Perspective Randal E. Bryant Carnegie Mellon University David R. O’Hallaron Carnegie Mellon University Intel Labs Prentice Hall Boston Columbus Indianapolis New York San Francisco Upper Saddle River Amsterdam Cape Town Dubai London Madrid Milan Munich Paris Montreal TorontoDelhi Mexico City Sao Paulo Sydney Hong Kong Seoul Singapore Taipei TokyoEditorial Director: Marcia Horton Editor-in-Chief: Michael Hirsch Acquisitions Editor: Matt Goldstein Editorial Assistant: Chelsea Bell Director Marketing: Margaret WaplesMarketing Coordinator: Kathryn Ferranti Managing Editor: Jeff Holcomb Senior Manufacturing Buyer: Carol Melville Art Director: Linda KnowlesCover Designer: Elena Sidorova Image Interior Permission Coordinator: Richard Rodrigues Cover Art: © Randal E. Bryant David R. O’Hallaron Media Producer: Katelyn Boller Project Management Interior Design: Paul C. Anagnostopoulos, Windfall Software Composition: Joe Snowden, Coventry Composition Printer/Binder: Edwards Brothers Cover Printer: Lehigh-Phoenix Color/Hagerstown Copyright © 2011, 2003 Randal E. Bryant David R. O’Hallaron. rights reserved. Manufactured United States America. publication protected Copyright, permission obtained publisher prior prohibited reproduction, storage retrieval system, transmission form means, electronic, mechanical, photocopying, recording, likewise. obtain permission(s) use materialfrom work, please submit written request Pearson Education, Inc., Permissions Department, 501 Boylston Street, Suite 900, Boston, Massachusetts 02116. Many designations manufacturers seller distinguish products claimed trademarks. designations appear book, publisher aware trademark claim, designations printed initial caps caps. Library Congress Cataloging-in-Publication Data Bryant, Randal. Computer system : programmer’s perspective / Randal E. Bryant, David R. O’Hallaron.—2nd ed. p. cm. Includes bibliographical references index. ISBN-13: 978-0-13-610804-7 (alk. paper) ISBN-10: 0-13-610804-0 (alk. paper)1. Computer systems. 2. Computers. 3. Telecommunication. 4. User interfaces (Computer systems) I. O’Hallaron, David Richard. II. Title. QA76.5.B795 2010 004—dc22 2009053083 1 098765432 1—EB—14 13 12 11 10 ISBN 10: 0-13-610804-0 ISBN 13: 978-0-13-610804-7To students instructors 15-213 course Carnegie Mellon University, inspiringus develop reﬁne material book.This page intentionally left blank Contents Preface xix Authors xxxiii 1 Tour Computer Systems 1 1.1 Information Bits + Context 3 1.2 Programs Translated Programs Different Forms 4 1.3 Pays Understand Compilation Systems Work 6 1.4 Processors Read Interpret Instructions Stored Memory 7 1.4.1 Hardware Organization System 71.4.2 Running hello Program 10 1.5 Caches Matter 12 1.6 Storage Devices Form Hierarchy 13 1.7 Operating System Manages Hardware 14 1.7.1 Processes 161.7.2 Threads 171.7.3 Virtual Memory 171.7.4 Files 19 1.8 Systems Communicate Systems Using Networks 20 1.9 Important Themes 21 1.9.1 Concurrency Parallelism 211.9.2 Importance Abstractions Computer Systems 24 1.10 Summary 25 Bibliographic Notes 26 Part Program Structure Execution 2 Representing Manipulating Information 29 2.1 Information Storage 33 2.1.1 Hexadecimal Notation 342.1.2 Words 38 2.1.3 Data Sizes 38 viiviii Contents 2.1.4 Addressing Byte Ordering 39 2.1.5 Representing Strings 462.1.6 Representing Code 472.1.7 Introduction Boolean Algebra 482.1.8 Bit-Level Operations C 512.1.9 Logical Operations C 54 2.1.10 Shift Operations C 54 2.2 Integer Representations 56 2.2.1 Integral Data Types 57 2.2.2 Unsigned Encodings 58 2.2.3 Two’s-Complement Encodings 602.2.4 Conversions Signed Unsigned 65 2.2.5 Signed vs. Unsigned C 69 2.2.6 Expanding Bit Representation Number 712.2.7 Truncating Numbers 752.2.8 Advice Signed vs. Unsigned 76 2.3 Integer Arithmetic 79 2.3.1 Unsigned Addition 792.3.2 Two’s-Complement Addition 83 2.3.3 Two’s-Complement Negation 87 2.3.4 Unsigned Multiplication 882.3.5 Two’s-Complement Multiplication 892.3.6 Multiplying Constants 922.3.7 Dividing Powers Two 95 2.3.8 Final Thoughts Integer Arithmetic 98 2.4 Floating Point 99 2.4.1 Fractional Binary Numbers 1002.4.2 IEEE Floating-Point Representation 103 2.4.3 Example Numbers 105 2.4.4 Rounding 1102.4.5 Floating-Point Operations 113 2.4.6 Floating Point C 114 2.5 Summary 118 Bibliographic Notes 119 Homework Problems 119 Solutions Practice Problems 134 3 Machine-Level Representation Programs 153 3.1 Historical Perspective 156 3.2 Program Encodings 159Contents ix 3.2.1 Machine-Level Code 160 3.2.2 Code Examples 1623.2.3 Notes Formatting 165 3.3 Data Formats 167 3.4 Accessing Information 168 3.4.1 Operand Speciﬁers 1693.4.2 Data Movement Instructions 1713.4.3 Data Movement Example 174 3.5 Arithmetic Logical Operations 177 3.5.1 Load Effective Address 1773.5.2 Unary Binary Operations 1783.5.3 Shift Operations 1793.5.4 Discussion 1803.5.5 Special Arithmetic Operations 182 3.6 Control 185 3.6.1 Condition Codes 1853.6.2 Accessing Condition Codes 1873.6.3 Jump Instructions Encodings 1893.6.4 Translating Conditional Branches 193 3.6.5 Loops 1973.6.6 Conditional Move Instructions 2063.6.7 Switch Statements 213 3.7 Procedures 219 3.7.1 Stack Frame Structure 219 3.7.2 Transferring Control 2213.7.3 Register Usage Conventions 2233.7.4 Procedure Example 2243.7.5 Recursive Procedures 229 3.8 Array Allocation Access 232 3.8.1 Basic Principles 2323.8.2 Pointer Arithmetic 233 3.8.3 Nested Arrays 2353.8.4 Fixed-Size Arrays 237 3.8.5 Variable-Size Arrays 238 3.9 Heterogeneous Data Structures 241 3.9.1 Structures 241 3.9.2 Unions 2443.9.3 Data Alignment 248 3.10 Putting Together: Understanding Pointers 252 3.11 Life Real World: Using gdb Debugger 254 3.12 Out-of-Bounds Memory References Buffer Overﬂow 256 3.12.1 Thwarting Buffer Overﬂow Attacks 261x Contents 3.13 x86-64: Extending IA32 64 Bits 267 3.13.1 History Motivation x86-64 2683.13.2 Overview x86-64 2703.13.3 Accessing Information 2733.13.4 Control 2793.13.5 Data Structures 290 3.13.6 Concluding Observations x86-64 291 3.14 Machine-Level Representations Floating-Point Programs 292 3.15 Summary 293 Bibliographic Notes 294Homework Problems 294Solutions Practice Problems 308 4 Processor Architecture 333 4.1 Y86 Instruction Set Architecture 336 4.1.1 Programmer-Visible State 3364.1.2 Y86 Instructions 337 4.1.3 Instruction Encoding 3394.1.4 Y86 Exceptions 3444.1.5 Y86 Programs 3454.1.6 Y86 Instruction Details 350 4.2 Logic Design Hardware Control Language HCL 352 4.2.1 Logic Gates 3534.2.2 Combinational Circuits HCL Boolean Expressions 3544.2.3 Word-Level Combinational Circuits HCL Integer Expressions 355 4.2.4 Set Membership 3604.2.5 Memory Clocking 361 4.3 Sequential Y86 Implementations 364 4.3.1 Organizing Processing Stages 3644.3.2 SEQ Hardware Structure 3754.3.3 SEQ Timing 3794.3.4 SEQ Stage Implementations 383 4.4 General Principles Pipelining 391 4.4.1 Computational Pipelines 3924.4.2 Detailed Look Pipeline Operation 3934.4.3 Limitations Pipelining 3944.4.4 Pipelining System Feedback 398 4.5 Pipelined Y86 Implementations 400 4.5.1 SEQ+: Rearranging Computation Stages 400Contents xi 4.5.2 Inserting Pipeline Registers 401 4.5.3 Rearranging Relabeling Signals 4054.5.4 Next PC Prediction 4064.5.5 Pipeline Hazards 4084.5.6 Avoiding Data Hazards Stalling 4134.5.7 Avoiding Data Hazards Forwarding 415 4.5.8 Load/Use Data Hazards 418 4.5.9 Exception Handling 4204.5.10 PIPE Stage Implementations 4234.5.11 Pipeline Control Logic 4314.5.12 Performance Analysis 4444.5.13 Unﬁnished Business 446 4.6 Summary 449 4.6.1 Y86 Simulators 450 Bibliographic Notes 451Homework Problems 451Solutions Practice Problems 457 5 Optimizing Program Performance 473 5.1 Capabilities Limitations Optimizing Compilers 476 5.2 Expressing Program Performance 480 5.3 Program Example 482 5.4 Eliminating Loop Inefﬁciencies 486 5.5 Reducing Procedure Calls 490 5.6 Eliminating Unneeded Memory References 491 5.7 Understanding Modern Processors 496 5.7.1 Overall Operation 497 5.7.2 Functional Unit Performance 5005.7.3 Abstract Model Processor Operation 502 5.8 Loop Unrolling 509 5.9 Enhancing Parallelism 513 5.9.1 Multiple Accumulators 5145.9.2 Reassociation Transformation 518 5.10 Summary Results Optimizing Combining Code 524 5.11 Limiting Factors 525 5.11.1 Register Spilling 525 5.11.2 Branch Prediction Misprediction Penalties 526 5.12 Understanding Memory Performance 531 5.12.1 Load Performance 531 5.12.2 Store Performance 532xii Contents 5.13 Life Real World: Performance Improvement Techniques 539 5.14 Identifying Eliminating Performance Bottlenecks 540 5.14.1 Program Proﬁling 5405.14.2 Using Proﬁler Guide Optimization 5425.14.3 Amdahl’s Law 545 5.15 Summary 547 Bibliographic Notes 548 Homework Problems 549Solutions Practice Problems 552 6 Memory Hierarchy 559 6.1 Storage Technologies 561 6.1.1 Random-Access Memory 5616.1.2 Disk Storage 5706.1.3 Solid State Disks 5816.1.4 Storage Technology Trends 583 6.2 Locality 586 6.2.1 Locality References Program Data 587 6.2.2 Locality Instruction Fetches 588 6.2.3 Summary Locality 589 6.3 Memory Hierarchy 591 6.3.1 Caching Memory Hierarchy 592 6.3.2 Summary Memory Hierarchy Concepts 595 6.4 Cache Memories 596 6.4.1 Generic Cache Memory Organization 5976.4.2 Direct-Mapped Caches 5996.4.3 Set Associative Caches 6066.4.4 Fully Associative Caches 6086.4.5 Issues Writes 6116.4.6 Anatomy Real Cache Hierarchy 6126.4.7 Performance Impact Cache Parameters 614 6.5 Writing Cache-friendly Code 615 6.6 Putting Together: Impact Caches Program Performance 620 6.6.1 Memory Mountain 621 6.6.2 Rearranging Loops Increase Spatial Locality 625 6.6.3 Exploiting Locality Programs 629 6.7 Summary 629 Bibliographic Notes 630Homework Problems 631Solutions Practice Problems 642Contents xiii Part II Running Programs System 7 Linking 653 7.1 Compiler Drivers 655 7.2 Static Linking 657 7.3 Object Files 657 7.4 Relocatable Object Files 658 7.5 Symbols Symbol Tables 660 7.6 Symbol Resolution 663 7.6.1 Linkers Resolve Multiply Deﬁned Global Symbols 6647.6.2 Linking Static Libraries 6677.6.3 Linkers Use Static Libraries Resolve References 670 7.7 Relocation 672 7.7.1 Relocation Entries 672 7.7.2 Relocating Symbol References 673 7.8 Executable Object Files 678 7.9 Loading Executable Object Files 679 7.10 Dynamic Linking Shared Libraries 681 7.11 Loading Linking Shared Libraries Applications 683 7.12 Position-Independent Code (PIC) 687 7.13 Tools Manipulating Object Files 690 7.14 Summary 691 Bibliographic Notes 691Homework Problems 692Solutions Practice Problems 698 8 Exceptional Control Flow 701 8.1 Exceptions 703 8.1.1 Exception Handling 7048.1.2 Classes Exceptions 7068.1.3 Exceptions Linux/IA32 Systems 708 8.2 Processes 712 8.2.1 Logical Control Flow 712 8.2.2 Concurrent Flows 713 8.2.3 Private Address Space 7148.2.4 User Kernel Modes 714 8.2.5 Context Switches 716xiv Contents 8.3 System Call Error Handling 717 8.4 Process Control 718 8.4.1 Obtaining Process IDs 7198.4.2 Creating Terminating Processes 7198.4.3 Reaping Child Processes 7238.4.4 Putting Processes Sleep 729 8.4.5 Loading Running Programs 730 8.4.6 Using fork andexecve Run Programs 733 8.5 Signals 736 8.5.1 Signal Terminology 7388.5.2 Sending Signals 7398.5.3 Receiving Signals 7428.5.4 Signal Handling Issues 7458.5.5 Portable Signal Handling 7528.5.6 Explicitly Blocking Unblocking Signals 7538.5.7 Synchronizing Flows Avoid Nasty Concurrency Bugs 755 8.6 Nonlocal Jumps 759 8.7 Tools Manipulating Processes 762 8.8 Summary 763 Bibliographic Notes 763 Homework Problems 764 Solutions Practice Problems 771 9 Virtual Memory 775 9.1 Physical Virtual Addressing 777 9.2 Address Spaces 778 9.3 VM Tool Caching 779 9.3.1 DRAM Cache Organization 7809.3.2 Page Tables 7809.3.3 Page Hits 7829.3.4 Page Faults 7829.3.5 Allocating Pages 7839.3.6 Locality Rescue 784 9.4 VM Tool Memory Management 785 9.5 VM Tool Memory Protection 786 9.6 Address Translation 787 9.6.1 Integrating Caches VM 791 9.6.2 Speeding Address Translation TLB 791 9.6.3 Multi-Level Page Tables 7929.6.4 Putting Together: End-to-end Address Translation 794 9.7 Case Study: Intel Core i7/Linux Memory System 799Contents xv 9.7.1 Core i7 Address Translation 800 9.7.2 Linux Virtual Memory System 803 9.8 Memory Mapping 807 9.8.1 Shared Objects Revisited 8079.8.2 fork Function Revisited 809 9.8.3 execve Function Revisited 810 9.8.4 User-level Memory Mapping mmap Function 810 9.9 Dynamic Memory Allocation 812 9.9.1 malloc andfree Functions 814 9.9.2 Dynamic Memory Allocation? 8169.9.3 Allocator Requirements Goals 8179.9.4 Fragmentation 8199.9.5 Implementation Issues 8209.9.6 Implicit Free Lists 8209.9.7 Placing Allocated Blocks 8229.9.8 Splitting Free Blocks 8239.9.9 Getting Additional Heap Memory 8239.9.10 Coalescing Free Blocks 8249.9.11 Coalescing Boundary Tags 8249.9.12 Putting Together: Implementing Simple Allocator 8279.9.13 Explicit Free Lists 8359.9.14 Segregated Free Lists 836 9.10 Garbage Collection 838 9.10.1 Garbage Collector Basics 8399.10.2 Mark&Sweep Garbage Collectors 8409.10.3 Conservative Mark&Sweep C Programs 842 9.11 Common Memory-Related Bugs C Programs 843 9.11.1 Dereferencing Bad Pointers 8439.11.2 Reading Uninitialized Memory 843 9.11.3 Allowing Stack Buffer Overﬂows 844 9.11.4 Assuming Pointers Objects Point Size 844 9.11.5 Making Off-by-One Errors 8459.11.6 Referencing Pointer Instead Object Points 8459.11.7 Misunderstanding Pointer Arithmetic 8469.11.8 Referencing Nonexistent Variables 846 9.11.9 Referencing Data Free Heap Blocks 847 9.11.10 Introducing Memory Leaks 847 9.12 Summary 848 Bibliographic Notes 848Homework Problems 849Solutions Practice Problems 853xvi Contents Part III Interaction Communication Programs 10 System-Level I/O 861 10.1 Unix I/O 862 10.2 Opening Closing Files 863 10.3 Reading Writing Files 865 10.4 Robust Reading Writing RioPackage 867 10.4.1 RioUnbuffered Input Output Functions 867 10.4.2 RioBuffered Input Functions 868 10.5 Reading File Metadata 873 10.6 Sharing Files 875 10.7 I/O Redirection 877 10.8 Standard I/O 879 10.9 Putting Together: I/O Functions Use? 880 10.10 Summary 881 Bibliographic Notes 882Homework Problems 882Solutions Practice Problems 883 11 Network Programming 885 11.1 Client-Server Programming Model 886 11.2 Networks 887 11.3 Global IP Internet 891 11.3.1 IP Addresses 89311.3.2 Internet Domain Names 89511.3.3 Internet Connections 899 11.4 Sockets Interface 900 11.4.1 Socket Address Structures 90111.4.2 socket Function 902 11.4.3 connect Function 903 11.4.4 open_clientfd Function 903 11.4.5 bind Function 904 11.4.6 listen Function 905 11.4.7 open_listenfd Function 905 11.4.8 accept Function 907 11.4.9 Example Echo Client Server 908Contents xvii 11.5 Web Servers 911 11.5.1 Web Basics 91111.5.2 Web Content 91211.5.3 HTTP Transactions 91411.5.4 Serving Dynamic Content 916 11.6 Putting Together: Tiny Web Server 919 11.7 Summary 927 Bibliographic Notes 928Homework Problems 928Solutions Practice Problems 929 12 Concurrent Programming 933 12.1 Concurrent Programming Processes 935 12.1.1 Concurrent Server Based Processes 936 12.1.2 Pros Cons Processes 937 12.2 Concurrent Programming I/O Multiplexing 939 12.2.1 Concurrent Event-Driven Server Based I/O Multiplexing 942 12.2.2 Pros Cons I/O Multiplexing 946 12.3 Concurrent Programming Threads 947 12.3.1 Thread Execution Model 94812.3.2 Posix Threads 948 12.3.3 Creating Threads 950 12.3.4 Terminating Threads 95012.3.5 Reaping Terminated Threads 951 12.3.6 Detaching Threads 95112.3.7 Initializing Threads 95212.3.8 Concurrent Server Based Threads 952 12.4 Shared Variables Threaded Programs 954 12.4.1 Threads Memory Model 95512.4.2 Mapping Variables Memory 956 12.4.3 Shared Variables 956 12.5 Synchronizing Threads Semaphores 957 12.5.1 Progress Graphs 96012.5.2 Semaphores 96312.5.3 Using Semaphores Mutual Exclusion 96412.5.4 Using Semaphores Schedule Shared Resources 96612.5.5 Putting Together: Concurrent Server Based Prethreading 970 12.6 Using Threads Parallelism 974xviii Contents 12.7 Concurrency Issues 979 12.7.1 Thread Safety 97912.7.2 Reentrancy 98012.7.3 Using Existing Library Functions Threaded Programs 98212.7.4 Races 98312.7.5 Deadlocks 985 12.8 Summary 988 Bibliographic Notes 989Homework Problems 989Solutions Practice Problems 994 Error Handling 999 A.1 Error Handling Unix Systems 1000 A.2 Error-Handling Wrappers 1001 References 1005 Index 1011Preface book (CS:APP) computer scientists, computer engineers, others want able write better programs learning going “underthe hood” computer system. aim explain enduring concepts underlying computer systems, show concrete ways ideas affect correctness, perfor-mance, utility application programs. systems books writtenfrom builder’s perspective , describing implement hardware sys- tems software, including operating system, compiler, network interface.This book written programmer’s perspective , describing application programmers use knowledge system write better programs. Ofcourse, learning system supposed provides good ﬁrst step learn-ing build one, book also serves valuable introduction tothose go implement systems hardware software. study learn concepts book, way becoming rare “power programmer” knows things work howto ﬁx break. aim present fundamental concepts inways ﬁnd useful right away. also prepared delve deeper,studying topics compilers, computer architecture, operating systems, em-bedded systems, networking. Assumptions Reader’s Background presentation machine code book based two related formatssupported Intel competitors, colloquially known “x86.” IA32 themachine code become de facto standard wide range systems.x86-64 extension IA32 enable programs operate larger data toreference wider range memory addresses. Since x86-64 systems able runIA32 code, forms machine code see widespread use theforeseeable future. consider machines execute C programs Unixor Unix-like (such Linux) operating systems. (To simplify presentation,we use term “Unix” umbrella term systems Unix astheir heritage, including Solaris, Mac OS, Linux.) text contains numerousprogramming examples compiled run Linux systems. Weassume access machine able log simplethings changing directories. computer runs Microsoft Windows, two choices. First, get copy Linux ( www.ubuntu.com ) install “dual boot” option, machine run either operating system. Alternatively, installinga copy Cygwin tools ( www.cygwin.com ), run Unix-like shell xixxx Preface Windows environment close provided Linux. features Linux available Cygwin, however. also assume familiarity C C++. prior experience Java, transition require effort part,but help you. Java C share similar syntax control statements.However, aspects C, particularly pointers, explicit dynamic memory allocation, formatted I/O, exist Java. Fortunately, C smalllanguage, clearly beautifully described classic “K&R” text Brian Kernighan Dennis Ritchie [58]. Regardless programmingbackground, consider K&R essential part personal systems library. Several early chapters book explore interactions C programs machine-language counterparts. machine-languageexamples generated GNU gcccompiler running IA32 x86- 64 processors. assume prior experience hardware, machinelanguage, assembly-language programming. New C? Advice C programming language help readers whose background C programming weak (or nonexistent), also included special notes highlight features especially important C. assume familiar C++ Java. Read Book Learning computer systems work programmer’s perspective great fun, mainly actively. Whenever learn something new,you try right away see result ﬁrst hand. fact, believe thatthe way learn systems dosystems, either working concrete problems writing running programs real systems. theme pervades entire book. new concept introduced, followed text one practice problems work immediately test understanding. Solutions practice problems areat end chapter. read, try solve problem own,and check solution make sure right track. chapteris followed set homework problems varying difﬁculty. instructor solutions homework problems Instructor’s Manual. eachhomework problem, show rating amount effort feel require: ◆Should require minutes. Little programming required. ◆◆ Might require 20 minutes. Often involves writing testing code. Many derived problems given exams. ◆◆◆ Requires signiﬁcant effort, perhaps 1–2 hours. Generally involves writing testing signiﬁcant amount code. ◆◆◆◆ lab assignment, requiring 10 hours effort.Preface xxi code/intro/hello.c 1#include <stdio.h> 2 3int main() 4{ 5 printf("hello, world\n"); 6 return 0; 7} code/intro/hello.c Figure 1 typical code example. code example text formatted directly, without manual intervention, fro C program compiled gccand tested Linux system. course, system may different version gcc, different compiler altogether, compiler might generate different machine code, theoverall behavior same. source code available theCS:APP Web page csapp.cs.cmu.edu . text, ﬁle names source programs documented horizontal bars surround formatted code.For example, program Figure 1 found ﬁle hello.c directory code/intro/ . encourage try running example programs system encounter them. avoid book overwhelming, bulk content, created number Web asides containing material supplements main presentation book. asides referenced within bookwith notation form CHAP :TOP , CHAP short encoding chapter subject, TOP short code topic covered. example, Web Aside data:bool contains supplementary material Boolean algebra presentation data representations Chapter 2, Web Aside arch:vlog contains material describing processor designs using Verilog hardware descrip-tion language, supplementing presentation processor design Chapter 4.All Web asides available CS:APP Web page. Aside aside? encounter asides form throughout text. Asides parenthetical remarks give additional insight current topic. Asides serve number purposes. little history lessons. example, C, Linux, Internet come from? asides meant clarify ideas students often ﬁnd confusing. example, difference cache line, set, block? asides give real-world examples. example, ﬂoating-point error crashed French rocket, geometry actual Seagate disk drive looks like. Finally, asides fun stuff. example, “hoinky”?xxii Preface Book Overview CS:APP book consists 12 chapters designed capture core ideas computer systems: .Chapter 1: Tour Computer Systems. chapter introduces major ideas themes computer systems tracing life cycle simple“hello, world” program. .Chapter 2: Representing Manipulating Information. cover computer arithmetic, emphasizing properties unsigned two’s-complement number representations affect programmers. consider numbersare represented therefore range values encoded givenword size. consider effect casting signed unsigned num-bers. cover mathematical properties arithmetic operations. Noviceprogrammers often surprised learn (two’s-complement) sumor product two positive numbers negative. hand, two’s-complement arithmetic satisﬁes algebraic properties ring, hence acompiler safely transform multiplication constant sequence ofshifts adds. use bit-level operations C demonstrate prin-ciples applications Boolean algebra. cover IEEE ﬂoating-pointformat terms represents values mathematical propertiesof ﬂoating-point operations. solid understanding computer arithmetic critical writing reliable programs. example, programmers compilers cannot replacethe expression (x<y) with(x-y < 0) , due possibility overﬂow. cannot even replace expression (-y < -x) , due asymmetric range negative positive numbers two’s-complement represen- tation. Arithmetic overﬂow common source programming errors andsecurity vulnerabilities, yet books cover properties computer arithmetic programmer’s perspective. .Chapter 3: Machine-Level Representation Programs. teach read IA32 x86-64 assembly language generated b C compiler. cover basic instruction patterns generated different control constructs,such conditionals, loops, switch statements. cover implemen- tation procedures, including stack allocation, register usage conventions,and parameter passing. cover way different data structures asstructures, unions, arrays allocated accessed. also use themachine-level view programs way understand common code se-curity vulnerabilities, buffer overﬂow, steps programmer,the compiler, operating system take mitigate threats. Learning concepts chapter helps become better programmer, understand programs represented machine.One certain beneﬁt develop thorough concrete under-standing pointers. .Chapter 4: Processor Architecture. chapter covers basic combinational sequential logic elements, shows elements bePreface xxiii combined datapath executes simpliﬁed subset IA32 instruc- tion set called “Y86.” begin design single-cycle datapath. Thisdesign conceptually simple, would fast. intro-duce pipelining , different steps required process instruction implemented separate stages. given time, stage workon different instruction. ﬁve-stage processor pipeline much re-alistic. control logic processor designs described using simplehardware description language called HCL. Hardware designs written HCLcan compiled linked simulators provided textbook, andthey used generate Verilog descriptions suitable synthesis intoworking hardware. .Chapter 5: Optimizing Program Performance. chapter introduces num- ber techniques improving code performance, idea thatprogrammers learn write C code way compiler canthen generate efﬁcient machine code. start transformations re- duce work done program hence standard practice writing program machine. progress transforma-tions enhance degree instruction-level parallelism generatedmachine code, thereby improving performance modern “superscalar”processors. motivate transformations, introduce simple opera-tional model modern out-of-order processors work, show tomeasure potential performance program terms critical pathsthrough graphical representation program. surprised howmuch speed program simple transformations C code. .Chapter 6: Memory Hierarchy. memory system one visi- ble parts computer system application programmers. point, youhave relied conceptual model memory system linear array withuniform access times. practice, memory system hierarchy storagedevices different capacities, costs, access times. cover differ-ent types RAM ROM memories geometry organization magnetic-disk solid-state drives. describe storage devices arranged hierarchy. show hierarchy made possible bylocality reference. make ideas concrete introducing uniqueview memory system “memory mountain” ridges temporallocality slopes spatial locality. Finally, show improve theperformance application programs improving temporal spatiallocality. .Chapter 7: Linking. chapter covers static dynamic linking, in- cluding ideas relocatable executable object ﬁles, symbol resolution,relocation, static libraries, shared object libraries, position-independentcode. Linking covered systems texts, cover sev-eral reasons. First, confusing errors programmers canencounter related glitches linking, especially large softwarepackages. Second, object ﬁles produced linkers tied conceptssuch loading, virtual memory, memory mapping.xxiv Preface .Chapter 8: Exceptional Control Flow. part presentation, step beyond single-program model introducing general conceptof exceptional control ﬂow (i.e., changes control ﬂow outside thenormal branches procedure calls). cover examples exceptionalcontrol ﬂow exist levels system, low-level hardwareexceptions interrupts, context switches concurrent processes,to abrupt changes control ﬂow caused delivery Unix signals, tothe nonlocal jumps C break stack discipline. part book introduce fundamental idea aprocess , abstraction executing program. learn pro- cesses work created manipulated applicationprograms. show application programmers make use multipleprocesses via Unix system calls. ﬁnish chapter, ableto write Unix shell job control. also ﬁrst introduction nondeterministic behavior arises concurrent program execution. .Chapter 9: Virtual Memory. presentation virtual memory system seeks give understanding works characteristics. Wewant know different simultaneous processes eachuse identical range addresses, sharing pages individualcopies others. also cover issues involved managing manipulatingvirtual memory. particular, cover operation storage allocatorssuch Unix malloc andfree operations. Covering material serves several purposes. reinforces concept virtual memory space array bytes program subdivide different storage units. helps understand effects programs containing memory ref-erencing errors storage leaks invalid pointer references. Finally,many application programmers write storage allocators optimizedtoward needs characteristics application. chapter, morethan other, demonstrates beneﬁt covering hardware andthe software aspects computer systems uniﬁed way. Traditional com-puter architecture operating systems texts present part virtualmemory story. .Chapter 10: System-Level I/O. cover basic concepts Unix I/O ﬁles descriptors. describe ﬁles shared, I/O redirectionworks, access ﬁle metadata. also develop robust buffered I/Opackage deals correctly curious behavior known short counts , library function reads part input data. cover Cstandard I/O library relationship Unix I/O, focusing limitations standard I/O make unsuitable network programming. general,the topics covered chapter building blocks next two chapterson network concurrent programming. .Chapter 11: Network Programming. Networks interesting I/O devices program, tying together many ideas studied earlier thetext, processes, signals, byte ordering, memory mapping, dynamicPreface xxv storage allocation. Network programs also provide compelling context concurrency, topic next chapter. chapter thin slicethrough network programming gets point writea Web server. cover client-server model underlies networkapplications. present programmer’s view Internet, show howto write Internet clients servers using sockets interface. Finally, weintroduce HTTP develop simple iterative Web server. .Chapter 12: Concurrent Programming. chapter introduces concurrent programming using Internet server design running motivational ex-ample. compare contrast three basic mechanisms writing con-current programs—processes, I/O multiplexing, threads—and show howto use build concurrent Internet servers. cover basic principles ofsynchronization using PandVsemaphore operations, thread safety reen- trancy, race conditions, deadlocks. Writing concurrent code essentialfor server applications. also describe use thread-level pro-gramming express parallelism application program, enabling fasterexecution multi-core processors. Getting cores working sin-gle computational problem requires careful coordination concurrentthreads, correctness achieve high performance. New Edition ﬁrst edition book published copyright 2003. Consider-ing rapid evolution computer technology, book content held upsurprisingly well. Intel x86 machines running Unix-like operating systems andprogrammed C proved combination continues encompass manysystems today. Changes hardware technology compilers experienceof many instructors teaching material prompted substantial revision. signiﬁcant changes: .Chapter 2: Representing Manipulating Information. tried make material accessible, careful explanations conceptsand many practice homework problems. moved ofthe theoretical aspects Web asides. also describe thesecurity vulnerabilities arise due overﬂow properties computerarithmetic. .Chapter 3: Machine-Level Representation Programs. extended coverage include x86-64, extension x86 processors 64-bit wordsize. also use code generated recent version gcc. enhanced coverage buffer overﬂow vulnerabilities. createdWeb asides two different classes instructions ﬂoating point, andalso view exotic transformations made compilers attempthigher degrees optimization. Another Web aside describes embedx86 assembly code withi n C program.xxvi Preface .Chapter 4: Processor Architecture. include careful exposition exception detection handling processor design. also cre-ated Web aside showing mapping processor designs Verilog,enabling synthesis working hardware. .Chapter 5: Optimizing Program Performance. greatly changed description out-of-order processor operates, createda simple technique analyzing program performance based pathsin data-ﬂow graph representation program. Web aside describeshow C programmers write programs make use SIMD (single-instruction, multiple-data) instructions found recent versions x86processors. .Chapter 6: Memory Hierarchy. added material solid-state disks, updated presentation based memoryhierarchy Intel Core i7 processor. .Chapter 7: Linking. chapter changed slightly. .Chapter 8: Exceptional Control Flow. enhanced discussion process model introduces fundamental concepts concurrency,such nondeterminism. .Chapter 9: Virtual Memory. updated memory system case study describe 64-bit Intel Core i7 processor. also updated sampleimplementation malloc work 32-bit 64-bit execution. .Chapter 10: System-Level I/O. chapter changed slightly. .Chapter 11: Network Programming. chapter changed slightly. .Chapter 12: Concurrent Programming. increased coverage general principles concurrency, also describe programmerscan use thread-level parallelism make programs run faster multi-coremachines. addition, added revised number practice homework problems. Origins Book book stems introductory course developed Carnegie Mel-lon University Fall 1998, called 15-213: Introduction Computer Systems (ICS) [14]. ICS course taught every semester since then, time toabout 150–250 students, ranging sophomores masters degree students wide variety majors. required course undergraduates CS ECE departments Carnegie Mellon, become prerequisitefor upper-level systems courses. idea ICS introduce students computers different way. students would opportunity build computer system. Onthe hand, students, including computer scientists computerengineers, required use program computers daily basis. wePreface xxvii decided teach systems point view programmer, using following ﬁlter: would cover topic affected performance,correctness, utility user-level C programs. example, topics hardware adder bus designs out. Topics machine language in, instead focusing write assem-bly language hand, would look ho w C compiler translates C constructs machine code, including pointers, loops, procedure calls, switch state-ments. Further, would take broader holistic view system hardware systems software, covering topics linking, loading,processes, signals, performance optimization, virtual memory, I/O, networkand concurrent programming. approach allowed us teach ICS course way practical, concrete, hands-on, exciting students. response studentsand faculty colleagues immediate overwhelmingly positive, real- ized others outside CMU might beneﬁt using approach. Hencethis book, developed ICS lecture notes, revised reﬂect changes technology computer systems im-plemented. Instructors: Courses Based Book Instructors use CS:APP book teach ﬁve different kinds systemscourses (Figure 2). particular course depends curriculum requirements,personal taste, backgrounds abilities students. left toright ﬁgure, courses characterized increasing emphasis theprogrammer’s perspective system. brief description: .ORG : computer organization course traditional topics covered untraditional style. Traditional topics logic design, processor architec-ture, assembly language, memory systems covered. However, ismore emphasis impact programmer. example, data repre-sentations related back data types operations C programs,and presentation assembly code based machine code generatedby C compiler rather hand-written assembly code. .ORG+ : ORG course additional emphasis impact hardware performance application programs. Compared ORG, studentslearn code optimization improving memory per- formance C programs. .ICS: baseline ICS course, designed produce enlightened programmers understand impact hardware, operating system, compila-tion system performance correctness application programs.A signiﬁcant difference ORG+ low-level processor architecture isnot covered. Instead, programmers work higher-level model mod-ern out-of-order processor. ICS course ﬁts nicely 10-week quarter,and also stretched 15-week semester covered leisurelypace.xxviii Preface Course Chapter Topic ORG ORG+ ICS ICS+ SP 1 Tour systems • • • • • 2 Data representation • • • • ⊙(d) 3 Machine language • • • • • 4 Processor architecture • •5 Code optimization • • •6 Memory hierarchy ⊙ (a)•• • ⊙(a) 7 Linking ⊙(c)⊙(c)• 8 Exceptional control ﬂow • • • 9 Virtual memory ⊙(b)•• • • 10 System-level I/O • • 11 Network programming • •12 Concurrent programming • • Figure 2 Five systems courses based CS:APP book. Notes: (a) Hardware only, (b) dynamic storage allocation, (c) dynamic linking, (d) ﬂoating point. ICS+ 15-213 course Carnegie Mellon. .ICS+ : baseline ICS course additional coverage systems program- ming topics system-level I/O, network programming, concurrent programming. semester-long Carnegie Mellon course, covers every chapter CS:APP except low-level processor architecture. .SP: systems programming course. Similar ICS+ course, drops ﬂoating point performance optimization, places emphasis onsystems programming, including process control, dynamic linking, system-level I/O, network programming, concurrent programming. Instructorsmight want supplement sources advanced topics asdaemons, terminal control, Unix IPC. main message Figure 2 CS:APP book gives lot options students instructors. want students exposed lower-level processor architecture, option available via ORG ORG+ courses. hand, want switch current computerorganization course ICS ICS+ course, wary making sucha drastic change once, move toward ICS incrementally. Youcan start ORG, teaches traditional topics nontraditional way.Once comfortable material, move ORG+, andeventually ICS. students experience C (for example programmed Java), could spend several weeks C cover material ORG ICS.Preface xxix Finally, note ORG+ SP courses would make nice two-term (either quarters semesters) sequence. might consider offering ICS+ asone term ICS one term SP . Classroom-Tested Laboratory Exercises ICS+ course Carnegie Mellon receives high evaluations students.Median scores 5 .0/5.0 means 4 .6/5.0 typical student course evaluations. Students cite fun, exciting, relevant laboratory exercises asthe primary reason. labs available CS:APP Web page. areexamples labs provided book: .Data Lab. lab requires students implement simple logical arith- metic functions, using highly restricted subset C. example, theymust compute absolute value number using bit-level operations.This lab helps students understand bit-level representations C datatypes bit-level behavior operations data. .Binary Bomb Lab. Abinary bomb program provided students object-code ﬁle. run, prompts user type six different strings. incorrect, bomb “explodes,” printing error messageand logging event grading server. Students must “defuse” theirown unique bombs disassembling reverse engineering programsto determine six strings be. lab teaches students tounderstand assembly language, also forces learn use adebugger. .Buffer Overﬂow Lab. Students required modify run-time behavior binary executable exploiting buffer overﬂow vulnerability. lab teaches students stack discipline, teaches thedanger writing code vulnerable buffer overﬂow attacks. .Architecture Lab. Several homework problems Chapter 4 combined lab assignment, students modify HCL descriptionof processor add new instructions, change branch prediction policy,or add remove bypassing paths register ports. resulting processorscan simulated run automated tests detect thepossible bugs. lab lets students experience exciting parts processordesign without requiring complete background logic design hardwaredescription languages. .Performance Lab. Students must optimize performance application kernel function convolution matrix transposition. lab providesa clear demonstration properties cache memories, givesstudents experience low-level program optimization. .Shell Lab. Students implement Unix shell program job control, including ctrl-c andctrl-z keystrokes, fg,bg, andjobs commands. student’s ﬁrst introduction concurrency, gives clear ideaof Unix process control, signals, signal handling.xxx Preface .Malloc Lab. Students implement versions malloc ,free , (optionally) realloc . lab gives students clear understanding data layout organization, requires evaluate different trade-offsbetween space time efﬁciency. .Proxy Lab. Students implement concurrent Web proxy sits browsers rest World Wide Web. lab exposes thestudents topics Web clients servers, ties together many ofthe concepts course, byte ordering, ﬁle I/O, process control,signals, signal handling, memory mapping, sockets, concurrency. Studentslike able see programs action real Web browsers Webservers. CS:APP Instructor’s Manual detailed discussion labs, well directions downloading support software. Acknowledgments Second Edition deeply grateful many people helped us produce secondedition CS:APP text. First foremost, would recognize colleagues taught ICS course Carnegie Mellon insightful feedback encouragement:Guy Blelloch, Roger Dannenberg, David Eckhardt, Greg Ganger, Seth Goldstein,Greg Kesden, Bruce Maggs, Todd Mowry, Andreas Nowatzyk, Frank Pfenning,and Markus Pueschel. Thanks also sharp-eyed readers contributed reports errata page ﬁrst edition: Daniel Amelang, Rui Baptista, Quarup Barreirinhas,Michael Bombyk, J ¨org Brauer, Jordan Brough, Yixin Cao, James Caroll, Rui Car- valho, Hyoung-Kee Choi, Al Davis, Grant Davis, Christian Dufour, Mao Fan,Tim Freeman, Inge Frick, Max Gebhardt, Jeff Goldblat, Thomas Gross, AnitaGupta, John Hampton, Hiep Hong, Greg Israelsen, Ronald Jones, Haudy Kazemi,Brian Kell, Constantine Kousoulis, Sacha Krakowiak, Arun Krishnaswamy, Mar-tin Kulas, Michael Li, Zeyang Li, Ricky Liu, Mario Lo Conte, Dirk Maas, DevonMacey, Carl Marcinik, Marrero, Simone Martins, Tao Men, Mark Morris-sey, Venkata Naidu, Bhas Nalabothula, Thomas Niemann, Eric Peskin, David Po,Anne Rogers, John Ross, Michael Scott, Seiki, Ray Shih, Darren Shultz, ErikSilkensen, Suryanto, Emil Tarazi, Nawanan Theera-Ampornpunt, Joe Trdinich,Michael Trigoboff, James Troup, Martin Vopatek, Alan West, Betsy Wolff, TimWong, James Woodruff, Scott Wright, Jackie Xiao, Guanpeng Xu, Qing Xu, CarenYang, Yin Yongsheng, Wang Yuanxuan, Steven Zhang, Day Zhong. Specialthanks Inge Frick, identiﬁed subtle deep copy bug lock-and-copyexample, Ricky Liu, amazing proofreading skills. Intel Labs colleagues Andrew Chien Limor Fix exceptionally supportive throughout writing text. Steve Schlosser graciously providedsome disk drive characterizations. Casey Helfrich Michael Ryan installed maintained new Core i7 box. Michael Kozuch, Babu Pillai, Jason Campbell provided valuable insight memory system performance, multi-corePreface xxxi systems, power wall. Phil Gibbons Shimin Chen shared consid- erable expertise solid-state disk designs. able call talents many, including Wen-Mei Hwu, Markus Pueschel, Jiri Simsa, provide detailed comments high-level advice. James Hoe helped us create Verilog version Y86 processorand work needed synthesize working hardware. Many thanks colleagues provided reviews draft manu- script: James Archibald (Brigham Young University), Richard Carver (GeorgeMason University), Mirela Damian (Villanova University), Peter Dinda (North-western University), John Fiore (Temple University), Jason Fritts (St. Louis Uni-versity), John Greiner (Rice University), Brian Harvey (University California,Berkeley), Heller (Penn State University), Wei Chung Hsu (University ofMinnesota), Michelle Hugue (University Maryland), Jeremy Johnson (DrexelUniversity), Geoff Kuenning (Harvey Mudd College), Ricky Liu, Sam Mad-den (MIT), Fred Martin (University Massachusetts, Lowell), Abraham Matta(Boston University), Markus Pueschel (Carnegie Mellon University), NormanRamsey (Tufts University), Glenn Reinmann (UCLA), Michela Taufer (Univer-sity Delaware), Craig Zilles (UIUC). Paul Anagnostopoulos Windfall Software outstanding job type- setting book leading production team. Many thanks Paul hissuperb team: Rick Camp (copyeditor), Joe Snowden (compositor), MaryEllen N.Oliver (proofreader), Laurel Muller (artist), Ted Laux (indexer). Finally, would like thank friends Prentice Hall. Marcia Horton always us. editor Matt Goldstein provided stellar leadership beginning end. profoundly grateful help, encouragement,and insights. Acknowledgments First Edition deeply indebted many friends colleagues thoughtful crit-icisms encouragement. special thanks 15-213 students, whose infec-tious energy enthusiasm spurred us on. Nick Carter Vinny Furia gener- ously provided malloc package. Guy Blelloch, Greg Kesden, Bruce Maggs, Todd Mowry taught course multiple semesters, gave us encouragement, helped improve coursematerial. Herb Derby provided early spiritual guidance encouragement. Al-lan Fisher, Garth Gibson, Thomas Gross, Satya, Peter Steenkiste, Hui Zhangencouraged us develop course start. suggestion Garthearly got whole ball rolling, picked reﬁned thehelp group led Allan Fisher. Mark Stehlik Peter Lee supportive building material undergraduate curriculum. Greg Kesden provided helpful feedback impact ICS OS course. GregGanger Jiri Schindler graciously provided disk drive characterizationsand answered questions modern disks. Tom Stricker showed us mem-ory mountain. James Hoe provided useful ideas feedback presentprocessor architecture.xxxii Preface special group students—Khalil Amiri, Angela Demke Brown, Chris Colohan, Jason Crawford, Peter Dinda, Julio Lopez, Bruce Lowekamp, JeffPierce, Sanjay Rao, Balaji Sarpeshkar, Blake Scholl, Sanjit Seshia, Greg Stef-fan, Tiankai Tu, Kip Walker, Yinglian Xie—were instrumental helpingus develop content course. particular, Chris Colohan established afun (and funny) tone persists day, invented legendary “binarybomb” proven great tool teaching machine code debuggingconcepts. Chris Bauer, Alan Cox, Peter Dinda, Sandhya Dwarkadas, John Greiner, Bruce Jacob, Barry Johnson, Heller, Bruce Lowekamp, Greg Morrisett,Brian Noble, Bobbie Othmer, Bill Pugh, Michael Scott, Mark Smotherman, GregSteffan, Bob Wier took time read advise uson early drafts book. special thanks Al Davis (University ofUtah), Peter Dinda (Northwestern University), John Greiner (Rice University),Wei Hsu (University Minnesota), Bruce Lowekamp (College William &Mary), Bobbie Othmer (University Minnesota), Michael Scott (University ofRochester), Bob Wier (Rocky Mountain College) class testing Betaversion. special thanks students well! would also like thank colleagues Prentice Hall. Marcia Horton, Eric Frank, Harold Stone unﬂagging support vision.Harold also helped us present accurate historical perspective RISC andCISC processor architectures. Jerry Ralya provided sharp insights taught usa lot good writing. Finally, would like acknowledge great technical writers Brian Kernighan late W. Richard Stevens, showing us technical bookscan beautiful. Thank all. Randy Bryant Dave O’HallaronPittsburgh, PennsylvaniaAbout Authors Randal E. Bryant received Bachelor’s degree University Michigan 1973 attendedgraduate school Massachusetts Institute ofTechnology, receiving Ph.D. degree computer sci-ence 1981. spent three years AssistantProfessor California Institute Technology,and faculty Carnegie Mellon since1984. currently University Professor Com-puter Science Dean School ComputerScience. also holds courtesy appointment Department Electrical Computer Engineering. taught courses computer systems undergraduate graduate level 30 years. many years teaching computer archi- tecture courses, began shifting focus computers designed toone programmers write efﬁcient reliable programs theyunderstand system better. Together Professor O’Hallaron, developedthe course 15-213 “Introduction Computer Systems” Carnegie Mellon basis book. also taught courses algorithms, programming,computer networking, VLSI design. Professor Bryant’s research concerns design software tools help software hardware designers verify correctness systems.These include several types simulators, well formal veriﬁcation tools thatprove correctness design using mathematical methods. publishedover 150 technical papers. research results used major computer manu-facturers, including Intel, FreeScale, IBM, Fujitsu. several majorawards research. include two inventor recognition awards atechnical achievement award Semiconductor Research Corporation, theKanellakis Theory Practice Award Association Computer Ma-chinery (ACM), W. R. G. Baker Award, Emmanuel Piore Award, andthe Phil Kaufman Award Institute Electrical Electronics Engi- neers (IEEE). Fellow ACM IEEE member U.S. National Academy Engineering. xxxiiixxxiv Authors David R. O’Hallaron Director Intel Labs Pittsburgh Associate Professor ComputerScience Electrical Computer Engineering atCarnegie Mellon University. received Ph.D.from University Virginia. taught computer systems courses undergraduate graduate levels topics ascomputer architecture, introductory computer sys-tems, parallel processor design, Internet services.Together Professor Bryant, developed thecourse Carnegie Mellon led book. 2004, awarded Herbert Simon Award Teaching Excellence theCMU School Computer Science, award winner chosen basedon poll students. Professor O’Hallaron works area computer systems, speciﬁc interests software systems scientiﬁc computing, data-intensive computing,and virtualization. best known example work Quake project, agroup computer scientists, civil engineers, seismologists devel-oped ability predict motion ground strong earthquakes. In2003, Professor O’Hallaron members Quake team theGordon Bell Prize, top international prize high-performance computing.CHAPTER1 Tour Computer Systems 1.1 Information Bits + Context 3 1.2 Programs Translated Programs Different Forms 4 1.3 Pays Understand Compilation Systems Work 6 1.4 Processors Read Interpret Instructions Stored Memory 7 1.5 Caches Matter 12 1.6 Storage Devices Form Hierarchy 13 1.7 Operating System Manages Hardware 14 1.8 Systems Communicate Systems Using Networks 20 1.9 Important Themes 21 1.10 Summary 25 Bibliographic Notes 26 12 Chapter 1 Tour Computer Systems Acomputer system consists hardware systems software work together run application programs. Speciﬁc implementations systems change overtime, underlying concepts not. computer systems similarhardware software components perform similar functions. book iswritten programmers want get better craft understandinghow components work affect correctness performanceof programs. poised exciting journey. dedicate learning concepts book, way becoming rare “power pro-grammer,” enlightened understanding underlying computer systemand impact application programs. going learn practical skills avoid strange numerical errors caused way computers represent numbers. learn howto optimize C code using clever tricks exploit designs modern processors memory systems. learn compiler implementsprocedure calls use knowledge avoid security holes buffer overﬂow vulnerabilities plague network Internet software. willlearn recognize avoid nasty errors linking confoundthe average programmer. learn write Unix shell, yourown dynamic storage allocation package, even Web server. willlearn promises pitfalls concurrency, topic increasing importance asmultiple processor cores integrated onto single chips. classic text C programming language [58], Kernighan Ritchie introduce readers C using hello program shown Figure 1.1. Although hello simple program, every major part system must work concert order run completion. sense, goal thisbook help understand happens why, run hello system. begin study systems tracing lifetime hello program, time created programmer, runs system, prints itssimple message, terminates. follow lifetime program, willbrieﬂy introduce key concepts, terminology, components come intoplay. Later chapters expand ideas. code/intro/hello.c 1#include <stdio.h> 2 3int main() 4{ 5 printf("hello, world\n"); 6} code/intro/hello.c Figure 1.1 Thehello program.Section 1.1 Information Bits + Context 3 1.1 Information Bits + Context Ourhello program begins life source program (or source ﬁle ) programmer creates editor saves text ﬁle called hello.c .T h e source program sequence bits, value 0 1, organizedin 8-bit chunks called bytes . byte represents text character program. modern systems represent text characters using ASCII standard represents character unique byte-sized integer value. example,Figure 1.2 shows ASCII representation hello.c program. Thehello.c program stored ﬁle sequence bytes. byte integer value corresponds character. example, ﬁrst bytehas integer value 35, corresponds character ‘ #’. second byte integer value 105, corresponds character ‘ i’, on. Notice text line terminated invisible newline character ‘ \n’, represented integer value 10. Files hello.c consist exclusively ASCII characters known text ﬁles . ﬁles known binary ﬁles. representation hello.c illustrates fundamental idea: information system—including disk ﬁles, programs stored memory, user data stored inmemory, data transferred across network—is represented bunch bits.The thing distinguishes different data objects context whichwe view them. example, different contexts, sequence bytes might represent integer, ﬂoating-point number, character string, machine instruction. programmers, need understand machine representations numbers integers real numbers. ﬁniteapproximations behave unexpected ways. fundamental idea isexplored detail Chapter 2. #include <sp> <stdio. 35 105 110 99 108 117 100 101 32 60 115 116 100 105 111 46 h > \n \n n <sp> main() \ n { 104 62 10 10 105 110 116 32 109 97 105 110 40 41 10 123 \n <sp> <sp> <sp> <sp> printf("hel 10 32 32 32 32 112 114 105 110 116 102 40 34 104 101 108 l , <sp> world\n");\ n } 108 111 44 32 119 111 114 108 100 92 110 34 41 59 10 125 Figure 1.2 ASCII text representation hello.c .4 Chapter 1 Tour Computer Systems Aside Origins C programming language C developed 1969 1973 Dennis Ritchie Bell Laboratories. American National Standards Institute (ANSI) ratiﬁed ANSI C standard 1989, standardization later became responsibility International Standards Organization (ISO). standards deﬁne C language set library functions known C standard library . Kernighan Ritchie describe ANSI C classic book, known affectionately “K&R” [58]. Ritchie’s words [88], C “quirky, ﬂawed, enormous success.” success? .C closely tied Unix operating system. C developed beginning system programming language Unix. Unix kernel, supporting tools libraries, written C. Unix became popular universities late 1970s early 1980s, many people exposed C found liked it. Since Unix written almost entirely C, could easily ported new machines, created even wider audience forboth C Unix. .C small, simple language. design controlled single person, rather committee, result clean, consistent design little baggage. K&R book describes thecomplete language standard library, numerous examples exercises, 261 pages. simplicity C made relatively easy learn port different computers. .C designed practical purpose. C designed implement Unix operating system. Later, people found could write programs wanted, without language getting way. C language choice system-level programming, huge installed base application-level programs well. However, perfect programmers situations. C pointers common source confusion programming errors. C also lacks explicit support useful abstractions classes, objects, exceptions. Newer languages C++ Javaaddress issues application-level programs. 1.2 Programs Translated Programs Different Forms Thehello program begins life high-level C program read understood human beings form. However, order run hello.c system, individual C statements must translated programsinto sequence low-level machine-language instructions. instructions packaged form called executable object program stored binary disk ﬁle. Object programs also referred executable object ﬁles . Unix system, translation source ﬁle object ﬁle performed compiler driver : unix> gcc -o hello hello.cSection 1.2 Programs Translated Programs Different Forms 5 Pre- processor (cpp)Compiler (cc1)Assembler (as)Linker (ld)hello.c hello.i hello.s hello.oprintf.o hello Source program (text)Modified source program (text)Assembly program (text)Relocatable object programs (binary)Executable object program (binary) Figure 1.3 compilation system. Here, gcccompiler driver reads source ﬁle hello.c translates executable object ﬁle hello . translation performed sequence four phases shown Figure 1.3. programs perform four phases(preprocessor ,compiler ,assembler , linker ) known collectively compilation system . .Preprocessing phase. preprocessor ( cpp) modiﬁes original C program according directives begin #character. example, #include <stdio.h> command line 1 hello.c tells preprocessor read contents system header ﬁle stdio.h insert directly program text. result another C program, typically .i sufﬁx. .Compilation phase. compiler ( cc1) translates text ﬁle hello.i text ﬁle hello.s , contains assembly-language program . statement assembly-language program exactly describes one low-levelmachine-language instruction standard text form. Assembly language useful provides common output language different compilers different high-level languages. example, C compilers Fortrancompilers generate output ﬁles assembly language. .Assembly phase. Next, assembler ( as) translates hello.s machine- language instructions, packages form known relocatable object program , stores result object ﬁle hello.o .T h e hello.o ﬁle binary ﬁle whose bytes encode machine language instructions rather thancharacters. view hello.o text editor, would appear gibberish. .Linking phase. Notice hello program calls printf function, part standard C library provided every C compiler. printf function resides separate precompiled object ﬁle called printf.o , must somehow merged hello.o program. linker ( ld) handles merging. result hello ﬁle, executable object ﬁle (or simply executable ) ready loaded memory executed system.6 Chapter 1 Tour Computer Systems Aside GNU project GCC one many useful tools developed GNU (short GNU’s Unix) project. GNU project tax-exempt charity started Richard Stallman 1984, ambitious goal developing complete Unix-like system whose source code unencumbered restrictions modiﬁed distributed. GNU project developed environment major components Unix operating system, except kernel, developed separately Linux project. GNU environment includes emacs editor, gcc compiler, gdb debugger, assembler, linker, utilities manipulating binaries, components. gcc compiler grown support many different languages, ability generate code many differentmachines. Supported languages include C, C++, Fortran, Java, Pascal, Objective-C, Ada. GNU project remarkable achievement, yet often overlooked. modern open- source movement (commonly associated Linux) owes intellectual origins GNU project’snotion free software (“free” “free speech,” “free beer”). Further, Linux owes much popularity GNU tools, provide environment Linux kernel. 1.3 Pays Understand Compilation Systems Work simple programs hello.c , rely compilation system produce correct efﬁcient machine code. However, importantreasons programmers need understand compilation systems work: .Optimizing program performance. Modern compilers sophisticated tools usually produce good code. programmers, need knowthe inner workings compiler order write efﬁcient code. However,in order make good coding decisions C programs, need abasic understanding machine-level code compiler translatesdifferent C statements machine code. example, switch statement always efﬁcient sequence if-else statements? much overhead incurred function call? loop efﬁcient aforloop? pointer references efﬁcient array indexes? loop run much faster sum local variable instead argument passed reference? function run faster wesimply rearrange parentheses arithmetic expression? Chapter 3, introduce two related machine languages: IA32, 32-bit code become ubiquitous machines running Linux, Windows,and recently Macintosh operating systems, x86-64, 64-bitextension found recent microprocessors. describe compilerstranslate different C constructs languages. Chapter 5, willlearn tune performance C programs making simpletransformations C code help compiler job better. InChapter 6, learn hierarchical nature memory system,how C compilers store data arrays memory, C programs canexploit knowledge run efﬁciently.Section 1.4 Processors Read Interpret Instructions Stored Memory 7 .Understanding link-time errors. experience, perplex- ing programming errors related operation linker, especiallywhen trying build large software systems. example, doesit mean linker reports cannot resolve reference? thedifference static variable global variable? happens ifyou deﬁne two global variables different C ﬁles name? Whatis difference static library dynamic library? itmatter order list libraries command line? scariest all,why linker-related errors appear run time? learnthe answers kinds questions Chapter 7. .Avoiding security holes. many years, buffer overﬂow vulnerabilities accounted majority security holes network Internet servers.These vulnerabilities exist programmers understand needto carefully restrict quantity forms data accept untrustedsources. ﬁrst step learning secure programming understand con-sequences way data control information stored programstack. cover stack discipline buffer overﬂow vulnerabilities inChapter 3 part study assembly language. also learn aboutmethods used programmer, compiler, operating systemto reduce threat attack. 1.4 Processors Read Interpret Instructions Stored Memory point, hello.c source program translated compilation system executable object ﬁle called hello stored disk. run executable ﬁle Unix system, type name application programknown shell : unix> ./hello hello, world unix> shell command-line interpreter prints prompt, waits type command line, performs command. ﬁrst word commandline correspond built-in shell command, shell assumes thatit name executable ﬁle load run. case,the shell loads runs hello program waits terminate. hello program prints message screen terminates. shell prints prompt waits next input command line. 1.4.1 Hardware Organization System understand happens hello program run it, need understand hardware organization typical system, shown Figure 1.4. particular picture modeled family Intel Pentium8 Chapter 1 Tour Computer Systems Figure 1.4 Hardware organizationof typical system. CPU: Central Processing Unit,ALU: Arithmetic/Logic Unit, PC: Program counter, USB: Universal Serial Bus.CPU Register file PC ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O bus Expansion slots devices suchas network adapters Disk controllerGraphics adapter Display Mouse KeyboardUSB controller Diskhello executable stored disk systems, systems similar look feel. Don’t worry complexity ﬁgure now. get various details stagesthroughout course book. Buses Running throughout system collection electrical conduits called buses carry bytes information back forth components. Busesare typically designed transfer ﬁxed-sized chunks bytes known words .T h e number bytes word (the word size ) fundamental system parameter varies across systems. machines today word sizes either 4 bytes (32bits) 8 bytes (64 bits). sake discussion here, assume wordsize 4 bytes, assume buses transfer one word time. I/O Devices Input/output (I/O) devices system’s connection external world. Ourexample system four I/O devices: keyboard mouse user input, adisplay user output, disk drive (or simply disk) long-term storage ofdata programs. Initially, executable hello program resides disk. I/O device connected I/O bus either controller adapter . distinction two mainly one packaging. Controllers chipsets device system’s main printed circuit board (often calledthemotherboard ). adapter card plugs slot motherboard. Regardless, purpose transfer information back forth I/O bus I/O device.Section 1.4 Processors Read Interpret Instructions Stored Memory 9 Chapter 6 say I/O devices disks work. Chapter 10, learn use Unix I/O interface access devices fromyour application programs. focus especially interesting class devicesknown networks, techniques generalize kinds devices well. Main Memory main memory temporary storage device holds program data manipulates processor executing program. Physically, main memory consists collection dynamic random access memory (DRAM) chips. Logically, memory organized linear array bytes, ownunique address (array index) starting zero. general, machineinstructions constitute program consist variable number bytes.The sizes data items correspond C program variables vary according totype. example, IA32 machine running Linux, data type short requires two bytes, types int,float , long four bytes, type double eight bytes. Chapter 6 say memory technologies DRAM chips work, combined form main memory. Processor central processing unit (CPU), simply processor , engine inter- prets (or executes ) instructions stored main memory. core word-sized storage device (or register ) called program counter (PC). point time, PC points (contains address of) machine-language instruction main memory.1 time power applied system, time power shut off, processor repeatedly executes instruction pointed theprogram counter updates program counter point next instruction.A processor appears operate according simple instruction execution model, deﬁned instruction set architecture . model, instructions execute strict sequence, executing single instruction involves performing seriesof steps. processor reads instruction memory pointed theprogram counter (PC), interprets bits instruction, performs simpleoperation dictated instruction, updates PC point nextinstruction, may may contiguous memory instruction thatwas executed. simple operations, revolve around main memory, register ﬁle , arithmetic/logic unit (ALU). register ﬁle small storage device consists collection word-sized registers,each unique name. ALU computes new data address values.Here examples simple operations CPU might carry outat request instruction: 1. PC also commonly used acronym “personal computer.” However, distinction two clear context.10 Chapter 1 Tour Computer Systems .Load: Copy byte word main memory register, overwriting previous contents register. .Store: Copy byte word register location main memory, overwriting previous contents location. .Operate: Copy contents two registers ALU, perform arithmetic operation two words, store result register, overwriting theprevious contents register. .Jump: Extract word instruction copy word program counter (PC), overwriting previous value PC. say processor appears simple implementation in- struction set architecture, fact modern processors use far complexmechanisms speed program execution. Thus, distinguish pro-cessor’s instruction set architecture, describing effect machine-codeinstruction, microarchitecture , describing processor actually implemented. study machine code Chapter 3, consider theabstraction provided machine’s instruction set architecture. Chapter 4 hasmore say processors actually implemented. 1.4.2 Running hello Program Given simple view system’s hardware organization operation, begin understand happens run example program. mustomit lot details ﬁlled later, contentwith big picture. Initially, shell program executing instructions, waiting us type command. type characters “ ./hello ” keyboard, shell program reads one register, stores memory, shown inFigure 1.5. hit enter key keyboard, shell knows ﬁnished typing command. shell loads executable hello ﬁle executing sequence instructions copies code data hello object ﬁle disk main memory. data include string characters“hello, world\n ” eventually printed out. Using technique known direct memory access (DMA, discussed Chap- ter 6), data travels directly disk main memory, without passing throughthe processor. step shown Figure 1.6. code data hello object ﬁle loaded memory, processor begins executing machine-language instructions hello pro- gram’s main routine. instructions copy bytes “ hello, world\n ” string memory register ﬁle, display device, wherethey displayed screen. step shown Figure 1.7.Section 1.4 Processors Read Interpret Instructions Stored Memory 11 Figure 1.5 Reading hello command thekeyboard.CPU Register file PC ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O bus Expansion slots devices suchas network adaptersDisk controllerGraphics adapter Display Mouse KeyboardUSB controller Disk“hello” User types “hello” DiskCPU Register file PC ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O bus Expansion slots devices suchas network adapters Disk controllerGraphics adapter Display Mouse KeyboardUSB controller“hello, world\n” hello code hello executable stored disk Figure 1.6 Loading executable disk main memory.12 Chapter 1 Tour Computer Systems Figure 1.7 Writing output stringfrom memory thedisplay.CPU Register file PC ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O bus Expansion slots devices suchas network adapters Disk controllerGraphics adapter Display Mouse KeyboardUSB controller Disk “hello, world\n”“hello, world\n” hello code hello executable stored disk 1.5 Caches Matter important lesson simple example system spends lot time moving information one place another. machine instructions inthehello program originally stored disk. program loaded, copied main memory. processor runs program, instruc-tions copied main memory processor. Similarly, data string“hello,world\n ”, originally disk, copied main memory, copied main memory display device. programmer’s perspective, muchof copying overhead slows “real work” program. Thus,a major goal system designers make copy operations run fast aspossible. physical laws, larger storage devices slower smaller stor- age devices. faster devices expensive build slowercounterparts. example, disk drive typical system might 1000 timeslarger main memory, might take processor 10,000,000 timeslonger read word disk memory. Similarly, typical register ﬁle stores hundred bytes information, opposed billions bytes main memory. However, processor canread data register ﬁle almost 100 times faster memory. Evenmore troublesome, semiconductor technology progresses years, thisprocessor-memory gap continues increase. easier cheaper make processors run faster make main memory run faster. deal processor-memory gap, system designers include smaller faster storage devices called cache memories (or simply caches) serve temporary staging areas information processor likely need inthe near future. Figure 1.8 shows cache memories typical system. L1Section 1.6 Storage Devices Form Hierarchy 13 Figure 1.8 Cache memories. I/O bridgeCPU chip Cache memoriesRegister file System bus Memory bus Bus interfaceMain memoryALU cache processor chip holds tens thousands bytes accessed nearly fast register ﬁle. larger L2 cache hundreds thousands millions bytes connected processor special bus. might take 5times longer process access L2 cache L1 cache, isstill 5 10 times faster accessing main memory. L1 L2 caches areimplemented hardware technology known static random access memory (SRAM). Newer powerful systems even three levels cache: L1,L2, L3. idea behind caching system get effect botha large memory fast one exploiting locality , tendency programs access data code localized regions. setting caches holddata likely accessed often, perform memory operationsusing fast caches. One important lessons book application program- mers aware cache memories exploit improve perfor-mance programs order magnitude. learn aboutthese important devices exploit Chapter 6. 1.6 Storage Devices Form Hierarchy notion inserting smaller, faster storage device (e.g., cache memory)between processor larger slower device (e.g., main memory) turns outto general idea. fact, storage devices every computer system areorganized memory hierarchy similar Figure 1.9. move top hierarchy bottom, devices become slower, larger, less costlyper byte. register ﬁle occupies top level hierarchy, knownas level 0, L0. show three levels caching L1 L3, occupying memory hierarchy levels 1 3. Main memory occupies level 4, on. main idea memory hierarchy storage one level serves cache storage next lower level. Thus, register ﬁle cache theL1 cache. Caches L1 L2 caches L2 L3, respectively. L3 cacheis cache main memory, cache disk. networkedsystems distributed ﬁle systems, local disk serves cache data storedon disks systems.14 Chapter 1 Tour Computer Systems CPU registers hold words retrieved cache memory. L1 cache holds cache lines retrieved L2 cache. L2 cache holds cache lines retrieved L3 cache. Main memory holds disk blocks retrieved local disks. Local disks hold files retrieved disks onremote network server.Regs L3 cache (SRAM)L2 cache (SRAM)L1 cache (SRAM) Main memory (DRAM) Local secondary storage (local disks) Remote secondary storage (distributed file systems, Web servers)Smaller, faster, costlier (per byte) storage devices Larger, slower, cheaper (per byte) storage devicesL0: L1: L2: L3: L4: L5: L6:L3 cache holds cache lines retrieved memory. Figure 1.9 example memory hierarchy. programmers exploit knowledge different caches improve performance, programmers exploit understanding entire memory hierarchy. Chapter 6 much say this. 1.7 Operating System Manages Hardware Back hello example. shell loaded ran hello program, hello program printed message, neither program accessed keyboard, display, disk, main memory directly. Rather, relied theservices provided operating system . think operating system layer software interposed application program hardware,as shown Figure 1.10. attempts application program manipulate thehardware must go operating system. operating system two primary purposes: (1) protect hardware misuse runaway applications, (2) provide applications simple uniform mechanisms manipulating complicated often wildly differentlow-level hardware devices. operating system achieves goals via Figure 1.10 Layered view acomputer system.Application programs Operating system Main memory I/O devices ProcessorSoftware HardwareSection 1.7 Operating System Manages Hardware 15 Figure 1.11 Abstractions provided byan operating system. Main memory I/O devices ProcessorProcesses Virtual memory Files fundamental abstractions shown Figure 1.11: processes ,virtual memory , ﬁles. ﬁgure suggests, ﬁles abstractions I/O devices, virtual memory abstraction main memory disk I/O devices, processesare abstractions processor, main memory, I/O devices. discusseach turn. Aside Unix Posix 1960s era huge, complex operating systems, IBM’s OS/360 Honeywell’s Multics systems. OS/360 one successful software projects history, Multics dragged years never achieved wide-scale use. Bell Laboratories original partner Multics project, dropped 1969 concern complexity project thelack progress. reaction unpleasant Multics experience, group Bell Labs researchers—Ken Thompson, Dennis Ritchie, Doug McIlroy, Joe Ossanna—began work 1969 simpleroperating system DEC PDP-7 computer, written entirely machine language. Many ideas new system, hierarchical ﬁle system notion shell user-level process, borrowed Multics implemented smaller, simpler package. 1970, Brian Kernighan dubbed new system “Unix” pun complexity “Multics.” kernel rewritten inC 1973, Unix announced outside world 1974 [89]. Bell Labs made source code available schools generous terms, Unix developed large following universities. inﬂuential work done University Californiaat Berkeley late 1970s early 1980s, Berkeley researchers adding virtual memory Internet protocols series releases called Unix 4.xBSD (Berkeley Software Distribution). Concurrently, Bell Labs releasing versions, became known System V Unix. Versions vendors, Sun Microsystems Solaris system, derived original BSD System V versions. Trouble arose mid 1980s Unix vendors tried differentiate adding new often incompatible features. combat trend, IEEE (Institute Electrical Electronics Engineers) sponsored effort standardize Unix, later dubbed “Posix” Richard Stallman. result family standards, known Posix standards, cover issues C languageinterface Unix system calls, shell programs utilities, threads, network programming. systems comply fully Posix standards, differences Unix versions gradually disappearing.16 Chapter 1 Tour Computer Systems 1.7.1 Processes program hello runs modern system, operating system provides illusion program one running system. Theprogram appears exclusive use processor, main memory, andI/O devices. processor appears execute instructions program, oneafter other, without interruption. code data program appearto objects system’s memory. illusions provided thenotion process, one important successful ideas computerscience. Aprocess operating system’s abstraction running program. Multi- ple processes run concurrently system, process appearsto exclusive use hardware. concurrently , mean instruc- tions one process interleaved instructions another process. Inmost systems, processes run CPUs run them.Traditional systems could execute one program time, newer multi- core processors execute several programs simultaneously. either case, single CPU appear execute multiple processes concurrently theprocessor switch among them. operating system performs interleavingwith mechanism known context switching . simplify rest discus- sion, consider uniprocessor system containing single CPU. return discussion multiprocessor systems Section 1.9.1. operating system keeps track state information process needs order run. state, known context , includes infor- mation current values PC, register ﬁle, contentsof main memory. point time, uniprocessor system execute code single process. operating system decides transfer con-trol current process new process, performs context switch saving context current process, restoring context newprocess, passing control new process. new process picks upexactly left off. Figure 1.12 shows basic idea example hello scenario. two concurrent processes example scenario: shell process hello process. Initially, shell process running alone, waiting input command line. ask run hello program, shell carries Figure 1.12 Process context switching.Process readProcess B User code Kernel code Kernel codeUser code User codeContext switch Context switchTime Disk interrupt Return fromreadSection 1.7 Operating System Manages Hardware 17 request invoking special function known system call passes control operating system. operating system saves shell’s context,creates new hello process context, passes control new hello process. hello terminates, operating system restores context shell process passes control back it, waits nextcommand line input. Implementing process abstraction requires close cooperation low-level hardware operating system software. explorehow works, applications create control processes,in Chapter 8. 1.7.2 Threads Although normally think process single control ﬂow, modern systems process actually consist multiple execution units, called threads , running context process sharing code globaldata. Threads increasingly important programming model therequirement concurrency network servers, easier share databetween multiple threads multiple processes, threadsare typically efﬁcient processes. Multi-threading also one way makeprograms run faster multiple processors available, discuss inSection 1.9.1. learn basic concepts concurrency, including towrite threaded programs, Chapter 12. 1.7.3 Virtual Memory Virtual memory abstraction provides process illusion exclusive use main memory. process uniform view memory, known virtual address space . virtual address space Linux processes shown Figure 1.13. (Other Unix systems use similar layout.)In Linux, topmost region address space reserved code datain operating system common processes. lower region theaddress space holds code data deﬁned user’s process. Note thataddresses ﬁgure increase bottom top. virtual address space seen process consists number well- deﬁned areas, speciﬁc purpose. learn areas later book, helpful look brieﬂy each, starting thelowest addresses working way up: .Program code data. Code begins ﬁxed address processes, followed data locations correspond global C variables. code anddata areas initialized directly contents executable object ﬁle,in case hello executable. learn part address space study linking loading Chapter 7.18 Chapter 1 Tour Computer Systems Figure 1.13 Process virtual addressspace. 0x08048000 (32) 0x00400000 (64) 0Memory invisible touser code printf function Loaded hello executable fileUser stack (created run time) Memory mapped region shared libraries Run-time heap (created run time malloc ) Read/write data Read-only code dataKernel virtual memory .Heap. code data areas followed immediately run-time heap . Unlike code data areas, ﬁxed size process beginsrunning, heap expands contracts dynamically run time resultof calls C standard library routines malloc andfree . study heaps detail learn managing virtual memory Chapter 9. .Shared libraries. Near middle address space area holds code data shared libraries C standard library math library. notion shared library powerful somewhat difﬁcultconcept. learn work study dynamic linking inChapter 7. .Stack. top user’s virtual address space user stack compiler uses implement function calls. Like heap, user stackexpands contracts dynamically execution program. Inparticular, time call function, stack grows. time returnfrom function, contracts. learn compiler uses stackin Chapter 3. .Kernel virtual memory. kernel part operating system always resident memory. top region address space reserved forthe kernel. Application programs allowed read write contentsof area directly call functions deﬁned kernel code. virtual memory work, sophisticated interaction required hardware operating system software, including hardware translationof every address generated processor. basic idea store contentsSection 1.7 Operating System Manages Hardware 19 process’s virtual memory disk, use main memory cache disk. Chapter 9 explains works important theoperation modern systems. 1.7.4 Files Aﬁleis sequence bytes, nothing nothing less. Every I/O device, including disks, keyboards, displays, even networks, modeled ﬁle. input output system performed reading writing ﬁles, using asmall set system calls known Unix I/O . simple elegant notion ﬁle nonetheless powerful provides applications uniform view varied I/O devices thatmight contained system. example, application programmers whomanipulate contents disk ﬁle blissfully unaware speciﬁc disktechnology. Further, program run different systems use different disk technologies. learn Unix I/O Chapter 10. Aside Linux project August 1991, Finnish graduate student named Linus Torvalds modestly announced new Unix-like operating system kernel: From: torvalds@klaava.Helsinki.FI (Linus Benedict Torvalds) Newsgroups: comp.os.minix Subject: would like see minix?Summary: small poll new operating system Date: 25 Aug 91 20:57:08 GMT Hello everybody using minix - I’m (free) operating system (just hobby, won’t big professional like gnu) 386(486) clones. brewing since April, starting get ready. I’d like feedback things people like/dislike minix, OS resembles somewhat (same physical layout file-system (due practical reasons)among things). I’ve currently ported bash(1.08) gcc(1.40), things seem work. implies I’ll get something practical within months, I’d like know features people would want. suggestions welcome, won’t promise I’ll implement :-) Linus (torvalds@kruuna.helsinki.fi)20 Chapter 1 Tour Computer Systems rest, say, history. Linux evolved technical cultural phenomenon. combining forces GNU project, Linux project developed complete, Posix-compliant version Unix operating system, including kernel supporting infrastructure. Linux available wide array computers, hand-held devices mainframe computers. group IBM even ported Linux wristwatch! 1.8 Systems Communicate Systems Using Networks point tour systems, treated system isolated collection hardware software. practice, modern systems often linkedto systems networks. point view individual system, thenetwork viewed another I/O device, shown Figure 1.14. Whenthe system copies sequence bytes main memory network adapter,the data ﬂows across network another machine, instead of, say, localdisk drive. Similarly, system read data sent machines copythis data main memory. advent global networks Internet, copying information one machine another become one important uses ofcomputer systems. example, applications email, instant messaging, theWorld Wide Web, FTP , telnet based ability copy informationover network. Returning hello example, could use familiar telnet application run hello remote machine. Suppose use telnet client running Figure 1.14 network another I/Odevice.CPU chip Register file PC ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O busExpansion slots Disk controllerNetwork adapter NetworkGraphics adapter Monitor Mouse KeyboardUSB controller DiskSection 1.9 Important Themes 21 1.User types “hello ” keyboard 5. Client prints “hello, world\n ” string display2. Client sends “ hello ” string telnet server 4. Telnet server sends “hello, world\n ” string client3. Server sends “ hello ” string shell, runs hello program passes output telnet serverLocal telnet clientRemote telnet server Figure 1.15 Using telnet run hello remotely network. local machine connect telnet server remote machine. log remote machine run shell, remote shell waiting receive aninput command. point, running hello program remotely involves ﬁve basic steps shown Figure 1.15. type “ hello ” string telnet client hit enter key, client sends string telnet server. telnet server receives thestring network, passes along remote shell program. Next, theremote shell runs hello program, passes output line back telnet server. Finally, telnet server forwards output string across network tothe telnet client, prints output string local terminal. type exchange clients servers typical network applications. Chapter 11, learn build network applications, andapply knowledge build simple Web server. 1.9 Important Themes concludes initial whirlwind tour systems. important idea takeaway discussion system hardware. acollection intertwined hardware systems software must cooperate inorder achieve ultimate goal running application programs. rest ofthis book ﬁll details hardware software, willshow how, knowing details, write programs faster, morereliable, secure. close chapter, highlight several important concepts cut across aspects computer systems. discuss importance theseconcepts multiple places within book. 1.9.1 Concurrency Parallelism Throughout history digital computers, two demands constant forces driving improvements: want more, want torun faster. factors improve processor things atonce. use term concurrency refer general concept system multiple, simultaneous activities, term parallelism refer use concurrency make system run faster. Parallelism exploited multiple22 Chapter 1 Tour Computer Systems levels abstraction computer system. highlight three levels here, working highest lowest level system hierarchy. Thread-Level Concurrency Building process abstraction, able devise systems multipleprograms execute time, leading concurrency . threads, even multiple control ﬂows executing within single process. Support concurrent execution found computer systems since adventof time-sharing early 1960s. Traditionally, concurrent execution wasonly simulated , single computer rapidly switch among executing processes, much juggler keeps multiple balls ﬂying air. formof concurrency allows multiple users interact system time,such many people want get pages single Web server. alsoallows single user engage multiple tasks concurrently, aWeb browser one window, word processor another, streaming musicplaying time. recently, actual computing done asingle processor, even processor switch among multiple tasks. Thisconﬁguration known uniprocessor system. construct system consisting multiple processors control single operating system kernel, multiprocessor system . systems available large-scale computing since 1980s, butthey recently become commonplace advent multi-core processors hyperthreading . Figure 1.16 shows taxonomy different processor types. Multi-core processors several CPUs (referred “cores”) integrated onto single integrated-circuit chip. Figure 1.17 illustrates organization anIntel Core i7 processor, microprocessor chip four CPU cores, eachwith L1 L2 caches sharing higher levels cache well theinterface main memory. Industry experts predict able havedozens, ultimately hundreds, cores single chip. Hyperthreading, sometimes called simultaneous multi-threading , tech- nique allows single CPU execute multiple ﬂows control. involveshaving multiple copies CPU hardware, program countersand register ﬁles, single copies parts hardware,such units perform ﬂoating-point arithmetic. Whereas conventional Figure 1.16 Categorizing differentprocessor conﬁgurations. Multiprocessors becoming prevalent withthe advent multi-core processors hyperthreading.All processors UniprocessorsMultiprocessors Multi- coreHyper- threadedSection 1.9 Important Themes 23 Figure 1.17 Intel Core i7 organization.Four processor cores areintegrated onto singlechip.Processor package Core 0 Core 3 . . .Regs L1 d-cache L2 unified cache L3 unified cache (shared cores) Main memoryL1 i-cacheRegs L1 d-cache L2 unified cacheL1 i-cache processor requires around 20,000 clock cycles shift different threads, hyperthreaded processor decides threads execute cycle-by-cycle basis. enables CPU make better advantage processingresources. example, one thread must wait data loaded intoa cache, CPU proceed execution different thread. ex-ample, Intel Core i7 processor core executing two threads, andso four-core system actually execute eight threads parallel. use multiprocessing improve system performance two ways. First, reduces need simulate concurrency performing multiple tasks.As mentioned, even personal computer used single person expectedto perform many activities concurrently. Second, run single applicationprogram faster, program expressed terms multiple threadsthat effectively execute parallel. Thus, although principles concur-rency formulated studied 50 years, advent multi-coreand hyperthreaded systems greatly increased desire ﬁnd ways writeapplication programs exploit thread-level parallelism available withthe hardware. Chapter 12 look much deeply concurrency itsuse provide sharing processing resources enable parallelismin program execution. Instruction-Level Parallelism much lower level abstraction, modern processors execute multipleinstructions one time, property known instruction-level parallelism .F r24 Chapter 1 Tour Computer Systems example, early microprocessors, 1978-vintage Intel 8086 required multiple (typically, 3–10) clock cycles execute single instruction. recentprocessors sustain execution rates 2–4 instructions per clock cycle. Anygiven instruction requires much longer start ﬁnish, perhaps 20 cycles ormore, processor uses number clever tricks process many 100instructions time. Chapter 4, explore use pipelining , actions required execute instruction partitioned different steps andthe processor hardware organized series stages, performing one steps. stages operate parallel, working different parts ofdifferent instructions. see fairly simple hardware design sustainan execution rate close one instruction per clock cycle. Processors sustain execution rates faster one instruction per cycle known superscalar processors. modern processors support super- scalar operation. Chapter 5, describe high-level model proces-sors. see application programmers use model understandthe performance programs. write programs thegenerated code achieves higher degrees instruction-level parallelism there-fore runs faster. Single-Instruction, Multiple-Data (SIMD) Parallelism lowest level, many modern processors special hardware allowsa single instruction cause multiple operations performed parallel,a mode known single-instruction, multiple-data , “SIMD” parallelism. example, recent generations Intel AMD processors instructions thatcan add four pairs single-precision ﬂoating-point numbers (C data type float ) parallel. SIMD instructions provided mostly speed applications process image, sound, video data. Although compilers attempt auto-matically extract SIMD parallelism C programs, reliable method towrite programs using special vector data types supported compilers gcc. describe style programming Web Aside opt:simd , supplement general presentation program optimization found Chapter 5. 1.9.2 Importance Abstractions Computer Systems use abstractions one important concepts computer science. example, one aspect good programming practice formulate simpleapplication-program interface (API) set functions allow programmersto use code without delve inner workings. Different program-ming languages provide different forms levels support abstraction, suchas Java class declarations C function prototypes. already introduced several abstractions seen com- puter systems, indicated Figure 1.18. processor side, instruction set architecture provides abstraction actual processor hardware. abstraction, machine-code program behaves executed proces-Section 1.10 Summary 25 Figure 1.18 abstractions pro-vided computersystem. major theme computer systems provide abstract represen- tations different levels tohide complexity theactual implementations. Main memory I/O devices Processor Operating systemProcesses Virtual memory FilesVirtual machine Instruction set architecture sor performs one instruction time. underlying hardware far elaborate, executing multiple instructions parallel, always waythat consistent simple, sequential model. keeping execu-tion model, different processor implementations execute machinecode, offering range cost performance. operating system side, introduced three abstractions: ﬁles abstraction I/O, virtual memory abstraction program memory, processes abstraction running program. abstractions add new one: virtual machine , providing abstraction entire computer, including operating system, processor, programs. idea avirtual machine introduced IBM 1960s, become moreprominent recently way manage computers must able runprograms designed multiple operating systems (such Microsoft Windows,MacOS, Linux) different versions operating system. return abstractions subsequent sections book. 1.10 Summary computer system consists hardware systems software cooperateto run application programs. Information inside computer represented asgroups bits interpreted different ways, depending context.Programs translated programs different forms, beginning asASCII text translated compilers linkers binary executableﬁles. Processors read interpret binary instructions stored main memory. Since computers spend time copying data memory,I/O devices, CPU registers, storage devices system arrangedin hierarchy, CPU registers top, followed multiple levelsof hardware cache memories, DRAM main memory, disk storage. Storagedevices higher hierarchy faster costly per bit thanthose lower hierarchy. Storage devices higher hierarchy serveas caches devices lower hierarchy. Programmers optimizethe performance C programs understanding exploiting memoryhierarchy.26 Chapter 1 Tour Computer Systems operating system kernel serves intermediary applica- tion hardware. provides three fundamental abstractions: (1) Files areabstractions I/O devices. (2) Virtual memory abstraction mainmemory disks. (3) Processes abstractions processor, main memory,and I/O devices. Finally, networks provide ways computer systems communicate one another. viewpoint particular system, network anotherI/O device. Bibliographic Notes Ritchie written interesting ﬁrst hand accounts early days C andUnix [87, 88]. Ritchie Thompson presented ﬁrst published accountof Unix [89]. Silberschatz, Gavin, Gagne [98] provide comprehensivehistory different ﬂavors Unix. GNU ( www.gnu.org ) Linux (www.linux.org ) Web pages loads current historical information. Posix standards available online ( www.unix.org ).Part Program Structure Execution exploration computer systems starts studying com- puter itself, comprising processor memory subsystem. Atthe core, require ways represent basic data types, approximations integer real arithmetic. con-sider machine-level instructions manipulate data com-piler translates C programs instructions. Next, study severalmethods implementing processor gain better understanding hardware resources used execute instructions. under- stand compilers machine-level code, examine maxi-mize program performance writing C programs that, compiled,achieve maximum possible performance. conclude de-sign memory subsystem, one complex components ofa modern computer system. part book give deep understanding application programs represented executed. gain skillsthat help write programs secure, reliable, make bestuse computing resources. 27This page intentionally left blank CHAPTER2 Representing Manipulating Information 2.1 Information Storage 33 2.2 Integer Representations 56 2.3 Integer Arithmetic 79 2.4 Floating Point 99 2.5 Summary 118 Bibliographic Notes 119 Homework Problems 119Solutions Practice Problems 134 2930 Chapter 2 Representing Manipulating Information Modern computers store process information represented 2-valued signals. lowly binary digits, bits, form basis digital revolution. familiar decimal, base-10, representation use 1000 years,having developed India, improved Arab mathematicians 12thcentury, brought West 13th century Italian mathematicianLeonardo Pisano (c. 1170 – c. 1250), better known Fibonacci. Using decimalnotation natural ten-ﬁngered humans, binary values work better whenbuilding machines store process information. Two-valued signals canreadily represented, stored, transmitted, example, presence orabsence hole punched card, high low voltage wire, amagnetic domain oriented clockwise counterclockwise. electronic circuitryfor storing performing computations 2-valued signals simple andreliable, enabling manufacturers integrate millions, even billions, suchcircuits single silicon chip. isolation, single bit useful. group bits together apply interpretation gives meaning different possible bit patterns, however, represent elements ﬁnite set. example, using abinary number system, use groups bits encode nonnegative numbers.By using standard character code, encode letters symbols adocument. cover encodings chapter, well encodingsto represent negative numbers approximate real numbers. consider three important representations numbers. Unsigned encodings based traditional binary notation, representing numbers greaterthan equal 0. Two’s-complement encodings common way represent signed integers, is, numbers may either positive neg- ative. Floating-point encodings base-two version scientiﬁc notation representing real numbers. Computers implement arithmetic operations, asaddition multiplication, different representations, similar thecorresponding operations integers real numbers. Computer representations use limited number bits encode number, hence operations overﬂow results large rep- resented. lead surprising results. example, today’scomputers (those using 32-bit representation data type int), computing expression 200 * 300 * 400 * 500 yields −884,901,888. runs counter properties integer arithmetic— computing product set positive numbers yielded negative result. hand, integer computer arithmetic satisﬁes many familiar properties true integer arithmetic. example, multiplication associative commutative, computing following C expressions yields−884,901,888: (500 * 400) * (300 * 200) ((500 * 400) * 300) * 200 ((200 * 500) * 300) * 400 400 * (200 * (300 * 500))Chapter 2 Representing Manipulating Information 31 computer might generate expected result, least consistent! Floating-point arithmetic altogether different mathematical properties. product set positive numbers always positive, although over-ﬂow yield special value +∞. Floating-point arithmetic associative, due ﬁnite precision representation. example, C expression(3.14+1e20)-1e20 evaluate 0 .0 machines, 3.14+(1e20- 1e20) evaluate 3 .14. different mathematical properties integer vs. ﬂoating-point arithmetic stem difference handle ﬁnite-ness representations—integer representations encode comparativelysmall range values, precisely, ﬂoating-point representations canencode wide range values, approximately. studying actual number representations, understand ranges values represented properties different arithmeticoperations. understanding critical writing programs work correctly full range numeric values portable across different combi-nations machine, operating system, compiler. describe, number computer security vulnerabilities arisen due subtleties ofcomputer arithmetic. Whereas earlier era program bugs would incon-venience people happened triggered, legions ofhackers try exploit bug ﬁnd obtain unauthorized accessto people’s systems. puts higher level obligation programmersto understand programs work made behave inundesirable ways. Computers use several different binary representations encode numeric values. need familiar representations progressinto machine-level programming Chapter 3. describe encodings inthis chapter show reason number representations. derive several ways perform arithmetic operations directly manip- ulating bit-level representations numbers. Understanding techniqueswill important understanding machine-level code generated compil-ers attempt optimize performance arithmetic expression eval-uation. treatment material based core set mathematical prin- ciples. start basic deﬁnitions encodings derive suchproperties range representable numbers, bit-level representations,and properties arithmetic operations. believe important youto examine material abstract viewpoint, programmers needto clear understanding computer arithmetic relates morefamiliar integer real arithmetic. Aside read chapter ﬁnd equations formulas daunting, let stop getting chapter! provide full derivations mathematical ideas completeness, best way read material often skip derivation initial reading. Instead, study examples32 Chapter 2 Representing Manipulating Information provided, sure work allof practice problems. examples give intuition behind ideas, practice problems engage active learning , helping put thoughts action. background, ﬁnd much easier go back follow derivations. assured, well, mathematical skills required understand material within reach someone good grasp high school algebra. C++ programming language built upon C, using exact numeric representations operations. Everything said chapter C also holdsfor C++. Java language deﬁnition, hand, created new set ofstandards numeric representations operations. Whereas C standardsare designed allow wide range implementations, Java standard quitespeciﬁc formats encodings data. highlight representationsand operations supported Java several places chapter. Aside evolution C programming language described aside Section 1.2, C programming language ﬁrst developed Dennis Ritchie Bell Laboratories use Unix operating system (also developed Bell Labs). time, system programs, operating systems, written largely assembly code, order access low-level representations different data types. example, feasible write memory allocator, provided malloc library function, high-level languages era. original Bell Labs version C documented ﬁrst edition book Brian Kernighan Dennis Ritchie [57]. time, C evolved efforts several standard- ization groups. ﬁrst major revision original Bell Labs C led ANSI C standard 1989, group working auspices American National Standards Institute. ANSI C major departure Bell Labs C, especially way functions declared. ANSI C described second edition Kernighan Ritchie’s book [58], still considered one bestreferences C. International Standards Organization took responsibility standardizing C lan- guage, adopting version substantially ANSI C 1990 hence referred “ISO C90.” organization sponsored updating language 1999, yielding “ISO C99.” Among things, version introduced new data types provided support text strings requiring characters found English language. GNU Compiler Collection ( gcc) compile programs according conventions several different versions C language, based different command line options, shown Figure 2.1. example, compile program prog.c according ISO C99, could give command line unix> gcc -std=c99 prog.c options -ansi and-std=c89 effect—the code compiled according ANSI ISO C90 standard. (C90 sometimes referred “C89,” since standardization effort began 1989.) option -std=c99 causes compiler follow ISO C99 convention.Section 2.1 Information Storage 33 C version gcccommand line option GNU 89 none ,-std=gnu89 ANSI, ISO C90 -ansi ,-std=c89 ISO C99 -std=c99 GNU 99 -std=gnu99 Figure 2.1 Specifying different versions C gcc. writing book, option speciﬁed, program compiled according version C based ISO C90, including features C99, C++, others speciﬁc gcc. version speciﬁed explicitly using option -std=gnu89 . GNU project developing version combines ISO C99, plus features, speciﬁed command line option -std=gnu99 . (Currently, implementation incomplete.) become default version. 2.1 Information Storage Rather accessing individual bits memory, computers use blocks eight bits, bytes , smallest addressable unit memory. machine- level program views memory large array bytes, referred virtual memory . Every byte memory identiﬁed unique number, known address , set possible addresses known virtual address space . indicated name, virtual address space conceptual imagepresented machine-level program. actual implementation (presentedin Chapter 9) uses combination random-access memory (RAM), disk storage,special hardware, operating system software provide program whatappears monolithic byte array. subsequent chapters, cover compiler run-time system partitions memory space manageable units store different program objects , is, program data, instructions, control information. Various mechanisms used allocate manage storage differentparts program. management performed within virtual addressspace. example, value pointer C—whether points integer,a structure, program object—is virtual address ﬁrst byteof block storage. C compiler also associates type information pointer, generate different machine-level code access value stored location designated pointer depending type value. Although C compiler maintains type information, actualmachine-level program generates information data types. simplytreats program object block bytes, program sequenceof bytes.34 Chapter 2 Representing Manipulating Information New C? role pointers C Pointers central feature C. provide mechanism referencing elements data structures, including arrays. like variable, pointer two aspects: value type.T h e value indicates location object, type indicates kind object (e.g., integer ﬂoating-point number) stored location. 2.1.1 Hexadecimal Notation single byte consists 8 bits. binary notation, value ranges 000000002 111111112. viewed decimal integer, value ranges 010to 25510. Neither notation convenient describing bit patterns. Binary notation verbose, decimal notation, tedious convert frombit patterns. Instead, write bit patterns base-16, hexadecimal numbers. Hexadecimal (or simply “hex”) uses digits ‘0’ ‘9’ along characters‘A’ ‘F’ represent 16 possible values. Figure 2.2 shows decimal andbinary values associated 16 hexadecimal digits. Written hexadecimal,the value single byte range 00 16to FF 16. C, numeric constants starting 0xor0Xare interpreted hexadecimal. characters ‘A’ ‘F’ may written either upper orlower case. example, could write number FA1D37B 16as0xFA1D37B , as0xfa1d37b , even mixing upper lower case, e.g., 0xFa1D37b . use C notation representing hexadecimal values book. common task working machine-level programs manually con- vert decimal, binary, hexadecimal representations bit patterns.Converting binary hexadecimal straightforward, since beperformed one hexadecimal digit time. Digits converted referringto chart shown Figure 2.2. One simple trick conver-sion head memorize decimal equivalents hex digits A,C, F. hex values B,D, Ecan translated decimal computing values relative ﬁrst three. example, suppose given number 0x173A4C . convert binary format expanding hexadecimal digit, follows: Hex digit 01234567 Decimal value 01234567 Binary value 0000 0001 0010 0011 0100 0101 0110 0111 Hex digit 8 9 B C E F Decimal value 8 9 10 11 12 13 14 15 Binary value 1000 1001 1010 1011 1100 1101 1110 1111 Figure 2.2 Hexadecimal notation. Hex digit encodes one 16 values.Section 2.1 Information Storage 35 Hexadecimal 173A4C Binary 0001 0111 0011 1010 0100 1100 gives binary representation 000101110011101001001100. Conversely, given binary number 1111001010110110110011, convert hexadecimal ﬁrst splitting groups 4 bits each. Note, however, ifthe total number bits multiple 4, make leftmost group one fewer 4 bits, effectively padding number leadingzeros. translate group 4 bits corresponding hexadecimaldigit: Binary 11 1100 1010 1101 1011 0011 Hexadecimal 3CADB3 Practice Problem 2.1 Perform following number conversions: A.0x39A7F8 binary B. Binary 1100100101111011 hexadecimalC.0xD5E4C binary D. Binary 1001101110011110110101 hexadecimal value xis power two, is, x=2nfor nonnegative integer n, readily write xin hexadecimal form remembering binary representation xis simply 1 followed nzeros. hexadecimal digit 0 represents four binary zeros. So, nwritten form i+4j, 0 ≤i≤3, write xwith leading hex digit 1(i=0),2(i=1),4(i=2), 8 (i=3), followed jhexadecimal 0s. example, x=2048=211, n=11=3+4.2, giving hexadecimal representation 0x800 . Practice Problem 2.2 Fill blank entries following table, giving decimal hexadecimal representations different powers 2: n 2n(Decimal) 2n(Hexadecimal) 9 512 0x200 19 16,384 0x10000 17 32 0x8036 Chapter 2 Representing Manipulating Information Converting decimal hexadecimal representations requires using multiplication division handle general case. convert decimal num-berxto hexadecimal, repeatedly divide xby 16, giving quotient qand remainder r, x=q.16+r. use hexadecimal digit represent- ingras least signiﬁcant digit generate remaining digits repeating process q. example, consider conversion decimal 314156: 314156 =19634 .16+12(C) 19634 =1227.16+2 (2) 1227=76.16+11 (B) 76=4.16+12 (C) 4=0.16+4 (4) read hexadecimal representation 0x4CB2C . Conversely, convert hexadecimal number decimal, multiply hexadecimal digits appropriate power 16. example, given number 0x7AF , compute decimal equivalent 7 .16 2+10.16+15= 7.256+10.16+15=1792+160+15=1967. Practice Problem 2.3 single byte represented two hexadecimal digits. Fill missing entries following table, giving decimal, binary, hexadecimal valuesof different byte patterns: Decimal Binary Hexadecimal 0 0000 0000 0x00 167 62 188 0011 0111 1000 1000 1111 0011 0x52 0xAC 0xE7 Aside Converting decimal hexadecimal converting larger values decimal hexadecimal, best let computer calculator work. example, following script Perl language converts list numbers (given command line) decimal hexadecimal:Section 2.1 Information Storage 37 bin/d2h 1#!/usr/local/bin/perl 2# Convert list decimal numbers hex 3 4for ($i = 0; $i < @ARGV; $i++) { 5 printf("%d\t= 0x%x\n", $ARGV[$i], $ARGV[$i]); 6} bin/d2h ﬁle set executable, command unix> ./d2h 100 500 751 yields output100 = 0x64 500 = 0x1f4 751 = 0x2ef Similarly, following script converts hexadecimal decimal: bin/h2d 1#!/usr/local/bin/perl 2# Convert list hex numbers decimal 3 4for ($i = 0; $i < @ARGV; $i++) { 5 $val = hex($ARGV[$i]); 6 printf("0x%x = %d\n", $val, $val); 7} bin/h2d Practice Problem 2.4 Without converting numbers decimal binary, try solve follow- ing arithmetic problems, giving answers hexadecimal. Hint: modify methods use performing decimal addition subtraction usebase 16. A.0x503c +0x8= B.0x503c −0x40= C.0x503c +64= D.0x50ea −0x503c =38 Chapter 2 Representing Manipulating Information 2.1.2 Words Every computer word size , indicating nominal size integer pointer data. Since virtual address encoded word, important systemparameter determined word size maximum size virtual addressspace. is, machine w-bit word size, virtual addresses range 0 2 w−1, giving program access 2wbytes. personal computers today 32-bit word size. limits virtual address space 4 gigabytes (written 4 GB), is, 4 ×109bytes. Al- though ample space applications, reached point wheremany large-scale scientiﬁc database applications require larger amounts ofstorage. Consequently, high-end machines 64-bit word sizes becoming in-creasingly common storage costs decrease. hardware costs drop time,even desktop laptop machines switch 64-bit word sizes, consider general case w-bit word size, well special cases w=32 andw=64. 2.1.3 Data Sizes Computers compilers support multiple data formats using different ways encode data, integers ﬂoating point, well different lengths. Forexample, many machines instructions manipulating single bytes, wellas integers represented 2-, 4-, 8-byte quantities. also support ﬂoating-point numbers represented 4- 8-byte quantities. C language supports multiple data formats integer ﬂoating- point data. C data type char represents single byte. Although name “char ” derives fact used store single character text string, also used store integer values. C data type intcan also preﬁxed qualiﬁers short ,long , recently long long , providing integer representations various sizes. Figure 2.3 shows number bytes allocated C declaration 32-bit 64-bit char 11 short int 22 int 44 long int 48 long long int 88 char * 48 float 44 double 88 Figure 2.3 Sizes (in bytes) C numeric data types. number bytes allocated varies machine compiler. chart shows values typical 32-bit 64-bit machines.Section 2.1 Information Storage 39 different C data types. exact number depends machine compiler. show typical sizes 32-bit 64-bit machines. Observe that“short” integers 2-byte allocations, unqualiﬁed int 4 bytes. “long” integer uses full word size machine. “long long” integerdata type, introduced ISO C99, allows full range 64-bit integers. 32-bitmachines, compiler must compile operations data type generating code performs sequences 32-bit operations. Figure 2.3 also shows pointer (e.g., variable declared type “char * ”) uses full word size machine. machines also support two different ﬂoating-point formats: single precision, declared C float , double precision, declared C double . formats use 4 8 bytes, respectively. New C? Declaring pointers data type T, declaration T*p; indicates pis pointer variable, pointing object type T. example, char *p;is declaration pointer object type char . Programmers strive make programs portable across different machines compilers. One aspect portability make program insensi-tive exact sizes different data types. C standards set lower boundson numeric ranges different data types, covered later, upper bounds. Since 32-bit machines standard since around 1980, many programs written assuming allocations listed thisword size Figure 2.3. Given increasing availability 64-bit machines, manyhidden word size dependencies show bugs migrating programsto new machines. example, many programmers assume program objectdeclared type intcan used store pointer. works ﬁne 32-bit machines leads problems 64-bit machine. 2.1.4 Addressing Byte Ordering program objects span multiple bytes, must establish two conventions: address object be, order bytes memory.In virtually machines, multi-byte object stored contiguous sequenceof bytes, address object given smallest address bytesused. example, suppose variable xof type inthas address 0x100 , is, value address expression &xis0x100 . 4 bytes xwould stored memory locations 0x100 ,0x101 ,0x102 , 0x103 .40 Chapter 2 Representing Manipulating Information ordering bytes representing object, two common conven- tions. Consider w-bit integer bit representation [ xw−1,xw−2,...,x 1,x0], xw−1is signiﬁcant bit x0is least. Assuming wis multiple 8, bits grouped bytes, signiﬁcant byte bits[x w−1,xw−2,...,xw−8], least signiﬁcant byte bits [ x7,x6,...,x0], bytes bits middle. machines choose store ob-ject memory ordered least signiﬁcant byte most, machines store least. former convention—where least signiﬁ- cant byte comes ﬁrst—is referred little endian . convention followed Intel-compatible machines. latter convention—where sig-niﬁcant byte comes ﬁrst—is referred big endian . convention followed machines IBM Sun Microsystems. Note said “most.”The conventions split precisely along corporate boundaries. example,both IBM Sun manufacture machines use Intel-compatible processorsand hence little endian. Many recent microprocessors bi-endian , meaning conﬁgured operate either little- big-endian machines. Continuing earlier example, suppose variable xof type int address 0x100 hexadecimal value 0x01234567 . ordering bytes within address range 0x100 0x103 depends type machine: 010x100 230x101 450x102 67 . . . . . .0x103Big endian 670x100 450x101 230x102 01 . . . . . .0x103Little endian Note word 0x01234567 high-order byte hexadecimal value 0x01 , low-order byte value 0x67 . People get surprisingly emotional byte ordering proper one. fact, terms “little endian” “big endian” come book Gulliver’s Travels Jonathan Swift, two warring factions could agree soft-boiled egg opened—by little end big. like eggissue, technological reason choose one byte ordering convention other, hence arguments degenerate bickering socio-political issues. long one conventions selected adhered consistently,the choice arbitrary. Aside Origin “endian” Jonathan Swift, writing 1726, described history controversy big little endians:Section 2.1 Information Storage 41 . . . Lilliput Blefusc u... have, going tell you, engaged obstinate war six-and-thirty moons past. began upon following occasion. allowed hands, primitive way breaking eggs, eat them, upon larger end; present majesty’s grandfather, boy, going eat egg, breaking according ancient practice, happened cut one ﬁngers. Whereupon emperor father published edict, commanding subjects, upon great penalties, break smaller end eggs.The people highly resented law, histories tell us, six rebellions raisedon account; wherein one emperor lost life, another crown. civil commotionswere constantly fomented monarchs Blefuscu; quelled, exiles always ﬂed refuge empire. computed eleven thousand persons several times suffered death, rather submit break eggs smaller end. Many hundred large volumes published upon controversy: books Big-endians long forbidden, whole party rendered incapable law holding employments. day, Swift satirizing continued conﬂicts England (Lilliput) France (Blefuscu). Danny Cohen, early pioneer networking protocols, ﬁrst applied terms refer byte ordering [25], terminology widely adopted. application programmers, byte orderings used machines totally invisible; programs compiled either class machine give identicalresults. times, however, byte ordering becomes issue. ﬁrst whenbinary data communicated network different machines. Acommon problem data produced little-endian machine sent big-endian machine, vice versa, leading bytes within words reverse order receiving program. avoid problems, code written fornetworking applications must follow established conventions byte ordering tomake sure sending machine converts internal representation networkstandard, receiving machine converts network standard internalrepresentation. see examples conversions Chapter 11. second case byte ordering becomes important looking byte sequences representing integer data. occurs often inspectingmachine-level programs. example, following line occurs ﬁle thatgives text representation machine-level code Intel IA32 processor: 80483bd: 01 05 64 94 04 08 add %eax,0x8049464 line generated disassembler , tool determines instruction sequence represented executable program ﬁle. learn disassemblers interpret lines Chapter 3. now, wesimply note line states hexadecimal byte sequence 01 05 64 94 04 08 byte-level representation instruction adds word data value stored address 0x8049464 . take ﬁnal 4 bytes sequence, 64 94 04 08 , write reverse order, 08 04 94 64. Dropping leading 0, value 0x8049464 , numeric value written right. bytes appear reverse order common occurrence reading machine-level program representations generated little-endian42 Chapter 2 Representing Manipulating Information 1#include <stdio.h> 2 3typedef unsigned char *byte_pointer; 4 5void show_bytes(byte_pointer start, int len) { 6 int i; 7 (i = 0; < len; i++) 8 printf(" %.2x", start[i]); 9 printf("\n"); 10 } 11 12 void show_int(int x) { 13 show_bytes((byte_pointer) &x, sizeof(int)); 14 } 1516 void show_float(float x) { 17 show_bytes((byte_pointer) &x, sizeof(float)); 18 } 1920 void show_pointer(void *x) { 21 show_bytes((byte_pointer) &x, sizeof(void *)); 22 } Figure 2.4 Code print byte representation program objects. code uses casting circumvent type system. Similar functions easily deﬁned datatypes. machines one. natural way write byte sequence lowest-numbered byte left highest right, contraryto normal way writing numbers signiﬁcant digit leftand least right. third case byte ordering becomes visible programs written circumvent normal type system. C language, bedone using cast allow object referenced according different data type created. coding tricks strongly discouraged formost application programming, quite useful even necessaryfor system-level programming. Figure 2.4 shows C code uses casting access print byte rep- resentations different program objects. use typedef deﬁne data type byte_pointer pointer object type “ unsigned char .” byte pointer references sequence bytes byte considered non-negative integer. ﬁrst routine show_bytes given address sequence bytes, indicated byte pointer, byte count. prints individualbytes hexadecimal. C formatting directive “ %.2x ” indicates integer printed hexadecimal least two digits.Section 2.1 Information Storage 43 New C? Naming data types typedef Thetypedef declaration C provides way giving name data type. great help improving code readability, since deeply nested type declarations difﬁcult decipher. syntax typedef exactly like declaring variable, except uses type name rather variable name. Thus, declaration byte_pointer Figure 2.4 form declaration variable type “ unsigned char * .” example, declaration typedef int *int_pointer; int_pointer ip; deﬁnes type “ int_pointer ” pointer int, declares variable ipof type. Alterna- tively, could declare variable directly int *ip; New C? Formatted printing printf Theprintf function (along cousins fprintf andsprintf ) provides way print information considerable control formatting details. ﬁrst argument format string , remaining arguments values printed. Within format string, character sequence starting ‘ %’ indicates format next argument. Typical examples include ‘ %d’ print decimal integer, ‘ %f’ print ﬂoating-point number, ‘ %c’ print character character code given argument. New C? Pointers arrays function show_bytes (Figure 2.4), see close connection pointers arrays, discussed detail Section 3.8. see function argument start type byte_ pointer (which deﬁned pointer unsigned char ), see array reference start[i] line 8. C, dereference pointer array notation, reference array elements pointer notation. example, reference start[i] indicates want read byte ipositions beyond location pointed start . Procedures show_int ,show_float , show_pointer demonstrate use procedure show_bytes print byte representations C program objects type int,float , void * , respectively. Observe simply pass show_ bytes pointer &xto argument x, casting pointer type “ unsigned char * .” cast indicates compiler program consider pointer sequence bytes rather object original data type. pointer lowest byte address occupied object.44 Chapter 2 Representing Manipulating Information New C? Pointer creation dereferencing lines 13, 17, 21 Figure 2.4, see uses two operations give C (and therefore C++) distinctive character. C “address of” operator &creates pointer. three lines, expression &xcreates pointer location holding object indicated variable x. type pointer depends type x, hence three pointers type int * ,float * , void ** , respectively. (Data type void * special kind pointer associated type information.) cast operator converts one data type another. Thus, cast (byte_pointer) &x indicates whatever type pointer &xhad before, program reference pointer data type unsigned char . casts shown change actual pointer; simply direct compiler refer data pointed according new data type. procedures use C sizeof operator determine number bytes used object. general, expression sizeof( T)returns number bytes required store object type T. Using sizeof rather ﬁxed value one step toward writing code portable across different machine types. ran code shown Figure 2.5 several different machines, giving results shown Figure 2.6. following machines used: Linux 32: Intel IA32 processor running Linux Windows: Intel IA32 processor running Windows Sun: Sun Microsystems SPARC processor running Solaris Linux 64: Intel x86-64 processor running Linux argument 12,345 hexadecimal representation 0x00003039 . int data, get identical results machines, except byte ordering. Inparticular, see least signiﬁcant byte value 0x39 printed ﬁrst Linux 32, Windows, Linux 64, indicating little-endian machines, lastfor Sun, indicating big-endian machine. Similarly, bytes float data identical, except byte ordering. hand, pointer valuesare completely different. different machine/operating system conﬁgurations code/data/show-bytes.c 1void test_show_bytes(int val) { 2 int ival = val; 3 float fval = (float) ival; 4 int *pval = &ival; 5 show_int(ival); 6 show_float(fval); 7 show_pointer(pval); 8} code/data/show-bytes.c Figure 2.5 Byte representation examples. code prints byte representations sample data objects.Section 2.1 Information Storage 45 Machine Value Type Bytes (hex) Linux 32 12,345 int 39 30 00 00 Windows 12,345 int 39 30 00 00 Sun 12,345 int 00 00 30 39 Linux 64 12,345 int 39 30 00 00 Linux 32 12,345.0 float 00 e4 40 46 Windows 12,345.0 float 00 e4 40 46 Sun 12,345.0 float 46 40 e4 00 Linux 64 12,345.0 float 00 e4 40 46 Linux 32 &ival int * e4 f9 ff bf Windows &ival int * b4 cc 22 00 Sun &ival int * ef ff fa 0c Linux 64 &ival int * b8 11 e5 ff ff 7f 00 00 Figure 2.6 Byte representations different data values. Results int andfloat identical, except byte ordering. Pointer values machine dependent. use different conventions storage allocation. One feature note Linux 32, Windows, Sun machines use 4-byte addresses, Linux 64machine uses 8-byte addresses. Observe although ﬂoating-point integer data encode numeric value 12,345, different byte patterns: 0x00003039 integer, 0x4640E400 ﬂoating point. general, two formats use different encoding schemes. expand hexadecimal patterns binary form shift appropriately, ﬁnd sequence 13 matching bits,indicated sequence asterisks, follows: 00003039 00000000000000000011000000111001 ************* 4640E400 01000110010000001110010000000000 coincidental. return example study ﬂoating- point formats. Practice Problem 2.5 Consider following three calls show_bytes : int val = 0x87654321; byte_pointer valp = (byte_pointer) &val; show_bytes(valp, 1); /* A. */ show_bytes(valp, 2); /* B. */ show_bytes(valp, 3); /* C. */46 Chapter 2 Representing Manipulating Information Indicate following values printed call little- endian machine big-endian machine: A. Little endian: Big endian: B. Little endian: Big endian: C. Little endian: Big endian: Practice Problem 2.6 Using show_int andshow_float , determine integer 3510593 hexa- decimal representation 0x00359141 , ﬂoating-point number 3510593 .0 hexadecimal representation 0x4A564504 . A. Write binary representations two hexadecimal values. B. Shift two strings relative one another maximize number matching bits. many bits match? C. parts strings match? 2.1.5 Representing Strings string C encoded array characters terminated null (having value 0) character. character represented standard encoding, common ASCII character code. Thus, run routine show_bytes arguments "12345" and6(to include terminating character), get result 31 32 33 34 35 00 . Observe ASCII code decimal digit xhappens 0x3x, terminating byte hex representation 0x00 . result would obtained system using ASCII character code, independent byte ordering word size conventions. Asa consequence, text data platform-independent binary data. Aside Generating ASCII table display table showing ASCII character code executing command man ascii . Practice Problem 2.7 would printed result following call show_bytes ? const char *s = "abcdef"; show_bytes((byte_pointer) s, strlen(s)); Note letters ‘ a’ ‘ z’ ASCII codes 0x61 0x7A .Section 2.1 Information Storage 47 Aside Unicode standard text encoding ASCII character set suitable encoding English-language documents, much way special characters, French ‘¸ c.’ wholly unsuited encoding documents languages Greek, Russian, Chinese. years, variety methods developed encode text different languages. Unicode Consortium devised comprehensive widely accepted standard encoding text. current Unicode standard (version 5.0) repertoire nearly 100,000 characters supporting languages ranging Albanian Xamtanga (a language spoken Xamir people Ethiopia). base encoding, known “Universal Character Set” Unicode, uses 32-bit representa- tion characters. would seem require every string text consist 4 bytes per character.However, alternative codings possible common characters require 1 2 bytes, less common ones require more. particular, UTF-8 representation encodes character asequence bytes, standard ASCII characters use single-byte encodings theyhave ASCII, implying ASCII byte sequences meaning UTF-8 ASCII. Java programming language uses Unicode representations strings. Program libraries also available C support Unicode. 2.1.6 Representing Code Consider following C function: 1int sum(int x, int y) { 2 retur nx+y ; 3} compiled sample machines, generate machine code following byte representations: Linux 32: 55 89 e5 8b 45 0c 03 45 08 c9 c3 Windows: 55 89 e5 8b 45 0c 03 45 08 5d c3 Sun: 81 c3 e0 08 90 02 00 09 Linux 64: 55 48 89 e5 89 7d fc 89 75 f8 03 45 fc c9 c3 ﬁnd instruction codings different. Different machine types use different incompatible instructions encodings. Even identical proces- sors running different operating systems differences coding conven-tions hence binary compatible. Binary code seldom portable acrossdifferent combinations machine operating system. fundamental concept computer systems program, perspective machine, simply sequence bytes. machine noinformation original source program, except perhaps auxiliarytables maintained aid debugging. see clearly study machine-level programming Chapter 3.48 Chapter 2 Representing Manipulating Information ~& 01 | 01 ^ 01 01 00 0 00 1 00 1 10 10 1 11 1 11 0 Figure 2.7 Operations Boolean algebra. Binary values 1 0 encode logic values True False , operations ~,&,|, ^encode logical operations ,And , Or, Exclusive-Or , respectively. 2.1.7 Introduction Boolean Algebra Since binary values core computers encode, store, manipu- late information, rich body mathematical knowledge evolved around thestudy values 0 1. started work George Boole (1815–1864) around 1850 thus known Boolean algebra . Boole observed encoding logic values True F alse binary values 1 0, could formulate algebra captures basic principles logical reasoning. simplest Boolean algebra deﬁned 2-element set {0,1}. Fig- ure 2.7 deﬁnes several operations algebra. symbols representingthese operations chosen match used C bit-level operations, aswill discussed later. Boolean operation ~corresponds logical op- eration Not, denoted symbol ¬. is, say ¬Pis true P true, vice versa. Correspondingly, ~pequals 1 pequals 0, vice versa. Boolean operation &corresponds logical operation , de- noted symbol ∧. say P∧Qholds Pis true Qis true. Correspondingly, p&qequals 1 p=1 q=1. Boolean opera- tion|corresponds logical operation Or, denoted symbol ∨.W es thatP∨Qholds either Pis true Qis true. Correspondingly, p|qequals 1 either p=1o rq=1. Boolean operation ^corresponds logical op- eration Exclusive-Or , denoted symbol ⊕. say P⊕Qholds either Pis true Qis true, both. Correspondingly, p^qequals 1 either p=1 q=0, orp=0 q=1. Claude Shannon (1916–2001), later founded ﬁeld information theory, ﬁrst made connection Boolean algebra digital logic. Inhis 1937 master’s thesis, showed Boolean algebra could applied thedesign analysis networks electromechanical relays. Although computertechnology advanced considerably since, Boolean algebra still plays centralrole design analysis digital systems. extend four Boolean operations also operate bit vectors , strings zeros ones ﬁxed length w. deﬁne operations bit vectors according applications matching elements arguments.Letaandbdenote bit vectors [ w−1,aw−2,...,a 0] [ bw−1,bw−2,...,b 0], respectively. deﬁne a&bto also bit vector length w, ith element equals ai&bi, 0 ≤i<w . operations |,^, ~are extended bit vectors similar fashion.Section 2.1 Information Storage 49 examples, consider case w=4, arguments a=[0110] andb=[1100]. four operations a&b,a|b,a^b, ~byield 0110 0110 0110 &1100 |1100 ^1100 ~1100 0100 1110 1010 0011 Practice Problem 2.8 Fill following table showing results evaluating Boolean operations bit vectors. Operation Result [01101001] b [01010101] ~a ~b a&b a|b a^b Web Aside DATA:BOOL Boolean algebra Boolean rings Boolean operations |,&, ~operating bit vectors length wform Boolean algebra , integer w> 0. simplest case w=1, two elements, general case 2wbit vectors length w. Boolean algebra many properties arithmetic integers. example, multiplication distributes addition, written a.(b+c)=(a.b)+(a.c), Boolean operation &distributes |, written a&(b|c)=(a&b)| (a&c). addition, however, Boolean operation |distributes &, write a|(b&c)= (a|b)&(a|c), whereas cannot say a+(b.c)=(a+b).(a+c)holds integers. consider operations ^,&, ~operating bit vectors length w, get different mathematical form, known Boolean ring . Boolean rings many properties common integer arithmetic. example, one property integer arithmetic every value xhas additive inverse −x, x+−x=0. similar property holds Boolean rings, ^is “addition” operation, case element additive inverse. is, a^a=0 value a, use 0 represent bit vector zeros. see holds single bits, since 0^0=1^1=0, extends bit vectors well. property holds even rearrange terms combine different order, (a^b)^a=b. property leads interesting results clever tricks, explore Problem 2.10. One useful application bit vectors represent ﬁnite sets. encode subset A⊆{0,1,...,w −1}with bit vector [ aw−1,...,a 1,a0], ai=1if i∈A. example, recalling write aw−1on left a0on the50 Chapter 2 Representing Manipulating Information right, bit vector a.=[01101001]encodes set A={0,3,5,6}, bit vector b.= [01010101]encodes set B={0,2,4,6}. way encoding sets, Boolean operations |and&correspond set union intersection, respectively, ~ corresponds set complement. Continuing earlier example, operationa&byields bit vector [01000001], A∩B={0,6}. see encoding sets bit vectors number practical applications. example, Chapter 8, see number ofdifferent signals interrupt execution program. selectively enable disable different signals specifying bit-vector mask, wher ea1i n bit position iindicates signal iis enabled, 0 indicates disabled. Thus, mask represents set enabled signals. Practice Problem 2.9 Computers generate color pictures video screen liquid crystal displayby mixing three different colors light: red, green, blue. Imagine simplescheme, three different lights, turned off, project-ing onto glass screen: Light sources Glass screen ObserverRed Green Blue create eight different colors based absence (0) presence (1) light sources R,G, andB: RGB Color 0 0 0 Black 0 0 1 Blue 0 1 0 Green 0 1 1 Cyan1 0 0 Red 1 0 1 Magenta 1 1 0 Yellow1 1 1 White colors represented bit vector length 3, apply Boolean operations them.Section 2.1 Information Storage 51 A. complement color formed turning lights turning lights off. would complement ofthe eight colors listed above? B. Describe effect applying Boolean operations following colors: Blue | Green = Yellow & Cyan = Red ^ Magenta = 2.1.8 Bit-Level Operations C One useful feature C supports bit-wise Boolean operations. fact, symbols used Boolean operations exactly used C: | Or,&for ,~for Not, ^for Exclusive-Or . applied “integral” data type, is, one declared type char orint, without qualiﬁers short ,long ,long long ,o runsigned . examples expression evaluation data type char : C expression Binary expression Binary result Hexadecimal result ~0x41 ~ [0100 0001] [1011 1110] 0xBE ~0x00 ~ [0000 0000] [1111 1111] 0xFF 0x69 & 0x55 [0110 1001] &[0101 0101] [0100 0001] 0x41 0x69 | 0x55 [0110 1001] |[0101 0101] [0111 1101] 0x7D examples show, best way determine effect bit-level ex- pression expand hexadecimal arguments binary representations,perform operations binary, convert back hexadecimal. Practice Problem 2.10 application property a^a=0 bit vector a, consider following program: 1void inplace_swap(int *x, int *y) { 2 * y=* x^* ; /* Step 1 */ 3 * x=* x^* ; /* Step 2 */ 4 * y=* x^* ; /* Step 3 */ 5} name implies, claim effect procedure swap values stored locations denoted pointer variables xandy. Note unlike usual technique swapping two values, need thirdlocation temporarily store one value moving other. Thereis performance advantage way swapping; merely intellectual amusement.52 Chapter 2 Representing Manipulating Information Starting values aandbin locations pointed xandy, respectively, ﬁll table follows, giving values stored two locations eachstep procedure. Use properties ^to show desired effect achieved. Recall every element additive inverse (that is, a^a=0). Step *x *y Initially ab Step 1 Step 2 Step 3 Practice Problem 2.11 Armed function inplace_swap Problem 2.10, decide write code reverse elements array swapping elements oppositeends array, working toward middle. arrive following function: 1void reverse_array(int a[], int cnt) { 2 int first, last; 3 (first = 0, last = cnt-1; 4 first <= last; 5 first++,last--) 6 inplace_swap(&a[first], &a[last]); 7} apply function array containing elements 1, 2, 3, 4, youﬁnd array has, expected, elements 4, 3, 2, 1. try onan array elements 1, 2, 3, 4, 5, however, surprised see array elements 5, 4, 0, 2, 1. fact, discover codealways works correctly arrays even length, sets middle element 0 whenever array odd length. A. array odd length cnt=2k+1, values variables first andlast ﬁnal iteration function reverse_array ? B. call function xor_swap set array element 0? C. simple modiﬁcation code reverse_array would eliminate problem? One common use bit-level operations implement masking operations, mask bit pattern indicates selected set bits within word. Asan example, mask 0xFF (having ones least signiﬁcant 8 bits) indicates low-order byte word. bit-level operation x & 0xFF yields value consisting least signiﬁcant byte x, bytes set 0. example, x=0x89ABCDEF , expression would yield 0x000000EF . expression ~0will yield mask ones, regardless word size ofSection 2.1 Information Storage 53 machine. Although mask written 0xFFFFFFFF 32-bit machine, code portable. Practice Problem 2.12 Write C expressions, terms variable x, following values. code work word size w≥8. reference, show result evalu- ating expressions x=0x87654321 , w=32. A. least signiﬁcant byte x, bits set 0. [ 0x00000021 ]. B. least signiﬁcant byte xcomplemented, least signiﬁcant byte left unchanged. [ 0x789ABC21 ]. C. least signiﬁcant byte set 1s, bytes xleft unchanged. [0x876543FF ]. Practice Problem 2.13 Digital Equipment VAX computer popular machine late 1970s late 1980s. Rather instructions Boolean operations Or, instructions bis(bit set) bic(bit clear). instructions take data word xand mask word m. generate result zconsisting bits xmodiﬁed according bits m. bis, modiﬁcation involves setting zto 1 bit position mis 1. bic, modiﬁcation involves setting zto 0 bit position mis 1. see operations relate C bit-level operations, assume functions bisandbicimplementing bit set bit clear operations, want use implement functions computing bit-wise operations|and^, without using C operations. Fill missing code below. Hint: Write C expressions operations bisandbic. /* Declarations functions implementing operations bis bic */ int bis(int x, int m);int bic(int x, int m); /* Compute x|y using calls functions bis bic */ int bool_or(int x, int y) { int result = ; return result; } /* Compute x^y using calls functions bis bic */ int bool_xor(int x, int y) { int result = ; return result; }54 Chapter 2 Representing Manipulating Information 2.1.9 Logical Operations C C also provides set logical operators ||,&&, and!, correspond Or, , operations logic. easily confused bit-level operations, function quite different. logical operations treat anynonzero argument representing True argument 0 representing F alse . return either 1 0, indicating result either True orF alse , respectively. examples expression evaluation: Expression Result !0x41 0x00 !0x00 0x01!!0x41 0x01 0x69 && 0x55 0x01 0x69 || 0x55 0x01 Observe bit-wise operation behavior matching logical counterpart special case arguments restricted 0 1. second important distinction logical operators &&and||ver- sus bit-level counterparts &and|is logical operators evaluate second argument result expression determined evaluat-ing ﬁrst argument. Thus, example, expression a& &5 / never cause division zero, expression p && *p++ never cause dereferencing null pointer. Practice Problem 2.14 Suppose xandyhave byte values 0x66 and0x39 , respectively. Fill following table indicating byte values different C expressions: Expression Value Expression Value x&y x& &y x|y x| |y ~ x|~ !x || !y x&! x& &~ Practice Problem 2.15 Using bit-level logical operations, writ e C expression equivalent tox= =y . words, return 1 xandyare equal, 0 otherwise. 2.1.10 Shift Operations C C also provides set shift operations shifting bit patterns left right. operand xhaving bit representation [ xn−1,xn−2,...,x 0], C expression x< <k yields value bit representation [ xn−k−1,xn−k−2,Section 2.1 Information Storage 55 ...,x 0,0,... 0]. is, xis shifted kbits left, dropping kmost signiﬁcant bits ﬁlling right end kzeros. shift amount value 0 n−1. Shift operations associate left right, x< <j << k equivalent (x << j) << k . corresponding right shift operation x> >k , slightly subtle behavior. Generally, machines support two forms right shift: logical arithmetic . logical right shift ﬁlls left end kzeros, giving result [0,..., 0,xn−1,xn−2,...x k]. arithmetic right shift ﬁlls left end krepe- titions signiﬁcant bit, giving result [ xn−1,...,xn−1,xn−1,xn−2,...x k]. convention might seem peculiar, see useful operatingon signed integer data. examples, following table shows effect applying different shift operations sample 8-bit data: Operation Values Argument x [01100011] [10010101] x< <4 [0011 0000 ] [0101 0000 ] x> >4 (logical) [ 0000 0110] [ 0000 1001] x> >4 (arithmetic) [ 0000 0110] [ 1111 1001] italicized digits indicate values ﬁll right (left shift) left (right shift) ends. Observe one entry involves ﬁlling zeros. exceptionis case shifting [10010101] right arithmetically. Since signiﬁcant bitis 1, used ﬁll value. C standards precisely deﬁne type right shift used. unsigned data (i.e., integral objects declared qualiﬁerunsigned ), right shifts must logical. signed data (the default), either arithmetic logical shifts may used. unfortunately means codeassuming one form potentially encounter portability problems.In practice, however, almost compiler/machine combinations use arithmeticright shifts signed data, many programmers assume case. Java, hand, precise deﬁnition right shifts performed. expression x> >k shifts xarithmetically kpositions, x >>> k shifts logically. Aside Shifting k, large values k data type consisting wbits, effect shifting value k≥w?F r example, effect computing following expressions 32-bit machine: int lval = 0xFEDCBA98 << 32; int aval = 0xFEDCBA98 >> 36; unsigned uval = 0xFEDCBA98u >> 40;56 Chapter 2 Representing Manipulating Information C standards carefully avoid stating done case. many machines, shift instructions consider lower log2wbits shift amount shifting w-bit value, shift amount effectively computed kmodw. example, 32-bit machine following convention, three shifts computed amounts 0, 4, 8, respectively,giving results lval 0xFEDCBA98 aval 0xFFEDCBA9uval 0x00FEDCBA behavior guaranteed C programs, however, shift amounts kept less word size. Java, hand, speciﬁcally requires shift amounts computed modular fashion shown. Aside Operator precedence issues shift operations might tempting write expression 1<<2 + 3<<4 , intending mean (1<<2) + (3<<4) . But, C, former expression equivalent 1 << (2+3) << 4 , since addition (and subtraction) higher precedence shifts. left-to-right associativity rule causes parenthesized as(1 << (2+3)) << 4 , giving value 512, rather intended 52. Getting precedence wrong C expressions common source program errors, often difﬁcult spot inspection. doubt, put parentheses! Practice Problem 2.16 Fill table showing effects different shift operations single- byte quantities. best way think shift operations work binaryrepresentations. Convert initial values binary, perform shifts, convert back hexadecimal. answers 8 binary digits 2hexadecimal digits. (Logical) (Arithmetic) x x << 3 x >> 2 x >> 2 Hex Binary Binary Hex Binary Hex Binary Hex 0xC3 0x75 0x87 0x66 2.2 Integer Representations section, describe two different ways bits used encode integers— one represent nonnegative numbers, one representSection 2.2 Integer Representations 57 C data type Minimum Maximum char −128 127 unsigned char 0 255 short [int] −32,768 32,767 unsigned short [int] 0 65,535 int −2,147,483,648 2,147,483,647 unsigned [int] 0 4,294,967,295 long [int] −2,147,483,648 2,147,483,647 unsigned long [int] 0 4,294,967,295 long long [int] −9,223,372,036,854,775,808 9,223,372,036,854,775,807 unsigned long long [int] 0 18,446,744,073,709,551,615 Figure 2.8 Typical ranges C integral data types 32-bit machine. Text square brackets optional. C data type Minimum Maximum char −128 127 unsigned char 0 255 short [int] −32,768 32,767 unsigned short [int] 0 65,535 int −2,147,483,648 2,147,483,647 unsigned [int] 0 4,294,967,295 long [int] −9,223,372,036,854,775,808 9,223,372,036,854,775,807 unsigned long [int] 0 18,446,744,073,709,551,615 long long [int] −9,223,372,036,854,775,808 9,223,372,036,854,775,807 unsigned long long [int] 0 18,446,744,073,709,551,615 Figure 2.9 Typical ranges C integral data types 64-bit machine. Text square brackets optional. negative, zero, positive numbers. see later strongly related mathematical properties machine-level implemen-tations. also investigate effect expanding shrinking encoded integerto ﬁt representation different length. 2.2.1 Integral Data Types C supports variety integral data types—ones represent ﬁnite ranges integers. shown Figures 2.8 2.9, along ranges values “typical” 32- 64-bit machines. type specify sizewith keyword char ,short ,long ,o rlong long , well indication whether represented numbers nonnegative (declared unsigned ), possibly58 Chapter 2 Representing Manipulating Information C data type Minimum Maximum char −127 127 unsigned char 0 255 short [int] −32,767 32,767 unsigned short [int] 0 65,535 int −32,767 32,767 unsigned [int] 0 65,535 long [int] −2,147,483,647 2,147,483,647 unsigned long [int] 0 4,294,967,295 long long [int] −9,223,372,036,854,775,807 9,223,372,036,854,775,807 unsigned long long [int] 0 18,446,744,073,709,551,615 Figure 2.10 Guaranteed ranges C integral data types. Text square brackets optional. C standards require data types least ranges values. negative (the default). saw Figure 2.3, number bytes allocated different sizes vary according machine’s word size compiler. Basedon byte allocations, different sizes allow different ranges values berepresented. machine-dependent range indicated size designator long . 64-bit machines use 8-byte representation, giving much wider range values 4-byte representation used 32-bit machines. One important feature note Figures 2.8 2.9 ranges symmetric—the range negative numbers extends one range ofpositive numbers. see happens consider negativenumbers represented. C standards deﬁne minimum ranges values data type must able represent. shown Figure 2.10, ranges smallerthan typical implementations shown Figures 2.8 2.9. particular, seethat require symmetric range positive negative numbers. alsosee data type intcould implemented 2-byte numbers, although mostly throwback days 16-bit machines. also see size long could implemented 4-byte numbers, often case. Data type long long introduced ISO C99, requires least 8-byte representation. New C? Signed unsigned numbers C, C++, Java C C++ support signed (the default) unsigned numbers. Java supports signed numbers. 2.2.2 Unsigned Encodings Assume integer data type wbits. write bit vector either /vectorx,t denote entire vector, [ xw−1,xw−2,...,x 0], denote individual bits within vector. Treating /vectorxas number written binary notation, obtain theSection 2.2 Integer Representations 59 Figure 2.11 Unsigned numberexamples w=4. bit iin binary representation value 1, contributes 2 ito value.16151413121110987654321020 = 121 = 222 = 423 = 8 [0001] [0101][1011][1111] unsigned interpretation /vectorx. express interpretation function B2Uw (for “binary unsigned,” length w): B2Uw(/vectorx).=w−1/summationdisplay i=0xi2i(2.1) equation, notation “.=” means left-hand side deﬁned equal right-hand side. function B2Uwmaps strings zeros ones length wto nonnegative integers. examples, Figure 2.11 shows mapping, given B2U , bit vectors integers following cases: B2U4([0001] )=0.23+0.22+0.21+1.20=0+0+0+1= 1 B2U4([0101] )=0.23+1.22+0.21+1.20=0+4+0+1= 5 B2U 4([1011] )=1.23+0.22+1.21+1.20=8+0+2+1=11 B2U 4([1111] )=1.23+1.22+1.21+1.20=8+4+2+1=15 (2.2) ﬁgure, represent bit position iby rightward-pointing blue bar length 2i. numeric value associated bit vector equals combined length bars corresponding bit values 1. Let us consider range values represented using wbits. least value given bit vector [00 ...0] integer value 0, greatest value given bit vector [11 ...1] integer value UMax w.=/summationtextw−1 i=02i= 2w−1. Using 4-bit case example, UMax 4=B2U 4([1111] )= 24−1=15. Thus, function B2U wcan deﬁned mapping B2U w:{0,1}w→ {0,..., 2w−1}. unsigned binary representation important property every number 0 2w−1has unique encoding w-bit value. example, one representation decimal value 11 unsigned, 4-bit number,namely [1011]. property captured mathematical terms stating function B2U wis bijection —it associates unique value bit vector of60 Chapter 2 Representing Manipulating Information length w; conversely, integer 0 2w−1 unique binary representation bit vector length w. 2.2.3 Two’s-Complement Encodings many applications, wish represent negative values well. com- mon computer representation signed numbers known two’s-complement form. deﬁned interpreting signiﬁcant bit word havenegative weight. express interpretation function B2T w(for “binary two’s-complement” length w): B2T w(/vectorx).=−xw−12w−1+w−2/summationdisplay i=0xi2i(2.3) signiﬁcant bit xw−1is also called sign bit . “weight” −2w−1, negation weight unsigned representation. sign bit set to1, represented value negative, set 0 value nonnegative.As examples, Figure 2.12 shows mapping, given B2T , bit vectors integers following cases: B2T 4([0001] )=− 0.23+0.22+0.21+1.20= 0+0+0+1= 1 B2T 4([0101] )=− 0.23+1.22+0.21+1.20= 0+4+0+1= 5 B2T 4([1011] )=− 1.23+0.22+1.21+1.20=− 8+0+2+1=− 5 B2T4([1111] )=− 1.23+1.22+1.21+1.20=− 8+4+2+1=− 1 (2.4) ﬁgure, indicate sign bit negative weight showing leftward-pointing gray bar. numeric value associated bit vector isthen given combination possible leftward-pointing gray bar therightward-pointing blue bars. Figure 2.12 Two’s-complementnumber examples w=4.Bit 3 serves sign bit, so, whenset 1, contributes−2 3=−8to value. weighting shown aleftward-pointing gray bar.876543210 –1–2–3–4–5–6–7–820 = 121 = 222 = 4–23 = –8 [0001] [0101][1011] [1111]Section 2.2 Integer Representations 61 see bit patterns identical Figures 2.11 2.12 (as well Equations 2.2 2.4), values differ signiﬁcant bit 1,since one case weight +8, case weight −8. Let us consider range values represented w-bit two’s- complement number. least representable value given bit vector [10 ...0] (set bit negative weight, clear others), integer value TMin w.=−2w−1. greatest value given bit vector [01 ...1] (clear bit negative weight, set others), integer value TMax w.=/summationtextw−2 i=02i= 2w−1−1. Using 4-bit case example, TMin 4=B2T 4([1000] )= −23=−8, TMax 4=B2T 4([0111] )=22+21+20=4+2+1=7. see B2T wis mapping bit patterns length wto numbers be- tween TMinwand TMaxw, written B2Tw:{0,1}w→{ − 2w−1,..., 2w−1−1}.A saw unsigned representation, every number within representablerange unique encoding w-bit two’s-complement number. mathemat- ical terms, say function B2T wis bijection —it associates unique value bit vector length w; conversely, integer −2w−1and 2w−1−1 unique binary representation bit vector length w. Practice Problem 2.17 Assuming w=4, assign numeric value possible hexadecimal digit, assuming either unsigned two’s-complement interpretation. Fill inthe following table according interpretations writing nonzeropowers two summations shown Equations 2.1 2.3: /vectorx Hexadecimal Binary B2U 4(/vectorx) B2T 4(/vectorx) 0xE [1110] 23+22+21=14 −23+22+21=−2 0x0 0x5 0x8 0xD 0xF Figure 2.13 shows bit patterns numeric values several important numbers different word sizes. ﬁrst three give ranges representableintegers terms values UMax w,TMin w, TMax w. refer three special values often ensuing discussion. drop thesubscript wand refer values UMax ,TMin , TMax whenwcan inferred context central discussion. points worth highlighting numbers. First, observed Figures 2.8 2.9, two’s-complement range asymmetric: |TMin|= |TMax |+1, is, positive counterpart TMin . shall see, leads peculiar properties two’s-complement arithmetic be62 Chapter 2 Representing Manipulating Information Word size w Value 8 16 32 64 UMax w 0xFF 0xFFFF 0xFFFFFFFF 0xFFFFFFFFFFFFFFFF 255 65,535 4,294,967,295 18,446,744,073,709,551,615 TMin w 0x80 0x8000 0x80000000 0x8000000000000000 −128 −32,768 −2,147,483,648 −9,223,372,036,854,775,808 TMax w 0x7F 0x7FFF 0x7FFFFFFF 0x7FFFFFFFFFFFFFFF 127 32,767 2,147,483,647 9,223,372,036,854,775,807 −1 0xFF 0xFFFF 0xFFFFFFFF 0xFFFFFFFFFFFFFFFF 0 0x00 0x0000 0x00000000 0x0000000000000000 Figure 2.13 Important numbers. numeric values hexadecimal representations shown. source subtle program bugs. asymmetry arises, half bit pat- terns (those sign bit set 1) represent negative numbers, half (thosewith sign bit set 0) represent nonnegative numbers. Since 0 nonnegative,this means represent one less positive number negative. Second,the maximum unsigned value twice maximum two’s-complementvalue: UMax =2TMax +1. bit patterns denote negative numbers two’s-complement notation become positive values unsigned representa-tion. Figure 2.13 also shows representations constants −1 0. Note −1 bit representation UMax —a string ones. Numeric value 0 represented string zeros representations. C standards require signed integers represented two’s- complement form, nearly machines so. Programmers con-cerned maximizing portability across possible machines assumeany particular range representable values, beyond ranges indicated Fig-ure 2.10, assume particular representation signed numbers.On hand, many programs written assuming two’s-complementrepresentation signed numbers, “typical” ranges shown Figures 2.8and 2.9, programs portable across broad range machines andcompilers. ﬁle <limits.h> C library deﬁnes set constants delim- iting ranges different integer data types particular machine onwhich compiler running. example, deﬁnes constants INT_MAX ,INT_ MIN, UINT_MAX describing ranges signed unsigned integers. two’s-complement machine data type int haswbits, constants correspond values TMax w,TMin w, UMax w. Aside Exact-size integer types programs, essential data types encoded using representations speciﬁc sizes. example, writing programs enable machine communicate Internet according standard protocol, important data types compatible speciﬁed protocol.Section 2.2 Integer Representations 63 seen C data types, especially long , different ranges different machines, fact C standards specify minimum ranges data type, exact ranges. Although choose data types compatible standard representations machines, guarantee portability. ISO C99 standard introduces another class integer types ﬁle stdint.h . ﬁle deﬁnes set data types declarations form intN_tanduintN_t, specifying N-bit signed unsigned integers, different values N. exact values Nare implementation dependent, compilers allow values 8, 16, 32, 64. Thus, unambiguously declare unsigned,16-bit variable giving type uint16_t , signed variable 32 bits int32_t . Along data types set macros deﬁning minimum maximum values value N. names form INTN_MIN ,INTN_MAX , UINTN_MAX . Java standard quite speciﬁc integer data type ranges repre- sentations. requires two’s-complement representation exact rangesshown 64-bit case (Figure 2.9). Java, single-byte data type calledbyte instead char , long long data type. detailed require- ments intended enable Java programs behave identically regardless ofthe machines running them. Aside Alternative representations signed numbers two standard representations signed numbers: Ones’ Complement: two’s complement, except signiﬁcant bit weight −(2w−1−1)rather −2w−1: B2O w(/vectorx).=−xw−1(2w−1−1)+w−2/summationdisplay i=0xi2i Sign-Magnitude: signiﬁcant bit sign bit determines whether remaining bits given negative positiveweight: B2S w(/vectorx).=(−1)xw−1./parenleftBiggw−2/summationdisplay i=0xi2i/parenrightBigg representations curious property two different encodings number 0. representations, [00 ...0] interpreted +0. value −0 represented sign-magnitude form [10 ...0] ones’-complement [11 ...1]. Although machines based ones’-complement representations built past, almost modern machines use two’scomplement. see sign-magnitude encoding used ﬂoating-point numbers. Note different position apostrophes: Two’s complement versus Ones’ complement. term “two’s complement” arises fact nonnegative xwe compute w-bit representation of−xas 2 w−x(a single two). term “ones’ complement” comes property compute −xin notation [111 ...1]−x(multiple ones).64 Chapter 2 Representing Manipulating Information 12,345 −12,345 53,191 Weight Bit Value Bit Value Bit Value 1 1 1 1 1 1 1 2 0 0 1 2 1 2 4 0 0 1 4 1 4 8 1 8 0 0 0 0 16 1 16 0 0 0 0 32 1 32 0 0 0 0 64 0 0 1 64 1 64 128 0 0 1 128 1 128 256 0 0 1 256 1 256 512 0 0 1 512 1 512 1,024 0 0 1 1,024 1 1,024 2,048 0 0 1 2,048 1 2,048 4,096 1 4,096 0 0 0 0 8,192 1 8,192 0 0 0 0 16,384 0 0 1 16,384 1 16,384 ±32,768 0 0 1 −32,768 1 32,768 Total 12,345 −12,345 53,191 Figure 2.14 Two’s-complement representations 12,345 −12,345, unsigned representation 53,191. Note latter two identical bit representations. example, consider following code: 1 short x = 12345; 2 short mx = -x; 3 4 show_bytes((byte_pointer) &x, sizeof(short)); 5 show_bytes((byte_pointer) &mx, sizeof(short)); run big-endian machine, code prints 30 39 andcf c7 , indi- cating xhas hexadecimal representation 0x3039 , mxhas hexadeci- mal representation 0xCFC7 . Expanding binary, get bit patterns [0011000000111001] xand [1100111111000111] mx. Figure 2.14 shows, Equation 2.3 yields values 12,345 −12,345 two bit patterns. Practice Problem 2.18 Chapter 3, look listings generated disassembler , program converts executable program ﬁle back readable ASCII form. Theseﬁles contain many hexadecimal numbers, typically representing values two’s-complement form. able recognize numbers understand theirSection 2.2 Integer Representations 65 signiﬁcance (for example, whether negative positive) important skill. lines labeled A–J (on right) following listing, convert hexadecimal values (in 32-bit two’s-complement form) shown right theinstruction names ( sub,mov, add) decimal equivalents: 8048337: 81 ec b8 01 00 00 sub $0x1b8,%esp A. 804833d: 8b 55 08 mov 0x8(%ebp),%edx 8048340: 83 c2 14 add $0x14,%edx B. 8048343: 8b 85 58 fe ff ff mov 0xfffffe58(%ebp),%eax C. 8048349: 03 02 add (%edx),%eax 804834b: 89 85 74 fe ff ff mov %eax,0xfffffe74(%ebp) D. 8048351: 8b 55 08 mov 0x8(%ebp),%edx 8048354: 83 c2 44 add $0x44,%edx E. 8048357: 8b 85 c8 fe ff ff mov 0xfffffec8(%ebp),%eax F. 804835d: 89 02 mov %eax,(%edx) 804835f: 8b 45 10 mov 0x10(%ebp),%eax G. 8048362: 03 45 0c add 0xc(%ebp),%eax H. 8048365: 89 85 ec fe ff ff mov %eax,0xfffffeec(%ebp) I. 804836b: 8b 45 08 mov 0x8(%ebp),%eax 804836e: 83 c0 20 add $0x20,%eax J. 8048371: 8b 00 mov (%eax),%eax 2.2.4 Conversions Signed Unsigned C allows casting different numeric data types. example, suppose variable xis declared int anduasunsigned . expression (unsigned) x converts value xto unsigned value, (int) u converts value u signed integer. effect casting signed value unsigned,or vice versa? mathematical perspective, one imagine several differentconventions. Clearly, want preserve value represented inboth forms. hand, converting negative value unsigned might yield zero. Converting unsigned value large represented two’s- complement form might yield TMax . implementations C, however, answer question based bit-level perspective, rather anumeric one. example, consider following code: 1 short int v = -12345; 2 unsigned short uv = (unsigned short) v; 3 printf("v = %d, uv = %u\n", v, uv); run two’s-complement machine, generates following output: v = -12345, uv = 53191 see effect casting keep bit values identicalbut change bits interpreted. saw Figure 2.14 16-bit66 Chapter 2 Representing Manipulating Information two’s-complement representation −12,345 identical 16-bit unsigned representation 53,191. Casting short int tounsigned short changed numeric value, bit representation. Similarly, consider following code: 1 unsigne u = 4294967295u; /* UMax_32 */ 2 int tu = (int) u; 3 printf("u = %u, tu = %d\n", u, tu); run two’s-complement machine, generates following output: u = 4294967295, tu = -1 see Figure 2.13 that, 32-bit word size, bit patterns represent- ing 4,294,967,295 ( UMax32) unsigned form −1 two’s-complement form identical. casting unsigned int toint, underlying bit representa- tion stays same. general rule C implementations handle conversions signed unsigned numbers word size—the numericvalues might change, bit patterns not. Let us capture principlein mathematical form. Since B2U wand B2Tware bijections, well-deﬁned inverses. Deﬁne U2B wto B2U−1 w, T2Bwto B2T−1 w. functions give unsigned two’s-complement bit patterns numericvalue. is, given integer xin range 0 ≤x<2 w, function U2Bw(x) gives unique w-bit unsigned representation x. Similarly, xis range −2w−1≤x<2w−1, function T2Bw(x)gives unique w-bit two’s- complement representation x. Observe values range 0 ≤x<2w−1, functions yield bit representation—the signiﬁcantbit 0, hence matter whether bit positive negativeweight. deﬁne function U2T wasU2Tw(x).=B2Tw(U2B w(x)). function takes number 0 2w−1 yields number −2w−1and 2w−1−1, two numbers identical bit representations, except argument unsigned, result two’s-complement representa- tion. Similarly, xbetween −2w−1and 2w−1−1, function T2U w, deﬁned T2Uw(x).=B2Uw(T2Bw(x)), yields number unsigned repre- sentation two’s-complement representation x. Pursuing earlier examples, see Figure 2.14 T2U16(−12,345) =53,191, U2T 16(53,191)=−12,345. is, 16-bit pattern written hexadecimal 0xCFC7 two’s-complement representation −12,345 unsigned representation 53,191. Similarly, Figure 2.13, see thatT2U 32(−1)=4,294,967,295, U2T 32(4,294,967,295)=−1. is, UMax bit representation unsigned form −1 two’s-complement form. see, then, function U2T describes conversion unsigned number 2-complement counterpart, T2U converts oppositeSection 2.2 Integer Representations 67 direction. describe effect casting data types C implementations. Practice Problem 2.19 Using table ﬁlled solving Problem 2.17, ﬁll following tabledescribing function T2U 4: x T2U 4(x) −8 −3 −2 −1 0 5 get better understanding relation signed number xand unsigned counterpart T2U w(x), use fact identical bit representations derive numerical relationship. Comparing Equations 2.1 and2.3, see bit pattern /vectorx, compute difference B2U w(/vectorx)− B2Tw(/vectorx), weighted sums bits 0 w−2 cancel other, leaving value: B2Uw(/vectorx)−B2Tw(/vectorx)=xw−1(2w−1−− 2w−1)=xw−12w. gives relationship B2Uw(/vectorx)=xw−12w+B2T w(/vectorx).I fw el e /vectorx=T2Bw(x), B2Uw(T2Bw(x))=T2U w(x)=xw−12w+x (2.5) relationship useful proving relationships unsigned two’s- complement arithmetic. two’s-complement representation x, bitxw−1 determines whether xis negative, giving T2U w(x)=/braceleftbiggx+2w,x < 0 x, x ≥0(2.6) examples, Figure 2.15 compares functions B2U B2T assign values bit patterns w=4. two’s-complement case, signiﬁcant bit serves sign bit, diagram gray, leftward-pointing bar.For unsigned case, bit positive weight, show black,rightward-pointing bar. going two’s complement unsigned, signiﬁcant bit changes weight −8t o+8. consequence, values negative two’s-complement representation increase 2 4=16 unsigned representation. Thus, −5 becomes +11, −1 becomes +15. Figure 2.16 illustrates general behavior function T2U . shows, mapping signed number unsigned counterpart, negative numbers con-verted large positive numbers, nonnegative numbers remain unchanged.68 Chapter 2 Representing Manipulating Information 876543211 6 1514131211109 0 –1–2–3–4–5–6–7–820 = 121 = 222 = 4–23 = –8 [1011] [1111]23 = 8 +16 +16 Figure 2.15 Comparing unsigned two’s-complement representations w=4. weight signiﬁcant bit −8for two’s complement, +8for unsigned, yielding net difference 16. Figure 2.16 Conversion two’scomplement unsigned. Function T2U converts negative numbers large positive numbers./H110012w/H110021 0 /H110022w/H1100212w 02w/H110021 Two’s complementUnsigned Practice Problem 2.20 Explain Equation 2.6 applies entries table generated solving Problem 2.19. Going direction, wish derive relationship unsigned number uand signed counterpart U2Tw(u), bit repre- sentations /vectoru=U2Bw(u). B2Tw(U2B w(u))=U2Tw(u)=−uw−12w+u (2.7) unsigned representation u, bituw−1determines whether uis greater equal 2w−1, giving U2Tw(u)=/braceleftbiggu, u < 2w−1 u−2w,u≥2w−1(2.8)Section 2.2 Integer Representations 69 Figure 2.17 Conversion un-signed two’s com-plement. Function U2T converts numbers greater 2 w−1−1to negative values./H110012w/H110021 0 /H110022w/H1100212w 02w/H110021 Two’s complementUnsigned behavior illustrated Figure 2.17. small ( <2w−1) numbers, conver- sion unsigned signed preserves numeric value. Large ( ≥2w−1) numbers converted negative values. summarize, considered effects converting directions be- tween unsigned two’s-complement representations. values xin range 0≤x<2w−1, T2Uw(x)=xand U2Tw(x)=x. is, numbers range identical unsigned two’s-complement representations. val-ues outside range, conversions either add subtract 2 w. exam- ple, T2U w(−1)=−1+2w=UMax w—the negative number closest 0 maps largest unsigned number. extreme, one see T2Uw(TMinw)=− 2w−1+2w=2w−1=TMax w+1—the negative number maps unsigned number outside range positive, two’s-complementnumbers. Using example Figure 2.14, see T2U 16(−12,345)= 65,536+−12,345=53,191. 2.2.5 Signed vs. Unsigned C indicated Figures 2.8 2.9, C supports signed unsigned arithmetic integer data types. Although C standard specify particu-lar representation signed numbers, almost machines use two’s complement. Generally, numbers signed default. example, declaring aconstant 12345 or0x1A2B , value considered signed. Adding charac- ter ‘U’o r‘u’ sufﬁx creates unsigned constant, e.g., 12345U or0x1A2Bu . C allows conversion unsigned signed. rule under- lying bit representation changed. Thus, two’s-complement machine, theeffect apply function U2T wwhen converting unsigned signed, T2U wwhen converting signed unsigned, wis number bits data type. Conversions happen due explicit casting, following code: 1 int tx, ty; 2 unsigned ux, uy; 3 4 tx = (int) ux; 5 uy = (unsigned) ty;70 Chapter 2 Representing Manipulating Information Alternatively, happen implicitly expression one type as- signed variable another, following code: 1 int tx, ty; 2 unsigned ux, uy; 3 4 tx = ux; /* Cast signed */ 5 uy = ty; /* Cast unsigned */ printing numeric values printf , directives %d,%u, %x used print number signed decimal, unsigned decimal, inhexadecimal format, respectively. Note printf make use type information, possible print value type intwith directive %uand value type unsigned directive %d. example, consider following code: 1 int x = -1; 2 unsigne u = 2147483648; /* 2 31st */ 3 4 printf("x = %u = %d\n", x, x); 5 printf("u = %u = %d\n", u, u); run 32-bit machine, prints following: x = 4294967295 = -1 u = 2147483648 = -2147483648 cases, printf prints word ﬁrst represented unsigned number, second represented signed number. see conversion routines action: T2U32(−1)=UMax32=232−1 U2T 32(231)=231−232= −231=TMin32. peculiar behavior arises due C’s handling expressions con- taining combinations signed unsigned quantities. operation isperformed one operand signed unsigned, C implicitly casts signed argument unsigned performs operations assumingthe numbers nonnegative. see, convention makes little dif-ference standard arithmetic operations, leads nonintuitive resultsfor relational operators <and>. Figure 2.18 shows sample rela- tional expressions resulting evaluations, assuming 32-bit machine us-ing two’s-complement representation. Consider comparison - 1<0 U . Since second operand unsigned, ﬁrst one implicitly cast unsigned, hence expression equivalent comparison 4294967295U < 0U (recall T2U w(−1)=UMaxw), course false. cases under- stood similar analyses. Practice Problem 2.21 Assuming expressions evaluated 32-bit machine uses two’s- complement arithmetic, ﬁll following table describing effect casting relational operations, style Figure 2.18:Section 2.2 Integer Representations 71 Expression Type Evaluation -2147483647-1 == 2147483648U -2147483647-1 < 2147483647 -2147483647-1U < 2147483647 -2147483647-1 < -2147483647 -2147483647-1U < -2147483647 Web Aside DATA:TMIN Writing TMin C Figure 2.18 Problem 2.21, carefully wrote value TMin 32as-2147483647-1 .W h simply write either -2147483648 or0x80000000 ? Looking C header ﬁle limits.h ,w e see use similar method write TMin 32and TMax 32: /* Minimum maximum values ‘signed int’ hold. */ #define INT_MAX 2147483647#define INT_MIN (-INT_MAX - 1) Unfortunately, curious interaction asymmetry two’s-complement representation conversion rules C force us write TMin 32in unusual way. Although understanding issue requires us delve one murkier corners C language standards, help us appreciate subtleties integer data types representations. 2.2.6 Expanding Bit Representation Number One common operation convert integers different word sizes retaining numeric value. course, may possible whenthe destination data type small represent desired value. Convertingfrom smaller larger data type, however, always possible. convert Expression Type Evaluation 0= =0 U unsigned 1 - 1<0 signed 1 - 1<0 U unsigned 0* 2147483647 > -2147483647-1 signed 1 2147483647U > -2147483647-1 unsigned 0* 2147483647 > (int) 2147483648U signed 1* - 1>- 2 signed 1 (unsigned) -1 > -2 unsigned 1 Figure 2.18 Effects C promotion rules. Nonintuitive cases marked ‘*’. either operand comparison unsigned, operand implicitly cast tounsigned. See Web Aside data:tmin write TMin 32as-2147483647-1 .72 Chapter 2 Representing Manipulating Information unsigned number larger data type, simply add leading zeros representation; operation known zero extension . converting two’s- complement number larger data type, rule perform sign extension , adding copies signiﬁcant bit representation. Thus, originalvalue bit representation [ x w−1,xw−2,...,x0], expanded representation [xw−1,..., xw−1,xw−1,xw−2,...,x0]. (We show sign bit xw−1in blue highlight role sign extension.) example, consider following code: 1short sx = -12345; /* -12345 */ 2unsigned short usx = sx; /* 53191 */ 3int x = sx; /* -12345 */ 4unsigned ux = usx; /* 53191 */ 5 6printf("sx = %d:\t", sx); 7show_bytes((byte_pointer) &sx, sizeof(short)); 8printf("usx = %u:\t", usx); 9show_bytes((byte_pointer) &usx, sizeof(unsigned short)); 10 printf("x = %d:\t", x); 11 show_bytes((byte_pointer) &x, sizeof(int)); 12 printf("ux = %u:\t", ux); 13 show_bytes((byte_pointer) &ux, sizeof(unsigned)); run 32-bit big-endian machine using two’s-complement representa- tion, code prints output sx = -12345: cf c7 usx = 53191: cf c7 x = -12345: ff ff cf c7 ux = 53191: 00 00 cf c7 see although two’s-complement representation −12,345 unsigned representation 53,191 identical 16-bit word size, dif-fer 32-bit word size. particular, −12,345 hexadecimal representation 0xFFFFCFC7 , 53,191 hexadecimal representation 0x0000CFC7 . for- mer sign extended—16 copies signiﬁcant bit 1, hexa- decimal representation 0xFFFF , added leading bits. latter extended 16 leading zeros, hexadecimal representation 0x0000 . illustration, Figure 2.19 shows result applying expanding word size w=3t ow=4 sign extension. Bit vector [101] represents value −4+1=−3. Applying sign extension gives bit vector [1101] representing value −8+4+1=−3. see that, w=4, combined value two signiﬁcant bits −8+4=−4, matching value sign bit w=3. Similarly, bit vectors [111] [1111] represent value −1. justify sign extension works? want prove B2T w+k([xw−1,..., xw−1/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright ktimes,xw−1,xw−2,...,x 0])=B2T w([xw−1,xw−2,...,x 0])Section 2.2 Integer Representations 73 Figure 2.19 Examples sign exten-sion w=3tow=4. Forw=4, combined weight upper 2 bits is−8+4=−4, matching sign bit forw=3. 876543210 –1–2–3–4–5–6–7–820 = 121 = 222 = 4–23 = –8 [101] [1101] [111] [1111]–22 = –4 where, expression left-hand side, made kadditional copies bit xw−1. proof follows induction k. is, prove sign extending 1 bit preserves numeric value, property hold whensign extending arbitrary number bits. Thus, task reduces provingthat B2T w+1([xw−1,xw−1,xw−2,...,x0])=B2Tw([xw−1,xw−2,...,x0]) Expanding left-hand expression Equation 2.3 gives following: B2Tw+1([xw−1,xw−1,xw−2,...,x 0])=−xw−12w+w−1/summationdisplay i=0xi2i =−xw−12w+xw−12w−1+w−2/summationdisplay i=0xi2i =−xw−1/parenleftBig 2w−2w−1/parenrightBig +w−2/summationdisplay i=0xi2i =−xw−12w−1+w−2/summationdisplay i=0xi2i =B2Tw([xw−1,xw−2,...,x0]) key property exploit 2w−2w−1=2w−1. Thus, combined effect adding bit weight −2wand converting bit weight −2w−1to one weight 2w−1is preserve original numeric value.74 Chapter 2 Representing Manipulating Information Practice Problem 2.22 Show following bit vectors two’s-complement representation of−5 applying Equation 2.3: A. [1011] B. [11011]C. [111011] Observe second third bit vectors derived ﬁrst sign extension. One point worth making relative order conversion one data size another unsigned signed affect behavior ofa program. Consider following code: 1 short sx = -12345; /* -12345 */ 2 unsigned uy = sx; /* Mystery! */ 3 4 printf("uy = %u:\t", uy); 5 show_bytes((byte_pointer) &uy, sizeof(unsigned)); run big-endian machine, code causes following output printed: uy = 4294954951: ff ff cf c7 shows converting short tounsigned , ﬁrst change size signed unsigned. is, (unsigned) sx equivalent (unsigned) (int) sx , evaluating 4,294,954,951, (unsigned) (unsigned short) sx , evaluates 53,191. Indeed convention required C standards. Practice Problem 2.23 Consider following C functions: int fun1(unsigned word) { return (int) ((word << 24) >> 24); } int fun2(unsigned word) { return ((int) word << 24) >> 24; } Assume executed machine 32-bit word size uses two’s- complement arithmetic. Assume also right shifts signed values per-formed arithmetically, right shifts unsigned values performed logically.Section 2.2 Integer Representations 75 A. Fill following table showing effect functions several example arguments. ﬁnd convenient work hexa-decimal representation. remember hex digits 8through Fhave signiﬁcant bits equal 1. w fun1(w) fun2(w) 0x00000076 0x87654321 0x000000C9 0xEDCBA987 B. Describe words useful computation functions performs. 2.2.7 Truncating Numbers Suppose that, rather extending value extra bits, reduce number bits representing number. occurs, example, code: 1 int x = 53191; 2 short sx = (short) x; /* -12345 */ 3 int = sx; /* -12345 */ typical 32-bit machine, cast xto short , truncate 32-bit int 16-bit short int . saw before, 16-bit pattern two’s-complement representation −12,345. cast back int, sign extension set high-order 16 bits ones, yielding 32-bit two’s-complement representation −12,345. truncating w-bit number /vectorx=[x w−1,xw−2,...,x0]t oak-bit number, drop high-order w−kbits, giving bit vector /vectorx/prime=[xk−1,xk−2,...,x0]. Truncating number alter value—a form overﬂow. investigatewhat numeric value result. unsigned number x, result truncating tokbits equivalent computing xmod 2 k. seen applying modulus operation Equation 2.1: B2Uw([xw−1,xw−2,...,x 0])mod 2k=/bracketleftBiggw−1/summationdisplay i=0xi2i/bracketrightBigg mod 2k =/bracketleftBiggk−1/summationdisplay i=0xi2i/bracketrightBigg mod 2k =k−1/summationdisplay i=0xi2i =B2Uk([xk−1,xk−2,...,x 0])76 Chapter 2 Representing Manipulating Information derivation, make use property 2imod 2k=0 i≥k, that/summationtextk−1 i=0xi2i≤/summationtextk−1 i=02i=2k−1<2k. two’s-complement number x, similar argument shows B2Tw([xw−1,xw−2,...,x0])mod 2k=B2Uk([xk−1,xk−2,...,x0]). is, xmod 2kcan represented unsigned number bit-level representation [xk−1,xk−2,...,x0]. general, however, treat truncated number signed. numeric value U2Tk(xmod 2k). Summarizing, effect truncation unsigned numbers B2U k([xk−1,xk−2,...,x0])=B2Uw([xw−1,xw−2,...,x0])mod 2k,(2.9) effect two’s-complement numbers B2Tk([xk−1,xk−2,...,x 0])=U2T k(B2U w([xw−1,xw−2,...,x 0])mod 2k)(2.10) Practice Problem 2.24 Suppose truncate 4-bit value (represented hex digits 0through F)t oa3 - bit value (represented hex digits 0through 7). Fill table showing effect truncation cases, terms unsigned two’s-complement interpretations bit patterns. Hex Unsigned Two’s complement Original Truncated Original Truncated Original Truncated 00 0 0 22 2 2 91 9 −7 B3 11 −5 F7 15 −1 Explain Equations 2.9 2.10 apply cases. 2.2.8 Advice Signed vs. Unsigned seen, implicit casting signed unsigned leads non- intuitive behavior. Nonintuitive features often lead program bugs, ones involving nuances implicit casting especially difﬁcult see. Since thecasting takes place without clear indication code, programmers oftenoverlook effects. following two practice problems illustrate subtle errors arise due implicit casting unsigned data type.Section 2.2 Integer Representations 77 Practice Problem 2.25 Consider following code attempts sum elements array a, number elements given parameter length : 1/* WARNING: buggy code */ 2float sum_elements(float a[], unsigned length) { 3 int i; 4 float result = 0; 5 6 (i = 0; <= length-1; i++) 7 result += a[i]; 8 return result; 9} run argument length equal 0, code return 0 .0. Instead encounters memory error. Explain happens. Show code canbe corrected. Practice Problem 2.26 given assignment writing function determines whether onestring longer another. decide make use string library functionstrlen following declaration: /* Prototype library function strlen */ size_t strlen(const char *s); ﬁrst attempt function: /* Determine whether string longer string *//* WARNING: function buggy */ int strlonger(char *s, char *t) { return strlen(s) - strlen(t) > 0; } test sample data, things seem work quite right. investigate determine data type size_t deﬁned (via typedef ) header ﬁle stdio.h unsigned int . A. cases function produce incorrect result? B. Explain incorrect result comes about.C. Show ﬁx code work reliably.78 Chapter 2 Representing Manipulating Information Aside Security vulnerability getpeername 2002, programmers involved FreeBSD open source operating systems project realized implementation getpeername library function security vulnerability. simpliﬁed version code went something like this: 1/* 2 * Illustration code vulnerability similar found 3 * FreeBSD’s implementation getpeername() 4 */ 5 6/* Declaration library function memcpy */ 7void *memcpy(void *dest, void *src, size_t n); 8 9/* Kernel memory region holding user-accessible data */ 10 #define KSIZE 1024 11 char kbuf[KSIZE]; 12 13 /* Copy maxlen bytes kernel region user buffer */ 14 int copy_from_kernel(void *user_dest, int maxlen) { 15 /* Byte count len minimum buffer size maxlen */ 16 int len = KSIZE < maxlen ? KSIZE : maxlen; 17 memcpy(user_dest, kbuf, len); 18 return len; 19 } code, show prototype library function memcpy line 7, designed copy speciﬁed number bytes nfrom one region memory another. function copy_from_kernel , starting line 14, designed copy data main- tained operating system kernel designated region memory accessible user. Mostof data structures maintained kernel readable user, since may con-tain sensitive information users jobs running system, regionshown kbuf intended one user could read. parameter maxlen intended length buffer allocated user indicated argument user_dest . computation line 16 makes sure bytes copied available either source destination buffer. Suppose, however, malicious programmer writes code calls copy_from_kernel negative value maxlen . minimum computation line 16 compute value len, passed parameter ntomemcpy . Note, however, parameter nis declared data type size_t . data type declared (via typedef ) library ﬁle stdio.h . Typically deﬁned unsigned int 32-bit machines. Since argument nis unsigned, memcpy treat large, positive number attempt copy many bytes kernel region user’s buffer. Copying many bytes (at least 2 31) actually work, program encounter invalid addresses process, program could read regions kernel memory authorized.Section 2.3 Integer Arithmetic 79 see problem arises due mismatch data types: one place length parameter signed; another place unsigned. mismatches source bugs and, example shows, even lead security vulnerabilities. Fortunately, reported cases programmer exploited vulnerability FreeBSD. issued security advisory, “FreeBSD-SA-02:38.signed-error,” advising system administrators apply patch would remove vulnerability. bug ﬁxed declaring parameter maxlen tocopy_from_kernel type size_t , consistent parameter nofmemcpy . also declare local variable lenand return value type size_t . seen multiple ways subtle features unsigned arith- metic, especially implicit conversion signed unsigned, lead toerrors vulnerabilities. One way avoid bugs never use unsignednumbers. fact, languages C support unsigned integers. Appar-ently language designers viewed trouble areworth. example, Java supports signed integers, requires theybe implemented two’s-complement arithmetic. normal right shift oper-ator>>is guaranteed perform arithmetic shift. special operator >>>is deﬁned perform logical right shift. Unsigned values useful want think words col- lections bits numeric interpretation. occurs, example, whenpacking word ﬂags describing various Boolean conditions. Addresses naturally unsigned, systems programmers ﬁnd unsigned types helpful.Unsigned values also useful implementing mathematical packages modular arithmetic multiprecision arithmetic, numbers rep- resented arrays words. 2.3 Integer Arithmetic Many beginning programmers surprised ﬁnd adding two positive num-bers yield negative result, comparison x<y yield different result comparison x - y<0 . properties artifacts ﬁnite na- ture computer arithmetic. Understanding nuances computer arithmeticcan help programmers write reliable code. 2.3.1 Unsigned Addition Consider two nonnegative integers xandy, 0 ≤x,y≤2w−1. numbers represented w-bit unsigned numbers. compute sum, however, possible range 0 ≤x+y≤2w+1−2. Representing sum could require w+1 bits. example, Figure 2.20 shows plot function x+ywhen xandyhave 4-bit representations. arguments (shown hor- izontal axes) range 0 15, sum ranges 0 30. shape thefunction sloping plane (the function linear dimensions). were80 Chapter 2 Representing Manipulating Information 32Integer addition 28 24 20 16 12 8 40 20 46810121402468101214 Figure 2.20 Integer addition. 4-bit word size, sum could require 5 bits. maintain sum w+1-bit number add another value, may re- quirew+2 bits, on. continued “word size inﬂation” means cannot place bound word size required fully represent results arith-metic operations. programming languages, Lisp, actually supportinﬁnite precision arithmetic allow arbitrary (within memory limits machine, course) integer arithmetic. commonly, programming languagessupport ﬁxed-precision arithmetic, hence operations “addition” and“multiplication” differ counterpart operations integers. Unsigned arithmetic viewed form modular arithmetic. Unsigned addition equivalent computing sum modulo 2 w. value com- puted simply discarding high-order bit w+1-bit representation x+y. example, consider 4-bit number representation x=9 y=12, bit representations [1001] [1100], respectively. sum 21, havinga 5-bit representation [10101]. discard high-order bit, get [0101],that is, decimal value 5. matches value 21 mod 16 =5. general, see x+y<2 w, leading bit w+1-bit representation sum equal 0, hence discarding change numeric value. hand, 2w≤x+y<2w+1, leading bit inSection 2.3 Integer Arithmetic 81 Figure 2.21 Relation integeraddition unsignedaddition. x+yis greater 2 w−1, sum overﬂows.2w 02w/H110011Overflow Normalx/H11001uyx/H11001y thew+1-bit representation sum equal 1, hence discarding equivalent subtracting 2wfrom sum. two cases illustrated Figure 2.21. give us value range 0 ≤x+y−2w<2w+1−2w=2w, precisely modulo 2wsum xandy. Let us deﬁne operation +u wfor arguments xandysuch 0 ≤x,y < 2was x+u wy=/braceleftbiggx+y, x +y<2w x+y−2w,2w≤x+y<2w+1(2.11) precisely result get C performing addition two w-bit unsigned values. arithmetic operation said overﬂow full integer result cannot ﬁt within word size limits data type. Equation 2.11 indicates, overﬂow occurs two operands sum 2wor more. Figure 2.22 shows plot unsigned addition function word size w=4. sum computed modulo 24=16. x+y<16, overﬂow, x+u 4yis simply x+y. shown region forming sloping plane labeled “Normal.” x+y≥16, addition overﬂows, effect decrementing sum 16. isshown region forming sloping plane labeled “Overﬂow.” executing C programs, overﬂows signaled errors. times, however, might wish determine whether overﬂow occurred. exam-ple, suppose compute s.=x+ u wy, wish determine whether sequals x+y. claim overﬂow occurred s<x (or equivalently, s<y ). see this, observe x+y≥x, hence sdid overﬂow, surely s≥x. hand, sdid overﬂow, s=x+y−2w. Given y<2w, y−2w<0, hence s=x+(y−2w)<x .I u r earlier example, saw 9 +u 412=5. see overﬂow occurred, since 5<9. Practice Problem 2.27 Write function following prototype: /* Determine whether arguments added without overflow */ int uadd_ok(unsigned x, unsigned y); function return 1 arguments xandycan added without causing overﬂow.82 Chapter 2 Representing Manipulating Information 16 14 12 10 86 4 2 0Overflow Normal 0246810121402468101214Unsigned addition (4–bit word) Figure 2.22 Unsigned addition. 4-bit word size, addition performed modulo 16. Modular addition forms mathematical structure known abelian group , named Danish mathematician Niels Henrik Abel (1802–1829). is, itis commutative (that’s “abelian” part comes in) associative; hasan identity element 0, every element additive inverse. Let us considerthe set w-bit unsigned numbers addition operation + u w. every value x, must value -u wxsuch -u wx+u wx=0. x=0, additive inverse clearly 0. x>0, consider value 2w−x. Observe number range 0 <2w−x<2w, and(x+2w−x)mod 2w=2wmod 2w=0. Hence, inverse xunder +u w. two cases lead following equation 0≤x<2w: -u wx=/braceleftbiggx, x =0 2w−x, x > 0(2.12) Practice Problem 2.28 represent bit pattern length w=4 single hex digit. unsigned interpretation digits, use Equation 2.12 ﬁll followingSection 2.3 Integer Arithmetic 83 table giving values bit representations (in hex) unsigned additive inverses digits shown. x -u 4x Hex Decimal Decimal Hex 0 5 8 F 2.3.2 Two’s-Complement Addition two’s-complement addition, must decide result either large (positive) small (negative) represent. Given integer values xandyin range −2w−1≤x, y≤2w−1−1, sum range −2w≤x+y≤2w−2, potentially requiring w+1 bits represent exactly. before, avoid ever-expanding data sizes truncating representation w bits. result familiar mathematically modular addition, however. Thew-bit two’s-complement sum two numbers exact bit-level representation unsigned sum. fact, computers use machineinstruction perform either unsigned signed addition. Thus, deﬁnetwo’s-complement addition word size w, denoted + w, operands xandy −2w−1≤x,y < 2w−1as x+t wy.=U2Tw(T2Uw(x)+u wT2Uw(y)) (2.13) Equation 2.5, write T2Uw(x)asxw−12w+x, T2U w(y)asyw−12w+ y. Using property +u wis simply addition modulo 2w, along prop- erties modular addition, x+t wy=U2T w(T2U w(x)+u wT2U w(y)) =U2T w[(xw−12w+x+yw−12w+y)mod 2w] =U2Tw[(x+y)mod 2w] terms xw−12wandyw−12wdrop since equal 0 modulo 2w. better understand quantity, let us deﬁne zas integer sum z.=x+y, z/primeasz/prime.=zmod 2w, andz/prime/primeasz/prime/prime.=U2Tw(z/prime). value z/prime/primeis equal x+t wy.W e divide analysis four cases, illustrated Figure 2.23: 1.−2w≤z<−2w−1. z/prime=z+2w. gives 0 ≤z/prime<−2w−1+ 2w=2w−1. Examining Equation 2.8, see z/primeis range z/prime/prime=z/prime. case referred negative overﬂow . added two negative numbers xandy(that’s way z<−2w−1) obtained nonnegative result z/prime/prime=x+y+2w.84 Chapter 2 Representing Manipulating Information Figure 2.23 Relation integerand two’s-complementaddition. x+yis less −2 w−1, negative overﬂow. greater 2w−1+1, positive overﬂow.+2w –2w00+2w/H110021+2w/H110021 –2w/H110021–2w/H110021 Negative overflowPositive overflow Case 4 Case 3 Case 2Case 1Normalx/H11001 tyx/H11001y 2.−2w−1≤z<0. z/prime=z+2w, giving −2w−1+2w= 2w−1≤z/prime<2w. Examining Equation 2.8, see z/primeis range z/prime/prime=z/prime−2w, therefore z/prime/prime=z/prime−2w=z+2w−2w=z. is, two’s- complement sum z/prime/primeequals integer sum x+y. 3.0≤z<2w−1. z/prime=z, giving 0 ≤z/prime<2w−1, hence z/prime/prime= z/prime=z. Again, two’s-complement sum z/prime/primeequals integer sum x+y. 4.2w−1≤z<2w. z/prime=z, giving 2w−1≤z/prime<2w. range z/prime/prime=z/prime−2w, giving z/prime/prime=x+y−2w. case referred positive overﬂow . added two positive numbers xandy(that’s way z≥2w−1) obtained negative result z/prime/prime=x+y−2w. preceding analysis, shown operation +t wis applied values xandyin range −2w−1≤x,y≤2w−1−1, x+t wy=⎧ ⎪⎨ ⎪⎩x+y−2w,2w−1≤x+yPositive overﬂow x+y, −2w−1≤x+y<2w−1Normal x+y+2w,x+y<−2w−1Negative overﬂow(2.14) illustration, Figure 2.24 shows examples 4-bit two’s-complement addition. example labeled case corresponds derivation Equation 2.14. Note 24=16, hence negative overﬂow yields result 16 integer sum, positive overﬂow yields result 16 less. include bit-level representations operands result. Observe thatthe result obtained performing binary addition operands andtruncating result four bits. Figure 2.25 illustrates two’s-complement addition word size w=4. operands range −8 7. x+y<−8, two’s-complement addition negative underﬂow, causing sum incremented 16. −8≤ x+y<8, addition yields x+y. x+y≥8, addition negative overﬂow, causing sum decremented 16. three ranges forms sloping plane ﬁgure.Section 2.3 Integer Arithmetic 85 xy x +yx +t 4y Case −8 −5 −13 3 1 [1000] [1011] [10011] [0011] −8 −8 −16 0 1 [1000] [1000] [10000] [0000] −85 −3 −32 [1000] [0101] [11101] [1101] 25 7 7 3 [0010] [0101] [00111] [0111] 55 1 0 −64 [0101] [0101] [01010] [1010] Figure 2.24 Two’s-complement addition examples. bit-level representation 4-bit two’s-complement sum obtained performing binary addition operands truncating result 4bits. Normal Negative overflowPositive overflowTwo’s-complement addition (4-bit word) 8 6 4 2 0 /H110022 /H110024 /H110026 /H110028 /H110028 /H110028/H110026/H110022 /H1100240246 /H110026/H110024/H1100220246 Figure 2.25 Two’s-complement addition. 4-bit word size, addition negative overﬂow x+y<−8and positive overﬂow x+y≥8.86 Chapter 2 Representing Manipulating Information Equation 2.14 also lets us identify cases overﬂow occurred. xandyare negative x+t wy≥0, negative overﬂow. bothxandyare positive x+t wy<0, positive overﬂow. Practice Problem 2.29 Fill following table style Figure 2.24. Give integer values 5-bit arguments, values integer two’s-complement sums,the bit-level representation two’s-complement sum, case thederivation Equation 2.14. xy x +yx +t 5y Case [10100] [10001] [11000] [11000] [10111] [01000] [00010] [00101] [01100] [00100] Practice Problem 2.30 Write function following prototype: /* Determine whether arguments added without overflow */ int tadd_ok(int x, int y); function return 1 arguments xandycan added without causing overﬂow. Practice Problem 2.31 coworker gets impatient analysis overﬂow conditions fortwo’s-complement addition presents following implementation oftadd_ok : /* Determine whether arguments added without overflow */ /* WARNING: code buggy. */ int tadd_ok(int x, int y) { int sum = x+y; return (sum-x == y) && (sum-y == x); } look code laugh. Explain why.Section 2.3 Integer Arithmetic 87 Practice Problem 2.32 assigned task writing code function tsub_ok , arguments xandy, return 1 computing x-ydoes cause overﬂow. written code Problem 2.30, write following: /* Determine whether arguments subtracted without overflow */ /* WARNING: code buggy. */ int tsub_ok(int x, int y) { return tadd_ok(x, -y); } values xandywill function give incorrect results? Writing correct version function left exercise (Problem 2.74). 2.3.3 Two’s-Complement Negation see every number xin range −2w−1≤x<2w−1has additive in- verse +t follows. First, x/negationslash=− 2w−1, see additive inverse simply −x. is, −2w−1<−x<2w−1and−x+t wx=−x+x=0. x=− 2w−1=TMinw, hand, −x=2w−1cannot represented w- bit number. claim special value additive inverse +t w. value −2w−1+t w−2w−1is given third case Equation 2.14, since −2w−1+− 2w−1=− 2w. gives −2w−1+t w−2w−1=− 2w+2w=0. analysis, deﬁne two’s-complement negation operation -t wforxin range −2w−1≤x<2w−1as -t wx=/braceleftbigg−2w−1,x=− 2w−1 −x, x > −2w−1(2.15) Practice Problem 2.33 represent bit pattern length w=4 single hex digit. two’s- complement interpretation digits, ﬁll following table determinethe additive inverses digits shown: x -t 4x Hex Decimal Decimal Hex 0 5 8 F observe bit patterns generated two’s-complement unsigned (Problem 2.28) negation?88 Chapter 2 Representing Manipulating Information Web Aside DATA:TNEG Bit-level representation two’s-complement negation several clever ways determine two’s-complement negation value represented bit level. techniques useful, one encounters value 0xfffffffa debugging program, lend insight nature two’s-complement representation. One technique performing two’s-complement negation bit level complement bits increment result. C, state integer value x, computing expressions -xand~ x+1 give identical results. examples 4-bit word size: /vectorx ~/vectorx incr(~/vectorx) [0101] 5 [1010] −6 [1011] −5 [0111] 7 [1000] −8 [1001] −7 [1100] −4 [0011] 3 [0100] 4 [0000] 0 [1111] −1 [0000] 0 [1000] −8 [0111] 7 [1000] −8 earlier example, know complement 0xfis0x0, complement 0xa is0x5, 0xfffffffa two’s-complement representation −6. second way perform two’s-complement negation number xis based splitting bit vector two parts. Let kbe position rightmost 1, bit-level representation xhas form [ xw−1,xw−2,...,x k+1,1,0,... 0]. (This possible long x/negationslash=0.) negation written binary form [ ~xw−1,~xw−2,...~xk+1,1,0,..., 0]. is, complement bit left bit position k. illustrate idea 4-bit numbers, highlight rightmost pattern 1 ,0,..., 0 italics: x −x [1100]−4[ 0 100]4 [1000 ]−8[ 1000 ]−8 [010 1] 5 [101 1]−5 [011 1] 7 [100 1]−7 2.3.4 Unsigned Multiplication Integers xandyin range 0 ≤x, y≤2w−1 represented w-bit un- signed numbers, product x.ycan range 0 (2w−1)2= 22w−2w+1+1. could require many 2 wbits represent. Instead, un- signed multiplication C deﬁned yield w-bit value given low-order wbits 2 w-bit integer product. Equation 2.9, seen equiv- alent computing product modulo 2w. Thus, effect w-bit unsigned multiplication operation *u wis x*u wy=(x.y)mod 2w(2.16)Section 2.3 Integer Arithmetic 89 2.3.5 Two’s-Complement Multiplication Integers xandyin range −2w−1≤x,y≤2w−1−1 represented w- bit two’s-complement numbers, product x.ycan range −2w−1. (2w−1−1)=− 22w−2+2w−1and−2w−1.−2w−1=22w−2. could require many 2 wbits represent two’s-complement form—most cases would ﬁt 2w−1 bits, special case 22w−2requires full 2 wbits (to include sign bit 0). Instead, signed multiplication C generally performed bytruncating 2 w-bit product wbits. Equation 2.10, effect w-bit two’s-complement multiplication operation * wis x*t wy=U2Tw((x.y)mod 2w) (2.17) claim bit-level representation product operation identical unsigned two’s-complement multiplication. is, given bit vectors /vectorx and/vectoryof length w, bit-level representation unsigned product B2U w(/vectorx)*u w B2U w(/vectory)is identical bit-level representation two’s-complement product B2T w(/vectorx)*t wB2T w(/vectory). implies machine use single type multiply instruction multiply signed unsigned integers. illustrations, Figure 2.26 shows results multiplying different 3-bit numbers. pair bit-level operands, perform unsigned andtwo’s-complement multiplication, yielding 6-bit products, truncate theseto 3 bits. unsigned truncated product always equals x.ymod 8. bit- level representations truncated products identical unsignedand two’s-complement multiplication, even though full 6-bit representationsdiffer. show low-order bits two products (unsigned two’s complement) identical, let x=B2T w(/vectorx)andy=B2Tw(/vectory)be two’s- complement values denoted bit patterns, let x/prime=B2Uw(/vectorx)andy/prime= B2U w(/vectory)be unsigned values. Equation 2.5, x/prime=x+xw−12w, Mode xy x .y Truncated x.y Unsigned 5 [101] 3 [011] 15 [001111] 7 [111] Two’s comp. −3 [101] 3 [011] −9 [110111] −1 [111] Unsigned 4 [100] 7 [111] 28 [011100] 4 [100] Two’s comp. −4 [100] −1 [111] 4 [000100] −4 [100] Unsigned 3 [011] 3 [011] 9 [001001] 1 [001] Two’s comp. 3 [011] 3 [011] 9 [001001] 1 [001] Figure 2.26 Three-bit unsigned two’s-complement multiplication examples. Although bit-level representations full products may differ, thetruncated products identical.90 Chapter 2 Representing Manipulating Information andy/prime=y+yw−12w. Computing product values modulo 2wgives following: (x/prime.y/prime)mod 2w=[(x+xw−12w).(y+yw−12w)] mod 2w(2.18) =[x.y+(xw−1y+yw−1x)2w+xw−1yw−122w] mod 2w =(x.y)mod 2w terms weight 2wdrop due modulus operator, shown low-order wbits x.yandx/prime.y/primeare identical. Practice Problem 2.34 Fill following table showing results multiplying different 3-bit num- bers, style Figure 2.26: Mode xy x .y Truncated x.y Unsigned [100] [101] Two’s comp. [100] [101] Unsigned [010] [111] Two’s comp. [010] [111] Unsigned [110] [110] Two’s comp. [110] [110] see unsigned arithmetic two’s-complement arithmetic w-bit numbers isomorphic—the operations +u w,-u w, and*u whave exact effect bit level +t w,-t w, *t w. Practice Problem 2.35 given assignment develop code function tmult_ok determine whether two arguments multiplied without causing overﬂow.Here solution: /* Determine whether arguments multiplied without overflow */ int tmult_ok(int x, int y) { int p = x*y; /* Either x zero, dividing p x gives */ return !x || p/x == y; } test code number values xandy, seems work properly. coworker challenges you, saying, “If can’t use subtraction totest whether addition overﬂowed (see Problem 2.31), usedivision test whether multiplication overﬂowed?” Devise mathematical justiﬁcation approach, along following lines. First, argue case x=0 handled correctly. Otherwise, considerSection 2.3 Integer Arithmetic 91 w-bit numbers x(x/negationslash=0),y,p, andq, pis result performing two’s- complement multiplication xandy, andqis result dividing pbyx. 1.Show x.y, integer product xandy, written form x.y=p+t2w, t/negationslash=0 computation poverﬂows. 2.Show pcan written form p=x.q+r, |r|<|x|. 3.Show q=yif r=t=0. Practice Problem 2.36 case data type inthas 32 bits, devise version tmult_ok (Prob- lem 2.35) uses 64-bit precision data type long long , without using division. Aside Security vulnerability XDR library 2002, discovered code supplied Sun Microsystems implement XDR library, widely used facility sharing data structures programs, security vulnerability arising fact multiplication overﬂow without notice given program. Code similar containing vulnerability shown below: 1/* 2 * Illustration code vulnerability similar found 3 * Sun’s XDR library. 4 */ 5void* copy_elements(void *ele_src[], int ele_cnt, size_t ele_size) { 6 /* 7 * Allocate buffer ele_cnt objects, ele_size bytes 8 * copy locations designated ele_src 9 */ 10 void *result = malloc(ele_cnt * ele_size); 11 (result == NULL) 12 /* malloc failed */ 13 return NULL; 14 void *next = result; 15 int i; 16 (i = 0; < ele_cnt; i++) { 17 /* Copy object destination */ 18 memcpy(next, ele_src[i], ele_size); 19 /* Move pointer next memory region */ 20 next += ele_size; 21 } 22 return result; 23 }92 Chapter 2 Representing Manipulating Information function copy_elements designed copy ele_cnt data structures, consisting ele_ size bytes buffer allocated function line 10. number bytes required computed asele_cnt * ele_size . Imagine, however, malicious programmer calls function ele_cnt 1,048,577 (220+1) ele_size 4,096 (212). multiplication line 10 overﬂow, causing 4096 bytes allocated, rather 4,294,971,392 bytes required hold much data. loop starting line 16 attempt copy bytes, overrunning end allocated buffer, therefore corrupting data structures. could cause program crash otherwisemisbehave. Sun code used almost every operating system, widely used programs Internet Explorer Kerberos authentication system. Computer Emergency Response Team (CERT), organization run Carnegie Mellon Software Engineering Institute track security vulnerabilities breaches, issued advisory “CA-2002-25,” many companies rushed patch code. Fortunately, reported security breaches caused vulnerability. similar vulnerability existed many implementations library function calloc . since patched. Practice Problem 2.37 given task patching vulnerability XDR code shown above. decide eliminate possibility multiplication overﬂowing (on 32-bit machine, least) computing number bytes allocate using data typelong long unsigned . replace original call malloc (line 10) follows: long long unsigned asize = ele_cnt * (long long unsigned) ele_size; void *result = malloc(asize); A. code provide improvement original? B. would change code eliminate vulnerability, assuming data type size_t unsigned int , 32 bits long? 2.3.6 Multiplying Constants machines, integer multiply instruction fairly slow, requiring 10 clock cycles, whereas integer operations—such addition, subtrac-tion, bit-level operations, shifting—require 1 clock cycle. conse-quence, one important optimization used compilers attempt replace multiplications constant factors combinations shift addition oper- ations. ﬁrst consider case multiplying power 2, thengeneralize arbitrary constants. Letxbe unsigned integer represented bit pattern [ x w−1,xw−2,...,x0]. k≥0, claim bit-level representation x2kis given bySection 2.3 Integer Arithmetic 93 [xw−1,xw−2,...,x 0,0,..., 0], kzeros added right. property derived using Equation 2.1: B2Uw+k([xw−1,xw−2,...,x 0,0,..., 0])=w−1/summationdisplay i=0xi2i+k =/bracketleftBiggw−1/summationdisplay i=0xi2i/bracketrightBigg .2k =x2k Fork<w , truncate shifted bit vector length w, giving [xw−k−1,xw−k−2,...,x0,0,..., 0]. Equation 2.9, bit vector numeric value x2kmod 2w=x*u w2k. Thus, unsigned variable x, C expression x< <k equivalent x * pwr2k , pwr2k equals 2k. particular, compute pwr2k as1U << k . similar reasoning, show two’s-complement number x bit pattern [ xw−1,xw−2,...,x0], kin range 0 ≤k<w , bit pattern [ xw−k−1,...,x0,0,..., 0] two’s-complement representation ofx*t w2k. Therefore, signed variable x, C expression x< <k equivalent tox * pwr2k , pwr2k equals 2k. Note multiplying power 2 cause overﬂow either unsigned two’s-complement arithmetic. result shows even get thesame effect shifting. Given integer multiplication much costly shifting adding, many C compilers try remove many cases integer multi-plied constant combinations shifting, adding, subtracting. Forexample, suppose program contains expression x*14 . Recognizing 14 = 2 3+22+21, compiler rewrite multiplication (x<<3) + (x<<2) + (x<<1) , replacing one multiplication three shifts two additions. two computations yield result, regardless whether xis unsigned two’s complement, even multiplication would cause overﬂow. (Thiscan shown properties integer arithmetic.) Even better, compiler also use property 14 =2 4−21to rewrite multiplication (x<<4) - (x<<1) , requiring two shifts subtraction. Practice Problem 2.38 see Chapter 3, lea instruction perform computations form (a<<k) + b , kis either 0, 1, 2, 3, bis either 0 program value. compiler often uses instruction perform multiplicationsby constant factors. example, compute 3*aas(a<<1) + . Considering cases bis either 0 equal a, possible values k, multiples acan computed single leainstruction?94 Chapter 2 Representing Manipulating Information Generalizing example, consider task generating code expression x*K, constant K. compiler express binary representation Kas alternating sequence zeros ones: [(0...0)(1...1)(0...0)...(1...1)]. example, 14 written [ (0...0)(111)(0)]. Consider run ones bit position ndown bit position m(n≥m). (For case 14, n=3 andm=1.) compute effect bits product using either two different forms: Form A: (x<<n) + (x<< n−1)+...+ (x<< m) Form B: (x<<n+1) - (x<< m) adding together results run, able compute x*Kwith- multiplications. course, trade-off using combinations ofshifting, adding, subtracting versus single multiplication instruction dependson relative speeds instructions, highly machine de- pendent. compilers perform optimization small number ofshifts, adds, subtractions sufﬁce. Practice Problem 2.39 could modify expression form B case bit position n signiﬁcant bit? Practice Problem 2.40 following values K, ﬁnd ways express x*Kusing speciﬁed number operations, consider additions subtrac-tions comparable cost. may need use tricks beyond simpleform B rules considered far. K Shifts Add/Subs Expression 62 1 31 1 1 −62 1 55 2 2 Practice Problem 2.41 run 1s starting bit position ndown bit position m(n≥m), saw generate two forms code, B. compiler decidewhich form use?Section 2.3 Integer Arithmetic 95 k> > k (Binary) Decimal 12340 /2k 0 0011000000110100 12340 12340.0 1 0001100000011010 6170 6170.0 4 0000001100000011 771 771.25 8 00000000 00110000 48 48.203125 Figure 2.27 Dividing unsigned numbers powers 2. examples illustrate performing logical right shift khas effect dividing 2kand rounding toward zero. 2.3.7 Dividing Powers Two Integer division machines even slower integer multiplication— requiring 30 clock cycles. Dividing power 2 also performedusing shift operations, use right shift rather left shift. two dif-ferent shifts—logical arithmetic—serve purpose unsigned two’s-complement numbers, respectively. Integer division always rounds toward zero. x≥0 y>0, result ⌊x/y⌋, real number a,⌊a⌋is deﬁned unique integer /primesuch a/prime≤a<a/prime+1. examples, ⌊3.14⌋=3,⌊−3.14⌋=− 4, ⌊3⌋=3. Consider effect applying logical right shift kto unsigned number. claim gives result dividing 2k. examples, Figure 2.27 shows effects performing logical right shifts 16-bit representation of12,340 perform division 1, 2, 16, 256. zeros shifted left areshown italics. also show result would obtain divisionswith real arithmetic. examples show result shifting consistentlyrounds toward zero, convention integer division. show relation logical right shifting dividing power 2, let xbe unsigned integer represented bit pattern [ x w−1,xw−2,...,x0], andkbe range 0 ≤k<w . Let x/primebe unsigned number w−k- bit representation [ xw−1,xw−2,...,x k], x/prime/primebe unsigned number k-bit representation [ xk−1,...,x0]. claim x/prime=⌊x/2k⌋. see this, Equation 2.1, x=/summationtextw−1 i=0xi2i,x/prime=/summationtextw−1 i=kxi2i−k, andx/prime/prime=/summationtextk−1 i=0xi2i.W e therefore write xasx=2kx/prime+x/prime/prime. Observe 0 ≤x/prime/prime≤/summationtextk−1 i=02i=2k−1, hence 0 ≤x/prime/prime<2k, implying ⌊x/prime/prime/2k⌋=0. Therefore, ⌊x/2k⌋=⌊x/prime+x/prime/prime/2k⌋= x/prime+⌊x/prime/prime/2k⌋=x/prime. Performing logical right shift bit vector [ xw−1,xw−2,...,x0]b ykyields bit vector [0, ..., 0,xw−1,xw−2,...,xk] bit vector numeric value x/prime. Therefore, unsigned variable x, C expression x> >k equivalent x / pwr2k , pwr2k equals 2k.96 Chapter 2 Representing Manipulating Information k> > k (Binary) Decimal −12340 /2k 0 1100111111001100 −12340 −12340.0 1 1110011111100110 −6170 −6170.0 4 1111110011111100 −772 −771.25 8 11111111 11001111 −49 −48.203125 Figure 2.28 Applying arithmetic right shift. examples illustrate arithmetic right shift similar division power 2, except rounds rather toward zero. consider effect performing arithmetic right shift two’s- complement number. positive number, 0 signiﬁcant bit,and effect logical right shift. Thus, arithmetic rightshift kis division 2 kfor nonnegative number. example negative number, Figure 2.28 shows effect applying arithmetic right shiftto 16-bit representation −12,340 different shift amounts. see, result almost dividing power 2. case rounding required ( k=1), result correct. rounding required, shifting causes result rounded downward rather toward zero, bethe convention. example, expression -7/2 yield -3rather -4. Let us better understand effect arithmetic right shifting use perform division power 2. Let xbe two’s-complement integer represented bit pattern [ x w−1,xw−2,...,x 0], kbe range 0≤k<w . Let x/primebe two’s-complement number represented w−k bits [xw−1,xw−2,...,xk], x/prime/primebe unsigned number represented low-order kbits [xk−1,...,x0]. similar analysis unsigned case, havex=2kx/prime+x/prime/prime, 0 ≤x/prime/prime<2k, giving x/prime=⌊x/2k⌋. Furthermore, observe shifting bit vector [ xw−1,xw−2,...,x0]right arithmetically bykyields bit vector [xw−1,..., xw−1,xw−1,xw−2,...,xk] sign extension w−kbits wbits [ xw−1,xw−2,...,x k]. Thus, shifted bit vector two’s-complement representation ⌊x/2k⌋. analysis conﬁrms ﬁndings examples Figure 2.28. Forx≥0, rounding required ( x/prime/prime=0), analysis shows shifted result desired value. x<0 y>0, however, result integer division ⌈x/y⌉, real number a,⌈a⌉is deﬁned unique integer a/primesuch a/prime−1<a≤a/prime. is, integer division round negative results upward toward zero. Thus, right shifting negative numberbykis equivalent dividing 2 kwhen rounding occurs. analysis also conﬁrms ﬁndings example Figure 2.28. correct improper rounding “biasing” value shifting. technique exploits property ⌈x/y⌉=⌊(x+y−1)/y⌋for integers xandysuch y>0. examples, x=−30 y=4, havex+y−1=−27, ⌈−30/4⌉=− 7=⌊ − 27/4⌋. x=−32 y=4,Section 2.3 Integer Arithmetic 97 k Bias −12,340 + Bias (Binary) >> k (Binary) Decimal −12340 /2k 00 1100111111001100 1100111111001100 −12340 −12340.0 11 110011111100110 11 110011111100110 −6170 −6170.0 41 5 110011111101 1011 1111 110011111101 −771 −771.25 8 255 11010000 11001011 11111111 11010000 −48 −48.203125 Figure 2.29 Dividing two’s-complement numbers powers 2. adding bias right shift, result rounded toward zero. x+y−1=−29, ⌈−32/4⌉=− 8=⌊ − 29/4⌋. see relation holds general, suppose x=ky+r, 0 ≤r<y , giving (x+y−1)/y= k+(r+y−1)/y, ⌊(x+y−1)/y⌋=k+⌊(r+y−1)/y⌋. latter term equal 0 r=0, 1 r>0. is, adding bias y−1t xand rounding division downward, get kwhen ydivides xand k+1 otherwise. Thus, x<0, ﬁrst add 2k−1t oxbefore right shifting, get correctly rounded result. analysis shows two’s-complement machine using arithmetic right shifts, C expression (x<0 ? x+(1<<k)-1 : x) >> k equivalent x/pwr2k , pwr2k equals 2k. Figure 2.29 demonstrates adding appropriate bias performing arithmetic right shift causes result correctly rounded. thirdcolumn, show result adding bias value −12,340, lower k bits (those shifted right) shown italics. see thatthe bits left may may incremented. case norounding required ( k=1), adding bias affects bits shifted off. cases rounding required, adding bias causes upper bits tobe incremented, result rounded toward zero. Practice Problem 2.42 Write function div16 returns value x/16 integer argument x. function use division, modulus, multiplication, conditionals ( ifor ?:), comparison operators (e.g., <,>,o r==), loops. may assume data type intis 32 bits long uses two’s-complement representation, right shifts performed arithmetically. see division power 2 implemented using logical arithmetic right shifts. precisely reason two types right shifts areavailable machines. Unfortunately, approach generalize todivision arbitrary constants. Unlike multiplication, cannot express divisionby arbitrary constants Kin terms division powers 2.98 Chapter 2 Representing Manipulating Information Practice Problem 2.43 following code, omitted deﬁnitions constants MandN: #define /* Mystery number 1 */ #define N /* Mystery number 2 */ int arith(int x, int y) { int result = 0; result = x*M + y/N; /* N mystery numbers. */ return result; } compiled code particular values MandN. compiler opti- mized multiplication division using methods discussed. Thefollowing translation generated machine code back C: /* Translation assembly code arith */ int optarith(int x, int y) { n tt=x ; x <<= 5; x- =t ;i f( y<0 )y+ =7 ;y >>= 3; /* Arithmetic shift */ return x+y; } values MandN? 2.3.8 Final Thoughts Integer Arithmetic seen, “integer” arithmetic performed computers really form modular arithmetic. ﬁnite word size used represent numbers limitsthe range possible values, resulting operations overﬂow. havealso seen two’s-complement representation provides clever way beable represent negative positive values, using bit-levelimplementations used perform unsigned arithmetic—operations asaddition, subtraction, multiplication, even division either identical orvery similar bit-level behaviors whether operands unsigned two’s-complement form. seen conventions C language yield surprising results, sources bugs hard recognize orunderstand. especially seen unsigned data type, concep- tually straightforward, lead behaviors even experienced programmersdo expect. also seen data type arise unexpected ways,for example, writing integer constants invoking library routines.Section 2.4 Floating Point 99 Practice Problem 2.44 Assume running code 32-bit machine using two’s-complement arith- metic signed values. Right shifts performed arithmetically signed valuesand logically unsigned values. variables declared initialized follows: int x = foo(); /* Arbitrary value */ int = bar(); /* Arbitrary value */ unsigned ux = x; unsigned uy = y; following C expressions, either (1) argue true (evalu- ates 1) values xandy, (2) give values xandyfor false (evaluates 0): A.( x>0 )| |( x - 1<0 ) B.(x & 7) != 7 || (x<<29 < 0) C.( x*x )> =0 D.x<0| |- x< =0 E.x>0| |- x> =0 F.x+y == uy+ux G.x*~y + uy*ux == -x 2.4 Floating Point ﬂoating-point representation encodes rational numbers form V=x×2y. useful performing computations involving large numbers ( |V|/greatermuch0), numbers close 0 ( |V|/lessmuch1), generally approximation real arithmetic. 1980s, every computer manufacturer devised conventions ﬂoating-point numbers represented details operationsperformed them. addition, often worry much theaccuracy operations, viewing speed ease implementation beingmore critical numerical precision. changed around 1985 advent IEEE Standard 754, carefully crafted standard representing ﬂoating-point numbers oper- ations performed them. effort started 1976 Intel’s sponsorship design 8087, chip provided ﬂoating-point support 8086processor. hired William Kahan, professor University California,Berkeley, consultant help design ﬂoating-point standard futureprocessors. allowed Kahan join forces committee generating anindustry-wide standard auspices Institute Electrical Elec-tronics Engineers (IEEE). committee ultimately adopted standard close to100 Chapter 2 Representing Manipulating Information one Kahan devised Intel. Nowadays, virtually computers support become known IEEE ﬂoating point . greatly improved portability scientiﬁc application programs across different machines. Aside IEEE Institute Electrical Electronic Engineers (IEEE—pronounced “Eye-Triple-Eee”) pro- fessional society encompasses electronic computer technology. publishes journals, sponsors conferences, sets committees deﬁne standards topics ranging power trans-mission software engineering. section, see numbers represented IEEE ﬂoating- point format. also explore issues rounding , number cannot represented exactly format hence must adjusted upward down-ward. explore mathematical properties addition, multiplica-tion, relational operators. Many programmers consider ﬂoating point best uninteresting worst arcane incomprehensible. see thatsince IEEE format based small consistent set principles, isreally quite elegant understandable. 2.4.1 Fractional Binary Numbers ﬁrst step understanding ﬂoating-point numbers consider binary numbers fractional values. Let us ﬁrst examine familiar decimal notation.Decimal notation uses representation form mdm−1...d1d0.d−1d−2...d−n, decimal digit diranges 0 9. notation represents value ddeﬁned d=m/summationdisplay i=−n10i×di weighting digits deﬁned relative decimal point symbol (‘ .’), meaning digits left weighted positive powers 10, giving integralvalues, digits right weighted negative powers 10, giving fractional values. example, 12 .34 10represents number 1 ×101+2×100+ 3×10−1+4×10−2=1234 100. analogy, consider notation form bmbm−1...b1b0.b−1b−2... b−n−1b−n, binary digit, bit, biranges 0 1, illustrated Figure 2.30. notation represents number bdeﬁned b=m/summationdisplay i=−n2i×bi (2.19) symbol ‘ .’ becomes binary point , bits left weighted positive powers 2, right weighted negative powers 2. example, 101 .112represents number 1 ×22+0×21+1×20+1× 2−1+1×2−2=4+0+1+1 2+1 4=53 4.Section 2.4 Floating Point 101 Figure 2.30 Fractional binary repre-sentation. Digits left binary point weights form 2 i, righthave weights form 1/2 i. bmbm–1· · ·· · · b2b1b0b–11 1/2 1/41/8 1/2 n–1 1/2n242m–12m b–2b–3· · · · · · ·b–n–1b–n One readily see Equation 2.19 shifting binary point one position left effect dividing number 2. example, 101.112represents number 53 4,1 0.111 2represents number 2 +0+1 2+ 1 4+1 8=27 8. Similarly, shifting binary point one position right effect multiplying number 2. example, 1011 .12represents number 8+0+2+1+1 2=111 2. Note numbers form 0 .11...12represent numbers 1. example, 0 .1111112represents63 64. use shorthand notation 1 .0−/epsilon1to represent values. Assuming consider ﬁnite-length encodings, decimal notation cannot represent numbers as1 3and5 7exactly. Similarly, fractional binary notation represent numbers written x×2y. values approximated. example, number1 5can represented exactly frac- tional decimal number 0.20. fractional binary number, however, cannotrepresent exactly instead must approximate increasing accuracy bylengthening binary representation: Representation Value Decimal 0.020 20.010 0.0121 40.2510 0.010 22 80.2510 0.0011 23 160.1875 10 0.00110 26 320.1875 10 0.001101 213 640.203125 10 0.0011010 226 1280.203125 10 0.00110011 251 2560.19921875 10102 Chapter 2 Representing Manipulating Information Practice Problem 2.45 Fill missing information following table: Fractional value Binary representation Decimal representation 1 80.001 0 .125 3 4 25 16 10.1011 1.001 5.875 3.1875 Practice Problem 2.46 imprecision ﬂoating-point arithmetic disastrous effects. Febru- ary 25, 1991, ﬁrst Gulf War, American Patriot Missile battery inDharan, Saudi Arabia, failed intercept incoming Iraqi Scud missile. TheScud struck American Army barracks killed 28 soldiers. U.S. GeneralAccounting Ofﬁce (GAO) conducted detailed analysis failure [72] de-termined underlying cause imprecision numeric calculation.In exercise, reproduce part GAO’s analysis. Patriot system contains internal clock, implemented counter incremented every 0.1 seconds. determine time seconds, theprogram would multiply value counter 24-bit quantity fractional binary approximation 1 10. particular, binary representation of1 10is nonterminating sequence 0 .000110011[0011] ...2, portion brackets repeated indeﬁnitely. program approximated 0 .1, value x,b considering ﬁrst 23 bits sequence right binary point:x=0.00011001100110011001100. (See Problem 2.51 discussion could approximated 0 .1 precisely.) A. binary representation 0 .1−x? B. approximate decimal value 0 .1−x? C. clock starts 0 system ﬁrst powered keeps counting there. case, system running around 100 hours. difference actual time time computed bythe software? D. system predicts incoming missile appear based velocity time last radar detection. Given Scud travelsat around 2000 meters per second, far prediction? Normally, slight error absolute time reported clock reading would affect tracking computation. Instead, depend relative timebetween two successive readings. problem Patriot software hadSection 2.4 Floating Point 103 upgraded use accurate function reading time, function calls replaced new code. result, trackingsoftware used accurate time one reading inaccurate time theother [100]. 2.4.2 IEEE Floating-Point Representation Positional notation considered previous section would ef- ﬁcient representing large numbers. example, representation 5×2100would consist bit pattern 101 followed 100 zeros. Instead, would like represent numbers form x×2yby giving values xandy. IEEE ﬂoating-point standard represents number form V=(−1)s× M×2E: .The signsdetermines whether number negative ( s=1) positive (s=0), interpretation sign bit numeric value 0 handled special case. .The signiﬁcand Mis fractional binary number ranges either 1 2 −/epsilon1or 0 1 −/epsilon1. .The exponent Eweights value (possibly negative) power 2. bit representation ﬂoating-point number divided three ﬁelds encode values: .The single sign bit sdirectly encodes sign s. .Thek-bit exponent ﬁeld exp=ek−1...e1e0encodes exponent E. .Then-bit fraction ﬁeld frac=fn−1...f1f0encodes signiﬁcand M, value encoded also depends whether exponent ﬁeld equals 0. Figure 2.31 shows packing three ﬁelds words two common formats. single-precision ﬂoating-point format (a float C), ﬁelds s,exp, frac 1, k=8, n=23 bits each, yielding 32- bit representation. double-precision ﬂoating-point format (a double C), ﬁelds s,exp, frac 1, k=11, n=52 bits each, yielding 64-bit representation. value encoded given bit representation divided three different cases (the latter two variants), depending value exp. illustrated Figure 2.32 single-precision format. Case 1: Normalized Values common case. occurs bit pattern exp neither zeros (numeric value 0) ones (numeric value 255 single precision,2047 double). case, exponent ﬁeld interpreted representing asigned integer biased form. is, exponent value E=e−Bias e unsigned number bit representation e k−1...e1e0, Bias bias104 Chapter 2 Representing Manipulating Information 31 exp frac30Single precision 23 022 63 exp frac (51:32)62Double precision 52 3251 31 frac (31:0)0 Figure 2.31 Standard ﬂoating-point formats. Floating-point numbers represented three ﬁelds. two common formats, packed 32-bit (singleprecision) 64-bit (double precision) words. s00000000 f ≠ 02. Denormalized s11111111000000000000000000000003a. Infinity s111111113b. NaNs ≠ 0 & ≠ 255 f1. Normalized Figure 2.32 Categories single-precision, ﬂoating-point values. value exponent determines whether number (1) normalized, (2) denormalized, (3) special value. value equal 2k−1−1 (127 single precision 1023 double). yields exponent ranges −126 +127 single precision −1022 +1023 double precision. fraction ﬁeld frac interpreted representing fractional value f, 0 ≤f< 1, binary representation 0 .fn−1...f1f0, is, binary point left signiﬁcant bit. signiﬁcand deﬁned beM=1+f. sometimes called implied leading 1 representation, view Mto number binary representation 1 .f n−1fn−2...f0. representation trick getting additional bit precision free, since wecan always adjust exponent Eso signiﬁcand Mis range 1 ≤M< 2 (assuming overﬂow). therefore need explicitly representthe leading bit, since always equals 1.Section 2.4 Floating Point 105 Case 2: Denormalized Values exponent ﬁeld zeros, represented number denormalized form. case, exponent value E=1−Bias , signiﬁcand value M=f, is, value fraction ﬁeld without implied leading 1. Aside set bias way denormalized values? exponent value 1 −Bias rather simply −Bias might seem counterintuitive. see shortly provides smooth transition denormalized normalized values. Denormalized numbers serve two purposes. First, provide way represent numeric value 0, since normalized number must always haveM≥1, hence cannot represent 0. fact ﬂoating-point representation of+0.0 bit pattern zeros: sign bit 0, exponent ﬁeld zeros (indicating denormalized value), fraction ﬁeld zeros, givingM=f=0. Curiously, sign bit 1, ﬁelds zeros, get value −0.0. IEEE ﬂoating-point format, values −0.0 +0.0 considered different ways others. second function denormalized numbers represent numbers close 0.0. provide property known gradual underﬂow possible numeric values spaced evenly near 0.0. Case 3: Special Values ﬁnal category values occurs exponent ﬁeld ones. thefraction ﬁeld zeros, resulting values represent inﬁnity, either +∞ s=0, or−∞ s=1. Inﬁnity represent results overﬂow , multiply two large numbers, divide zero. fractionﬁeld nonzero, resulting value called “ NaN ,” short “Not Number.” values returned result operation result cannot given real number inﬁnity, computing√ −1o r∞−∞ . also useful applications representing uninitialized data. 2.4.3 Example Numbers Figure 2.33 shows set values represented hypothetical 6-bit format k=3 exponent bits n=2 fraction bits. bias 23−1−1= 3. Part ﬁgure shows representable values (other NaN ). two inﬁnities extreme ends. normalized numbers maximummagnitude ±14. denormalized numbers clustered around 0. seen clearly part B ﬁgure, show numbersbetween −1.0 +1.0. two zeros special cases denormalized numbers. Observe representable numbers uniformly distributed—they aredenser nearer origin. Figure 2.34 shows examples hypothetical 8-bit ﬂoating-point format k=4 exponent bits n=3 fraction bits. bias 2 4−1−1=7. The106 Chapter 2 Representing Manipulating Information /H1100210 /H110020.8 /H110020.6 /H110020.4 /H110020.2 /H110010.2/H110010 /H110020 /H110010.4 /H110010.6 /H110010.8 /H110011 0 /H110021/H1100250 /H110015 /H1100110 /H11001/H11009 /H11002/H11009 Denormalized Normalized Infinity Denormalized Normalized Infinity(a) Complete range (b) Values /H110021.0 /H110011.0 Figure 2.33 Representable values 6-bit ﬂoating-point format. k=3 exponent bits n=2fraction bits. bias 3. Exponent Fraction Value Description Bit representation eE 2EfM 2E×MV Decimal Zero 0 0000 000 0−61 640 80 80 5120 0.0 Smallest pos. 0 0000 001 0−61 641 81 81 5121 5120.001953 0 0000 010 0−61 642 82 82 5121 2560.003906 0 0000 011 0−61 643 83 83 5123 5120.005859... Largest denorm. 0 0000 111 0−61 647 87 87 5127 5120.013672 Smallest norm. 0 0001 000 1−61 640 88 88 5121 640.015625 0 0001 001 1−61 641 89 89 5129 5120.017578... 0 0110 110 6−11 26 814 814 167 80.875 0 0110 111 6−11 27 815 815 1615 160.9375 One 0 0111 000 70 10 88 88 81 1.0 0 0111 001 70 11 89 89 89 81.125 0 0111 010 70 12 810 810 85 41.25... 0 1110 110 14 7 1286 814 81792 8224 224.0 Largest norm. 0 1110 111 14 7 1287 815 81920 8240 240.0 Inﬁnity 0 1111 000 —— —— — — ∞ — Figure 2.34 Example nonnegative values 8-bit ﬂoating-point format. k=4exponent bits n=3fraction bits. bias 7.Section 2.4 Floating Point 107 ﬁgure divided three regions representing three classes numbers. different columns show exponent ﬁeld encodes exponent E, fraction ﬁeld encodes signiﬁcand M, together form represented value V=2E×M. Closest 0 denormalized numbers, starting 0 itself. Denormalized numbers format E=1−7=−6, giving weight 2E=1 64. fractions fand signiﬁcands Mrange values 0 ,1 8,...,7 8, giving numbers Vin range 0 to1 64×7 8=7 512. smallest normalized numbers format also E=1−7=−6, fractions also range values 0 ,1 8,...7 8. However, signiﬁcands range 1 +0=1t o1 +7 8=15 8, giving numbers Vin range8 512=1 64 to15 512. Observe smooth transition largest denormalized number7 512 smallest normalized number8 512. smoothness due deﬁnition ofEfor denormalized values. making 1 −Bias rather −Bias , com- pensate fact signiﬁcand denormalized number havean implied leading 1. increase exponent, get successively larger normalized values, passing 1.0 largest normalized number. number exponent E=7, giving weight 2 E=128. fraction equals7 8, giving signiﬁ- candM=15 8. Thus, numeric value V=240. Going beyond overﬂows +∞. One interesting property representation interpret bit representations values Figure 2.34 unsigned integers, occur inascending order, values represent ﬂoating-point numbers. isno accident—the IEEE format designed ﬂoating-point numbers couldbe sorted using integer sorting routine. minor difﬁculty occurs dealing negative numbers, since leading 1, occur descendingorder, overcome without requiring ﬂoating-point operations toperform comparisons (see Problem 2.83). Practice Problem 2.47 Consider 5-bit ﬂoating-point representation based IEEE ﬂoating-pointformat, one sign bit, two exponent bits ( k=2), two fraction bits ( n=2). exponent bias 2 2−1−1=1. table follows enumerates entire nonnegative range 5-bit ﬂoating-point representation. Fill blank table entries using followingdirections: e: value represented considering exponent ﬁeld unsigned integer E: value exponent biasing 2 E: numeric weight exponent f: value fraction108 Chapter 2 Representing Manipulating Information M: value signiﬁcand 2E×M: (unreduced) fractional value number V: reduced fractional value number Decimal: decimal representation number Express values 2E,f,M,2E×M, andVeither integers (when possible) fractions formx y, yis power 2. need ﬁll entries marked “—”. Bits eE 2EfM 2E×MV Decimal 00 00 0 00 00 1 00 01 0 00 01 1 00 10 0 00 10 1 1011 45 45 45 41.25 00 11 0 00 11 1 01 00 0 01 00 1 01 01 0 01 01 1 01 10 0 ——— —— — — 01 10 1 ——— —— — — 01 11 0 ——— —— — — 01 11 1 ——— —— — — Figure 2.35 shows representations numeric values important single- double-precision ﬂoating-point numbers. 8-bit formatshown Figure 2.34, see general properties ﬂoating-pointrepresentation k-bit exponent n-bit fraction: .The value +0.0 always bit representation zeros. .The smallest positive denormalized value bit representation consisting 1 least signiﬁcant bit position otherwise zeros. fraction (and signiﬁcand) value M=f=2−nand exponent value E=− 2k−1+2. numeric value therefore V=2−n−2k−1+2. .The largest denormalized value bit representation consisting exponent ﬁeld zeros fraction ﬁeld ones. fraction(and signiﬁcand) value M=f=1−2 −n(which written 1 −/epsilon1) exponent value E=− 2k−1+2. numeric value therefore V=(1− 2−n)×2−2k−1+2, slightly smaller smallest normalized value.Section 2.4 Floating Point 109 Single precision Double precision Description exp frac Value Decimal Value Decimal Zero 00 ...00 0 ...00 0 0 .00 0 .0 Smallest denorm. 00 ...00 0 ...01 2−23×2−1261.4×10−452−52×2−10224.9×10−324 Largest denorm. 00 ...00 1 ...11 (1−/epsilon1)×2−1261.2×10−38(1−/epsilon1)×2−10222.2×10−308 Smallest norm. 00 ...01 0 ...00 1 ×2−1261.2×10−381×2−10222.2×10−308 One 01 ...11 0 ...00 1 ×201.01 ×201.0 Largest norm. 11 ...10 1 ...11 (2−/epsilon1)×21273.4×1038(2−/epsilon1)×210231.8×10308 Figure 2.35 Examples nonnegative ﬂoating-point numbers. .The smallest positive normalized value bit representation wit ha1i n least signiﬁcant bit exponent ﬁeld otherwise zeros. signiﬁcand value M=1 exponent value E=− 2k−1+2. numeric value therefore V=2−2k−1+2. .The value 1 .0 bit representation signiﬁcant bit exponent ﬁeld equal 1 bits equal 0. signiﬁcand valueisM=1 exponent value E=0. .The largest normalized value bit representation sign bit 0, least signiﬁcant bit exponent equal 0, bits equal 1. Ithas fraction value f=1−2 −n, giving signiﬁcand M=2−2−n(which written 2 −/epsilon1). exponent value E=2k−1−1, giving numeric value V=(2−2−n)×22k−1−1=(1−2−n−1)×22k−1. One useful exercise understanding ﬂoating-point representations con- vert sample integer values ﬂoating-point form. example, saw Figure2.14 12,345 binary representation [11000000111001]. create normal-ized representation shifting 13 positions right binary point, giving 12345 =1.1000000111001 2×213. encode IEEE single-precision format, construct fraction ﬁeld dropping leading 1 adding 10zeros end, giving binary representation [10000001110010000000000]. Toconstruct exponent ﬁeld, add bias 127 13, giving 140, bi-nary representation [10001100]. combine sign bit 0 get theﬂoating-point representation binary [01000110010000001110010000000000].Recall Section 2.1.4 observed following correlation bit-level representations integer value 12345 (0x3039 ) single-precision ﬂoating-point value 12345.0 (0x4640E400 ): 00003039 00000000000000000011000000111001 ************* 4640E400 01000110010000001110010000000000110 Chapter 2 Representing Manipulating Information see region correlation corresponds low-order bits integer, stopping signiﬁcant bit equal 1 (this bitforms implied leading 1), matching high-order bits fraction part ofthe ﬂoating-point representation. Practice Problem 2.48 mentioned Problem 2.6, integer 3,510,593 hexadecimal representa-tion0x00359141 , single-precision, ﬂoating-point number 3510593 .0 hexadecimal representation 0x4A564504 . Derive ﬂoating-point representa- tion explain correlation bits integer ﬂoating-pointrepresentations. Practice Problem 2.49 A. ﬂoating-point format n-bit fraction, give formula smallest positive integer cannot represented exactly (because itwould require n+1-bit fraction exact). Assume exponent ﬁeld sizekis large enough range representable exponents provide limitation problem. B. numeric value integer single-precision format (n=23)? 2.4.4 Rounding Floating-point arithmetic approximate real arithmetic, since repre- sentation limited range precision. Thus, value x, generally want systematic method ﬁnding “closest” matching value x/primethat rep- resented desired ﬂoating-point format. task rounding operation. One key problem deﬁne direction round value ishalfway two possibilities. example, $1.50 want roundit nearest dollar, result $1 $2? alternative approach isto maintain lower upper bound actual number. example, wecould determine representable values x −andx+such value xis guaran- teed lie them: x−≤x≤x+. IEEE ﬂoating-point format deﬁnes four different rounding modes . default method ﬁnds closest match, three used computing upper lower bounds. Figure 2.36 illustrates four rounding modes applied problem rounding monetary amount nearest whole dollar. Round-to-even (alsocalled round-to-nearest) default mode. attempts ﬁnd closest match.Thus, rounds $1.40 $1 $1.60 $2, since closest whole dollarvalues. design decision determine effect rounding valuesthat halfway two possible results. Round-to-even mode adopts theSection 2.4 Floating Point 111 Mode $1.40 $1.60 $1.50 $2.50 $ −1.50 Round-to-even $1 $2 $2 $2 $ −2 Round-toward-zero $1 $1 $1 $2 $ −1 Round-down $1 $1 $1 $2 $ −2 Round-up $2 $2 $2 $3 $ −1 Figure 2.36 Illustration rounding modes dollar rounding. ﬁrst rounds nearest value, three bound result below. convention rounds number either upward downward least signiﬁcant digit result even. Thus, rounds $1.50 $2.50to $2. three modes produce guaranteed bounds actual value. useful numerical applications. Round-toward-zero mode roundspositive numbers downward negative numbers upward, giving value ˆxsuch that|ˆx|≤|x|. Round-down mode rounds positive negative numbers downward, giving value x −such x−≤x. Round-up mode rounds positive negative numbers upward, giving value x+such x≤x+. Round-to-even ﬁrst seems like rather arbitrary goal—why reason prefer even numbers? consistently round values halfwaybetween two representable values upward? problem conventionis one easily imagine scenarios rounding set data valueswould introduce statistical bias computation average thevalues. average set numbers rounded means wouldbe slightly higher average numbers themselves. Conversely, wealways rounded numbers halfway downward, average set ofrounded numbers would slightly lower average numbers them-selves. Rounding toward even numbers avoids statistical bias real-lifesituations. round upward 50% time round downward about50% time. Round-to-even rounding applied even rounding whole number. simply consider whether least signiﬁcant digit evenor odd. example, suppose want round decimal numbers nearesthundredth. would round 1.2349999 1.23 1.2350001 1.24, regardlessof rounding mode, since halfway 1.23 1.24. otherhand, would round 1.2350000 1.2450000 1.24, since 4 even. Similarly, round-to-even rounding applied binary fractional num- bers. consider least signiﬁcant bit value 0 even 1 odd. general,the rounding mode signiﬁcant bit pattern formXX...X.YY ...Y100..., XandYdenote arbitrary bit values rightmost Ybeing position wish round. bit patterns form denote values halfway two possible results. exam-ples, consider problem rounding values nearest quarter (i.e., 2 bits right binary point). would round 10 .00011 2(23 32) 10 .002(2),112 Chapter 2 Representing Manipulating Information 10 .001102(23 16)u pt o1 0 .012(21 4), values halfway be- tween two possible values. would round 10 .11100 2(27 8)u pt o1 1 .002(3) 10.101002(25 8) 10 .102(21 2), since values halfway two possible results, prefer least signiﬁcant bit equal zero. Practice Problem 2.50 Show following binary fractional values would rounded nearesthalf (1 bit right binary point), according round-to-even rule. case, show numeric values, rounding. A. 10 .010 2 B. 10 .011 2 C. 10 .1102 D. 11 .0012 Practice Problem 2.51 saw Problem 2.46 Patriot missile software approximated 0 .1a sx= 0.000110011001100110011002. Suppose instead used IEEE round- to-even mode determine approximation x/primeto 0.1 23 bits right binary point. A. binary representation x/prime? B. approximate decimal value x/prime−0.1? C. far would computed clock 100 hours opera- tion? D. far would program’s prediction position Scud missile been? Practice Problem 2.52 Consider following two 7-bit ﬂoating-point representations based IEEE ﬂoating point format. Neither sign bit—they represent nonnegativenumbers. 1.Format k=3 exponent bits. exponent bias 3. n=4 fraction bits. 2.Format B k=4 exponent bits. exponent bias 7. n=3 fraction bits. Below, given bit patterns Format A, task convert closest value Format B. necessary, apply round-to- even rounding rule. addition, give values numbers given Format ASection 2.4 Floating Point 113 Format B bit patterns. Give whole numbers (e.g., 17) fractions (e.g., 17 /64). Format Format B Bits Value Bits Value 011 0000 1 0111 000 1 101 1110 010 1001 110 1111 000 0001 2.4.5 Floating-Point Operations IEEE standard speciﬁes simple rule determining result arith- metic operation addition multiplication. Viewing ﬂoating-point valuesxandyas real numbers, operation ⊙deﬁned real numbers, computation yield Round (x⊙y), result applying rounding exact result real operation. practice, clever tricks ﬂoating-pointunit designers use avoid performing exact computation, since compu- tation need sufﬁciently precise guarantee correctly rounded result. one arguments special value −0,∞,o r NaN , stan- dard speciﬁes conventions attempt reasonable. example, 1 /−0i deﬁned yield −∞, 1 /+0 deﬁned yield +∞. One strength IEEE standard’s method specifying behavior ﬂoating-point operations independent particular hardware orsoftware realization. Thus, examine abstract mathematical propertieswithout considering actually implemented. saw earlier integer addition, unsigned two’s complement, forms abelian group. Addition real numbers also forms abelian group, must consider effect rounding properties. Let us deﬁnex+ fyto Round (x+y). operation deﬁned values xandy, although may yield inﬁnity even xandyare real numbers due overﬂow. operation commutative, x+fy=y+fxfor values xand y. hand, operation associative. example, single- precision ﬂoating point expression (3.14+1e10)-1e10 evaluates 0.0—the value 3.14 lost due rounding. hand, expression 3.14+(1e10- 1e10) evaluates 3.14 . abelian group, values inverses ﬂoating-point addition, is, x+f−x=0. exceptions inﬁnities (since + ∞−∞= NaN ), NaN ’s, since NaN +fx=NaN x. lack associativity ﬂoating-point addition important group property lacking. important implications scientiﬁc programmersand compiler writers. example, suppose compiler given following codefragment: x=a+b+c ; y=b+c+d ;114 Chapter 2 Representing Manipulating Information compiler might tempted save one ﬂoating-point addition generating following code: t=b+c ; x=a+t ; y=t+d ; However, computation might yield different value xthan would original, since uses different association addition operations. mostapplications, difference would small inconsequential. Unfor-tunately, compilers way knowing trade-offs user willing tomake efﬁciency faithfulness exact behavior original pro-gram. result, tend conservative, avoiding optimizationsthat could even slightest effect functionality. hand, ﬂoating-point addition satisﬁes following monotonicity property: a≥bthenx+a≥x+bfor values a,b, andxother NaN . property real (and integer) addition obeyed unsigned two’s-complement addition. Floating-point multiplication also obeys many properties one normally associates multiplication. Let us deﬁne x* fyto Round (x×y). oper- ation closed multiplication (although possibly yielding inﬁnity NaN ), commutative, 1.0 multiplicative identity. hand,it associative, due possibility overﬂow loss precisiondue rounding. example, single-precision ﬂoating point, expression(1e20*1e20)*1e-20 evaluates +∞, 1e20*(1e20*1e-20) evaluates 1e20 . addition, ﬂoating-point multiplication distribute addition. example, single-precision ﬂoating point, expression 1e20*(1e20- 1e20) evaluates 0.0, 1e20*1e20-1e20*1e20 evaluates NaN. hand, ﬂoating-point multiplication satisﬁes following mono- tonicity properties values a,b, andcother NaN : a≥bandc≥0⇒a* fc≥b*fc a≥bandc≤0⇒a*fc≤b*fc addition, also guaranteed a*fa≥0, long a/negationslash=NaN .A sw e saw earlier, none monotonicity properties hold unsigned two’s-complement multiplication. lack associativity distributivity serious concern scientiﬁc programmers compiler writers. Even seemingly simple task writingcode determine whether two lines intersect 3-dimensional space amajor challenge. 2.4.6 Floating Point C versions C provide two different ﬂoating-point data types: float double . machines support IEEE ﬂoating point, data types corre- spond single- double-precision ﬂoating point. addition, machines useSection 2.4 Floating Point 115 round-to-even rounding mode. Unfortunately, since C standards require machine use IEEE ﬂoating point, standard methods tochange rounding mode get special values −0,+∞,−∞,o rNaN . systems provide combination include (‘ .h’) ﬁles procedure libraries provide access features, details vary one system an-other. example, GNU compiler gccdeﬁnes program constants INFINITY (for+∞) NAN(for NaN ) following sequence occurs program ﬁle: #define _GNU_SOURCE 1 #include <math.h> recent versions C, including ISO C99, include third ﬂoating-point data type, long double . many machines compilers, data type equivalent double data type. Intel-compatible machines, however, gcc implements data type using 80-bit “extended precision” format, providinga much larger range precision standard 64-bit format. Theproperties format investigated Problem 2.85. Practice Problem 2.53 Fill following macro deﬁnitions generate double-precision values +∞, −∞, 0: #define POS_INFINITY #define NEG_INFINITY #define NEG_ZERO cannot use include ﬁles (such math.h ), make use fact largest ﬁnite number represented double precision around 1 .8×10308. casting values int,float , double formats, program changes numeric values bit representations follows (assuming a32-bit int): .From inttofloat , number cannot overﬂow, may rounded. .From intorfloat todouble , exact numeric value preserved be- cause double greater range (i.e., range representable values), well greater precision (i.e., number signiﬁcant bits). .From double tofloat , value overﬂow +∞ or−∞, since range smaller. Otherwise, may rounded, precision smaller. .From float ordouble toint value rounded toward zero. example, 1 .999 converted 1, −1.999 converted −1. Furthermore, value may overﬂow. C standards specify ﬁxed result case. Intel-compatible microprocessors designate the116 Chapter 2 Representing Manipulating Information bit pattern [10 ...00] ( TMin wfor word size w)a sa n integer indeﬁnite value. conversion ﬂoating point integer cannot assign reasonableinteger approximation yields value. Thus, expression (int) +1e10 yields -21483648 , generating negative value positive one. Web Aside DATA:IA32-FP Intel IA32 ﬂoating-point arithmetic next chapter, begin in-depth study Intel IA32 processors, processor found many today’s personal computers. highlight idiosyncrasy machines seriously affect behavior programs operating ﬂoating-point numbers compiled gcc. IA32 processors, like processors, special memory elements called registers holding ﬂoating-point values computed used. unusual feature IA32 ﬂoating-point registers use special 80-bit extended-precision format provide greater range precision normal 32-bit single-precision 64-bit double-precision formats used values held memory. (See Problem 2.85.) single- double-precision numbers converted format loaded memory ﬂoating-point registers. arithmetic always performed extended precision. Numbers converted extended precision single- double-precisionformat stored memory. extension 80 bits register data contraction smaller format memory data undesirable consequences programmers. means storing number register memory retrieving back register cause change, due rounding, underﬂow, overﬂow. storing retrieving always visible C programmer, leading peculiar results. recent versions Intel processors, including IA32 newer 64-bit machines, provide direct hardware support single- double-precision ﬂoating-point operations. peculiarities historic IA32 approach diminish importance new hardware compilers generate code based newer ﬂoating-point instructions. Aside Ariane 5: high cost ﬂoating-point overﬂow Converting large ﬂoating-point numbers integers common source programming errors. error disastrous consequences maiden voyage Ariane 5 rocket, June 4, 1996. 37 seconds liftoff, rocket veered ﬂight path, broke up, exploded. Communication satellites valued $500 million board rocket. later investigation [69, 39] showed computer controlling inertial navigation system sent invalid data computer controlling engine nozzles. Instead sending ﬂight control information, sent diagnostic bit pattern indicating overﬂow occurred conversion 64-bit ﬂoating-point number 16-bit signed integer. value overﬂowed measured horizontal velocity rocket, could 5 times higher achieved earlier Ariane 4 rocket. design Ariane 4 software, carefully analyzed numeric values determined horizontal velocitySection 2.4 Floating Point 117 would never overﬂow 16-bit number. Unfortunately, simply reused part software Ariane 5 without checking assumptions based. © Fourmy/REA/SABA/Corbis Practice Problem 2.54 Assume variables x,f, dare type int,float , double , respectively. values arbitrary, except neither fnordequals +∞,−∞,o r NaN . following C expressions, either argue always true(i.e., evaluate 1) give value variables true (i.e.,evaluates 0). A.x == (int)(double) x B.x == (int)(float) x C.d == (double)(float) D.f == (float)(double) f E.f == -(-f) F.1.0/2 == 1/2.0 G.d*d >= 0.0 H.(f+d)-f == d118 Chapter 2 Representing Manipulating Information 2.5 Summary Computers encode information bits, generally organized sequences bytes. Different encodings used representing integers, real numbers, charac-ter strings. Different models computers use different conventions encodingnumbers ordering bytes within multi-byte data. C language designed accommodate wide range different imple- mentations terms word sizes numeric encodings. current machineshave 32-bit word sizes, although high-end machines increasingly 64-bit words.Most machines use two’s-complement encoding integers IEEE encod-ing ﬂoating point. Understanding encodings bit level, well asunderstanding mathematical characteristics arithmetic operations, im-portant writing programs operate correctly full range numericvalues. casting signed unsigned integers size, C implementations follow convention underlying bit pattern doesnot change. two’s-complement machine, behavior characterized byfunctions T2U wand U2Tw, w-bit value. implicit casting C gives results many programmers anticipate, often leading program bugs. Due ﬁnite lengths encodings, computer arithmetic properties quite different conventional integer real arithmetic. ﬁnite length cause numbers overﬂow, exceed range representation.Floating-point values also underﬂow, close 0 .0 changed zero. ﬁnite integer arithmetic implemented C, well pro- gramming languages, peculiar properties compared true integer arith-metic. example, expression x*x evaluate negative number due overﬂow. Nonetheless, unsigned two’s-complement arithmetic satisfymany properties integer arithmetic, including associativity, com-mutativity, distributivity. allows compilers many optimizations. Forexample, replacing expression 7*x by(x<<3)-x , make use as- sociative, commutative, distributive properties, along relationshipbetween shifting multiplying powers 2. seen several clever ways exploit combinations bit-level opera- tions arithmetic operations. example, saw two’s-complementarithmetic ~x+1 equivalent -x. another example, suppose want bit pattern form [0 ,..., 0,1,..., 1], consisting w−kzeros followed k ones. bit patterns useful masking operations. pattern gen-erated C expression (1<<k)-1 , exploiting property desired bit pattern numeric value 2 k−1. example, expression (1<<8)-1 generate bit pattern 0xFF . Floating-point representations approximate real numbers encoding num- bers form x×2y. common ﬂoating-point representation deﬁned IEEE Standard 754. provides several different precisions, mostcommon single (32 bits) double (64 bits). IEEE ﬂoating point also hasrepresentations special values representing plus minus inﬁnity, well asnot-a-number.Homework Problems 119 Floating-point arithmetic must used carefully, limited range precision, obey common mathematicalproperties associativity. Bibliographic Notes Reference books C [48, 58] discuss properties different data types andoperations. (Of two, Steele Harbison [48] cover newer fea-tures found ISO C99.) C standards specify details pre-cise word sizes numeric encodings. details intentionally omitted tomake possible implement C wide range different machines. Severalbooks written giving advice C programmers [59, 70] warn aboutproblems overﬂow, implicit casting unsigned, pit- falls covered chapter. books also provide helpful advice variable naming, coding styles, code testing. Seacord’s book securityissues C C++ programs [94], combines information C programs,how compiled executed, vulnerabilities may arise. Bookson Java (we recommend one coauthored James Gosling, creator ofthe language [4]) describe data formats arithmetic operations supportedby Java. books logic design [56, 115] section encodings arith- metic operations. books describe different ways implementing arithmeticcircuits. Overton’s book IEEE ﬂoating point [78] provides detailed descrip-tion format well properties perspective numericalapplications programmer. Homework Problems 2.55◆ Compile run sample code uses show_bytes (ﬁleshow-bytes.c )o n different machines access. Determine byte orderings usedby machines. 2.56◆ Try running code show_bytes different sample values. 2.57◆ Write procedures show_short ,show_long , show_double print byte representations C objects types short int ,long int , double , respec- tively. Try several machines. 2.58◆◆ Write procedure is_little_endian return 1 compiled run little-endian machine, return 0 compiled run big-endian machine. program run machine, regardless wordsize.120 Chapter 2 Representing Manipulating Information 2.59◆◆ Writ e C expression yield word consisting least signiﬁcant byte x, remaining bytes y. operands x=0x89ABCDEF andy= 0x76543210 , would give 0x765432EF . 2.60◆◆ Suppose number bytes w-bit word 0 (least signiﬁcant) w/8−1 (most signiﬁcant). Write code following C function, return anunsigned value byte iof argument xhas replaced byte b: unsigned replace_byte (unsigned x, int i, unsigned char b); examples showing function work: replace_byte(0x12345678, 2, 0xAB) --> 0x12AB5678 replace_byte(0x12345678, 0, 0xAB) --> 0x123456AB Bit-level integer coding rules several following problems, artiﬁcially restrict programming constructs use help gain better understanding bit-level,logic, arithmetic operations C. answering problems, codemust follow rules: .Assumptions Integers represented two’s-complement form. Right shifts signed data performed arithmetically. Data type intiswbits long. problems, given speciﬁc value w, otherwise code work long wis multiple 8. use expression sizeof(int)<<3 compute w. .Forbidden Conditionals ( ifor?:), loops, switch statements, function calls, macro invocations. Division, modulus, multiplication. Relative comparison operators ( <,>,<=, >=). Casting, either explicit implicit. .Allowed operations bit-level logic operations. Left right shifts, shift amounts 0 w−1. Addition subtraction. Equality ( ==) inequality ( !=) tests. (Some problems allow these.) Integer constants INT_MIN andINT_MAX . Even rules, try make code readable choosing descriptive variable names using comments describe logic behind solutions. example, following code extracts signiﬁcant byte integer argument x:Homework Problems 121 /* Get significant byte x */ int get_msb(int x) { /* Shift w-8 */int shift_val = (sizeof(int)-1)<<3; /* Arithmetic shift */ int xrigh t=x> > shift_val; /* Zero LSB */ return xright & 0xFF; } 2.61 ◆◆ Write C expressions evaluate 1 following conditions true, andto 0 false. Assume xis type int. A. bit xequals 1. B. bit xequals 0. C. bit least signiﬁcant byte xequals 1. D. bit signiﬁcant byte xequals 0. code follow bit-level integer coding rules (page 120), additional restriction may use equality ( ==) inequality ( !=) tests. 2.62◆◆◆ Write function int_shifts_are_arithmetic() yields 1 run machine uses arithmetic right shifts int’s, 0 otherwise. code work machine word size. Test code several machines. 2.63◆◆◆ Fill code following C functions. Function srl performs logical right shift using arithmetic right shift (given value xsra ), followed oper- ations including right shifts division. Function sraperforms arithmetic right shift using logical right shift (given value xsrl ), followed operations including right shifts division. may use computation8*sizeof(int) determine w, number bits data type int. shift amount kcan range 0 w−1. unsigned srl(unsigned x, int k) { /* Perform shift arithmetically */ unsigned xsra = (int) x >> k; ... }122 Chapter 2 Representing Manipulating Information int sra(int x, int k) { /* Perform shift logically */ int xsrl = (unsigned) x >> k; ... } 2.64◆ Write code implement following function: /* Return 1 odd bit x equals 1; 0 otherwise. Assume w=32. */ int any_odd_one(unsigned x); function follow bit-level integer coding rules (page 120), except may assume data type inthasw=32 bits. 2.65◆◆◆◆ Write code implement following function: /* Return 1 x contains odd number 1s; 0 otherwise. Assume w=32. */ int odd_ones(unsigned x); function follow bit-level integer coding rules (page 120), except may assume data type inthasw=32 bits. code contain total 12 arithmetic, bit-wise, logical operations. 2.66◆◆◆ Write code implement following function: /* * Generate mask indicating leftmost 1 x. Assume w=32.* example 0xFF00 -> 0x8000, 0x6600 --> 0x4000.*I fx=0 , return 0. */ int leftmost_one(unsigned x); function follow bit-level integer coding rules (page 120), except may assume data type inthasw=32 bits. code contain total 15 arithmetic, bit-wise, logical operations. Hint: First transform xinto bit vector form [0 ...011...1]. 2.67◆◆ given task writing procedure int_size_is_32() yields 1 run machine intis 32 bits, yields 0 otherwise. allowed use sizeof operator. ﬁrst attempt:Homework Problems 123 1/* following code run properly machines */ 2int bad_int_size_is_32() { 3 /* Set significant bit (msb) 32-bit machine */ 4 int set_ms b=1< <3 1 ; 5 /* Shift past msb 32-bit word */ 6 int beyond_ms b=1< <3 2 ; 7 8 /* set_msb nonzero word size >= 32 9 beyond_msb zero word size <= 32 */ 10 return set_msb && !beyond_msb; 11 } compiled run 32-bit SUN SPARC, however, procedure returns 0. following compiler message gives us indication problem: warning: left shift count >= width type A. way code fail comply C standard? B. Modify code run properly machine data type intis least 32 bits. C. Modify code run properly machine data type intis least 16 bits. 2.68◆◆ Write code function following prototype: /* * Mask least signficant n bits set 1 * Examples :n=6- - > 0x2F,n=1 7- - > 0x1FFFF * Assume 1 <= n <= w */ int lower_one_mask(int n); function follow bit-level integer coding rules (page 120). careful case n=w. 2.69◆◆◆ Write code function following prototype: /* * rotating left shift. Assume 0 < =n<w * Examples whe n x = 0x12345678 dw=3 2 : * n=4 -> 0x23456781, n=20 -> 0x67812345 */ unsigned rotate_left(unsigned x, int n); function follow bit-level integer coding rules (page 120). careful case n=0.124 Chapter 2 Representing Manipulating Information 2.70◆◆ Write code function following prototype: /* * Return 1 x represented n-bit, 2’s complement* number; 0 otherwise* Assume 1 <= n <= w */ int fits_bits(int x, int n); function follow bit-level integer coding rules (page 120). 2.71◆ started working company implementing set proceduresto operate data structure 4 signed bytes packed 32-bitunsigned . Bytes within word numbered 0 (least signiﬁcant) 3 (most signiﬁcant). assigned task implementing functionfor machine using two’s-complement arithmetic arithmetic right shifts withthe following prototype: /* Declaration data type 4 bytes packed unsigned */ typedef unsigned packed_t; /* Extract byte word. Return signed integer */ int xbyte(packed_t word, int bytenum); is, function extract designated byte sign extend 32-bit int. predecessor (who ﬁred incompetence) wrote following code: /* Failed attempt xbyte */ int xbyte(packed_t word, int bytenum) { return (word >> (bytenum << 3)) & 0xFF; } A. wrong code? B. Give correct implementation function uses left right shifts, along one subtraction. 2.72◆◆ given task writing function copy integer val buffer buf, enough space available buffer. code write: /* Copy integer buffer space available */ /* WARNING: following code buggy */Homework Problems 125 void copy_int(int val, void *buf, int maxbytes) { (maxbytes-sizeof(val) >= 0) memcpy(buf, (void *) &val, sizeof(val)); } code makes use library function memcpy . Although use bit artiﬁcial here, simply want copy int, illustrates approach commonly used copy larger data structures. carefully test code discover always copies value buffer, even maxbytes small. A. Explain conditional test code always succeeds. Hint: sizeof operator returns value type size_t . B. Show rewrite conditional test make work properly. 2.73◆◆ Write code function following prototype: /* Addition saturates TMin TMax */ int saturating_add(int x, int y); Instead overﬂowing way normal two’s-complement addition does, sat- urating addition returns TMax would positive overﬂow, TMin would negative overﬂow. Saturating arithmetic commonly used programs perform digital signal processing. function follow bit-level integer coding rules (page 120). 2.74◆◆ Write function following prototype: /* Determine whether arguments subtracted without overflow */ int tsub_ok(int x, int y); function return 1 computation x−ydoes overﬂow. 2.75◆◆◆ Suppose want compute complete 2 w-bit representation x.y, bothxandyare unsigned, machine data type unsigned iswbits. low-order wbits product computed expression x*y,s require procedure prototype unsigned int unsigned_high_prod(unsigned x, unsigned y); computes high-order wbits x.yfor unsigned variables. access library function prototype int signed_high_prod(int x, int y); computes high-order wbits x.yfor case xandyare two’s- complement form. Write code calling procedure implement functionfor unsigned arguments. Justify correctness solution.126 Chapter 2 Representing Manipulating Information Hint: Look relationship signed product x.yand unsigned product x/prime.y/primein derivation Equation 2.18. 2.76◆◆ Suppose given task generating code multiply integer variable x various different constant factors K. efﬁcient, want use operations +,-, <<. following values K, write C expressions perform multiplication using three operations per expression. A. K = 17: B. K =− 7: C. K = 60: D. K =− 112: 2.77◆◆ Write code function following prototype: /* Divide power two. Assume 0 < = k < w-1 */ int divide_power2(int x, int k); function compute x/2kwith correct rounding, follow bit-level integer coding rules (page 120). 2.78◆◆ Write code function mul3div4 that, integer argument x, computes 3*x/4 , following bit-level integer coding rules (page 120). code shouldreplicate fact computation 3*xcan cause overﬂow. 2.79◆◆◆ Write code function threefourths which, integer argument x, computes value of3 4x, rounded toward zero. overﬂow. function follow bit-level integer coding rules (page 120). 2.80◆◆ Write C expressions generate bit patterns follow, akrepresents krepetitions symbol a. Assume w-bit data type. code may contain references parameters jandk, representing values jandk, parameter representing w. A. 1w−k0k B. 0w−k−j1k0j 2.81◆ running programs machine values type intare 32 bits. represented two’s complement, right shifted arithmetically. Values type unsigned also 32 bits.Homework Problems 127 generate arbitrary values xandy, convert unsigned values follows: /* Create arbitrary values */ int x = random(); int = random(); /* Convert unsigned */ unsigned ux = (unsigned) x; unsigned uy = (unsigned) y; following C expressions, indicate whether expression always yields 1. always yields 1, describe underlying mathematical principles. Otherwise, give example arguments make ityield 0. A.(x<y) == (-x>-y) B.((x+y)<<4) + y-x == 17*y+15*x C.~x+~y+1 == ~(x+y) D.(ux-uy) == -(unsigned)(y-x) E.((x >> 2) << 2) <= x 2.82◆◆ Consider numbers binary representation consisting inﬁnite stringof form 0 . yyyyyy ..., yis ak-bit sequence. example, binary representation 1 3is 0.01010101 ...(y=01), representation of1 5is 0.001100110011 ...(y=0011). A. Let Y=B2U k(y), is, number binary representation y. Give formula terms Yandkfor value represented inﬁnite string. Hint: Consider effect shifting binary point kpositions right. B. numeric value string following values y? (a) 101 (b) 0110 (c) 010011 2.83◆ Fill return value following procedure, tests whether ﬁrstargument less equal second. Assume function f2ureturns unsigned 32-bit number bit representation ﬂoating-pointargument. assume neither argument NaN . two ﬂavors zero, +0 −0, considered equal. int float_le(float x, float y) { unsigned ux = f2u(x); unsigned uy = f2u(y);128 Chapter 2 Representing Manipulating Information /* Get sign bits */ unsigned sx = ux >> 31; unsigned sy = uy >> 31; /* Give expression using ux, uy, sx, sy */ return ; } 2.84◆ Given ﬂoating-point format k-bit exponent n-bit fraction, write formulas exponent E, signiﬁcand M, fraction f, value Vfor quantities follow. addition, describe bit representation. A. number 7 .0 B. largest odd integer represented exactlyC. reciprocal smallest positive normalized value 2.85◆ Intel-compatible processors also support “extended precision” ﬂoating-pointformat 80-bit word divided sign bit, k=15 exponent bits, single integer bit, n=63 fraction bits. integer bit explicit copy implied bit IEEE ﬂoating-point representation. is, equals 1 fornormalized values 0 denormalized values. Fill following table givingthe approximate values “interesting” numbers format: Extended precision Description Value Decimal Smallest positive denormalized Smallest positive normalized Largest normalized 2.86◆ Consider 16-bit ﬂoating-point representation based IEEE ﬂoating-pointformat, one sign bit, seven exponent bits ( k=7), eight fraction bits (n=8). exponent bias 2 7−1−1=63. Fill table follows numbers given, following instructions column: Hex: four hexadecimal digits describing encoded form. M: value signiﬁcand. number formxorx y, xis integer, yis integral power 2. Examples include: 0,67 64, and1 256. E: integer value exponent. V: numeric value represented. Use notation xor x×2z, xandzare integers.Homework Problems 129 example, represent number7 8, would s=0,M=7 4, E=−1. number would therefore exponent ﬁeld 0x3E (decimal value 63 −1=62) signiﬁcand ﬁeld 0xC0 (binary 110000002), giving hex representation 3EC0 . need ﬁll entries marked “—”. Description Hex MEV −0 — Smallest value >2 512 — Largest denormalized −∞ ——— Number hex representation 3BB0 — 2.87◆◆ Consider following two 9-bit ﬂoating-point representations based IEEEﬂoating-point format. 1.Format one sign bit. k=5 exponent bits. exponent bias 15. n=3 fraction bits. 2.Format B one sign bit. k=4 exponent bits. exponent bias 7. n=4 fraction bits. Below, given bit patterns Format A, task convert closest value Format B. rounding necessary, round toward +∞. addition, give values numbers given Format Format B bit patterns. Give whole numbers (e.g., 17) fractions (e.g., 17/64 17 /26). Format Format B Bits Value Bits Value 1 01111 001−9 81 0111 0010−9 8 0 10110 011 1 00111 010 0 00000 111 1 11100 000 0 10111 100 2.88◆ running programs machine values type int 32- bit two’s-complement representation. Values type float use 32-bit IEEE format, values type double use 64-bit IEEE format.130 Chapter 2 Representing Manipulating Information generate arbitrary integer values x,y, z, convert values type double follows: /* Create arbitrary values */ int x = random();int = random();int z = random();/* Convert double */ double dx = (double) x; double dy = (double) y; double dz = (double) z; following C expressions, indicate whether expression always yields 1. always yields 1, describe underlying mathematical principles. Otherwise, give example arguments makeit yield 0. Note cannot use IA32 machine running gcc test answers, since would use 80-bit extended-precision representation bothfloat anddouble . A.(float) x == (float) dx B.dx - dy == (double) (x-y) C.( x+d )+d z= =d x+( y+d z ) D.( x*d )*d z= =d x*( y*d z ) E.d x/d x= =d z/d z 2.89◆ assigned task writin g C function compute ﬂoating- point representation 2x. decide best way directly construct IEEE single-precision representation result. xis small, routine return 0 .0. xis large, return +∞. Fill blank portions code follows compute correct result. Assume thefunction u2freturns ﬂoating-point value identical bit representation unsigned argument. float fpwr2(int x) { /* Result exponent fraction */ unsigned exp, frac; unsigned u; (x < ){ /* small. Return 0.0 */ exp = ; frac = ; } else (x < ){Homework Problems 131 /* Denormalized result */ exp = ; frac = ; } else (x < ){ /* Normalized result. */ exp = ; frac = ; } else { /* big. Return +oo */ exp = ; frac = ; } /* Pack exp frac 32 bits */ u = exp << 23 | frac; /* Return float */ return u2f(u); } 2.90◆ Around 250 B.C., Greek mathematician Archimedes proved that223 71<π<22 7. access computer standard library <math.h> , would able determine single-precision ﬂoating-point approximation ofπhas hexadecimal representation 0x40490FDB . course, approximations, since πis rational. A. fractional binary number denoted ﬂoating-point value? B. fractional binary representation 22 7?Hint: See Problem 2.82. C. bit position (relative binary point) two approxima- tions πdiverge? Bit-level ﬂoating-point coding rules following problems, write code implement ﬂoating-point func- tions, operating directly bit-level representations ﬂoating-point numbers. code exactly replicate conventions IEEE ﬂoating-point oper-ations, including using round-to-even mode rounding required. Toward end, deﬁne data type float_bits equivalent un- signed : /* Access bit-level representation floating-point number */ typedef unsigned float_bits; Rather using data type float code, use float_bits . may use intandunsigned data types, including unsigned integer constants operations. may use unions, structs, arrays. Most132 Chapter 2 Representing Manipulating Information signiﬁcantly, may use ﬂoating-point data types, operations, con- stants. Instead, code perform bit manipulations implementthe speciﬁed ﬂoating-point operations. following function illustrates use coding rules. argument f, returns ±0i ffis denormalized (preserving sign f) returns f otherwise. /* f denorm, return 0. Otherwise, return f */ float_bits float_denorm_zero(float_bits f) { /* Decompose bit representation parts */unsigned sign = f>>31;unsigned exp = f>>23 & 0xFF;unsigned frac = f & 0x7FFFFF;if (exp == 0) { /* Denormalized. Set fraction 0 */frac = 0; }/* Reassemble bits */return (sign << 31) | (exp << 23) | frac; } 2.91 ◆◆ Following bit-level ﬂoating-point coding rules, implement function withthe following prototype: /* Compute -f. f NaN, return f. */ float_bits float_negate(float_bits f); ﬂoating-point number f, function computes −f.I ffisNaN , func- tion simply return f. Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations. 2.92◆◆ Following bit-level ﬂoating-point coding rules, implement function withthe following prototype: /* Compute |f|. f NaN, return f. */ float_bits float_absval(float_bits f); ﬂoating-point number f, function computes |f|.I ffisNaN , function simply return f. Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations.Homework Problems 133 2.93◆◆◆ Following bit-level ﬂoating-point coding rules, implement function withthe following prototype: /* Compute 2*f. f NaN, return f. */ float_bits float_twice(float_bits f); ﬂoating-point number f, function computes 2 .0.f.I ffisNaN , function simply return f. Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations. 2.94◆◆◆ Following bit-level ﬂoating-point coding rules, implement function withthe following prototype: /* Compute 0.5*f. f NaN, return f. */ float_bits float_half(float_bits f); ﬂoating-point number f, function computes 0 .5.f.I ffisNaN , function simply return f. Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations. 2.95◆◆◆◆ Following bit-level ﬂoating-point coding rules, implement function following prototype: /* * Compute (int) f. * conversion causes overflow f NaN, return 0x80000000 */ int float_f2i(float_bits f); ﬂoating-point number f, function computes (int) f. function round toward zero. fcannot represented integer (e.g., range, NaN ), function return 0x80000000 . Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations. 2.96◆◆◆◆ Following bit-level ﬂoating-point coding rules, implement function withthe following prototype: /* Compute (float) */ float_bits float_i2f(int i);134 Chapter 2 Representing Manipulating Information argument i, function computes bit-level representation (float) . Test function evaluating 232values argument fand com- paring result would obtained using machine’s ﬂoating-pointoperations. Solutions Practice Problems Solution Problem 2.1 (page 35) Understanding relation hexadecimal binary formats im-portant start looking machine-level programs. method doingthese conversions text, takes little practice become familiar. A.0x39A7F8 binary: Hexadecimal 39A7F8 Binary 0011 1001 1010 0111 1111 1000 B. Binary 1100100101111011 hexadecimal: Binary 1100 1001 0111 1011 Hexadecimal C97B C.0xD5E4C binary: Hexadecimal D5E4C Binary 1101 0101 1110 0100 1100 D. Binary 1001101110011110110101 hexadecimal: Binary 10 0110 1110 0111 1011 0101 Hexadecimal 26E7B5 Solution Problem 2.2 (page 35) problem gives chance think powers 2 hexadecimal representations. n 2n(Decimal) 2n(Hexadecimal) 9 512 0x200 19 524,288 0x80000 14 16,384 0x4000 16 65,536 0x10000 17 131,072 0x20000 53 2 0x20 7 128 0x80Solutions Practice Problems 135 Solution Problem 2.3 (page 36) problem gives chance try conversions hexadecimal decimal representations smaller numbers. larger ones, becomesmuch convenient reliable use calculator conversion program. Decimal Binary Hexadecimal 0 0000 0000 0x00 167=10.16+7 1010 0111 0xA7 62=3.16+14 0011 1110 0x3E 188=11.16+12 1011 1100 0xBC 3.16+7=55 0011 0111 0x37 8.16+8=136 1000 1000 0x88 15.16+3=243 1111 0011 0xF3 5.16+2=82 0101 0010 0x52 10.16+12=172 1010 1100 0xAC 14.16+7=231 1110 0111 0xE7 Solution Problem 2.4 (page 37) begin debugging machine-level programs, ﬁnd many cases simple hexadecimal arithmetic would useful. alwaysconvert numbers decimal, perform arithmetic, convert back, butbeing able work directly hexadecimal efﬁcient informative. A.0x503c +0x8=0x5044 . Adding 8to hex cgives 4with carry 1. B.0x503c −0x40=0x4ffc . Subtracting 4from 3in second digit position requires borrow third. Since digit 0, must also borrow fourth position. C.0x503c +64=0x507c . Decimal 64 (2 6) equals hexadecimal 0x40 . D.0x50ea −0x503c =0xae . subtract hex c(decimal 12) hex a(decimal 10), borrow 16 second digit, giving hex e(decimal 14). second digit, subtract 3from hex d(decimal 13), giving hex (decimal 10). Solution Problem 2.5 (page 45) problem tests understanding byte representation data thetwo different byte orderings. Little endian: 21 Big endian: 87 Little endian: 21 43 Big endian: 87 65 Little endian: 21 43 65 Big endian: 87 65 43 Recall show_bytes enumerates series bytes starting one lowest address working toward one highest address. little-endian machine, list bytes least signiﬁcant most. big-endian machine, list bytes signiﬁcant byte least.136 Chapter 2 Representing Manipulating Information Solution Problem 2.6 (page 46) problem another chance practice hexadecimal binary conversion. also gets thinking integer ﬂoating-point representations. willexplore representations detail later chapter. A. Using notation example text, write two strings follows: 00359141 00000000001101011001000101000001 ********************* 4A564504 01001010010101100100010100000100 B. second word shifted two positions right relative ﬁrst, ﬁnd sequence 21 matching bits. C. ﬁnd bits integer embedded ﬂoating-point number, except signiﬁcant bit value 1. case examplein text well. addition, ﬂoating-point number nonzerohigh-order bits match integer. Solution Problem 2.7 (page 46) prints 61 62 63 64 65 66 . Recall also library routine strlen count terminating null character, show_bytes printed character ‘ f’. Solution Problem 2.8 (page 49) problem drill help become familiar Boolean operations. Operation Result [01101001] b [01010101] ~a [10010110] ~b [10101010] a&b [01000001] a|b [01111101] a^b [00111100] Solution Problem 2.9 (page 50) problem illustrates Boolean algebra used describe reason real-world systems. see color algebra identical theBoolean algebra bit vectors length 3. A. Colors complemented complementing values R,G, B. this, see White complement Black, Yellow thecomplement Blue, Magenta complement Green, Cyan complement Red.Solutions Practice Problems 137 B. perform Boolean operations based bit-vector representation colors. get following: Blue (001) | Green (010) = Cyan (011) Yellow (110) & Cyan (011) = Green (010) Red (100) ^ Magenta (101) = Blue (001) Solution Problem 2.10 (page 51) procedure relies fact Exclusive-Or commutative associa- tive, a^a=0 a. Step *x *y Initially ab Step 1 aa ^b Step 2 a^(a^b)=(a^a)^b=ba ^b Step 3 bb ^(a^b)=(b^b)^a=a See Problem 2.11 case function fail. Solution Problem 2.11 (page 52) problem illustrates subtle interesting feature inplace swap rou- tine. A. first andlast value k, attempting swap middle element itself. B. case, arguments xandytoinplace_swap point location. compute * x^* , get 0. store 0 middle element array, subsequent steps keep setting element to0. see reasoning Problem 2.10 implicitly assumed x andydenote different locations. C. Simply replace test line 4 reverse_array first < last , since need swap middle element itself. Solution Problem 2.12 (page 53) expressions: A.x & 0xFF B.x ^ ~0xFF C.x | 0xFF expressions typical kind commonly found performing low-level bit operations. expression ~0xFF creates mask 8 least-signiﬁcant bits equal 0 rest equal 1. Observe mask generatedregardless word size. contrast, expression 0xFFFFFF00 would work 32-bit machine.138 Chapter 2 Representing Manipulating Information Solution Problem 2.13 (page 53) problems help think relation Boolean operations typical ways programmers apply masking operations. code: /* Declarations functions implementing operations bis bic */ int bis(int x, int m); int bic(int x, int m); /* Compute x|y using calls functions bis bic */ int bool_or(int x, int y) { int result = bis(x,y);return result; } /* Compute x^y using calls functions bis bic */ int bool_xor(int x, int y) { int result = bis(bic(x,y), bic(y,x));return result; } Thebisoperation equivalent Boolean Or—a bit set zif either bit set xor set m. hand, bic(x, m) equivalent x&~m ; want result equal 1 corresponding bit xis 1 mis 0. Given that, implement |with single call bis. implement ^,w e take advantage property x^y=(x&~y)|(~x&y). Solution Problem 2.14 (page 54) problem highlights relation bit-level Boolean operations logic operations C. common programming error use bit-level operationwhen logic one intended, vice versa. Expression Value Expression Value x & 0x20 x && 0x01 x | 0x7F x || 0x01 ~x | ~y 0xDF !x || !y 0x00 x & !y 0x00 x && ~y 0x01 Solution Problem 2.15 (page 54) expression ! ( x^y ) . is, x^ywill zero every bit xmatches corresponding bit y. exploit ability !to determine whether word contains nonzero bit. real reason use expression rather simply writing x= = y, demonstrates nuances bit-level logical operations.Solutions Practice Problems 139 Solution Problem 2.16 (page 56) problem drill help understand different shift operations. (Logical) (Arithmetic) x x << 3 x >> 2 x >> 2 Hex Binary Binary Hex Binary Hex Binary Hex 0xC3 [11000011] [00011000] 0x18 [00110000] 0x30 [11110000] 0xF0 0x75 [01110101] [10101000] 0xA8 [00011101] 0x1D [00011101] 0x1D 0x87 [10000111] [00111000] 0x38 [00100001] 0x21 [11100001] 0xE1 0x66 [01100110] [00110000] 0x30 [00011001] 0x19 [00011001] 0x19 Solution Problem 2.17 (page 61) general, working examples small word sizes good way understand computer arithmetic. unsigned values correspond Figure 2.2. two’s- complement values, hex digits 0through 7have signiﬁcant bit 0, yielding nonnegative values, hex digits 8through Fhave signiﬁcant bit 1, yielding negative value. /vectorx Hexadecimal Binary B2U 4(/vectorx) B2T 4(/vectorx) 0xE [1110] 23+22+21=14 −23+22+21=−2 0x0 [0000] 0 0 0x5 [0101] 22+20=522+20=5 0x8 [1000] 23=8 −23=−8 0xD [1101] 23+22+20=13 −23+22+20=−3 0xF [1111] 23+22+21+20=15 −23+22+21+20=−1 Solution Problem 2.18 (page 64) 32-bit machine, value consisting eight hexadecimal digits beginning one digits 8through frepresents negative number. quite com- mon see numbers beginning string f’s, since leading bits negative number ones. must look carefully, though. example, thenumber 0x8048337 seven digits. Filling leading zero gives 0x08048337 , positive number. 8048337: 81 ec b8 01 00 00 sub $0x1b8,%esp A. 440 804833d: 8b 55 08 mov 0x8(%ebp),%edx 8048340: 83 c2 14 add $0x14,%edx B. 20 8048343: 8b 85 58 fe ff ff mov 0xfffffe58(%ebp),%eax C. -424 8048349: 03 02 add (%edx),%eax 804834b: 89 85 74 fe ff ff mov %eax,0xfffffe74(%ebp) D. -396 8048351: 8b 55 08 mov 0x8(%ebp),%edx8048354: 83 c2 44 add $0x44,%edx E. 68 8048357: 8b 85 c8 fe ff ff mov 0xfffffec8(%ebp),%eax F. -312140 Chapter 2 Representing Manipulating Information 804835d: 89 02 mov %eax,(%edx) 804835f: 8b 45 10 mov 0x10(%ebp),%eax G. 16 8048362: 03 45 0c add 0xc(%ebp),%eax H. 12 8048365: 89 85 ec fe ff ff mov %eax,0xfffffeec(%ebp) I. -276 804836b: 8b 45 08 mov 0x8(%ebp),%eax 804836e: 83 c0 20 add $0x20,%eax J. 32 8048371: 8b 00 mov (%eax),%eax Solution Problem 2.19 (page 67) functions T2U U2T peculiar mathematical perspective. important understand behave. solve problem reordering rows solution Problem 2.17 according two’s-complement value listing unsigned value asthe result function application. show hexadecimal values makethis process concrete. /vectorx(hex) x T2U 4(x) 0x8 −88 0xD −31 3 0xE −21 4 0xF −11 5 0x0 00 0x5 55 Solution Problem 2.20 (page 68) exercise tests understanding Equation 2.6. ﬁrst four entries, values xare negative T2U4(x)=x+24. remaining two entries, values xare nonnegative T2U4(x)=x. Solution Problem 2.21 (page 70) problem reinforces understanding relation two’s- complement unsigned representations, effects C promotionrules. Recall TMin 32is−2,147,483,648, cast unsigned be- comes 2,147,483,648. addition, either operand unsigned, otheroperand cast unsigned comparing. Expression Type Evaluation -2147483647-1 == 2147483648U unsigned 1 -2147483647-1 < 2147483647 signed 1 -2147483647-1U < 2147483647 unsigned 0 -2147483647-1 < -2147483647 signed 1 -2147483647-1U < -2147483647 unsigned 1Solutions Practice Problems 141 Solution Problem 2.22 (page 74) exercise provides concrete demonstration sign extension preserves numeric value two’s-complement representation. A. [1011]: −23+21+20=− 8+2+1=− 5 B. [11011]: −24+23+21+20=− 16+8+2+1=− 5 C. [111011]: −25+24+23+21+20=− 32+16+8+2+1=− 5 Solution Problem 2.23 (page 74) expressions functions common program “idioms” extracting values word multiple bit ﬁelds packed. exploitthe zero-ﬁlling sign-extending properties different shift operations.Note carefully ordering cast shift operations. fun1 , shifts performed unsigned variable word , hence logical. fun2 , shifts performed casting word toint, hence arithmetic. A. w fun1(w) fun2(w) 0x00000076 0x00000076 0x00000076 0x87654321 0x00000021 0x00000021 0x000000C9 0x000000C9 0xFFFFFFC90xEDCBA987 0x00000087 0xFFFFFF87 B. Function fun1 extracts value low-order 8 bits argument, giving integer ranging 0 255. Function fun2 extracts value low-order 8 bits argument, also performs sign extension.The result number −128 127. Solution Problem 2.24 (page 76) effect truncation fairly intuitive unsigned numbers, two’s- complement numbers. exercise lets explore properties using smallword sizes. Hex Unsigned Two’s complement Original Truncated Original Truncated Original Truncated 00 00 0 0 22 22 2 2 91 91 −71 B3 11 3 −53 F7 15 7 −1 −1 Equation 2.9 states, effect truncation unsigned values simply ﬁnd residue, modulo 8. effect truncation signed valuesis bit complex. According Equation 2.10, ﬁrst compute modulo 8residue argument. give values 0 7 arguments 0 through7, also arguments −8 −1. apply function U2T 3to residues, giving two repetitions sequences 0 3 −4 −1.142 Chapter 2 Representing Manipulating Information Solution Problem 2.25 (page 77) problem designed demonstrate easily bugs arise due implicit casting signed unsigned. seems quite natural pass parameterlength unsigned, since one would never want use negative length. stopping criterion <= length-1 also seems quite natural. combining two yields unexpected outcome! Since parameter length unsigned, computation 0 −1is performed using unsigned arithmetic, equivalent modular addition. result thenUMax .T h e ≤comparison also performed using unsigned comparison, since number less equal UMax , comparison always holds! Thus, code attempts access invalid elements array a. code ﬁxed either declaring length int, changing test forloop < length . Solution Problem 2.26 (page 77) example demonstrates subtle feature unsigned arithmetic, also property sometimes perform unsigned arithmetic without realizing it. Thiscan lead tricky bugs. A.For cases function produce incorrect result? function incorrectly return 1 sis shorter t. B.Explain incorrect result comes about. Since strlen deﬁned yield unsigned result, difference comparison com-puted using unsigned arithmetic. sis shorter t, difference strlen(s) - strlen(t) negative, instead becomes large, unsigned number, greater 0. C.Show ﬁx code work reliably. Replace test following: return strlen(s) > strlen(t); Solution Problem 2.27 (page 81) function direct implementation rules given determine whether unsigned addition overﬂows. /* Determine whether arguments added without overflow */ int uadd_ok(unsigned x, unsigned y) { unsigned sum = x+y; return sum >= x; } Solution Problem 2.28 (page 82) problem simple demonstration arithmetic modulo 16. easiest way solve convert hex pattern unsigned decimal value. nonzerovalues x, must (- u 4x)+x=16. convert complemented value back hex.Solutions Practice Problems 143 x -u 4x Hex Decimal Decimal Hex 0 00 0 5 51 1 B 8 88 8 13 3 3 F 15 1 1 Solution Problem 2.29 (page 86) problem exercise make sure understand two’s-complement addition. xy x +yx +t 5y Case −12 −15 −27 5 1 [10100] [10001] [100101] [00101] −8 −8 −16 −16 2 [11000] [11000] [110000] [10000] −98 −1 −12 [10111] [01000] [111111] [11111] 25 77 3 [00010] [00101] [000111] [00111] 12 4 16 −16 4 [01100] [00100] [010000] [10000] Solution Problem 2.30 (page 86) function direct implementation rules given determine whether two’s-complement addition overﬂows. /* Determine whether arguments added without overflow */ int tadd_ok(int x, int y) { int sum = x+y;int neg_ove r=x< 0& &y< 0& &s u m> =0 ; int pos_ove r=x> =0& &y> =0& &s u m< 0 ; return !neg_over && !pos_over; } Solution Problem 2.31 (page 86) coworker could learned, studying Section 2.3.2, two’s- complement addition forms abelian group, expression (x+y)-x evaluate yregardless whether addition overﬂows, (x+y)-y always evaluate x. Solution Problem 2.32 (page 87) function give correct values, except yisTMin . case, -yalso equal TMin , function tadd_ok consider be144 Chapter 2 Representing Manipulating Information negative overﬂow time xis negative. fact, x-ydoes overﬂow cases. One lesson learned exercise TMin included one cases test procedure function. Solution Problem 2.33 (page 87) problem helps understand two’s-complement negation using smallword size. Forw=4, TMin 4=−8. So−8 additive inverse, values negated integer negation. x -t 4x Hex Decimal Decimal Hex 0 00 0 5 5 −5 B 8 −8 −8 8 −33 3 F −11 1 bit patterns unsigned negation. Solution Problem 2.34 (page 90) problem exercise make sure understand two’s-complement multiplication. Mode xyx .y Truncated x.y Unsigned 4 [100] 5 [101] 20 [010100] 4 [100] Two’s comp. −4 [100] −3 [101] 12 [001100] −4 [100] Unsigned 2 [010] 7 [111] 14 [001110] 6 [110] Two’s comp. 2 [010] −1 [111] −2 [111110] −2 [110] Unsigned 6 [110] 6 [110] 36 [100100] 4 [100] Two’s comp. −2 [110] −2 [110] 4 [000100] −4 [100] Solution Problem 2.35 (page 90) It’s realistic test function possible values xandy. Even could run 10 billion tests per second, would require 58 years test allcombinations data type intis 32 bits. hand, feasible test code writing function data type short orchar testing exhaustively. Here’s principled approach, following proposed set arguments: 1.We know x.ycan written 2 w-bit two’s-complement number. Let udenote unsigned number represented lower wbits, vdenote two’s-complement number represented upper wbits. Then, based Equation 2.3, see x.y=v2 w+u.Solutions Practice Problems 145 also know u=T2U w(p), since unsigned two’s- complement numbers arising bit pattern, Equa-tion 2.5, write u=p+p w−12w, pw−1is signiﬁcant bit ofp. Letting t=v+pw−1, x.y=p+t2w. t=0, x.y=p; multiplication overﬂow. t/negationslash=0, x.y/negationslash=p; multiplication overﬂow. 2.By deﬁnition integer division, dividing pby nonzero xgives quotient qand remainder rsuch p=x.q+r, |r|<|x|. (We use absolute values here, signs xandrmay differ. example, dividing −7 2 gives quotient −3 remainder −1.) 3.Suppose q=y. x.y=x.y+r+t2w. this, see thatr+t2w=0. |r|<|x|≤2w, identity hold t=0, case r=0. Suppose r=t=0. x.y=x.q, implying y=q. xequals 0, multiplication overﬂow, see code provides reliable way test whether two’s-complement multiplication causes overﬂow. Solution Problem 2.36 (page 91) 64 bits, perform multiplication without overﬂowing. test whether casting product 32 bits changes value: 1/* Determine whether arguments multiplied without overflow */ 2int tmult_ok(int x, int y) { 3 /* Compute product without overflow */ 4 long long pll = (long long) x*y; 5 /* See casting int preserves value */ 6 return pll == (int) pll; 7} Note casting right-hand side line 4 critical. instead wrote line long long pll = x*y; product would computed 32-bit value (possibly overﬂowing) thensign extended 64 bits. Solution Problem 2.37 (page 92) A. change help all. Even though computation asize accurate, call malloc cause value converted 32-bit unsigned number, overﬂow conditions occur. B. malloc 32-bit unsigned number argument, cannot possibly allocate block 232bytes, point attempting allocate copy much memory. Instead, function146 Chapter 2 Representing Manipulating Information abort return NULL , illustrated following replacement original call malloc (line 10): long long unsigned required_size = ele_cnt * (long long unsigned) ele_size; size_t request_size = (size_t) required_size;if (required_size != request_size) /* Overflow must occurred. Abort operation */return NULL; void *result = malloc(request_size);if (result == NULL) /* malloc failed */ return NULL; Solution Problem 2.38 (page 93) Chapter 3, see many examples lea instruction action. instruction provided support pointer arithmetic, C compiler oftenuses way perform multiplication small constants. value k, compute two multiples: 2 k(when bis 0) 2k+1 (when bisa). Thus, compute multiples 1, 2, 3, 4, 5, 8, 9. Solution Problem 2.39 (page 94) expression simply becomes -(x<< m). see this, let word size wso n=w−1. Form B states compute (x<<w) - (x<< m), shifting xto left wwill yield value 0. Solution Problem 2.40 (page 94) problem requires try optimizations already described also supply bit ingenuity. K Shifts Add/Subs Expression 62 1 (x<<2) + (x<<1) 31 1 1 (x<<5) - x −62 1 (x<<1) - (x<<3) 55 2 2 (x<<6) - (x<<3) - x Observe fourth case uses modiﬁed version form B. view bit pattern [110111] run 6 ones zero middle, apply rule form B, subtract term corresponding themiddle zero bit. Solution Problem 2.41 (page 94) Assuming addition subtraction performance, rule isto choose form n=m, either form n=m+1, form B n>m +1.Solutions Practice Problems 147 justiﬁcation rule follows. Assume ﬁrst m> 1. n=m, form requires single shift, form B requires two shifts subtraction. n=m+1, forms require two shifts either addition subtraction. n>m +1, form B requires two shifts one subtraction, form requires n−m+1>2 shifts n−m> 1 additions. case m=1, get one fewer shift forms B, rules apply choosing two. Solution Problem 2.42 (page 97) challenge compute bias without testing conditionaloperations. use trick expression x> >3 1 generates word ones xis negative, zeros otherwise. masking appropriate bits, get desired bias value. int div16(int x) { /* Compute bias either 0 (x >= 0) 15 (x < 0) */ int bias = (x >> 31) & 0xF;return (x + bias) >> 4; } Solution Problem 2.43 (page 98) found people difﬁculty exercise working di- rectly assembly code. becomes clear put form shown inoptarith . see Mis 31; x*Mis computed (x<<5)-x . see Nis 8; bias value 7 added yis negative, right shift 3. Solution Problem 2.44 (page 99) “C puzzle” problems provide clear demonstration programmers mustunderstand properties computer arithmetic: A.( x>0 )| |( x - 1<0 ) False . Let xbe−2,147,483,648 ( TMin 32). x-1 equal 2147483647 ( TMax32). B.(x & 7) != 7 || (x<<29 < 0) True .I f( x&7 )! =7 evaluates 0, must bit x2equal 1. shifted left 29, become sign bit. C.( x*x )> =0 False . xis 65,535 ( 0xFFFF ),x*xis−131,071 ( 0xFFFE0001 ). D.x<0| |- x< =0 True .I fxis nonnegative, -xis nonpositive. E.x>0| |- x> =0 False . Letxbe−2,147,483,648 ( TMin 32). xand-xare negative.148 Chapter 2 Representing Manipulating Information F.x+y == uy+ux True . Two’s-complement unsigned addition bit-level be- havior, commutative. G.x*~y + uy*ux == -x True .~yequals -y-1 .uy*ux equals x*y. Thus, left hand side equivalent tox*-y-x+x*y . Solution Problem 2.45 (page 102) Understanding fractional binary representations important step under- standing ﬂoating-point encodings. exercise lets try simple ex-amples. Fractional value Binary representation Decimal representation 1 80.001 0.125 3 40.11 0.75 25 161.1001 1.5625 43 1610.1011 2.6875 9 81.001 1.125 47 8101.111 5.875 51 1611.0011 3.1875 One simple way think fractional binary representations repre- sent number fraction formx 2k. write binary using binary representation x, binary point inserted kpositions right. example, for25 16, 25 10=11001 2. put binary point four positions right get 1 .10012. Solution Problem 2.46 (page 102) cases, limited precision ﬂoating-point numbers major problem, relative error computation still fairly low. example, however, system sensitive absolute error. A. see 0 .1−xhas binary representation 0.000000000000000000000001100[1100] ...2 B. Comparing binary representation of1 10, see simply 2−20×1 10, around 9 .54×10−8. C. 9.54×10−8×100×60×60×10≈0.343 seconds. D. 0.343×2000≈687 meters. Solution Problem 2.47 (page 107) Working ﬂoating-point representations small word sizes helps clarify IEEE ﬂoating point works. Note especially transition betweendenormalized normalized values.Solutions Practice Problems 149 Bits eE 2EfM 2E×MV Decimal 00 00 0 0010 40 40 40 0.0 00 00 1 0011 41 41 41 40.25 00 01 0 0012 42 42 41 20.5 00 01 1 0013 43 43 43 40.75 00 10 0 1010 44 44 41 1.0 00 10 1 1011 45 45 45 41.25 00 11 0 1012 46 46 43 21.5 00 11 1 1013 47 47 47 41.75 01 00 0 2120 44 48 42 2.0 01 00 1 2121 45 410 45 22.5 01 01 0 2122 46 412 43 3.0 01 01 1 2123 47 414 47 23.5 01 10 0 ——— —— — ∞ — 01 10 1 ——— —— — NaN — 01 11 0 ——— —— — NaN — 01 11 1 ——— —— — NaN — Solution Problem 2.48 (page 110) Hexadecimal value 0x359141 equivalent binary [1101011001000101000001]. Shifting right 21 places gives 1 .1010110010001010000012×221. form fraction ﬁeld dropping leading 1 adding two 0s, giving [10101100100010100000100]. exponent formed adding bias 127 21,giving 148 (binary [10010100]). combine sign ﬁeld 0 give abinary representation [01001010010101100100010100000100] . see matching bits two representations correspond low-order bits integer, signiﬁcant bit equal 1 matching thehigh-order 21 bits fraction: 00359141 00000000001101011001000101000001 ********************* 4A564504 01001010010101100100010100000100 Solution Problem 2.49 (page 110) exercise helps think numbers cannot represented exactly ﬂoating point.150 Chapter 2 Representing Manipulating Information A. number binary representation 1, followed n0s, followed 1, giving value 2n+1+1. B. n=23, value 224+1=16,777,217. Solution Problem 2.50 (page 112) Performing rounding hand helps reinforce idea round-to-even binary numbers. Original Rounded 10.010 2 21 410.02 10.011 2 23 810.121 2 10.110 2 23 411.03 11.001 2 31 811.03 Solution Problem 2.51 (page 112) A. Looking nonterminating sequence 1 /10, see 2 bits right rounding position 1, better ap-proximation 1 /10 would obtained incrementing xto get x /prime= 0.00011001100110011001101 2, larger 0 .1. B. see x/prime−0.1 binary representation: 0.0000000000000000000000000[1100] . Comparing binary representation of1 10, see 2−22×1 10, around 2 .38×10−8. C. 2.38×10−8×100×60×60×10≈0.086 seconds, factor 4 less error Patriot system. D. 0.343×2000≈171 meters. Solution Problem 2.52 (page 112) problem tests lot concepts ﬂoating-point representations, including encoding normalized denormalized values, well rounding. Format Format B Bits Value Bits Value Comments 011 0000 1 0111 000 1 101 111015 21001 11115 2 010 100125 320110 1003 4Round 110 111131 21011 000 16 Round 000 00011 640001 0001 64Denorm →norm Solution Problem 2.53 (page 115) general, better use library macro rather inventing code. code seems work variety machines, however.Solutions Practice Problems 151 assume value 1e400 overﬂows inﬁnity. #define POS_INFINITY 1e400 #define NEG_INFINITY (-POS_INFINITY) #define NEG_ZERO (-1.0/POS_INFINITY) Solution Problem 2.54 (page 117) Exercises one help develop ability reason ﬂoating- point operations programmer’s perspective. Make sure understand answers. A.x == (int)(double) x Yes, since double greater precision range int. B.x == (int)(float) x No. example, xisTMax . C.d == (double)(float) No. example, dis1e40 , get +∞ right. D.f == (float)(double) f Yes, since double greater precision range float . E.f == -(-f) Yes, since ﬂoating-point number negated simply inverting sign bit. F.1.0/2 == 1/2.0 Yes, numerators denominators converted ﬂoating-point representations division performed. G.d*d >= 0.0 Yes, although may overﬂow +∞. H.(f+d)-f == No, example fis1.0e20 anddis 1.0, expression f+d rounded 1.0e20 , expression left-hand side evaluate 0.0, right-hand side 1 .0.This page intentionally left blank CHAPTER3 Machine-Level Representation Programs 3.1 Historical Perspective 156 3.2 Program Encodings 159 3.3 Data Formats 167 3.4 Accessing Information 168 3.5 Arithmetic Logical Operations 177 3.6 Control 185 3.7 Procedures 219 3.8 Array Allocation Access 232 3.9 Heterogeneous Data Structures 241 3.10 Putting Together: Understanding Pointers 252 3.11 Life Real World: Using gdb Debugger 254 3.12 Out-of-Bounds Memory References Buffer Overﬂow 256 3.13 x86-64: Extending IA32 64 Bits 267 3.14 Machine-Level Representations Floating-Point Programs 292 3.15 Summary 293 Bibliographic Notes 294 Homework Problems 294 Solutions Practice Problems 308 153154 Chapter 3 Machine-Level Representation Programs Computers execute machine code , sequences bytes encoding low-level op- erations manipulate data, manage memory, read write data storagedevices, communicate networks. compiler generates machine codethrough series stages, based rules programming language, theinstruction set target machine, conventions followed operat-ing system. gccC compiler generates output form assembly code , textual representation machine code giving individual instructions inthe program. gccthen invokes assembler linker generate exe- cutable machine code assembly code. chapter, take closelook machine code human-readable representation assembly code. programming high-level language C, even Java, shielded detailed, machine-level implementation pro-gram. contrast, writing programs assembly code (as done theearly days computing) programmer must specify low-level instructions theprogram uses carry computation. time, much produc-tive reliable work higher level abstraction provided high-levellanguage. type checking provided compiler helps detect many programerrors makes sure reference manipulate data consistent ways. Withmodern, optimizing compilers, generated code usually least efﬁcientas skilled, assembly-language programmer would write hand. Best ofall, program written high-level language compiled executed anumber different machines, whereas assembly code highly machine speciﬁc. spend time learning machine code? Even though com- pilers work generating assembly code, able read understand important skill serious programmers. invoking com-piler appropriate command-line parameters, compiler generate ﬁleshowing output assembly-code form. reading code, under-stand optimization capabilities compiler analyze underlyinginefﬁciencies code. experience Chapter 5, programmers seek-ing maximize performance critical section code often try differentvariations source code, time compiling examining generatedassembly code get sense efﬁciently program run. Furthermore, times layer abstraction provided high-level language hides information run-time behavior program need un-derstand. example, writing concurrent programs using thread package,as covered Chapter 12, important know region memory used tohold different program variables. information visible assembly-code level. another example, many ways programs attacked,allowing worms viruses infest system, involve nuances way pro-grams store run-time control information. Many attacks involve exploiting weaknesses system programs overwrite information thereby take controlof system. Understanding vulnerabilities arise guardagainst requires knowledge machine-level representation pro- grams. need programmers learn assembly code shifted theyears one able write programs directly assembly one ofbeing able read understand code generated compilers.Chapter 3 Machine-Level Representation Programs 155 chapter, learn details two particular assembly languages see C programs get compiled forms machine code. Readingthe assembly code generated compiler involves different set skills thanwriting assembly code hand. must understand transformations typicalcompilers make converting constructs C machine code. Relative tothe computations expressed C code, optimizing compilers rearrangeexecution order, eliminate unneeded computations, replace slow operations withfaster ones, even change recursive computations iterative ones. Under-standing relation source code generated assembly oftenbe challenge—it’s much like putting together puzzle slightly differ-ent design picture box. form reverse engineering —trying understand process system created studying systemand working backward. case, system machine-generated assembly-language program, rather something designed human. simpliﬁesthe task reverse engineering, generated code follows fairly reg-ular patterns, run experiments, compiler generate codefor many different programs. presentation, give many examples andprovide number exercises illustrating different aspects assembly languageand compilers. subject mastering details prerequisite tounderstanding deeper fundamental concepts. say “I un-derstand general principles, don’t want bother learning details” aredeluding themselves. critical spend time studying examples,working exercises, checking solutions provided. presentation based two related machine languages: Intel IA32, dominant language computers today, x86-64, extension run on64-bit machines. focus starts IA32. Intel processors grown fromprimitive 16-bit processors 1978 mainstream machines today’s desk-top, laptop, server computers. architecture grown correspondingly,with new features added 16-bit architecture transformed becomeIA32, supporting 32-bit data addresses. result rather peculiar designwith features make sense viewed historical perspective. Itis also laden features providing backward compatibility used modern compilers operating systems. focus subset fea- tures used gccand Linux. allows us avoid much complexity arcane features IA32. technical presentation starts quick tour show relation be- tween C, assembly code, machine code. proceed details ofIA32, starting representation manipulation data imple-mentation control. see control constructs C, if,while , switch statements, implemented. cover implementation pro- cedures, including program maintains run-time stack support thepassing data control procedures, well storage local vari-ables. Next, consider data structures arrays, structures, unions implemented machine level. background machine-level pro-gramming, examine problems bounds memory references andthe vulnerability systems buffer overﬂow attacks. ﬁnish part the156 Chapter 3 Machine-Level Representation Programs presentation tips using gdbdebugger examining run-time behavior machine-level program. discuss, extension IA32 64 bits, termed x86-64, origi- nally developed Advanced Micro Devices (AMD), Intel’s biggest competitor. Whereas 32-bit machine make use around 4 gigabytes (232bytes) random-access memory, current 64-bit machines use 256 terabytes (248 bytes). computer industry currently midst transition 32- bit 64-bit machines. microprocessors recent server desktopmachines, well many laptops, support either 32-bit 64-bit operation.However, operating systems running machines support only32-bit applications, capabilities hardware fully utilized.As memory prices drop, desire perform computations involving verylarge data sets increases, 64-bit machines applications become common-place. therefore appropriate take close look x86-64. see inmaking transition 32 64 bits, engineers AMD also incorporatedfeatures make machines better targets optimizing compilers thatimprove system performance. provide Web Asides cover material intended dedicated machine- language enthusiasts. one, examine code generated code com- piled using higher degrees optimization. successive version gcc compiler implements sophisticated optimization algorithms, canradically transform program point difﬁcult understand re-lation original source code generated machine-level program.Another Web Aside gives brief presentation ways incorporate assemblycode C programs. applications, programmer must drop downto assembly code access low-level features machine. One approach towrite entire functions assembly code combine C functions duringthe linking stage. second use gcc’s support embedding assembly code directly within C programs. provide separate Web Asides two differentmachine languages ﬂoating-point code. “x87” ﬂoating-point instructionshave available since early days Intel processors. implementationof ﬂoating point particularly arcane, advise people deter-mined work ﬂoating-point code older machines attempt study thissection. recent “SSE” instructions developed support multi- media applications , recent versions (version 2 later), recent versions gcc, SSE become preferred method map- ping ﬂoating point onto IA32 x86-64 machines. 3.1 Historical Perspective Intel processor line, colloquially referred x86, followed long, evo- lutionary development. started one ﬁrst single-chip, 16-bit micropro-cessors, many compromises made due limited capabilitiesof integrated circuit technology time. Since then, grown take ad-vantage technology improvements well satisfy demands higher performance supporting advanced operating systems.Section 3.1 Historical Perspective 157 list follows shows models Intel processors key features, especially affecting machine-level programming. use thenumber transistors required implement processors indication ofhow evolved complexity (K denotes 1000, denotes 1,000,000). 8086: (1978, 29 K transistors). One ﬁrst single-chip, 16-bit microproces- sors. 8088, variant 8086 8-bit external bus, formedthe heart original IBM personal computers. IBM contracted withthen-tiny Microsoft develop MS-DOS operating system. orig-inal models came 32,768 bytes memory two ﬂoppy drives (nohard drive). Architecturally, machines limited 655,360-byteaddress space—addresses 20 bits long (1,048,576 bytes address-able), operating system reserved 393,216 bytes use.In 1980, Intel introduced 8087 ﬂoating-point coprocessor (45 K tran-sistors) operate alongside 8086 8088 processor, executing theﬂoating-point instructions. 8087 established ﬂoating-point modelfor x86 line, often referred “x87.” 80286: (1982, 134 K transistors). Added (and obsolete) addressing modes. Formed basis IBM PC-AT personal computer, theoriginal platform MS Windows. i386: (1985, 275 K transistors). Expanded architecture 32 bits. Added ﬂat addressing model used Linux recent versions Windowsfamily operating system. ﬁrst machine series thatcould support Unix operating system. i486: (1989, 1.2 transistors). Improved performance integrated ﬂoating-point unit onto processor chip signiﬁcantly changethe instruction set. Pentium: (1993, 3.1 transistors). Improved performance, added minor extensions instruction set. PentiumPro: (1995, 5.5 transistors). Introduced radically new processor design, internally known P6microarchitecture. Added class “conditional move” instructions instruction set. Pentium II: (1997, 7 transistors). Continuation P6 microarchitecture. Pentium III: (1999, 8.2 transistors). Introduced SSE, class instructions manipulating vectors integer ﬂoating-point data. datum canbe 1, 2, 4 bytes, packed vectors 128 bits. Later versions chip went 24 transistors, due incorporation level-2 cache chip. Pentium 4: (2000, 42 transistors). Extended SSE SSE2, adding new data types (including double-precision ﬂoating point), along 144 newinstructions formats. extensions, compilers useSSE instructions, rather x87 instructions, compile ﬂoating-pointcode. Introduced NetBurst microarchitecture, could operate high clock speeds, cost high power consumption.158 Chapter 3 Machine-Level Representation Programs Pentium 4E: (2004, 125 transistors). Added hyperthreading , method run two programs simultaneously single processor, well EM64T,Intel’s implementation 64-bit extension IA32 developed Ad-vanced Micro Devices (AMD), refer x86-64. Core 2: (2006, 291 transistors). Returned back microarchitecture similar P6. First multi-core Intel microprocessor, multiple processors implemented single chip. support hyperthreading. Core i7: (2008, 781 transistors). Incorporated hyperthreading multi-core, initial version supporting two executing programson core four cores chip. successive processor designed backward compatible— able run code compiled earlier version. see, manystrange artifacts instruction set due evolutionary heritage. Intel hashad several names processor line, including IA32 , “Intel Architecture 32-bit,” recently Intel64 , 64-bit extension IA32, refer x86-64 . refer overall line commonly used colloquial name “x86,” reﬂecting processor naming conventions i486. Aside Moore’s law Intel microprocessor complexity 1.0E /H1100109 1.0E /H1100108 1.0E /H1100107 1.0E /H1100106 1.0E /H1100105 1.0E /H1100104 1975 1980808680286i386i486PentiumPentium 4Pentium 4eCore 2 DuoCore i7 Pentium IIPentium III 1985 1990 1995 2000 2005 2010 YearTransistorsPentiumPro plot number transistors different Intel processors versus year introduction, use logarithmic scale y-axis, see growth phenomenal. Fitting line data, see number transistors increases annual rate approximately 38%, meaning number transistors doubles every 26 months. growth sustained multiple-decade history x86 microprocessors.Section 3.2 Program Encodings 159 1965, Gordon Moore, founder Intel Corporation, extrapolated chip technology day, could fabricate circuits around 64 transistors single chip, predict number transistors per chip would double every year next 10 years. predication became known Moore’s law . turns out, prediction little bit optimistic, also short-sighted. 45 years, semiconductor industry able double transistor counts average every 18 months. Similar exponential growth rates occurred aspects computer technology—disk capacities, memory-chip capacities, processor performance. remarkable growth rates havebeen major driving forces computer revolution. years, several companies produced processors com- patible Intel processors, capable running exact machine-levelprograms. Chief among Advanced Micro Devices (AMD). years,AMD lagged behind Intel technology, forcing marketing strategy wherethey produced processors less expensive although somewhat lower inperformance. became competitive around 2002, ﬁrst breakthe 1-gigahertz clock-speed barrier commercially available microprocessor,and introducing x86-64, widely adopted 64-bit extension IA32. Althoughwe talk Intel processors, presentation holds well compatible processors produced Intel’s rivals. Much complexity x86 concern interested programs Linux operating system generated gcc compiler. memory model provided original 8086 extensions 80286 obsolete.Instead, Linux uses referred ﬂataddressing, entire memory space viewed programmer large array bytes. see list developments, number formats instructions added x86 manipulating vectors small integers ﬂoating-point numbers. features added allow improved performance onmultimedia applications, image processing, audio video encodingand decoding, three-dimensional computer graphics. default invocationfor 32-bit execution, gccassumes generating code i386, even though 1985-era microprocessors running longer. bygiving speciﬁc command-line options, compiling 64-bit operation, willthe compiler make use recent extensions. next part presentation, focus IA32 instruc- tion set. look extension 64 bits via x86-64 toward end ofthe chapter. 3.2 Program Encodings Suppose writ e C program two ﬁles p1.c andp2.c . compile code IA32 machine using Unix command line: unix> gcc -O1 -o p p1.c p2.c160 Chapter 3 Machine-Level Representation Programs command gccindicates gccC compiler. Since default compiler Linux, could also invoke simply cc. command-line option -O1 instructs compiler apply level-one optimizations. general, increasing thelevel optimization makes ﬁnal program run faster, risk increasedcompilation time difﬁculties running debugging tools code. willalso see, invoking higher levels optimization generate code heavilytransformed relationship generated machine code theoriginal source code difﬁcult understand. therefore use level-oneoptimization learning tool see happens increase levelof optimization. practice, level-two optimization (speciﬁed option -O2) considered better choice terms resulting program performance. Thegcccommand actually invokes sequence programs turn source code executable code. First, C preprocessor expands source code include ﬁles speciﬁed #include commands expand macros, speciﬁed #define declarations. Second, compiler generates assembly- code versions two source ﬁles names p1.s andp2.s . Next, assembler converts assembly code binary object-code ﬁlesp1.o andp2.o . Object code one form machine code—it contains binary representations allof instructions, addresses global values yet ﬁlled in. Finally,thelinker merges two object-code ﬁles along code implementing library functions (e.g., printf ) generates ﬁnal executable code ﬁle p. Executable code second form machine code consider—it exact formof code executed processor. relation different forms machine code linking process described detail Chapter 7. 3.2.1 Machine-Level Code described Section 1.9.2, computer systems employ several different forms abstraction, hiding details implementation use sim-pler, abstract model. Two especially important machine-levelprogramming. First, format behavior machine-level program de-ﬁned instruction set architecture , “ISA,” deﬁning processor state, format instructions, effect instructions state. ISAs, including IA32 x86-64, describe behavior program instruction executed sequence, one instructioncompleting next one begins. processor hardware far elab-orate, executing many instructions concurrently, employ safeguards toensure overall behavior matches sequential operation dictated theISA. Second, memory addresses used machine-level program vir-tual addresses, providing memory model appears large bytearray. actual implementation memory system involves combination multiple hardware memories operating system software, described Chapter 9. compiler work overall compilation sequence, transforming programs expressed relatively abstract execution model pro-Section 3.2 Program Encodings 161 vided C elementary instructions processor executes. assembly-code representation close machine code. main feature isthat readable textual format, compared binary format ofmachine code. able understand assembly code relates theoriginal C code key step understanding computers execute programs. IA32 machine code differs greatly original C code. Parts processor state visible normally hidden C programmer: .The program counter (commonly referred “PC,” called %eip IA32) indicates address memory next instruction executed. .The integer register ﬁle contains eight named locations storing 32-bit values. registers hold addresses (corresponding C pointers) integerdata. registers used keep track critical parts programstate, others used hold temporary data, local variablesof procedure, value returned function. .The condition code registers hold status information recentlyexecuted arithmetic logical instruction. used implement con-ditional changes control data ﬂow, required implementifandwhile statements. .A set ﬂoating-point registers store ﬂoating-point data. Whereas C provides model objects different data types declared allocated memory, machine code views memory simplya large, byte-addressable array. Aggregate data types C arrays structures represented machine code contiguous collections bytes. Even scalar data types, assembly code makes distinctions signed orunsigned integers, different types pointers, even pointersand integers. program memory contains executable machine code program, information required operating system, run-time stack managingprocedure calls returns, blocks memory allocated user (forexample, using malloc library function). mentioned earlier, program memory addressed using virtual addresses. given time, limited subranges virtual addresses considered valid. example, although 32-bit addresses IA32 potentially span 4-gigabyte range address values, atypical program access megabytes. operating systemmanages virtual address space, translating virtual addresses physicaladdresses values actual processor memory. single machine instruction performs elementary operation. example, might add two numbers stored registers, transfer data betweenmemory register, conditionally branch new instruction address. Thecompiler must generate sequences instructions implement programconstructs arithmetic expression evaluation, loops, procedure calls andreturns.162 Chapter 3 Machine-Level Representation Programs Aside ever-changing forms generated code presentation, show code generated particular version gcc particular settings command-line options. compile code machine, chances using different compiler different version gccand hence generate different code. open- source community supporting gcc keeps changing code generator, attempting generate efﬁcient code according changing code guidelines provided microprocessor manufacturers. goal studying examples shown presentation demonstrate examine assembly code map back constructs found high-level programming languages. willneed adapt techniques style code generated particular compiler. 3.2.2 Code Examples Suppose writ e C code ﬁle code.c containing following procedure deﬁni- tion: 1int accum = 0; 2 3int sum(int x, int y) 4{ 5 n tt=x+y ; 6 accum += t; 7 return t; 8} see assembly code generated C compiler, use “ -S” option command line: unix> gcc -O1 -S code.c cause gccto run compiler, generating assembly ﬁle code.s , go further. (Normally would invoke assembler generate object-code ﬁle.) assembly-code ﬁle contains various declarations including set lines: sum: pushl %ebp movl %esp, %ebp movl 12(%ebp), %eax addl 8(%ebp), %eax addl %eax, accum popl %ebp ret indented line code corresponds single machine instruction. example, pushl instruction indicates contents register %ebp pushed onto program stack. information local variable names data types stripped away. still see reference globalSection 3.2 Program Encodings 163 variable accum , since compiler yet determined memory variable stored. use ‘ -c’ command-line option, gccwill compile assemble code: unix> gcc -O1 -c code.c generate object-code ﬁle code.o binary format hence cannot viewed directly. Embedded within 800 bytes ﬁle code.o 17-byte sequence hexadecimal representation 55 89 e5 8b 45 0c 03 45 08 01 05 00 00 00 00 5d c3 object-code corresponding assembly instructions listed above. Akey lesson learn program actually executed machineis simply sequence bytes encoding series instructions. machine hasvery little information source code instructions weregenerated. Aside ﬁnd byte representation program? generate bytes, used disassembler (to described shortly) determine code sumis 17 bytes long. ran GNU debugging tool gdbon ﬁle code.o gave command (gdb) x/17xb sum telling examine (abbreviated ‘x’) 17 hex-formatted (also abbreviated ‘x’) bytes (abbreviated ‘b’). ﬁnd gdb many useful features analyzing machine-level programs, discussed Section 3.11. inspect contents machine-code ﬁles, class programs known disassemblers invaluable. programs generate format similar assembly code machine code. Linux systems, program objdump (for “object dump”) serve role given ‘ -d’ command-line ﬂag: unix> objdump -d code.o result (where added line numbers left annotations italicized text) follows: Disassembly function sumin binary file code.o 100000000 <sum>: Offset Bytes Equivalent assembly language 2 0: 55 push %ebp 3 1: 89 e5 mov %esp,%ebp 4 3: 8b 45 0c mov 0xc(%ebp),%eax 5 6: 03 45 08 add 0x8(%ebp),%eax 6 9: 01 05 00 00 00 00 add %eax,0x0 7 f: 5d pop %ebp 8 10: c3 ret164 Chapter 3 Machine-Level Representation Programs left, see 17 hexadecimal byte values listed byte sequence earlier, partitioned groups 1 6 bytes each. groups asingle instruction, assembly-language equivalent shown right. Several features machine code disassembled representation worth noting: .IA32 instructions range length 1 15 bytes. instructionencoding designed commonly used instructions feweroperands require smaller number bytes less common ones oneswith operands. .The instruction format designed way given startingposition, unique decoding bytes machine instructions.For example, instruction pushl %ebp start byte value 55. .The disassembler determines assembly code based purely byte sequences machine-code ﬁle. require access source assembly-code versions program. .The disassembler uses slightly different naming convention instruc- tions assembly code generated gcc. example, omitted sufﬁx ‘ l’ many instructions. sufﬁxes size designators omitted cases. Generating actual executable code requires running linker set object-code ﬁles, one must contain function main . Suppose ﬁle main.c following function: 1int main() 2{ 3 return sum(1, 3); 4} Then, could generate executable program prog follows: unix> gcc -O1 -o prog code.o main.c ﬁle prog grown 9,123 bytes, since contains code two procedures also information used start terminate program aswell interact operating system. also disassemble ﬁle prog : unix> objdump -d prog disassembler extract various code sequences, including following: Disassembly function sumin executable file prog 108048394 <sum>: Offset Bytes Equivalent assembly language 2 8048394: 55 push %ebp 3 8048395: 89 e5 mov %esp,%ebp 4 8048397: 8b 45 0c mov 0xc(%ebp),%eaxSection 3.2 Program Encodings 165 5 804839a: 03 45 08 add 0x8(%ebp),%eax 6 804839d: 01 05 18 a0 04 08 add %eax,0x804a018 7 80483a3: 5d pop %ebp 8 80483a4: c3 ret code almost identical generated disassembly code.c . One important difference addresses listed along left different—thelinker shifted location code different range addresses. Asecond difference linker determined location storing global variable accum . line 6 disassembly code.o , address accum listed 0. disassembly prog , address set 0x804a018 . shown assembly-code rendition instruction. also seen thelast 4 bytes instruction, listed least-signiﬁcant 18 a0 04 08 . 3.2.3 Notes Formatting assembly code generated gccis difﬁcult human read. one hand, contains information need concerned, otherhand, provide description program works. Forexample, suppose ﬁle simple.c contains following code: 1int simple(int *xp, int y) 2{ 3 n tt=* x p+y ; 4 * x p=t ; 5 return t; 6} gccis run ﬂags ‘ -S’ ‘ -O1’, generates following ﬁle simple.s : .file "simple.c" .text .globl simple .type simple, @function simple: pushl %ebp movl %esp, %ebp movl 8(%ebp), %edx movl 12(%ebp), %eax addl (%edx), %eax movl %eax, (%edx)popl %ebp ret .size simple, .-simple .ident "GCC: (Ubuntu 4.3.2-1ubuntu11) 4.3.2" .section .note.GNU-stack,"",@progbits166 Chapter 3 Machine-Level Representation Programs lines beginning ‘ .’ directives guide assembler linker. generally ignore these. hand, explanatoryremarks instructions relate source code. provide clearer presentation assembly code, show form omits directives, including line numbers explanatoryannotations. example, annotated version would appear follows: 1simple: 2 pushl %ebp Save frame pointer 3 movl %esp, %ebp Create new frame pointer 4 movl 8(%ebp), %edx Retrieve xp 5 movl 12(%ebp), %eax Retrieve 6 addl (%edx), %eax Add *xp get 7 movl %eax, (%edx) Store xp 8 popl %ebp Restore frame pointer 9 ret Return typically show lines code relevant point discussed. line numbered left reference annotated right abrief description effect instruction relates computa-tions original C code. stylized version way assembly-languageprogrammers format code. Aside ATT versus Intel assembly-code formats presentation, show assembly code ATT (named “AT&T,” company operated Bell Laboratories many years) format, default format gcc,objdump , tools consider. programming tools, including Microsoft well documentationfrom Intel, show assembly code Intel format. two formats differ number ways. example, gcccan generate code Intel format sumfunction using following command line: unix> gcc -O1 -S -masm=intel code.c gives following assembly code: Assembly code simple Intel format 1simple: 2 push ebp 3 mov ebp, esp 4 mov edx, DWORD PTR [ebp+8] 5 mov eax, DWORD PTR [ebp+12] 6 add eax, DWORD PTR [edx] 7 mov DWORD PTR [edx], eax 8 pop ebp 9 retSection 3.3 Data Formats 167 see Intel ATT formats differ following ways: .The Intel code omits size designation sufﬁxes. see instruction movinstead movl . .The Intel code omits ‘ %’ character front register names, using espinstead %esp . .The Intel code different way describing locations memory, example ‘ DWORD PTR [ebp+8] ’ rather ‘ 8(%ebp) ’. .Instructions multiple operands list reverse order. confusing switching two formats. Although using Intel format presentation, encounter IA32 documen- tation Intel Windows documentation Microsoft. 3.3 Data Formats Due origins 16-bit architecture expanded 32-bit one, Intel uses term “word” refer 16-bit data type. Based this, refer 32-bit quantities “double words.” refer 64-bit quantities “quad words.”Most instructions encounter operate bytes double words. Figure 3.1 shows IA32 representations used primitive data types C. common data types stored double words. includes bothregular long int’s, whether signed. addition, pointers (shown char * ) stored 4-byte double words. Bytes commonly used manipulating string data. saw Section 2.1, recent ex-tensions C language include data type long long , represented using 8 bytes. IA32 support data type hardware. Instead, com-piler must generate sequences instructions operate data 32 bits C declaration Intel data type Assembly code sufﬁx Size (bytes) char Byte b 1 short Word w 2 int Double word l 4 long int Double word l 4 long long int —— 4 char * Double word l 4 float Single precision 4 double Double precision l 8 long double Extended precision 10/12 Figure 3.1 Sizes C data types IA32. IA32 provide hardware support 64-bit integer arithmetic. Compiling code long long data requires generating sequences operations perform arithmetic 32-bit chunks.168 Chapter 3 Machine-Level Representation Programs time. Floating-point numbers come three different forms: single-precision (4-byte) values, corresponding C data type float ; double-precision (8-byte) values, corresponding C data type double ; extended-precision (10-byte) values. gccuses data type long double refer extended-precision ﬂoating- point values. also stores 12-byte quantities improve memory systemperformance, discussed later. Using long double data type (intro- duced ISO C99) gives us access extended-precision capability x86.For machines, data type represented using 8-byte format ordinary double data type. table indicates, assembly-code instructions generated gcchave single-character sufﬁx denoting size operand. example, datamovement instruction three variants: movb (move byte), movw (move word), andmovl (move double word). sufﬁx ‘ l’ used double words, since 32-bit quantities considered “long words,” holdover era 16-bitword sizes standard. Note assembly code uses sufﬁx ‘ l’ denote 4-byte integer well 8-byte double-precision ﬂoating-point number.This causes ambiguity, since ﬂoating point involves entirely different set ofinstructions registers. 3.4 Accessing Information IA32 central processing unit (CPU) contains set eight registers storing 32-bit values. registers used store integer data well pointers.Figure 3.2 diagrams eight registers. names begin %e, other- wise, peculiar names. original 8086, registers 16 bitsand speciﬁc purpose. names chosen reﬂect different purposes. ﬂat addressing, need specialized registers greatly reduced. part, ﬁrst six registers considered general-purpose regis- Figure 3.2 IA32 integer registers.All eight registers accessed either 16bits (word) 32 bits (double word). 2 low- order bytes ﬁrst fourregisters accessedindependently.%ah31 15 8 7 0 %eax %ax %al %ch %ecx %cx %cl %dh %edx %dx %dl %bh %ebx %bx %esi %si %edi %di %esp %sp %ebp %bp%bl Stack pointer Frame pointerSection 3.4 Accessing Information 169 ters restrictions placed use. said “for part,” instructions use ﬁxed registers sources and/or destinations. addition,within procedures different conventions saving restoring theﬁrst three registers ( %eax ,%ecx , %edx ) next three ( %ebx ,%edi , and%esi ). discussed Section 3.7. ﬁnal two registers ( %ebp %esp ) contain pointers important places program stack. altered according set standard conventions stack management. indicated Figure 3.2, low-order 2 bytes ﬁrst four registers independently read written byte operation instructions. Thisfeature provided 8086 allow backward compatibility 8008 and8080—two 8-bit microprocessors date back 1974. byte instructionupdates one single-byte “register elements,” remaining 3 bytes theregister change. Similarly, low-order 16 bits register beread written word operation instructions. feature stems IA32’s evolutionary heritage 16-bit microprocessor also used operatingon integers size designator short . 3.4.1 Operand Speciﬁers instructions one operands , specifying source values reference performing operation destination location toplace result. IA32 supports number operand forms (see Figure 3.3). Sourcevalues given constants read registers memory. Results bestored either registers memory. Thus, different operand possibilities canbe classiﬁed three types. ﬁrst type, immediate , constant values. ATT-format assembly code, written ‘ $’ followed integer using standard C notation, example, $-577 or$0x1F . value ﬁts 32-bit word used, although assembler use 1- 2-byte encodings Type Form Operand value Name Immediate $Imm Imm Immediate Register Ea R[Ea] Register Memory Imm M[Imm ] Absolute Memory (Ea) M[R[Ea]] Indirect Memory Imm(Eb) M[Imm+R[Eb]] Base + displacement Memory (Eb,Ei) M[R[Eb]+R[Ei]] Indexed Memory Imm(Eb,Ei) M[Imm+R[Eb]+R[Ei]] Indexed Memory (,Ei,s) M[R[Ei].s] Scaled indexed Memory Imm(,Ei,s) M[Imm+R[Ei].s] Scaled indexed Memory (Eb,Ei,s) M[R[Eb]+R[Ei].s] Scaled indexed Memory Imm(Eb,Ei,s) M[Imm+R[Eb]+R[Ei].s] Scaled indexed Figure 3.3 Operand forms. Operands denote immediate (constant) values, register values, values memory. scaling factor smust either 1, 2, 4, 8.170 Chapter 3 Machine-Level Representation Programs possible. second type, register , denotes contents one registers, either one eight 32-bit registers (e.g., %eax ) double-word operation, one eight 16-bit registers (e.g., %ax) word operation, one eight single-byte register elements (e.g., %al) byte operation. Figure 3.3, use notation Eato denote arbitrary register a, indicate value reference R[Ea], viewing set registers array Rindexed register identiﬁers. third type operand memory reference, access memory location according computed address, often called effective ad- dress . Since view memory large array bytes, use notation Mb[Addr ] denote reference b-byte value stored memory starting address Addr . simplify things, generally drop subscript b. Figure 3.3 shows, many different addressing modes allowing dif- ferent forms memory references. general form shown bottomof table syntax Imm(E b,Ei,s). reference four components: immediate offset Imm , base register Eb, index register Ei, scale factor s, smust 1, 2, 4, 8. effective address computed asImm+R[Eb]+R[Ei].s.This general form often seen referencing el- ements arrays. forms simply special cases general form components omitted. see, complexaddressing modes useful referencing array structure elements. Practice Problem 3.1 Assume following values stored indicated memory addresses registers: Address Value Register Value 0x100 0xFF %eax 0x100 0x104 0xAB %ecx 0x10x108 0x13 %edx 0x30x10C 0x11 Fill following table showing values indicated operands: Operand Value %eax 0x104 $0x108 (%eax) 4(%eax) 9(%eax,%edx) 260(%ecx,%edx) 0xFC(,%ecx,4) (%eax,%edx,4)Section 3.4 Accessing Information 171 Instruction Effect Description mov S,DD ←S Move movb Move byte movw Move word movl Move double word movs S,DD ←SignExtend (S) Move sign extension movsbw Move sign-extended byte word movsbl Move sign-extended byte double word movswl Move sign-extended word double word movz S,DD ←ZeroExtend (S) Move zero extension movzbw Move zero-extended byte word movzbl Move zero-extended byte double word movzwl Move zero-extended word double word pushl R[%esp ]←R[%esp ]−4; Push double word M[R[%esp ]]←S popl DD ←M[R[%esp ]]; Pop double word R[%esp ]←R[%esp ]+4 Figure 3.4 Data movement instructions. 3.4.2 Data Movement Instructions Among heavily used instructions copy data one location another. generality operand notation allows simple datamovement instruction perform many machines would require numberof instructions. Figure 3.4 lists important data movement instructions. canbe seen, group many different instructions instruction classes , instructions class perform operation, different operandsizes. example, mov class consists three instructions: movb ,movw , movl . three instructions perform operation; differ operate data size 1, 2, 4 bytes, respectively. instructions mov class copy source values destinations. source operand designates value immediate, stored register, orstored memory. destination operand designates location either register memory address. IA32 imposes restriction move instruction cannot operands refer memory locations. Copying value onememory location another requires two instructions—the ﬁrst load sourcevalue register, second write register value destination.Referring Figure 3.2, register operands instructions anyof eight 32-bit registers ( %eax –%ebp ) movl , eight 16-bit regis- ters ( %ax–%bp) movw , single-byte register elements ( %ah–%bh, %al–%bl) movb . following mov instruction examples show ﬁve172 Chapter 3 Machine-Level Representation Programs possible combinations source destination types. Recall source operand comes ﬁrst destination second: 1 movl $0x4050,%eax Immediate--Register, 4 bytes 2 movw %bp,%sp Register--Register, 2 bytes 3 movb (%edi,%ecx),%ah Memory--Register, 1 byte 4 movb $-17,(%esp) Immediate--Memory, 1 byte 5 movl %eax,-12(%ebp) Register--Memory, 4 bytes movs movz instruction classes serve copy smaller amount source data larger data location, ﬁlling upper bits either signexpansion ( movs ) zero expansion ( movz ). sign expansion, upper bits destination ﬁlled copies signiﬁcant bit thesource value. zero expansion, upper bits ﬁlled zeros. beseen, three instructions classes, covering cases 1-and 2-byte source sizes 2- 4-byte destination sizes (omitting redundantcombinations movsww andmovzww , course). Aside Comparing byte movement instructions Observe three byte-movement instructions movb ,movsbl , movzbl differ subtle ways. example: Assume initially %dh = CD, %eax = 98765432 1 movb %dh,%al %eax = 987654CD 2 movsbl %dh,%eax %eax = FFFFFFCD 3 movzbl %dh,%eax %eax = 000000CD examples, set low-order byte register %eax second byte %edx .T h e movb instruction change 3 bytes. movsbl instruction sets 3 bytes either ones zeros, depending high-order bit source byte. movzbl instruction sets 3 bytes zeros case. ﬁnal two data movement operations used push data onto pop data program stack. see, stack plays vital role thehandling procedure calls. way background, stack data structure values added deleted, according “last-in, ﬁrst-out” discipline. add data stack via push operation remove via popop- eration, property value popped always value wasmost recently pushed still stack. stack implemented anarray, always insert remove elements one end array. Thisend called topof stack. IA32, program stack stored region memory. illustrated Figure 3.5, stack grows downward thatthe top element stack lowest address stack elements. (By con- vention, draw stacks upside down, stack “top” shown bottom ﬁgure). stack pointer %esp holds address top stack element.Section 3.4 Accessing Information 173 %eax %edx %esp 0x10800x123 0x108%eax %edx %esp 0x108 0x10400x123 0x104%eax %edx %esp0x1230x123pushl %eax popl %edx 0x108Initially Stack “bottom” Increasing address Stack “top”Stack “bottom” 0x123 0x123 Stack “top”Stack “top”0x108Stack “bottom” Figure 3.5 Illustration stack operation. convention, draw stacks upside down, “top” stack shown bottom. IA32 stacks grow towardlower addresses, pushing involves decrementing stack pointer (register %esp ) storing memory, popping involves reading memory incrementing thestack pointer. Thepushl instruction provides ability push data onto stack, thepopl instruction pops it. instructions takes single operand—the data source pushing data destination popping. Pushing double-word value onto stack involves ﬁrst decrementing stack pointer 4 writing value new top stack address. Therefore, behavior instruction pushl %ebp equivalent pair instructions subl $4,%esp Decrement stack pointer movl %ebp,(%esp) Store %ebp stack except pushl instruction encoded machine code single byte, whereas pair instructions shown requires total 6 bytes. ﬁrsttwo columns Figure 3.5 illustrate effect executing instruction pushl %eax %esp is0x108 and%eax is0x123 . First %esp decremented 4, giving 0x104 , 0x123 stored memory address 0x104 . Popping double word involves reading top stack location incrementing stack pointer 4. Therefore, instruction popl %eax equivalent following pair instructions: movl (%esp),%eax Read %eax stack addl $4,%esp Increment stack pointer third column Figure 3.5 illustrates effect executing instruction popl %edx immediately executing pushl . Value 0x123 read from174 Chapter 3 Machine-Level Representation Programs memory written register %edx . Register %esp incremented back 0x108 . shown ﬁgure, value 0x123 remains memory location 0x104 overwritten (e.g., another push operation). However, stack top alwaysconsidered address indicated %esp . value stored beyond stack top considered invalid. Since stack contained memory program code forms program data, programs access arbitrary positions within thestack using standard memory addressing methods. example, assuming topmost element stack double word, instruction movl 4(%esp),%edx copy second double word stack register %edx . Practice Problem 3.2 following lines assembly language, determine appropriate instruction sufﬁx based operands. (For example, mov rewritten movb ,movw ,o rmovl .) 1 mov %eax, (%esp) 2 mov (%eax), %dx 3 mov $0xFF, %bl 4 mov (%esp,%edx,4), %dh 5 push $0xFF 6 mov %dx, (%eax) 7 pop %edi Practice Problem 3.3 following lines code generates error message invoke assembler. Explain wrong line. 1 movb $0xF, (%bl) 2 movl %ax, (%esp) 3 movw (%eax),4(%esp) 4 movb %ah,%sh 5 movl %eax,$0x123 6 movl %eax,%dx 7 movb %si, 8(%ebp) 3.4.3 Data Movement Example example code uses data movement instructions, consider data exchange routine shown Figure 3.6, C code assembly codegenerated gcc. omit portion assembly code allocates space run-time stack procedure entry deallocates prior return. detailsof set-up completion code covered discuss procedurelinkage. code left called “body.”Section 3.4 Accessing Information 175 New C? examples pointers Function exchange (Figure 3.6) provides good illustration use pointers C. Argument xp pointer integer, yis integer itself. statement int x = *xp; indicates read value stored location designated xpand store local variable named x. read operation known pointer dereferencing . C operator *performs pointer dereferencing. statement * x p=y ; reverse—it writes value parameter yat location designated xp. also form pointer dereferencing (and hence operator *), indicates write operation since left-hand side assignment. following example exchange action: n ta=4 ; int b = exchange(&a, 3); printf("a = %d , b = %d\n", a, b); code printa=3 ,b=4 C operator &(called “address of” operator) creates pointer, case location holding local variable a. Function exchange overwrote value stored awith 3 returned 4 function value. Observe passing pointer exchange , could modify data held remote location. body procedure starts execution, procedure parameters xp andyare stored offsets 8 12 relative address register %ebp . Instructions 1 2 read parameter xpfrom memory store register (a) C code 1 int exchange(int *xp, int y) 2 { 3 int x = *xp; 4 5 * x p=y ; 6 return x; 7 }(b) Assembly code xp %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %edx Get xp copying %eax below, x becomes return value 2 movl (%edx), %eax G e txa tx p 3 movl 12(%ebp), %ecx Get 4 movl %ecx, (%edx) Store xp Figure 3.6 C assembly code exchange routine body. stack set-up completion portions omitted.176 Chapter 3 Machine-Level Representation Programs %edx . Instruction 2 uses register %edx reads xinto register %eax , direct implementation operation x = *xp C program. Later, register %eax used return value function, return value bex. Instruction 3 loads parameter yinto register %ecx . Instruction 4 writes value memory location designated xpin register %edx , direct implementation operation * x p=y . example illustrates mov instructions used read memory register (instructions 1 3),and write register memory (instruction 4.) Two features assembly code worth noting. First, see call “pointers” C simply addresses. Dereferencing pointer involvescopying pointer register, using register memoryreference. Second, local variables xare often kept registers rather stored memory locations. Register access much faster memory access. Practice Problem 3.4 Assume variables vandpdeclared types src_t v; dest_t *p; src_t anddest_t data types declared typedef . wish use appropriate data movement instruction implement operation *p = (dest_t) v; vis stored appropriately named portion register %eax (i.e.,%eax , %ax,o r%al), pointer pis stored register %edx . following combinations src_t anddest_t , write line assembly code appropriate transfer. Recall performing cast thatinvolves size change change “signedness” C, operationshould change signedness ﬁrst (Section 2.2.6). src_t dest_t Instruction int int movl %eax, (%edx) char int char unsigned unsigned char int int char unsigned unsigned char unsigned int Practice Problem 3.5 given following information. function prototype void decode1(int *xp, int *yp, int *zp);Section 3.5 Arithmetic Logical Operations 177 compiled assembly code. body code follows: xp %ebp+8, yp %ebp+12, zp %ebp+16 1 movl 8(%ebp), %edi 2 movl 12(%ebp), %edx 3 movl 16(%ebp), %ecx 4 movl (%edx), %ebx 5 movl (%ecx), %esi 6 movl (%edi), %eax 7 movl %eax, (%edx) 8 movl %ebx, (%ecx) 9 movl %esi, (%edi) Parameters xp,yp, zpare stored memory locations offsets 8, 12, 16, respectively, relative address register %ebp . Write C code decode1 effect equivalent assembly code above. 3.5 Arithmetic Logical Operations Figure 3.7 lists integer logic operations. operationsare given instruction classes, different variants differentoperand sizes. (Only leal size variants.) example, instruction class add consists three addition instructions: addb ,addw , addl , adding bytes, words, double words, respectively. Indeed, instructionclasses shown instructions operating byte, word, double-word data.The operations divided four groups: load effective address, unary, binary,and shifts. Binary operations two operands, unary operations one operand. operands speciﬁed using notation described inSection 3.4. 3.5.1 Load Effective Address load effective address instruction leal actually variant movl instruc- tion. form instruction reads memory register, itdoes reference memory all. ﬁrst operand appears memory refer-ence, instead reading designated location, instruction copies effective address destination. indicate computation Figure 3.7 using C address operator &S. instruction used generate point- ers later memory references. addition, used compactly describecommon arithmetic operations. example, register %edx contains value x, instruction leal 7(%edx,%edx,4), %eax set register %eax 5x+7. Compilers often ﬁnd clever uses leal nothing effective address computations. destination operand must register.178 Chapter 3 Machine-Level Representation Programs Instruction Effect Description leal S,DD ←&S Load effective address inc DD ←D+1 Increment dec DD ←D-1 Decrement neg DD ←-D Negate DD ←~D Complement add S,DD ←D+S Add sub S,DD ←D-S Subtract imul S,DD ←D*S Multiply xor S,DD ←D^S Exclusive-or S,DD ←D|S S,DD ←D&S sal k,DD ←D<<k Left shift shl k,DD ←D<<k Left shift (same sal) sar k,DD ←D>>Ak Arithmetic right shift shr k,DD ←D>>Lk Logical right shift Figure 3.7 Integer arithmetic operations. load effective address ( leal ) instruction commonly used perform simple arithmetic. remaining ones standardunary binary operations. use notation >>Aand>>Lto denote arithmetic logical right shift, respectively. Note nonintuitive ordering operands ATT-format assembly code. Practice Problem 3.6 Suppose register %eax holds value xand%ecx holds value y. Fill table formulas indicating value stored register %edx given assembly code instructions: Instruction Result leal 6(%eax), %edx leal (%eax,%ecx), %edx leal (%eax,%ecx,4), %edx leal 7(%eax,%eax,8), %edx leal 0xA(,%ecx,4), %edx leal 9(%eax,%ecx,2), %edx 3.5.2 Unary Binary Operations Operations second group unary operations, single operand serving source destination. operand either register orSection 3.5 Arithmetic Logical Operations 179 memory location. example, instruction incl (%esp) causes 4-byte element top stack incremented. syntax reminiscent ofthe C increment ( ++) decrement ( --) operators. third group consists binary operations, second operand used source destination. syntax reminiscent Cassignment operators, x+ =y . Observe, however, source operand given ﬁrst destination second. looks peculiar noncommutativeoperations. example, instruction subl %eax,%edx decrements register %edx value %eax . (It helps read instruction “Subtract %eax %edx .”) ﬁrst operand either immediate value, register, memory location. second either register memory location. themovl instruction, however, two operands cannot memory locations. Practice Problem 3.7 Assume following values stored indicated memory addresses registers: Address Value Register Value 0x100 0xFF %eax 0x100 0x104 0xAB %ecx 0x10x108 0x13 %edx 0x30x10C 0x11 Fill following table showing effects following instructions, terms register memory location updated theresulting value: Instruction Destination Value addl %ecx,(%eax) subl %edx,4(%eax) imull $16,(%eax,%edx,4) incl 8(%eax) decl %ecx subl %edx,%eax 3.5.3 Shift Operations ﬁnal group consists shift operations, shift amount given ﬁrst, value shift given second. arithmetic logical right shifts arepossible. shift amount encoded single byte, since shift amountsbetween 0 31 possible (only low-order 5 bits shift amount areconsidered). shift amount given either immediate single-byte register element %cl. (These instructions unusual allowing speciﬁc register operand.) Figure 3.7 indicates, two names the180 Chapter 3 Machine-Level Representation Programs left shift instruction: saland shl. effect, ﬁlling right zeros. right shift instructions differ sarperforms arithmetic shift (ﬁll copies sign bit), whereas shrperforms logical shift (ﬁll zeros). destination operand shift operation either register amemory location. denote two different right shift operations Figure 3.7as>> A(arithmetic) >>L(logical). Practice Problem 3.8 Suppose want generate assembly code following C function: int shift_left2_rightn(int x, int n) { x <<= 2;x >>= n;return x; } code follows portion assembly code performs actual shifts leaves ﬁnal value register %eax . Two key instructions omitted. Parameters xandnare stored memory locations offsets 8 12, respectively, relative address register %ebp . 1 movl 8(%ebp), %eax Get x 2 x <<= 2 3 movl 12(%ebp), %ecx Get n 4 x >>= n Fill missing instructions, following annotations right. right shift performed arithmetically. 3.5.4 Discussion see instructions shown Figure 3.7 used either unsigned two’s-complement arithmetic. right shifting requires instructionsthat differentiate signed versus unsigned data. one featuresthat makes two’s-complement arithmetic preferred way implement signedinteger arithmetic. Figure 3.8 shows example function performs arithmetic operations translation assembly code. before, omitted stack set-up completion portions. Function arguments x,y, zare stored memory offsets 8, 12, 16 relative address register %ebp , respectively. assembly code instructions occur different order C source code. Instructions 2 3 compute expression z*48 combination leal shift instructions. Line 5 computes value x+y. Line 6 computes oft1and0xFFFF . ﬁnal multiply computed line 7. Since destination multiply register %eax , value returned function.Section 3.5 Arithmetic Logical Operations 181 (a) C code 1int arith(int x, 2 int y, 3 int z) 4{ 5 int t1 = x+y; 6 int t2 = z*48; 7 int t3 = t1 & 0xFFFF; 8 int t4 = t2 * t3; 9 return t4; 10 }(b) Assembly code xa %ebp+ 8 ,ya %ebp+12, z %ebp+16 1 movl 16(%ebp), %eax z 2 leal (%eax,%eax,2), %eax z*3 3 sall $4, %eax t2 = z*48 4 movl 12(%ebp), %edx 5 addl 8(%ebp), %edx t1 = x+y 6 andl $65535, %edx t3 = t1&0xFFFF 7 imull %edx, %eax Return t4 = t2*t3 Figure 3.8 C assembly code arithmetic routine body. stack set-up completion portions omitted. assembly code Figure 3.8, sequence values register %eax corresponds program values z,3*z,z*48 , t4(as return value). gen- eral, compilers generate code uses individual registers multiple programvalues moves program values among registers. Practice Problem 3.9 following variant function Figure 3.8(a), expressions beenreplaced blanks: 1int arith(int x, 2 int y, 3 int z) 4{ 5 int t1 = ; 6 int t2 = ; 7 int t3 = ; 8 int t4 = ; 9 return t4; 10 } portion generated assembly code implementing expressions follows: xa %ebp+ 8 ,ya %ebp+12, z %ebp+16 1 movl 12(%ebp), %eax 2 xorl 8(%ebp), %eax 3 sarl $3, %eax 4 notl %eax 5 subl 16(%ebp), %eax Based assembly code, ﬁll missing portions C code.182 Chapter 3 Machine-Level Representation Programs Practice Problem 3.10 common ﬁnd assembly code lines form xorl %edx,%edx code generated C Exclusive-Or operations present. A. Explain effect particular Exclusive-Or instruction useful operation implements. B. would straightforward way express operation assembly code? C. Compare number bytes encode two different implementa- tions operation. 3.5.5 Special Arithmetic Operations Figure 3.9 describes instructions support generating full 64-bit product two 32-bit numbers, well integer division. Theimull instruction, member imul instruction class listed Fig- ure 3.7, known “two-operand” multiply instruction. generates 32-bitproduct two 32-bit operands, implementing operations * u 32and*t 32de- scribed Sections 2.3.4 2.3.5. Recall truncating product 32bits, unsigned multiply two’s-complement multiply bit-level behavior. IA32 also provides two different “one-operand” multiply instruc-tions compute full 64-bit product two 32-bit values—one unsigned(mull ), one two’s-complement ( imull ) multiplication. these, one argument must register %eax , given instruction Instruction Effect Description imull R[%edx ]:R[%eax ]←S×R[%eax ] Signed full multiply mull R[%edx ]:R[%eax ]←S×R[%eax ] Unsigned full multiply cltd R[%edx ]:R[%eax ]←SignExtend (R[%eax ]) Convert quad word idivl R[%edx ]←R[%edx ]:R[%eax ] mod S; Signed divide R[%eax ]←R[%edx ]:R[%eax ]÷S divl R[%edx ]←R[%edx ]:R[%eax ] mod S; Unsigned divide R[%eax ]←R[%edx ]:R[%eax ]÷S Figure 3.9 Special arithmetic operations. operations provide full 64-bit multi- plication division, signed unsigned numbers. pair registers %edx and%eax viewed forming single 64-bit quad word.Section 3.5 Arithmetic Logical Operations 183 source operand. product stored registers %edx (high-order 32 bits) and%eax (low-order 32 bits). Although name imull used two distinct multiplication operations, assembler tell one intended countingthe number operands. example, suppose signed numbers xandystored positions 8 12 relative %ebp , want store full 64-bit product 8 bytes top stack. code would proceed follows: xa %ebp+ 8 ,ya %ebp+12 1 movl 12(%ebp), %eax P u tyi n %eax 2 imull 8(%ebp) Multiply x 3 movl %eax, (%esp) Store low-order 32 bits 4 movl %edx, 4(%esp) Store high-order 32 bits Observe locations store two registers correct little-endian machine—the high-order bits register %edx stored offset 4 relative low-order bits %eax . stack growing toward lower addresses, means low-order bits top stack. earlier table arithmetic operations (Figure 3.7) list divi- sion modulus operations. operations provided single-operanddivide instructions similar single-operand multiply instructions. signeddivision instruction idivl takes dividend 64-bit quantity registers %edx (high-order 32 bits) %eax (low-order 32 bits). divisor given in- struction operand. instruction stores quotient register %eax remainder register %edx . example, suppose signed numbers xandystored positions 8 12 relative %ebp , want store values x/yandxmodyon stack. gccgenerates following code: xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %edx P u txi n %edx 2 movl %edx, %eax Copy x %eax 3 sarl $31, %edx Sign extend x %edx 4 idivl 12(%ebp) Divide 5 movl %eax, 4(%esp) Storex/y 6 movl %edx, (%esp) Storex%y move instruction line 1 arithmetic shift line 3 combined effect setting register %edx either zeros ones depending sign x, move instruction line 2 copies xinto%eax . Thus, combined registers %edx and%eax storing 64-bit, sign-extended version ofx. Following idivl instruction, quotient remainder copied top two stack locations (instructions 5 6).184 Chapter 3 Machine-Level Representation Programs conventional method setting divisor makes use cltd1 instruction. instruction sign extends %eax into%edx . instruction, code sequence shown becomes xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp),%eax Load x %eax 2 cltd Sign extend %edx 3 idivl 12(%ebp) Divide 4 movl %eax, 4(%esp) Storex/y 5 movl %edx, (%esp) Storex%y see ﬁrst two instructions overall effect ﬁrst three instructions earlier code sequence. Different versions gccgenerate two different ways setting dividend integer division. Unsigned division makes use divl instruction. Typically register %edx set 0 beforehand. Practice Problem 3.11 Modify assembly code shown signed division computes theunsigned quotient remainder numbers xandyand stores results stack. Practice Problem 3.12 Consider following C function prototype, num_t data type declared using typedef : void store_prod(num_t *dest, unsigned x, num_t y) { *dest = x*y; } gccgenerates following assembly code implementing body compu- tation: dest %ebp+ 8 ,xa %ebp+12, %ebp+16 1 movl 12(%ebp), %eax 2 movl 20(%ebp), %ecx 3 imull %eax, %ecx 4 mull 16(%ebp) 5 leal (%ecx,%edx), %edx 6 movl 8(%ebp), %ecx 7 movl %eax, (%ecx) 8 movl %edx, 4(%ecx) 1. instruction called cdqin Intel documentation, one cases ATT-format name instruction bears relation Intel name.Section 3.6 Control 185 Observe code requires two memory reads fetch argument y(lines 2 4), two multiplies (lines 3 4), two memory writes store result(lines 7 8). A. data type num_t ? B. Describe algorithm used compute product argue correct. 3.6 Control far, considered behavior straight-line code, instruc- tions follow one another sequence. constructs C, conditionals,loops, switches, require conditional execution, sequence opera- tions gets performed depends outcomes tests applied data.Machine code provides two basic low-level mechanisms implementing condi-tional behavior: tests data values either alters control ﬂow thedata ﬂow based result tests. Data-dependent control ﬂow general common approach implementing conditional behavior, examine ﬁrst. Normally,both statements C instructions machine code executed sequentially , order appear program. execution order set machine-code instructions altered jump instruction, indicating control pass part program, possibly contingent resultof test. compiler must generate instruction sequences build uponthis low-level mechanism implement control constructs C. presentation, ﬁrst cover machine-level mechanisms show different control constructs C implemented them. Wethen return use conditional data transfer implement data-dependentbehavior. 3.6.1 Condition Codes addition integer registers, CPU maintains set single-bit condition code registers describing attributes recent arithmetic logical opera- tion. registers tested perform conditional branches. mostuseful condition codes are: CF: Carry Flag. recent operation generated carry signiﬁcant bit. Used detect overﬂow unsigned operations. ZF: Zero Flag. recent operation yielded zero. SF: Sign Flag. recent operation yielded negative value. OF: Overﬂow Flag. recent operation caused two’s-complement overﬂow—either negative positive.186 Chapter 3 Machine-Level Representation Programs Instruction Based Description cmp S2,S1S1-S2 Compare cmpb Compare byte cmpw Compare word cmpl Compare double word test S2,S1S1&S2 Test testb Test byte testw Test word testl Test double word Figure 3.10 Comparison test instructions. instructions set condition codes without updating registers. example, suppose used one add instructions perform equivalent C assignment t=a+b , variables a,b, tare integers. condition codes would set according following C expressions: CF:(unsigned ) < (unsigned) Unsigned overﬂow ZF:(t == 0) Zero SF:( t<0 ) Negative OF:( a<0= =b<0 )& &( t<0! =a<0 ) Signed overﬂow Theleal instruction alter condition codes, since intended used address computations. Otherwise, instructions listed inFigure 3.7 cause condition codes set. logical operations, asXor, carry overﬂow ﬂags set 0. shift operations, carry ﬂag set last bit shifted out, overﬂow ﬂag set 0. reasonsthat delve into, incand decinstructions set overﬂow zero ﬂags, leave carry ﬂag unchanged. addition setting condition codes instructions Figure 3.7, two instruction classes (having 8, 16, 32-bit forms) set conditioncodes without altering registers; listed Figure 3.10. Thecmpinstructions set condition codes according differences two operands. behave way subinstructions, except set condition codes without updating destinations. ATT format,the operands listed reverse order, making code difﬁcult read. instructions set zero ﬂag two operands equal. ﬂags used determine ordering relations two operands. test instructions behave manner instructions, except set condition codes without altering destinations. Typically, sameoperand repeated (e.g., testl %eax,%eax see whether %eax negative, zero, positive), one operands mask indicating bits betested.Section 3.6 Control 187 Instruction Synonym Effect Set condition sete setz D←ZF Equal / zero setne setnz D←~ZF equal / zero sets DD ←SF Negative setns DD ←~SF Nonnegative setg setnle D←~(SF ^ )& ~ZF Greater (signed >) setge setnl D←~(SF ^ ) Greater equal (signed >=) setl setnge D←SF ^ Less (signed <) setle setng D←(SF ^ )|Z F Less equal (signed <=) seta setnbe D←~CF & ~ZF (unsigned >) setae setnb D←~CF equal (unsigned >=) setb setnae D←CF (unsigned <) setbe setna D←CF | ZF equal (unsigned <=) Figure 3.11 setinstructions. instruction sets single byte 0 1 based combination condition codes. instructions “synonyms,” i.e., alternate names machine instruction. 3.6.2 Accessing Condition Codes Rather reading condition codes directly, three common ways using condition codes: (1) set single byte 0 1 dependingon combination condition codes, (2) conditionally jump tosome part program, (3) conditionally transfer data. theﬁrst case, instructions described Figure 3.11 set single byte 0 1depending combination condition codes. refer entireclass instructions setinstructions; differ one another based combinations condition codes consider, indicated differentsufﬁxes instruction names. important recognize sufﬁxes forthese instructions denote different conditions different operand sizes. Forexample, instructions setl andsetb denote “set less” “set below,” “set long word” “set byte.” Asetinstruction either one eight single-byte register elements (Figure 3.2) single-byte memory location destination, setting byteto either 0 1. generate 32-bit result, must also clear high-order 24bits. typical instruction sequence compute C expression a<b , andbare type int, proceeds follows: ai si n %edx,bi si n %eax 1 cmpl %eax, %edx Compare a:b 2 setl %al Set low order byte %eax 0 1 3 movzbl %al, %eax Set remaining bytes %eax 0 Themovzbl instruction clears high-order 3 bytes %eax .188 Chapter 3 Machine-Level Representation Programs underlying machine instructions, multiple possible names, list “synonyms.” example, setg (for “set greater”) andsetnle (for “set less equal”) refer machine instruction. Compilers disassemblers make arbitrary choices names use. Although arithmetic logical operations set condition codes, de- scriptions different setinstructions apply case comparison instruction executed, setting condition codes according com-putation = a-b . speciﬁcally, let a,b, andtbe integers represented two’s-complement form variables a,b, t, respectively, t=a- wb, wdepends sizes associated aandb. Consider sete , “set equal” instruction. a=b, havet=0, hence zero ﬂag indicates equality. Similarly, consider testing signed comparison setl , “set less,” instruction. overﬂow occurs (indicated OFset 0), a<b a-t wb< 0, indicated SFset 1, a≥bwhen a-t wb≥0, indicated SFset 0. hand, overﬂow occurs, a<b a-t wb>0 (positive overﬂow) a>b a-t wb<0 (negative overﬂow). cannot overﬂow a=b. Thus, OFis set 1, a<b SFis set 0. Combining cases, Exclusive-Or overﬂow sign bits provides test whether a<b . signed comparison tests based combinations SF ^ andZF. testing unsigned comparisons, let aandbbe integers represented unsigned form variables aandb. performing computation = a-b , carry ﬂag set cmp instruction a−b<0, unsigned comparisons use combinations carry zero ﬂags. important note machine code distinguishes signed unsigned values. Unlike C, associate data type programvalue. Instead, mostly uses instructions two cases, becausemany arithmetic operations bit-level behavior unsigned two’s-complement arithmetic. circumstances require different instructions handle signed unsigned operations, using different versions ofright shifts, division multiplication instructions, different combinationsof condition codes. Practice Problem 3.13 following C code int comp(data_t a, data_t b) { return COMP b; } shows general comparison arguments aandb, set data type arguments declaring data_t typedef declaration, set comparison deﬁning COMP #define declaration. Suppose ais in%edx andbis in%eax . following instruction sequences, determine data types data_t comparisons COMP couldSection 3.6 Control 189 cause compiler generate code. (There multiple correct answers; list all.) A.cmpl %eax, %edx setl %al B.cmpw %ax, %dx setge %al C.cmpb %al, %dlsetb %al D.cmpl %eax, %edxsetne %al Practice Problem 3.14 following C code int test(data_t a) { return TEST 0; } shows general comparison argument aand 0, set data type argument declaring data_t typedef , nature comparison declaring TEST #define declaration. following instruction sequences, determine data types data_t comparisons TEST could cause compiler generate code. (There multiple correct answers; list correct ones.) A.testl %eax, %eax setne %al B.testw %ax, %ax sete %al C.testb %al, %al setg %al D.testw %ax, %ax seta %al 3.6.3 Jump Instructions Encodings normal execution, instructions follow order listed. jump instruction cause execution switch completely new position program. jump destinations generally indicated in190 Chapter 3 Machine-Level Representation Programs Instruction Synonym Jump condition Description jmp Label 1 Direct jump jmp * Operand 1 Indirect jump je Label jz ZF Equal / zero jne Label jnz ~ZF equal / zero js Label SF Negative jns Label ~SF Nonnegative jg Label jnle ~ (SF ^ )& ~ZF Greater (signed >) jge Label jnl ~ (SF ^ ) Greater equal (signed >=) jl Label jnge SF ^ Less (signed <) jle Label jng (SF ^ )|Z F Less equal (signed <=) ja Label jnbe ~CF & ~ZF (unsigned >) jae Label jnb ~CF equal (unsigned >=) jb Label jnae CF (unsigned <) jbe Label jna CF | ZF equal (unsigned <=) Figure 3.12 jump instructions. instructions jump labeled destination jump condition holds. instructions “synonyms,” alternate namesfor machine instruction. assembly code label . Consider following (very contrived) assembly-code sequence: 1 movl $0,%eax Set %eax 0 2 jmp .L1 Goto .L1 3 movl (%eax),%edx Null pointer dereference 4.L1: 5 popl %edx instruction jmp .L1 cause program skip movl instruc- tion instead resume execution popl instruction. generating object-code ﬁle, assembler determines addresses labeled instruc-tions encodes jump targets (the addresses destination instructions) part jump instructions. Figure 3.12 shows different jump instructions. jmpinstruction jumps unconditionally. either direct jump, jump target encoded part instruction, indirect jump, jump target read register memory location. Direct jumps written assembly givinga label jump target, e.g., label “ .L1” code shown. Indirect jumps written using ‘ *’ followed operand speciﬁer using one formats described Section 3.4.1. examples, instruction jmp *%eax uses value register %eax jump target, instruction jmp *(%eax)Section 3.6 Control 191 reads jump target memory, using value %eax read address. remaining jump instructions table conditional —they either jump continue executing next instruction code sequence, dependingon combination condition codes. names instructionsand conditions jump match setinstructions (see Figure 3.11). setinstructions, underlying machine instructions multiple names. Conditional jumps direct. Although concern detailed format machine code, understanding targets jump instructions encoded becomeimportant study linking Chapter 7. addition, helps inter-preting output disassembler. assembly code, jump targets writtenusing symbolic labels. assembler, later linker, generate properencodings jump targets. several different encodings jumps,but commonly used ones PC relative . is, encode difference address target instruction address theinstruction immediately following jump. offsets encoded using 1,2, 4 bytes. second encoding method give “absolute” address, using 4bytes directly specify target. assembler linker select appropriateencodings jump destinations. example PC-relative addressing, following fragment assembly code generated compiling ﬁle silly.c . contains two jumps: jle instruction line 1 jumps forward higher address, jginstruction line 8 jumps back lower one. 1 jle .L2 <=, goto dest2 2.L5: dest1: 3 movl %edx, %eax 4 sarl %eax 5 subl %eax, %edx 6 leal (%edx,%edx,2), %edx 7 testl %edx, %edx 8 jg .L5 >, goto dest1 9.L2: dest2: 10 movl %edx, %eax disassembled version “ .o” format generated assembler follows: 1 8: 7e 0d jle 17 <silly+0x17> Target = dest2 2 a: 89 d0 mov %edx,%eax dest1: 3 c: d1 f8 sar %eax 4 e: 29 c2 sub %eax,%edx 5 10: 8d 14 52 lea (%edx,%edx,2),%edx 6 13: 85 d2 test %edx,%edx 7 15: 7f f3 jg <silly+0xa> Target = dest1 8 17: 89 d0 mov %edx,%eax dest2:192 Chapter 3 Machine-Level Representation Programs annotations generated disassembler right, jump targets indicated 0x17 jump instruction line 1 0xa jump instruction line 7. Looking byte encodings instructions, however,we see target ﬁrst jump instruction encoded (in second byte)as0xd(decimal 13). Adding 0xa(decimal 10), address following instruction, get jump target address 0x17 (decimal 23), address instruction line 8. Similarly, target second jump instruction encoded 0xf3 (dec- imal−13) using single-byte, two’s-complement representation. Adding 0x17 (decimal 23), address instruction line 8, get 0xa (decimal 10), address instruction line 2. examples illustrate, value program counter perform- ing PC-relative addressing address instruction following jump, notthat jump itself. convention dates back early implementations, processor would update program counter ﬁrst step executing aninstruction. following shows disassembled version program linking: 1 804839c: 7e 0d jle 80483ab <silly+0x17> 2 804839e: 89 d0 mov %edx,%eax 3 80483a0: d1 f8 sar %eax 4 80483a2: 29 c2 sub %eax,%edx 5 80483a4: 8d 14 52 lea (%edx,%edx,2),%edx 6 80483a7: 85 d2 test %edx,%edx 7 80483a9: 7f f3 jg 804839e <silly+0xa> 8 80483ab: 89 d0 mov %edx,%eax instructions relocated different addresses, encodings jump targets lines 1 7 remain unchanged. using PC-relativeencoding jump targets, instructions compactly encoded (requiringjust 2 bytes), object code shifted different positions memorywithout alteration. Practice Problem 3.15 following excerpts disassembled binary, information hasbeen replaced Xs. Answer following questions instructions. A. target jeinstruction below? (You don’t need know anything call instruction here.) 804828f: 74 05 je XXXXXXX 8048291: e8 1e 00 00 00 call 80482b4 B. target jbinstruction below? 8048357: 72 e7 jb XXXXXXX 8048359: c6 05 10 a0 04 08 01 movb $0x1,0x804a010Section 3.6 Control 193 C. address movinstruction? XXXXXXX: 74 12 je 8048391 XXXXXXX: b8 00 00 00 00 mov $0x0,%eax D. code follows, jump target encoded PC-relative form 4- byte, two’s-complement number. bytes listed least signiﬁcant tomost, reﬂecting little-endian byte ordering IA32. addressof jump target? 80482bf: e9 e0 ff ff ff jmp XXXXXXX 80482c4: 90 nop E. Explain relation annotation right byte coding left. 80482aa: ff 25 fc 9f 04 08 jmp *0x8049ffc implement control constructs C via conditional control transfer, compiler must use different types jump instructions seen. Wewill go common constructs, starting simple conditionalbranches, consider loops switch statements. 3.6.4 Translating Conditional Branches general way translate conditional expressions statements C machine code use combinations conditional unconditional jumps.(As alternative, see Section 3.6.6 conditionals beimplemented conditional transfers data rather control.) example,Figure 3.13(a) shows C code function computes absolute value difference two numbers. 2gcc generates assembly code shown Figure 3.13(c). created version C, called gotodiff (Figure 3.13(b)), closely follows control ﬂow assembly code. uses goto statement C, similar unconditional jump assembly code. Thestatement goto x_ge_y line 4 causes jump label x_ge_y (since occurs whenx≥y) line 7, skipping computation y-xon line 5. test fails, program computes result y-xand transfers unconditionally end code. Using goto statements generally considered bad programming style, since use make code difﬁcult read debug. use themin presentation way construct C programs describe controlﬂow assembly-code programs. call style programming “goto code.” assembly-code implementation ﬁrst compares two operands (line 3), setting condition codes. comparison result indicates xis greater 2. Actually, return negative value one subtractions overﬂows. interest demonstrate machine code, implement robust code.194 Chapter 3 Machine-Level Representation Programs (a) Original C code 1int absdiff(int x, int y) { 2 (x < y) 3 retur ny-x ; 4 else 5 retur nx-y ; 6}(b) Equivalent goto version 1int gotodiff(int x, int y) { 2 int result; 3 (x >= y) 4 goto x_ge_y; 5 result = - x; 6 goto done; 7 x_ge_y: 8 resul t=x-y ; 9 done: 10 return result; 11 } (c) Generated assembly code xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %edx Get x 2 movl 12(%ebp), %eax Get 3 cmpl %eax, %edx Compare x:y 4 jge .L2 >= goto x_ge_y 5 subl %edx, %eax Compute result = y-x 6 jmp .L3 Gotodone 7.L2: x_ge_y: 8 subl %eax, %edx Compute result = x-y 9 movl %edx, %eax Set result return value 10 .L3: done: Begin completion code Figure 3.13 Compilation conditional statements. C procedure absdiff (part (a)) contains if-else statement. generated assembly code shown (part (c)), alongwith C procedure gotodiff (part (b)) mimics control ﬂow assembly code. stack set-up completion portions assembly code omitted. equal y, jumps block code computes x-y (line 8). Otherwise, continues execution code computes y-x(line 5). cases, computed result stored register %eax , program reaches line 10, point executes stack completion code (not shown). general form if-else statement C given template ( test-expr ) then-statement else else-statement test-expr integer expression evaluates either 0 (interpreted meaning “false”) nonzero value (interpreted meaning “true”). oneof two branch statements ( then-statement orelse-statement ) executed.Section 3.6 Control 195 general form, assembly implementation typically adheres following form, use C syntax describe control ﬂow: t= test-expr ; (!t) goto false; then-statementgoto done; false: else-statement done: is, compiler generates separate blocks code then-statement else-statement . inserts conditional unconditional branches make sure correct block executed. Practice Problem 3.16 given C code 1void cond(int a, int *p) 2{ 3 f( p& &a>0 ) 4 *p += a; 5} gccgenerates following assembly code body function: a%ebp+ 8 ,pa %ebp+12 1 movl 8(%ebp), %edx 2 movl 12(%ebp), %eax 3 testl %eax, %eax 4 je .L3 5 testl %edx, %edx 6 jle .L3 7 addl %edx, (%eax) 8.L3: A. Write goto version C performs computation mimics control ﬂow assembly code, style shown Figure 3.13(b).You might ﬁnd helpful ﬁrst annotate assembly code donein examples. B. Explain assembly code contains two conditional branches, even though C code one ifstatement.196 Chapter 3 Machine-Level Representation Programs Practice Problem 3.17 alternate rule translating ifstatements goto code follows: t= test-expr ; (t) goto true; else-statement goto done; true: then-statement done: A. Rewrite goto version absdiff based alternate rule. B. think reasons choosing one rule other? Practice Problem 3.18 Starting C code form 1int test(int x, int y) { 2 int val = ; 3 ( ){ 4 ( ) 5 val = ; 6 else 7 val = ; 8 } else ( ) 9 val = ; 10 return val; 11 } gccgenerates following assembly code: xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %eax 2 movl 12(%ebp), %edx 3 cmpl $-3, %eax 4 jge .L2 5 cmpl %edx, %eax 6 jle .L3 7 imull %edx, %eax 8 jmp .L4 9.L3: 10 leal (%edx,%eax), %eax 11 jmp .L4 12 .L2:Section 3.6 Control 197 13 cmpl $2, %eax 14 jg .L5 15 xorl %edx, %eax 16 jmp .L4 17 .L5: 18 subl %edx, %eax 19 .L4: Fill missing expressions C code. make code ﬁt C code template, need undo reordering computationsdone gcc. 3.6.5 Loops C provides several looping constructs—namely, do-while ,while , for.N corresponding instructions exist machine code. Instead, combinations condi-tional tests jumps used implement effect loops. compilers generate loop code based do-while form loop, even though form relatively uncommon actual programs. loops transformed do- form compiled machine code. study translation loops progression, starting do-while working toward ones complex implementations. Do-While Loops general form do-while statement follows: body-statementwhile ( test-expr ); effect loop repeatedly execute body-statement , evaluate test-expr , continue loop evaluation result nonzero. Observe body- statement executed least once. general form translated conditionals goto statements follows: loop: body-statement t= test-expr ; (t) goto loop; is, iteration program evaluates body statement test expression. test succeeds, go back another iteration. example, Figure 3.14(a) shows implementation routine com- pute factorial argument, written n!, do-while loop. function computes proper value n>0.198 Chapter 3 Machine-Level Representation Programs (a) C code 1int fact_do(int n) 2{ 3 int result = 1; 4 { 5 result *= n; 6 n = n-1; 7 } (n > 1); 8 return result; 9}(c) Corresponding assembly-language code Argument: n %ebp+8 Registers: n %edx, result %eax 1 movl 8(%ebp), %edx Get n 2 movl $1, %eax Set result = 1 3.L2: loop: 4 imull %edx, %eax Compute result *= n 5 subl $1, %edx Decrement n 6 cmpl $1, %edx Compare n:1 7 jg .L2 >, goto loop Return result (b) Register usage Register Variable Initially %eax result 1 %edx n n Figure 3.14 Code do-while version factorial program. C code, generated assembly code, table register usage shown. Practice Problem 3.19 A. maximum value nfor represent n! 32-bit int? B. 64-bit long long int ? assembly code shown Figure 3.14(c) shows standard implementation ado-while loop. Following initialization register %edx hold nand%eax hold result , program begins looping. ﬁrst executes body loop, consisting updates variables result andn(lines 4–5). tests whether n>1, and, so, jumps back beginning loop. see conditional jump (line 7) key instruction implementing loop. Itdetermines whether continue iterating exit loop. Determining registers used program values chal- lenging, especially loop code. shown mapping Figure 3.14.In case, mapping fairly simple determine: see ngetting loaded register %edx line 1, getting decremented line 5, tested line 6. therefore conclude register holds n. see register %eax getting initialized 1 (line 2), updated multiplication line 4. Furthermore, since %eax used return function value, often chosen hold program values returned. therefore conclude %eax corresponds program value result .Section 3.6 Control 199 Aside Reverse engineering loops key understanding generated assembly code relates original source code ﬁnd mapping program values registers. task simple enough loop Figure 3.14, much challenging complex programs. C compiler often rearrange computations, variables C code counterpart machine code, new values introduced machine code exist source code. Moreover, often try minimize register usage mapping multiple program values onto single register. process described fact_do works general strategy reverse engineering loops. Look registers initialized loop, updated tested within loop, usedafter loop. provides clue combined solve puzzle. prepared forsurprising transformations, clearly cases compiler able optimizethe code, others hard explain compiler chose particular strategy. Inour experience, gccoften makes transformations provide performance beneﬁt even decrease code performance. Practice Problem 3.20 C code 1int dw_loop(int x, int y, int n) { 2 { 3 x+ =n ; 4 y* =n ; 5 n--; 6 } ((n > 0) && (y < n)); 7 return x; 8} gccgenerates following assembly code: xa %ebp+ 8 ,ya %ebp+12, n %ebp+16 1 movl 8(%ebp), %eax 2 movl 12(%ebp), %ecx 3 movl 16(%ebp), %edx 4.L2: 5 addl %edx, %eax 6 imull %edx, %ecx 7 subl $1, %edx 8 testl %edx, %edx 9 jle .L5 10 cmpl %edx, %ecx 11 jl .L2 12 .L5: A. Make table register usage, similar one shown Figure 3.14(b).200 Chapter 3 Machine-Level Representation Programs B. Identify test-expr body-statement C code, corresponding lines assembly code. C. Add annotations assembly code describing operation pro- gram, similar shown Figure 3.14(b). Loops general form statement follows: ( test-expr ) body-statement differs do-while test-expr evaluated loop potentially terminated ﬁrst execution body-statement . number ways translate loop machine code. One common approach, also used gcc, transform code do-while loop using conditional branch skip ﬁrst execution body needed: (! test-expr ) goto done; body-statement ( test-expr ); done: This, turn, transformed goto code t= test-expr ; (!t) goto done; loop: body-statement t= test-expr ; (t) goto loop; done: Using implementation strategy, compiler often optimize initial test, example determining test condition always hold. example, Figure 3.15 shows implementation factorial func- tion using loop (Figure 3.15(a)). function correctly computes 0! =1. adjacent function fact_while_goto (Figure 3.15(b)) C rendition assembly code generated gcc. Comparing code generated fact_while (Figure 3.15) fact_do (Figure 3.14), see nearly iden- tical. difference initial test (line 3) jump around loop(line 4). compiler closely followed template converting loop ado-while loop, translating loop goto code.Section 3.6 Control 201 (a) C code 1int fact_while(int n) 2{ 3 int result = 1; 4 (n > 1) { 5 result *= n; 6 n = n-1; 7 } 8 return result; 9}(b) Equivalent goto version 1int fact_while_goto(int n) 2{ 3 int result = 1; 4 (n <= 1) 5 goto done; 6 loop: 7 result *= n; 8 n = n-1; 9 (n > 1) 10 goto loop; 11 done: 12 return result; 13 } (c) Corresponding assembly-language code Argument: n %ebp+8 Registers: n %edx, result %eax 1 movl 8(%ebp), %edx Get n 2 movl $1, %eax Set result = 1 3 cmpl $1, %edx Compare n:1 4 jle .L7 <=, goto done 5.L10: loop: 6 imull %edx, %eax Compute result *= n 7 subl $1, %edx Decrement n 8 cmpl $1, %edx Compare n:1 9 jg .L10 >, goto loop 10 .L7: done: Return result Figure 3.15 C assembly code version factorial. Thefact_while_ goto function illustrates operation assembly code version. Practice Problem 3.21 C code 1int loop_while(int a, int b) 2{ 3 int result = 1; 4 (a < b) { 5 result *= (a+b); 6 a++; 7 } 8 return result; 9}202 Chapter 3 Machine-Level Representation Programs gccgenerates following assembly code: aa %ebp+ 8 ,ba %ebp+12 1 movl 8(%ebp), %ecx 2 movl 12(%ebp), %ebx 3 movl $1, %eax 4 cmpl %ebx, %ecx 5 jge .L11 6 leal (%ebx,%ecx), %edx 7 movl $1, %eax 8.L12: 9 imull %edx, %eax 10 addl $1, %ecx 11 addl $1, %edx 12 cmpl %ecx, %ebx 13 jg .L12 14 .L11: generating code, gcc makes interesting transformation that, effect, introduces new program variable. A. Register %edx initialized line 6 updated within loop line 11. Consider new program variable. Describe relates thevariables C code. B. Create table register usage function. C. Annotate assembly code describe operates.D. Write goto version function (in C) mimics assembly code program operates. Practice Problem 3.22 function, fun_a , following overall structure: int fun_a(unsigned x) { int val = 0; ( ){ ; } return ; } gccC compiler generates following assembly code: xa %ebp+8 1 movl 8(%ebp), %edx 2 movl $0, %eax 3 testl %edx, %edxSection 3.6 Control 203 4 je .L7 5.L10: 6 xorl %edx, %eax 7 shrl %edx Shift right 1 8 jne .L10 9.L7: 10 andl $1, %eax Reverse engineer operation code following: A. Use assembly-code version ﬁll missing parts C code. B. Describe English function computes. Loops general form forloop follows: ( init-expr ;test-expr ;update-expr ) body-statement C language standard states (with one exception, highlighted Problem 3.24) behavior loop identical following code, uses awhile loop: init-expr ; ( test-expr ){ body-statement update-expr ; } program ﬁrst evaluates initialization expression init-expr . enters loop ﬁrst evaluates test condition test-expr , exiting test fails, executes body loop body-statement , ﬁnally evaluates update expression update-expr . compiled form code based transformation do-while described previously, ﬁrst giving do-while form: init-expr ; (! test-expr ) goto done; { body-statement update-expr ; } ( test-expr ); done:204 Chapter 3 Machine-Level Representation Programs This, turn, transformed goto code init-expr ; t= test-expr ; (!t) goto done; loop: body-statement update-expr ; t= test-expr ; (t) goto loop; done: example, consider factorial function written forloop: 1int fact_for(int n) 2{ 3 int i; 4 int result = 1; 5 (i = 2; <= n; i++) 6 result *= i; 7 return result; 8} shown, natural way writing factorial function loop multiply factors 2 n, function quite different code showed using either ado-while loop. identify different components loop code follows: init-expr i=2 test-expr i< =n update-expr i++ body-statement result *= i; Substituting components template shown yields following version goto code: 1int fact_for_goto(int n) 2{ 3 n ti=2 ; 4 int result = 1; 5 (!(i <= n)) 6 goto done; 7 loop: 8 result *= i; 9 i++;Section 3.6 Control 205 10 (i <= n) 11 goto loop; 12 done: 13 return result; 14 } Indeed, close examination assembly code produced gccclosely follows template: Argument: n %ebp+8 Registers: n %ecx,ii n %edx, result %eax 1 movl 8(%ebp), %ecx Get n 2 movl $2, %edx Set 2 (init) 3 movl $1, %eax Set result 1 4 cmpl $1, %ecx Compare n:1 (!test) 5 jle .L14 <=, goto done 6.L17: loop: 7 imull %edx, %eax Compute result *= (body) 8 addl $1, %edx Increment (update) 9 cmpl %edx, %ecx Compare n:i (test) 10 jge .L17 >=, goto loop 11 .L14: done: see presentation three forms loops C— do-while , , for—can translated single strategy, generating code con- tains one conditional branches. Conditional transfer control providesthe basic mechanism translating loops machine code. Practice Problem 3.23 function fun_b following overall structure: int fun_b(unsigned x) { int val = 0; int i; ( ; ; ){ } return val; } gccC compiler generates following assembly code: xa %ebp+8 1 movl 8(%ebp), %ebx 2 movl $0, %eax 3 movl $0, %ecx 4.L13:206 Chapter 3 Machine-Level Representation Programs 5 leal (%eax,%eax), %edx 6 movl %ebx, %eax 7 andl $1, %eax 8 orl %edx, %eax 9 shrl %ebx Shift right 1 10 addl $1, %ecx 11 cmpl $32, %ecx 12 jne .L13 Reverse engineer operation code following: A. Use assembly-code version ﬁll missing parts C code. B. Describe English function computes. Practice Problem 3.24 Executing continue statement C causes program jump end current loop iteration. stated rule translating forloop loop needs reﬁnement dealing continue statements. example, consider following code: /* Example loop using continue statement */ /* Sum even numbers 0 9 */ int sum = 0; int i; (i = 0; < 10; i++) { (i & 1) continue; sum += i; } A. would get naively applied rule translating forloop loop? would wrong code? B. could replace continue statement goto statement ensure loop correctly duplicates behavior forloop? 3.6.6 Conditional Move Instructions conventional way implement conditional operations condi- tional transfer control , program follows one execution path condition holds another not. mechanism simple andgeneral, inefﬁcient modern processors. alternate strategy conditional transfer data. approach computes outcomes conditional operation, selects one based onwhether condition holds. strategy makes sense restrictedcases, implemented simple conditional move instruction better matched performance characteristics modern processors.Section 3.6 Control 207 examine strategy implementation recent versions IA32 processors. Starting PentiumPro 1995, recent generations IA32 processors conditional move instructions either nothing copy valueto register, depending values condition codes. years, theseinstructions largely unused. default settings, gccdid gen- erate code used them, would prevent backward compatibility,even though almost x86 processors manufactured Intel competitors since 1997 supported instructions. recently, systems runningon processors certain support conditional moves, Intel-basedApple Macintosh computers (introduced 2006) 64-bit versions Linuxand Windows, gccwill generate code using conditional moves. giving special command-line parameters machines, indicate gccthat tar- get machine supports conditional move instructions. example, Figure 3.16(a) shows variant form function absdiff used Figure 3.13 illustrate conditional branching. version uses conditional expression rather conditional statement illustrate concepts behind conditional data transfers clearly, fact gcc (a) Original C code 1int absdiff(int x, int y) { 2 retur nx<y?y - x: x-y; 3}(b) Implementation using conditional assignment 1int cmovdiff(int x, int y) { 2 int tval = y-x; 3 int rval = x-y; 4 n tt e t=x<y ; 5 /* Line requires 6 single instruction: */ 7 (test) rval = tval; 8 return rval; 9} (c) Generated assembly code xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %ecx Get x 2 movl 12(%ebp), %edx Get 3 movl %edx, %ebx Copy 4 subl %ecx, %ebx Compute y-x 5 movl %ecx, %eax Copy x 6 subl %edx, %eax Compute x-y set return value 7 cmpl %edx, %ecx Compare x:y 8 cmovl %ebx, %eax <, replace return value y-x Figure 3.16 Compilation conditional statements using conditional assignment. C function absdiff (a) contains conditional expression. generated assembly code shown (c), along wit h C function cmovdiff (b) mimics operation assembly code. stack set-up completion portions assembly code havebeen omitted.208 Chapter 3 Machine-Level Representation Programs generates identical code version version Figure 3.13. compile giving gccthe command-line option ‘ -march=i686 ’,3we generate assembly code shown Figure 3.16(c), approximate form shownby C function cmovdiff shown Figure 3.16(b). Studying C version, see computes y-xandx-y, naming tval andrval , respec- tively. tests whether xis less y, so, copies tval torval returning rval . assembly code Figure 3.16(c) follows logic. key single cmovl instruction (line 8) assembly code implements conditional assignment (line 7) cmovdiff . instruction syntax mov instruction, except performs data movement speciﬁed condition holds. (The sufﬁx ‘ l’i ncmovl stands “less,” “long.”) understand code based conditional data transfers outperform code based conditional control transfers (as Figure 3.13), must understandsomething modern processors operate. see Chapters 4and 5, processors achieve high performance pipelining , instruc- tion processed via sequence stages, performing one small portion ofthe required operations (e.g., fetching instruction memory, determiningthe instruction type, reading memory, performing arithmetic operation,writing memory, updating program counter.) approach achieveshigh performance overlapping steps successive instructions, suchas fetching one instruction performing arithmetic operations pre-vious instruction. requires able determine sequence ofinstructions executed well ahead time order keep pipeline full instructions executed. machine encounters conditional jump(referred “branch”), often cannot determine yet whether jump followed. Processors employ sophisticated branch prediction logic try guess whether jump instruction followed. long guessreliably (modern microprocessor designs try achieve success rates orderof 90%), instruction pipeline kept full instructions. Mispredicting ajump, hand, requires processor discard much work ithas already done future instructions begin ﬁlling pipeline in-structions starting correct location. see, misprediction canincur serious penalty, say, 20–40 clock cycles wasted effort, causing seriousdegradation program performance. example, ran timings absdiff function Intel Core i7 processor using methods implementing conditional operation. atypical application, outcome test x<y highly unpredictable, even sophisticated branch prediction hardware guess correctly onlyaround 50% time. addition, computations performed thetwo code sequences require single clock cycle. consequence, branchmisprediction penalty dominates performance function. IA32code conditional jumps, found function requires around 13 clock 3. gccterminology, Pentium considered model “586” PentiumPro considered model “686” x86 line.Section 3.6 Control 209 cycles per call branching pattern easily predictable, around 35 clock cycles per call branching pattern random. inferthat branch misprediction penalty around 44 clock cycles. means timerequired function ranges around 13 57 cycles, depending onwhether branch predicted correctly. Aside determine penalty? Assume probability misprediction p, time execute code without misprediction TOK, misprediction penalty TMP. average time execute code function pis Tavg(p)=(1−p)T OK+p(T OK+TMP)=TOK+pTMP. given TOKandTran, average time p=0.5, want determine TMP. Substituting equation, get Tran=Tavg(0.5)= TOK+0.5TMP, therefore TMP=2(Tran−TMP). So, TOK=13 Tran=35, get TMP=44. hand, code compiled using conditional moves requires around 14 clock cycles regardless data tested. ﬂow controldoes depend data, makes easier processor keep itspipeline full. Practice Problem 3.25 Running Pentium 4, code required around 16 cycles branchingpattern highly predictable, around 31 cycles pattern random. A. approximate miss penalty? B. many cycles would function require branch mispre- dicted? Figure 3.17 illustrates conditional move instructions added IA32 instruction set introduction PentiumPro microprocessor andsupported IA32 processors manufactured Intel competitorssince 1997. instructions two operands: source register mem-ory location S, destination register R. different set(Section 3.6.2) jump instructions (Section 3.6.3), outcome instructions dependson values condition codes. source value read either mem-ory source register, copied destination speciﬁedcondition holds. IA32, source destination values 16 32 bits long. Single- byte conditional moves supported. Unlike unconditional instructions, operand length explicitly encoded instruction name (e.g., movw andmovl ), assembler infer operand length conditional move instruction name destination register, instructionname used operand lengths. Unlike conditional jumps, processor execute conditional move in- structions without predict outcome test. processor simply210 Chapter 3 Machine-Level Representation Programs Instruction Synonym Move condition Description cmove S,R cmovz ZF Equal / zero cmovne S,R cmovnz ~ZF equal / zero cmovs S,R SF Negative cmovns S,R ~SF Nonnegative cmovg S,R cmovnle ~ (SF ^ )& ~ZF Greater (signed >) cmovge S,R cmovnl ~ (SF ^ ) Greater equal (signed >=) cmovl S,R cmovnge SF ^ Less (signed <) cmovle S,R cmovng (SF ^ )|Z F Less equal (signed <=) cmova S,R cmovnbe ~CF & ~ZF (unsigned >) cmovae S,R cmovnb ~CF equal (Unsigned >=) cmovb S,R cmovnae CF (unsigned <) cmovbe S,R cmovna CF | ZF equal (unsigned <=) Figure 3.17 conditional move instructions. instructions copy source value Sto destination Rwhen move condition holds. instructions “synonyms,” alternate names machine instruction. reads source value (possibly memory), checks condition code, either updates destination register keeps same. explorethe implementation conditional moves Chapter 4. understand conditional operations implemented via condi- tional data transfers, consider following general form conditional expressionand assignment: v= test-expr ?then-expr :else-expr ; traditional IA32, compiler generates code form shown following abstract code: (! test-expr ) goto false; v= true-expr ; goto done; false: v= else-expr ; done: code contains two code sequences—one evaluating then-expr one evalu- ating else-expr . combination conditional unconditional jumps used ensure one sequences evaluated.Section 3.6 Control 211 code based conditional move, then-expr else-expr evaluated, ﬁnal value chosen based evaluation test-expr . described following abstract code: vt = then-expr ; v= else-expr ; t= test-expr ; (t) v = vt; ﬁnal statement sequence implemented conditional move— value vtis copied vonly test condition tholds. conditional expressions compiled using conditional moves. signiﬁcantly, abstract code shown evaluates then-expr else-expr regardless test outcome. one two expressions could possibly generate error condition side effect, could lead invalidbehavior. illustration, consider following C function: int cread(int *xp) { return (xp ? *xp : 0); } ﬁrst, seems like good candidate compile using conditional move read value designated pointer xp, shown following assembly code: Invalid implementation function cread xp register %edx 1 movl $0, %eax Set 0 return value 2 testl %edx, %edx Test xp 3 cmovne (%edx), %eax !0, dereference xp get return value implementation invalid, however, since dereferencing xpby cmovne instruction (line 3) occurs even test fails, causing null pointer dereferencing error. Instead, code must compiled using branching code. similar case holds either two branches causes side effect, illustrated following function: 1/* Global variable */ 2int lcount = 0; 3int absdiff_se(int x, int y) { 4 retur nx<y? (lcount++, y-x) : x-y; 5} function increments global variable lcount part then-expr . Thus, branching code must used ensure side effect occurs testcondition holds. Using conditional moves also always improve code efﬁciency. example, either then-expr else-expr evaluation requires signiﬁcant212 Chapter 3 Machine-Level Representation Programs computation, effort wasted corresponding condition hold. Compilers must take account relative performance wastedcomputation versus potential performance penalty due branch mispre-diction. truth, really enough information make decisionreliably; example, know well branches follow pre-dictable patterns. experiments gccindicate uses conditional moves two expressions computed easily, example, withsingle add instructions. experience, gccuses conditional control transfers even many cases cost branch misprediction would exceed evenmore complex computations. Overall, then, see conditional data transfers offer alternative strategy conditional control transfers implementing conditional operations.They used restricted cases, cases fairly common andprovide much better match operation modern processors. Practice Problem 3.26 following C function, left deﬁnition operation OPincomplete: #define OP /* Unknown operator */ int arith(int x) { return x OP 4; } compiled, gccgenerates following assembly code: Register: x %edx 1 leal 3(%edx), %eax 2 testl %edx, %edx 3 cmovns %edx, %eax 4 sarl $2, %eax Return value %eax A. operation OP? B. Annotate code explain works. Practice Problem 3.27 Starting C code form 1int test(int x, int y) { 2 int val = ; 3 ( ){ 4 ( ) 5 val = ; 6 else 7 val = ;Section 3.6 Control 213 8 } else ( ) 9 val = ; 10 return val; 11 } gcc, command-line setting ‘ -march=i686 ’, generates following as- sembly code: xa %ebp+ 8 ,ya %ebp+12 1 movl 8(%ebp), %ebx 2 movl 12(%ebp), %ecx 3 testl %ecx, %ecx 4 jle .L2 5 movl %ebx, %edx 6 subl %ecx, %edx 7 movl %ecx, %eax 8 xorl %ebx, %eax 9 cmpl %ecx, %ebx 10 cmovl %edx, %eax 11 jmp .L4 12 .L2: 13 leal 0(,%ebx,4), %edx 14 leal (%ecx,%ebx), %eax 15 cmpl $-2, %ecx 16 cmovge %edx, %eax 17 .L4: Fill missing expressions C code. 3.6.7 Switch Statements Aswitch statement provides multi-way branching capability based value integer index. particularly useful dealing testswhere large number possible outcomes. makethe C code readable, also allow efﬁcient implementation using adata structure called jump table . jump table array entry iis address code segment implementing action program take whenthe switch index equals i. code performs array reference jump table using switch index determine target jump instruction. Theadvantage using jump table long sequence if-else statements time taken perform switch independent number switch cases. gccselects method translating switch statement based number cases sparsity case values. Jump tables used anumber cases (e.g., four more) span small range values. Figure 3.18(a) shows example C switch statement. example number interesting features, including case labels span contiguous(a) Switch statement 1int switch_eg(int x, int n) { 2 int result = x; 3 4 switch (n) { 56 case 100: 7 result *= 13; 8 break; 9 10 case 102: 11 result += 10; 12 /* Fall */ 13 14 case 103: 15 result += 11; 16 break; 17 18 case 104: 19 case 106: 20 result *= result; 21 break; 2223 default: 24 result = 0; 25 } 26 27 return result; 28 }(b) Translation extended C 1int switch_eg_impl(int x, int n) { 2 /* Table code pointers */ 3 static void *jt[7] = { 4 &&loc_A, &&loc_def, &&loc_B, 5 &&loc_C, &&loc_D, &&loc_def, 6 &&loc_D 7 }; 8 9 unsigned inde x=n- 100; 10 int result; 11 12 (index > 6) 13 goto loc_def; 14 15 /* Multiway branch */ 16 goto *jt[index]; 17 18 loc_def: /* Default case*/ 19 result = 0; 20 goto done; 21 22 loc_C: /* Case 103 */ 23 result = x; 24 goto rest; 25 26 loc_A: /* Case 100 */ 27 resul t=x*1 3 ; 28 goto done; 29 30 loc_B: /* Case 102 */ 31 resul t=x+1 0 ; 32 /* Fall */ 33 34 rest: /* Finish case 103 */ 35 result += 11; 36 goto done; 37 38 loc_D: /* Cases 104, 106 */ 39 resul t=x*x ; 40 /* Fall */ 41 42 done: 43 return result; 44 } Figure 3.18 Switch statement example translation extended C. translation shows structure jump table jtand accessed. tables supported gcc extension C language.Section 3.6 Control 215 xa %ebp+ 8 ,na %ebp+12 1 movl 8(%ebp), %edx Get x 2 movl 12(%ebp), %eax Get n Set jump table access 3 subl $100, %eax Compute index = n-100 4 cmpl $6, %eax Compare index:6 5 ja .L2 >, goto loc_def 6 jmp *.L7(,%eax,4) Goto *jt[index] Default case 7.L2: loc_def: 8 movl $0, %eax result = 0; 9 jmp .L8 Gotodone Case 103 10 .L5: loc_C: 11 movl %edx, %eax result = x; 12 jmp .L9 Gotorest Case 100 13 .L3: loc_A: 14 leal (%edx,%edx,2), %eax result = x*3; 15 leal (%edx,%eax,4), %eax result = x+4*result 16 jmp .L8 Gotodone Case 102 17 .L4: loc_B: 18 leal 10(%edx), %eax result = x+10 Fall 19 .L9: rest: 20 addl $11, %eax result += 11; 21 jmp .L8 Gotodone Cases 104, 106 22 .L6: loc_D 23 movl %edx, %eax result = x 24 imull %edx, %eax result *= x Fall 25 .L8: done: Return result Figure 3.19 Assembly code switch statement example Figure 3.18. range (there labels cases 101 105), cases multiple labels (cases 104 106), cases fall cases (case 102) code case end break statement. Figure 3.19 shows assembly code generated compiling switch_eg . behavior code shown C procedure switch_eg_impl Figure 3.18(b). code makes use support provided gccfor jump tables,216 Chapter 3 Machine-Level Representation Programs extension C language. array jtcontains seven entries, address block code. locations deﬁned labels inthe code, indicated entries jtby code pointers, consisting labels preﬁxed ‘ &&.’ (Recall operator &creates pointer data value. making extension, authors gcc created new operator &&to create pointer code location.) recommend study C procedureswitch_eg_impl relates assembly code version. original C code cases values 100, 102–104, 106, switch variable ncan arbitrary int. compiler ﬁrst shifts range 0 6 subtracting 100 n, creating new program variable call index C version. simpliﬁes branching possibilities treating index unsigned value, making use fact negative numbers two’s-complement representation map large positive numbers unsignedrepresentation. therefore test whether index outside range 0–6 testing whether greater 6. C assembly code, areﬁve distinct locations jump to, based value index . are: loc_ A(identiﬁed assembly code .L3),loc_B (.L4),loc_C (.L5),loc_D (.L6), andloc_def (.L2), latter destination default case. labels identiﬁes block code implementing one case branches.In C assembly code, program compares index 6 jumps code default case greater. key step executing switch statement access code location jump table. occurs line 16 C code, goto statement references jump table jt. computed goto supported gccas extension C language. assembly-code version, similar operationoccurs line 6, jmpinstruction’s operand preﬁxed ‘ *’, indicating indirect jump, operand speciﬁes memory location indexed register%eax , holds value index . (We see Section 3.8 array references translated machine code.) C code declares jump table array seven elements, pointer code location. elements span values 0–6 index , corresponding values 100–106 n. Observe jump table handles duplicate cases simply code label ( loc_D ) entries 4 6, handles missing cases using label default case ( loc_def ) entries 1 5. assembly code, jump table indicated following declarations, added comments: 1 .section .rodata 2 .align 4 Align address multiple 4 3.L7: 4 .long .L3 Case 100: loc_A 5 .long .L2 Case 101: loc_def 6 .long .L4 Case 102: loc_B 7 .long .L5 Case 103: loc_CSection 3.6 Control 217 8 .long .L6 Case 104: loc_D 9 .long .L2 Case 105: loc_def 10 .long .L6 Case 106: loc_D declarations state within segment object-code ﬁle called “.rodata ” (for “Read-Only Data”), sequence seven “long” (4-byte) words, value word given instruction addressassociated indicated assembly code labels (e.g., .L3). Label .L7marks start allocation. address associated label serves basefor indirect jump (line 6). different code blocks (C labels loc_A loc_D andloc_def ) im- plement different branches switch statement. simply compute value result go end function. Similarly, assembly-code blocks compute value register %eax jump po- sition indicated label .L8 end function. code case labels 102 103 follow pattern, account way case 102falls 103 original C code. handled assembly codeandswitch_eg_impl separate destinations two cases ( loc_C andloc_B C, .L5 and.L4 assembly), blocks converge code increments result 11 (labeled rest C .L9 assembly). Examining code requires careful study, key point see use jump table allows efﬁcient way implement multiwaybranch. case, program could branch ﬁve distinct locations asingle jump table reference. Even switch statement hundreds cases, could handled single jump table access. Practice Problem 3.28 C function follows, omitted body switch statement. C code, case labels span contiguous range, cases hadmultiple labels. int switch2(int x) { int result = 0; switch (x) { /* Body switch statement omitted */ } return result; } compiling function, gccgenerates assembly code follows initial part procedure jump table. Variable xis initially offset 8 relative register %ebp .218 Chapter 3 Machine-Level Representation Programs xa %ebp+8 1 movl 8(%ebp), %eax Set jump table access 2 addl $2, %eax 3 cmpl $6, %eax 4 ja .L2 5 jmp *.L8(,%eax,4)Jump table switch2 1.L8: 2 .long .L3 3 .long .L2 4 .long .L4 5 .long .L5 6 .long .L6 7 .long .L6 8 .long .L7 Based information, answer following questions: A. values case labels switch statement body? B. cases multiple labels C code? Practice Problem 3.29 C function switcher general structure 1int switcher(int a, int b, int c) 2{ 3 int answer; 4 switch(a) { 5 case : /* Case */ 6 c= ; 7 /* Fall */ 8 case : /* Case B */ 9 answer = ; 10 break; 11 case : /* Case C */ 12 case : /* Case */ 13 answer = ; 14 break; 15 case : /* Case E */ 16 answer = ; 17 break; 18 default: 19 answer = ; 20 } 21 return answer; 22 } gccgenerates assembly code jump table shown Figure 3.20. Fill missing parts C code. Except ordering case labels CandD, one way ﬁt different cases template.Section 3.7 Procedures 219 aa %ebp+ 8 ,ba %ebp+12, c %ebp+16 1 movl 8(%ebp), %eax 2 cmpl $7, %eax 3 ja .L2 4 jmp *.L7(,%eax,4) 5.L2: 6 movl 12(%ebp), %eax 7 jmp .L8 8.L5: 9 movl $4, %eax 10 jmp .L8 11 .L6: 12 movl 12(%ebp), %eax 13 xorl $15, %eax 14 movl %eax, 16(%ebp) 15 .L3: 16 movl 16(%ebp), %eax 17 addl $112, %eax 18 jmp .L8 19 .L4: 20 movl 16(%ebp), %eax 21 addl 12(%ebp), %eax 22 sall $2, %eax 23 .L8:1.L7: 2 .long .L3 3 .long .L2 4 .long .L4 5 .long .L2 6 .long .L5 7 .long .L6 8 .long .L2 9 .long .L4 Figure 3.20 Assembly code jump table Problem 3.29. 3.7 Procedures procedure call involves passing data (in form procedure parame- ters return values) control one part program another. Inaddition, must allocate space local variables procedure entryand deallocate exit. machines, including IA32, provide simpleinstructions transferring control procedures. passing dataand allocation deallocation local variables handled manipulatingthe program stack. 3.7.1 Stack Frame Structure IA32 programs make use program stack support procedure calls. machine uses stack pass procedure arguments, store return information,to save registers later restoration, local storage. portion stackallocated single procedure call called stack frame . Figure 3.21 diagrams general structure stack frame. topmost stack frame delimited two pointers, register %ebp serving frame pointer , register %esp220 Chapter 3 Machine-Level Representation Programs Figure 3.21 Stack frame structure. stack used passingarguments, storingreturn information, forsaving registers, forlocal storage.. . . . . .Stack “bottom” Stack “top”Argument n Argument 1 Argument build areaReturn address Saved registers, local variables, temporariesSaved%ebp/H110014/H110014n /H110018 Stack pointer %esp/H110014 /H110024Frame pointer %ebpEarlier frames Caller’s frame Current frameIncreasing address serving stack pointer . stack pointer move procedure executing, hence information accessed relative frame pointer. Suppose procedure P(the caller ) calls procedure Q(the callee ). arguments toQare contained within stack frame P. addition, Pcalls Q, return address within Pwhere program resume execution returns Qis pushed onto stack, forming end P’s stack frame. stack frame Qstarts saved value frame pointer (a copy register %ebp ), followed copies saved register values.Section 3.7 Procedures 221 Procedure Qalso uses stack local variables cannot stored registers. occur following reasons: .There enough registers hold local data. .Some local variables arrays structures hence must accessedby array structure references. .The address operator ‘ &’ applied local variable, hence must able generate address it. addition, Quses stack frame storing arguments procedures calls. illustrated Figure 3.21, within called procedure, ﬁrst argumentis positioned offset 8 relative %ebp , remaining arguments (assuming data types require 4 bytes) stored successive 4-byteblocks, argument iis offset 4 +4irelative %ebp . Larger arguments (such structures larger numeric formats) require larger regions stack. described earlier, stack grows toward lower addresses stack pointer %esp points top element stack. Data stored retrieved stack using pushl andpopl instructions. Space data speciﬁed initial value allocated stack simply decrementing thestack pointer appropriate amount. Similarly, space deallocated byincrementing stack pointer. 3.7.2 Transferring Control instructions supporting procedure calls returns shown following table: Instruction Description call Label Procedure call call * Operand Procedure call leave Prepare stack return ret Return call Thecall instruction target indicating address instruction called procedure starts. Like jumps, call either direct indirect.In assembly code, target direct call given label, target ofan indirect call given *followed operand speciﬁer using one formats described Section 3.4.1. effect call instruction push return address stack jump start called procedure. return address address theinstruction immediately following call program, execution resume location called procedure returns. ret instruction pops address stack jumps location. proper use thisinstruction prepared stack stack pointer points theplace preceding call instruction stored return address.222 Chapter 3 Machine-Level Representation Programs %eip %esp0x080483dc 0xff9bc960 (a) Executing call%eip%esp0x08048394 0xff9bc95c 0x080483e1 (b) call%eip %esp0x080483e1 0xff9bc960 (c) ret Figure 3.22 Illustration call andret functions. Thecall instruction transfers control start function, ret instruction returns back instruction following call. Figure 3.22 illustrates execution call andretinstructions sumandmain functions introduced Section 3.2.2. following excerpts disassembled code two functions: Beginning function sum 108048394 <sum>: 2 8048394: 55 push %ebp ... Return function sum 3 80483a4: c3 ret ...Call sum main 4 80483dc: e8 b3 ff ff ff call 8048394 <sum> 5 80483e1: 83 c4 14 add $0x14,%esp code, see call instruction address 0x080483dc main calls function sum. status shown Figure 3.22(a), indicated values stack pointer %esp program counter %eip . effect thecall push return address 0x080483e1 onto stack jump ﬁrst instruction function sum, address 0x08048394 (Figure 3.22(b)). execution function sumcontinues hits retinstruction address 0x080483a4 . instruction pops value 0x080483e1 stack jumps address, resuming execution main call instruction sum(Figure 3.22(c)). Theleave instruction used prepare stack returning. equivalent following code sequence: 1 movl %ebp, %esp Set stack pointer beginning frame 2 popl %ebp Restore saved %ebp set stack ptr end caller’s frameSection 3.7 Procedures 223 Alternatively, preparation performed explicit sequence move pop operations. Register %eax used returning value function returns integer pointer. Practice Problem 3.30 following code fragment occurs often compiled version libraryroutines: 1 call next 2next: 3 popl %eax A. value register %eax get set? B. Explain matching retinstruction call . C. useful purpose code fragment serve? 3.7.3 Register Usage Conventions set program registers acts single resource shared proce- dures. Although one procedure active given time, must makesure one procedure (the caller ) calls another (the callee ), callee overwrite register value caller planned use later. Forthis reason, IA32 adopts uniform set conventions register usage mustbe respected procedures, including program libraries. convention, registers %eax ,%edx , %ecx classiﬁed caller-save registers. procedure Qis called P, overwrite registers without destroying data required P. hand, registers %ebx ,%esi , %edi classiﬁed callee-save registers. means Qmust save values registers stack overwriting them, restore thembefore returning, P(or higher-level procedure) may need values future computations. addition, registers %ebp and%esp must maintained according conventions described here. example, consider following code: 1int P(int x) 2{ 3 int = x*x; 4 int z = Q(y); 5 retur ny+z ; 6}224 Chapter 3 Machine-Level Representation Programs Procedure Pcomputes ybefore calling Q, must also ensure value ofyis available Qreturns. one two means: .It store value yin stack frame calling Q; Q returns, procedure Pcan retrieve value yfrom stack. words, P, caller, saves value. .It store value yin callee-save register. Q, procedure called Q, wants use register, must save register value stack frame restore value returns (in words, callee saves value). Qreturns P, value ywill callee-save register, either register never altered savedand restored. Either convention made work, long agreement function responsible saving value. IA32 follows approaches,partitioning registers one set caller-save, another set iscallee-save. Practice Problem 3.31 following code sequence occurs right near beginning assembly codegenerated gccfor C procedure: 1 subl $12, %esp 2 movl %ebx, (%esp) 3 movl %esi, 4(%esp) 4 movl %edi, 8(%esp) 5 movl 8(%ebp), %ebx 6 movl 12(%ebp), %edi 7 movl (%ebx), %esi 8 movl (%edi), %eax 9 movl 16(%ebp), %edx 10 movl (%edx), %ecx see three registers ( %ebx ,%esi , %edi ) saved stack (lines 2–4). program modiﬁes three registers ( %eax ,%ecx , %edx ). end procedure, values registers %edi ,%esi , %ebx restored (not shown), three left modiﬁed states. Explain apparent inconsistency saving restoring register states. 3.7.4 Procedure Example example, consider C functions deﬁned Figure 3.23, function caller includes call function swap_add . Figure 3.24 shows stack frame structure caller calls function swap_add swap_addSection 3.7 Procedures 225 1int swap_add(int *xp, int *yp) 2{ 3 int x = *xp; 4 int = *yp; 5 6 * x p=y ; 7 * p=x ; 8 retur nx+y ; 9} 10 11 int caller() 12 { 13 int arg1 = 534; 14 int arg2 = 1057; 15 int sum = swap_add(&arg1, &arg2); 16 int diff = arg1 - arg2; 1718 return sum * diff; 19 } Figure 3.23 Example procedure deﬁnition call. Saved%ebp arg1arg2 +12 +8+4 0+4 00 –4–8 UnusedStack frame callerJust call toswap_addFrame pointer %ebp Frame pointer %ebp Stack pointer %espStack framefor swap_add%esp Stack pointer&arg2 &arg1Saved%ebp arg1arg2 Return address Saved%ebp Saved%ebxUnusedIn body swap_add &arg2 &arg1 Figure 3.24 Stack frames caller andswap_add .Procedure swap_add retrieves arguments stack frame caller . running. instructions access stack locations relative stack pointer %esp others access locations relative base pointer %ebp . offsets identiﬁed lines shown relative two pointers.226 Chapter 3 Machine-Level Representation Programs New C? Passing parameters function languages, Pascal, provide two different ways pass parameters procedures—by value , caller provides actual parameter value, reference , caller provides pointer value. C, parameters passed value, mimic effect reference parameter explicitly generating pointer value passing pointer procedure. see call caller toswap_add (Figure 3.23). passing pointers arg1 andarg2 ,caller provides way swap_add modify values. One ways C++ extends C inclusion reference parameters. stack frame caller includes storage local variables arg1 andarg2 , positions −4 −8 relative frame pointer. variables must stored stack, since code must associate address them. Thefollowing assembly code compiled version caller shows calls swap_add : 1caller: 2 pushl %ebp Save old %ebp 3 movl %esp, %ebp Set%ebp frame pointer 4 subl $24, %esp Allocate 24 bytes stack 5 movl $534, -4(%ebp) Set arg1 534 6 movl $1057, -8(%ebp) Set arg2 1057 7 leal -8(%ebp), %eax Compute &arg2 8 movl %eax, 4(%esp) Store stack 9 leal -4(%ebp), %eax Compute &arg1 10 movl %eax, (%esp) Store stack 11 call swap_add Call swap_add function code saves copy %ebp sets %ebp beginning stack frame (lines 2–3). allocates 24 bytes stack decrementing stackpointer (recall stack grows toward lower addresses). initializes arg1 andarg2 534 1057, respectively (lines 5–6), computes values &arg2 and&arg1 stores stack form arguments swap_ add(lines 7–10). stores arguments relative stack pointer, offsets 0 +4 later access swap_add . calls swap_add . 24 bytes allocated stack frame, 8 used local variables, 8 used passing parameters swap_add , 8 used anything. Aside gcc allocate space never gets used? see code generated gccforcaller allocates 24 bytes stack even though makes use 16 them. see many examples apparent wastefulness. gcc adheres x86 programming guideline total stack space used function multiple 16 bytes. Including 4 bytes saved value %ebp 4 bytes return address, caller uses total 32 bytes. motivation convention ensure proper alignment accessing data. explain reason alignment conventions implemented Section 3.9.3.Section 3.7 Procedures 227 compiled code swap_add three parts: “setup,” stack frame initialized; “body,” actual computation procedure isperformed; “ﬁnish,” stack state restored procedurereturns. following setup code swap_add . Recall reaching part code, call instruction pushed return address onto stack. 1swap_add: 2 pushl %ebp Save old %ebp 3 movl %esp, %ebp Set%ebp frame pointer 4 pushl %ebx Save %ebx Function swap_add requires register %ebx temporary storage. Since callee-save register, pushes old value onto stack part stack frame setup. point, state stack shown right-hand sideof Figure 3.24. Register %ebp shifted serve frame pointer swap_add . following body code swap_add : 5 movl 8(%ebp), %edx Get xp 6 movl 12(%ebp), %ecx Get yp 7 movl (%edx), %ebx Get x 8 movl (%ecx), %eax Get 9 movl %eax, (%edx) Store xp 10 movl %ebx, (%ecx) Store x yp 11 addl %ebx, %eax Return value = x+y code retrieves arguments stack frame caller . Since frame pointer shifted, locations arguments shifted positions +4 0 relative old value %esp positions +12 +8 relative new value of%ebp . sum variables xandyis stored register %eax passed returned value. following ﬁnishing code swap_add : 12 popl %ebx Restore %ebx 13 popl %ebp Restore %ebp 14 ret Return code restores values registers %ebx and%ebp , also resetting stack pointer points stored return address, ret instruction transfers control back caller . following code caller comes immediately instruction calling swap_add : 12 movl -4(%ebp), %edx 13 subl -8(%ebp), %edx 14 imull %edx, %eax 15 leave 16 ret228 Chapter 3 Machine-Level Representation Programs code retrieves values arg1 andarg2 stack order compute diff , uses register %eax return value swap_add . Observe use theleave instruction reset stack frame pointer prior return. seen code examples code generated gccsometimes uses aleave instruction deallocate stack frame, sometimes uses one two popl instructions. Either approach acceptable, guidelines Intel AMD preferable change time. see example compiler generates code manage stack structure according simple set conventions. Arguments passedto function stack, retrieved using positive offsets(+8,+12,...) relative %ebp . Space allocated stack either using push instructions subtracting offsets stack pointer. Beforereturning, function must restore stack original condition restoringany callee-saved registers %ebp , resetting %esp points return address. important procedures follow consistent setof conventions setting restoring stack order program execute properly. Practice Problem 3.32 C function funhas following code body: * p=d ; return x-c; IA32 code implementing body follows: 1 movsbl 12(%ebp),%edx 2 movl 16(%ebp), %eax 3 movl %edx, (%eax) 4 movswl 8(%ebp),%eax 5 movl 20(%ebp), %edx 6 subl %eax, %edx 7 movl %edx, %eax Write prototype function fun, showing types ordering arguments p,d,x, c. Practice Problem 3.33 Given C function 1int proc(void) 2{ 3 int x,y; 4 scanf("%x %x", &y, &x); 5 return x-y; 6}Section 3.7 Procedures 229 gccgenerates following assembly code: 1proc: 2 pushl %ebp 3 movl %esp, %ebp 4 subl $40, %esp 5 leal -4(%ebp), %eax 6 movl %eax, 8(%esp) 7 leal -8(%ebp), %eax 8 movl %eax, 4(%esp) 9 movl $.LC0, (%esp) Pointer string "%x %x" 10 call scanf Diagram stack frame point 11 movl -4(%ebp), %eax 12 subl -8(%ebp), %eax 13 leave 14 ret Assume procedure proc starts executing following register val- ues: Register Value %esp 0x800040 %ebp 0x800060 Suppose proc callsscanf (line 10), scanf reads values 0x46 0x53 standard input. Assume string “ %x %x ” stored memory location 0x300070 . A. value %ebp get set line 3? B. value %esp get set line 4? C. addresses local variables xandystored? D. Draw diagram stack frame proc right scanf returns. Include much information addresses contents thestack frame elements. E. Indicate regions stack frame used proc . 3.7.5 Recursive Procedures stack linkage conventions described previous section allow pro- cedures call recursively. Since call private spaceon stack, local variables multiple outstanding calls interferewith one another. Furthermore, stack discipline naturally provides properpolicy allocating local storage procedure called deallocatingit returns.230 Chapter 3 Machine-Level Representation Programs 1int rfact(int n) 2{ 3 int result; 4 (n <= 1) 5 result = 1; 6 else 7 resul t=n* rfact(n-1); 8 return result; 9} Figure 3.25 C code recursive factorial program. Figure 3.25 shows C code recursive factorial function. assembly code generated gccis shown Figure 3.26. Let us examine machine code operate called argument n. set-up code (lines 2– 5) creates stack frame containing old version %ebp , saved value callee-save register %ebx , 4 bytes hold argument calls recursively, illustrated Figure 3.27. uses register %ebx save copy n(line 6). sets return value register %eax 1 (line 7) anticipation case n≤1, event jump completion code. recursive case, computes n−1, stores stack, calls (lines 10–12). Upon completion code, assume (1) register %eax holds Argument: n %ebp+8 Registers: n %ebx, result %eax 1rfact: 2 pushl %ebp Save old %ebp 3 movl %esp, %ebp Set%ebp frame pointer 4 pushl %ebx Save callee save register %ebx 5 subl $4, %esp Allocate 4 bytes stack 6 movl 8(%ebp), %ebx Get n 7 movl $1, %eax result = 1 8 cmpl $1, %ebx Compare n:1 9 jle .L53 <=, goto done 10 leal -1(%ebx), %eax Compute n-1 11 movl %eax, (%esp) Store top stack 12 call rfact Call rfact(n-1) 13 imull %ebx, %eax Compute result = return value * n 14 .L53: done: 15 addl $4, %esp Deallocate 4 bytes stack 16 popl %ebx Restore %ebx 17 popl %ebp Restore %ebp 18 ret Return result Figure 3.26 Assembly code recursive factorial program Figure 3.25.Section 3.7 Procedures 231 Figure 3.27 Stack frame recursivefactorial function. state frame shownjust recursive call. +8 +4 0Stack frame callingprocedure Frame pointer %ebp Stack frame forrfactn Return address Saved%ebp Saved%ebx n-1Stack pointer %esp value (n−1)! (2) callee-save register %ebx holds parameter n.I therefore multiplies two quantities (line 13) generate return value ofthe function. cases—the terminal condition recursive call—the code pro- ceeds completion section (lines 15–17) restore stack callee-savedregister, returns. see calling function recursively proceeds like function call. stack discipline provides mechanism invocationof function private storage state information (saved values ofthe return location, frame pointer, callee-save registers). need be, canalso provide storage local variables. stack discipline allocation anddeallocation naturally matches call-return ordering functions. methodof implementing function calls returns even works complex patterns,including mutual recursion (for example, procedure P calls Q, turncalls P). Practice Problem 3.34 C function general structure int rfun(unsigned x) { ( ) return ; unsigned nx = ; int rv = rfun(nx); return ; } gccgenerates following assembly code (with setup completion code omitted): 1 movl 8(%ebp), %ebx 2 movl $0, %eax 3 testl %ebx, %ebx 4 je .L3232 Chapter 3 Machine-Level Representation Programs 5 movl %ebx, %eax 6 shrl %eax Shift right 1 7 movl %eax, (%esp) 8 call rfun 9 movl %ebx, %edx 10 andl $1, %edx 11 leal (%edx,%eax), %eax 12 .L3: A. value rfun store callee-save register %ebx ? B. Fill missing expressions C code shown above.C. Describe English function code computes. 3.8 Array Allocation Access Arrays C one means aggregating scalar data larger data types. C uses particularly simple implementation arrays, hence translation machine code fairly straightforward. One unusual feature C wecan generate pointers elements within arrays perform arithmetic pointers. translated address computations machine code. Optimizing compilers particularly good simplifying address compu- tations used array indexing. make correspondence Ccode translation machine code somewhat difﬁcult decipher. 3.8.1 Basic Principles data type Tand integer constant N, declaration TA[N]; two effects. First, allocates contiguous region L.Nbytes memory, Lis size (in bytes) data type T. Let us denote starting location asxA. Second, introduces identiﬁer Athat used pointer beginning array. value pointer xA. array elements accessed using integer index ranging 0 N−1. Array element stored address xA+L.i. examples, consider following declarations: char A[12]; char *B[8]; double C[6]; double *D[5];Section 3.8 Array Allocation Access 233 declarations generate arrays following parameters: Array Element size Total size Start address Element 11 2 xA xA+i B 43 2 xB xB+4i C 84 8 xC xC+8i 42 0 xD xD+4i Array Aconsists 12 single-byte ( char ) elements. Array Cconsists six double-precision ﬂoating-point values, requiring 8 bytes. BandDare arrays pointers, hence array elements 4 bytes each. memory referencing instructions IA32 designed simplify array access. example, suppose Eis array int’s, wish evaluate E[i] , address Eis stored register %edx andiis stored register %ecx . instruction movl (%edx,%ecx,4),%eax perform address computation xE+4i, read memory location, copy result register %eax . allowed scaling factors 1, 2, 4, 8 cover sizes common primitive data types. Practice Problem 3.35 Consider following declarations: short S[7]; short *T[3]; short **U[6];long double V[8]; long double *W[4]; Fill following table describing element size, total size, address element ifor arrays. Array Element size Total size Start address Element xS xT U xU V xV W xW 3.8.2 Pointer Arithmetic C allows arithmetic pointers, computed value scaled according size data type referenced pointer. is, pis pointer data234 Chapter 3 Machine-Level Representation Programs type T, value pisxp, expression p+i value xp+L.i, Lis size data type T. unary operators &and*allow generation dereferencing point- ers. is, expression Expr denoting object, &Expr pointer giving address object. expression AExpr denoting address, *AExpr gives value address. expressions Expr and*&Expr therefore equivalent. array subscripting operation applied arrays andpointers. array reference A[i] identical expression *(A+i) . com- putes address ith array element accesses memory location. Expanding earlier example, suppose starting address integer array Eand integer index iare stored registers %edx and%ecx , respectively. following expressions involving E. also show assembly-code implementation expression, result stored register %eax . Expression Type Value Assembly code E int * xE movl %edx,%eax E[0] int M[xE] movl (%edx),%eax E[i] int M[xE+4i] movl (%edx,%ecx,4),%eax &E[2] int * xE+8 leal 8(%edx),%eax E+i-1 int * xE+4i−4 leal -4(%edx,%ecx,4),%eax *(E+i-3) int * M[xE+4i−12] movl -12(%edx,%ecx,4),%eax &E[i]-E int movl %ecx,%eax examples, leal instruction used generate address, movl used reference memory (except ﬁrst last cases, formercopies address latter copies index). ﬁnal example shows thatone compute difference two pointers within data structure,with result divided size data type. Practice Problem 3.36 Suppose address short integer array Sand integer index iare stored registers %edx and%ecx , respectively. following expressions, give type, formula value, assembly code implementation. resultshould stored register %eax pointer register element %axif ashort integer. Expression Type Value Assembly code S+1 S[3] &S[i] S[4*i+1] S+i-5Section 3.8 Array Allocation Access 235 3.8.3 Nested Arrays general principles array allocation referencing hold even create arrays arrays. example, declaration int A[5][3]; equivalent declaration typedef int row3_t[3]; row3_t A[5]; Data type row3_t deﬁned array three integers. Array Acontains ﬁve elements, requiring 12 bytes store three integers. total arraysize 4 .5.3=60 bytes. Array Acan also viewed two-dimensional array ﬁve rows three columns, referenced A[0][0] A[4][2] . array elements ordered memory “row major” order, meaning elements row 0, whichcan written A[0] , followed elements row 1 ( A[1] ), on. Row Element Address A[0] A[0][0] xA A[0][1] xA+4 A[0][2] xA+8 A[1] A[1][0] xA+12 A[1][1] xA+16 A[1][2] xA+20 A[2] A[2][0] xA+24 A[2][1] xA+28 A[2][2] xA+32 A[3] A[3][0] xA+36 A[3][1] xA+40 A[3][2] xA+44 A[4] A[4][0] xA+48 A[4][1] xA+52 A[4][2] xA+56 ordering consequence nested declaration. Viewing Aas array ﬁve elements, array three int’s, ﬁrst A[0] , followed byA[1] , on. access elements multidimensional arrays, compiler generates code compute offset desired element uses one movinstructions start array base address (possibly scaled) offset asan index. general, array declared TD[R][C];236 Chapter 3 Machine-Level Representation Programs array element D[i][j] memory address &D[i][j] =xD+L(C.i+j), (3.1) Lis size data type Tin bytes. example, consider 5 ×3 integer array Adeﬁned earlier. Suppose xA,i, andjare offsets 8, 12, 16 relative %ebp , respectively. array element A[i][j] copied register %eax following code: Aa %ebp+ 8 ,ia %ebp+12,j %ebp+16 1 movl 12(%ebp), %eax Get 2 leal (%eax,%eax,2), %eax Compute 3*i 3 movl 16(%ebp), %edx Get j 4 sall $2, %edx Compute j*4 5 addl 8(%ebp), %edx Compute xA+4j 6 movl (%edx,%eax,4), %eax Read M[xA+4j+12i] seen, code computes element’s address xA+4j+12i= xA+4(3i+j)using combination shifting, adding, scaling avoid costly multiplication instructions. Practice Problem 3.37 Consider following source code, MandNare constants declared #define : 1int mat1[M][N]; 2int mat2[N][M]; 3 4int sum_element(int i, int j) { 5 return mat1[i][j] + mat2[j][i]; 6} compiling program, gccgenerates following assembly code: ia %ebp+ 8 ,ja %ebp+12 1 movl 8(%ebp), %ecx 2 movl 12(%ebp), %edx 3 leal 0(,%ecx,8), %eax 4 subl %ecx, %eax 5 addl %edx, %eax 6 leal (%edx,%edx,4), %edx 7 addl %ecx, %edx 8 movl mat1(,%eax,4), %eax 9 addl mat2(,%edx,4), %eax Use reverse engineering skills determine values MandNbased assembly code.Section 3.8 Array Allocation Access 237 3.8.4 Fixed-Size Arrays C compiler able make many optimizations code operating multi- dimensional arrays ﬁxed size. example, suppose declare data type fix_ matrix 16 ×16 arrays integers follows: 1#define N 16 2typedef int fix_matrix[N][N]; (This example illustrates good coding practice. Whenever program uses constant array dimension buffer size, best associate name withit via #define declaration, use name consistently, rather numeric value. way, occasion ever arises change value, bedone simply modifying #define declaration.) code Figure 3.28(a) computes element i, kof product arrays AandB, according formula/summationtext 0≤j<Nai,j.bj,k. C compiler generates code recoded C, shown function fix_prod_ele_opt Figure 3.28(b). code contains number clever optimizations. recognizes loop access theelements row iof array A, creates local pointer variable, named Arow , provide direct access row iof array. Arow initialized &A[i][0] , array element A[i][j] accessed Arow[j] . also recognizes loop access elements array BasB[0][k] , B[1][k] ,..., B[15][k] sequence. elements occupy positions memory starting address array element B[0][k] spaced 64 bytes apart. program therefore use pointer variable Bptr access successive locations. C, pointer shown incremented N(16), although fact actual address incremented 4 .16=64. following actual assembly code loop. see four variables maintained registers within loop: Arow ,Bptr ,j, result . Registers: Arow %esi, Bptr %ecx, j %edx, result %ebx 1.L6: loop: 2 movl (%ecx), %eax Get *Bptr 3 imull (%esi,%edx,4), %eax Multiply Arow[j] 4 addl %eax, %ebx Add result 5 addl $1, %edx Increment j 6 addl $64, %ecx Add 64 Bptr 7 cmpl $16, %edx Compare j:16 8 jne .L6 !=, goto loop seen, register %ecx incremented 64 within loop (line 6). Machine code considers every pointer byte address, compilingpointer arithmetic, must scale every increment size underlying datatype.238 Chapter 3 Machine-Level Representation Programs Practice Problem 3.38 following C code sets diagonal elements one ﬁxed-size arrays val: 1/* Set diagonal elements val */ 2void fix_set_diag(fix_matrix A, int val) { 3 int i; 4 f r( i=0 ;i<N ; i++) 5 A[i][i] = val; 6} compiled, gccgenerates following assembly code: Aa %ebp+8, val %ebp+12 1 movl 8(%ebp), %ecx 2 movl 12(%ebp), %edx 3 movl $0, %eax 4.L14: 5 movl %edx, (%ecx,%eax) 6 addl $68, %eax 7 cmpl $1088, %eax 8 jne .L14 Create C-code program fix_set_diag_opt uses optimizations similar assembly code, style code Figure 3.28(b). Useexpressions involving parameter Nrather integer constants, code work correctly Nis redeﬁned. 3.8.5 Variable-Size Arrays Historically, C supported multidimensional arrays sizes (with possible exception ﬁrst dimension) could determined compile time.Programmers requiring variable-sized arrays allocate storage thesearrays using functions malloc orcalloc , explicitly encode mapping multidimensional arrays single-dimension ones via row-majorindexing, expressed Equation 3.1. ISO C99 introduced capability array dimensions expressions computed array allocated,and recent versions gcc support conventions variable-sized arrays ISO C99. C version variable-size arrays, declare array int A[ expr1 ][expr2 ], either local variable argument function, dimensions array determined evaluating expres-sions expr1 expr2 time declaration encountered. So, example, write function access element i, jof ann×narray follows: 1int var_ele(int n, int A[n][n], int i, int j) { 2 return A[i][j]; 3}Section 3.8 Array Allocation Access 239 (a) Original C code 1/* Compute i,k fixed matrix product */ 2int fix_prod_ele (fix_matrix A, fix_matrix B, int i, int k) { 3 int j; 4 int result = 0; 5 6 f r( j=0 ;j<N ; j++) 7 result += A[i][j] * B[j][k]; 8 9 return result; 10 } (b) Optimized C code 1/* Compute i,k fixed matrix product */ 2int fix_prod_ele_opt(fix_matrix A, fix_matrix B, int i, int k) { 3 int *Arow = &A[i][0]; 4 int *Bptr = &B[0][k]; 5 int result = 0; 6 int j; 7 (j = 0; j != N; j++) { 8 result += Arow[j] * *Bptr; 9 Bptr += N; 10 } 11 return result; 12 } Figure 3.28 Original optimized code compute element i, kof matrix product ﬁxed-length arrays. compiler performs optimizations automatically. parameter nmust precede parameter A[n][n] , function compute array dimensions parameter encountered. gccgenerates code referencing function na %ebp+ 8 ,Aa %ebp+12, %ebp+16, j %ebp+20 1 movl 8(%ebp), %eax Get n 2 sall $2, %eax Compute 4*n 3 movl %eax, %edx Copy 4*n 4 imull 16(%ebp), %edx Compute 4*n*i 5 movl 20(%ebp), %eax Get j 6 sall $2, %eax Compute 4*j 7 addl 12(%ebp), %eax Compute xA+4∗j 8 movl (%eax,%edx), %eax Read xA+4∗(n∗i+j) annotations show, code computes address element i, jasxA+ 4(n.i+j). address computation similar ﬁxed-size array (page 236), except (1) positions arguments stack shifteddue addition parameter n, (2) multiply instruction used (line 4) to240 Chapter 3 Machine-Level Representation Programs 1/* Compute i,k variable matrix product */ 2int var_prod_ele(int n, int A[n][n], int B[n][n], int i, int k) { 3 int j; 4 int result = 0; 5 6 f r( j=0 ;j<n ; j++) 7 result += A[i][j] * B[j][k]; 8 9 return result; 10 } Figure 3.29 Code compute element i, k matrix product variable-sized arrays. compiler performs optimizations similar ﬁxed-size arrays. compute n.i, rather leal instruction compute 3 i. see therefore referencing variable-size arrays requires slight generalization ﬁxed-size ones. dynamic version must use multiplication instruction scale iby n, rather series shifts adds. processors, multiplication incur signiﬁcant performance penalty, unavoidable case. variable-sized arrays referenced within loop, compiler often optimize index computations exploiting regularity accesspatterns. example, Figure 3.29 shows C code compute element i, kof product two n×narrays AandB. compiler generates code similar saw ﬁxed-size arrays. fact, code bears close resemblance ofFigure 3.28(b), except scales Bptr , pointer element B[j][k] , variable value nrather ﬁxed value Non iteration. following assembly code loop var_prod_ele : n stored %ebp+8 Registers: Arow %esi, Bptr %ecx,ji n %edx, result %ebx,%edi holds 4*n 1.L30: loop: 2 movl (%ecx), %eax Get *Bptr 3 imull (%esi,%edx,4), %eax Multiply Arow[j] 4 addl %eax, %ebx Add result 5 addl $1, %edx Increment j 6 addl %edi, %ecx Add 4*n Bptr 7 cmpl %edx, 8(%ebp) Compare n:j 8 jg .L30 >, goto loop see program makes use scaled value 4 n(register %edi ) incrementing Bptr actual value nstored offset 8 %ebp check loop bounds. need two values show C code, due tothe scaling pointer arithmetic. code retrieves value nfrom memory iteration check loop termination (line 7). example register spilling : enough registers hold needed temporary data, hence compiler must keep local variables memory. casethe compiler chose spill n, “read-only” value—it changeSection 3.9 Heterogeneous Data Structures 241 value within loop. IA32 must often spill loop values memory, since processor registers. general, reading memory done morereadily writing memory, spilling read-only variables preferable.See Problem 3.61 regarding improve code avoid register spilling. 3.9 Heterogeneous Data Structures C provides two mechanisms creating data types combining objects dif-ferent types: structures , declared using keyword struct , aggregate multiple objects single unit; unions , declared using keyword union , allow object referenced using several different types. 3.9.1 Structures C struct declaration creates data type groups objects possibly different types single object. different components structure arereferenced names. implementation structures similar arraysin components structure stored contiguous region ofmemory, pointer structure address ﬁrst byte. compiler maintains information structure type indicating byte offset ofeach ﬁeld. generates references structure elements using offsets asdisplacements memory referencing instructions. New C? Representing object struct Thestruct data type constructor closest thing C provides objects C++ Java. allows programmer keep information entity single data structure, reference information names. example, graphics program might represent rectangle structure: struct rect { int llx; /* X coordinate lower-left corner */ int lly; /* coordinate lower-left corner */ int color; /* Coding color */ int width; /* Width (in pixels) */ int height; /* Height (in pixels) */ }; could declare variable rof type struct rect set ﬁeld values follows: struct rect r; r.llx = r.lly = 0; r.color = 0xFF00FF;r.width = 10; r.height = 20; expression r.llx selects ﬁeld llxof structure r.242 Chapter 3 Machine-Level Representation Programs Alternatively, declare variable initialize ﬁelds single statement: struct rec tr={0 ,0 , 0xFF00FF, 10, 20 }; common pass pointers structures one place another rather copying them. example, following function computes area rectangle, pointer rectanglestruct passed function: int area(struct rect *rp) { return (*rp).width * (*rp).height; } expression (*rp).width dereferences pointer selects width ﬁeld resulting structure. Parentheses required, compiler would interpret expression *rp.width *(rp.width) , valid. combination dereferencing ﬁeld selection common C provides alternative notation using ->. is, rp->width equivalent expression (*rp).width . example, could write function rotates rectangle counterclockwise 90 degrees void rotate_left(struct rect *rp) { /* Exchange width height */ int = rp->height; rp->height = rp->width; rp->width = t;/* Shift new lower-left corner */rp->llx -= t; } objects C++ Java elaborate structures C, also associate set methods object invoked perform computation. C, would simply write ordinary functions, functions area androtate_left shown above. example, consider following structure declaration: struct rec { int i; int j; int a[3]; int *p; }; structure contains four ﬁelds: two 4-byte int’s, array consisting three 4-byte int’s, 4-byte integer pointer, giving total 24 bytes: Offset Contents i0 4 8 20 24 j a[0] a[1] a[2] pSection 3.9 Heterogeneous Data Structures 243 Observe array ais embedded within structure. numbers along top diagram give byte offsets ﬁelds beginning thestructure. access ﬁelds structure, compiler generates code adds appropriate offset address structure. example, suppose variable r type struct rec * register %edx . following code copies element r->i element r->j : 1 movl (%edx), %eax Get r->i 2 movl %eax, 4(%edx) Store r->j Since offset ﬁeld iis 0, address ﬁeld simply value r.T store ﬁeld j, code adds offset 4 address r. generate pointer object within structure, simply add ﬁeld’s offset structure address. example, generate pointer&(r->a[1]) adding offset 8 +4.1=12. pointer rin register %eax integer variable iin register %edx , generate pointer value &(r->a[i]) single instruction Registers: r %edx,ii n %eax 1 leal 8(%edx,%eax,4), %eax Set%eax &r->a[i] ﬁnal example, following code implements statement r->p = &r->a[r->i + r->j]; starting rin register %edx : 1 movl 4(%edx), %eax Get r->j 2 addl (%edx), %eax Add r->i 3 leal 8(%edx,%eax,4), %eax Compute &r->a[r->i + r->j] 4 movl %eax, 20(%edx) Store r->p examples show, selection different ﬁelds structure handled completely compile time. machine code contains informationabout ﬁeld declarations names ﬁelds. Practice Problem 3.39 Consider following structure declaration: struct prob { int *p; struct { int x; int y; }s ; struct prob *next; };244 Chapter 3 Machine-Level Representation Programs declaration illustrates one structure embedded within another, arrays embedded within structures, arrays embeddedwithin arrays. following procedure (with expressions omitted) operates structure: void sp_init(struct prob *sp) { sp->s.x = ; sp->p = ; sp->next = ; } A. offsets (in bytes) following ﬁelds? p: s.x: s.y: next : B. many total bytes structure require? C. compiler generates following assembly code body sp_ init : sp %ebp+8 1 movl 8(%ebp), %eax 2 movl 8(%eax), %edx 3 movl %edx, 4(%eax) 4 leal 4(%eax), %edx 5 movl %edx, (%eax) 6 movl %eax, 12(%eax) basis information, ﬁll missing expressions code forsp_init . 3.9.2 Unions Unions provide way circumvent type system C, allowing single object referenced according multiple types. syntax union declaration isidentical structures, semantics different. Rather thanhaving different ﬁelds reference different blocks memory, referencethe block. Consider following declarations: struct S3 { char c; int i[2];Section 3.9 Heterogeneous Data Structures 245 double v; }; union U3 { char c;int i[2];double v; }; compiled IA32 Linux machine, offsets ﬁelds, well total size data types S3andU3, shown following table: Type ci v Size S3 0 4 12 20 U3 00 0 8 (We see shortly ihas offset 4 S3rather 1, discuss results would different machine running Microsoft Windows.)For pointer pof type union U3 * , references p->c ,p->i[0] , p->v would reference beginning data structure. Observe also overall size ofa union equals maximum size ﬁelds. Unions useful several contexts. However, also lead nasty bugs, since bypass safety provided C type system. One applicationis know advance use two different ﬁelds data structure mutually exclusive. Then, declaring two ﬁelds part union ratherthan structure reduce total space allocated. example, suppose want implement binary tree data structure leaf node double data value, internal node pointers two children, data. declare struct NODE_S { struct NODE_S *left; struct NODE_S *right; double data; }; every node requires 16 bytes, half bytes wasted type node. hand, declare node union NODE_U { struct { union NODE_U *left; union NODE_U *right; } internal; double data; };246 Chapter 3 Machine-Level Representation Programs every node require 8 bytes. nis pointer node type union NODE * , would reference data leaf node n->data , children internal node n->internal.left andn->internal.right . encoding, however, way determine whether given node leaf internal node. common method introduce enumer-ated type deﬁning different possible choices union, create astructure containing tag ﬁeld union: typedef enum { N_LEAF, N_INTERNAL } nodetype_t; struct NODE_T { nodetype_t type;union { struct { struct NODE_T *left; struct NODE_T *right; } internal;double data; } info; }; structure requires total 12 bytes: 4 type , either 4 info.internal.left andinfo.internal.right , 8 info.data . case, savings gain using union small relative awkwardness ofthe resulting code. data structures ﬁelds, savings morecompelling. Unions also used access bit patterns different data types. example, following code returns bit representation float unsigned : 1unsigned float2bit(float f) 2{ 3 union { 4 float f; 5 unsigned u; 6 } temp; 7 temp.f = f; 8 return temp.u; 9}; code, store argument union using one data type, access using another. Interestingly, code generated procedure identical tothat following procedure: 1unsigned copy(unsigned u) 2{ 3 return u; 4}Section 3.9 Heterogeneous Data Structures 247 body procedures single instruction: 1 movl 8(%ebp), %eax demonstrates lack type information machine code. argu- ment offset 8 relative %ebp regardless whether float unsigned . procedure simply copies argument return value without modifying bits. using unions combine data types different sizes, byte-ordering issues become important. example, suppose write procedure willcreate 8-byte double using bit patterns given two 4-byte unsigned ’s: 1double bit2double(unsigned word0, unsigned word1) 2{ 3 union { 4 double d; 5 unsigned u[2]; 6 } temp; 7 8 temp.u[0] = word0; 9 temp.u[1] = word1; 10 return temp.d; 11 } little-endian machine IA32, argument word0 become low-order 4 bytes d, word1 become high-order 4 bytes. big- endian machine, role two arguments reversed. Practice Problem 3.40 Suppose given job checking tha C compiler generates proper code structure union access. write following structure declaration: typedef union { struct { short v; short d; int s; } t1; struct { int a[2]; char *p; } t2; } u_type; write series functions form void get(u_type *up, TYPE *dest) { *dest = EXPR; }248 Chapter 3 Machine-Level Representation Programs different access expressions EXPR , destination data type TYPE set according type associated EXPR . examine code generated compiling functions see match expectations. Suppose functions upanddest loaded registers %eax %edx , respectively. Fill following table data type TYPE sequences 1–3 instructions compute expression store result dest . Try use registers %eax and%edx , using register %ecx sufﬁce. EXPR TYPE Code up->t1.s int movl 4(%eax), %eax movl %eax, (%edx) up->t1.v &up->t1.d up->t2.a up->t2.a[up->t1.s] *up->t2.p 3.9.3 Data Alignment Many computer systems place restrictions allowable addresses primitive data types, requiring address type object must amultiple value K(typically 2, 4, 8). alignment restrictions simplify design hardware forming interface processor thememory system. example, suppose processor always fetches 8 bytes frommemory address must multiple 8. guarantee anydouble aligned address multiple 8, value read written single memory operation. Otherwise, may need toSection 3.9 Heterogeneous Data Structures 249 perform two memory accesses, since object might split across two 8-byte memory blocks. IA32 hardware work correctly regardless alignment data. However, Intel recommends data aligned improve memory systemperformance. Linux follows alignment policy 2-byte data types (e.g.,short ) must address multiple 2, larger data types (e.g., int,int * ,float , double ) must address multiple 4. Note requirement means least signiﬁcant bit address ofan object type short must equal zero. Similarly, object type int, pointer, must address low-order 2 bits equal zero. Aside case mandatory alignment IA32 instructions, keeping data aligned improves efﬁciency, affect program behavior. hand, SSE instructions implementing multimedia operations work correctly unaligned data. instructions operate 16-byte blocks data, instructions transfer data SSE unit memory require memory addresses tobe multiples 16. attempt access memory address satisfy alignmentwill lead exception , default behavior program terminate. motivation behind IA32 convention making sure every stack frame multiple 16 bytes long (see aside page 226). compiler allocate storage within stackframe way block stored 16-byte alignment. Aside Alignment Microsoft Windows Microsoft Windows imposes stronger alignment requirement—any primitive object Kbytes, K=2, 4, 8, must address multiple K. particular, requires address adouble along long multiple 8. requirement enhances memory performance expense wasted space. Linux convention, 8-byte values aligned 4-byte boundaries probably good i386, back memory scarce memory interfaces 4 bytes wide. modern processors, Microsoft’s alignment better design decision. Data type long double , gccgenerates IA32 code allocating 12 bytes (even though actual data type requires 10 bytes) 4-byte alignment requirement Windows Linux. Alignment enforced making sure every data type organized allocated way every object within type satisﬁes alignment restrictions. compiler places directives assembly code indicating thedesired alignment global data. example, assembly-code declaration ofthe jump table beginning page 217 contains following directive line 2: .align 4 ensures data following (in case start jump table) willstart address multiple 4. Since table entry 4 bytes long,the successive elements obey 4-byte alignment restriction.250 Chapter 3 Machine-Level Representation Programs Library routines allocate memory, malloc , must designed return pointer satisﬁes worst-case alignment restrictionfor machine running on, typically 4 8. code involving structures,the compiler may need insert gaps ﬁeld allocation ensure eachstructure element satisﬁes alignment requirement. structure somerequired alignment starting address. example, consider following structure declaration: struct S1 { int i; char c; int j; }; Suppose compiler used minimal 9-byte allocation, diagrammed follows: Offset Contents i04 59 cj would impossible satisfy 4-byte alignment requirement ﬁelds i(offset 0) j(offset 5). Instead, compiler inserts 3-byte gap (shown shaded blue) ﬁelds candj: Offset Contents i04 5 81 2 cj result, jhas offset 8, overall structure size 12 bytes. Further- more, compiler must ensure pointer pof type struct S1* satisﬁes 4-byte alignment. Using earlier notation, let pointer phave value xp. xpmust multiple 4. guarantees p->i (address xp) p->j (address xp+8) satisfy 4-byte alignment requirements. addition, compiler may need add padding end structure element array structures satisfy alignment requirement.For example, consider following structure declaration: struct S2 { int i; int j; char c; }; pack structure 9 bytes, still satisfy alignment requirements ﬁelds iandjby making sure starting address structure satisﬁes 4-byte alignment requirement. Consider, however, following declaration: struct S2 d[4];Section 3.9 Heterogeneous Data Structures 251 9-byte allocation, possible satisfy alignment requirement element d, elements addresses xd,xd+9, xd+18, xd+27. Instead, compiler allocates 12 bytes structure S2, ﬁnal 3 bytes wasted space: Offset Contents i04 9 81 2 cj way elements dwill addresses xd,xd+12,xd+24, xd+36. long xdis multiple 4, alignment restrictions satisﬁed. Practice Problem 3.41 following structure declarations, determine offset ﬁeld, total size structure, alignment requirement Linux/IA32. A.struct P1 { int i; char c; int j; char d; }; B.struct P2 { int i; char c; char d; int j; }; C.struct P3 { short w[3]; char c[3] }; D.struct P4 { short w[3]; char *c[3] }; E.struct P3 { struct P1 a[2]; struct P2 *p }; Practice Problem 3.42 structure declaration struct { char *a; short b;double c;char d; float e; char f; long long g; void *h; } foo; suppose compiled Windows machine, primitive data type ofKbytes must offset multiple K. A. byte offsets ﬁelds structure? B. total size structure?C. Rearrange ﬁelds structure minimize wasted space, show byte offsets total size rearranged structure.252 Chapter 3 Machine-Level Representation Programs 3.10 Putting Together: Understanding Pointers Pointers central feature C programming language. serve uniform way generate references elements within different data structures.Pointers source confusion novice programmers, underlyingconcepts fairly simple. highlight key principles pointers andtheir mapping machine code. .Every pointer associated type . type indicates kind object pointer points to. Using following pointer declarations illustrations, int *ip; char **cpp; variable ipis pointer object type int, cppis pointer object pointer object type char . general, object type T, pointer type *T. special void * type represents generic pointer. example, malloc function returns generic pointer, converted typed pointer via either explicit cast implicit casting assignment operation. Pointer types part ofmachine code; abstraction provided C help programmersavoid addressing errors. .Every pointer value . value address object designated type. special NULL (0) value indicates pointer point anywhere. .Pointers created &operator . operator applied C expression categorized lvalue , meaning expression appear left side assignment. Examples include variables theelements structures, unions, arrays. seen machine-code realization &operator often uses leal instruction compute expression value, since instruction designed compute addressof memory reference. .Pointers dereferenced *operator . result value type associated pointer. Dereferencing implemented memoryreference, either storing retrieving speciﬁed address. .Arrays pointers closely related . name array referenced (but updated) pointer variable. Array referencing (e.g., a[3] ) exact effect pointer arithmetic dereferencing (e.g., *(a+3) ). array referencing pointer arithmetic require scaling offsets object size. write expression p+ifor pointer pwith value p, resulting address computed p+L.i, Lis size data type associated p. .Casting one type pointer another changes type value. One effect casting change scaling pointer arithmetic. forexample, pis pointer type char * value p, expressionSection 3.10 Putting Together: Understanding Pointers 253 (int *) p+7 computes p+28, (int *) (p+7) computes p+7. (Recall casting higher precedence addition.) .Pointers also point functions. provides powerful capability storing passing references code, invoked otherpart program. example, function deﬁned proto-type int fun(int x, int *p); declare assign pointer fpto function following code sequence: (int) (*fp)(int, int *); fp = fun; invoke function using pointer: n ty=1 ;int result = fp(3, &y); value function pointer address ﬁrst instruction machine-code representation function. New C? Function pointers syntax declaring function pointers especially difﬁcult novice programmers understand. declaration int (*f)(int*); helps read starting inside (starting “ f”) working outward. Thus, see f pointer, indicated “ (*f) .” pointer function single int * argument, indicated “ (*f)(int*) ”. Finally, see pointer function takes int * argument returns int. parentheses around *fare required, otherwise declaration int *f(int*); would read as(int *) f(int*);That is, would interpreted function prototype, declaring function fthat int * argument returns int * . Kernighan & Ritchie [58, Sect. 5.12] present helpful tutorial reading C declarations.254 Chapter 3 Machine-Level Representation Programs 3.11 Life Real World: Using gdb Debugger GNU debugger gdb provides number useful features support run-time evaluation analysis machine-level programs. examplesand exercises book, attempt infer behavior program byjust looking code. Using gdb, becomes possible study behavior watching program action, considerable control itsexecution. Figure 3.30 shows examples gdb commands help working machine-level, IA32 programs. helpful ﬁrst run objdump get disassembled version program. examples based running gdb ﬁle prog , described disassembled page 164. start gdb following command line: unix> gdb prog general scheme set breakpoints near points interest pro- gram. set entry function, program address.When one breakpoints hit program execution, program willhalt return control user. breakpoint, examine differentregisters memory locations various formats. also single-step theprogram, running instructions time, proceed nextbreakpoint. examples suggest, gdb obscure command syntax, on- line help information (invoked within gdb help command) overcomes shortcoming. Rather using command-line interface gdb, many programmers prefer using ddd, extension gdb provides graphic user interface. Web Aside ASM:OPT Machine code generated higher levels optimization presentation, looked machine code generated level-one optimization (speciﬁed command-line option ‘ -O1’). practice, heavily used programs compiled higher levels optimization. example, GNU libraries packages compiled level-two optimization, speciﬁed command-line option ‘ -O2’. Recent versions gccemploy extensive set optimizations level two, making mapping source code generated code difﬁcult discern. examples optimizations found level two: .The control structures become entangled. procedures multiple return points,and stack management code set complete function intermixed code implementing operations procedure. .Procedure calls often inlined , replacing instructions implementing procedures. eliminates much overhead involved calling returning function, enables optimizations speciﬁc individual function calls. hand, try set breakpoint function debugger, might never encounter call function.Section 3.11 Life Real World: Using gdb Debugger 255 Command Effect Starting stopping quit Exit gdb run Run program (give command line arguments here) kill Stop program Breakpoints break sum Set breakpoint entry function sum break *0x8048394 Set breakpoint address 0x8048394 delete 1 Delete breakpoint 1 delete Delete breakpoints Execution stepi Execute one instruction stepi 4 Execute four instructions nexti Likestepi , proceed function calls continue Resume execution finish Run current function returns Examining code disas Disassemble current function disas sum Disassemble function sum disas 0x8048397 Disassemble function around address 0x8048397 disas 0x8048394 0x80483a4 Disassemble code within speciﬁed address range print /x $eip Print program counter hex Examining data print $eax Print contents %eax decimal print /x $eax Print contents %eax hex print /t $eax Print contents %eax binary print 0x100 Print decimal representation 0x100 print /x 555 Print hex representation 555 print /x ($ebp+8) Print contents %ebp plus 8 hex print *(int *) 0xfff076b0 Print integer address 0xfff076b0 print *(int *) ($ebp+8) Print integer address %ebp +8 x/2w 0xfff076b0 Examine two (4-byte) words starting address 0xfff076b0 x/20b sum Examine ﬁrst 20 bytes function sum Useful information info frame Information current stack frame info registers Values registers help Get information gdb Figure 3.30 Example gdb commands. examples illustrate ways gdb supports debugging machine-level programs.256 Chapter 3 Machine-Level Representation Programs .Recursion often replaced iteration. example, recursive factorial function rfact (Fig- ure 3.25) compiled code similar generated loop implementation (Figure 3.15). Again, lead surprises try monitor program execution debugger. optimizations signiﬁcantly improve program performance, make mapping source machine code much difﬁcult discern. make programs moredifﬁcult debug. Nonetheless, higher level optimizations become standard, sothose study programs machine level must become familiar possible optimizations may encounter. 3.12 Out-of-Bounds Memory References Buffer Overﬂow seen C perform bounds checking array references, local variables stored stack along state information suchas saved register values return addresses. combination lead seriousprogram errors, state stored stack gets corrupted write anout-of-bounds array element. program tries reload registeror execute ret instruction corrupted state, things go seriously wrong. particularly common source state corruption known buffer overﬂow . Typically character array allocated stack hold string, size string exceeds space allocated array. demonstrated following program example: 1/* Sample implementation library function gets() */ 2char *gets(char *s) 3{ 4 int c; 5 char *dest = s; 6 int gotchar = 0; /* least one character read? */ 7 ((c = getchar()) != ’\n’ && c != EOF) { 8 *dest++ = c; /* bounds checking! */ 9 gotchar = 1; 10 } 11 *dest++ = ’\0’; /* Terminate string */ 12 (c == EOF && !gotchar) 13 return NULL; /* End file error */ 14 return s; 15 } 16Section 3.12 Out-of-Bounds Memory References Buffer Overﬂow 257 17 /* Read input line write back */ 18 void echo() 19 { 20 char buf[8]; /* Way small! */ 21 gets(buf); 22 puts(buf); 23 } preceding code shows implementation library function gets demonstrate serious problem function. reads line thestandard input, stopping either terminating newline character someerror condition encountered. copies string location designated byargument s, terminates string null character. show use gets function echo , simply reads line standard input echoes back standard output. problem gets way determine whether sufﬁcient space allocated hold entire string. echo example, purposely made buffer small—just eight characters long. stringlonger seven characters cause out-of-bounds write. Examining assembly code generated gccforecho shows stack organized. 1echo: 2 pushl %ebp Save %ebp stack 3 movl %esp, %ebp 4 pushl %ebx Save %ebx 5 subl $20, %esp Allocate 20 bytes stack 6 leal -12(%ebp), %ebx Compute buf %ebp-12 7 movl %ebx, (%esp) Store buf top stack 8 call gets Call gets 9 movl %ebx, (%esp) Store buf top stack 10 call puts Call puts 11 addl $20, %esp Deallocate stack space 12 popl %ebx Restore %ebx 13 popl %ebp Restore %ebp 14 ret Return see example program stores contents registers %ebp and%ebx stack, allocates additional 20 bytes subtracting 20 stack pointer (line 5). location character array bufis computed 12 bytes %ebp (line 6), stored value %ebx , illustrated Figure 3.31. long user types seven characters, string returnedbygets (including terminating null) ﬁt within space allocated buf. longer string, however, cause gets overwrite information258 Chapter 3 Machine-Level Representation Programs Figure 3.31 Stack organization echo function. Character arraybuf part saved state. out-of-bounds write buf corrupt program state.Stack frame caller Stack frame forechoReturn address Saved%ebp Saved%ebx%ebp [7] [6] [5] [4] [3] [2] [1] [0] buf stored stack. string gets longer, following information get corrupted: Characters typed Additional corrupted state 0–7 None 8–11 Saved value %ebx 12–15 Saved value %ebp 16–19 Return address 20+ Saved state caller table indicates, corruption cumulative—as number char- acters increases, state gets corrupted. Depending portions state affected, program misbehave several different ways: .If stored value %ebx corrupted, register restored properly line 12, caller able rely integrity ofthis register, even though callee-saved. .If stored value %ebp corrupted, register restored properly line 13, caller able reference localvariables parameters properly. .If stored value return address corrupted, retinstruction (line 14) cause program jump totally unexpected location. None behaviors would seem possible based C code. impact out-of-bounds writing memory functions gets under- stood studying program machine-code level. code echo simple sloppy. better version involves using function fgets , includes argument count maximum number bytes read. Problem 3.68 asks write echo function handle input string arbitrary length. general, using gets function overﬂow storage considered bad programming practice. C compiler evenproduces following error message compiling ﬁle containing call togets :“ h e gets function dangerous used.” Unfortunately,Section 3.12 Out-of-Bounds Memory References Buffer Overﬂow 259 number commonly used library functions, including strcpy ,strcat , sprintf , property generate byte sequence without given indication size destination buffer [94]. conditions canlead vulnerabilities buffer overﬂow. Practice Problem 3.43 Figure 3.32 shows (low-quality) implementation function reads linefrom standard input, copies string newly allocated storage, returns apointer result. Consider following scenario. Procedure getline called return address equal 0x8048643 , register %ebp equal 0xbffffc94 , register %ebx equal 0x1, register %edi equal 0x2, register %esi equal 0x3.Y u type string “ 012345678901234567890123 ”. program terminates (a) C code 1/* low-quality code. 2 intended illustrate bad programming practices. 3 See Problem 3.43. */ 4char *getline() 5{ 6 char buf[8]; 7 char *result; 8 gets(buf); 9 result = malloc(strlen(buf)); 10 strcpy(result, buf); 11 return result; 12 } (b) Disassembly call gets 1080485c0 <getline>: 2 80485c0: 55 push %ebp 3 80485c1: 89 e5 mov %esp,%ebp 4 80485c3: 83 ec 28 sub $0x28,%esp 5 80485c6: 89 5d f4 mov %ebx,-0xc(%ebp) 6 80485c9: 89 75 f8 mov %esi,-0x8(%ebp) 7 80485cc: 89 7d fc mov %edi,-0x4(%ebp) Diagram stack point 8 80485cf: 8d 75 ec lea -0x14(%ebp),%esi 9 80485d2: 89 34 24 mov %esi,(%esp) 10 80485d5: e8 a3 ff ff ff call 804857d <gets> Modify diagram show stack contents point Figure 3.32 C disassembled code Problem 3.43.260 Chapter 3 Machine-Level Representation Programs segmentation fault. run gdb determine error occurs execution retinstruction getline . A. Fill diagram follows, indicating much stack executing instruction line 7 disassembly. Labelthe quantities stored stack (e.g., “Return address”) right, andtheir hexadecimal values (if known) within box. box represents 4bytes. Indicate position %ebp . 08 04 86 43 Return address B. Modify diagram show effect call gets (line 10). C. address program attempt return?D. register(s) corrupted value(s) getline returns? E. Besides potential buffer overﬂow, two things wrong code getline ? pernicious use buffer overﬂow get program perform function would otherwise unwilling do. one mostcommon methods attack security system computer network.Typically, program fed string contains byte encoding someexecutable code, called exploit code , plus extra bytes overwrite return address pointer exploit code. effect executing ret instruction jump exploit code. one form attack, exploit code uses system call start shell program, providing attacker range operating system functions.In another form, exploit code performs otherwise unauthorized task,repairs damage stack, executes reta second time, causing (apparently) normal return caller. example, famous Internet worm November 1988 used four dif- ferent ways gain access many computers across Internet. One wasa buffer overﬂow attack ﬁnger daemon fingerd , serves requests ﬁnger command. invoking ﬁnger appropriate string, worm could make daemon remote site buffer overﬂow execute codethat gave worm access remote system. worm gained access asystem, would replicate consume virtually machine’s comput-ing resources. consequence, hundreds machines effectively paralyzeduntil security experts could determine eliminate worm. author ofSection 3.12 Out-of-Bounds Memory References Buffer Overﬂow 261 worm caught prosecuted. sentenced 3 years probation, 400 hours community service, $10,500 ﬁne. Even day, however,people continue ﬁnd security leaks systems leave vulnerable tobuffer overﬂow attacks. highlights need careful programming. Anyinterface external environment made “bullet proof” nobehavior external agent cause system misbehave. Aside Worms viruses worms viruses pieces code attempt spread among computers. described Spafford [102], worm program run propagate fully working version machines. virus piece code adds programs, including operating systems. cannot run independently. popular press, term “virus” used refer variety different strategies spreading attacking code among systems, hear people saying “virus” properly called “worm.” 3.12.1 Thwarting Buffer Overﬂow Attacks Buffer overﬂow attacks become pervasive caused many problems computer systems modern compilers operating systemshave implemented mechanisms make difﬁcult mount attacksand limit ways intruder seize control system via bufferoverﬂow attack. section, present ones provided recentversions gccfor Linux. Stack Randomization order insert exploit code system, attacker needs inject code well pointer code part attack string. Generatingthis pointer requires knowing stack address string located.Historically, stack addresses program highly predictable. allsystems running combination program operating system version,the stack locations fairly stable across many machines. So, example, ifan attacker could determine stack addresses used common Web server,it could devise attack would work many machines. Using infectiousdisease analogy, many systems vulnerable exact strain ofa virus, phenomenon often referred security monoculture [93]. idea stack randomization make position stack vary one run program another. Thus, even many machines running identicalcode, would using different stack addresses. implemented allocating random amount space 0 nbytes stack start program, example, using allocation function alloca , allocates space speciﬁed number bytes stack. allocated space isnot used program, causes subsequent stack locations vary fromone execution program another. allocation range nneeds large enough get sufﬁcient variations stack addresses, yet small enough itdoes waste much space program.262 Chapter 3 Machine-Level Representation Programs following code shows simple way determine “typical” stack address: 1int main() { 2 int local; 3 printf("local %p\n", &local); 4 return 0; 5} code simply prints address local variable main function. Running code 10,000 times Linux machine 32-bit mode, addresses ranged 0xff7fa7e0 to0xffffd7e0 , range around 223. comparison, running older Linux system, address occurred every time. Runningin 64-bit mode newer machine, addresses ranged 0x7fff00241914 to0x7ffffff98664 , range nearly 2 32. Stack randomization become standard practice Linux systems. one larger class techniques known address-space layout randomization , ASLR [95]. ASLR, different parts program, including programcode, library code, stack, global variables, heap data, loaded differentregions memory time program run. means program runningon one machine different address mappings programrunning machines. thwart forms attack. Overall, however, persistent attacker overcome randomization brute force, repeatedly attempting attacks different addresses. common trick isto include long sequence nop(pronounced “no op,” short “no operation”) instructions actual exploit code. Executing instruction ef-fect, incrementing program counter next instruction. longas attacker guess address somewhere within sequence, programwill run sequence hit exploit code. common term forthis sequence “nop sled” [94], expressing idea program “slides”through sequence. set 256-byte nop sled, randomization overn=2 23can cracked enumerating 215=32,768 starting addresses, entirely feasible determined attacker. 64-bit case, trying enumer- ate 224=16,777,216 bit daunting. see stack randomization aspects ASLR increase effort required successfully attack asystem, therefore greatly reduce rate virus worm spread,but cannot provide complete safeguard. Practice Problem 3.44 Running stack-checking code 10,000 times system running Linux ver-sion 2.6.16, obtained addresses ranging minimum 0xffffb754 maximum 0xffffd754 . A. approximate range addresses? B. attempted buffer overrun 128-byte nop sled, many attempts would take exhaustively test starting addresses?Section 3.12 Out-of-Bounds Memory References Buffer Overﬂow 263 Figure 3.33 Stack organization echo function stack protector enabled. special “canary” value ispositioned array buf saved state. code checks canaryvalue determine whether stack state corrupted.Stack frame caller Stack frame forechoReturn address Saved%ebp Saved%ebx Canary%ebp [7] [6] [5] [4] [3] [2] [1] [0] buf Stack Corruption Detection second line defense able detect stack corrupted. saw example echo function (Figure 3.31) corruption typically occurs overrun bounds local buffer. C, noreliable way prevent writing beyond bounds array. Instead, tryto detect write occurred harmful effects occur. Recent versions gccincorporate mechanism known stack protector generated code detect buffer overruns. idea store special canary value 4in stack frame local buffer rest stack state, illustrated Figure 3.33 [32, 94]. canary value, also referred guard value , generated randomly time program run, easy way attacker determine is. restoring register state andreturning function, program checks canary altered bysome operation function one called. so, program abortswith error. Recent versions gcctry determine whether function vulnerable stack overﬂow, insert type overﬂow detection automatically. fact,for earlier demonstration stack overﬂow, give command-lineoption “ -fno-stack-protector ” prevent gccfrom inserting code. compile function echo without option, hence stack protector enabled, get following assembly code: 1echo: 2 pushl %ebp 3 movl %esp, %ebp 4 pushl %ebx 5 subl $20, %esp 6 movl %gs:20, %eax Retrieve canary 7 movl %eax, -8(%ebp) Store stack 4. term “canary” refers historic use birds detect presence dangerous gasses coal mines.264 Chapter 3 Machine-Level Representation Programs 8 xorl %eax, %eax Zero register 9 leal -16(%ebp), %ebx Compute buf %ebp-16 10 movl %ebx, (%esp) Store buf top stack 11 call gets Call gets 12 movl %ebx, (%esp) Store buf top stack 13 call puts Call puts 14 movl -8(%ebp), %eax Retrieve canary 15 xorl %gs:20, %eax Compare stored value 16 je .L19 =, goto ok 17 call __stack_chk_fail Stack corrupted! 18 .L19: ok: 19 addl $20, %esp Normal return ... 20 popl %ebx 21 popl %ebp 22 ret see version function retrieves value memory (line 6) stores stack offset −8 %ebp . instruction argument %gs:20 indication canary value read memory using segmented addressing , addressing mechanism dates back 80286 seldom found programs running modern systems. storing canary specialsegment, marked “read only,” attacker cannot overwrite thestored canary value. restoring register state returning, functioncompares value stored stack location canary value (via xorl instruction line 15.) two identical, xorl instruction yield 0, function complete normal fashion. nonzero value indicatesthat canary stack modiﬁed, code call errorroutine. Stack protection good job preventing buffer overﬂow attack corrupting state stored program stack. incurs small performancepenalty, especially gcc inserts local buffer typechar function. course, ways corrupt state executing program, reducing vulnerability stack thwarts manycommon attack strategies. Practice Problem 3.45 function intlen , along functions len andiptoa , provides convoluted way computing number decimal digits required representan integer. use way study aspects gccstack protector facility. int len(char *s) { return strlen(s); } void iptoa(char *s, int *p)Section 3.12 Out-of-Bounds Memory References Buffer Overﬂow 265 { int val = *p; sprintf(s, "%d", val); } int intlen(int x) { int v; char buf[12];v=x ;iptoa(buf, &v);return len(buf); } following show portions code intlen , compiled without stack protector: Without protector 1 subl $36, %esp 2 movl 8(%ebp), %eax 3 movl %eax, -8(%ebp) 4 leal -8(%ebp), %eax 5 movl %eax, 4(%esp) 6 leal -20(%ebp), %ebx 7 movl %ebx, (%esp) 8 call iptoa protector 1 subl $52, %esp 2 movl %gs:20, %eax 3 movl %eax, -8(%ebp) 4 xorl %eax, %eax 5 movl 8(%ebp), %eax 6 movl %eax, -24(%ebp) 7 leal -24(%ebp), %eax 8 movl %eax, 4(%esp) 9 leal -20(%ebp), %ebx 10 movl %ebx, (%esp) 11 call iptoa A. versions: positions stack frame buf,v, (when present) canary value? B. would rearranged ordering local variables protected code provide greater security buffer overrun attack?266 Chapter 3 Machine-Level Representation Programs Limiting Executable Code Regions ﬁnal step eliminate ability attacker insert executable code system. One method limit memory regions hold executable code.In typical programs, portion memory holding code generated bythe compiler need executable. portions restricted allowjust reading writing. see Chapter 9, virtual memory spaceis logically divided pages , typically 2048 4096 bytes per page. hardware supports different forms memory protection , indicating forms access allowed user programs operating system kernel.Many systems allow control three forms access: read (reading data frommemory), write (storing data memory), execute (treating memorycontents machine-level code). Historically, x86 architecture merged theread execute access controls single 1-bit ﬂag, page marked asreadable also executable. stack kept readable writable,and therefore bytes stack also executable. Various schemes wereimplemented able limit pages readable executable,but generally introduced signiﬁcant inefﬁciencies. recently, AMD introduced “NX” (for “no-execute”) bit memory protection 64-bit processors, separating read execute accessmodes, Intel followed suit. feature, stack marked readable writable, executable, checking whether page isexecutable performed hardware, penalty efﬁciency. types programs require ability dynamically generate ex- ecute code. example, “just-in-time” compilation techniques dynamically gen-erate code programs written interpreted languages, Java, improveexecution performance. Whether restrict executable code justthat part generated compiler creating original program depends language operating system. techniques outlined—randomization, stack protection, lim- iting portions memory hold executable code—are three mostcommon mechanisms used minimize vulnerability programs bufferoverﬂow attacks. properties require special efforton part programmer incur little performance penalty.Each separately reduces level vulnerability, combination be-come even effective. Unfortunately, still ways attack computers[81, 94], worms viruses continue compromise integrity manymachines. Web Aside ASM:EASM Combining assembly code C programs Althoug h C compiler good job converting computations express program machine code, features machine cannot accessed b C program. example, IA32 machines condition code PF(for “parity ﬂag”) set 1 even number ones low-order 8 bits computed result. Computing information CSection 3.13 x86-64: Extending IA32 64 Bits 267 requires least seven shifting, masking, exclusive-or operations (see Problem 2.65). ironic hardware performs computation part every arithmetic logical operation, thereis way C program determine value PFcondition code. two ways incorporate assembly code C programs. First, write entire function separate assembly-code ﬁle let assembler linker combine code wehave written C. Second, use inline assembly feature gcc, brief sections assembly code incorporated int C program using asmdirective. approach advantage minimizes amount machine-speciﬁc code. course, including assembly code n C program makes code speciﬁc particular class machines (such IA32), used desired feature accessed way. 3.13 x86-64: Extending IA32 64 Bits Intel’s IA32 instruction set architecture (ISA) dominant instruction format world’s computers many years. IA32 platform ofchoice Windows, Linux, and, since 2006, even Macintosh computers. TheIA32 format used today was, part, deﬁned 1985 introduc-tion i386 microprocessor, extending 16-bit instruction set deﬁned original 8086 32 bits. Even though subsequent processor generations in-troduced new instruction types formats, many compilers, including gcc, avoided using features interest maintaining backward compatibility.For example, saw Section 3.6.6 conditional move instructions, intro-duced Intel 1995, yield signiﬁcant efﬁciency improvements moretraditional conditional branches, yet conﬁgurations gccwill generate instructions. shift underway 64-bit version Intel instruction set. Originally developed Advanced Micro Devices (AMD) named x86-64 ,i ti sn w supported processors AMD (who call AMD64 ) Intel, refer Intel64 . people still refer “x86-64,” follow convention. (Some vendors shortened simply “x64”.) Newer versionsof Linux Windows support extension, although systems still run 32-bit versions operating systems. extending gccto support x86-64, developers saw opportunity also make use instruction-setfeatures added recent generations IA32 processors. combination new hardware revised compiler makes x86-64 code substantially different form performance IA32 code. creatingthe 64-bit extension, AMD engineers adopted features found inreduced instruction set computers (RISC) [49] made favored targetsfor optimizing compilers. example, 16 general-purpose registers,rather performance-limiting 8 original 8086. developers gcc able exploit features, well recent generations IA32 architecture, obtain substantial performance improvements. example, procedure parameters passed via registers rather thestack, greatly reducing number memory read write operations.268 Chapter 3 Machine-Level Representation Programs section serves supplement description IA32, describing extensions hardware software support accommodatex86-64. assume readers already familiar IA32. start briefhistory AMD Intel arrived x86-64, followed summary themain features distinguish x86-64 code IA32 code, work ourway individual features. 3.13.1 History Motivation x86-64 many years since introduction i386 1985, capabilities microprocessors changed dramatically. 1985, fully conﬁgured high-enddesktop computer, Sun-3 workstation sold Sun Microsystems, hadat 8 megabytes random-access memory (RAM) 100 megabytes ofdisk storage. used Motorola 68020 microprocessor (Intel microprocessors ofthat era necessary features performance high-end ma-chines) 12.5-megahertz clock ran around 4 million instructions persecond. Nowadays, typical high-end desktop system 4 gigabytes RAM(512×increase), 1 terabyte disk storage (10,000 ×increase), nearly 4- gigahertz clock, running around 5 billion instructions per second (1250 ×increase). Microprocessor-based systems become pervasive. Even today’s supercom-puters based harnessing power many microprocessors computing inparallel. Given large quantitative improvements, remarkable theworld’s computing base mostly runs code binary compatible machinesthat existed back 1985 (except nearly enough memoryto handle today’s operating systems applications). 32-bit word size IA32 become major limitation growing capacity microprocessors. signiﬁcantly, word size machinedeﬁnes range virtual addresses programs use, giving 4-gigabytevirtual address space case 32 bits. feasible buy thanthis amount RAM machine, system cannot make effective useof it. applications involve manipulating large data sets, scientiﬁccomputing, databases, data mining, 32-bit word size makes life difﬁcult programmers. must write code using out-of-core algorithms, 5where data reside disk explicitly read memory processing. progress computing technology requires shifting larger word size. Following tradition growing word sizes doubling, next logicalstep 64 bits. fact, 64-bit machines available time. DigitalEquipment Corporation introduced Alpha processor 1992, becamea popular choice high-end computing. Sun Microsystems introduced 64-bit version SPARC architecture 1995. time, however, Intel nota serious contender high-end computers, company less pressure switch 64 bits. 5. physical memory machine often referred core memory, dating era bit random-access memory implemented magnetized ferrite core.Section 3.13 x86-64: Extending IA32 64 Bits 269 Intel’s ﬁrst foray 64-bit computers Itanium processors, based totally new instruction set, known “IA64.” Unlike Intel’s historic strategyof maintaining backward compatibility introduced new generation ofmicroprocessor, IA64 based radically new approach jointly developedwith Hewlett-Packard. Large Instruction Word (VLIW) format packs multiple instructions bundles, allowing higher degrees parallel execution.Implementing IA64 proved difﬁcult, ﬁrst Itanium chips didnot appear 2001, achieve expected level performanceon real applications. Although performance Itanium-based systems hasimproved, captured signiﬁcant share computer market.Itanium machines execute IA32 code compatibility mode, withvery good performance. users preferred make less expensive,and often faster, IA32-based systems. Meanwhile, Intel’s archrival, Advanced Micro Devices (AMD), saw op- portunity exploit Intel’s misstep IA64. years, AMD lagged justbehind Intel technology, relegated competing Intel basis price. Typically, Intel would introduce new microprocessor pricepremium. AMD would come along 6 12 months later undercutIntel signiﬁcantly get sales—a strategy worked yielded lowproﬁts. 2003, AMD introduced 64-bit microprocessor based “x86-64”instruction set. name implies, x86-64 evolution Intel instruc-tion set 64 bits. maintains full backward compatibility IA32, addsnew data formats, well features enable higher capacity higher performance. x86-64, AMD captured high-end market historically belonged Intel. AMD’s recent generations processors in-deed proved successful high-performance machines. recently, AMDhas renamed instruction set AMD64 , “x86-64” persists favored name. Intel realized strategy complete shift IA32 IA64 working, began supporting variant x86-64 2004 withprocessors Pentium 4 Xeon line. Since already used name“IA64” refer Itanium, faced difﬁculty ﬁnding ownname 64-bit extension. end, decided describe x86-64 enhancement IA32, referred IA32-EM64T , “Enhanced Memory 64-bit Technology.” late 2006, adopted name Intel64 . compiler side, developers gcc steadfastly maintained binary compatibility i386, even useful features added IA32instruction set, including conditional moves modern set ﬂoating-point instructions. features would used code compiledwith special settings command-line options. Switching x86-64 targetprovided opportunity gccto give backward compatibility instead exploit newer features even standard command-line options. text, use “IA32” refer combination hardware gcc code found traditional 32-bit versions Linux running Intel-based machines. use “x86-64” refer hardware code combination runningon newer 64-bit machines AMD Intel. worlds Linux andgcc, two platforms referred “i386” “x86_64,” respectively.270 Chapter 3 Machine-Level Representation Programs 3.13.2 Overview x86-64 combination new hardware supplied Intel AMD, new versions gcctargeting machines makes x86-64 code substantially different generated IA32 machines. main features include: .Pointers long integers 64 bits long. Integer arithmetic operationssupport 8, 16, 32, 64-bit data types. .The set general-purpose registers expanded 8 16. .Much program state held registers rather stack. Integer pointer procedure arguments (up 6) passed via registers. procedures need access stack all. .Conditional operations implemented using conditional move instructionswhen possible, yielding better performance traditional branching code. .Floating-point operations implemented using register-oriented in-struction set introduced SSE version 2, rather stack-based ap-proach supported IA32. Data Types Figure 3.34 shows sizes different C data types x86-64, comparesthem sizes IA32 (rightmost column). see pointers (shown hereas data type char * ) require 8 bytes rather 4. referred quad words Intel, since 4 times longer nominal 16-bit “word.” principle, gives programs ability access 2 64bytes, 16 exabytes , memory (around 18 .4×1018bytes). seems like astonishing amount memory, keep mind 4 gigabytes seemed like extremely large amount memory ﬁrst 32-bit machines appeared late 1970s. Inpractice, machines really support full address range—the current Assembly x86-64 C declaration Intel data type code sufﬁx size (bytes) IA32 Size char Byte b 11 short Word w 22 int Double word l 44 long int Quad word q 84 long long int Quad word q 88 char * Quad word q 84 float Single precision 44 double Double precision 88 long double Extended precision 10/16 10/12 Figure 3.34 Sizes standard data types x86-64. compared sizes IA32. long integers pointers require 8 bytes, compared 4 IA32.Section 3.13 x86-64: Extending IA32 64 Bits 271 generations AMD Intel x86-64 machines support 256 terabytes (248bytes) virtual memory—but allocating full 64 bits pointers good idea forlong-term compatibility. also see preﬁx “ long ” changes integers 64 bits, allowing considerably larger range values. fact, data type long becomes identical tolong long . Moreover, hardware provides registers hold 64-bit integers instructions operate quad words. IA32, long preﬁx also changes ﬂoating-point double use 80-bit format supported IA32 (Section 2.4.6). stored memorywith allocation 16 bytes x86-64, compared 12 bytes IA32. Thisimproves performance memory read write operations, typicallyfetch 8 16 bytes time. Whether 12 16 bytes allocated, low-order 10 bytes actually used. Moreover, long double data type supported older class ﬂoating-point instructions idiosyn-cratic properties (see Web Aside data:ia32-fp ), float anddouble data types supported recent SSE instructions. long double data type used programs requiring additional precision andrange extended-precision format provides double-precision format. Practice Problem 3.46 shown Figure 6.17(b), cost DRAM, memory technology usedto implement main memories microprocessors, dropped around$8,000 per megabyte 1980 around $0.06 2010, roughly factor 1.48 every year, around 51 every 10 years. Let us assume trends continue indeﬁnitely (which may realistic), budget machine’smemory around $1,000, would conﬁgured machine with128 kilobytes 1980 16.3 gigabytes 2010. A. Estimate $1,000 budget would pay 256 terabytes memory. B. Estimate $1,000 budget would pay 16 exabytes memory.C. much earlier would transition points occur raised DRAM budget $10,000? Assembly-Code Example Section 3.2.3, presented IA32 assembly code generated gcc function simple . C code simple_l , similar simple , except uses long integers: long int simple_l(long int *xp, long int y) { long tt=* x p+y ; * x p=t ; return t; }272 Chapter 3 Machine-Level Representation Programs gccis run x86-64 Linux machine command line unix> gcc -O1 -S -m32 code.c generates code compatible IA32 machine (we annotate code highlight instructions read (R) data memory instructionswrite (W) data memory): IA32 implementation function simple_l. xp %ebp+ 8 ,ya %ebp+12 1simple_l: 2 pushl %ebp Save frame pointer (W) 3 movl %esp, %ebp Create new frame pointer 4 movl 8(%ebp), %edx Retrieve xp (R) 5 movl 12(%ebp), %eax Retrieve yp (R) 6 addl (%edx), %eax Add *xp get (R) 7 movl %eax, (%edx) Store xp (W) 8 popl %ebp Restore frame pointer (R) 9 ret Return (R) instruct gccto generate x86-64 code unix> gcc -O1 -S -m64 code.c (on machines, ﬂag -m64 required), get different code: x86-64 version function simple_l. xp %rdi, %rsi 1simple_l: 2 movq %rsi, %rax Copy 3 addq (%rdi), %rax Add *xp get (R) 4 movq %rax, (%rdi) Store xp (W) 5 ret Return (R) key differences include: .Instead movl andaddl instructions, see movq andaddq . pointers variables declared long integers 64 bits (quad words) ratherthan 32 bits (long words). .We see 64-bit versions registers (e.g., %rsi and%rdi , rather %esi and%edi ). procedure returns value storing register %rax . .No stack frame gets generated x86-64 version. eliminates instructions set (lines 2–3) remove (line 8) stack frame theIA32 code. .Arguments xpandyare passed registers ( %rdi and%rsi , respectively) rather stack. eliminates need fetch arguments frommemory.Section 3.13 x86-64: Extending IA32 64 Bits 273 net effect changes IA32 code consists eight instruc- tions making seven memory references (ﬁve reads, two writes), x86-64code consists four instructions making three memory references (two reads,one write). relative performance two versions depends greatly thehardware executed. Running Intel Pentium 4E, one ofthe ﬁrst Intel machines support x86-64, found IA32 version requiresaround 18 clock cycles per call simple_l , x86-64 version requires 12. 50% performance improvement machine Ccode quite striking. newer Intel Core i7 processor, found ver-sions required around 12 clock cycles, indicating performance improvement.On machines tried, performance difference lies somewhere be-tween two extremes. general, x86-64 code compact, requires fewermemory accesses, runs efﬁciently corresponding IA32 code. 3.13.3 Accessing Information Figure 3.35 shows set general-purpose registers x86-64. Compared registers IA32 (Figure 3.2), see number differences: .The number registers doubled 16. .All registers 64 bits long. 64-bit extensions IA32 registers arenamed %rax ,%rcx ,%rdx ,%rbx ,%rsi ,%rdi ,%rsp , %rbp . new registers named %r8–%r15 . .The low-order 32 bits register accessed directly. gives us familiar registers IA32: %eax ,%ecx ,%edx ,%ebx ,%esi ,%edi ,%esp , and%ebp , well eight new 32-bit registers: %r8d –%r15d . .The low-order 16 bits register accessed directly, case IA32. word-size versions new registers named %r8w –%r15w . .The low-order 8 bits register accessed directly. true IA32 ﬁrst four registers ( %al,%cl,%dl,%bl). byte-size versions IA32 registers named %sil ,%dil ,%spl , %bpl . byte-size versions new registers named %r8b –%r15b . .For backward compatibility, second byte registers %rax ,%rcx ,%rdx , %rbx directly accessed instructions single-byte operands. IA32, registers used interchangeably, special cases. Register %rsp special status, holds pointer top stack element. Unlike IA32, however, frame pointerregister; register %rbp available use general-purpose register. Particular conventions used passing procedure arguments via registers registers saved restored procedure calls, discussedin Section 3.13.4. addition, arithmetic instructions make special use ofregisters %rax and%rdx . part, operand speciﬁers x86-64 IA32 (see Figure 3.3), except base index register identiﬁers must274 Chapter 3 Machine-Level Representation Programs %ah31 63 15 8 7 0 %eax %ax %al %bh %ebx %bx %bl %ch %ecx %cx %cl %dh %edx %dx %esi %si %edi %di %ebp %bp %esp%rax %rbx%rcx%rdx %rsi %rdi%rbp%rsp %sp%dl %sil %dil %bpl%spl %r8d %r8 %r8w %r8b %r9 %r10 %r11 %r12 %r13 %r14 %r15Return value Callee saved4th argument3rd argument2nd argument1st argumentCallee savedStack pointer 5th argument 6th argumentCaller savedCaller savedCallee savedCallee savedCallee savedCallee saved %r9d %r9w %r9b %r10d %r10w %r10b %r11d %r11w %r11b%r12d %r12w %r12b%r13d %r13w %r13b%r14d %r14w %r14b%r15d %r15w %r15b Figure 3.35 Integer registers. existing eight registers extended 64-bit versions, eight new registers added. register accessed either 8 bits (byte), 16 bits (word), 32 bits (double word), 64 bits (quad word).Section 3.13 x86-64: Extending IA32 64 Bits 275 use ‘ r’ version register (e.g., %rax ) rather ‘ e’ version. addition IA32 addressing forms, forms PC-relative operand addressing supported. IA32, form addressing supported jump andother control transfer instructions (see Section 3.6.3). mode provided tocompensate fact offsets (shown Figure 3.3 Imm ) 32 bits long. viewing ﬁeld 32-bit two’s-complement number, instructions access data within window around ±2.15×10 9relative program counter. x86-64, program counter named %rip . example PC-relative data addressing, consider following proce- dure, calls function simple_l examined earlier: long int gval1 = 567; long int gval2 = 763; long int call_simple_l() { long z = simple_l(&gval1, 12L); retur n z + gval2; } code references global variables gval1 andgval2 . function compiled, assembled, linked, get following executable code (asgenerated disassembler objdump ): 1 0000000000400541 <call_simple_l>: 2 400541: 0c 00 00 00 mov $0xc,%esi Load 12 2nd argument 3 400546: bf 20 10 60 00 mov $0x601020,%edi Load &gval1 1st argument 4 40054b: e8 c3 ff ff ff callq 400513 <simple_l> Call simple_l 5 400550: 48 03 05 d1 0a 20 00 add 0x200ad1(%rip),%rax Add gval2 result 6 400557: c3 retq Return instruction line 3 stores address global variable gval1 register %rdi . copying constant value 0x601020 register %edi .T h e upper 32 bits %rdi automatically set zero. instruction line 5 retrieves value gval2 adds value returned call simple_l . see PC-relative addressing—the immediate value 0x200ad1 added address following instruction get 0x200ad1 +0x400557 =0x601028 . Figure 3.36 documents data movement instructions available x86-64 beyond found IA32 (see Figure 3.4). instructions require destination register, indicated R. Others either register memory location destination, indicated D. instructions fall within class instructions seen IA32. movabsq instruction, hand, counterpart IA32. instruction copy full 64-bit immediatevalue destination register. movq instruction immediate value source operand, limited 32-bit value, sign-extended 64 bits.276 Chapter 3 Machine-Level Representation Programs Instruction Effect Description movabsq I,RR ←I Move absolute quad word mov S,DD ←S Move movq Move quad word movs S,DD ←SignExtend (S) Move sign extension movsbq Move sign-extended byte quad word movswq Move sign-extended word quad word movslq Move sign-extended double word quad word movz S,DD ←ZeroExtend (S) Move zero extension movzbq Move zero-extended byte quad word movzwq Move zero-extended word quad word pushq R[%rsp ]←R[%rsp ]−8; Push quad word M[R[%rsp ]]←S popq DD ←M[R[%rsp ]]; Pop quad word R[%rsp ]←R[%rsp ]+8 Figure 3.36 Data movement instructions. supplement movement instructions IA32 (Figure 3.4). movabsq instruction allows immediate data (shown I) source value. Others allow immediate data, register, memory (shown S). instructions require destination register (shown R), others allow register memory destinations (shown D). Moving smaller data size larger one involve either sign ex- tension ( movs ) zero extension ( movz ). Perhaps unexpectedly, instructions move generate 32-bit register values also set upper 32 bits registerto zero. Consequently need instruction movzlq . Similarly, instruction movzbq exact behavior movzbl destination register—both set upper 56 bits destination register zero. Thisis contrast instructions generate 8- 16-bit values, movb ; instructions alter bits register. new stack instructionspushq andpopq allow pushing popping 64-bit values. Practice Problem 3.47 following C function converts argument type src_t return value typedst_t , two types deﬁned using typedef : dest_t cvt(src_t x) { dest_ = (dest_t) x; return y; }Section 3.13 x86-64: Extending IA32 64 Bits 277 Assume argument xis appropriately named portion register %rdi (i.e.,%rdi ,%edi ,%di,o r%dil ), form data movement instruction used perform type conversion copy value ap-propriately named portion register %rax . Fill following table indicating instruction, source register, destination register followingcombinations source destination type: src_t dest_t Instruction SD long long movq %rdi %rax int long char long unsigned int unsigned long unsigned char unsigned long long int unsigned long unsigned Arithmetic Instructions Figure 3.7, listed number arithmetic logic instructions, using class name, “ add”, represent instructions different operand sizes, addb (byte), addw (word), addl (long word). classes add instructions operate quad words sufﬁx ‘ q’. Examples quad-word instructions include leaq (load effective address), incq (increment), addq (add), salq (shift left). quad-word instructions argument types shorter counterparts. mentioned earlier, instructions generate 32-bit register results, addl , also set upper 32 bits register zero. Instructions generate 16-bit results, addw , affect 16-bit destination registers, similarly instructions generate 8-bitresults. movq instruction, immediate operands limited 32-values, sign extended 64 bits. mixing operands different sizes, gccmust choose right combina- tions arithmetic instructions, sign extensions, zero extensions. dependon subtle aspects type conversion behavior instructions dif-ferent operand sizes. illustrated following C function: 1 long int gfun(int x, int y) 2 { 3 long int t1 = (long )x+y ; /* 64-bit addition */ 4 long int t2 = (long) (x + y); /* 32-bit addition */ 5 return t1 | t2; 6 } Given integers 32 bits long integers 64, two additions function proceed follows. Recall casting higher precedence thanaddition, line 3 calls xto converted 64 bits, operand278 Chapter 3 Machine-Level Representation Programs promotion yis also converted. Value t1is computed using 64-bit addition. hand, t2is computed line 4 performing 32-bit addition extending value 64 bits. assembly code generated function follows: 1gfun: xi n %rdi,yi n %rsi 2 leal (%rsi,%rdi), %eax Compute t2 32-bit sum x cltq equivalent movslq %eax,%rax 3 cltq Sign extend 64 bits 4 movslq %esi,%rsi Convert long 5 movslq %edi,%rdi Convert x long 6 addq %rdi, %rsi Compute t1 (64-bit addition) 7 orq %rsi, %rax Set t1 | t2 return value 8 ret Return Local value t2is computed leal instruction (line 2), uses 32-bit arithmetic. sign-extended 64 bits using cltq instruction, see special instruction equivalent executing instruction movslq %eax,%rax .T h e movslq instructions lines 4–5 take lower 32 bits arguments sign extend 64 bits registers. addq instruction line 6 performs 64-bit addition get t1. Practice Problem 3.48 C function arithprob arguments a,b,c, dhas following body: return a*b + c*d; compiles following x86-64 code: 1arithprob: 2 movslq %ecx,%rcx 3 imulq %rdx, %rcx 4 movsbl %sil,%esi 5 imull %edi, %esi 6 movslq %esi,%rsi 7 leaq (%rcx,%rsi), %rax 8 ret arguments return value signed integers various lengths. Arguments a,b,c, dare passed appropriate regions registers %rdi , %rsi ,%rdx , %rcx , respectively. Based assembly code, write function prototype describing return argument types arithprob . Figure 3.37 show instructions used generate full 128-bit product two 64-bit words, well ones support 64-bit division. similar 32- bit counterparts (Figure 3.9). Several instructions view combinationSection 3.13 x86-64: Extending IA32 64 Bits 279 Instruction Effect Description imulq R[%rdx ]:R[%rax ]←S×R[%rax ] Signed full multiply mulq R[%rdx ]:R[%rax ]←S×R[%rax ] Unsigned full multiply cltq R[%rax ]←SignExtend (R[%eax ]) Convert %eax quad word cqto R[%rdx ]:R[%rax ]←SignExtend (R[%rax ]) Convert oct word idivq R[%rdx ]←R[%rdx ]:R[%rax ] mod S; Signed divide R[%rax ]←R[%rdx ]:R[%rax ]÷S divq R[%rdx ]←R[%rdx ]:R[%rax ] mod S; Unsigned divide R[%rax ]←R[%rdx ]:R[%rax ]÷S Figure 3.37 Special arithmetic operations. operations support full 64-bit multiplication division, signed unsigned numbers. pair registers %rdx and%rax viewed forming single 128-bit oct word. registers %rdx and%rax forming 128-bit oct word . example, imulq andmulq instructions store result multiplying two 64-bit values—the ﬁrst given source operand second register %rax . two divide instructions idivq anddivq start %rdx:%rax 128-bit dividend source operand 64-bit divisor. store quotient register %rax remainder register %rdx . Preparing dividend depends whether unsigned ( divq ) signed ( idivq ) division performed. former case, register %rdx simply set zero. latter case, instruction cqto used perform sign extension, copying sign bit %rax every bit %rdx .6Figure 3.37 also shows instruction cltq sign extend register %eax to%rax .7This instruction shorthand instruction movslq %eax,%rax . 3.13.4 Control control instructions methods implementing control transfers x86-64 IA32 (Section 3.6.) shown Figure 3.38, two newinstructions, cmpq andtestq , added compare test quad words, aug- menting byte, word, double word sizes (Figure 3.10). gccuses conditional data transfer conditional control transfer, since x86-64 ma-chines support conditional moves. illustrate similarity IA32 x86-64 code, consider as- sembly code generated compiling integer factorial function implementedwith loop (Figure 3.15), shown Figure 3.39. seen, 6. ATT-format instruction cqto called cqoin Intel AMD documentation. 7. Instruction cltq called cdqe Intel AMD documentation.280 Chapter 3 Machine-Level Representation Programs Instruction Based Description cmp S2,S1S1-S2 Compare cmpq Compare quad word test S2,S1S1&S2 Test testq Test quad word Figure 3.38 64-bit comparison test instructions. instructions set condition codes without updating registers. (a) IA32 version 1fact_while: na %ebp+8 2 pushl %ebp Save frame pointer 3 movl %esp, %ebp Create new frame pointer 4 movl 8(%ebp), %edx Get n 5 movl $1, %eax Set result = 1 6 cmpl $1, %edx Compare n:1 7 jle .L7 <=, goto done 8.L10: loop: 9 imull %edx, %eax Compute result *= n 10 subl $1, %edx Decrement n 11 cmpl $1, %edx Compare n:1 12 jg .L10 >, goto loop 13 .L7: done: 14 popl %ebp Restore frame pointer 15 ret Return result (b) x86-64 version 1fact_while: ni n %rdi 2 movl $1, %eax Set result = 1 3 cmpl $1, %edi Compare n:1 4 jle .L7 <=, goto done 5.L10: loop: 6 imull %edi, %eax Compute result *= n 7 subl $1, %edi Decrement n 8 cmpl $1, %edi Compare n:1 9 jg .L10 >, goto loop 10 .L7: done: 11 rep (See explanation aside) 12 ret Return result Figure 3.39 IA32 x86-64 versions factorial. compiled C code shown Figure 3.15.Section 3.13 x86-64: Extending IA32 64 Bits 281 two versions similar. differ arguments passed (on stack vs. registers), absence stack frame frame pointer thex86-64 code. Aside rep instruction code? line 11 x86-64 code, see instruction repprecedes return instruction ret. Looking Intel AMD documentation repinstruction, ﬁnd normally used implement repeating string operation [3, 29]. seems completely inappropriate here. answer puzzlecan seen AMD’s guidelines compiler writers [1]. recommend using combination ofrep followed ret avoid making ret instruction destination conditional jump instruction. Without repinstruction, jginstruction would proceed retinstruction branch taken. According AMD, processors cannot properly predict destination aretinstruction reached jump instruction. repinstruction serves form no-operation here, inserting jump destination change behavior code,except make faster AMD processors. Practice Problem 3.49 function fun_c following overall structure: long fun_c(unsigned long x) { long val = 0; int i;for ( ; ; ){ ; } ; return ; } gccC compiler generates following assembly code: 1fun_c: xi n %rdi 2 movl $0, %ecx 3 movl $0, %edx 4 movabsq $72340172838076673, %rsi 5.L2: 6 movq %rdi, %rax 7 andq %rsi, %rax 8 addq %rax, %rcx 9 shrq %rdi Shift right 1 10 addl $1, %edx 11 cmpl $8, %edx 12 jne .L2282 Chapter 3 Machine-Level Representation Programs 13 movq %rcx, %rax 14 sarq $32, %rax 15 addq %rcx, %rax 16 movq %rax, %rdx 17 sarq $16, %rdx 18 addq %rax, %rdx 19 movq %rdx, %rax 20 sarq $8, %rax 21 addq %rdx, %rax 22 andl $255, %eax 23 ret Reverse engineer operation code. ﬁnd useful convert decimal constant line 4 hexadecimal. A. Use assembly-code version ﬁll missing parts C code. B. Describe English code computes. Procedures already seen code samples x86-64 implementation procedure calls differs substantially IA32. doubling register set, programs need dependent stack storing retrievingprocedure information. greatly reduce overhead procedure callsand returns. highlights procedures implemented x86-64: .Arguments (up ﬁrst six) passed procedures via registers, ratherthan stack. eliminates overhead storing retrieving valueson stack. .Thecallq instruction stores 64-bit return address stack. .Many functions require stack frame. functions cannot keep local variables registers need allocate space stack. .Functions access storage stack 128 bytes beyond (i.e., alower address than) current value stack pointer. allows somefunctions store information stack without altering stack pointer. .There frame pointer. Instead, references stack locations maderelative stack pointer. functions allocate total stack storageneeds beginning call keep stack pointer ﬁxed position. .As IA32, registers designated callee-save registers. must saved restored procedure modiﬁes them.Section 3.13 x86-64: Extending IA32 64 Bits 283 Operand Argument Number size (bits) 123456 64 %rdi %rsi %rdx %rcx %r8 %r9 32 %edi %esi %edx %ecx %r8d %r9d 16 %di %si %dx %cx %r8w %r9w 8 %dil %sil %dl %cl %r8b %r9b Figure 3.40 Registers passing function arguments. registers used speciﬁed order named according argument sizes. Argument Passing six integral (i.e., integer pointer) arguments passed via registers. registers used speciﬁed order, name used register de-pending size data type passed. shown Figure 3.40.Arguments allocated registers according ordering ar-gument list. Arguments smaller 64 bits accessed using appropriatesubsection 64-bit register. example, ﬁrst argument 32 bits, canbe accessed %edi . example argument passing, consider following C function eight arguments: void proc(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) { *a1p += a1; *a2p += a2;*a3p += a3;*a4p += a4; } arguments include range different-sized integers (64, 32, 16, 8 bits) well different types pointers, 64 bits. function implemented x86-64 follows: x86-64 implementation function proc Arguments passed follows: a1 %rdi (64 bits) a1p %rsi (64 bits)a2 %edx (32 bits)a2p %rcx (64 bits)a3 %r8w (16 bits)a3p %r9 (64 bits)284 Chapter 3 Machine-Level Representation Programs a4 %rsp+8 (8 bits) a4p %rsp+16 (64 bits) 1proc: 2 movq 16(%rsp), %r10 Fetch a4p (64 bits) 3 addq %rdi, (%rsi) *a1p += a1 (64 bits) 4 addl %edx, (%rcx) *a2p += a2 (32 bits) 5 addw %r8w, (%r9) *a3p += a3 (16 bits) 6 movzbl 8(%rsp), %eax Fetch a4 (8 bits) 7 addb %al, (%r10) *a4p += a4 (8 bits) 8 ret ﬁrst six arguments passed registers, last two positions 8 16 relative stack pointer. Different versions add instruction used according sizes operands: addq fora1(long ),addl fora2(int), addw fora3(short ), addb fora4(char ). Practice Problem 3.50 C function incrprob arguments q,t, xof different sizes, may signed unsigned. function following body: *t += x; *q += *t; compiles following x86-64 code: 1incrprob: 2 addl (%rdx), %edi 3 movl %edi, (%rdx) 4 movslq %edi,%rdi 5 addq %rdi, (%rsi) 6 ret Determine four valid function prototypes incrprob determining ordering possible types three parameters. Stack Frames already seen many compiled functions require stack frame.If local variables held registers, function call functions (sometimes referred leaf procedure , reference tree structure procedure calls), need stack save thereturn address. hand, several reasons function may require stack frame: .There many local variables hold registers. .Some local variables arrays structures.Section 3.13 x86-64: Extending IA32 64 Bits 285 .The function uses address-of operator ( &) compute address local variable. .The function must pass arguments stack another function. .The function needs save state callee-save register modify-ing it. conditions hold, ﬁnd compiled code function creating stack frame. Unlike code IA32, stack pointer ﬂuctuatesback forth values pushed popped, stack frames x86-64procedures usually ﬁxed size, set beginning procedure bydecrementing stack pointer (register %rsp ). stack pointer remains ﬁxed position call, making possible access data using offsets relativeto stack pointer. consequence, frame pointer (register %ebp ) seen IA32 code longer needed. Whenever one function (the caller ) calls another (the callee ), return ad- dress gets pushed onto stack. convention, consider part thecaller’s stack frame, encodes part caller’s state. infor-mation gets popped stack control returns caller, doesnot affect offsets used caller accessing values within stack frame. following function illustrates many aspects x86-64 stack discipline. Despite length example, worth studying carefully. long int call_proc() { long x1 = 1; int x2 = 2; short x3 = 3; char x4 = 4; proc(x1, &x1, x2, &x2, x3, &x3, x4, &x4); return (x1+x2)*(x3-x4); } gccgenerates following x86-64 code. x86-64 implementation call_proc 1call_proc: 2 subq $32, %rsp Allocate 32-byte stack frame 3 movq $1, 16(%rsp) Store 1 &x1 4 movl $2, 24(%rsp) Store 2 &x2 5 movw $3, 28(%rsp) Store 3 &x3 6 movb $4, 31(%rsp) Store 4 &x4 7 leaq 24(%rsp), %rcx Pass &x2 argument 4 8 leaq 16(%rsp), %rsi Pass &x1 argument 2 9 leaq 31(%rsp), %rax Compute &x4 10 movq %rax, 8(%rsp) Pass &x4 argument 8 11 movl $4, (%rsp) Pass 4 argument 7 12 leaq 28(%rsp), %r9 Pass &x3 argument 6 13 movl $3, %r8d Pass 3 argument 5 14 movl $2, %edx Pass 2 argument 3 15 movl $1, %edi Pass 1 argument 1286 Chapter 3 Machine-Level Representation Programs 16 call proc Call 17 movswl 28(%rsp),%eax Get x3 convert int 18 movsbl 31(%rsp),%edx Get x4 convert int 19 subl %edx, %eax Compute x3-x4 20 cltq Sign extend long int 21 movslq 24(%rsp),%rdx Get x2 22 addq 16(%rsp), %rdx Compute x1+x2 23 imulq %rdx, %rax Compute (x1+x2)*(x3-x4) 24 addq $32, %rsp Deallocate stack frame 25 ret Return Figure 3.41(a) illustrates stack frame set execution call_ proc . Function call_proc allocates 32 bytes stack decrementing stack pointer. uses bytes 16–31 hold local variables x1(bytes 16–23), x2(bytes 24–27), x3(bytes 28–29), x4(byte 31). allocations sized according variable types. Byte 30 unused. Bytes 0–7 8–15 stack frame areused hold seventh eighth arguments call_proc , since enough argument registers. parameters allocated eight bytes each, eventhough parameter x4requires single byte. code call_proc ,w e see instructions initializing local variables setting parameters(both registers stack) call call_proc . proc returns, local variables combined compute ﬁnal expression, returnedin register %rax . stack space deallocated simply incrementing stack pointer retinstruction. Figure 3.41(b) illustrates stack execution proc .T h e call instruction pushed return address onto stack, stack pointeris shifted 8 relative position execution call_proc . Figure 3.41 Stack frame structure call_proc .The frame required hold local variables x1through x4, well seventh eighth arguments proc . execution proc (b), stack pointer shifted 8.Stack pointer %rsp (a) call procx1 Argument 8 Argument 724 16 8031 28 x4 x3 x2 Stack pointer %rsp (b) call procx1 Argument 8 Argument 7 Return address32 2416 80x4 x3 x2Section 3.13 x86-64: Extending IA32 64 Bits 287 Hence, within code proc , arguments 7 8 accessed offsets 8 16 stack pointer. Observe call_proc changed stack pointer execu- tion. gccdetermined 32 bytes would sufﬁce holding local variables holding additional arguments proc . Minimizing amount move- ment stack pointer simpliﬁes compiler’s task generating reference tostack elements using offsets stack pointer. Register Saving Conventions saw IA32 (Section 3.7.3) registers used holding temporary values designated caller-saved , function free overwrite values, others callee-saved , function must save values stack writing them. x86-64, following registers designatedas callee-saved: %rbx ,%rbp , %r12 –%r15 . Aside caller-saved temporary registers? 16 general-purpose registers, we’ve seen 6 designated passing arguments, 6 callee-saved temporaries, 1 ( %rax ) holds return value function, 1 ( %rsp ) serves stack pointer. %r10 and%r11 left caller-saved temporary registers. course, argument register used fewer six arguments function done using thatargument, %rax used multiple times ﬁnal result generated. illustrate use callee-saved registers somewhat unusual version recursive factorial function: /* Compute x! store resultp */ void sfact_helper(long int x, long int *resultp) { (x <= 1) *resultp = 1; else { long int nresult; sfact_helper(x-1, &nresult); *result p=x* nresult; } } compute factorial value x, function would called top level follows: long int sfact(long int x) { long int result;sfact_helper(x, &result); return result; }288 Chapter 3 Machine-Level Representation Programs x86-64 code sfact_helper shown below. Arguments: x %rdi, resultp %rsi 1sfact_helper: 2 movq %rbx, -16(%rsp) Save %rbx (callee save) 3 movq %rbp, -8(%rsp) Save %rbp (callee save) 4 subq $40, %rsp Allocate 40 bytes stack 5 movq %rdi, %rbx Copy x %rbx 6 movq %rsi, %rbp Copy resultp %rbp 7 cmpq $1, %rdi Compare x:1 8 jg .L14 >, goto recur 9 movq $1, (%rsi) Store 1 *resultp 10 jmp .L16 Gotodone 11 .L14: recur: 12 leaq 16(%rsp), %rsi Compute &nresult second argument 13 leaq -1(%rdi), %rdi Compute xm1 = x-1 first argument 14 call sfact_helper Call sfact_helper(xm1, &nresult) 15 movq %rbx, %rax Copy x 16 imulq 16(%rsp), %rax Compute x*nresult 17 movq %rax, (%rbp) Store resultp 18 .L16: done: 19 movq 24(%rsp), %rbx Restore %rbx 20 movq 32(%rsp), %rbp Restore %rbp 21 addq $40, %rsp Deallocate stack 22 ret Return Figure 3.42 illustrates sfact_helper uses stack store values callee-saved registers hold local variable nresult . implementation Figure 3.42 Stack frame function sfact_helper .This function decrements thestack pointer saving state.Stack pointer %rsp (a) decrementing stack pointerSaved%rbp Saved%rbx0 –8 –16 +32 +24+16 +8 0Stack pointer %rspSaved%rbp Saved%rbx nresult Unused Unused (b) decrementing stack pointerSection 3.13 x86-64: Extending IA32 64 Bits 289 interesting feature two callee-saved registers uses ( %rbx %rbp ) saved stack (lines 2–3) stack pointer decremented (line 4) allocate stack frame. consequence, stack offset %rbx shifts −16 beginning +24 end (line 19). Similarly, offset for%rbp shifts −8t o+32. able access memory beyond stack pointer unusual feature x86-64. requires virtual memory management system allocate memoryfor region. x86-64 ABI [73] speciﬁes programs use 128 bytes beyond (i.e., lower addresses than) current stack pointer. ABI refers tothis area red zone . must kept available reading writing stack pointer moves. Practice Problem 3.51 C program long int local_array(int i) { long int a[4] = {2L, 3L, 5L, 7L}; n ti x=i&3 ;return a[idx]; } gccgenerates following code: x86-64 implementation local_array Argument: %edi 1local_array: 2 movq $2, -40(%rsp) 3 movq $3, -32(%rsp) 4 movq $5, -24(%rsp) 5 movq $7, -16(%rsp) 6 andl $3, %edi 7 movq -40(%rsp,%rdi,8), %rax 8 ret A. Draw diagram indicating stack locations used function offsets relative stack pointer. B. Annotate assembly code describe effect instruction.C. interesting feature example illustrate x86-64 stack discipline?290 Chapter 3 Machine-Level Representation Programs Practice Problem 3.52 recursive factorial program long int rfact(long int x) { (x <= 0) return 1; else { long int xm1 = x-1; retur n x * rfact(xm1); } } gccgenerates following code: x86-64 implementation recursive factorial function rfact Argument x %rdi 1rfact: 2 pushq %rbx 3 movq %rdi, %rbx 4 movl $1, %eax 5 testq %rdi, %rdi 6 jle .L11 7 leaq -1(%rdi), %rdi 8 call rfact 9 imulq %rbx, %rax 10 .L11: 11 popq %rbx 12 ret A. value function store %rbx ? B. purposes pushq (line 2) popq (line 11) instructions? C. Annotate assembly code describe effect instruction.D. function manage stack frame differently others seen? 3.13.5 Data Structures Data structures follow principles x86-64 IA32: arrays allocated sequences identically sized blocks holding array elements,structures allocated sequences variably sized blocks holding structureelements, unions allocated single block big enough hold largestunion element.Section 3.13 x86-64: Extending IA32 64 Bits 291 One difference x86-64 follows stringent set alignment re- quirements. scalar data type requiring Kbytes, starting address must multiple K. Thus, data types long anddouble well pointers, must aligned 8-byte boundaries. addition, data type long double uses 16-byte alignment (and size allocation), even though actual representation requiresonly 10 bytes. alignment conditions imposed improve memory sys-tem performance—the memory interface designed processors reador write aligned blocks 8 16 bytes long. Practice Problem 3.53 following structure declarations, determine offset ﬁeld,the total size structure, alignment requirement x86-64. A.struct P1 { int i; char c; long j; char d; }; B.struct P2 { long i; char c; char d; int j; }; C.struct P3 { short w[3]; char c[3] }; D.struct P4 { short w[3]; char *c[3] }; E.struct P3 { struct P1 a[2]; struct P2 *p }; 3.13.6 Concluding Observations x86-64 AMD authors gccdeserve credit moving x86 processors new era. formulation x86-64 hardware programming conventions changed processor one relied heavily stack tohold program state one heavily used part state heldin much faster expanded register set. Finally, x86 caught ideasdeveloped RISC processors early 1980s! Processors capable running either IA32 x86-64 code becoming com- monplace. Many current desktop laptop systems still running 32-bit ver-sions operating systems, machines restricted runningonly 32-bit applications, well. Machines running 64-bit operating systems, andtherefore capable running 32- 64-bit applications, become thewidespread choice high-end machines, database servers scien-tiﬁc computing. biggest drawback transforming applications 32 bitsto 64 bits pointer variables double size, since many data struc-tures contain pointers, means overall memory requirement nearlydouble. transition 32- 64-bit applications occurred oneshaving memory needs exceed 4-gigabyte address space limitation IA32.History shown applications grow use available processing power andmemory size, reliably predict 64-bit processors running 64-bitoperating systems applications become increasingly commonplace.292 Chapter 3 Machine-Level Representation Programs 3.14 Machine-Level Representations Floating-Point Programs Thus far, considered programs represent operate inte- ger data types. order implement programs make use ﬂoating-pointdata, must method storing ﬂoating-point data additional in-structions operate ﬂoating-point values, convert ﬂoating-pointand integer values, perform comparisons ﬂoating-point values.We also require conventions pass ﬂoating-point values function ar-guments return function results. call combination storagemodel, instructions, conventions ﬂoating-point architecture machine. Due long evolutionary heritage, x86 processors provide multiple ﬂoating- point architectures, two current use. ﬁrst, referred “x87,”dates back earliest days Intel microprocessors recently thestandard implementation. second, referred “SSE,” based recentadditions x86 processors support multimedia applications. Web Aside ASM:X87 x87 ﬂoating-point architecture historical x87 ﬂoating-point architecture one least elegant features x87 architecture. original Intel machines, ﬂoating point performed separate coprocessor , unit registers processing capabilities executes subset instructions. coprocessor implemented separate chip, named 8087, 80287, i387, accompany processor chips 8086, 80286, i386, respectively, hence colloquial name “x87.” x86 processors support x87 architecture, continues possible target compiling ﬂoating-point code. x87 instructions operate shallow stack ﬂoating-point registers. stack model, instructions read values memory push onto stack; others pop operands stack, perform operation, push result; others pop values stack storethem memory. approach advantage simple algorithm compiler map evaluation arithmetic expressions stack code. Modern compilers make many optimizations ﬁt well within stack model, example, making use single computed result multiple times. Consequently, x87 architecture implements odd hybrid stack register model, different elements stack read written explicitly, well shifted pushing popping. addition, x87 stack limited depth eight values; additional values pushed, ones bottom simply discarded. Hence, compiler must keep track stack depth. Furthermore, compiler must treat ﬂoating-point registers caller-save, since valuesmight disappear bottom procedures push values onto stack. Web Aside ASM:SSE SSE ﬂoating-point architecture Starting Pentium 4, SSE2 instruction set, added support multimedia applications, becomes viable ﬂoating-point architecture compiled C code. Unlike stack-based architecture x87, SSE-based ﬂoating point uses straightforward register-based approach, much better targetSection 3.15 Summary 293 optimizing compilers. SSE2, ﬂoating-point code similar integer code, except uses different set registers instructions. compiling x86-64, gccgenerates SSE code. hand, default generate x87 code IA32, directed generate SSE code suitable setting command-line parameters. 3.15 Summary chapter, peered beneath layer abstraction provided C language get view machine-level programming. compilergenerate assembly-code representation machine-level program, gain insights compiler optimization capabilities, along ma-chine, data types, instruction set. Chapter 5, see knowingthe characteristics compiler help trying write programs haveefﬁcient mappings onto machine. also gotten complete pictureof program stores data different memory regions. Chapter 12, wewill see many examples application programmers need know whethera program variable run-time stack, dynamically allocated datastructure, part global program data. Understanding programs maponto machines makes easier understand differences kindsof storage. Machine-level programs, representation assembly code, differ many ways C programs. minimal distinction differentdata types. program expressed sequence instructions, whichperforms single operation. Parts program state, registers therun-time stack, directly visible programmer. low-level operationsare provided support data manipulation program control. compilermust use multiple instructions generate operate different data structuresand implement control constructs conditionals, loops, procedures.We covered many different aspects C gets compiled. Wehave seen lack bounds checking C makes many programs prone tobuffer overﬂows. made many systems vulnerable attacks maliciousintruders, although recent safeguards provided run-time system thecompiler help make programs secure. examined mapping C onto IA32 x86-64, much covered handled similar way combinations oflanguage machine. example, compiling C++ similar compilingC. fact, early implementations C++ ﬁrst performed source-to-source con- version C++ C generated object-code runnin g C compiler result. C++ objects represented structures, similar C struct . Methods represented pointers code implementing methods. contrast,Java implemented entirely different fashion. object code Java aspecial binary representation known Java byte code . code viewed machine-level program virtual machine . name suggests, machine implemented directly hardware. Instead, software interpreters process294 Chapter 3 Machine-Level Representation Programs byte code, simulating behavior virtual machine. Alternatively, approach known just-in-time compilation dynamically translates byte code se- quences machine instructions. approach provides faster execution whencode executed multiple times, loops. advantage using byte codeas low-level representation program code “exe-cuted” many different machines, whereas machine code consideredruns x86 machines. Bibliographic Notes Intel AMD provide extensive documentation processors. Thisincludes general descriptions assembly-language programmer’s view thehardware [2, 27], well detailed references individual instructions[3, 28, 29]. Reading instruction descriptions complicated facts that(1) documentation based Intel assembly-code format, (2) aremany variations instruction due different addressing executionmodes, (3) illustrative examples. Still, remain authori-tative references behavior instruction. organization amd64.org responsible deﬁning Application Binary Interface (ABI) x86-64 code running Linux systems [73]. inter- face describes details procedure linkages, binary code ﬁles, number ofother features required machine-code programs execute properly. discussed, ATT format used gccis different Intel format used Intel documentation compilers (including theMicrosoft compilers). Blum’s book [9] one references based ATTformat, provides extensive description embed assembly codeinto C programs using asmdirective. Muchnick’s book compiler design [76] considered comprehen- sive reference code-optimization techniques. covers many techniqueswe discuss here, register usage conventions advantages gener-ating code loops based do-while form. Much written use buffer overﬂow attack systems Internet. Detailed analyses 1988 Internet worm publishedby Spafford [102] well members team MIT helped stop itsspread [40]. Since number papers projects generated ways bothto create prevent buffer overﬂow attacks. Seacord’s book [94] provides awealth information buffer overﬂow attacks code generatedby C compilers. Homework Problems 3.54◆ function prototype int decode2(int x, int y, int z); compiled IA32 assembly code. body code follows:Homework Problems 295 xa %ebp+ 8 ,ya %ebp+12, z %ebp+16 1 movl 12(%ebp), %edx 2 subl 16(%ebp), %edx 3 movl %edx, %eax 4 sall $31, %eax 5 sarl $31, %eax 6 imull 8(%ebp), %edx 7 xorl %edx, %eax Parameters x,y, zare stored memory locations offsets 8, 12, 16 relative address register %ebp . code stores return value register %eax . Write C code decode2 effect equivalent assembly code. 3.55◆ following code computes product xandyand stores result memory. Data type ll_t deﬁned equivalent long long . typedef long long ll_t; void store_prod(ll_t *dest, int x, ll_t y) { *dest = x*y; } gccgenerates following assembly code implementing computation: dest %ebp+ 8 ,xa %ebp+12, %ebp+16 1 movl 16(%ebp), %esi 2 movl 12(%ebp), %eax 3 movl %eax, %edx 4 sarl $31, %edx 5 movl 20(%ebp), %ecx 6 imull %eax, %ecx 7 movl %edx, %ebx 8 imull %esi, %ebx 9 addl %ebx, %ecx 10 mull %esi 11 leal (%ecx,%edx), %edx 12 movl 8(%ebp), %ecx 13 movl %eax, (%ecx) 14 movl %edx, 4(%ecx) code uses three multiplications implement multiprecision arith- metic required implement 64-bit arithmetic 32-bit machine. Describe thealgorithm used compute product, annotate assembly code showhow realizes algorithm. Hint: See Problem 3.12 solution.296 Chapter 3 Machine-Level Representation Programs 3.56◆◆ Consider following assembly code: xa %ebp+ 8 ,na %ebp+12 1 movl 8(%ebp), %esi 2 movl 12(%ebp), %ebx 3 movl $-1, %edi 4 movl $1, %edx 5.L2: 6 movl %edx, %eax 7 andl %esi, %eax 8 xorl %eax, %edi 9 movl %ebx, %ecx 10 sall %cl, %edx 11 testl %edx, %edx 12 jne .L2 13 movl %edi, %eax preceding code generated compiling C code followingoverall form: 1int loop(int x, int n) 2{ 3 int result = ; 4 int mask; 5 (mask = ; mask ; mask = ){ 6 result ^= ; 7 } 8 return result; 9} task ﬁll missing parts C code get program equivalent generated assembly code. Recall result function returnedin register %eax . ﬁnd helpful examine assembly code before, during, loop form consistent mapping registers program variables. A. registers hold program values x,n,result , mask ? B. initial values result andmask ? C. test condition mask ? D. mask get updated? E. result get updated? F. Fill missing parts C code. 3.57◆◆ Section 3.6.6, examined following code candidate use ofconditional data transfer:Homework Problems 297 int cread(int *xp) { return (xp ? *xp : 0); } showed trial implementation using conditional move instruction argued valid, since could attempt read null address. Writ e C function cread_alt behavior cread , except compiled use conditional data transfer. compiled thecommand-line option ‘ -march=i686 ’, generated code use conditional move instruction rather one jump instructions. 3.58◆◆ code follows shows example branching enumerated typevalue switch statement. Recall enumerated types C simply wayto introduce set names associated integer values. default, valuesassigned names go zero upward. code, actions associated different case labels omitted. /* Enumerated type creates set constants numbered 0 upward */ typedef enum {MODE_A, MODE_B, MODE_C, MODE_D, MODE_E} mode_t; int switch3(int *p1, int *p2, mode_t action) { int result = 0; switch(action) { case MODE_A: case MODE_B: case MODE_C: case MODE_D:case MODE_E:default:} return result; } part generated assembly code implementing different actions shown Figure 3.43. annotations indicate argument locations, theregister values, case labels different jump destinations. Register%edx corresponds program variable result initialized −1. Fill missing parts C code. Watch cases fall through.298 Chapter 3 Machine-Level Representation Programs Arguments: p1 %ebp+8, p2 %ebp+12, action %ebp+16 Registers: result %edx (initialized -1) jump targets: 1.L17: MODE_E 2 movl $17, %edx 3 jmp .L19 4.L13: MODE_A 5 movl 8(%ebp), %eax 6 movl (%eax), %edx 7 movl 12(%ebp), %ecx 8 movl (%ecx), %eax 9 movl 8(%ebp), %ecx 10 movl %eax, (%ecx) 11 jmp .L19 12 .L14: MODE_B 13 movl 12(%ebp), %edx 14 movl (%edx), %eax 15 movl %eax, %edx 16 movl 8(%ebp), %ecx 17 addl (%ecx), %edx 18 movl 12(%ebp), %eax 19 movl %edx, (%eax) 20 jmp .L19 21 .L15: MODE_C 22 movl 12(%ebp), %edx 23 movl $15, (%edx) 24 movl 8(%ebp), %ecx 25 movl (%ecx), %edx 26 jmp .L19 27 .L16: MODE_D 28 movl 8(%ebp), %edx 29 movl (%edx), %eax 30 movl 12(%ebp), %ecx 31 movl %eax, (%ecx) 32 movl $17, %edx 33 .L19: default 34 movl %edx, %eax Set return value Figure 3.43 Assembly code Problem 3.58. code implements different branches switch statement. 3.59◆◆ problem give chance reverse engineer switch statement machine code. following procedure, body switch statement removed:Homework Problems 299 1int switch_prob(int x, int n) 2{ 3 int result = x; 4 5 switch(n) { 67 /* Fill code */ 8 } 9 10 return result; 11 } Figure 3.44 shows disassembled machine code procedure. see lines 4 5 parameters xandnare loaded registers %eax %edx , respectively. jump table resides different area memory. see indirect jump line 9 jump table begins address 0x80485d0 . Using gdb debugger, examine six 4-byte words memory comprising jump table command x/6w 0x80485d0 .gdb prints following: (gdb) x/6w 0x80485d0 0x80485d0: 0x08048438 0x08048448 0x08048438 0x0804843d 0x80485e0: 0x08048442 0x08048445 Fill body switch statement C code behavior machine code. 108048420 <switch_prob>: 2 8048420: 55 push %ebp 3 8048421: 89 e5 mov %esp,%ebp 4 8048423: 8b 45 08 mov 0x8(%ebp),%eax 5 8048426: 8b 55 0c mov 0xc(%ebp),%edx 6 8048429: 83 ea 32 sub $0x32,%edx 7 804842c: 83 fa 05 cmp $0x5,%edx 8 804842f: 77 17 ja 8048448 <switch_prob+0x28> 9 8048431: ff 24 95 d0 85 04 08 jmp *0x80485d0(,%edx,4) 10 8048438: c1 e0 02 shl $0x2,%eax 11 804843b: eb 0e jmp 804844b <switch_prob+0x2b> 12 804843d: c1 f8 02 sar $0x2,%eax 13 8048440: eb 09 jmp 804844b <switch_prob+0x2b> 14 8048442: 8d 04 40 lea (%eax,%eax,2),%eax 15 8048445: 0f af c0 imul %eax,%eax 16 8048448: 83 c0 0a add $0xa,%eax 17 804844b: 5d pop %ebp 18 804844c: c3 ret Figure 3.44 Disassembled code Problem 3.59.300 Chapter 3 Machine-Level Representation Programs 3.60◆◆◆ Consider following source code, R,S, andTare constants declared #define : int A[R][S][T]; int store_ele(int i, int j, int k, int *dest) { *dest = A[i][j][k];return sizeof(A); } compiling program, gccgenerates following assembly code: ia %ebp+ 8 ,ja %ebp+12, k %ebp+16, dest %ebp+20 1 movl 12(%ebp), %edx 2 leal (%edx,%edx,4), %eax 3 leal (%edx,%eax,2), %eax 4 imull $99, 8(%ebp), %edx 5 addl %edx, %eax 6 addl 16(%ebp), %eax 7 movl A(,%eax,4), %edx 8 movl 20(%ebp), %eax 9 movl %edx, (%eax) 10 movl $1980, %eax A. Extend Equation 3.1 two dimensions three provide formula location array element A[i][j][k] . B. Use reverse engineering skills determine values R,S, andT based assembly code. 3.61◆◆ code generated C compiler var_prod_ele (Figure 3.29) cannot ﬁt values uses loop registers, must retrieve value ofnfrom memory iteration. Write C code function incorporates optimizations similar performed gcc, compiled code spill loop values memory. Recall processor six registers available hold temporary data, since registers %ebp and%esp cannot used purpose. One registers must used hold result multiply instruction. Hence, youmust reduce number values loop six ( result ,Arow ,Bcol ,j,n, and4*n) ﬁve. need ﬁnd strategy works particular compiler. Keep trying different strategies ﬁnd one works. 3.62◆◆ following code transposes elements M×Marray, Mis constant deﬁned #define :Homework Problems 301 void transpose(Marray_t A) { int i, j; f r( i=0 ;i<M ; i++) f r( j=0 ;j<i ; j++) { int = A[i][j]; A[i][j] = A[j][i]; A[j][i] = t; } } compiled optimization level -O2,gccgenerates following code inner loop function: 1.L3: 2 movl (%ebx), %eax 3 movl (%esi,%ecx,4), %edx 4 movl %eax, (%esi,%ecx,4) 5 addl $1, %ecx 6 movl %edx, (%ebx) 7 addl $52, %ebx 8 cmpl %edi, %ecx 9 jl .L3 A. value M? B. registers hold program values iandj? C. Writ e C code version transpose makes use optimizations occur loop. Use parameter Min code rather numeric constants. 3.63◆◆ Consider following source code, E1andE2are macro expressions de- clared #define compute dimensions array terms parameter n. code computes sum elements column jof array. 1int sum_col(int n, int A[E1(n)][E2(n)], int j) { 2 int i; 3 int result = 0; 4 (i = 0; < E1(n); i++) 5 result += A[i][j]; 6 return result; 7} compiling program, gccgenerates following assembly code: na %ebp+ 8 ,Aa %ebp+12, j %ebp+16 1 movl 8(%ebp), %eax 2 leal (%eax,%eax), %edx302 Chapter 3 Machine-Level Representation Programs 3 leal (%edx,%eax), %ecx 4 movl %edx, %ebx 5 leal 1(%edx), %eax 6 movl $0, %edx 7 testl %eax, %eax 8 jle .L3 9 leal 0(,%ecx,4), %esi 10 movl 16(%ebp), %edx 11 movl 12(%ebp), %ecx 12 leal (%ecx,%edx,4), %eax 13 movl $0, %edx 14 movl $1, %ecx 15 addl $2, %ebx 16 .L4: 17 addl (%eax), %edx 18 addl $1, %ecx 19 addl %esi, %eax 20 cmpl %ebx, %ecx 21 jne .L4 22 .L3: 23 movl %edx, %eax Use reverse engineering skills determine deﬁnitions E1andE2. 3.64◆◆ exercise, examine code generated gccfor functions structures arguments return values, see languagefeatures typically implemented. following C code function word_sum structures argument return values, function prod calls word_sum : typedef struct { int a; int *p; } str1; typedef struct { int sum; int diff; } str2; str2 word_sum(str1 s1) { str2 result; result.sum = s1.a + *s1.p; result.diff = s1.a - *s1.p;Homework Problems 303 return result; } int prod(int x, int y) { str1 s1;str2 s2;s1.a = x;s1.p = &y;s2 = word_sum(s1);return s2.sum * s2.diff; } gccgenerates following code two functions: 1word_sum: 2 pushl %ebp 3 movl %esp, %ebp 4 pushl %ebx 5 movl 8(%ebp), %eax 6 movl 12(%ebp), %ebx 7 movl 16(%ebp), %edx 8 movl (%edx), %edx 9 movl %ebx, %ecx 10 subl %edx, %ecx 11 movl %ecx, 4(%eax) 12 addl %ebx, %edx 13 movl %edx, (%eax) 14 popl %ebx 15 popl %ebp 16 ret $41prod: 2 pushl %ebp 3 movl %esp, %ebp 4 subl $20, %esp 5 leal 12(%ebp), %edx 6 leal -8(%ebp), %ecx 7 movl 8(%ebp), %eax 8 movl %eax, 4(%esp) 9 movl %edx, 8(%esp) 10 movl %ecx, (%esp) 11 call word_sum 12 subl $4, %esp 13 movl -4(%ebp), %eax 14 imull -8(%ebp), %eax 15 leave 16 ret instruction ret $4 like normal return instruction, increments stack pointer 8 (4 return address plus 4 additional), rather 4. A. see lines 5–7 code word_sum appears three values retrieved stack, even though function single argument. Describe three values are. B. see line 4 code prod 20 bytes allocated stack frame. get used ﬁve ﬁelds 4 bytes each. Describe eachof ﬁelds gets used. C. would describe general strategy passing structures argu- ments function? D. would describe general strategy handling structure return value function?304 Chapter 3 Machine-Level Representation Programs 3.65◆◆◆ following code, AandBare constants deﬁned #define : typedef struct { short x[A][B]; /* Unknown constants B */ int y; } str1; typedef struct { char array[B]; int t; short s[B]; int u; } str2; void setVal(str1 *p, str2 *q) { int v1 = q->t; int v2 = q->u; p->y = v1+v2; } gccgenerates following code body setVal : 1 movl 12(%ebp), %eax 2 movl 36(%eax), %edx 3 addl 12(%eax), %edx 4 movl 8(%ebp), %eax 5 movl %edx, 92(%eax) values AandB? (The solution unique.) 3.66◆◆◆ charged maintaining large C program, come across following code: 1typedef struct { 2 int left; 3 a_struct a[CNT]; 4 int right; 5} b_struct; 6 7void test(int i, b_struct *bp) 8{ 9 int n = bp->left + bp->right; 10 a_struct *ap = &bp->a[i]; 11 ap->x[ap->idx] = n; 12 }Homework Problems 305 100000000 <test>: 2 0: 55 push %ebp 3 1: 89 e5 mov %esp,%ebp 4 3: 8b 45 08 mov 0x8(%ebp),%eax 5 6: 8b 4d 0c mov 0xc(%ebp),%ecx 6 9: 8d 04 80 lea (%eax,%eax,4),%eax 7 c: 03 44 81 04 add 0x4(%ecx,%eax,4),%eax 8 10: 8b 91 b8 00 00 00 mov 0xb8(%ecx),%edx 9 16: 03 11 add (%ecx),%edx 10 18: 89 54 81 08 mov %edx,0x8(%ecx,%eax,4) 11 1c: 5d pop %ebp 12 1d: c3 ret Figure 3.45 Disassembled code Problem 3.66. declarations compile-time constant CNTand structure a_struct ﬁle necessary access privilege. Fortunately, copy ‘ .o’ version code, able disassemble objdump program, yielding disassembly shown Figure 3.45. Using reverse engineering skills, deduce following. A. value CNT. B. complete declaration structure a_struct . Assume ﬁelds structure idxandx. 3.67◆◆◆ Consider following union declaration: union ele { struct { int *p;int y; } e1;struct { int x; union ele *next; } e2; }; declaration illustrates structures embedded within unions. following procedure (with expressions omitted) operates linked list unions list elements: void proc (union ele *up) { up-> = *(up-> ) - up-> ; }306 Chapter 3 Machine-Level Representation Programs A. would offsets (in bytes) following ﬁelds: e1.p : e1.y : e2.x : e2.next : B. many total bytes would structure require? C. compiler generates following assembly code body proc : %ebp+8 1 movl 8(%ebp), %edx 2 movl 4(%edx), %ecx 3 movl (%ecx), %eax 4 movl (%eax), %eax 5 subl (%edx), %eax 6 movl %eax, 4(%ecx) basis information, ﬁll missing expressions code forproc .Hint: union references ambiguous interpretations. ambiguities get resolved see references lead. Thereis one answer perform casting violateany type constraints. 3.68◆ Write function good_echo reads line standard input writes standard output. implementation work input line arbitrarylength. may use library function fgets , must make sure function works correctly even input line requires space youhave allocated buffer. code also check error conditionsand return one encountered. Refer deﬁnitions standard I/Ofunctions documentation [48, 58]. 3.69◆ following declaration deﬁnes class structures use constructingbinary trees: 1typedef struct ELE *tree_ptr; 2 3struct ELE { 4 long val; 5 tree_ptr left; 6 tree_ptr right; 7};Homework Problems 307 function following prototype: long trace(tree_ptr tp); gccgenerates following x86-64 code: 1trace: tp %rdi 2 movl $0, %eax 3 testq %rdi, %rdi 4 je .L3 5.L5: 6 movq (%rdi), %rax 7 movq 16(%rdi), %rdi 8 testq %rdi, %rdi 9 jne .L5 10 .L3: 11 rep 12 ret A. Generat e C version function, using loop. B. Explain English function computes. 3.70◆◆ Using tree data structure saw Problem 3.69, function withthe prototype long traverse(tree_ptr tp); gccgenerates following x86-64 code: 1traverse: tp %rdi 2 movq %rbx, -24(%rsp) 3 movq %rbp, -16(%rsp) 4 movq %r12, -8(%rsp) 5 subq $24, %rsp 6 movq %rdi, %rbp 7 movabsq $-9223372036854775808, %rax 8 testq %rdi, %rdi 9 je .L9 10 movq (%rdi), %rbx 11 movq 8(%rdi), %rdi 12 call traverse 13 movq %rax, %r12 14 movq 16(%rbp), %rdi 15 call traverse308 Chapter 3 Machine-Level Representation Programs 16 cmpq %rax, %r12 17 cmovge %r12, %rax 18 cmpq %rbx, %rax 19 cmovl %rbx, %rax 20 .L9: 21 movq (%rsp), %rbx 22 movq 8(%rsp), %rbp 23 movq 16(%rsp), %r12 24 addq $24, %rsp 25 ret A. Generat e C version function. B. Explain English function computes. Solutions Practice Problems Solution Problem 3.1 (page 170) exercise gives practice different operand forms. Operand Value Comment %eax 0x100 Register 0x104 0xAB Absolute address $0x108 0x108 Immediate (%eax) 0xFF Address 0x100 4(%eax) 0xAB Address 0x104 9(%eax,%edx) 0x11 Address 0x10C 260(%ecx,%edx) 0x13 Address 0x108 0xFC(,%ecx,4) 0xFF Address 0x100 (%eax,%edx,4) 0x11 Address 0x10C Solution Problem 3.2 (page 174) seen, assembly code generated gcc includes sufﬁxes instructions, disassembler not. able switch thesetwo forms important skill learn. One important feature memoryreferences IA32 always given double-word registers, %eax , even operand byte single word. code written sufﬁxes: 1 movl %eax, (%esp) 2 movw (%eax), %dx 3 movb $0xFF, %bl 4 movb (%esp,%edx,4), %dh 5 pushl $0xFF 6 movw %dx, (%eax) 7 popl %ediSolutions Practice Problems 309 Solution Problem 3.3 (page 174) Since rely gcc generate assembly code, able write correct assembly code critical skill. Nonetheless, exercise willhelp become familiar different instruction operand types. code explanations errors: 1 movb $0xF, (%bl) Cannot use %bl address register 2 movl %ax, (%esp) Mismatch instruction suffix register ID 3 movw (%eax),4(%esp) Cannot source destination memory references 4 movb %ah,%sh register named %sh 5 movl %eax,$0x123 Cannot immediate destination 6 movl %eax,%dx Destination operand incorrect size 7 movb %si, 8(%ebp) Mismatch instruction suffix register ID Solution Problem 3.4 (page 176) exercise gives experience different data movement instruc-tions relate data types conversion rules C. src_t dest_t Instruction int int movl %eax, (%edx) char int movsbl %al, (%edx)char unsigned movsbl %al, (%edx) unsigned char int movzbl %al, (%edx)int char movb %al, (%edx)unsigned unsigned char movb %al, (%edx)unsigned int movl %eax, (%edx) Solution Problem 3.5 (page 176) Reverse engineering good way understand systems. case, want reverse effect C compiler determine C code gave rise thisassembly code. best way run “simulation,” starting values x,y, zat locations designated pointers xp,yp, zp, respectively. would get following behavior: xp %ebp+8, yp %ebp+12, zp %ebp+16 1 movl 8(%ebp), %edi Get xp 2 movl 12(%ebp), %edx Get yp 3 movl 16(%ebp), %ecx Get zp 4 movl (%edx), %ebx Get 5 movl (%ecx), %esi Get z 6 movl (%edi), %eax Get x 7 movl %eax, (%edx) Store x yp 8 movl %ebx, (%ecx) Store zp 9 movl %esi, (%edi) Store z xp310 Chapter 3 Machine-Level Representation Programs this, generate following C code: void decode1(int *xp, int *yp, int *zp) { int tx = *xp;int ty = *yp;int tz = *zp; *yp = tx; *zp = ty; *xp = tz; } Solution Problem 3.6 (page 178) exercise demonstrates versatility leal instruction gives practice deciphering different operand forms. Although operandforms classiﬁed type “Memory” Figure 3.3, memory access occurs. Instruction Result leal 6(%eax), %edx 6+x leal (%eax,%ecx), %edx x+y leal (%eax,%ecx,4), %edx x+4y leal 7(%eax,%eax,8), %edx 7+9x leal 0xA(,%ecx,4), %edx 10+4y leal 9(%eax,%ecx,2), %edx 9+x+2y Solution Problem 3.7 (page 179) problem gives chance test understanding operands arithmetic instructions. instruction sequence designed result ofeach instruction affect behavior subsequent ones. Instruction Destination Value addl %ecx,(%eax) 0x100 0x100 subl %edx,4(%eax) 0x104 0xA8 imull $16,(%eax,%edx,4) 0x10C 0x110 incl 8(%eax) 0x108 0x14decl %ecx %ecx 0x0subl %edx,%eax %eax 0xFD Solution Problem 3.8 (page 180) exercise gives chance generate little bit assembly code. solution code generated gcc. loading parameter nin register %ecx ,i use byte register %clto specify shift amount sarl instruction:Solutions Practice Problems 311 1 movl 8(%ebp), %eax Get x 2 sall $2, %eax x <<= 2 3 movl 12(%ebp), %ecx Get n 4 sarl %cl, %eax x >>= n Solution Problem 3.9 (page 181) problem fairly straightforward, since expressions imple- mented single instruction reordering expressions. 5 int t1 = x^y; 6 n tt 2=t 1> >3 ; 7 int t3 = ~t2; 8 int t4 = t3-z; Solution Problem 3.10 (page 182) A. instruction used set register %edx zero, exploiting property thatx^x=0 x. corresponds C statement x=0 . B. direct way setting register %edx zero instruction movl $0,%edx . C. Assembling disassembling code, however, ﬁnd version withxorl requires 2 bytes, version movl requires 5. Solution Problem 3.11 (page 184) simply replace cltd instruction one sets register %edx 0, use divl rather idivl division instruction, yielding following code: xa %ebp+ 8 ,ya %ebp+12 movl 8(%ebp),%eax Load x %eax movl $0,%edx Set high-order bits 0 divl 12(%ebp) Unsigned divide movl %eax, 4(%esp) Storex/y movl %edx, (%esp) Storex%y Solution Problem 3.12 (page 184) A. see program performing multiprecision operations 64-bit data. also see 64-bit multiply operation (line 4) usesunsigned arithmetic, conclude num_t isunsigned long long . B. Let xdenote value variable x, let ydenote value y, write y=y h.232+yl, yhandylare values represented high- low-order 32 bits, respectively. therefore compute x.y=x.yh.232+x.yl. full representation product would 96 bits long, require low-order 64 bits. therefore let low-order 32 bits x.yhandtbe full 64-bit product x.yl, which312 Chapter 3 Machine-Level Representation Programs split high- low-order parts thandtl. ﬁnal result tlas low-order part, s+thas high-order part. annotated assembly code: dest %ebp+ 8 ,xa %ebp+12, %ebp+16 1 movl 12(%ebp), %eax Get x 2 movl 20(%ebp), %ecx Get y_h 3 imull %eax, %ecx Comput e = x*y_h 4 mull 16(%ebp) Comput e = x*y_l 5 leal (%ecx,%edx), %edx Add t_h 6 movl 8(%ebp), %ecx Get dest 7 movl %eax, (%ecx) Store t_l 8 movl %edx, 4(%ecx) Store s+t_h Solution Problem 3.13 (page 188) important understand assembly code keep track type program value. Instead, different instructions determine operandsizes whether signed unsigned. mapping instructionsequences back C code, must bit detective work infer datatypes program values. A. sufﬁx ‘ l’ register identiﬁers indicate 32-bit operands, comparison two’s complement ‘ <’. infer data_t must int. B. sufﬁx ‘ w’ register identiﬁers indicate 16-bit operands, comparison two’s-complement ‘ >=’. infer data_t must beshort . C. sufﬁx ‘ b’ register identiﬁers indicate 8-bit operands, comparison unsigned ‘ <’. infer data_t must un- signed char . D. sufﬁx ‘ l’ register identiﬁers indicate 32-bit operands, comparison ‘ !=’, whether arguments signed, unsigned, pointers. infer data_t could either int, unsigned , form pointer. ﬁrst two cases, could also long size designator. Solution Problem 3.14 (page 189) problem similar Problem 3.13, except involves test instructions rather cmpinstructions. A. sufﬁx ‘ l’ register identiﬁers indicate 32-bit operands, comparison ‘ !=’, signed unsigned. infer thatdata_t must either int,unsigned , type pointer. ﬁrst two cases, could also long size designator. B. sufﬁx ‘ w’ register identiﬁer indicate 16-bit operands, comparison ‘ ==’, signed unsigned. infer thatdata_t must either short orunsigned short .Solutions Practice Problems 313 C. sufﬁx ‘ b’ register identiﬁer indicate 8-bit operand, comparison two’s complement ‘ >’. infer data_t must char . D. sufﬁx ‘ w’ register identiﬁer indicate 16-bit operands, comparison unsigned ‘ >’. infer data_t must unsigned short . Solution Problem 3.15 (page 192) exercise requires examine disassembled code detail reason encodings jump targets. also gives practice hexadecimalarithmetic. A. jeinstruction target 0x8048291 +0x05 . original disas- sembled code shows, 0x8048296 : 804828f: 74 05 je 8048296 8048291: e8 1e 00 00 00 call 80482b4 B. jbinstruction target 0x8048359 −25 (since 0xe7 1-byte, two’s-complement representation −25). original disassembled code shows, 0x8048340 : 8048357: 72 e7 jb 8048340 8048359: c6 05 10 a0 04 08 01 movb $0x1,0x804a010 C. According annotation produced disassembler, jump target absolute address 0x8048391 . According byte encoding, must address 0x12 bytes beyond movinstruction. Subtracting gives address 0x804837f , conﬁrmed disassembled code: 804837d: 74 12 je 8048391 804837f: b8 00 00 00 00 mov $0x0,%eax D. Reading bytes reverse order, see target offset 0xffffffe0 , decimal −32. Adding 0x80482c4 (the address nopinstruction) gives address 0x80482a4 : 80482bf: e9 e0 ff ff ff jmp 80482a4 80482c4: 90 nop E. indirect jump denoted instruction code ff 25 . address jump target read encoded explicitly following4 bytes. Since machine little endian, given reverse orderasfc 9f 04 08 . Solution Problem 3.16 (page 195) Annotating assembly code writing C code mimics control ﬂow good ﬁrst steps understanding assembly-language programs. problem gives practice example simple control ﬂow. also gives chance examine implementation logical operations.314 Chapter 3 Machine-Level Representation Programs A. C code: 1void goto_cond(int a, int *p) { 2 (p == 0) 3 goto done; 4 (a <= 0) 5 goto done; 6 *p += a; 7 done: 8 return; 9} B. ﬁrst conditional branch part implementation &&ex- pression. test pbeing non-null fails, code skip test a>0 . Solution Problem 3.17 (page 196) exercise help think idea general translation rule apply it. A. Converting alternate form involves switching around lines code: 1int gotodiff_alt(int x, int y) { 2 int result; 3 (x < y) 4 goto true; 5 resul t=x-y ; 6 goto done; 7 true: 8 result = - x; 9 done: 10 return result; 11 } B. respects, choice arbitrary. original rule works better common case else statement. case, simply modify translation rule follows: t= test-expr ; (!t) goto done; then-statement done: translation based alternate rule cumbersome. Solution Problem 3.18 (page 196) problem requires work nested branch structure, see rule translating ifstatements applied. theSolutions Practice Problems 315 part, machine code straightforward translation C code. difference initialization expression (line 2 C code) beenmoved (line 15 assembly code) gets computed itis certain returned value. 1int test(int x, int y) { 2 int val = x^y; 3 (x < -3) { 4 (y < x) 5 val = x*y; 6 else 7 val = x+y; 8 } else (x > 2) 9 val = x-y; 10 return val; 11 } Solution Problem 3.19 (page 198) A. build table factorials computed data type int, get following: nn ! OK? 11 22 36 42 4 Y5 120 6 720 7 5,040 Y8 40,320 9 362,880 10 3,628,800 Y11 39,916,800 12 479,001,600 13 1,932,053,504 Y14 1,278,945,280 N see 14! overﬂowed, since numbers stopped growing. learned Problem 2.35, also test whether computation ofn!has overﬂowed computing n!/nand seeing whether equals (n−1)!. B. computation data type long long lets us go 20!, yielding 2,432,902,008,176,640,000.316 Chapter 3 Machine-Level Representation Programs Solution Problem 3.20 (page 199) code generated compiling loops tricky analyze, compiler perform many different optimizations loop code, itcan difﬁcult match program variables registers. start practicing skill fairly simple loop. A. register usage determined simply looking argu- ments get fetched. Register usage Register Variable Initially %eax x x %ecx %edx n n B. body-statement portion consists lines 3 5 C code lines 5 7 assembly code. test-expr portion line 6 C code. assembly code, implemented instructions lines 8 11. C. annotated code follows: xa %ebp+ 8 ,ya %ebp+12, n %ebp+16 1 movl 8(%ebp), %eax Get x 2 movl 12(%ebp), %ecx Get 3 movl 16(%ebp), %edx Get n 4.L2: loop: 5 addl %edx, %eax x+ =n 6 imull %edx, %ecx y* =n 7 subl $1, %edx n-- 8 testl %edx, %edx Test n 9 jle .L5 <= 0, goto done 10 cmpl %edx, %ecx Compare y:n 11 jl .L2 <, goto loop 12 .L5: done: code Problem 3.16, two conditional branches required implement &&operation. Solution Problem 3.21 (page 201) problem demonstrates transformations made compiler make difﬁcult decipher generated assembly code. A. see register initialized a+band incremented iteration. Similarly, value a(held register %ecx ) incremented iteration. therefore see value register %edx always equal a+b. Let us call apb(for “aplusb”).Solutions Practice Problems 317 B. table register usage: Register Program value Initial value %ecx %ebx b b %eax result 1 %edx apb a+b C. annotated code follows: Arguments: %ebp+ 8 ,ba %ebp+12 Registers: %ecx, b %ebx, result %eax, %edx set apb (a+b) 1 movl 8(%ebp), %ecx Get 2 movl 12(%ebp), %ebx Get b 3 movl $1, %eax Set result = 1 4 cmpl %ebx, %ecx Compare a:b 5 jge .L11 >=, goto done 6 leal (%ebx,%ecx), %edx Compute apb = a+b 7 movl $1, %eax Set result = 1 8.L12: loop: 9 imull %edx, %eax Compute result *= apb 10 addl $1, %ecx Compute a++ 11 addl $1, %edx Compute apb++ 12 cmpl %ecx, %ebx Compare b:a 13 jg .L12 >, goto loop 14 .L11: done: Return result D. equivalent goto code follows: 1int loop_while_goto(int a, int b) 2{ 3 int result = 1; 4 (a >= b) 5 goto done; 6 /* apb value a+b original code */ 7 int apb = a+b; 8 loop: 9 result *= apb; 10 a++; 11 apb++; 12 (b > a) 13 goto loop; 14 done: 15 return result; 16 }318 Chapter 3 Machine-Level Representation Programs Solution Problem 3.22 (page 202) able work backward assembly code C code prime example reverse engineering. A. original C code: int fun_a(unsigned x) { int val = 0;while (x) { val ^= x; x >>= 1; } return val & 0x1; } B. code computes parity argument x. is, returns 1 odd number ones xand 0 even number. Solution Problem 3.23 (page 205) problem trickier Problem 3.22, since code within loop complex overall operation less familiar. A. original C code: int fun_b(unsigned x) { int val = 0;int i;for (i = 0; < 32; i++) { val = (val << 1) | (x & 0x1);x >>= 1; } return val; } B. code reverses bits x, creating mirror image. shifting bits xfrom left right, ﬁlling bits shifts valfrom right left. Solution Problem 3.24 (page 206) stated rule translating loop loop bit simplistic—this aspect requires special consideration. A. Applying translation rule would yield following code: /* Naive translation loop loop */ /* WARNING: buggy code */ int sum = 0;i n ti=0 ;Solutions Practice Problems 319 (i < 10) { (i & 1) /* cause infinite loop */continue; sum += i; i++; } code inﬁnite loop, since continue statement would prevent index variable ifrom updated. B. general solution replace continue statement goto statement skips rest loop body goes directly updateportion: /* Correct translation loop loop */ int sum = 0; n ti=0 ; (i < 10) { (i & 1) goto update; sum += i; update: i++; } Solution Problem 3.25 (page 209) problem reinforces method computing misprediction penalty. A. apply formula directly get TMP=2(31−16)=30. B. misprediction occurs, function require around 16 +30=46 cycles. Solution Problem 3.26 (page 212) problem provides chance study use conditional moves. A. operator ‘ /’. see example dividing power 2 right shifting (see Section 2.3.7). shifting k=2, must add bias 2k−1=3 dividend negative. B. annotated version assembly code: Computation function arith Register: x %edx 1 leal 3(%edx), %eax temp = x+3 2 testl %edx, %edx Test x 3 cmovns %edx, %eax >= 0, temp = x 4 sarl $2, %eax Return temp >> 2 (= x/4)320 Chapter 3 Machine-Level Representation Programs program creates temporary value equal x+3, anticipation xbeing negative therefore requiring biasing. cmovns instruction conditionally changes number xwhen x≥0, shifted 2 generate x/4. Solution Problem 3.27 (page 212) problem similar Problem 3.18, except conditionals implemented conditional data transfers. Although might seem dauntingto ﬁt code framework original C code, ﬁnd followsthe translation rules fairly closely. 1int test(int x, int y) { 2 int val = 4*x; 3 f( y>0 ){ 4 (x < y) 5 val = x-y; 6 else 7 val = x^y; 8 } else (y < -2) 9 val = x+y; 10 return val; 11 } Solution Problem 3.28 (page 217) problem gives chance reason control ﬂow switch statement. Answering questions requires combine information fromseveral places assembly code. 1.Line 2 assembly code adds 2 xto set lower range cases zero. means minimum case label −2. 2.Lines 3 4 cause program jump default case adjusted case value greater 6. implies maximum case label is−2+6=4. 3.In jump table, see entry line 3 (case value −1) destination ( .L2) jump instruction line 4, indicating default case behavior. Thus, case label −1 missing switch statement body. 4.In jump table, see entries lines 6 7 destination. correspond case labels 2 3. reasoning, draw following two conclusions: A. case labels switch statement body values −2, 0, 1, 2, 3, 4. B. case destination .L6had labels 2 3. Solution Problem 3.29 (page 218) key reverse engineering compiled switch statements combine information assembly code jump table sort different cases. see jainstruction (line 3) code default caseSolutions Practice Problems 321 label .L2. see repeated label jump table .L4, must code cases C D. see code falls line 14, label .L6must match case label .L3must match case B. leaves label .L2to match case E. original C code follows. Observe compiler optimized case aequals 4 setting return value 4, rather a. 1int switcher(int a, int b, int c) 2{ 3 int answer; 4 switch(a) { 6 case 5: 7 c=b^1 5 ; 8 /* Fall */ 9 case 0: 10 answe r=c+ 112; 11 break; 12 case 2: 13 case 7: 14 answer = (c + b) << 2; 15 break; 16 case 4: 17 answer = a; /* equivalently, answe r=4* / 18 break; 19 default: 20 answer = b; 21 } 22 return answer; 23 } Solution Problem 3.30 (page 223) another example assembly-code idiom. ﬁrst seems quite peculiar—a call instruction matching ret. realize really procedure call all. A.%eax set address popl instruction. B. true procedure call, since control follows ordering instructions return address popped stack. C. way IA32 get value program counter integer register. Solution Problem 3.31 (page 224) problem makes concrete discussion register usage conventions. Reg-isters %edi ,%esi , %ebx callee-save. procedure must save stack altering values restore returning. otherthree registers caller-save. altered without affecting behavior caller.322 Chapter 3 Machine-Level Representation Programs Solution Problem 3.32 (page 228) One step learning read IA32 code become familiar way arguments passed stack. key solving problem note thatthe storage datpis implemented instruction line 3 assembly code, work backward determine types positions arguments dandp. Similarly, subtraction performed line 6, work backward determine types positions arguments xandc. following function prototype: int fun(short c, char d, int *p, int x); example shows, reverse engineering like solving puzzle. It’s importantto identify points unique choice, work around thesepoints ﬁll rest details. Solution Problem 3.33 (page 228) able reason functions use stack critical part under-standing compiler-generated code. example illustrates, compiler mayallocate signiﬁcant amount space never gets used. A. started %esp value 0x800040 .T h e pushl instruction line 2 decrements stack pointer 4, giving 0x80003C , becomes new value %ebp . B. Line 4 decrements stack pointer 40 (hex 0x28 ), yielding 0x800014 . C. see two leal instructions (lines 5 7) compute arguments pass scanf , two movl instructions (lines 6 8) store stack. Since function arguments appear stack atincreasingly positive offsets %esp , conclude line 5 computes &x, line 7 computes line &y. values 0x800038 and0x800034 , respectively. D. stack frame following structure contents: 0x800060 0x53 0x46 0x800038 0x800034 0x3000700x80003C 0x800038 0x8000340x800030 0x80002C 0x8000280x8000240x800020 0x80001C 0x8000180x800014x y%ebp %esp E. Byte addresses 0x800020 0x800033 unused.Solutions Practice Problems 323 Solution Problem 3.34 (page 231) problem provides chance examine code recursive function. important lesson learn recursive code exact structure theother functions seen. stack register-saving disciplines sufﬁce make recursive functions operate correctly. A. Register %ebx holds value parameter x, used compute result expression. B. assembly code generated following C code: int rfun(unsigned x) { (x == 0) return 0; unsigned nx = x>>1;int rv = rfun(nx); return (x & 0x1) + rv; } C. Like code Problem 3.49, function computes sum bits argument x. recursively computes sum least signiﬁcant bit, adds least signiﬁcant bit get result. Solution Problem 3.35 (page 233) exercise tests understanding data sizes array indexing. Observethat pointer kind 4 bytes long. IA32, gccallocates 12 bytes data typelong double , even though actual format requires 10 bytes. Array Element size Total size Start address Element 21 4 xS xS+2i 41 2 xT xT+4i U 42 4 xU xU+4i V 12 96 xV xV+12i W 41 6 xW xW+4i Solution Problem 3.36 (page 234) problem variant one shown integer array E. important understand difference pointer object pointed to. Sincedata type short requires 2 bytes, array indices scaled factor 2. Rather using movl , before, use movw . Expression Type Value Assembly S+1 short * xS+2 leal 2(%edx),%eax S[3] short M[xS+6] movw 6(%edx),%ax &S[i] short * xS+2i leal (%edx,%ecx,2),%eax S[4*i+1] short M[xS+8i+2] movw 2(%edx,%ecx,8),%ax S+i-5 short * xS+2i−10 leal -10(%edx,%ecx,2),%eax324 Chapter 3 Machine-Level Representation Programs Solution Problem 3.37 (page 236) problem requires work scaling operations determine address computations, apply Equation 3.1 row-major indexing. Theﬁrst step annotate assembly code determine address references computed: 1 movl 8(%ebp), %ecx Get 2 movl 12(%ebp), %edx Get j 3 leal 0(,%ecx,8), %eax 8*i 4 subl %ecx, %eax 8*i-i = 7*i 5 addl %edx, %eax 7*i+j 6 leal (%edx,%edx,4), %edx 5*j 7 addl %ecx, %edx 5*j+i 8 movl mat1(,%eax,4), %eax mat1[7*i+j] 9 addl mat2(,%edx,4), %eax mat2[5*j+i] see reference matrix mat1 byte offset 4 (7i+j), reference matrix mat2 byte offset 4 (5j+i). this, determine thatmat1 7 columns, mat2 5, giving M=5 N=7. Solution Problem 3.38 (page 238) exercise requires able study compiler-generated assembly code understand optimizations performed. case, compilerwas clever optimizations. Let us ﬁrst study following C code, see derived assembly code generated original function. 1/* Set diagonal elements val */ 2void fix_set_diag_opt(fix_matrix A, int val) { 3 int *Abase = &A[0][0]; 4 int index = 0; 5 { 6 Abase[index] = val; 7 index += (N+1); 8 } (index != (N+1)*N); 9} function introduces variable Abase , type int * , pointing start array A. pointer designates sequence 4-byte integers consisting elements row-major order. introduce integer variable index steps diagonal elements A, property diagonal elements iandi+1are spaced N+1elements apart sequence, reach diagonal element N(index value N(N+1)), gone beyond end. actual assembly code follows general form, pointer increments must scaled factor 4. label register %eax holding aSolutions Practice Problems 325 value index4 equal index C version, scaled factor 4. N=16, see stopping point index4 4 .16(16+1)=1088. Aa %ebp+8, val %ebp+12 1 movl 8(%ebp), %ecx Get Abase = &A[0][0] 2 movl 12(%ebp), %edx Get val 3 movl $0, %eax Set index4 0 4.L14: loop: 5 movl %edx, (%ecx,%eax) Set Abase[index4/4] val 6 addl $68, %eax index4 += 4(N+1) 7 cmpl $1088, %eax Compare index4:4N(N+1) 8 jne .L14 !=, goto loop Solution Problem 3.39 (page 243) problem gets think structure layout code used access structure ﬁelds. structure declaration variant example shown inthe text. shows nested structures allocated embedding innerstructures within outer ones. A. layout structure follows: Offset Contents p0481 2 1 6 s.x s.y next B. uses 16 bytes. C. always, start annotating assembly code: sp %ebp+8 1 movl 8(%ebp), %eax Get sp 2 movl 8(%eax), %edx Get sp->s.y 3 movl %edx, 4(%eax) Store sp->s.x 4 leal 4(%eax), %edx Compute &(sp->s.x) 5 movl %edx, (%eax) Store sp->p 6 movl %eax, 12(%eax) Store sp sp->next this, generate C code follows: void sp_init(struct prob *sp) { sp->s.x = sp->s.y; sp->p = &(sp->s.x); sp->next = sp; } Solution Problem 3.40 (page 247) Structures unions involve simple set concepts, takes practice comfortable different referencing patterns implementations.326 Chapter 3 Machine-Level Representation Programs EXPR TYPE Code up->t1.s int movl 4(%eax), %eax movl %eax, (%edx) up->t1.v short movw (%eax), %ax movw %ax, (%edx) &up->t1.d short * leal 2(%eax), %eax movl %eax, (%edx) up->t2.a int * movl %eax, (%edx)up->t2.a[up->t1.s] int movl 4(%eax), %ecx movl (%eax,%ecx,4), %eaxmovl %eax, (%edx) *up->t2.p char movl 8(%eax), %eax movb (%eax), %al movb %al, (%edx) Solution Problem 3.41 (page 251) Understanding structure layout alignment important understand- ing much storage different data structures require understanding thecode generated compiler accessing structures. problem lets youwork details example structures. A.struct P1 { int i; char c; int j; char d; }; icj Total Alignment 0 4 8 12 16 4 B.struct P2 { int i; char c; char d; int j; }; icjd Total Alignment 0458 1 2 4 C.struct P3 { short w[3]; char c[3] }; wc Total Alignment 0 6 10 2 D.struct P4 { short w[3]; char *c[3] }; wc Total Alignment 0 8 20 4 E.struct P3 { struct P1 a[2]; struct P2 *p }; ap Total Alignment 03 2 3 6 4Solutions Practice Problems 327 Solution Problem 3.42 (page 251) exercise understanding structure layout alignment. A. object sizes byte offsets: Field b c defgh Size 4 2 8 14184 Offset 0 4 8 16 20 24 32 40 B. structure total 48 bytes long. end structure must padded 4 bytes satisfy 8-byte alignment requirement. C. One strategy works, data elements length equal power two, order structure elements descending order size.This leads declaration, struct { double c; long long g; float e; char *a; void *h;short b; char d; char f; } foo; following offsets, total 32 bytes: Field c g eahbdf Size 8 8 4 44211 Offset 0 8 16 20 24 28 30 31 Solution Problem 3.43 (page 259) problem covers wide range topics, stack frames, string represen- tations, ASCII code, byte ordering. demonstrates dangers out-of-bounds memory references basic ideas behind buffer overﬂow. A. Stack line 7: 08 04 86 43 bf ff fc 94 00 00 00 03 00 00 00 0200 00 00 01%ebp Return address Saved%ebp Saved%edi Saved%esi Saved%ebx buf[4-7] buf[0-3]328 Chapter 3 Machine-Level Representation Programs B. Stack line 10: 08 04 86 00 33 32 31 3039 38 37 36 35 34 33 32 31 30 39 3837 36 35 34 33 32 31 30%ebp Return address Saved%ebp Saved%edi Saved%esi Saved%ebx buf[4-7] buf[0-3] C. program attempting return address 0x08048600 . low-order byte overwritten terminating null character. D. saved values following registers altered: Register Value %ebp 33323130 %edi 39383736%esi 35343332%ebx 31303938 values loaded registers getline returns. E. call malloc strlen(buf)+1 argument, code also check returned value equal NULL . Solution Problem 3.44 (page 262) A. corresponds range around 213addresses. B. 128-byte nop sled would cover 27addresses test, would require 26=64 attempts. example clearly shows degree randomization version Linux would provide minimal deterrence overﬂow attack. Solution Problem 3.45 (page 264) problem gives another chance see IA32 code manages stack,and also better understand defend buffer overﬂow attacks. A. unprotected code, see lines 4 6 compute positions ofvandbufto offsets −8 −20 relative %ebp . protected code, canary stored offset −8 (line 3), vandbufare offsets −24 −20 (lines 7 9). B. protected code, local variable vis positioned closer top stack buf, overrun buf corrupt value v.Solutions Practice Problems 329 fact, bufis positioned buffer overrun corrupt canary value. Solution Problem 3.46 (page 271) Achieving factor 51 price improvement every 10 years 3 decades beentruly remarkable, helps explain computers become pervasivein society. A. Assuming baseline 16.3 gigabytes 2010, 256 terabytes represents increase factor 1 .608×10 4, would take around 25 years, giving us 2035. B. Sixteen exabytes increase 1 .054×109over 16.3 gigabytes. would take around 53 years, giving us 2063. C. Increasing budget factor 10 cuts 6 years schedule, making possible meet two memory-size goals years 2029 2057,respectively. numbers, course, taken literally. would require scaling memory technology well beyond believed fundamentalphysical limits current technology. Nonetheless, indicates that, within lifetimes many readers book, systems exabyte-scalememory systems. Solution Problem 3.47 (page 276) problem illustrates subtleties type conversion differentmove instructions. cases, make use property movl instruction set upper 32 bits destination register zeros. Someof problems multiple solutions. src_t dest_t Instruction SD Explanation long long movq %rdi %rax conversion int long movslq %edi %rax Sign extend char long movsbq %dil %rax Sign extend unsigned int unsigned long movl %edi %eax Zero extend 64 bits unsigned char unsigned long movzbq %dil %rax Zero extend 64 unsigned char unsigned long movzbl %dil %eax Zero extend 64 bits long int movslq %edi %rax Sign extend 64 bits long int movl %edi %eax Zero extend 64 bits unsigned long unsigned movl %edi %eax Zero extend 64 bits show long tointconversion use either movslq ormovl , even though one sign extend upper 32 bits, zero extendit. values upper 32 bits ignored subsequent instruction %eax operand.330 Chapter 3 Machine-Level Representation Programs Solution Problem 3.48 (page 278) step code arithprob determine following: 1.The ﬁrst movslq instruction sign extends dto long integer prior multi- plication c. implies dhas type intandchas type long . 2.Themovsbl instruction (line 4) sign extends bto integer prior multi- plication a. means bhas type char andahas type int. 3.The sum computed using leaq instruction, indicating return value type long . this, determine unique prototype arithprob long arithprob(int a, char b, long c, int d); Solution Problem 3.49 (page 281) problem demonstrates clever way count number 1 bits word. uses several tricks look fairly obscure assembly-code level. A. original C code: long fun_c(unsigned long x) { long val = 0; int i; f r( i=0 ;i<8 ; i++) { val += x & 0x0101010101010101L; x >>= 1; } val += (val >> 32); val += (val >> 16);val += (val >> 8); return val & 0xFF; } B. code sums bits xby computing 8 single-byte sums parallel, using 8 bytes val. sums two halves val, two low-order 16 bits, 2 low-order bytes sum get ﬁnal amount inthe low-order byte. masks high-order bits get ﬁnal result. Thisapproach advantage requires 8 iterations, rather themore typical 64. Solution Problem 3.50 (page 284) step code incrprob determine following: 1.Theaddl instruction fetches 32-bit integer location given third argument register adds 32-bit version ﬁrst argumentregister. this, infer tis third argument xis ﬁrst argument. see tmust pointer signed unsigned integer, butxcould either signed unsigned, could either 32 bits 64 (since adding *t, code truncate 32 bits).Solutions Practice Problems 331 2.Themovslq instruction sign extends sum (a copy *t) long integer. this, infer tmust pointer signed integer. 3.Theaddq instruction adds sign-extended value previous sum location indicated second argument register. this, inferthatqis second argument pointer long integer. four valid prototypes incrprob , depending whether xis long, whether signed unsigned. show four different prototypes: void incrprob_s(int x, long *q, int *t); void incrprob_u(unsigned x, long *q, int *t);void incrprob_sl(long x, long *q, int *t);void incrprob_ul(unsigned long x, long *q, int *t); Solution Problem 3.51 (page 289) function example leaf function requires local storage. use space beyond stack pointer local storage, never altering stackpointer. A. Stack locations used: 0 –8 –16–24–32–40Stack pointer %rsp Unused Unused a[3] a[2] a[1] a[0] B. x86-64 implementation local_array Argument %edi 1local_array: 2 movq $2, -40(%rsp) Store 2 a[0] 3 movq $3, -32(%rsp) Store 3 a[1] 4 movq $5, -24(%rsp) Store 5 a[2] 5 movq $7, -16(%rsp) Store 7 a[3] 6 andl $3, %edi Compute id x=i&3 7 movq -40(%rsp,%rdi,8), %rax Compute a[idx] return value 8 ret Return C. function never changes stack pointer. stores local values region beyond stack pointer. Solution Problem 3.52 (page 290) A. Register %rbx used hold parameter x.332 Chapter 3 Machine-Level Representation Programs B. Since %rbx callee-saved, must stored stack. Since use stack function, code uses push pop instructions tosave restore register. C. x86-64 implementation recursive factorial function rfact Argument: x %rdi 1rfact: 2 pushq %rbx Save %rbx (callee save) 3 movq %rdi, %rbx Copy x %rbx 4 movl $1, %eax result = 1 5 testq %rdi, %rdi Test x 6 jle .L11 <=0, goto done 7 leaq -1(%rdi), %rdi Compute xm1 = x-1 8 call rfact Call rfact(xm1) 9 imulq %rbx, %rax Compute result = x*rfact(xm1) 10 .L11: done: 11 popq %rbx Restore %rbx 12 ret Return D. Instead explicitly decrementing incrementing stack pointer, code use pushq andpopq modify stack pointer save restore register state. Solution Problem 3.53 (page 291) problem similar Problem 3.41, updated x86-64. A.struct P1 { int i; char c; long j; char d; }; icj Total Alignment 0 4 8 16 24 8 B.struct P2 { long i; char c; char d; int j; }; icd j Total Alignment 0 8 9 12 16 8 C.struct P3 { short w[3]; char c[3] }; wc Total Alignment 0 6 10 2 D.struct P4 { short w[3]; char *c[3] }; wc Total Alignment 0 8 32 8 E.struct P3 { struct P1 a[2]; struct P2 *p }; ap Total Alignment 04 8 5 6 8CHAPTER4 Processor Architecture 4.1 Y86 Instruction Set Architecture 336 4.2 Logic Design Hardware Control Language HCL 352 4.3 Sequential Y86 Implementations 364 4.4 General Principles Pipelining 391 4.5 Pipelined Y86 Implementations 400 4.6 Summary 449 Bibliographic Notes 451Homework Problems 451 Solutions Practice Problems 457 333334 Chapter 4 Processor Architecture Modern microprocessors among complex systems ever created humans. single silicon chip, roughly size ﬁngernail, contain acomplete high-performance processor, large cache memories, logic re-quired interface external devices. terms performance, processorsimplemented single chip today dwarf room-sized supercomputers thatcost $10 million 20 years ago. Even embedded processors found ineveryday appliances cell phones, personal digital assistants, handheldgame systems far powerful early developers computers everenvisioned. Thus far, viewed computer systems level machine- language programs. seen processor must execute sequence ofinstructions, instruction performs primitive operation, asadding two numbers. instruction encoded binary form sequence of1 bytes. instructions supported particular processor byte-level encodings known instruction-set architecture (ISA). Different “families” processors, Intel IA32, IBM/Freescale PowerPC, theARM processor family different ISAs. program compiled one typeof machine run another. hand, many differentmodels processors within single family. manufacturer produces proces-sors ever-growing performance complexity, different models remaincompatible ISA level. Popular families, IA32, processors sup-plied multiple manufacturers. Thus, ISA provides conceptual layer ofabstraction compiler writers, need know instructions arepermitted encoded, processor designers, must buildmachines execute instructions. chapter, take brief look design processor hardware. study way hardware system execute instructions particular ISA.This view give better understanding computers work thetechnological challenges faced computer manufacturers. One important con-cept actual way modern processor operates quite differentfrom model computation implied ISA. ISA model would seemto imply sequential instruction execution, instruction fetched executed completion next one begins. executing different parts multiple instructions simultaneously, processor achieve higher perfor-mance executed one instruction time. Special mechanisms areused make sure processor computes results would se-quential execution. idea using clever tricks improve performance whilemaintaining functionality simpler abstract model well knownin computer science. Examples include use caching Web browsers andinformation retrieval data structures balanced binary trees hash tables. Chances never design processor. task experts working fewer 100 companies worldwide. Why, then, youlearn processor design? .It intellectually interesting important. intrinsic value learn- ing things work. especially interesting learn inner workings ofChapter 4 Processor Architecture 335 system part daily lives computer scientists engi- neers yet remains mystery many. Processor design embodies many ofthe principles good engineering practice. requires creating simple andregular structure perform complex task. .Understanding processor works aids understanding overallcomputer system works. Chapter 6, look memory system techniques used create image large memory veryfast access time. Seeing processor side processor-memory interfacewill make presentation complete. .Although people design processors, many design hardware systems thatcontain processors. become commonplace processors embed- ded real-world systems automobiles appliances. Embedded-system designers must understand processors work, sys-tems generally designed programmed lower level abstractionthan case desktop systems. .You might work processor design. Although number companies producing microprocessors small, design teams working pro-cessors already large growing. 1000 people involved different aspects major processor design. chapter, start deﬁning simple instruction set use running example processor implementations. call “Y86”instruction set, inspired IA32 instruction set, iscolloquially referred “x86.” Compared IA32, Y86 instruction set hasfewer data types, instructions, addressing modes. also simpler byte-level encoding. Still, sufﬁciently complete allow us write simple programsmanipulating integer data. Designing processor implement Y86 requires usto face many challenges faced processor designers. provide background digital hardware design. describe basic building blocks used processor connected togetherand operated. presentation builds discussion Boolean algebra andbit-level operations Chapter 2. also introduce simple language, HCL(for “Hardware Control Language”), describe control portions hardwaresystems. later use language describe processor designs. Even ifyou already background logic design, read section understandour particular notation. ﬁrst step designing processor, present functionally correct, somewhat impractical, Y86 processor based sequential operation. processor executes complete Y86 instruction every clock cycle. clockmust run slowly enough allow entire series actions complete withinone cycle. processor could implemented, performance would bewell could achieved much hardware. sequential design basis, apply series transforma- tions create pipelined processor. processor breaks execution instruction ﬁve steps, handled separate section stage336 Chapter 4 Processor Architecture hardware. Instructions progress stages pipeline, one instruction entering pipeline clock cycle. result, processor canbe executing different steps ﬁve instructions simultaneously. Makingthis processor preserve sequential behavior Y86 ISA requires handlinga variety hazard conditions, location operands one instruction depend instructions still pipeline. devised variety tools studying experimenting processor designs. include assembler Y86, simulator run-ning Y86 programs machine, simulators two sequential onepipelined processor design. control logic designs described ﬁlesin HCL notation. editing ﬁles recompiling simulator, al-ter extend simulator’s behavior. number exercises provided thatinvolve implementing new instructions modifying machine processesinstructions. Testing code provided help evaluate correctness yourmodiﬁcations. exercises greatly aid understanding materialand give appreciation many different design alternatives facedby processor designers. Web Aside arch:vlog presents representation pipelined Y86 proces- sor Verilog hardware description language. involves creating modulesfor basic hardware building blocks overall processor structure. Weautomatically translate HCL description control logic Verilog. Byﬁrst debugging HCL description simulators, eliminate many thetricky bugs would otherwise show hardware design. Given Verilog description, commercial open-source tools support simulation logic synthesis , generating actual circuit designs microprocessors. So, although much effort expend create pictorial textual de-scriptions system, much one would writing software, fact thatthese designs automatically synthesized demonstrates indeedcreating system realized hardware. 4.1 Y86 Instruction Set Architecture Deﬁning instruction set architecture, Y86, includes deﬁning differ-ent state elements, set instructions encodings, set programmingconventions, handling exceptional events. 4.1.1 Programmer-Visible State Figure 4.1 illustrates, instruction Y86 program read modify part processor state. referred programmer-visible state, “programmer” case either someone writing programsin assembly code compiler generating machine-level code. see ourprocessor implementations need represent organize thisstate exactly manner implied ISA, long make sure thatmachine-level programs appear access programmer-visible state.The state Y86 similar IA32. eight program registers :Section 4.1 Y86 Instruction Set Architecture 337 RF: Program registers Stat: Program status DMEM: MemoryCC: Condition codes %eax %ecx %edx%ebx%esi %edi %esp%ebp PCZF SF Figure 4.1 Y86 programmer-visible state. IA32, programs Y86 access modify program registers, condition code, program counter (PC), thememory. status code indicates whether program running normally, somespecial event occurred. %eax ,%ecx ,%edx ,%ebx ,%esi ,%edi ,%esp , %ebp . stores word. Register %esp used stack pointer push, pop, call, return instructions. Otherwise, registers ﬁxed meanings values. arethree single-bit condition codes ,ZF,SF, OF, storing information effect recent arithmetic logical instruction. program counter(PC) holds address instruction currently executed. memory conceptually large array bytes, holding program data. Y86 programs reference memory locations using virtual addresses .A combination hardware operating system software translates actual, physical , addresses indicating values actually stored memory. study virtual memory detail Chapter 9. now, wecan think virtual memory system providing Y86 programs imageof monolithic byte array. ﬁnal part program state status code Stat, indicating overall state program execution. indicate either normal operation, somesort exception occurred, instruction attempts read invalid memory address. possible status codes handling exceptions described Section 4.1.4. 4.1.2 Y86 Instructions Figure 4.2 gives concise description individual instructions Y86 ISA. use instruction set target processor implementations. set Y86 instructions largely subset IA32 instruction set. includes 4-byte integer operations, fewer addressing modes, includes smaller setof operations. Since use 4-byte data, refer “words”without ambiguity. ﬁgure, show assembly-code representationof instructions left byte encodings right. assembly-code format similar ATT format IA32. details different Y86 instructions. .The IA32 movl instruction split four different instructions: irmovl , rrmovl ,mrmovl , rmmovl , explicitly indicating form source destination. source either immediate ( i), register ( r), memory ( m).338 Chapter 4 Processor Architecture Figure 4.2 Y86 instruction set.Instruction encodingsrange 1 and6 bytes. instructionconsists 1-byte instruction speciﬁer,possibly 1-byte registerspeciﬁer, possibly 4- byte constant word. Field fnspeciﬁes particular integer operation ( OPl ), data movement condition( cmovXX ), branch condition ( jXX ). numeric values shownin hexadecimal.halt noprrmovl rA,rB irmovl V,rB rmmovl rA,D(rB) mrmovl D(rB),rA OPl rA,rB jXX Dest cmovXX rA,rB call Dest retpushl rA popl rA01234 5 67289ABrB rBrBrBrB rBV DD DestDest0 Byte 12345 rA rA0 0000 0 fn fnfn 0 000FFrA F rA rArA rA designated ﬁrst character instruction name. destination either register ( r) memory ( m). designated second character instruction name. Explicitly identifying four types data transferwill prove helpful decide implement them. memory references two memory movement instructions simple base displacement format. support second indexregister scaling register’s value address computation. IA32, allow direct transfers one memory location another. addition, allow transfer immediate data tomemory. .There four integer operation instructions, shown Figure 4.2 OPl. addl ,subl ,andl , xorl . operate register data, whereas IA32 also allows operations memory data. instructions setthe three condition codes ZF,SF, OF(zero, sign, overﬂow). .The seven jump instructions (shown Figure 4.2 jXX) arejmp,jle,jl,je, jne,jge, jg. Branches taken according type branch settings condition codes. branch conditions withIA32 (Figure 3.12).Section 4.1 Y86 Instruction Set Architecture 339 .There six conditional move instructions (shown Figure 4.2 cmovXX ): cmovle ,cmovl ,cmove ,cmovne ,cmovge , cmovg . format register-register move instruction rrmovl , destination register updated condition codes satisfy required constraints. .Thecall instruction pushes return address stack jumps destination address. retinstruction returns call. .Thepushl andpopl instructions implement push pop, IA32. .Thehalt instruction stops instruction execution. IA32 comparable instruction, called hlt. IA32 application programs permitted use instruction, since causes entire system suspend operation. Y86, executing halt instruction causes processor stop, status code set HLT. (See Section 4.1.4.) 4.1.3 Instruction Encoding Figure 4.2 also shows byte-level encoding instructions. instruction requires 1 6 bytes, depending ﬁelds required. Everyinstruction initial byte identifying instruction type. byte splitinto two 4-bit parts: high-order, code , part, low-order, function , part. see Figure 4.2, code values range 0to0xB. function values signiﬁcant cases group related instructions sharea common code. given Figure 4.3, showing speciﬁc encodings ofthe integer operation, conditional move, branch instructions. Observe thatrrmovl instruction code conditional moves. viewed “unconditional move” jmpinstruction unconditional jump, function code 0. shown Figure 4.4, eight program registers associated register identiﬁer (ID) ranging 0 7. numbering registers Y86 matches used IA32. program registers stored within CPUin register ﬁle , small random-access memory register IDs serve Operations Branches 6addl 0 6subl 1 6andl 2 6xorl 37 7jmp 0 jle 1 7jl 2 7je 37jne 4 7jge 5 7jg 6Moves 2 2rrmovl 0 cmovle 1 2 cmovl 2 2 cmove 32 cmovne 4 2 cmovge 5 2 cmovg 6 Figure 4.3 Function codes Y86 instruction set. code speciﬁes particular integer operation, branch condition, data transfer condition. instructions shown OPl ,jXX , cmovXX Figure 4.2.340 Chapter 4 Processor Architecture Number Register name 0 %eax 1 %ecx2 %edx3 %ebx4 %esp5 %ebp6 %esi7 %ediF register Figure 4.4 Y86 program register identiﬁers. eight program registers associated identiﬁer (ID) ranging 0to7.I D0xF register ﬁeld instruction indicates absence register operand. addresses. ID value 0xF used instruction encodings within hardware designs need indicate register accessed. instructions 1 byte long, require operands longer encodings. First, additional register speciﬁer byte , specifying either one two registers. register ﬁelds called rAand rBin Figure 4.2. assembly-code versions instructions show, specify theregisters used data sources destinations, well base register used inan address computation, depending instruction type. Instructions haveno register operands, branches call , register speciﬁer byte. require one register operand ( irmovl ,pushl , andpopl ) register speciﬁer set value 0xF. convention prove useful processor implementation. instructions require additional 4-byte constant word . word serve immediate data irmovl , displacement rmmovl andmrmovl address speciﬁers, destination branches calls. Note branch andcall destinations given absolute addresses, rather using PC-relativeaddressing seen IA32. Processors use PC-relative addressing give morecompact encodings branch instructions allow code copied fromone part memory another without need update branch targetaddresses. Since concerned simplicity presentation, weuse absolute addressing. IA32, integers little-endian encoding.When instruction written disassembled form, bytes appear reverseorder. example, let us generate byte encoding instruction rmmovl %esp,0x12345(%edx) hexadecimal. Figure 4.2, see rmmovl initial byte 40. also see source register %esp encoded rAﬁeld, base register %edx encoded rBﬁeld. Using register numbers Figure 4.4, get register speciﬁer byte 42. Finally, theSection 4.1 Y86 Instruction Set Architecture 341 displacement encoded 4-byte constant word. ﬁrst pad 0x12345 leading zeros ﬁll 4 bytes, giving byte sequence 00 01 23 45 . write byte-reversed order 45 23 01 00 . Combining these, get instruction encoding 404245230100 . One important property instruction set byte encodings must unique interpretation. arbitrary sequence bytes either encodes aunique instruction sequence legal byte sequence. property holdsfor Y86, every instruction unique combination code functionin initial byte, given byte, determine length meaning ofany additional bytes. property ensures processor execute object-code program without ambiguity meaning code. Even thecode embedded within bytes program, readily determinethe instruction sequence long start ﬁrst byte sequence.On hand, know starting position code sequence, cannot reliably determine split sequence individual instructions.This causes problems disassemblers tools attempt extract machine-level programs directly object-code byte sequences. Practice Problem 4.1 Determine byte encoding Y86 instruction sequence follows. Theline “ .pos 0x100 ” indicates starting address object code 0x100 . .pos 0x100 # Start code address 0x100 irmovl $15,%ebx # Load 15 %ebx rrmovl %ebx,%ecx # Copy 15 %ecx loop: # loop: rmmovl %ecx,-3(%ebx) # Save %ecx address 15-3 = 12addl %ebx,%ecx # Increment %ecx 15jmp loop # Goto loop Practice Problem 4.2 byte sequence listed, determine Y86 instruction sequence encodes. invalid byte sequence, show instruction sequence point indicate invalid value occurs. sequence, weshow starting address, colon, byte sequence. A.0x100:30f3fcffffff40630008000000 B.0x200:a06f80080200000030f30a00000090 C.0x300:50540700000010f0b01f D.0x400:6113730004000000 E.0x500:6362a0f0342 Chapter 4 Processor Architecture Aside Comparing IA32 Y86 instruction encodings Compared instruction encodings used IA32, encoding Y86 much simpler also less compact. register ﬁelds occur ﬁxed positions Y86 instructions, whereas packed various positions different IA32 instructions. use 4-bit encoding registers, even though eight possible registers. IA32 uses 3 bits. Thus, IA32 pack push pop instruction 1 byte, 5-bit ﬁeld indicating instruction type remaining 3bits register speciﬁer. IA32 encode constant values 1, 2, 4 bytes, whereas Y86 alwaysrequires 4 bytes. Aside RISC CISC instruction sets IA32 sometimes labeled “complex instruction set computer” (CISC—pronounced “sisk”),and deemed opposite ISAs classiﬁed “reduced instruction set computers”(RISC—pronounced “risk”). Historically, CISC machines came ﬁrst, evolved earliest computers. early 1980s, instruction sets mainframe minicomputers grown quite large, machine designers incorporated new instructions support high-level tasks, manipulating circular buffers, performing decimal arithmetic, evaluating polynomials. ﬁrst microprocessorsappeared early 1970s limited instruction sets, integrated-circuit technology posed severe constraints could implemented single chip. Microprocessors evolvedquickly and, early 1980s, following path increasing instruction-set complexity set bymainframes minicomputers. x86 family took path, evolving IA32, recently x86-64. Even x86 line continues evolve new classes instructions added based needs emerging applications. RISC design philosophy developed early 1980s alternative trends. group hardware compiler experts IBM, strongly inﬂuenced ideas IBM researcher John Cocke, recognized could generate efﬁcient code much simpler form instruction set. fact, many high-level instructions added instruction sets difﬁcult generate compiler seldom used. simpler instruction set could implemented much less hardware could organized efﬁcient pipeline structure, similar described later chapter. IBM commercialize idea many years later, developed Power PowerPC ISAs. RISC concept developed Professors David Patterson, University California Berkeley, John Hennessy, Stanford University. Patterson gave name RISC new class machines, CISC existing class, since previously need special designation nearly universal form instruction set. Comparing CISC original RISC instruction sets, ﬁnd following general character- istics: CISC Early RISC large number instructions. Intel document describing complete set ofinstructions [28, 29] 1200 pages long.Many fewer instructions. Typically less 100. instructions long execution times. include instructions copy entireblock one part memory anotherand others copy multiple registers andfrom memory.No instruction long execution time. early RISC machines even havean integer multiply instruction, requiringcompilers implement multiplication asequence additions.Section 4.1 Y86 Instruction Set Architecture 343 CISC Early RISC Variable-length encodings. IA32 instructions range 1 15 bytes.Fixed-length encodings. Typically instructions encoded 4 bytes. Multiple formats specifying operands. IA32, memory operand speciﬁer havemany different combinations displacement,base index registers, scale factors.Simple addressing formats. Typically base displacement addressing. Arithmetic logical operations applied memory register operands.Arithmetic logical operations use register operands. Memory referencing onlyallowed load instructions, reading memory register, store instructions, writing register memory. Thisconvention referred load/store architecture . Implementation artifacts hidden machine- level programs. ISA provides cleanabstraction programs theyget executed.Implementation artifacts exposed machine- level programs. RISC machinesprohibit particular instruction sequencesand jumps take effect untilthe following instruction executed. Thecompiler given task optimizing performance within constraints. Condition codes. Special ﬂags set side effect instructions used conditional branch testing.No condition codes. Instead, explicit test instructions store test results normal registers use conditional evaluation. Stack-intensive procedure linkage. stack used procedure arguments returnaddresses.Register-intensive procedure linkage. Registers used procedure arguments returnaddresses. procedures therebyavoid memory references. Typically, theprocessor many (up 32) registers. Y86 instruction set includes attributes CISC RISC instruction sets. CISC side, condition codes, variable-length instructions, stack-intensive procedure linkages. RISC side, uses load-store architecture regular encoding. viewed taking aCISC instruction set (IA32) simplifying applying principles RISC. Aside RISC versus CISC controversy 1980s, battles raged computer architecture community regarding merits RISC versus CISC instruction sets. Proponents RISC claimed could get computing power given amount hardware combination streamlined instruction set design, advanced compiler technology, pipelined processor implementation. CISC proponents countered fewer CISC instructions required perform given task, machines could achieve higheroverall performance. Major companies introduced RISC processor lines, including Sun Microsystems (SPARC), IBM Motorola (PowerPC), Digital Equipment Corporation (Alpha). British company, Acorn344 Chapter 4 Processor Architecture Computers Ltd., developed architecture, ARM (originally acronym “Acorn RISC Machine”), widely used embedded applications, cellphones. early 1990s, debate diminished became clear neither RISC CISC purest forms better designs incorporated best ideas both. RISC machines evolved introduced instructions, many take multiple cycles execute. RISC machinestoday hundreds instructions repertoire, hardly ﬁtting name “reduced instruction set machine.” idea exposing implementation artifacts machine-level programs proved short-sighted. new processor models developed using advanced hardware structures,many artifacts became irrelevant, still remained part instruction set. Still, thecore RISC design instruction set well-suited execution pipelined machine. recent CISC machines also take advantage high-performance pipeline structures. discuss Section 5.7, fetch CISC instructions dynamically translate sequence simpler, RISC-like operations. example, instruction adds register memory translated three operations: one read original memory value, one perform addition,and third write sum memory. Since dynamic translation generally performed well advance actual instruction execution, processor sustain high execution rate. Marketing issues, apart technological ones, also played major role determining success different instruction sets. maintaining compatibility existing processors, Intel x86 made easy keep moving one generation processor next. integrated-circuit technology improved, Intel x86 processor manufacturers could overcome inefﬁciencies created original 8086 instruction set design, using RISC techniques produce performancecomparable best RISC machines. saw Section 3.13, evolution IA32 x86-64provided opportunity incorporate several features RISC x86. areas desktop andlaptop computing, x86 achieved total domination, increasingly popular high-end server machines. RISC processors done well market embedded processors , controlling systems cellular telephones, automobile brakes, Internet appliances. applications, savingon cost power important maintaining backward compatibility. terms number processors sold, large growing market. 4.1.4 Y86 Exceptions programmer-visible state Y86 (Figure 4.1) includes status code Stat describing overall state executing program. possible values thiscode shown Figure 4.5. Code value 1, named AOK, indicates program executing normally, codes indicate type exception occurred. Code 2, named HLT, indicates processor executed halt instruction. Code 3, named ADR, indicates processor attempted read write invalid memory address, either fetching instructionor reading writing data. limit maximum address (the exact limitvaries implementation), access address beyond limit willtrigger ADRexception. Code 4, named INS, indicates invalid instruction code encountered.Section 4.1 Y86 Instruction Set Architecture 345 Value Name Meaning 1 AOK Normal operation 2 HLT halt instruction encountered 3 ADR Invalid address encountered 4 INS Invalid instruction encountered Figure 4.5 Y86 status codes. design, processor halts code AOK . Y86, simply processor stop executing instructions encounters exceptions listed. complete design, processorwould typically invoke exception handler , procedure designated handle speciﬁc type exception encountered. described Chapter 8, exceptionhandlers conﬁgured different effects, aborting programor invoking user-deﬁned signal handler . 4.1.5 Y86 Programs Figure 4.6 shows IA32 Y86 assembly code following C function: int Sum(int *Start, int Count) { int sum = 0;while (Count) { sum += *Start; Start++; Count--; }return sum; } IA32 code generated gcccompiler. Y86 code essentially same, except Y86 sometimes requires two instructions accomplish whatcan done single IA32 instruction. written program usingarray indexing, however, conversion Y86 code would difﬁcult,since Y86 scaled addressing modes. code follows many programming conventions seen IA32, including use stackand frame pointers. simplicity, follow IA32 convention registers designated callee-save registers. programmingconvention either adopt ignore please. Figure 4.7 shows example complete program ﬁle written Y86 as- sembly code. program contains data instructions. Directives indicatewhere place code data align it. program speciﬁes issues such346 Chapter 4 Processor Architecture IA32 code int Sum(int *Start, int Count) 1 Sum: 2 pushl %ebp 3 movl %esp,%ebp 4 movl 8(%ebp),%ecx ecx = Start 5 movl 12(%ebp),%edx edx = Count 6 xorl %eax,%eax u m=0 7 testl %edx,%edx 8 je .L34 9 .L35: 10 addl (%ecx),%eax add *Start sum 11 addl $4,%ecx Start++ 12 decl %edx Count-- 13 jnz .L35 Stop 0 14 .L34: 15 movl %ebp,%esp 16 popl %ebp 17 retY86 code int Sum(int *Start, int Count) 1 Sum: 2 pushl %ebp 3 rrmovl %esp,%ebp 4 mrmovl 8(%ebp),%ecx ecx = Start 5 mrmovl 12(%ebp),%edx edx = Count 6 xorl %eax,%eax u m=0 7 andl %edx,%edx Set condition codes 8 je End 9 Loop: 10 mrmovl (%ecx),%esi get *Start 11 addl %esi,%eax add sum 12 irmovl $4,%ebx 13 addl %ebx,%ecx Start++ 14 irmovl $-1,%ebx 15 addl %ebx,%edx Count-- 16 jne Loop Stop 0 17 End: 18 rrmovl %ebp,%esp 19 popl %ebp 20 ret Figure 4.6 Comparison Y86 IA32 assembly programs. TheSum function computes sum integer array. Y86 code differs IA32 mainly may require multiple instructions perform done single IA32 instruction. stack placement, data initialization, program initialization, program termi- nation. program, words beginning “ .” assembler directives telling assembler adjust address generating code insert somewords data. directive .pos 0 (line 2) indicates assembler begin generating code starting address 0. starting address Y86 programs. next two instructions (lines 3 4) initialize stack framepointers. see label Stack declared end program (line 47), indicate address 0x100 using .pos directive (line 46). stack therefore start address grow toward lower addresses. must ensurethat stack grow large overwrites code program data. Lines 9 13 program declare array four words, values 0xd,0xc0 ,0xb00 , 0xa000 . label array denotes start array, aligned 4-byte boundary (using .align directive). Lines 17 6 show “main” procedure calls function Sumon four-word array halts.1# Execution begins address 0 2 .pos 0 3init: irmovl Stack, %esp # Set stack pointer 4 irmovl Stack, %ebp # Set base pointer 5 call Main # Execute main program 6 halt # Terminate program 7 8# Array 4 elements 9 .align 4 10 array: .long 0xd 11 .long 0xc0 12 .long 0xb00 13 .long 0xa000 1415 Main: pushl %ebp 16 rrmovl %esp,%ebp 17 irmovl $4,%eax 18 pushl %eax # Push 4 19 irmovl array,%edx 20 pushl %edx # Push array 21 call Sum # Sum(array, 4) 22 rrmovl %ebp,%esp 23 popl %ebp 24 ret 25 26 # int Sum(int *Start, int Count) 27 Sum: pushl %ebp 28 rrmovl %esp,%ebp 29 mrmovl 8(%ebp),%ecx # ecx = Start 30 mrmovl 12(%ebp),%edx # edx = Count 31 xorl %eax,%eax # sum = 0 32 andl %edx,%edx # Set condition codes 33 je End 34 Loop: mrmovl (%ecx),%esi # get *Start 35 addl %esi,%eax # add sum 36 irmovl $4,%ebx # 37 addl %ebx,%ecx # Start++ 38 irmovl $-1,%ebx # 39 addl %ebx,%edx # Count-- 40 jne Loop # Stop 0 41 End: rrmovl %ebp,%esp 42 popl %ebp 43 ret 44 45 # stack starts grows lower addresses 46 .pos 0x100 47 Stack: Figure 4.7 Sample program written Y86 assembly code. TheSum function called compute sum four-element array.348 Chapter 4 Processor Architecture example shows, since tool creating Y86 code assem- bler, programmer must perform tasks ordinarily delegate compiler,linker, run-time system. Fortunately, small programs, forwhich simple mechanisms sufﬁce. Figure 4.8 shows result assembling code shown Figure 4.7 assembler call yas. assembler output ASCII format make readable. lines assembly ﬁle contain instructions data, objectcode contains address, followed values 1 6 bytes. implemented instruction set simulator call yis, purpose model execution Y86 machine-code program, withoutattempting model behavior speciﬁc processor implementation. Thisform simulation useful debugging programs actual hardware isavailable, checking result either simulating hardware runningthe program hardware itself. Running sample object code, yis generates following output: Stopped 52 steps PC = 0x11. Status ’HLT’, CC Z=1 S=0 O=0 Changes registers: %eax: 0x00000000 0x0000abcd %ecx: 0x00000000 0x00000024%ebx: 0x00000000 0xffffffff %esp: 0x00000000 0x00000100 %ebp: 0x00000000 0x00000100 %esi: 0x00000000 0x0000a000 Changes memory: 0x00e8: 0x00000000 0x000000f80x00ec: 0x00000000 0x0000003d 0x00f0: 0x00000000 0x00000014 0x00f4: 0x00000000 0x00000004 0x00f8: 0x00000000 0x00000100 0x00fc: 0x00000000 0x00000011 ﬁrst line simulation output summarizes execution resulting values PC program status. printing register memoryvalues, prints words change simulation, either registersor memory. original values (here zero) shown left, ﬁnal values shown right. see output register %eax contains 0xabcd , sum four-element array passed subroutine Sum. addition, see stack, starts address 0x100 grows toward lower addresses, used, causing changes words memory ataddresses 0xe8 0xfc . well away 0x7c , maximum address executable code.Section 4.1 Y86 Instruction Set Architecture 349 | # Execution begins address 0 0x000: | .pos 0 0x000: 30f400010000 | init: irmovl Stack, %esp # Set stack pointer 0x006: 30f500010000 | irmovl Stack, %ebp # Set base pointer 0x00c: 8024000000 | call Main # Execute main program 0x011: 00 | halt # Terminate program | | # Array 4 elements 0x014: | .align 4 0x014: 0d000000 | array: .long 0xd 0x018: c0000000 | .long 0xc0 0x01c: 000b0000 | .long 0xb00 0x020: 00a00000 | .long 0xa000 | 0x024: a05f | Main: pushl %ebp 0x026: 2045 | rrmovl %esp,%ebp 0x028: 30f004000000 | irmovl $4,%eax 0x02e: a00f | pushl %eax # Push 4 0x030: 30f214000000 | irmovl array,%edx 0x036: a02f | pushl %edx # Push array 0x038: 8042000000 | call Sum # Sum(array, 4) 0x03d: 2054 | rrmovl %ebp,%esp 0x03f: b05f | popl %ebp 0x041: 90 | ret | | # int Sum(int *Start, int Count) 0x042: a05f | Sum: pushl %ebp 0x044: 2045 | rrmovl %esp,%ebp0x046: 501508000000 | mrmovl 8(%ebp),%ecx # ecx = Start 0x04c: 50250c000000 | mrmovl 12(%ebp),%edx # edx = Count 0x052: 6300 | xorl %eax,%eax # sum = 0 0x054: 6222 | andl %edx,%edx # Set condition codes 0x056: 7378000000 | je End 0x05b: 506100000000 | Loop: mrmovl (%ecx),%esi # get *Start 0x061: 6060 | addl %esi,%eax # add sum 0x063: 30f304000000 | irmovl $4,%ebx # 0x069: 6031 | addl %ebx,%ecx # Start++ 0x06b: 30f3ffffffff | irmovl $-1,%ebx # 0x071: 6032 | addl %ebx,%edx # Count-- 0x073: 745b000000 | jne Loop # Stop 0 0x078: 2054 | End: rrmovl %ebp,%esp 0x07a: b05f | popl %ebp 0x07c: 90 | ret | | # stack starts grows lower addresses 0x100: | .pos 0x100 0x100: | Stack: Figure 4.8 Output yas assembler. line includes hexadecimal address 1 6 bytes object code.350 Chapter 4 Processor Architecture Practice Problem 4.3 Write Y86 code implement recursive sum function rSum , based follow- ing C code: int rSum(int *Start, int Count) { (Count <= 0) return 0; return *Start + rSum(Start+1, Count-1); } might ﬁnd helpful compile C code IA32 machine translate instructions Y86. Practice Problem 4.4 Modify Y86 code Sum function (Figure 4.6) implement function AbsSum computes sum absolute values array. Use conditional jump instruction within inner loop. Practice Problem 4.5 Modify Y86 code Sum function (Figure 4.6) implement function AbsSum computes sum absolute values array. Use conditional move instruction within inner loop. 4.1.6 Y86 Instruction Details Y86 instructions transform program state straightforward manner, deﬁning intended effect instruction difﬁcult. Two unusualinstruction combinations, however, require special attention. Thepushl instruction decrements stack pointer 4 writes register value memory. therefore totally clear processor shoulddo executing instruction pushl %esp , since register pushed changed instruction. Two different conventions possible:(1) push original value %esp , (2) push decremented value %esp . Y86 processor, let us adopt convention used IA32, determined following problem. Practice Problem 4.6 Let us determine behavior instruction pushl %esp IA32 proces- sor. could try reading Intel documentation instruction, simplerapproach conduct experiment actual machine. C compiler wouldnot normally generate instruction, must use hand-generated assemblySection 4.1 Y86 Instruction Set Architecture 351 code task. test function written (Web Aside asm:easm describes write programs combine C code hand-written assemblycode): 1 .text 2.globl pushtest 3pushtest: 4 pushl %ebp 5 movl %esp, %ebp 6 movl %esp, %eax Copy stack pointer 7 pushl %esp Push stack pointer 8 popl %edx Pop back 9 subl %edx,%eax Subtract new old stack pointer 10 leave Restore stack & frame pointers 11 ret experiments, ﬁnd function pushtest always returns zero. imply behavior instruction pushl %esp IA32? similar ambiguity occurs instruction popl %esp . could either set %esp value read memory incremented stack pointer. Problem 4.6, let us run experiment determine IA32 machinewould handle instruction, design Y86 machine follow sameconvention. Practice Problem 4.7 following assembly-code function lets us determine behavior in-struction popl %esp IA32: 1 .text 2.globl poptest 3poptest: 4 pushl %ebp 5 movl %esp, %ebp 6 pushl $0xabcd Push test value 7 popl %esp Pop stack pointer 8 movl %esp, %eax Set popped value return value 9 leave Restore stack frame pointers 10 ret ﬁnd function always returns 0xabcd . imply behavior popl %esp ? Y86 instruction would exact behavior?352 Chapter 4 Processor Architecture Aside Getting details right: Inconsistencies across x86 models Problems 4.6 4.7 designed help us devise consistent set conventions instructions push pop stack pointer. seems little reason one would want perform either operations, natural question ask “Why worry picky details?” Several useful lessons learned importance consistency following excerpt Intel documentation popinstruction [29]: IA-32 processors Intel 286 on, PUSH ESP instruction pushes value ESP register existed instruction executed. (This also true Intel 64 architecture,real-address virtual-8086 modes IA-32 architecture.) Intel ®8086 processor, PUSH SP instruction pushes new value SP register (that value decremented 2). note states different models x86 processors different things instructed push stack pointer register. push original value, others push decremented value. (Interestingly, corresponding ambiguity popping stack pointer register.) two drawbacks inconsistency: .It decreases code portability. Programs may different behavior depending processor model. Although particular instruction common, even potential incompat- ibility serious consequences. .It complicates documentation. see here, special note required try clarify thedifferences. documentation x86 already complex enough without special cases one. conclude, therefore, working details advance striving complete consistency save lot trouble long run. 4.2 Logic Design Hardware Control Language HCL hardware design, electronic circuits used compute functions bits store bits different kinds memory elements. contemporary circuittechnology represents different bit values high low voltages signal wires. Incurrent technology, logic value 1 represented high voltage around 1.0 volt,while logic value 0 represented low voltage around 0.0 volts. Three majorcomponents required implement digital system: combinational logic tocompute functions bits, memory elements store bits, clock signals toregulate updating memory elements. section, provide brief description different components. also introduce HCL (for “hardware control language”), language thatwe use describe control logic different processor designs. describe HCL informally here. complete reference HCL found Web Aside arch:hcl .Section 4.2 Logic Design Hardware Control Language HCL 353 Aside Modern logic design one time, hardware designers created circuit designs drawing schematic diagrams logic circuits (ﬁrst paper pencil, later computer graphics terminals). Nowadays, designs expressed hardware description language (HDL), textual notation looks similar programming language used describe hardware structures rather program behaviors. commonly used languages Verilog, syntax similar C, VHDL, syntax similar Ada programming language. languages originally designed expressing simulation models digital circuits. mid-1980s, researchers developed logic synthesis programs could generate efﬁcient circuit designs HDL descriptions. numberof commercial synthesis programs, become dominant technique generating digitalcircuits. shift hand-designed circuits synthesized ones likened shift fromwriting programs assembly code writing high-level language compilergenerate machine code. HCL language expresses control portions hardware design, limited set operations modularity. see, however, control logic difﬁcult part designing microprocessor. developed tools directly translate HCL Verilog, combining code Verilog code basic hardware units, generate HDLdescriptions actual working microprocessors synthesized. carefully separating out, designing, testing control logic, create working microprocessor reasonable effort. Web Aside arch:vlog describes generate Verilog versions Y86 processor. 4.2.1 Logic Gates Logic gates basic computing elements digital circuits. generate output equal Boolean function bit values inputs. Figure 4.9shows standard symbols used Boolean functions ,Or, Not. HCL expressions shown gates operators C (Section 2.1.9):&&for ,||for Or, !for Not. use instead bit-level C operators &,|, ~, logic gates operate single-bit quantities, entire words. Although ﬁgure illustrates two-input versions Orgates, common see used n-way operations n>2. still write HCL using binary operators, though, operation three-input gate inputs a,b, cis described HCL expression a& &b& &c . Logic gates always active. input gate changes, within small amount time, output change accordingly. Figure 4.9 Logic gate types. gate generates output equal Booleanfunction inputs.And outOr aa ba b out/H11005 && b /H11005 || b out/H11005!a354 Chapter 4 Processor Architecture Figure 4.10 Combinational circuit totest bit equality. output equal 1 whenboth inputs 0, 1.a beqBit equal 4.2.2 Combinational Circuits HCL Boolean Expressions assembling number logic gates network, construct compu- tational blocks known combinational circuits . Two restrictions placed networks constructed: .The outputs two logic gates cannot connected together. Other-wise, two could try drive wire opposite directions, possibly causingan invalid voltage circuit malfunction. .The network must acyclic . is, cannot path series gates forms loop network. loops cause ambiguity inthe function computed network. Figure 4.10 shows example simple combinational circuit ﬁnd useful. two inputs, aand b. generates single output eq, output equal 1 either aand bare 1 (detected upper gate) 0 (detected lower gate). write function network HCL bool eq = (a && b) || (!a && !b); code simply deﬁnes bit-level (denoted data type bool ) signal eqas function inputs aand b. example shows, HCL uses C-style syntax, ‘=’ associating signal name expression. Unlike C, however, view performing computation assigning result memorylocation. Instead, simply way give name expression. Practice Problem 4.8 Write HCL expression signal xor, equal Exclusive-Or inputs b. relation signals xorand eqdeﬁned above? Figure 4.11 shows another example simple useful combinational circuit known multiplexor (commonly referred “MUX”). multiplexor selects value among set different data signals, depending valueof control input signal. single-bit multiplexor, two data signals input bits aand b, control signal input bit s. output equal awhen sis 1, equal bwhen sis 0. circuit, see two gates determine whether pass respective data inputs Orgate.Section 4.2 Logic Design Hardware Control Language HCL 355 Figure 4.11 Single-bit multiplexorcircuit. output equal input controlsignal 1 equal input b 0.s b aBit MUX upper gate passes signal bwhen sis 0 (since input gate is!s), lower gate passes signal awhen sis 1. Again, write HCL expression output signal, using operations present inthe combinational circuit: bool = (s && a) || (!s && b); HCL expressions demonstrate clear parallel combinational logic circuits logical expressions C. use Boolean operations tocompute functions inputs. Several differences two waysof expressing computation worth noting: .Since combinational circuit consists series logic gates, theproperty outputs continually respond changes inputs. Ifsome input circuit changes, delay, outputs willchange accordingly. contrast, C expression evaluated isencountered execution program. .Logical expressions C allow arguments arbitrary integers, interpreting0a false anything else true . contrast, logic gates operate bit values 0 1. .Logical expressions C property might partiallyevaluated. outcome orOroperation determined evaluating ﬁrst argument, second argument beevaluated. example, C expression (a && !a) && func(b,c) function func called, expression (a && !a) evalu- ates 0. contrast, combinational logic partial evaluation rules. gates simply respond changing inputs. 4.2.3 Word-Level Combinational Circuits HCL Integer Expressions assembling large networks logic gates, construct combinational circuits compute much complex functions. Typically, design circuitsthat operate data words . groups bit-level signals represent integer control pattern. example, processor designs contain numerous words, word sizes ranging 4 32 bits, representing integers, addresses, instruction codes, register identiﬁers.356 Chapter 4 Processor Architecture Figure 4.12 Word-level equality testcircuit. output equal 1 bitfrom word equals counterpart word B. Word-level equality oneof operations HCL. (a) Bit-level implementationBit equal Bit equal Bit equal Bit equalb31 a31 b30 a30 b1 a1 b0 a0eq31 eq1 eq0eq30 Eq . . .. . . (b) Word-level abstractionABA = B/H11005 Combinational circuits perform word-level computations constructed using logic gates compute individual bits output word, based theindividual bits input words. example, Figure 4.12 shows combinationalcircuit tests whether two 32-bit words Aand Bare equal. is, output equal 1 bit Aequals corresponding bit B. circuit implemented using 32 single-bit equality circuits shown Figure 4.10. outputs single-bit circuits combined gate form circuit output. HCL, declare word-level signal int, without specifying word size. done simplicity. full-featured hardware descriptionlanguage, every word declared speciﬁc number bits. HCL allowswords compared equality, functionality circuit shownin Figure 4.12 expressed word level bool Eq = (A == B); arguments Aand Bare type int. Note use syntax conventions C, ‘ =’ denotes assignment, ‘ ==’ denotes equality operator. shown right side Figure 4.12, draw word-level circuits using medium-thickness lines represent set wires carrying individualbits word, show resulting Boolean signal dashed line. Practice Problem 4.9 Suppose want implement word-level equality circuit using Exclusive- Orcircuits Problem 4.8 rather bit-level equality circuits. Design circuit 32-bit word consisting 32 bit-level Exclusive-Or circuits two additional logic gates.Section 4.2 Logic Design Hardware Control Language HCL 357 Figure 4.13 Word-level multiplexorcircuit. output equal input word whenthe control signal 1, equal B otherwise. Multiplexors aredescribed HCL usingcase expressions. (a) Bit-level implementation (b) Word-level abstractionout31 out30 out0s B AOut MUX int = [ : A; l : B; ];b31 a31 b30 a30 b0 a0. . . Figure 4.13 shows circuit word-level multiplexor. circuit gener- ates 32-bit word equal one two input words, AorB, depending control input bit s. circuit consists 32 identical subcircuits, structure similar bit-level multiplexor Figure 4.11. Rather simplyreplicating bit-level multiplexor 32 times, word-level version reduces thenumber inverters generating !sonce reusing bit position. use many forms multiplexors processor designs. allow us select word number sources depending control condi-tion. Multiplexing functions described HCL using case expressions . case expression following general form: [ select 1: expr 1 select 2: expr 2 ... selectk: exprk ] expression contains series cases, case iconsists Boolean expression select i, indicating case selected, integer expression expri, indicating resulting value.358 Chapter 4 Processor Architecture Unlike switch statement C, require different selection expressions mutually exclusive. Logically, selection expressions eval-uated sequence, case ﬁrst one yielding 1 selected. example,the word-level multiplexor Figure 4.13 described HCL int = [ s: A;1: B; ]; code, second selection expression simply 1, indicating case selected prior one been. way specify defaultcase HCL. Nearly case expressions end manner. Allowing nonexclusive selection expressions makes HCL code read- able. actual hardware multiplexor must mutually exclusive signals con-trolling input word passed output, signals sand !sin Figure 4.13. translate HCL case expression hardware, logic syn- thesis program would need analyze set selection expressions resolveany possible conﬂicts making sure ﬁrst matching case would beselected. selection expressions arbitrary Boolean expressions, arbitrary number cases. allows case expressions describe blockswhere many choices input signals complex selection criteria. Forexample, consider diagram four-way multiplexor shown Figure 4.14.This circuit selects among four input words A,B,C, Dbased control signals s1and s0, treating controls 2-bit binary number. express HCL using Boolean expressions describe different combinations control bit patterns: int Out4 = [ !s1 && !s0 : A; # 00 ! 1 :B ;#0 1 ! 0 :C ;#1 01 :D ;#1 1 ]; comments right (any text starting #and running rest line comment) show combination s1and s0will cause case Figure 4.14 Four-way multiplexor. different combinations control signals s1 ands0 determine datainput transmitted output.Ds1 s0 Out4C B AMUX4Section 4.2 Logic Design Hardware Control Language HCL 359 selected. Observe selection expressions sometimes simpliﬁed, since ﬁrst matching case selected. example, second expressioncan written !s1, rather complete !s1&&s0, since possibility s1equal 0 given ﬁrst selection expression. Similarly, third expression written !s0, fourth simply written as1. ﬁnal example, suppose want design logic circuit ﬁnds minimum value among set words A,B, C, diagrammed follows: C B AMIN3 Min3 express using HCL case expression int Min3 = [ A< =B& &A< =C:A ;B< =A& &B< =C:B ;1: C ; ]; Practice Problem 4.10 Write HCL code describing circuit word inputs A,B, Cselects median three values. is, output equals word lying minimum maximum three inputs. Combinational logic circuits designed perform many different types operations word-level data. detailed design beyond thescope presentation. One important combinational circuit, known anarithmetic/logic unit (ALU), diagrammed abstract level Figure 4.15. circuit three inputs: two data inputs labeled Aand B, control input. Depending setting control input, circuit performdifferent arithmetic logical operations data inputs. Observe four 0 XX/H11001 YA L UA B1 XX/H11002 YA L UA B2 XX&YA L UA B3 XX^YA L UA B Figure 4.15 Arithmetic/logic unit (ALU). Depending setting function input, circuit perform one four different arithmetic logical operations.360 Chapter 4 Processor Architecture operations diagrammed ALU correspond four different integer operations supported Y86 instruction set, control values matchthe function codes instructions (Figure 4.3). Note also orderingof operands subtraction, Ainput subtracted Binput. ordering chosen anticipation ordering arguments subl instruction. 4.2.4 Set Membership processor designs, ﬁnd many examples want compare one signal number possible matching signals, test whetherthe code instruction processed matches category instruc- tion codes. simple example, suppose want generate signals s1and s0for four-way multiplexor Figure 4.14 selecting high- low-order bits 2-bit signal code , follows: codes1 s0 C B AControl MUX4 Out4 circuit, 2-bit signal code would control selection among four data words A,B,C, D. express generation signals s1and s0 using equality tests based possible values code : bool s1 = code == 2 || code == 3; bool s0 = code == 1 || code == 3; concise expression written expresses property s1 1 code set {2,3}, s0is 1 code set {1,3}: bool s1 = code { 2, 3 }; bool s0 = code { 1, 3 }; general form set membership test iexpr in{iexpr1,iexpr2,..., iexprk}Section 4.2 Logic Design Hardware Control Language HCL 361 value tested, iexpr , candidate matches, iexpr 1through iexpr k, integer expressions. 4.2.5 Memory Clocking Combinational circuits, nature, store information. Instead, simply react signals inputs, generating outputs equal somefunction inputs. create sequential circuits , is, systems state perform computations state, must introduce devices storeinformation represented bits. storage devices controlled singleclock , periodic signal determines new values loaded devices. consider two classes memory devices: Clocked registers (or simply registers ) store individual bits words. clock signal controls loading register value input. Random-access memories (or simply memories ) store multiple words, using address select word read written. Examplesof random-access memories include (1) virtual memory system ofa processor, combination hardware operating systemsoftware make appear processor access word withina large address space; (2) register ﬁle, register identiﬁersserve addresses. IA32 Y86 processor, register ﬁle holdsthe eight program registers ( %eax ,%ecx , etc.). see, word “register” means two slightly different things speaking hardware versus machine-language programming. hardware, aregister directly connected rest circuit input outputwires. machine-level programming, registers represent small collectionof addressable words CPU, addresses consist register IDs.These words generally stored register ﬁle, although see thehardware sometimes pass word directly one instruction another toavoid delay ﬁrst writing reading register ﬁle. necessaryto avoid ambiguity, call two classes registers “hardware registers”and “program registers,” respectively. Figure 4.16 gives detailed view hardware register operates. time, register remains ﬁxed state (shown asx), generating output equal current state. Signals propagate combinational logic preceding register, creating new value registerinput (shown y), register output remains ﬁxed long clock low. clock rises, input signals loaded register next state(y), becomes new register output next rising clock edge. key point registers serve barriers combinational logicin different parts circuit. Values propagate register input itsoutput every clock cycle rising clock edge. Y86 processors will362 Chapter 4 Processor Architecture State = x State = Input = Output = x Output = Rising clock x Figure 4.16 Register operation. register outputs remain held current register state clock signal rises. clock rises, values register inputs arecaptured become new register state. use clocked registers hold program counter ( PC), condition codes ( CC), program status ( Stat). following diagram shows typical register ﬁle: Register fileA BvalA valW dstWsrcA valB srcB clockWrite port W Read ports register ﬁle two read ports , named B, one write port , named W. multiported random-access memory allows multiple read write operations take place simultaneously. register ﬁle diagrammed, circuitcan read values two program registers update state third. Eachport address input, indicating program register selected,and data output input giving value program register. addressesare register identiﬁers, using encoding shown Figure 4.4. two read ports address inputs srcA srcB (short “source A” “source B”) data outputs valA valB (short “value A” “value B”). write port address input dstW (short “destination W”) data input valW (short “value W”). register ﬁle combinational circuit, since internal storage. implementation, however, data read register ﬁle werea block combinational logic addresses inputs data outputs.When either srcA orsrcB set register ID, then, delay, value stored corresponding program register appear either valA valB. example, setting srcA 3 cause value program register %ebx read, value appear output valA. writing words register ﬁle controlled clock signal manner similar loading values clocked register. Every time theclock rises, value input valW written program register indicated bySection 4.2 Logic Design Hardware Control Language HCL 363 register ID input dstW . dstW set special ID value 0xF,n program register written. Since register ﬁle read written, anatural question ask “What happens attempt read write sameregister simultaneously?” answer straightforward: update registerwhile using register ID read port, would observe transitionfrom old value new. incorporate register ﬁle ourprocessor design, make sure take property consideration. processor random-access memory storing program data, illustrated below: Data memorydata data addresserror read write clock memory single address input, data input writing, data output reading. Like register ﬁle, reading memory operates mannersimilar combinational logic: provide address address input set write control signal 0, delay, value stored address appear data .T h e error signal set 1 address range 0 otherwise. Writing memory controlled clock:we set address desired address, data desired value, write 1. operate clock, speciﬁed location memory beupdated, long address valid. read operation, error signal set 1 address invalid. signal generated combinational logic, since required bounds checking purely function address inputand involve saving state. Aside Real-life memory design memory system full-scale microprocessor far complex simple one assume design. consists several forms hardware memories, including several random-access memories plus magnetic disk, well variety hardware software mechanisms managing devices. design characteristics memory system described Chapter 6. Nonetheless, simple memory design used smaller systems, provides us abstraction interface processor memory complex systems. processor includes additional read-only memory reading instruc- tions. actual systems, memories merged single memory two ports: one reading instructions reading writing data.364 Chapter 4 Processor Architecture 4.3 Sequential Y86 Implementations components required implement Y86 processor. ﬁrst step, describe processor called SEQ (for “sequential” processor). eachclock cycle, SEQ performs steps required process complete instruction.This would require long cycle time, however, clock rate would beunacceptably low. purpose developing SEQ provide ﬁrst step towardour ultimate goal implementing efﬁcient, pipelined processor. 4.3.1 Organizing Processing Stages general, processing instruction involves number operations. organize particular sequence stages, attempting make instructions followa uniform sequence, even though instructions differ greatly actions.The detailed processing step depends particular instruction executed. Creating framework allow us design processor makes best use hardware. following informal description stagesand operations performed within them: Fetch: fetch stage reads bytes instruction memory, using program counter (PC) memory address. instruction itextracts two 4-bit portions instruction speciﬁer byte, referredto icode (the instruction code) ifun (the instruction function). possibly fetches register speciﬁer byte, giving one theregister operand speciﬁers rAand rB. also possibly fetches 4-byte constant word valC . computes valP address instruction following current one sequential order. is, valP equals value PC plus length fetched instruction. Decode: decode stage reads two operands register ﬁle, giving values valA and/or valB. Typically, reads registers designated instruction ﬁelds rAand rB, instructions reads register %esp . Execute: execute stage, arithmetic/logic unit (ALU) either performs operation speciﬁed instruction (according value ifun), computes effective address memory reference, increments ordecrements stack pointer. refer resulting value valE.T h e condition codes possibly set. jump instruction, stage teststhe condition codes branch condition (given ifun) see whether branch taken. Memory: memory stage may write data memory, may read data memory. refer value read valM . Write back: write-back stage writes two results register ﬁle. PC update: PC set address next instruction. processor loops indeﬁnitely, performing stages. simpliﬁed im- plementation, processor stop exception occurs: executes aSection 4.3 Sequential Y86 Implementations 365 1 0x000: 30f209000000 | irmovl $9, %edx 2 0x006: 30f315000000 | irmovl $21, %ebx 3 0x00c: 6123 | subl %edx, %ebx # subtract 4 0x00e: 30f480000000 | irmovl $128,%esp # Problem 4.11 5 0x014: 404364000000 | rmmovl %esp, 100(%ebx) # store 6 0x01a: a02f | pushl %edx # push 7 0x01c: b00f | popl %eax # Problem 4.12 8 0x01e: 7328000000 | je done # taken 9 0x023: 8029000000 | call proc # Problem 4.16 10 0x028: | done: 11 0x028: 00 | halt 12 0x029: | proc: 13 0x029: 90 | ret # Return Figure 4.17 Sample Y86 instruction sequence. trace processing instructions different stages. halt invalid instruction, attempts read write invalid address. complete design, processor would enter exception-handling modeand begin executing special code determined type exception. seen preceding description, surprising amount processing required execute single instruction. must perform thestated operation instruction, must also compute addresses, update stackpointers, determine next instruction address. Fortunately, overall ﬂowcan similar every instruction. Using simple uniform structure isimportant designing hardware, since want minimize total amountof hardware, must ultimately map onto two-dimensional surface integrated-circuit chip. One way minimize complexity differentinstructions share much hardware possible. example, ourprocessor designs contains single arithmetic/logic unit used differentways depending type instruction executed. cost duplicating blocks logic hardware much higher cost multiple copiesof code software. also difﬁcult deal many special cases andidiosyncrasies hardware system software. challenge arrange computing required different instructions ﬁt within general framework. use code shown inFigure 4.17 illustrate processing different Y86 instructions. Figures 4.18through 4.21 contain tables describing different Y86 instructions proceedthrough stages. worth effort study tables carefully. arein form enables straightforward mapping hardware. line inthese tables describes assignment signal stored state (indicated bythe assignment operation ←). read evaluated sequence top bottom. later map computations hardware,we ﬁnd need perform evaluations strict sequential order.366 Chapter 4 Processor Architecture Stage OPl rA,rB rrmovl rA,rB irmovl V,rB Fetch icode :ifun←M1[PC] icode :ifun←M1[PC] icode :ifun←M1[PC] rA:rB←M1[PC+1] rA:rB←M1[PC+1] rA:rB←M1[PC+1] valC←M4[PC+2] valP←PC+2 valP←PC+2 valP←PC+6 Decode valA←R[rA] valA←R[rA] valB←R[rB] Execute valE←valB OP valA valE ←0+valA valE ←0+valC Set CC Memory Write back R[rB]←valE R [rB]←valE R [rB]←valE PC update PC←valP PC ←valP PC ←valP Figure 4.18 Computations sequential implementation Y86 instructions OPl, rrmovl , irmovl .These instructions compute value store result register. notation icode :ifun indicates two components instruction byte, rA :rB indicates two components register speciﬁer byte. notation M1[x]indicates accessing (either reading writing) 1 byte memory location x, M4[x]indicates accessing 4 bytes. Figure 4.18 shows processing required instruction types OPl(integer logical operations), rrmovl (register-register move), irmovl (immediate- register move). Let us ﬁrst consider integer operations. Examining Figure 4.2,we see carefully chosen encoding instructions thefour integer operations ( addl ,subl ,andl , xorl ) value icode . handle identical sequence steps, except ALU computation must set according particular instruction operation,encoded ifun. processing integer-operation instruction follows general pattern listed above. fetch stage, require constant word, valP computed PC+2. decode stage, read operands. supplied ALU execute stage, along function speciﬁerifun, valE becomes instruction result. computation shown expression valB OP valA , OPindicates operation speciﬁed ifun. Note ordering two arguments—this order consistent conventionsof Y86 (and IA32). example, instruction subl %eax,%edx supposed compute value R[%edx ]−R[%eax ]. Nothing happens memory stage instructions, valE written register rBin write-back stage, PC set valP complete instruction execution.Section 4.3 Sequential Y86 Implementations 367 Aside Tracing execution subl instruction example, let us follow processing subl instruction line 3 object code shown Figure 4.17. see previous two instructions initialize registers %edx and%ebx 9 21, respectively. also see instruction located address 0x00c consists 2 bytes, values 0x61 and0x23 . stages would proceed shown following table, lists generic rule processing OPlinstruction (Figure 4.18) left, computations speciﬁc instruction right. Generic Speciﬁc Stage OPl rA,rB subl %edx, %ebx Fetch icode :ifun←M1[PC] icode :ifun←M1[0x00c ]=6:1 rA:rB←M1[PC+1] rA:rB←M1[0x00d ]=2:3 valP←PC+2 valP←0x00c +2=0x00e Decode valA←R[rA] valA←R[%edx ]=9 valB←R[rB] valB←R[%ebx ]=21 Execute valE←valB OP valA valE ←21−9=12 Set CC ZF←0,SF←0,OF←0 Memory Write back R[rB]←valE R [%ebx ]←valE=12 PC update PC←valP PC ←valP=0x00e trace shows, achieve desired effect setting register %ebx 12, setting three condition codes zero, incrementing PC 2. Executing rrmovl instruction proceeds much like arithmetic operation. need fetch second register operand, however. Instead, set thesecond ALU input zero add ﬁrst, giving valE=valA, written register ﬁle. Similar processing occurs irmovl , except use constant value valC ﬁrst ALU input. addition, must increment program counter 6 irmovl due long instruction format. Neither instructions changes condition codes. Practice Problem 4.11 Fill right-hand column following table describe processing oftheirmovl instruction line 4 object code Figure 4.17:368 Chapter 4 Processor Architecture Generic Speciﬁc Stage irmovl V,rB irmovl $128, %esp Fetch icode :ifun←M1[PC] rA:rB←M1[PC+1] valC←M4[PC+2] valP←PC+6 Decode Execute valE←0+valC Memory Write back R[rB]←valE PC update PC←valP instruction execution modify registers PC? Figure 4.19 shows processing required memory write read in- structions rmmovl andmrmovl . see basic ﬂow before, using ALU add valC tovalB, giving effective address (the sum displacement Stage rmmovl rA,D(rB) mrmovl D(rB),rA Fetch icode :ifun←M1[PC] icode :ifun←M1[PC] rA:rB←M1[PC+1] rA:rB←M1[PC+1] valC←M4[PC+2] valC←M4[PC+2] valP←PC+6 valP←PC+6 Decode valA←R[rA] valB←R[rB] valB←R[rB] Execute valE←valB+valC valE ←valB+valC Memory M4[valE]←valA valM ←M4[valE] Write back R[rA]←valM PC update PC←valP PC ←valP Figure 4.19 Computations sequential implementation Y86 instructions rmmovl andmrmovl .These instructions read write memory.Section 4.3 Sequential Y86 Implementations 369 base register value) memory operation. memory stage either write register value valA memory, read valM memory. Aside Tracing execution rmmovl instruction Let us trace processing rmmovl instruction line 5 object code shown Figure 4.17. see previous instruction initialized register %esp 128, %ebx still holds 12, computed subl instruction (line 3). also see instruction located address 0x014 consists 6 bytes. ﬁrst 2 values 0x40 and0x43 , ﬁnal 4 byte-reversed version number 0x00000064 (decimal 100). stages would proceed follows: Generic Speciﬁc Stage rmmovl rA,D(rB) rmmovl %esp, 100(%ebx) Fetch icode :ifun←M1[PC] icode :ifun←M1[0x014 ]=4:0 rA:rB←M1[PC+1] rA:rB←M1[0x015 ]=4:3 valC←M4[PC+2] valC←M4[0x016 ]=100 valP←PC+6 valP←0x014 +6=0x01a Decode valA←R[rA] valA←R[%esp ]=128 valB←R[rB] valB←R[%ebx ]=12 Execute valE←valB+valC valE ←12+100=112 Memory M4[valE]←valA 4[112]←128 Write back PC update PC←valP PC ←0x01a trace shows, instruction effect writing 128 memory address 112 incrementing PC 6. Figure 4.20 shows steps required process pushl andpopl instructions. among difﬁcult Y86 instructions implement, in-volve accessing memory incrementing decrementing stack pointer.Although two instructions similar ﬂows, important differences. Thepushl instruction starts much like previous instructions, decode stage use %esp identiﬁer second register operand, giving stack pointer value valB. execute stage, use ALU decrement stack pointer 4. decremented value used memory writeaddress also stored back %esp write-back stage. using valE address write operation, adhere Y86 (and IA32) convention thatpushl decrement stack pointer writing, even though actual updating stack pointer occur memory operation completed.370 Chapter 4 Processor Architecture Stage pushl rA popl rA Fetch icode :ifun←M1[PC] icode :ifun←M1[PC] rA:rB←M1[PC+1] rA:rB←M1[PC+1] valP←PC+2 valP←PC+2 Decode valA←R[rA] valA←R[%esp ] valB←R[%esp ] valB←R[%esp ] Execute valE←valB+(−4) valE←valB+4 Memory M4[valE]←valA valM ←M4[valA] Write back R[%esp ]←valE R [%esp ]←valE R[rA]←valM PC update PC←valP PC ←valP Figure 4.20 Computations sequential implementation Y86 instructions pushl andpopl .These instructions push pop stack. Aside Tracing execution pushl instruction Let us trace processing pushl instruction line 6 object code shown Figure 4.17. point, 9 register %edx 128 register %esp . also see instruction located address 0x01a consists 2 bytes values 0xa0 and0x28 . stages would proceed follows: Generic Speciﬁc Stage pushl rA pushl %edx Fetch icode :ifun←M1[PC] icode :ifun←M1[0x01a ]=a:0 rA:rB←M1[PC+1] rA:rB←M1[0x01b ]=2:8 valP←PC+2 valP←0x01a +2=0x01c Decode valA←R[rA] valA←R[%edx ]=9 valB←R[%esp ] valB←R[%esp ]=128 Execute valE←valB+(−4) valE←128+(−4)=124 Memory M4[valE]←valA 4[124]←9 Write back R[%esp ]←valE R [%esp ]←124 PC update PC←valP PC ←0x01cSection 4.3 Sequential Y86 Implementations 371 trace shows, instruction effect setting %esp 124, writing 9 address 124, incrementing PC 2. Thepopl instruction proceeds much like pushl , except read two copies stack pointer decode stage. clearly redundant, wewill see stack pointer valA valB makes subsequent ﬂow similar instructions, enhancing overall uniformityof design. use ALU increment stack pointer 4 executestage, use unincremented value address memory operation.In write-back stage, update stack pointer register incre-mented stack pointer, register rAwith value read memory. Using unincremented stack pointer memory read address preserves Y86(and IA32) convention popl ﬁrst read memory increment stack pointer. Practice Problem 4.12 Fill right-hand column following table describe processing ofthepopl instruction line 7 object code Figure 4.17: Generic Speciﬁc Stage popl rA popl %eax Fetch icode :ifun←M1[PC] rA:rB←M1[PC+1] valP←PC+2 Decode valA←R[%esp ] valB←R[%esp ] Execute valE←valB+4 Memory valM←M4[valA] Write back R[%esp ]←valE R[rA]←valM PC update PC←valP effect instruction execution registers PC?372 Chapter 4 Processor Architecture Practice Problem 4.13 would effect instruction pushl %esp according steps listed Figure 4.20? conform desired behavior Y86, asdetermined Problem 4.6? Practice Problem 4.14 Assume two register writes write-back stage popl occur order listed Figure 4.20. would effect executing popl %esp ? conform desired behavior Y86, determined Problem 4.7? Figure 4.21 indicates processing three control transfer instructions: different jumps, call , ret. see implement instruc- tions overall ﬂow preceding ones. integer operations, process jumps uniform manner, since differ determining whether take thebranch. jump instruction proceeds fetch decode much like theprevious instructions, except require register speciﬁer byte. Inthe execute stage, check condition codes jump condition deter-mine whether take branch, yielding 1-bit signal Cnd. PC update stage, test ﬂag, set PC valC (the jump target) ﬂag 1, valP (the address following instruction) ﬂag 0. notation x?a:bis similar conditional expression C—it yields awhen x nonzero bwhen xis zero. Stage jXX Dest call Dest ret Fetch icode :ifun←M1[PC] icode :ifun←M1[PC] icode :ifun←M1[PC] valC←M4[PC+1] valC←M4[PC+1] valP←PC+5 valP←PC+5 valP←PC+1 Decode valA←R[%esp ] valB←R[%esp ] valB←R[%esp ] Execute valE←valB+(−4) valE←valB+4 Cnd←Cond(CC,ifun) Memory M4[valE]←valP valM ←M4[valA] Write back R[%esp ]←valE R [%esp ]←valE PC update PC←Cnd ?valC :valP PC ←valC PC ←valM Figure 4.21 Computations sequential implementation Y86 instructions jXX, call , ret.These instructions cause control transfers.Section 4.3 Sequential Y86 Implementations 373 Aside Tracing execution jeinstruction Let us trace processing jeinstruction line 8 object code shown Figure 4.17. condition codes set zero subl instruction (line 3), branch taken. instruction located address 0x01e consists 5 bytes. ﬁrst value 0x73 , remaining 4 byte-reversed version number 0x00000028 , jump target. stages would proceed follows: Generic Speciﬁc Stage jXX Dest je 0x028 Fetch icode :ifun←M1[PC] icode :ifun←M1[0x01e ]=7:3 valC←M4[PC+1] valC←M4[0x01f ]=0x028 valP←PC+5 valP←0x01e +5=0x023 Decode Execute Cnd←Cond(CC,ifun) Cnd←Cond(/angbracketleft0,0,0/angbracketright,3)=0 Memory Write back PC update PC←Cnd ?valC :valP PC ←0?0x028 :0x023 =0x023 trace shows, instruction effect incrementing PC 5. Practice Problem 4.15 see instruction encodings (Figures 4.2 4.3) rmmovl instruction unconditional version general class instructionsthat include conditional moves. Show would modify steps rrmovl instruction also handle six conditional move instructions. may ﬁnd useful see implementation jXX instructions (Figure 4.21) handles conditional behavior. Stage cmovXX rA,rB Fetch icode :ifun←M1[PC] rA:rB←M1[PC+1] valP←PC+2 Decode valA←R[rA] Execute valE←0+valA Memory Write back R[rB]←valE PC update PC←valP374 Chapter 4 Processor Architecture Instructions call andretbear similarity instructions pushl andpopl , except push pop program counter values. instruction call ,w e push valP, address instruction follows call instruction. PC update stage, set PC valC , call destination. instruction ret, assign valM , value popped stack, PC PC update stage. Practice Problem 4.16 Fill right-hand column following table describe processing thecall instruction line 9 object code Figure 4.17: Generic Speciﬁc Stage call Dest call 0x029 Fetch icode :ifun←M1[PC] valC←M4[PC+1] valP←PC+5 Decode valB←R[%esp ] Execute valE←valB+(−4) Memory M4[valE]←valP Write back R[%esp ]←valE PC update PC←valC effect would instruction execution registers, PC, memory? created uniform framework handles different types Y86 instructions. Even though instructions widely varying behavior, wecan organize processing six stages. task create hardwaredesign implements stages connects together. Aside Tracing execution ret instruction Let us trace processing retinstruction line 13 object code shown Figure 4.17. instruction address 0x029 encoded single byte 0x90 . previous call instruction set%esp 124 stored return address 0x028 memory address 124. stages would proceed follows:Section 4.3 Sequential Y86 Implementations 375 Generic Speciﬁc Stage ret ret Fetch icode :ifun←M1[PC] icode :ifun←M1[0x029 ]=9:0 valP←PC+1 valP←0x029 +1=0x02a Decode valA←R[%esp ] valA←R[%esp ]=124 valB←R[%esp ] valB←R[%esp ]=124 Execute valE←valB+4 valE←124+4=128 Memory valM←M4[valA] valM←M4[124]=0x028 Write back R[%esp ]←valE R [%esp ]←128 PC update PC←valM PC ←0x028 trace shows, instruction effect setting PC 0x028 , address halt instruction. also sets %esp 128. 4.3.2 SEQ Hardware Structure computations required implement Y86 instructions orga- nized series six basic stages: fetch, decode, execute, memory, write back,and PC update. Figure 4.22 shows abstract view hardware structure canperform computations. program counter stored register, shownin lower left-hand corner (labeled “PC”). Information ﬂows along wires(shown grouped together heavy black line), ﬁrst upward around tothe right. Processing performed hardware units associated different stages. feedback paths coming back right-hand side contain theupdated values write register ﬁle updated program counter. InSEQ, processing hardware units occurs within single clock cycle,as discussed Section 4.3.3. diagram omits small blocks combi-national logic well control logic needed operate differenthardware units route appropriate values units. add thisdetail later. method drawing processors ﬂow going bottomto top unconventional. explain reason convention westart designing pipelined processors. hardware units associated different processing stages: Fetch: Using program counter register address, instruction memory reads bytes instruction. PC incrementer computesvalP, incremented program counter.376 Chapter 4 Processor Architecture Figure 4.22 Abstract view SEQ,a sequential implemen-tation. information processed exe- cution instruction follows clockwise ﬂowstarting instructionfetch using program counter (PC), shown lower left-hand corner ofthe ﬁgure. ABM EPC Write back Memory ExecutenewPC valE, valM valM Data memory Addr, Data valE CCALUCnd aluA, aluB valA, valB srcA, srcB dstE, dstM Register file valPDecode icode, ifun rA, rB valC FetchInstruction memoryPC increment PCSection 4.3 Sequential Y86 Implementations 377 Decode: register ﬁle two read ports, B, via register values valA valB read simultaneously. Execute: execute stage uses arithmetic/logic (ALU) unit different purposes according instruction type. integer operations, itperforms speciﬁed operation. instructions, serves asan adder compute incremented decremented stack pointer, tocompute effective address, simply pass one inputs itsoutputs adding zero. condition code register (CC) holds three condition-code bits. New values condition codes computed ALU. Whenexecuting jump instruction, branch signal Cnd computed based condition codes jump type. Memory: data memory reads writes word memory executing memory instruction. instruction data memories access samememory locations, different purposes. Write back: register ﬁle two write ports. Port E used write values computed ALU, port used write values read fromthe data memory. Figure 4.23 gives detailed view hardware required implement SEQ (although see complete details examine individualstages). see set hardware units earlier, wires areshown explicitly. ﬁgure, well hardware diagrams, usethe following drawing conventions: .Hardware units shown light blue boxes. include memories, ALU, forth. use basic set units ourprocessor implementations. treat units “black boxes” notgo detailed designs. .Control logic blocks drawn gray rounded rectangles. blocks serve select among set signal sources, compute Boolean func-tion. examine blocks complete detail, including developingHCL descriptions. .Wire names indicated white round boxes. simply labels wires, kind hardware element. .Word-wide data connections shown medium lines. lines actually represents bundle 32 wires, connected parallel, transferringa word one part hardware another. .Byte narrower data connections shown thin lines. lines actually represents bundle four eight wires, depending type ofvalues must carried wires. .Single-bit connections shown dotted lines. represent control values passed units blocks chip. computations shown Figures 4.18 4.21 property line represents either computation speciﬁc value, such378 Chapter 4 Processor Architecture statPC Memory Execute Decode FetchnewPC New PC data outdmem_error read writeData memory Addr DataMem. control Cnd valEvalMStat CC ALUALU fun. ALU AALU B valA valB dstE dstM srcA srcB dstE dstM srcA srcB Register File Write backAB EM icodeinstr_valid imem_errorifun rA rB valC valP PC incrementInstruction memory PC Figure 4.23 Hardware structure SEQ, sequential implementation. control signals, well register control word connections, shown.Section 4.3 Sequential Y86 Implementations 379 Stage Computation OPl rA,rB mrmovl D(rB),rA Fetch icode ,ifun icode :ifun←M1[PC] icode :ifun←M1[PC] rA,rB rA :rB←M1[PC+1] rA:rB←M1[PC+1] valC valC ←M4[PC+2] valP valP ←PC+2 valP←PC+6 Decode valA,srcA valA ←R[rA] valB,srcB valB ←R[rB] valB←R[rB] Execute valE valE ←valB OP valA valE ←valB+valC Cond. codes Set CC Memory read/write valM←M4[valE] Write back E port, dstE R [rB]←valE port, dstM R [rA]←valM PC update PC PC ←valP PC ←valP Figure 4.24 Identifying different computation steps sequential imple- mentation. second column identiﬁes value computed operation performed stages SEQ. computations instructions OPl andmrmovl shown examples computations. asvalP, activation hardware unit, memory. com- putations actions listed second column Figure 4.24. additionto signals already described, list includes four register ID signals:srcA, source valA;srcB, source valB;dstE, register valE gets written; dstM , register valM gets written. two right-hand columns ﬁgure show computations OPlandmrmovl instructions illustrate values computed. map computations hardware, want implement control logic transferthe data different hardware units operate units waythat speciﬁed operations performed different instructiontypes. purpose control logic blocks, shown gray rounded boxesin Figure 4.23. task proceed individual stages create detailed designs blocks. 4.3.3 SEQ Timing introducing tables Figures 4.18 4.21, stated read written programming notation, assignmentsperformed sequence top bottom. hand, hardwarestructure Figure 4.23 operates fundamentally different way, single clock transition triggering ﬂow combinational logic execute entire380 Chapter 4 Processor Architecture instruction. Let us see hardware implement behavior listed tables. implementation SEQ consists combinational logic two forms memory devices: clocked registers (the program counter condition coderegister) random-access memories (the register ﬁle, instruction memory,and data memory). Combinational logic require sequencing control—values propagate network logic gates whenever inputschange. described, also assume reading random- access memory operates much like combinational logic, output wordgenerated based address input. reasonable assumption smallermemories (such register ﬁle), mimic effect larger circuitsusing special clock circuits. Since instruction memory used readinstructions, therefore treat unit combinational logic. left four hardware units require explicit control sequencing—the program counter, condition code register, datamemory, register ﬁle. controlled via single clock signal triggers loading new values registers writing values therandom-access memories. program counter loaded new instructionaddress every clock cycle. condition code register loaded aninteger operation instruction executed. data memory written whenanrmmovl ,pushl ,o rcall instruction executed. two write ports register ﬁle allow two program registers updated every cycle, canuse special register ID 0xFas port address indicate write performed port. clocking registers memories required control sequencing activities processor. hardware achieves sameeffect would sequential execution assignments shown tablesof Figures 4.18 4.21, even though state updates actually occursimultaneously clock rises start next cycle. equivalenceholds nature Y86 instruction set, haveorganized computations way design obeys followingprinciple: processor never needs read back state updated instruction order complete processing instruction. principle crucial success implementation. illustration, suppose implemented pushl instruction ﬁrst decrementing %esp 4 using updated value %esp address write operation. approach would violate principle stated above. would require reading updated stack pointer register ﬁle order perform memoryoperation. Instead, implementation (Figure 4.20) generates decrementedvalue stack pointer signal valE uses signal data register write address memory write. result, itcan perform register memory writes simultaneously clock rises tobegin next clock cycle.Section 4.3 Sequential Y86 Implementations 381 another illustration principle, see instructions (the integer operations) set condition codes, instructions (the jumpinstructions) read condition codes, instruction must set thenread condition codes. Even though condition codes set theclock rises begin next clock cycle, updated instructionattempts read them. Figure 4.25 shows SEQ hardware would process instructions lines 3 4 following code sequence, shown assembly code theinstruction addresses listed left: 1 0x000: irmovl $0x100,%ebx # %ebx <-- 0x100 2 0x006: irmovl $0x200,%edx # %edx <-- 0x200 3 0x00c: addl %edx,%ebx # %ebx <-- 0x300 CC <-- 000 4 0x00e: je dest # taken 5 0x013: rmmovl %ebx,0(%edx) # M[0x200] <-- 0x300 6 0x019: dest: halt diagrams labeled 1 4 shows four state elements plus combinational logic connections among state elements. show combinational logic wrapped around condition code register,because combinational logic (such ALU) generates input condition code register, parts (such branch computationand PC selection logic) condition code register input. show theregister ﬁle data memory separate connections reading andwriting, since read operations propagate units werecombinational logic, write operations controlled clock. color coding Figure 4.25 indicates circuit signals relate different instructions executed. assume processing starts thecondition codes, listed order ZF,SF, OF, set 100. beginning clock cycle 3 (point 1), state elements hold state updated second irmovl instruction (line 2 listing), shown light gray. combinational logic shown white, indicating yet time react thechanged state. clock cycle begins address 0x00c loaded program counter. causes addl instruction (line 3 listing), shown blue, fetched processed. Values ﬂow combinational logic, includingthe reading random-access memories. end cycle (point 2),the combinational logic generated new values ( 000) condition codes, update program register %ebx , new value ( 0x00e ) program counter. point, combinational logic updated according theaddl instruction (shown blue), state still holds values set second irmovl instruction (shown light gray). clock rises begin cycle 4 (point 3), updates program counter, register ﬁle, condition code register occur, showthese blue, combinational logic yet reacted changes, andso show white. cycle, jeinstruction (line 4 listing), shown dark gray, fetched executed. Since condition code ZFis 0, branch not382 Chapter 4 Processor Architecture ClockCycle 1 Cycle 1: Cycle 2: Cycle 3: Cycle 4: Cycle 5: Beginning cycle 3 End cycle 3Cycle 2 Cycle 3 Cycle 4 1 12 234 0x000: irmovl $0x100,%ebx # %ebx <-- 0x100 0x006: irmovl $0x200,%edx # %edx <-- 0x2000x00c: addl %edx,%ebx # %ebx <-- 0x300 CC <-- 0000x00e: je dest # taken0x013: rmmov1 %ebx,0(%edx) # M[0x200] <-- 0x300 Combinational Logic Read Read PortsWrite Data memoryCombinational LogicRead Read PortsWrite PortsWrite %ebx 0x300 Beginning cycle 4 End cycle 43 4 Combinational Logic CC 000Read Read PortsWrite PortsWrite Combinational Logic CC 000Read Read PortsWrite PortsWrite000 0x00e 0x013Write Ports Register file %ebx /H110050x100 PC 0x00cCC 100 PC 0x00eCC 100 PC 0x00cRegister file %ebx /H110050x100Data memory Data memory Register file %ebx /H110050x300 PC 0x00eRegister file %ebx /H110050x300Data memory Figure 4.25 Tracing two cycles execution SEQ. cycle begins state elements (program counter, condition code register, register ﬁle, data memory)set according previous instruction. Signals propagate combinationallogic creating new values state elements. values loaded state elements start next cycle.Section 4.3 Sequential Y86 Implementations 383 taken. end cycle (point 4), new value 0x013 generated program counter. combinational logic updated according tothejeinstruction (shown dark gray), state still holds values set theaddl instruction (shown blue) next cycle begins. example illustrates, use clock control updating state elements, combined propagation values combinationallogic, sufﬁces control computations performed instruction ourimplementation SEQ. Every time clock transitions low high, theprocessor begins executing new instruction. 4.3.4 SEQ Stage Implementations section, devise HCL descriptions control logic blocks required implement SEQ. complete HCL description SEQ given Web Asidearch:hcl . show example blocks here, others given practice problems. recommend work practice problems way check understanding blocks relate computational requirements different instructions. Part HCL description SEQ include deﬁnition different integer Boolean signals used arguments theHCL operations. include names different hardware signals, aswell constant values different instruction codes, function codes, registernames, ALU operations, status codes. must explicitlyreferenced control logic shown. constants use documentedin Figure 4.26. convention, use uppercase names constant values. addition instructions shown Figures 4.18 4.21, include processing nop andhalt instructions. nop instruction simply ﬂows stages without much processing, except increment PC 1. Thehalt instruction causes processor status set HLT, causing halt operation. Fetch Stage shown Figure 4.27, fetch stage includes instruction memory hardwareunit. unit reads 6 bytes memory time, using PC address ofthe ﬁrst byte (byte 0). byte interpreted instruction byte split (bythe unit labeled “Split”) two 4-bit quantities. control logic blocks labeled“icode” “ifun” compute instruction function codes equalingeither values read memory or, event instruction addressis valid (as indicated signal imem_error ), values corresponding anopinstruction. Based value icode , compute three 1-bit signals (shown dashed lines): instr_valid : byte correspond legal Y86 instruction? signal used detect illegal instruction. need_regids : instruction include register speciﬁer byte? need_valC : instruction include constant word?384 Chapter 4 Processor Architecture Name Value (Hex) Meaning INOP 0 Code nopinstruction IHALT 1 Code halt instruction IRRMOVL 2 Code rrmovl instruction IIRMOVL 3 Code irmovl instruction IRMMOVL 4 Code rmmovl instruction IMRMOVL 5 Code mrmovl instruction IOPL 6 Code integer operation instructions IJXX 7 Code jump instructions ICALL 8 Code call instruction IRET 9 Code retinstruction IPUSHL Code pushl instruction IPOPL B Code popl instruction FNONE 0 Default function code RESP 4 Register ID %esp RNONE F Indicates register ﬁle access ALUADD 0 Function addition operation SAOK 1 Status code normal operation SADR 2 Status code address exception SINS 3 Status code illegal instruction exception SHLT 4 Status code halt Figure 4.26 Constant values used HCL descriptions. values represent encodings instructions, function codes, register IDs, ALU operations, status codes. signals instr_valid imem_error (generated instruction address bounds) used generate status code memory stage. example, HCL description need_regids simply determines whether value icode one instructions register speciﬁer byte: bool need_regids = icode { IRRMOVL, IOPL, IPUSHL, IPOPL, IIRMOVL, IRMMOVL, IMRMOVL }; Practice Problem 4.17 Write HCL code signal need_valC SEQ implementation.Section 4.3 Sequential Y86 Implementations 385 Figure 4.27 SEQ fetch stage. Six bytes read theinstruction memory usingthe PC startingaddress. bytes,we generate differentinstruction ﬁelds. PCincrement block computes signal valP.icode ifun rA rB valC valP Need valC Need regidsPC increment Align Bytes 1–5 Byte 0 imem_errorInstruction memory PCSplitInstr valid icode ifun Figure 4.27 shows, remaining 5 bytes read instruction memory encode combination register speciﬁer byte constant word.These bytes processed hardware unit labeled “Align” registerﬁelds constant word. computed signal need_regids 1, byte 1 split register speciﬁers rAand rB. Otherwise, two ﬁelds set 0xF(RNONE ), indicating registers speciﬁed instruction. Recall also (Figure 4.2) instruction one register operand, theother ﬁeld register speciﬁer byte 0xF(RNONE ). Thus, assume signals rAand rBeither encode registers want access indicate register access required. unit labeled “Align” also generates theconstant word valC . either bytes 1 4 bytes 2 5, depending value signal need_regids . PC incrementer hardware unit generates signal valP, based current value PC, two signals need_regids need_valC . PC value p,need_regids value r, need_valC value i, incrementer generates value p+1+r+4i. Decode Write-Back Stages Figure 4.28 provides detailed view logic implements decode write-back stages SEQ. two stages combined bothaccess register ﬁle. register ﬁle four ports. supports two simultaneous reads (on ports B) two simultaneous writes (on ports E M). port hasboth address connection data connection, address connectionis register ID, data connection set 32 wires serving either anoutput word (for read port) input word (for write port) register ﬁle. two read ports address inputs srcA srcB, two write386 Chapter 4 Processor Architecture valA Cnd valB valM valE Register fileA dstE dstM srcA srcB dstE dstM srcA srcB rA icode rBBM E Figure 4.28 SEQ decode write-back stage. instruction ﬁelds decoded generate register identiﬁers four addresses (two read two write) used theregister ﬁle. values read register ﬁle become signals valA valB. Thetwo write-back values valE valM serve data writes. ports address inputs dstE dstM . special identiﬁer 0xF(RNONE )o na n address port indicates register accessed. four blocks bottom Figure 4.28 generate four different register IDs register ﬁle, based instruction code icode , register speciﬁers rAand rB, possibly condition signal Cnd computed execute stage. Register ID srcA indicates register read generate valA. desired value depends instruction type, shown ﬁrst row thedecode stage Figures 4.18 4.21. Combining entries singlecomputation gives following HCL description srcA (recall RESP register ID %esp ): # Code SEQ int srcA = [ icode { IRRMOVL, IRMMOVL, IOPL, IPUSHL } : rA; icode { IPOPL, IRE } : RESP; 1 : RNONE; # Don’t need register ]; Practice Problem 4.18 register signal srcB indicates register read generate signal valB. desired value shown second step decode stage Figures 4.18 4.21. Write HCL code srcB. Register ID dstE indicates destination register write port E, computed value valE stored. shown Figures 4.18 4.21 ﬁrst step write-back stage. ignore moment conditional moveinstructions, combine destination registers differentinstructions give following HCL description dstE:Section 4.3 Sequential Y86 Implementations 387 # WARNING: Conditional move implemented correctly int dstE = [ icode { IRRMOV L}:r B ; icode { IIRMOVL, IOPL} : rB; icode { IPUSHL, IPOPL, ICALL, IRE } : RESP; 1 : RNONE; # Don’t write register ]; revisit signal implement conditional moves examine execute stage. Practice Problem 4.19 Register ID dstM indicates destination register write port M, valM , value read memory, stored. shown Figures 4.18 4.21 thesecond step write-back stage. Write HCL code dstM . Practice Problem 4.20 popl instruction uses register ﬁle write ports simultaneously. instruction popl %esp , address used E write ports, different data. handle conﬂict, must establish apriority among two write ports attempt write register cycle, write higher-priority port takes place.Which two ports given priority order implement desiredbehavior, determined Problem 4.7? Execute Stage execute stage includes arithmetic/logic unit (ALU). unit performs theoperation add,subtract ,and,o r Exclusive-Or inputs aluA aluB based setting alufun signal. data control signals generated three control blocks, diagrammed Figure 4.29. ALU output becomesthe signal valE. Figure 4.29 SEQ execute stage. ALU either performs operation integeroperation instruction orit acts adder. condition code registers set according theALU value. conditioncode values tested determine whether branch taken.Cnd valE cond CC Set CCALUALU fun. ALU BALU valC valA valB icode ifun388 Chapter 4 Processor Architecture Figures 4.18 4.21, ALU computation instruction shown ﬁrst step execute stage. operands listed aluB ﬁrst, followed byaluA make sure subl instruction subtracts valA valB. see value aluA valA,valC , either −4o r+4, depending instruction type. therefore express behavior control block thatgenerates aluA follows: int aluA = [ icode { IRRMOVL, IOP L } : valA; icode { IIRMOVL, IRMMOVL, IMRMOV L } : valC; icode { ICALL, IPUSH L}:- 4 ; icode { IRET, IPOP L}:4 ; # instructions don’t need ALU ]; Practice Problem 4.21 Based ﬁrst operand ﬁrst step execute stage Figures 4.18 4.21, write HCL description signal aluB SEQ. Looking operations performed ALU execute stage, see mostly used adder. OPlinstructions, however, want use operation encoded ifun ﬁeld instruction. therefore write HCL description ALU control follows: int alufun = [ icode == IOPL : ifun;1 : ALUADD; ]; execute stage also includes condition code register. ALU gen- erates three signals condition codes based—zero, sign, andoverﬂow—every time operates. However, want set conditioncodes OPlinstruction executed. therefore generate signal set_cc controls whether condition code register updated: bool set_cc = icode { IOPL }; hardware unit labeled “cond” uses combination condition codes function code determine whether conditional branch data transfershould take place (Figure 4.3). generates Cnd signal used setting ofdstE conditional moves, next PC logic conditional branches. instructions, Cnd signal may set either 1 0, depending instruction’s function code setting condition codes, willbe ignored control logic. omit detailed design unit.Section 4.3 Sequential Y86 Implementations 389 Figure 4.30 SEQ memory stage. data memory eitherwrite read memoryvalues. value read frommemory forms signalvalM. statStat valM data Mem. read Mem. writewritereaddmem_error imem_errorinstr_valid Mem. addrMem. data icode valE valA valPdata inData memory Practice Problem 4.22 conditional move instructions, abbreviated cmovXX , instruction code IRRMOVL . Figure 4.28 shows, implement instructions making use Cnd signal, generated execute stage. Modify HCL code dstE implement instructions. Memory Stage memory stage task either reading writing program data. shown Figure 4.30, two control blocks generate values memoryaddress memory input data (for write operations). Two blocks generate control signals indicating whether perform read write operation. read operation performed, data memory generates thevalue valM . desired memory operation instruction type shown memory stage Figures 4.18 4.21. Observe address memory readsand writes always valE orvalA. describe block HCL follows: int mem_addr = [ icode { IRMMOVL, IPUSHL, ICALL, IMRMOV L } : valE; icode { IPOPL, IRE } : valA; # instructions don’t need address ]; Practice Problem 4.23 Looking memory operations different instructions shown Fig- ures 4.18 4.21, see data memory writes always either valA orvalP. Write HCL code signal mem_data SEQ.390 Chapter 4 Processor Architecture want set control signal mem_read instructions read data memory, expressed following HCL code: bool mem_read = icode { IMRMOVL, IPOPL, IRET }; Practice Problem 4.24 want set control signal mem_write instructions write data memory. Write HCL code signal mem_write SEQ. ﬁnal function memory stage compute status code Stat result- ing instruction execution, according values icode ,imem_error , instr_valid generated fetch stage, signal dmem_error generated data memory. Practice Problem 4.25 Write HCL code Stat, generating four status codes SAOK ,SADR ,SINS , SHLT (see Figure 4.26). PC Update Stage ﬁnal stage SEQ generates new value program counter. (See Figure 4.31.) ﬁnal steps Figures 4.18 4.21 show, new PC bevalC ,valM ,o rvalP, depending instruction type whether branch taken. selection described HCL follows: int new_pc = [ # Call. Use instruction constanticode == ICALL : valC; # Taken branch. Use instruction constant icode == IJXX && Cnd : valC; # Completion RET instruction. Use value stack icode == IRET : valM; # Default: Use incremented PC 1 : valP; ]; Figure 4.31 SEQ PC update stage.The next value PC selected among signals valC, valM, andvalP, depending theinstruction code branch ﬂag.PC New PC icode Cnd valC valM valPSection 4.4 General Principles Pipelining 391 Surveying SEQ stepped complete design Y86 processor. seen organizing steps required execute different in-structions uniform ﬂow, implement entire processor smallnumber different hardware units single clock control sequenc-ing computations. control logic must route signals theseunits generate proper control signals based instruction types branch conditions. problem SEQ slow. clock must run slowly enough signals propagate stages within singlecycle. example, consider processing retinstruction. Starting updated program counter beginning clock cycle, instruction mustbe read instruction memory, stack pointer must read theregister ﬁle, ALU must decrement stack pointer, return addressmust read memory order determine next value theprogram counter. must completed end clock cycle. style implementation make good use hardware units, since unit active fraction total clock cycle. see achieve much better performance introducing pipelining. 4.4 General Principles Pipelining attempting design pipelined Y86 processor, let us consider somegeneral properties principles pipelined systems. systems familiarto anyone serving line cafeteria run car automated car wash. pipelined system, task performed dividedinto series discrete stages. cafeteria, involves supplying salad, amain dish, dessert, beverage. car wash, involves spraying water andsoap, scrubbing, applying wax, drying. Rather one customer runthrough entire sequence beginning end next begin,we allow multiple customers proceed system once. typicalcafeteria line, customers maintain order pipeline pass stages, even want courses. case car wash, new car allowed enter spraying stage preceding carmoves spraying stage scrubbing stage. general, cars mustmove system rate avoid one car crash thenext. key feature pipelining increases throughput system, is, number customers served per unit time, may also slightlyincrease latency , is, time required service individual customer. example, customer cafeteria wants salad could pass nonpipelined system quickly, stopping salad stage. customerin pipelined system attempts go directly salad stage risks incurringthe wrath customers.392 Chapter 4 Processor Architecture Figure 4.32 Unpipelined computationhardware. 320 ps cycle, systemspends 300 ps evaluating combinational logic function 20 ps storingthe results outputregister. (a) Hardware: Unpipelined (b) Pipeline diagram300 ps 20 ps Delay /H11005 320 ps Throughput /H11005 3.12 GIPSCombinational logicR eg Clock I1 I2I3 Time 4.4.1 Computational Pipelines Shifting focus computational pipelines, “customers” instructions stages perform portion instruction execution. Figure 4.32 showsan example simple nonpipelined hardware system. consists logicthat performs computation, followed register hold results thiscomputation. clock signal controls loading register regulartime interval. example system decoder compact disk (CD)player. incoming signals bits read surface CD, logic decodes generate audio signals. computational block ﬁgure implemented combinational logic, meaning signals passthrough series logic gates, outputs becoming function theinputs time delay. contemporary logic design, measure circuit delays units picosec- onds (abbreviated “ps”), 10 −12seconds. example, assume combi- national logic requires 300 picoseconds, loading register requires20 ps. Figure 4.32 also shows form timing diagram known pipeline dia- gram . diagram, time ﬂows left right. series instructions (here named I1,I2, andI3) written top bottom. solid rectangles indicate times instructions executed. implementation, wemust complete one instruction beginning next. Hence, boxes notoverlap one another vertically. following formula gives maximum rate could operate system: Throughput =1 instruction (20+300)picosecond.1000 picosecond 1 nanosecond≈3.12 GIPS express throughput units giga-instructions per second (abbreviated GIPS), billions instructions per second. total time required perform single instruction beginning end known latency . system, latency 320 ps, reciprocal throughput.Section 4.4 General Principles Pipelining 393 ClockComb. logic AR eg (a) Hardware: Three-stage pipeline100 ps 20 ps Comb. logic BR eg100 ps 20 ps Comb. logic CR eg100 ps 20 ps (b) Pipeline diagramTimeDelay /H11005 360 ps Throughput /H11005 8.33 GIPS I1 I2 I3ABC ABC ABC Figure 4.33 Three-stage pipelined computation hardware. computation split stages A, B, C. 120-ps cycle, instruction progresses one stage. Suppose could divide computation performed system three stages, A, B, C, requires 100 ps, illustrated Figure 4.33. Thenwe could put pipeline registers stages instruction moves system three steps, requiring three complete clock cycles frombeginning end. pipeline diagram Figure 4.33 illustrates, could allowI2to enter stage soon I1moves B, on. steady state, three stages would active, one instruction leaving new one enteringthe system every clock cycle. see third clock cycle thepipeline diagram I1is stage C, I2is stage B, I3is stage A. system, could cycle clocks every 100 +20=120 picoseconds, giving throughput around 8 .33 GIPS. Since processing single instruction requires 3 clock cycles, latency pipeline 3 ×120=360 ps. increased throughput system factor 8 .33/3.12=2.67 expense added hardware slight increase latency (360 /320=1.12). increased latency due time overhead added pipeline registers. 4.4.2 Detailed Look Pipeline Operation better understand pipelining works, let us look detail timing operation pipeline computations. Figure 4.34 shows pipeline diagramfor three-stage pipeline already looked (Figure 4.33). transferof instructions pipeline stages controlled clock signal, shown pipeline diagram. Every 120 ps, signal rises 0 1, initiating next set pipeline stage evaluations.394 Chapter 4 Processor Architecture Figure 4.34 Three-stage pipelinetiming. rising edge clock signal controls themovement instructions one pipeline stage next.Clock I1 I2 I3 120 0 240 360 Time480 600ABC ABC ABC Figure 4.35 traces circuit activity times 240 360, instruction I1(shown dark gray) propagates stage C, I2(shown blue) propa- gates stage B, I3(shown light gray) propagates stage A. rising clock time 240 (point 1), values computed stage Afor instruction I2have reached input ﬁrst pipeline register, state output remain set computed stage instruction I1.T h e values computed stage B instruction I1have reached input second pipeline register. clock rises, inputs loaded pipeline reg-isters, becoming register outputs (point 2). addition, input stage Ais set initiate computation instruction I3. signals propagate combinational logic different stages (point 3). curved wavefronts diagram point 3 suggest, signals propagate differ-ent sections different rates. time 360, result values reach inputs pipeline registers (point 4). clock rises time 360, theinstructions progressed one pipeline stage. see detailed view pipeline operation slowing clock would change pipeline behavior. signals propagate thepipeline register inputs, change register states occur theclock rises. hand, could disastrous effects clockwere run fast. values would time propagate combinational logic, register inputs would yet valid clock rises. discussion timing SEQ processor (Section 4.3.3), see simple mechanism clocked registers blocks ofcombinational logic sufﬁces control ﬂow instructions pipeline. Asthe clock rises falls repeatedly, different instructions ﬂow thestages pipeline without interfering one another. 4.4.3 Limitations Pipelining example Figure 4.33 shows ideal pipelined system able divide computation three independent stages, requiring one-thirdof time required original logic. Unfortunately, factors often arisethat diminish effectiveness pipelining.Section 4.4 General Principles Pipelining 395 Figure 4.35 One clock cycle pipelineoperation. clock rises time 240(point 1), instructions I1 (shown dark gray) I2(shown blue) completed stages B andA. clock rises, instructions begin propagating throughstages C B, whileinstruction I3(shown light gray) beginspropagating throughstage (points 2 3). clock rises again, resultsfor instructions havepropagated inputs pipeline registers (point 4).B AC B Clock Clock Clock ClockClock I1 I2I3 Time Time /H11005 239120 240 360 2 1 1 Time /H11005 241 2 Time /H11005 300 3 Time /H11005 359 434 Comb. logic AR eg100 ps 20 ps Comb. logic BR eg100 ps 20 ps Comb. logic CR eg100 ps 20 ps Comb. logic AR eg100 ps 20 ps Comb. logic BR eg100 ps 20 ps Comb. logic CR eg100 ps 20 ps Comb. logic AR eg100 ps 20 ps Comb. logic BR eg100 ps 20 ps Comb. logic CR eg100 ps 20 ps Comb. logic AR eg100 ps 20 ps Comb. logic BR eg100 ps 20 ps Comb. logic CR eg100 ps 20 ps Nonuniform Partitioning Figure 4.36 shows system divide computation three stages before, delays stages range 50 150 ps. sum ofthe delays stages remains 300 ps. However, rate we396 Chapter 4 Processor Architecture I1 I2I3AB C AB C AB C TimeClockComb. logic AR eg (a) Hardware: Three-stage pipeline, nonuniform stage delays50 ps 20 ps Comb. logic BR eg150 ps 20 ps Comb. logic CR eg100 ps 20 ps (b) Pipeline diagramDelay /H11005 510 ps Throughput /H11005 5.88 GIPS Figure 4.36 Limitations pipelining due nonuniform stage delays. system throughput limited speed slowest stage. operate clock limited delay slowest stage. pipeline diagram ﬁgure shows, stage idle (shown white box) 100 psevery clock cycle, stage C idle 50 ps every clock cycle. Onlystage B continuously active. must set clock cycle 150 +20=170 picoseconds, giving throughput 5 .88 GIPS. addition, latency would increase 510 ps due slower clock rate. Devising partitioning system computation series stages uniform delays major challenge hardware designers. Often, hardware units processor, ALU memories,cannot subdivided multiple units shorter delay. makes difﬁcultto create set balanced stages. concern level detail designing pipelined Y86 processor, important appreciatethe importance timing optimization actual system design. Practice Problem 4.26 Suppose analyze combinational logic Figure 4.32 determine itcan separated sequence six blocks, named F, delays 80,30, 60, 50, 70, 10 ps, respectively, illustrated follows: 80 ps 30 ps 60 ps 50 ps 70 ps 10 ps AE F C B D20 ps ClockR egSection 4.4 General Principles Pipelining 397 create pipelined versions design inserting pipeline registers pairs blocks. Different combinations pipeline depth (howmany stages) maximum throughput arise, depending insert thepipeline registers. Assume pipeline register delay 20 ps. A. Inserting single register gives two-stage pipeline. register inserted maximize throughput? would throughputand latency? B. two registers inserted maximize throughput three-stage pipeline? would throughput latency? C. three registers inserted maximize throughput four-stage pipeline? would throughput latency? D. minimum number stages would yield design maximum achievable throughput? Describe design, throughput, andits latency. Diminishing Returns Deep Pipelining Figure 4.37 illustrates another limitation pipelining. example, havedivided computation six stages, requiring 50 ps. Inserting pipelineregister pair stages yields six-stage pipeline. minimumclock period system 50 +20=70 picoseconds, giving throughput 14.29 GIPS. Thus, doubling number pipeline stages, improve performance factor 14 .29/8.33=1.71. Even though cut time required computation block factor 2, get doubling ofthe throughput, due delay pipeline registers. delay becomes limiting factor throughput pipeline. new design, delay consumes 28.6% total clock period. Modern processors employ deep (15 stages) pipelines attempt maximize processor clock rate. processor architects divide theinstruction execution large number simple steps stagecan small delay. circuit designers carefully design pipelineregisters minimize delay. chip designers must also carefully design Comb. logicComb. logicComb. logicComb. logicComb. logicComb. logic50 ps R eg50 ps 20 ps 20 ps 20 ps 20 ps 20 ps 20 ps 50 ps R eg50 ps Delay = 420 ps, Throughput = 14.29 GIPS ClockR eg50 ps R eg50 ps R egR eg Figure 4.37 Limitations pipelining due overhead. combinational logic split shorter blocks, delay due register updating becomes limiting factor.398 Chapter 4 Processor Architecture clock distribution network ensure clock changes exact time across entire chip. factors contribute challenge designinghigh-speed microprocessors. Practice Problem 4.27 Suppose could take system Figure 4.32 divide arbitrarynumber pipeline stages k, delay 300 /k, pipeline register delay 20 ps. A. would latency throughput system, functions ofk? B. would ultimate limit throughput? 4.4.4 Pipelining System Feedback point, considered systems objects passing pipeline—whether cars, people, instructions—are completely in-dependent one another. system executes machine programs IA32 Y86, however, potential dependencies successiveinstructions. example, consider following Y86 instruction sequence: 1 irmovl $50, %eax 2 addl %eax , %ebx 3 mrmovl 100( %ebx ), %edx 1 irmovl $50,%eax 2 addl %eax,%ebx 3 mrmovl 100(%ebx),%edx three-instruction sequence, data dependency succes- sive pair instructions, indicated circled register names arrowsbetween them. irmovl instruction (line 1) stores result %eax , must read addl instruction (line 2); instruction stores result in%ebx , must read mrmovl instruction (line 3). Another source sequential dependencies occurs due instruction control ﬂow. Consider following Y86 instruction sequence: 1loop: 2 subl %edx,%ebx 3 jne targ 4 irmovl $10,%edx 5 jmp loop 6targ: 7 haltSection 4.4 General Principles Pipelining 399 Figure 4.38 Limitations pipeliningdue logical depen-dencies. going unpipelined system feedback (a) pipelined one (c), change itscomputational behavior,as seen two pipeline diagrams (b d). TimeClockTime(a) Hardware: Unpipelined feedback (b) Pipeline diagram (d) Pipeline diagram(c) Hardware: Three-stage pipeline feedbackCombinational logicR eg Clock Comb. logic AR egComb. logic BR egComb. logic CR eg I1 I2 I3I1 I2 I3 ABC ABC ABC I4 ABC Thejneinstruction (line 3) creates control dependency since outcome conditional test determines whether next instruction execute betheirmovl instruction (line 4) halt instruction (line 7). design SEQ, dependencies handled feedback paths shown right-hand side Figure 4.22. feedback brings updated register values register ﬁle new PC value PC register. Figure 4.38 illustrates perils introducing pipelining system con- taining feedback paths. original system (Figure 4.38(a)), result eachinstruction fed back around next instruction. illustrated thepipeline diagram (Figure 4.38(b)), result I1becomes input to400 Chapter 4 Processor Architecture I2, on. attempt convert three-stage pipeline straightforward manner (Figure 4.38(c)), change behavior system.As Figure 4.38(c) shows, result I1becomes input I4. attempting speed system via pipelining, changed system behavior. introduce pipelining Y86 processor, must deal feed- back effects properly. Clearly, would unacceptable alter system be-havior occurred example Figure 4.38. Somehow must deal thedata control dependencies instructions resulting behaviormatches model deﬁned ISA. 4.5 Pipelined Y86 Implementations ﬁnally ready major task chapter—designing pipelined Y86processor. start making small adaptation sequential processor SEQto shift computation PC fetch stage. add pipelineregisters stages. ﬁrst attempt handle dif-ferent data control dependencies properly. making modiﬁcations,however, achieve goal efﬁcient pipelined processor implementsthe Y86 ISA. 4.5.1 SEQ+: Rearranging Computation Stages transitional step toward pipelined design, must slightly rearrange order ﬁve stages SEQ PC update stage comes beginningof clock cycle, rather end. transformation requires onlyminimal change overall hardware structure, work better withthe sequencing activities within pipeline stages. refer modiﬁeddesign “SEQ+.” move PC update stage logic active beginning clock cycle making compute PC value current instruction. Figure 4.39 shows SEQ SEQ+ differ PC computation. SEQ (Figure 4.39(a)), PC computation takes place end clockcycle, computing new value PC register based values signals PC New PC icode Cnd valC (a) SEQ new PC computation (b) SEQ /H11001 PC selectionvalM valPPC PC plcode pValC pValM Cnd pValP Figure 4.39 Shifting timing PC computation. SEQ+, compute value program counter current state ﬁrst step instructionexecution.Section 4.5 Pipelined Y86 Implementations 401 computed current clock cycle. SEQ+ (Figure 4.39(b)), create state registers hold signals computed instruction. Then, anew clock cycle begins, values propagate exact logic tocompute PC now-current instruction. label registers “pIcode,”“pCnd,” on, indicate given cycle, hold control signalsgenerated previous cycle. Figure 4.40 shows detailed view SEQ+ hardware. see contains exact hardware units control blocks inSEQ (Figure 4.23), PC logic shifted top, activeat end clock cycle, bottom, active beginning. Aside PC SEQ+? One curious feature SEQ+ hardware register storing program counter. Instead, PC computed dynamically based state information stored previous instruction. small illustration fact implement processor way differs conceptual model implied ISA, long processor correctly executes arbitrary machine-language programs. need encode state form indicated programmer-visible state, long processor generate correct values part programmer-visible state (such program counter). exploit principle even creating pipelined design. Out-of-order processing techniques, described Section 5.7, take idea extreme executinginstructions completely different order occur machine-level program. shift state elements SEQ SEQ+ example general transformation known circuit retiming [65]. Retiming changes state repre- sentation system without changing logical behavior. often used tobalance delays different stages system. 4.5.2 Inserting Pipeline Registers ﬁrst attempt creating pipelined Y86 processor, insert pipeline registers stages SEQ+ rearrange signals somewhat, yieldingthe PIPE– processor, “–” name signiﬁes processor hassomewhat less performance ultimate processor design. structure ofPIPE– illustrated Figure 4.41. pipeline registers shown ﬁgure black boxes, containing different ﬁelds shown white boxes. Asindicated multiple ﬁelds, pipeline register holds multiple bytes words. Unlike labels shown rounded boxes hardware structure thetwo sequential processors (Figures 4.23 4.40), white boxes representactual hardware components. Observe PIPE– uses nearly set hardware units sequen- tial design SEQ (Figure 4.40), pipeline registers separating stages.The differences signals two systems discussed Section 4.5.3.402 Chapter 4 Processor Architecture Memory Execute Decode Fetch PCvalM data read writeData memory Addr DataMem. control Cnd valE CC ALUALU fun. ALU AALU B valA valB dstE dstM srcA srcB dstE dstM srcA srcB Register file Write backAB EM icode ifun rA rB valC valP PC incrementInstruction memory PC PC plcode pValC pValM pCnd pValPstat dmem_errorStat instr_valid imem_error Figure 4.40 SEQ+ hardware structure. Shifting PC computation end clock cycle beginning makes suitable pipelining.Section 4.5 Pipelined Y86 Implementations 403 Stat stat valA statstatWrite back W icode valE valM dstE dstM ALU AALU BALU fun.M icode Cnd valE valA dstE dstM E icode ifun valC valA valB dstM srcA srcB dstE icode statstatstat ifun valC valP rB rA F predPCdata data M_Cnd e_CndMemory ALU Execute dstE dstM srcA srcB Select Predict PC Select PCd_srcA d_rvalAd_srcB W_valMM_valA W_valE M_valAf_pcf_statD_statE_statM_statm_statW_stat imem_error instr_valid W_valMCC Decode Fetchreaddmem_error write AddrMem. control Register fileAB EM PC incrementInstruction memorydstEData memorystat Figure 4.41 Hardware structure PIPE–, initial pipelined implementation. inserting pipeline registers SEQ+ (Figure 4.40), create ﬁve-stage pipeline. several shortcomings version deal shortly.404 Chapter 4 Processor Architecture pipeline registers labeled follows: Fholds predicted value program counter, discussed shortly. Dsits fetch decode stages. holds information recently fetched instruction processing decode stage. Esits decode execute stages. holds information recently decoded instruction values read registerﬁle processing execute stage. Msits execute memory stages. holds results recently executed instruction processing memory stage.It also holds information branch conditions branch targets forprocessing conditional jumps. Wsits memory stage feedback paths supply computed results register ﬁle writing return addressto PC selection logic completing retinstruction. Figure 4.42 shows following code sequence would ﬂow ﬁve-stage pipeline, comments identify instructions I1toI5for reference: 1 irmovl $1,%eax # I1 2 irmovl $2,%ebx # I2 3 irmovl $3,%ecx # I3 4 irmovl $4,%edx # I4 5 halt # I5 right side ﬁgure shows pipeline diagram instruction sequence. pipeline diagrams simple pipelined computationunits Section 4.4, diagram shows progression instruction throughthe pipeline stages, time increasing left right. numbers along thetop identify clock cycles different stages occur. example, incycle 1, instruction I1is fetched, proceeds pipeline stages, result written register ﬁle end cycle 5. InstructionI2is fetched cycle 2, result written back end cycle 6, on. bottom, show expanded view pipeline cycle 5. Atthis point, instruction pipeline stages. Figure 4.42, also justify convention drawing processors instructions ﬂow bottom top. expanded view cycle 5shows pipeline stages fetch stage bottom write-back stage top, diagrams pipeline hardware (Figure 4.41). look ordering instructions pipeline stages, see theyappear order program listing. Since normal programﬂow goes top bottom listing, preserve ordering thepipeline ﬂow go bottom top. convention particularly useful whenworking simulators accompany text.Section 4.5 Pipelined Y86 Implementations 405 irmovl $1,%eax #Il irmovl $2,%ebx #I2 irmovl $3,%ecx #I3 irmovl $4,%edx #I4 halt #I5FDEM W12345 FDEM W6 FDEM W7 FDEM W8 FDEM W9 Cycle 5 W Il I2 E I3 I4 F I5 Figure 4.42 Example instruction ﬂow pipeline. 4.5.3 Rearranging Relabeling Signals sequential implementations SEQ SEQ+ process one instruction time, unique values signals valC ,srcA, valE.I n pipelined design, multiple versions values associatedwith different instructions ﬂowing system. example, thedetailed structure PIPE–, four white boxes labeled “stat” holdthe status codes four different instructions. (See Figure 4.41.) need takegreat care make sure use proper version signal, else couldhave serious errors, storing result computed one instruction thedestination register speciﬁed another instruction. adopt naming schemewhere signal stored pipeline register uniquely identiﬁed preﬁxingits name pipe register written uppercase. example, fourstatus codes named D_stat ,E_stat ,M_stat , W_stat . also need refer signals computed within stage. labeled preﬁxing signal name ﬁrst character stage name, writtenin lowercase. Using status codes examples, see control logic blockslabeled “stat” fetch memory stages. outputs blocks aretherefore named f_stat m_stat . also see actual status overall processor Stat computed block write-back stage, based status value pipeline register W.406 Chapter 4 Processor Architecture Aside difference signals M_stat m_stat? naming system, uppercase preﬁxes “D,” “E,” “M,” “W” refer pipeline registers , M_stat refers status code ﬁeld pipeline register M. lowercase preﬁxes “f,” “d,” “e,” “m,” “w” refer pipeline stages , m_stat refers status signal generated memory stage control logic block. Understanding naming convention critical understanding operation pipelined processors. decode stages SEQ+ PIPE– generate signals dstE dstM indicating destination register values valE valM . SEQ+, could connect signals directly address inputs register ﬁle write ports.With PIPE–, signals carried along pipeline execute andmemory stages, directed register ﬁle reach write-back stage (shown detailed views stages). makesure write port address data inputs hold values instruction.Otherwise, write back would writing values instruction thewrite-back stage, register IDs instruction decode stage.As general principle, want keep information particularinstruction contained within single pipeline stage. One block PIPE– present SEQ+ exact form block labeled “Select A” decode stage. see block generatesthe value valA pipeline register E choosing either valP pipeline register value read port register ﬁle. block isincluded reduce amount state must carried forward pipelineregisters E M. different instructions, call requires valP memory stage. jump instructions require value valP execute stage (in event jump taken). None instructionsrequires value read register ﬁle. Therefore, reduce amountof pipeline register state merging two signals carrying throughthe pipeline single signal valA. eliminates need block labeled “Data” SEQ (Figure 4.23) SEQ+ (Figure 4.40), served similarpurpose. hardware design, common carefully identify signals getused reduce amount register state wiring merging signalssuch these. shown Figure 4.41, pipeline registers include ﬁeld status code Stat, initially computed fetch stage possibly modiﬁed memory stage. discuss implement processing exceptionalevents Section 4.5.9, covered implementation normal in-struction execution. Sufﬁce say point systematic approachis associate status code instruction passes pipeline,as indicated ﬁgure. 4.5.4 Next PC Prediction taken measures design PIPE– properly handle control dependencies. goal pipelined design issue new instruction onSection 4.5 Pipelined Y86 Implementations 407 every clock cycle, meaning clock cycle, new instruction proceeds execute stage ultimately completed. Achieving goal wouldyield throughput one instruction per cycle. this, must determinethe location next instruction right fetching current instruction.Unfortunately, fetched instruction conditional branch, notknow whether branch taken several cycles later, afterthe instruction passed execute stage. Similarly, fetchedinstruction ret, cannot determine return location instruction passed memory stage. exception conditional jump instructions ret, deter- mine address next instruction based information computed duringthe fetch stage. call andjmp(unconditional jump), valC , con- stant word instruction, others valP, address next instruction. therefore achieve goal issuing new instructionevery clock cycle cases predicting next value PC. in- struction types, prediction completely reliable. conditional jumps,we predict either jump taken, new PC value would bevalC , predict taken, new PC value would bevalP. either case, must somehow deal case prediction incorrect therefore fetched partially executed wronginstructions. return matter Section 4.5.11. technique guessing branch direction initiating fetching instructions according guess known branch prediction . used form virtually processors. Extensive experiments conducted effective strategies predicting whether branches taken [49,Section 2.3]. systems devote large amounts hardware task. ourdesign, use simple strategy predicting conditional branches arealways taken, predict new value PC valC . Aside branch prediction strategies design uses always taken branch prediction strategy. Studies show strategy around 60% success rate [47, 120]. Conversely, never taken (NT) strategy around 40% success rate. slightly sophisticated strategy, known backward taken, forward not-taken (BTFNT), predicts branches lower addresses next instruction taken, higher addresses taken. strategy success rate around 65%. improvement stems fact loops closed backward branches, loops generally executed multiple times. Forward branches used conditional operations, less likely taken. Problems 4.54 4.55, modify Y86 pipeline processor implement NT BTFNT branch prediction strategies. saw Section 3.6.6, mispredicted branches degrade performance program considerably, thus motivating use conditional data transfer rather conditional control transfer possible. still left predicting new PC value resulting ret in- struction. Unlike conditional jumps, nearly unbounded set possible408 Chapter 4 Processor Architecture results, since return address whatever word top stack. design, attempt predict value return address.Instead, simply hold processing instructions ret instruction passes write-back stage. return part theimplementation Section 4.5.11. Aside Return address prediction stack programs, easy predict return addresses, since procedure calls returns occur matched pairs. time procedure called, returns instruction following thecall. property exploited high-performance processors including hardware stack withinthe instruction fetch unit holds return address generated procedure call instructions. Every time procedure call instruction executed, return address pushed onto stack. return instruction fetched, top value popped stack used predicted return address. Like branch prediction, mechanism must provided recover prediction incorrect, since times calls returns match. general, prediction highly reliable.This hardware stack part programmer-visible state. PIPE– fetch stage, diagrammed bottom Figure 4.41, responsi- ble predicting next value PC selecting actual PC instruction fetch. see block labeled “Predict PC” choose eithervalP, computed PC incrementer valC , fetched instruction. value stored pipeline register F predicted value program counter. block labeled “Select PC” similar block labeled “PC” theSEQ+ PC selection stage (Figure 4.40). chooses one three values serve asthe address instruction memory: predicted PC, value valP not-taken branch instruction reaches pipeline register (stored regis-terM_valA ), value return address ret instruction reaches pipeline register W (stored W_valM ). return handling jump return instructions complete pipeline control logic Section 4.5.11. 4.5.5 Pipeline Hazards structure PIPE– good start creating pipelined Y86 processor. Recall discussion Section 4.4.4, however, introducing pipelining system feedback lead problems dependencies successive instructions. must resolve issue complete ourdesign. dependencies take two forms: (1) data dependencies, results computed one instruction used data following instruction,and (2) control dependencies, one instruction determines location following instruction, executing jump, call, return. Whensuch dependencies potential cause erroneous computation thepipeline, called hazards . Like dependencies, hazards classiﬁed either data hazards orcontrol hazards . section, concern ourselvesSection 4.5 Pipelined Y86 Implementations 409 F 0x000: irmovl $10,%edx# progl# progl 0x006: irmovl $3,%eax 0x00c: nop0x00d: nop0x00e: nop0x00f: addl %edx,%eax0x011: haltDEM W FDEM W FDEM W FDEM W FDEM W FDEM W FDEM W Cycle 6 Cycle 712345 6 7 8 91 01 1 W DR[%eax ] 3 valA R[ %edx ]/H11005 10 valB R[ %eax ]/H11005 3 Figure 4.43 Pipelined execution prog1 without special pipeline control. cycle 6, second irmovl writes result program register %eax . Theaddl instruction reads source operands cycle 7, gets correct values %edx and%eax . data hazards. Control hazards discussed part overall pipeline control (Section 4.5.11). Figure 4.43 illustrates processing sequence instructions refer asprog1 PIPE– processor. Let us assume example successive ones program registers initially value 0. code loads values10 3 program registers %edx and%eax , executes three nop instructions, adds register %edx to%eax . focus attention potential data hazards resulting data dependencies two irmovl instructions addl instruction. right-hand side ﬁgure, show pipeline diagram instruction sequence. pipeline stages cycles 6 7 areshown highlighted pipeline diagram. this, show expanded viewof write-back activity cycle 6 decode activity cycle 7. Afterthe start cycle 7, irmovl instructions passed write- back stage, register ﬁle holds updated values %edx and%eax . addl instruction passes decode stage cycle 7, therefore read correct values source operands. data dependenciesbetween two irmovl instructions addl instruction created data hazards example.410 Chapter 4 Processor Architecture valA R[ %edx ]/H11005 10 valB R[ %eax ]/H11005 0F 0x000: irmovl $10,%edx# prog2# prog2 0x006: irmovl $3,%eax 0x00c: nop 0x00d: nop 0x00e: addl %edx,%eax 0x010: haltDEM W FDEM W FDEM W FDEM W FDEM W FDEM W Cycle 612345 6 7 8 91 0 W R[%eax ] 3 Error . . . Figure 4.44 Pipelined execution prog2 without special pipeline control. write program register %eax occur start cycle 7, addl instruction gets incorrect value register decode stage. saw prog1 ﬂow pipeline get correct results, three nopinstructions create delay instructions data dependencies. Let us see happens nop instructions removed. Figure 4.44 illustrates pipeline ﬂow program, named prog2 , containing twonop instructions two irmovl instructions generating values registers %edx and%eax , addl instruction two registers operands. case, crucial step occurs cycle 6, addl instruc- tion reads operands register ﬁle. expanded view pipelineactivities cycle shown bottom ﬁgure. ﬁrst irmovl instruction passed write-back stage, program register %edx updated register ﬁle. second irmovl instruction write- back stage cycle, write program register %eax occurs start cycle 7 clock rises. result, incorrect value zero would read register %eax (recall assume registers initially 0), since pending write register yet occurred. Clearly toadapt pipeline handle hazard properly. Figure 4.45 shows happens one nop instruction irmovl instructions addl instruction, yielding programSection 4.5 Pipelined Y86 Implementations 411 M_valE /H11005 3 M_dstE /H11005 %eax valA R[ %edx ]/H11005 0 valB R[ %eax ]/H11005 0F 0x000: irmovl $10,%edx# prog3# prog3 0x006: irmovl $3,%eax 0x00c: nop 0x00d: addl %edx,%eax 0x00f: haltDEM W FDEM W FDEM W FDEM W FDEM W Cycle 512345 6 7 8 9 W R[%edx ] 10 Error . . . Figure 4.45 Pipelined execution prog3 without special pipeline control. cycle 5, theaddl instruction reads source operands register ﬁle. pending write register %edx still write-back stage, pending write register %eax still memory stage. operands valA valB get incorrect values. prog3 . must examine behavior pipeline cycle 5 addl instruction passes decode stage. Unfortunately, pending write register %edx still write-back stage, pending write %eax still memory stage. Therefore, addl instruction would get incorrect values operands. Figure 4.46 shows happens remove nopinstructions irmovl instructions addl instruction, yielding program prog4 . must examine behavior pipeline cycle 4 addl instruction passes decode stage. Unfortunately, pending write register %edx still memory stage, new value %eax computed execute stage. Therefore, addl instruction would get incorrect values operands. examples illustrate data hazard arise instruction one operands updated three preceding instructions.These hazards occur pipelined processor reads operands an412 Chapter 4 Processor Architecture e_valE 0 /H11001 3/H11005 3 E_dstE /H11005 %eaxM_valE /H11005 10 M_dstE /H11005 %edx valA R[ %edx ]/H11005 0 valB R[ %eax ]/H11005 0F 0x000: irmovl $10,%edx# prog4# prog4 0x006: irmovl $3,%eax 0x00c: addl %edx,%eax 0x00e: haltDEM W FDEM W FDEM W FDEM W Cycle 412345 6 7 8 E Error Figure 4.46 Pipelined execution prog4 without special pipeline control. cycle 4, theaddl instruction reads source operands register ﬁle. pending write register %edx still memory stage, new value register %eax computed execute stage. operands valA valB get incorrect values. instruction register ﬁle decode stage write results instruction register ﬁle three cycles later, instructionpasses write-back stage. Aside Enumerating classes data hazards Hazards potentially occur one instruction updates part program state read later instruction. Y86, program state includes program registers, program counter,the memory, condition code register, status register. Let us look hazard possibilities proposed design forms state. Program registers: hazards already identiﬁed. arise register ﬁle read one stage written another, leading possible unintended interactionsbetween different instructions. Program counter: Conﬂicts updating reading program counter give rise control hazards. hazard arises fetch-stage logic correctly predicts new value program counter fetching next instruction. Mispredicted branches ret instructions require special handling, discussed Section 4.5.11.Section 4.5 Pipelined Y86 Implementations 413 Memory: Writes reads data memory occur memory stage. time instruction reading memory reaches stage, preceding instructions writing memory already done so. hand, interference instructions writing data memory stage reading instructions fetch stage, since instruction data memories reference single address space. happen programs containing self-modifying code , instructions write portion memory instructions later fetched. systems complex mechanisms detect avoid hazards, others simply mandate programs use self-modifying code. assume simplicity programs modify themselves, andtherefore need take special measures update instruction memory based updates data memory program execution. Condition code register: written integer operations execute stage. read conditional moves execute stage conditional jumps memory stage. time conditional move jump reaches execute stage, preceding integer operation already completed stage. hazards arise. Status register: program status affected instructions ﬂow pipeline. mechanism associating status code instruction pipeline enablesthe processor come orderly halt exception occurs, discussed Section 4.5.9. analysis shows need deal register data hazards, control hazards, making sure exceptions handled properly. systematic analysis form important whendesigning complex system. identify potential difﬁculties implementing system, guide generation test programs used checking correctness system. 4.5.6 Avoiding Data Hazards Stalling One general technique avoiding hazards involves stalling , processor holds back one instructions pipeline hazardcondition longer holds. processor avoid data hazards holding backan instruction decode stage instructions generating sourceoperands passed write-back stage. details mechanismwill discussed Section 4.5.11. involves simple enhancements pipelinecontrol logic. effect stalling diagrammed Figures 4.47 ( prog2 ) 4.48 (prog4 ). (We omit prog3 discussion, since operates similarly two examples.) addl instruction decode stage, pipeline control logic detects least one instructions execute, memory,or write-back stage update either register %edx register %eax . Rather letting addl instruction pass stage incorrect results, stalls instruction, holding back decode stage either one (for prog2 )o r three (for prog4 ) extra cycles. three programs, addl instruction ﬁnally gets correct values two source operands cycle 7 proceeds downthe pipeline.414 Chapter 4 Processor Architecture F 0x000: irmovl $10,%edx# prog2# prog2 0x006: irmovl $3,%eax 0x00c: nop0x00d: nop bubblebubble 0x00e: addl %edx,%eax0x010: haltDEM W FDEM W FDEM W FDEM W EMW FDDE W FFDE W M12345 6 7 8 91 01 1 Figure 4.47 Pipelined execution prog2 using stalls. decoding addl instruction cycle 6, stall control logic detects data hazard due pending write register %eax write-back stage. injects bubble execute stage repeats decoding addl instruction cycle 7. effect, machine dynamically inserted nop instruction, giving ﬂow similar shown prog1 (Figure 4.43). F 0x000: irmovl $10,%edx# prog4# prog4 0x006: irmovl $3,%eax bubblebubble bubblebubble bubblebubble 0x00c: addl %edx,%eax 0x00e: haltDEM W FDEM W EMW EMW EMW F F FDDE W FFDE W M12345 6 7 8 91 01 1 Figure 4.48 Pipelined execution prog4 using stalls. decoding addl instruction cycle 4, stall control logic detects data hazards source registers. injects bubble execute stage repeats decoding addl instruction cycle 5. detects hazards source registers, injects bubble execute stage, repeats decoding addl instruction cycle 6. Still, detects hazard source register %eax , injects bubble execute stage, repeats decoding addl instruction cycle 7. effect, machine dynamically inserted three nop instructions, giving ﬂow similar shown prog1 (Figure 4.43). holding back addl instruction decode stage, must also hold back halt instruction following fetch stage. keeping program counter ﬁxed value, halt instruction fetched repeatedly stall completed. Stalling involves holding back one group instructions stages allowing instructions continue ﬂowing pipeline. thenshould stages would normally processing addl instruction? handle injecting bubble execute stage time hold instruction back decode stage. bubble like dynamically generated nopinstruction—it cause changes registers, memory, condition codes, program status. shown white boxes thepipeline diagrams Figures 4.47 4.48. ﬁgures, arrow betweenthe box labeled “D” addl instruction box labeled “E” one ofSection 4.5 Pipelined Y86 Implementations 415 pipeline bubbles indicates bubble injected execute stage place addl instruction would normally passed decode execute stage. look detailed mechanisms making pipelinestall injecting bubbles Section 4.5.11. using stalling handle data hazards, effectively execute programs prog2 andprog4 dynamically generating pipeline ﬂow seen prog1 (Fig- ure 4.43). Injecting one bubble prog2 three prog4 effect three nopinstructions second irmovl instruction addl instruction. mechanism implemented fairly easily (see Problem 4.51),but resulting performance good. numerous cases whichone instruction updates register closely following instruction uses sameregister. cause pipeline stall three cycles, reducing theoverall throughput signiﬁcantly. 4.5.7 Avoiding Data Hazards Forwarding design PIPE– reads source operands register ﬁle decode stage, also pending write one source registers write-back stage. Rather stalling write completed, cansimply pass value written pipeline register E thesource operand. Figure 4.49 shows strategy expanded view the. . .0x000: irmovl $10,%edx# prog2# prog2 0x006: irmovl $3,%eax 0x00c: nop 0x00d: nop 0x00e: addl %edx,%eax0x010: halt srcA /H11005 %edx srcB /H11005 %eaxW_dstE /H11005 %eax W_valE /H11005 3 valA R[ %edx ]/H11005 10 valB W_valE /H11005 3MCycle 6 R[%eax ] 3F12345 6 7 8 91 0 FDEM W FDEM W FDEM W DEM W FDEM W FDEM W Figure 4.49 Pipelined execution prog2 using forwarding. cycle 6, decode- stage logic detects presence pending write register %eax write-back stage. uses value source operand valB rather value read register ﬁle.416 Chapter 4 Processor Architecture. . .F 0x000: irmovl $10,%edx# prog3# prog3 0x006: irmovl $3,%eax 0x00c: nop0x00d: addl %edx,%eax0x00f: haltDEM W FDEM W FDEM W FDEM W FDEM W12345 6 7 8 9 srcA /H11005 %edx srcB /H11005 %eaxW_dstE /H11005 %edx W_valE /H11005 10 valA W_valE /H11005 10 valB M_valE /H11005 3Cycle 5 R[%edx ] 10 DW M_dstE /H11005 %eax M_valE /H11005 3M Figure 4.50 Pipelined execution prog3 using forwarding. cycle 5, decode- stage logic detects pending write register %edx write-back stage register %eax memory stage. uses values valA valB rather values read register ﬁle. pipeline diagram cycle 6 prog2 . decode-stage logic detects register %eax source register operand valB, also pending write %eax write port E. therefore avoid stalling simply using data word supplied port E (signal W_valE ) value operand valB. technique passing result value directly one pipeline stage earlierone commonly known data forwarding (or simply forwarding , sometimes bypassing ). allows instructions prog2 proceed pipeline without stalling. Data forwarding requires adding additional data connectionsand control logic basic hardware structure. Figure 4.50 illustrates, data forwarding also used pending write register memory stage, avoiding need stall program prog3 . cycle 5, decode-stage logic detects pending write register %edx port E write-back stage, well pending write register %eax way port E still memory stage. Rather stalling writes occurred, use value write-back stage (signalW_valE ) operand valA value memory stage (signal M_valE ) operand valB.Section 4.5 Pipelined Y86 Implementations 417 F 0x000: irmovl $10,%edx# prog4# prog4 0x006: irmovl $3,%eax 0x00c: addl %edx,%eax0x00e: haltDEM W FDEM W FDEM W FDEM W12345 6 7 8 srcA /H11005 %edx srcB /H11005 %eaxM_dstE /H11005 %edx M_valE /H11005 10 valA M_valE /H11005 10 valB e_valE /H11005 3Cycle 4 DM E_dstE /H11005 %eax e_valE 0 /H11001 3/H11005 3E Figure 4.51 Pipelined execution prog4 using forwarding. cycle 4, decode- stage logic detects pending write register %edx memory stage. also detects new value computed register %eax execute stage. uses values valA valB rather values read register ﬁle. exploit data forwarding full extent, also pass newly computed values execute stage decode stage, avoiding need stall forprogram prog4 , illustrated Figure 4.51. cycle 4, decode-stage logic detects pending write register %edx memory stage, also value computed ALU execute stage later written toregister %eax . use value memory stage (signal M_valE ) operand valA. also use ALU output (signal e_valE ) operand valB. Note using ALU output introduce timing problems. decode stageonly needs generate signals valA valB end clock cycle pipeline register E loaded results decode stage theclock rises start next cycle. ALU output valid point. uses forwarding illustrated programs prog2 toprog4 involve forwarding values generated ALU destined write port E. Forwarding also used values read memory destined forwrite port M. memory stage, forward value beenread data memory (signal m_valM ). write-back stage, forward pending write port (signal W_valM ). gives total ﬁve different forwarding sources ( e_valE ,m_valM ,M_valE ,W_valM , W_valE ) two different forwarding destinations ( valA valB).418 Chapter 4 Processor Architecture expanded diagrams Figures 4.49 4.51 also show decode- stage logic determine whether use value register ﬁle usea forwarded value. Associated every value written back theregister ﬁle destination register ID. logic compare IDs withthe source register IDs srcA srcB detect case forwarding. possible multiple destination register IDs match one source IDs. mustestablish priority among different forwarding sources handle cases.This discussed look detailed design forwarding logic. Figure 4.52 shows structure PIPE, extension PIPE– handle data hazards forwarding. Comparing structure PIPE–(Figure 4.41), see values ﬁve forwarding sources fedback two blocks labeled “Sel+Fwd A” “Fwd B” decode stage.The block labeled “Sel+Fwd A” combines role block labeled “Select A”in PIPE– forwarding logic. allows valA pipeline register E either incremented program counter valP, value read port register ﬁle, one forwarded values. block labeled “Fwd B”implements forwarding logic source operand valB. 4.5.8 Load/Use Data Hazards One class data hazards cannot handled purely forwarding, mem- ory reads occur late pipeline. Figure 4.53 illustrates example load/use hazard , one instruction (the mrmovl address 0x018 ) reads value memory register %eax next instruction (the addl address 0x01e ) needs value source operand. Expanded views cycles 7 8 shownin lower part ﬁgure, assume program registers initially havevalue 0. addl instruction requires value register cycle 7, generated mrmovl instruction cycle 8. order “forward” themrmovl addl , forwarding logic would make value go backward time! Since clearly impossible, must ﬁnd mech-anism handling form data hazard. (The data hazard register %ebx , value generated irmovl instruction address 0x012 used addl instruction address 0x01e , handled forwarding.) Figure 4.54 demonstrates, avoid load/use data hazard combination stalling forwarding. requires modiﬁcations con-trol logic, use existing bypass paths. mrmovl instruction passes execute stage, pipeline control logic detects instruction decode stage (the addl ) requires result read memory. stalls instruction decode stage one cycle, causing bubble injected intothe execute stage. expanded view cycle 8 shows, value read frommemory forwarded memory stage addl instruction decode stage. value register %ebx also forwarded write- back memory stage. indicated pipeline diagram arrow fromthe box labeled “D” cycle 7 box labeled “E” cycle 8, injected bub-ble replaces addl instruction would normally continue ﬂowing pipeline.Section 4.5 Pipelined Y86 Implementations 419 valA Fwd BW icode valE valM dstE dstM ALU AALU BALU fun.M icode Cnd valE valA dstE dstM E icode ifun valC valA valB dstM srcA srcB dstE icode ifun valC valP rB rA F predPCdata data M_Cnddmem_errorm_stat M_valEm_valM e_CndMemory ALU Execute dstEdstE dstM srcA srcB Sel+Fwd Predict PC Select PCd_srcA d_srcB W_valMe_dstEM_valAW_valMW_valE W_valE M_valA W_valMCC Decode Fetchread writeData memory AddrMem. control Register fileAB EM PC incrementInstruction memory f_pcstatstat imem_error instr_validStat stat statWrite back statstatstat Figure 4.52 Hardware structure PIPE, ﬁnal pipelined implementation. additional bypassing paths enable forwarding results three preceding instructions. allows us handle formsof data hazards without stalling pipeline.420 Chapter 4 Processor Architecture M_dstE /H11005 %ebx M_valE /H11005 10M M_dstM /H11005 %eax m_valM M[128] /H11005 3MF 0x000: irmovl $128,%edx# prog5# prog5 0x006: irmovl $3,%ecx 0x00c: rmmovl %ecx, 0(%edx) 0x012: irmovl $10,%ebx0x018: mrmovl 0(%edx),%eax # Load %eax 0x01e: addl %ebx,%eax # Use %eax 0x020: haltDEM W FDEM W FDEM W FDEM W FDEM W FDEM W FDEM W12345 6 7 8 91 01 1 valA M_valE /H11005 10 valB R[ %eax ]/H11005 0Cycle 7 Cycle 8 Error . . . Figure 4.53 Example load/use data hazard. Theaddl instruction requires value register %eax decode stage cycle 7. preceding mrmovl reads new value register memory stage cycle 8, late addl instruction. use stall handle load/use hazard called load interlock . Load interlocks combined forwarding sufﬁce handle possible forms datahazards. Since load interlocks reduce pipeline throughput, nearlyachieve throughput goal issuing one new instruction every clock cycle. 4.5.9 Exception Handling discuss Chapter 8, variety activities processor lead toexceptional control ﬂow , normal chain program execution gets broken. Exceptions generated either internally , executing program, orexternally , outside signal. instruction set architecture includes three different internally generated exceptions, caused (1) halt instruction, (2) instruction invalid combination instruction function code,and (3) attempt access invalid address, either instruction fetch ordata read write. complete processor design would also handle externalexceptions, processor receives signal network interfacehas received new packet, user clicked mouse button. Handling exceptions correctly challenging aspect microprocessor design. canSection 4.5 Pipelined Y86 Implementations 421 W_dstE /H11005 %ebx W_valE /H11005 10W M_dstM /H11005 %eax m_valM M[128] /H11005 3MF 0x000: irmovl $128,%edx 0x006: irmovl $3,%ecx0x00c: rmmovl %ecx, 0(%edx)0x012: irmovl $10,%ebx0x018: mrmovl 0(%edx),%eax # Load %eax 0x01e: addl %ebx,%eax # Use %eax 0x020: halt# prog5 # prog5 DEM W FDEM W FDEM W FDEM W FDEM W EMW FD E W F FD E W12345 6 7 8 91 01 1 1 2 valA W_valE /H11005 10 valB m_valM /H11005 3Cycle 8. . .bubblebubble Figure 4.54 Handling load/use hazard stalling. stalling addl instruction one cycle decode stage, value valB forwarded mrmovl instruction memory stage addl instruction decode stage. occur unpredictable times, require creating clean break ﬂow instructions processor pipeline. handling three internalexceptions gives glimpse true complexity correctly detecting andhandling exceptions. Let us refer instruction causing exception excepting instruc- tion. case invalid instruction address, actual excepting instruction, useful think sort “virtual instruction”at invalid address. simpliﬁed ISA model, want processor haltwhen reaches exception set appropriate status code, listed Fig-ure 4.5. appear instructions excepting instruction havecompleted, none following instructions effect programmer-visible state. complete design, processor would con- tinue invoking exception handler , procedure part operating422 Chapter 4 Processor Architecture system, implementing part exception handling beyond scope presentation. pipelined system, exception handling involves several subtleties. First, possible exceptions triggered multiple instructions simultaneously. Forexample, one cycle pipeline operation, could halt instruction fetch stage, data memory could report out-of-bounds dataaddress instruction memory stage. must determine theseexceptions processor report operating system. basic rule toput priority exception triggered instruction furthest along thepipeline. example above, would out-of-bounds address attemptedby instruction memory stage. terms machine-language program,the instruction memory stage appear execute one thefetch stage, therefore exception reported operatingsystem. second subtlety occurs instruction ﬁrst fetched begins execution, causes exception, later canceled due mispredicted branch.The following example program object code form: 0x000: 6300 | xorl %eax,%eax 0x002: 740e000000 | jne Target # taken 0x007: 30f001000000 | irmovl $1, %eax # Fall through0x00d: 00 | halt0x00e: | Target:0x00e: ff | .byte 0xFF # Invalid instruction code program, pipeline predict branch taken, fetch attempt use byte value 0xFF instruction (generated assembly code using .byte directive). decode stage therefore detect invalid instruction exception. Later, pipeline discoverthat branch taken, instruction address 0x00e never even fetched. pipeline control logic cancel thisinstruction, want avoid raising exception. third subtlety arises pipelined processor updates different parts system state different stages. possible instruction followingone causing exception alter part state exceptinginstruction completes. example, consider following code sequence, inwhich assume user programs allowed access addresses greaterthan0xc0000000 (as case 32-bit versions Linux): 1 irmovl $1,%eax 2 xorl %esp,%esp # Set stack pointer 0 CC 100 3 pushl %eax # Attempt write 0xfffffffc 4 addl %eax,%eax # (Should executed) Would set CC 000 Thepushl instruction causes address exception, decrementing stack pointer causes wrap around 0xfffffffc . exception detected memory stage. cycle, addl instruction execute stage,Section 4.5 Pipelined Y86 Implementations 423 cause condition codes set new values. would violate requirement none instructions following excepting instructionshould effect system state. general, correctly choose among different exceptions avoid raising exceptions instructions fetched due mispredictedbranches merging exception-handling logic pipeline structure. Thatis motivation us include status code Statin pipeline registers (Figures 4.41 4.52). instruction generates exception stage inits processing, status ﬁeld set indicate nature exception. Theexception status propagates pipeline rest informationfor instruction, reaches write-back stage. point, pipelinecontrol logic detects occurrence exception stops execution. avoid updating programmer-visible state instructions beyond excepting instruction, pipeline control logic must disable anyupdating condition code register data memory instruction inthe memory write-back stages caused exception. example programabove, control logic would detect pushl memory stage caused exception, therefore updating condition code register bytheaddl instruction would disabled. Let us consider method handling exceptions deals sub- tleties mentioned. exception occurs one stages apipeline, information simply stored status ﬁelds pipeline reg-isters. event effect ﬂow instructions pipeline anexcepting instruction reaches ﬁnal pipeline stage, except disable updat-ing programmer-visible state (the condition code register memory)by later instructions pipeline. Since instructions reach write-back stagein order would executed nonpipelined processor, areguaranteed ﬁrst instruction encountering exception arrive ﬁrst inthe write-back stage, point program execution stop statuscode pipeline register W recorded program status. in-struction fetched later canceled, exception status information theinstruction gets canceled well. instruction following one causes ex- ception alter programmer-visible state. simple rule carrying exception status together information instruction throughthe pipeline provides simple reliable mechanism handling exceptions. 4.5.10 PIPE Stage Implementations created overall structure PIPE, pipelined Y86 processor forwarding. uses set hardware units earlier sequentialdesigns, addition pipeline registers, reconﬁgured logic blocks, andadditional pipeline control logic. section, go design thedifferent logic blocks, deferring design pipeline control logic nextsection. Many logic blocks identical counterparts SEQ andSEQ+, except must choose proper versions different signals thepipeline registers (written pipeline register name, written uppercase,424 Chapter 4 Processor Architecture preﬁx) stage computations (written ﬁrst character stage name, written lowercase, preﬁx). example, compare HCL code logic generates srcA signal SEQ corresponding code PIPE: # Code SEQ int srcA = [ icode { IRRMOVL, IRMMOVL, IOPL, IPUSHL } : rA;icode { IPOPL, IRE } : RESP; 1 : RNONE; # Don’t need register ]; # Code PIPE int d_srcA = [ D_icode { IRRMOVL, IRMMOVL, IOPL, IPUSHL } : D_rA; D_icode { IPOPL, IRE } : RESP; 1 : RNONE; # Don’t need register ]; differ preﬁxes added PIPE signals: “ D_” source values, indicate signals come pipeline register D, “ d_” result value, indicate generated decode stage. avoid repetition,we show HCL code blocks differ SEQbecause preﬁxes names. reference, complete HCL code forPIPE given Web Aside arch:hcl . PC Selection Fetch Stage Figure 4.55 provides detailed view PIPE fetch stage logic. discussed earlier, stage must also select current value program counter andpredict next PC value. hardware units reading instruction frommemory extracting different instruction ﬁelds thosewe considered SEQ (see fetch stage Section 4.3.4). PC selection logic chooses three program counter sources. mispredicted branch enters memory stage, value valP instruction (indicating address following instruction) read pipeline registerM (signal M_valA ). retinstruction enters write-back stage, return address read pipeline register W (signal W_valM ). cases use predicted value PC, stored pipeline register F (signal F_predPC ): int f_pc = [ # Mispredicted branch. Fetch incremented PC M_icode == IJXX && !M_Cnd : M_valA; # Completion RET instruction. W_icode == IRET : W_valM; # Default: Use predicted value PC 1 : F_predPC; ];Section 4.5 Pipelined Y86 Implementations 425 Need valC Need regidsPredict PC Select PCPC increment Align Bytes 1–5 f_pcByte 0 imem_errorInstruction memorySplitInstr validD icode stat ifun valC valP rB rA F predPCM_icode M_Bch M_valA W_icode W_valM icodestat ifun Figure 4.55 PIPE PC selection fetch logic. Within one cycle time limit, processor predict address next instruction. PC prediction logic chooses valC fetched instruction either call jump, valP otherwise: int f_predPC = [ f_icode { IJXX, ICAL L } : f_valC; 1 : f_valP; ]; logic blocks labeled “Instr valid,” “Need regids,” “Need valC” SEQ, appropriately named source signals. Unlike SEQ, must split computation instruction status two parts. fetch stage, test memory error due out-of-rangeinstruction address, detect illegal instruction halt instruction. Detecting invalid data address must deferred memory stage. Practice Problem 4.28 Write HCL code signal f_stat , providing provisional status fetched instruction.426 Chapter 4 Processor Architecture icode ifun valC valP rB rAAB srcA srcBdstM dstE ERegister filee_dstE e_valE d_rvalA d_rvalBE icode stat statifun valC valA valB Sel+Fwd AFwd BdstE dstM srcA srcB dstE dstM srcA srcBM_dstE M_valE M_dstM m_valM W_dstM W_valM W_dstE W_valE d_srcAd_srcB Figure 4.56 PIPE decode write-back stage logic. instruction requires valP value read register port A, two merged form signal valA later stages. block labeled“Sel+Fwd A” performs task also implements forwarding logic source operand valA. blocklabeled “Fwd B” implements forwarding logic source operand valB. register write locations speciﬁed dstE dstM signals write-back stage rather decode stage, since writing results instruction currently write-back stage. Decode Write-Back Stages Figure 4.56 gives detailed view decode write-back logic PIPE. blocks labeled “ dstE”, “dstM ”, “srcA”, “ srcB” similar coun- terparts implementation SEQ. Observe register IDs suppliedto write ports come write-back stage (signals W_dstE W_dstM ), rather decode stage. want writes occur tothe destination registers speciﬁed instruction write-back stage. Practice Problem 4.29 block labeled “dstE” decode stage generates register ID Eport register ﬁle, based ﬁelds fetched instruction pipelineSection 4.5 Pipelined Y86 Implementations 427 register D. resulting signal named d_dstE HCL description PIPE. Write HCL code signal, based HCL description SEQ signaldstE. (See decode stage SEQ Section 4.3.4.) concern logic implement conditional moves yet. complexity stage associated forwarding logic. mentioned earlier, block labeled “Sel+Fwd A” serves two roles. mergesthevalP signal valA signal later stages order reduce amount state pipeline register. also implements forwarding logic source operand valA. merging signals valA valP exploits fact call jump instructions need value valP later stages, instructions need value read port register ﬁle. selection iscontrolled icode signal stage. signal D_icode matches instruction code either call orjXX, block select D_valP output. mentioned Section 4.5.7, ﬁve different forwarding sources, data word destination register ID: Data word Register ID Source description e_valE e_dstE ALU output m_valM M_dstM Memory output M_valE M_dstE Pending write port E memory stage W_valM W_dstM Pending write port write-back stage W_valE W_dstE Pending write port E write-back stage none forwarding conditions hold, block select d_rvalA , value read register port output. Putting together, get following HCL description new value valA pipeline register E: int d_valA = [ D_icode { ICALL, IJX X } : D_valP; # Use incremented PC d_srcA == e_dstE : e_valE; # Forward valE executed_srcA == M_dstM : m_valM; # Forward valM memory d_srcA == M_dstE : M_valE; # Forward valE memory d_srcA == W_dstM : W_valM; # Forward valM write back d_srcA == W_dstE : W_valE; # Forward valE write back 1 : d_rvalA; # Use value read register file ]; priority given ﬁve forwarding sources HCL code important. priority determined HCL code order which428 Chapter 4 Processor Architecture WF 0x000: irmovl $10,%edx 0x006: irmovl $3,%edx0x00c: rrmovl %edx,%eax0x00e: halt# prog6 # prog6 DEM W FDEM W FDEM FDEM W12345 6 7 8 valA e_valE /H11005 3Cycle 4 M_dstE /H11005%edx M_valE /H11005 10 srcA /H11005 %edxM E_dstE /H11005%edx e_valE 0/H11001 3/H11005 3E Figure 4.57 Demonstration forwarding priority. cycle 4, values %edx available execute memory stages. forwarding logic choose one execute stage, since represents recently generated value register. ﬁve destination register IDs tested. order one shown chosen, pipeline would behave incorrectly programs. Figure4.57 shows example program requires correct setting priorityamong forwarding sources execute memory stages. program,the ﬁrst two instructions write register %edx , third uses register source operand. rrmovl instruction reaches decode stage cycle 4, forwarding logic must choose two values destined itssource register. one choose? set priority, must considerthe behavior machine-language program executed one instructionat time. ﬁrst irmovl instruction would set register %edx 10, second would set register 3, rrmovl instruction would read 3 %edx . imitate behavior, pipelined implementation always give priority forwarding source earliest pipeline stage, since holds latest instruction program sequence setting register. Thus, logic inthe HCL code ﬁrst tests forwarding source execute stage, thenthose memory stage, ﬁnally sources write-back stage. forwarding priority two sources either memory write-back stages concern instruction popl %esp , since instruction write two registers simultaneously.Section 4.5 Pipelined Y86 Implementations 429 Practice Problem 4.30 Suppose order third fourth cases (the two forwarding sources memory stage) HCL code d_valA reversed. Describe resulting behavior rrmovl instruction (line 5) following program: 1 irmovl $5, %edx 2 irmovl $0x100,%esp 3 rmmovl %edx,0(%esp) 4 popl %esp 5 rrmovl %esp,%eax Practice Problem 4.31 Suppose order ﬁfth sixth cases (the two forwarding sources write-back stage) HCL code d_valA reversed. Write Y86 program would executed incorrectly. Describe error would occur itseffect program behavior. Practice Problem 4.32 Write HCL code signal d_valB , giving value source operand valB supplied pipeline register E. One small part write-back stage remains. shown Figure 4.52, overall processor status Stat computed block based status value pipeline register W. Recall Section 4.1.1 code indicate eithernormal operation ( AOK) one three exception conditions. Since pipeline register W holds state recently completed instruction, natural use value indication overall processor status. specialcase consider bubble write-back stage. part ofnormal operation, want status code AOKfor case well: int Stat = [ W_stat == SBUB : SAOK; 1 : W_stat; ]; Execute Stage Figure 4.58 shows execute stage logic PIPE. hardware units logic blocks identical SEQ, appropriate renaming signals.We see signals e_valE e_dstE directed toward decode stage one forwarding sources. One difference logic labeled “Set CC,” determines whether update condition codes, signals m_stat and430 Chapter 4 Processor Architecture e_Cnd W_stat m_state_valE e_dstEM icode stat statCnd valE valA dstE dstM E icode ifun valC valA valB dstM srcA srcB dstEALU ASet CCALU BALU fun.ALU CCconddstE Figure 4.58 PIPE execute stage logic. part design similar logic SEQ implementation. W_stat inputs. signals used detect cases instruction causing exception passing later pipeline stages, therefore anyupdating condition codes suppressed. aspect design isdiscussed Section 4.5.11. Practice Problem 4.33 second case HCL code d_valA uses signal e_dstE see whether select ALU output e_valE forwarding source. Suppose instead use signal E_dstE , destination register ID pipeline register E selection. Write Y86 program would give incorrect result thismodiﬁed forwarding logic. Memory Stage Figure 4.59 shows memory stage logic PIPE. Comparing memorystage SEQ (Figure 4.30), see that, noted before, block labeled “Data”in SEQ present PIPE. block served select data sourcesvalP (forcall instructions) valA, selection performed block labeled “Sel+Fwd A” decode stage. blocks stageare identical counterparts SEQ, appropriate renaming thesignals. ﬁgure, also see many values pipeline registers W supplied parts circuit part forwarding pipeline control logic.Section 4.5 Pipelined Y86 Implementations 431 Stat stat M_icode M_CndW_icode W_dstM m_valM M_dstE M_dstM M_valA M_valEW_dstEW_valMW_valE W icode valE valM dstE dstM icodestat stat Cnd valE valA dstE dstMdata data inreadm_stat dmem_error writeData memory Addrstat Mem. read Mem. write Figure 4.59 PIPE memory stage logic. Many signals pipeline registers W passed earlier stages provide write-back results, instruction addresses, forwarded results. Practice Problem 4.34 stage, complete computation status code Stat detecting case invalid address data memory. Write HCL code signalm_stat . 4.5.11 Pipeline Control Logic ready complete design PIPE creating pipeline control logic. logic must handle following four control cases othermechanisms, data forwarding branch prediction, sufﬁce: Processing ret:The pipeline must stall ret instruction reaches write-back stage. Load/use hazards: pipeline must stall one cycle instruction reads value memory instruction uses value. Mispredicted branches: time branch logic detects jump taken, several instructions branch target havestarted pipeline. instructions must removed thepipeline. Exceptions: instruction causes exception, want disable updating programmer-visible state later instructions haltexecution excepting instruction reaches write-back stage. go desired actions cases develop control logic handle them.432 Chapter 4 Processor Architecture Desired Handling Special Control Cases ret instruction, consider following example program. program shown assembly code, addresses different instructions onthe left reference: 0x000: irmovl Stack,%esp # Initialize stack pointer 0x006: call Proc # procedure call 0x00b: irmovl $10,%edx # return point 0x011: halt0x020: .pos 0x200x020: Proc: # Proc:0x020: ret # return immediately 0x021: rrmovl %edx,%ebx # executed 0x030: .pos 0x30 0x030: Stack: # Stack: Stack pointer Figure 4.60 shows want pipeline process ret instruction. earlier pipeline diagrams, ﬁgure shows pipeline activity withtime growing right. Unlike before, instructions listed thesame order occur program, since program involves control ﬂowwhere instructions executed linear sequence. Look instructionaddresses see different instructions come program. diagram shows, ret instruction fetched cycle 3 proceeds pipeline, reaching write-back stage cycle 7. itpasses decode, execute, memory stages, pipeline cannot doany useful activity. Instead, want inject three bubbles pipeline. Oncetheretinstruction reaches write-back stage, PC selection logic set program counter return address, therefore fetch stage fetch theirmovl instruction return point (address 0x00b ). FDEM W FDEM W FD EMW F DEM W FDEM W FDEM W FDEM W0x000: irmovl Stack,%edx 0x006: call proc0x020: ret 0x00b: irmovl $10,%edx # Return pointbubblebubble bubblebubble bubblebubble# prog7# prog7 12345 6 7 8 91 01 1 Figure 4.60 Simpliﬁed view ret instruction processing. pipeline stall ret passes decode, execute, memory stages, injecting three bubbles process. PC selectionlogic choose return address instruction fetch address ret reaches write-back stage (cycle 7).Section 4.5 Pipelined Y86 Implementations 433 FDEM W FDEM W FD EMW F DEM W F FEM W FDEM W0x000: irmovl Stack,%edx 0x006: call proc0x020: ret0x021: rrmovl %edx,%ebx # executed 0x021: rrmovl %edx,%ebx # executed 0x021: rrmovl %edx,%ebx # executed 0x00b: irmovl $10,%edx # Return pointbubblebubble bubblebubble bubblebubble# prog7# prog7 12345 6 7 8 91 01 1 DEM W Figure 4.61 Actual processing ret instruction. fetch stage repeatedly fetches rrmovl instruction following ret instruction, pipeline control logic injects bubble decode stage rather allowing rrmovl instruction proceed. resulting behavior equivalent shown Figure 4.60. Figure 4.61 shows actual processing retinstruction example program. key observation way inject bubble thefetch stage pipeline. every cycle, fetch stage reads instruction instruction memory. Looking HCL code implementing PCprediction logic Section 4.5.10, see retinstruction new value PC predicted valP, address following instruction. example program, would 0x021 , address rrmovl instruction following ret. prediction correct example, would cases, attempting predict return addresses correctlyin design. three clock cycles, fetch stage stalls, causing rrmovl instruction fetched replaced bubble decode stage. Thisprocess illustrated Figure 4.61 three fetches, arrow leadingdown bubbles passing remaining pipeline stages. Finally, theirmovl instruction fetched cycle 7. Comparing Figure 4.61 Figure 4.60, see implementation achieves desired effect, slightly peculiar fetching incorrect instruction 3 consecutive cycles. load/use hazard, already described desired pipeline opera- tion Section 4.5.8, illustrated example Figure 4.54. mrmovl andpopl instructions read data memory. either ex- ecute stage, instruction requiring destination register decodestage, want hold back second instruction decode stage injecta bubble execute stage next cycle. this, forwarding logicwill resolve data hazard. pipeline hold back instruction de-code stage keeping pipeline register ﬁxed state. so, alsokeep pipeline register F ﬁxed state, next instruction fetcheda second time. summary, implementing pipeline ﬂow requires detecting the434 Chapter 4 Processor Architecture FDEM W FDEM W FD EMW F DEM W FDEM W FDEM W0x000: xorl %eax,%eax 0x002: jne target # taken 0x00e: irmovl $2,%edx # Target 0x014: irmovl $3,%ebx # Target /H110011 0x007: irmovl $1,%eax # Fall 0x00d: halt# prog8 12345 6 7 8 91 0 bubblebubble bubblebubble Figure 4.62 Processing mispredicted branch instructions. pipeline predicts branches taken starts fetching instructions jump target. Two instructions fetched misprediction detected cycle 4 jump instruction ﬂows execute stage. cycle 5, pipeline cancels two target instructions injecting bubbles decode execute stages, alsofetches instruction following jump. hazard condition, keeping pipeline register F ﬁxed, injecting bubble execute stage. handle mispredicted branch, consider following program, shown assembly code, instruction addresses shown left reference: 0x000: xorl %eax,%eax 0x002: jne target # taken 0x007: irmovl $1, %eax # Fall through0x00d: halt 0x00e: target:0x00e: irmovl $2, %edx # Target0x014: irmovl $3, %ebx # Target+10x01a: halt Figure 4.62 shows instructions processed. before, instruc- tions listed order enter pipeline, rather order occurin program. Since jump instruction predicted taken, instruc-tion jump target fetched cycle 3, instruction following thisone fetched cycle 4. time branch logic detects jumpshould taken cycle 4, two instructions fetched shouldnot continue executed. Fortunately, neither instructions causeda change programmer-visible state. occur instructionreaches execute stage, cause condition codes change. Wecan simply cancel (sometimes called instruction squashing ) two misfetched in- structions injecting bubbles decode execute instructions thefollowing cycle also fetching instruction following jump instruction.The two misfetched instructions simply disappear pipeline. discuss Section 4.5.11, simple extension basic clocked registerSection 4.5 Pipelined Y86 Implementations 435 design enable us inject bubbles pipeline registers part pipeline control logic. instruction causes exception, must make pipelined im- plementation match desired ISA behavior, prior instructions complet-ing none following instructions effect programstate. Achieving effects complicated facts (1) exceptions detected two different stages (fetch memory) program execution,and (2) program state updated three different stages (execute, memory, write-back). stage designs include status code statin pipeline register track status instruction passes pipeline stages. anexception occurs, record information part instruction’s statusand continue fetching, decoding, executing instructions nothing wereamiss. excepting instruction reaches memory stage, take steps pre- vent later instructions modifying programmer-visible state (1) disablingthe setting condition codes instructions execute stage, (2) injecting bubbles memory stage disable writing data memory, and(3) stalling write-back stage excepting instruction, thus bringingthe pipeline halt. pipeline diagram Figure 4.63 illustrates pipeline control han- dles situation instruction causing exception followed one thatwould change condition codes. cycle 6, pushl instruction reaches memory stage generates memory error. cycle, addl instruc- tion execute stage generates new values condition codes. disable FDEM W FDEM W FD E FD E FD EMWWW W0x000: irmovl $1,%eax 0x006: xorl %esp,%esp #CC = 1000x008: pushl %eax0x00a: addl %eax,%eax0x00c: irmovl $2,%eax# prog10 # prog10 12345 6 7 8 91 0 . . . Cycle 6 mem_error /H110051set_cc ← 0M New CC /H11005 000E Figure 4.63 Processing invalid memory reference exception. cycle 6, invalid memory reference thepushl instruction causes updating condition codes disabled. pipeline starts injecting bubbles memory stage stalling excepting instruction write-back stage.436 Chapter 4 Processor Architecture Condition Trigger Processing ret IRET∈{Dicode,Eicode,Micode} Load/use hazard Eicode ∈{IMRMOVL ,IPOPL }&&EdstM∈{dsrcA,dsrcB} Mispredicted branch Eicode =IJXX&& ! eCnd Exception mstat∈{SADR,SINS,SHLT}||Wstat∈{SADR,SINS,SHLT} Figure 4.64 Detection conditions pipeline control logic. Four different conditions require altering pipeline ﬂow either stalling pipeline canceling partially executed instructions. setting condition codes excepting instruction memory write-back stage (by examining signals m_stat W_stat setting signal set_cc zero). also see combination injecting bubbles memory stage stalling excepting instruction write-back stagein example Figure 4.63—the pushl instruction remains stalled write- back stage, none subsequent instructions get past execute stage. combination pipelining status signals, controlling setting condition codes, controlling pipeline stages, achieve desired behav-ior exceptions: instructions prior excepting instruction completed,while none following instructions effect programmer-visiblestate. Detecting Special Control Conditions Figure 4.64 summarizes conditions requiring special pipeline control. givesexpressions describing conditions three special cases arise.These expressions implemented simple blocks combinational logic thatmust generate results end clock cycle order controlthe action pipeline registers clock rises start next cycle. Duringa clock cycle, pipeline registers D, E, hold states instructionsthat decode, execute, memory pipeline stages, respectively. Aswe approach end clock cycle, signals d_srcA d_srcB set register IDs source operands instruction decode stage.Detecting ret instruction passes pipeline simply involves checking instruction codes instructions decode, execute, andmemory stages. Detecting load/use hazard involves checking instructiontype ( mrmovl orpopl ) instruction execute stage comparing destination register source registers instruction decode stage.The pipeline control logic detect mispredicted branch jumpinstruction execute stage, set conditions required torecover misprediction instruction enters memory stage. ajump instruction execute stage, signal e_Cnd indicates whether jump taken. detect excepting instruction examining theinstruction status values memory write-back stages. memorystage, use signal m_stat , computed within stage, rather M_statSection 4.5 Pipelined Y86 Implementations 437 x x xn opxState /H11005 x (a) NormalState /H11005 Input /H11005 stall /H11005 0bubble /H11005 0Output /H11005 x Output /H11005 Rising clock State /H11005 x (b) StallState /H11005 x Input /H11005 stall /H11005 1bubble /H11005 0Output /H11005 x Output /H11005 x Rising clock State /H11005 x (c) BubbleState /H11005nop Input /H11005 stall /H11005 0bubble /H11005 1Output /H11005 x Output /H11005nop Rising clock Figure 4.65 Additional pipeline register operations. (a) normal conditions, state output register set value input clock rises.(b) operated stall mode, state held ﬁxed previous value. (c) operated bubble mode, state overwritten nop operation. pipeline register. internal signal incorporates possibility data memory address error. Pipeline Control Mechanisms Figure 4.65 shows low-level mechanisms allow pipeline control logic tohold back instruction pipeline register inject bubble pipeline.These mechanisms involve small extensions basic clocked register describedin Section 4.2.5. Suppose pipeline register two control inputs stall bubble . settings signals determine pipeline register updated clock rises. normal operation (Figure 4.65(a)), inputs set 0, causing register load input new state. Whenthestall signal set 1 (Figure 4.65(b)), updating state disabled. Instead, register remain previous state. makes possible to438 Chapter 4 Processor Architecture Pipeline register Condition F E W Processing ret stall bubble normal normal normal Load/use hazard stall stall bubble normal normalMispredicted branch normal bubble bubble normal normal Figure 4.66 Actions pipeline control logic. different conditions require altering pipeline ﬂow either stalling pipeline canceling partially executedinstructions. hold back instruction pipeline stage. bubble signal set 1 (Figure 4.65(c)), state register set ﬁxed reset conﬁguration giving state equivalent nopinstruction. particular pattern ones zeros pipeline register’s reset conﬁguration depends set ﬁeldsin pipeline register. example, inject bubble pipeline register D, wewant icode ﬁeld set constant value INOP (Figure 4.26). inject bubble pipeline register E, want icode ﬁeld set INOP thedstE,dstM ,srcA, srcB ﬁelds set constant RNONE . Determining reset conﬁguration one tasks hardware designer designinga pipeline register. concern details here. willconsider error set bubble stall signals 1. table Figure 4.66 shows actions different pipeline stages take three special conditions. involves combination ofnormal, stall, bubble operations pipeline registers. terms timing, stall bubble control signals pipeline registers generated blocks combinational logic. values must valid theclock rises, causing pipeline registers either load, stall, bubbleas next clock cycle begins. small extension pipeline registerdesigns, implement complete pipeline, including control, usingthe basic building blocks combinational logic, clocked registers, random-access memories. Combinations Control Conditions discussion special pipeline control conditions far, assumed thatat one special case could arise single clock cycle. common bug indesigning system fail handle instances multiple special conditionsarise simultaneously. Let us analyze possibilities. need worry aboutcombinations involving program exceptions, since carefully designedour exception-handling mechanism consider instructions pipeline.Figure 4.67 diagrams pipeline states cause three special controlconditions. diagrams show blocks decode, execute, memorystages. shaded boxes represent particular constraints must satisﬁedfor condition arise. load/use hazard requires instruction theSection 4.5 Pipelined Y86 Implementations 439 Figure 4.67 Pipeline states specialcontrol conditions. two pairs indicated canarise simultaneously.Load/use MMispredict ret 1ret 2ret 3 E DM EJXX Load ret Use bubbleret bubblebubbleret DM Combination Combination DM E DM E execute stage reads value memory register, instruction decode stage register source operand. mispredicted branch requires instruction execute stage jump instruction. three possible cases ret—the instruction either decode, execute, memory stage. retinstruction moves pipeline, earlier pipeline stages bubbles. see diagrams control conditions mutually exclusive. example, possible load/use hazard mispre-dicted branch simultaneously, since one requires load instruction ( mrmovl popl ) execute stage, requires jump. Similarly, second third retcombinations cannot occur time load/use hazard mispredicted branch. two combinations indicated arrows arisesimultaneously. Combination involves not-taken jump instruction execute stage aretinstruction decode stage. Setting combination requires ret target not-taken branch. pipeline control logic detectthat branch mispredicted therefore cancel retinstruction. Practice Problem 4.35 Write Y86 assembly-language program causes combination arise determines whether control logic handles correctly. Combining control actions combination conditions (Figure 4.66), get following pipeline control actions (assuming either bubble astall overrides normal case): Pipeline register Condition F E W Processing ret stall bubble normal normal normal Mispredicted branch normal bubble bubble normal normal Combination stall bubble bubble normal normal is, would handled like mispredicted branch, stall fetch stage. Fortunately, next cycle, PC selection logic choose theaddress instruction following jump, rather predicted program440 Chapter 4 Processor Architecture counter, matter happens pipeline register F. conclude pipeline correctly handle combination. Combination B involves load/use hazard, loading instruction sets register %esp , retinstruction uses register source operand, since must pop return address stack. pipeline control logicshould hold back retinstruction decode stage. Practice Problem 4.36 Write Y86 assembly-language program causes combination B arise completes halt instruction pipeline operates correctly. Combining control actions combination B conditions (Figure 4.66), get following pipeline control actions: Pipeline register Condition F E W Processing ret stall bubble normal normal normal Load/use hazard stall stall bubble normal normal Combination stall bubble+stall bubble normal normalDesired stall stall bubble normal normal sets actions triggered, control logic would try stall ret instruction avoid load/use hazard also inject bubble decodestage due retinstruction. Clearly, want pipeline perform sets actions. Instead, want take actions load/usehazard. actions processing retinstruction delayed one cycle. analysis shows combination B requires special handling. fact, original implementation PIPE control logic handle combinationcorrectly. Even though design passed many simulation tests, subtlebug uncovered analysis shown. programhaving combination B executed, control logic would set bubbleand stall signals pipeline register 1. example shows importanceof systematic analysis. would unlikely uncover bug runningnormal programs. left undetected, pipeline would faithfully implementthe ISA behavior. Control Logic Implementation Figure 4.68 shows overall structure pipeline control logic. Based onsignals pipeline registers pipeline stages, control logic generatesstall bubble control signals pipeline registers, also determineswhether condition code registers updated. combine theSection 4.5 Pipelined Y86 Implementations 441 FCCW icode valE valM dstE stat stat stat statdstM icode Cnd valE valA dstE dstM E icode ifun valC valA valB dstM srcA srcB dstE icode ifun valC valP rB rA F predPCsrcAsrcBstat Pipe control logicM_icodeW_stat e_Cndm_stat E_dstM d_srcB d_srcA D_icodeE_icode E_bubbleset_ccW_stall M_bubble D_bubble D_stall F_stall Figure 4.68 PIPE pipeline control logic. logic overrides normal ﬂow instructions pipeline handle special conditions procedure returns, mispredicted branches, load/use hazards, program exceptions. detection conditions Figure 4.64 actions Figure 4.66 create HCL descriptions different pipeline control signals. Pipeline register F must stalled either load/use hazard ret instruction: bool F_stall = # Conditions load/use hazard E_icode { IMRMOVL, IPOPL } && E_dstM { d_srcA, d_srcB } || # Stalling fetch ret passes pipeline IRET { D_icode, E_icode, M_icode }; Practice Problem 4.37 Write HCL code signal D_stall PIPE implementation. Pipeline register must set bubble mispredicted branch ret instruction. analysis preceding section shows, however, should442 Chapter 4 Processor Architecture inject bubble load/use hazard combination ret instruction: bool D_bubble = # Mispredicted branch(E_icode == IJXX && !e_Cnd) ||# Stalling fetch ret passes pipeline# condition load/use hazard !(E_icode { IMRMOVL, IPOPL } && E_dstM { d_srcA, d_srcB }) && IRET { D_icode, E_icode, M_icode }; Practice Problem 4.38 Write HCL code signal E_bubble PIPE implementation. Practice Problem 4.39 Write HCL code signal set_cc PIPE implementation. occur OPlinstructions, consider effects program excep- tions. Practice Problem 4.40 Write HCL code signals M_bubble W_stall PIPE implemen- tation. latter signal requires modifying exception condition listed Fig-ure 4.64. covers special pipeline control signal values. complete HCL code PIPE, pipeline control signals set zero. Aside Testing design seen, many ways introduce bugs design even simple microprocessor. pipelining, many subtle interactions instructions different pipeline stages. seen many design challenges involve unusual instructions (such popping stack pointer) unusual instruction combinations (such not-taken jump followed ret). also see exception handling adds entirely new dimension possible pipeline behaviors. sure design correct? hardware manufacturers, dominant concern, since cannot simply report error users download code patches Internet. Even simple logic design error serious consequences, especially microprocessors increasingly used operate systems critical lives health, automotive antilock braking systems, heart pacemakers, aircraft control systems.Section 4.5 Pipelined Y86 Implementations 443 Simply simulating design running number “typical” programs sufﬁcient means testing system. Instead, thorough testing requires devising ways systematically generating many tests exercise many different instructions instruction combinations possible. creating Y86 processor designs, also devised number testing scripts, generates many different tests, runs simulations processor, compares resulting register memory values produced yisinstruction set simulator. brief description scripts: optest: Runs 49 tests different Y86 instructions different source destination registers jtest: Runs 64 tests different jump call instructions, different combinations whether branches taken cmtest: Runs 28 tests different conditional move instructions, different control combi- nations htest: Runs 600 tests different data hazard possibilities, different combinations source destination instructions, different numbers nop instructions instruction pairs ctest: Tests 22 different control combinations, based analysis similar Sec- tion 4.5.11 etest: Tests 12 different combinations instructions causing exceptions instructions following could alter programmer-visible state key idea testing method want systematic possible, generating tests create different conditions likely cause pipeline errors. Aside Formally verifying design Even design passes extensive set tests, cannot certain operate correctly possible programs. number possible programs could test unimaginably large, even consider tests consisting short code segments. Newer methods formal veriﬁcation , however, hold promise tools rigorously consider possible behaviors system determine whether design errors. able apply formal veriﬁcation earlier version Y86 processors [13]. set framework compare behavior pipelined design PIPE unpipelined versionSEQ. is, able prove arbitrary Y86 program, two processors would identical effects programmer-visible state. course, veriﬁer cannot actually run possible programs, since inﬁnite number them. Instead, uses form proof induction, showing consistency two processors cycle-by-cycle basis. Carrying analysis requires reasoning hardware using symbolic methods consider program values arbitrary integers, abstract ALU sort “black box,” computing unspeciﬁed function arguments. assume ALUs SEQ PIPE compute identical functions. used HCL descriptions control logic generate control logic symbolic processor models, could catch bugs HCL code. able show SEQ PIPE identical guarantee either faithfully implements Y86 instruction set444 Chapter 4 Processor Architecture architecture. However, would uncover bug due incorrect pipeline design, major source design errors. experiments, veriﬁed version PIPE considered chapter also several variants give homework problems, add instructions, modify hardware capabilities, use different branch prediction strategies. Interestingly, found one bug designs, involving control combination B (described Section 4.5.11) solutionto variant described Problem 4.57. exposed weakness testing regime caused usto add additional cases ctest testing script. Formal veriﬁcation still early stage development. tools often difﬁcult use, capacity verify large-scale designs. able verify Y86 processors part relative simplicity. Even then, required several weeks effort multiple runs tools, requiring eight hours computer time. active area research, tools becoming commercially available, use companies Intel, AMD, IBM. Web Aside ARCH:VLOG Verilog implementation pipelined Y86 processor mentioned, modern logic design involves writing textual representations hardware designs hardware description language . design tested simulation variety formal veriﬁcation tools. conﬁdence design, use logic synthesis tools translate design actual logic circuits. developed models Y86 processor designs Verilog hardware description language. designs combine modules implementing basic building blocks processor,along control logic generated directly HCL descriptions. able synthesize designs, download logic circuit descriptions onto ﬁeld-programmable gate array (FPGA) hardware, run processors actual Y86 programs. 4.5.12 Performance Analysis see conditions requiring special action pipeline control logic cause pipeline fall short goal issuing new instruction onevery clock cycle. measure inefﬁciency determining often abubble gets injected pipeline, since cause unused pipeline cycles. Areturn instruction generates three bubbles, load/use hazard generates one, anda mispredicted branch generates two. quantify effect penalties overall performance computing estimate average number clock cycles PIPE would require per instruction executes, measure knownas CPI (for “cycles per instruction”). measure reciprocal theaverage throughput pipeline, time measured clock cycles ratherthan picoseconds. useful measure architectural efﬁciency design. ignore performance implications exceptions (which, deﬁnition, occur rarely), another way think CPI imagine run theprocessor benchmark program observe operation execute stage. cycle, execute stage would either process instruction, instruction would continue remaining stages completion,Section 4.5 Pipelined Y86 Implementations 445 would process bubble, injected due one three special cases. stage processes total Ciinstructions Cbbubbles, processor required around Ci+Cbtotal clock cycles execute Ciinstructions. say “around” ignore cycles required start instructions ﬂowingthrough pipeline. compute CPI benchmark follows: CPI=C i+Cb Ci=1.0+Cb Ci is, CPI equals 1.0 plus penalty term Cb/Ciindicating average number bubbles injected per instruction executed. Since three different instructiontypes cause bubble injected, break penalty term threecomponents: CPI=1.0+lp+mp+rp lp(for “load penalty”) average frequency bubbles in- jected stalling load/use hazards, mp(for “mispredicted branch penalty”) average frequency bubbles injected canceling instruc-tions due mispredicted branches, rp(for “return penalty”) average frequency bubbles injected stalling retinstructions. penalties indicates total number bubbles injected statedreason (some portion C b) divided total number instructions executed ( Ci). estimate penalties, need know frequently relevant instructions (load, conditional branch, return) occur, ofthese frequently particular condition arises. Let us pick following setof frequencies CPI computation (these comparable measurementsreported [47] [49]): .Load instructions ( mrmovl andpopl ) account 25% instructions executed. these, 20% cause load/use hazards. .Conditional branches account 20% instructions executed. these,60% taken 40% taken. .Return instructions account 2% instructions executed. therefore estimate penalties product fre- quency instruction type, frequency condition arises, numberof bubbles get injected condition occurs: Instruction Condition Cause Name frequency frequency Bubbles Product Load/Use lp 0.25 0 .20 1 0 .05 Mispredict mp 0.20 0 .40 2 0 .16 Return rp 0.02 1 .00 3 0 .06 Total Penalty 0 .27 sum three penalties 0 .27, giving CPI 1 .27.446 Chapter 4 Processor Architecture goal design pipeline issue one instruction per cycle, giving CPI 1 .0. quite meet goal, overall performance still quite good. also see effort reduce CPI shouldfocus mispredicted branches. account 0 .16 total penalty 0 .27, conditional branches common, prediction strategy often fails, andwe cancel two instructions every misprediction. Practice Problem 4.41 Suppose use branch prediction strategy achieves success rate 65%,such backward taken, forward not-taken, described Section 4.5.4. Whatwould impact CPI, assuming frequencies affected? Practice Problem 4.42 Let us analyze relative performance using conditional data transfers versusconditional control transfers programs wrote Problems 4.4 4.5.Assume using programs compute sum absolute valuesof long array, overall performance determined largely thenumber cycles required inner loop. Assume jump instructions arepredicted taken, around 50% array values positive. A. average, many instructions executed inner loops two programs? B. average, many bubbles would injected inner loop two programs? C. average number clock cycles required per array element two programs? 4.5.13 Unﬁnished Business created structure PIPE pipelined microprocessor, designed control logic blocks, implemented pipeline control logic handle specialcases normal pipeline ﬂow sufﬁce. Still, PIPE lacks several keyfeatures would required actual microprocessor design. highlighta discuss would required add them. Multicycle Instructions instructions Y86 instruction set involve simple operations asadding numbers. processed single clock cycle within executestage. complete instruction set, would also need implementinstructions requiring complex operations integer multiplicationand division, ﬂoating-point operations. medium-performance processor PIPE, typical execution times operations range 3 4Section 4.5 Pipelined Y86 Implementations 447 cycles ﬂoating-point addition 32 integer division. implement instructions, require additional hardware perform computationsand mechanism coordinate processing instructions restof pipeline. One simple approach implementing multicycle instructions simply expand capabilities execute stage logic integer ﬂoating-pointarithmetic units. instruction remains execute stage many clockcycles requires, causing fetch decode stages stall. approach issimple implement, resulting performance good. Better performance achieved handling complex opera- tions special hardware functional units operate independently themain pipeline. Typically, one functional unit performing integer mul-tiplication division, another performing ﬂoating-point operations. Asan instruction enters decode stage, issued special unit. unit performs operation, pipeline continues processing instructions.Typically, ﬂoating-point unit pipelined, thus multiple operations execute concurrently main pipeline different units. operations different units must synchronized avoid incorrect behavior. example, data dependencies differentoperations handled different units, control logic may need stallone part system results operation handled otherpart system completed. Often, different forms forwarding areused convey results one part system parts, saw different stages PIPE. overall design becomes complex seen PIPE, techniques stalling, forwarding, andpipeline control used make overall behavior match sequentialISA model. Interfacing Memory System presentation PIPE, assumed instruction fetch unitand data memory could read write memory location one clock cycle. also ignored possible hazards caused self-modifying code whereone instruction writes region memory later instructions fetched. Furthermore, reference memory locations according virtualaddresses, require translation physical addresses actualread write operation performed. Clearly, unrealistic thisprocessing single clock cycle. Even worse, memory values accessedmay reside disk, requiring millions clock cycles read processormemory. discussed Chapters 6 9, memory system processor uses combination multiple hardware memories operating system soft-ware manage virtual memory system. memory system organized ahierarchy, faster smaller memories holding subset memory beingbacked slower larger memories. level closest processor,thecache memories provide fast access heavily referenced memory448 Chapter 4 Processor Architecture locations. typical processor two ﬁrst-level caches—one reading instruc- tions one reading writing data. Another type cache memory, knownas translation look-aside buffer , TLB, provides fast translation virtual physical addresses. Using combination TLBs caches, indeed pos-sible read instructions read write data single clock cycle ofthe time. Thus, simpliﬁed view memory referencing processors actually quite reasonable. Although caches hold heavily referenced memory locations, times cache miss occurs, reference made location held cache. best case, missing data beretrieved higher-level cache main memory processor,requiring 3 20 clock cycles. Meanwhile, pipeline simply stalls, holding theinstruction fetch memory stage cache perform reador write operation. terms pipeline design, implemented byadding stall conditions pipeline control logic. cache miss theconsequent synchronization pipeline handled completely hardware,keeping time required small number clock cycles. cases, memory location referenced actually stored disk memory. occurs, hardware signals page fault exception. Like exceptions, cause processor invoke operating system’sexception handler code. code set transfer disk tothe main memory. completes, operating system return backto original program, instruction causing page fault re-executed. time, memory reference succeed, although might cause acache miss. hardware invoke operating system routine, thenreturns control back hardware, allows hardware system softwareto cooperate handling page faults. Since accessing disk requiremillions clock cycles, several thousand cycles processing performed bythe OS page fault handler little impact performance. perspective processor, combination stalling han- dle short-duration cache misses exception handling handle long-durationpage faults takes care unpredictability memory access times due structure memory hierarchy. Aside State-of-the-art microprocessor design ﬁve-stage pipeline, shown PIPE processor, represented state art processor design mid-1980s. prototype RISC processor developed Patterson’s research group Berkeley formed basis ﬁrst SPARC processor, developed Sun Microsystems 1987. processor developed Hennessy’s research group Stanford commercialized MIPS Technologies (a company founded Hennessy) 1986. used ﬁve-stage pipelines.The Intel i486 processor also uses ﬁve-stage pipeline, although different partitioning responsibilities among stages, two decode stages combined execute/memory stage [33]. pipelined designs limited throughput one instruction per clock cycle. CPI (for “cycles per instruction”) measure described Section 4.5.12 never less 1.0. different stages process one instruction time. recent processors support superscalarSection 4.6 Summary 449 operation, meaning achieve CPI less 1.0 fetching, decoding, executing multiple instructions parallel. superscalar processors become widespread, accepted performance measure shifted CPI reciprocal—the average number instructions executed per cycle, IPC. exceed 1.0 superscalar processors. advanced designs use technique known out-of-order execution execute multiple instructions parallel, possibly totally different order occur program, preserving overall behavior impliedby sequential ISA model. form execution described Chapter 5 part discussionof program optimization. Pipelined processors historical artifacts, however. majority processors sold used embedded systems, controlling automotive functions, consumer products, devices processor directly visible system user. applications, simplicity pipelined processor, one explored chapter, reduces cost power requirements compared higher-performance models. recently, multicore processors gained following, argued could get overall computing power integrating many simple processors single chip ratherthan smaller number complex ones. strategy sometimes referred “many-core” processors [10]. 4.6 Summary seen instruction set architecture, ISA, provides layer abstraction behavior processor—in terms set instructions encodings—and processor implemented. ISA providesa sequential view program execution, one instruction executed tocompletion next one begins. deﬁned Y86 instruction set starting IA32 instructions simplifying data types, address modes, instruction encoding considerably.The resulting ISA attributes RISC CISC instruction sets. thenorganized processing required different instructions series ofﬁve stages, operations stage vary according instructionbeing executed. this, constructed SEQ processor, en-tire instruction executed every clock cycle ﬂow ﬁvestages. Pipelining improves throughput performance system letting different stages operate concurrently. given time, multiple operations arebeing processed different stages. introducing concurrency, mustbe careful provide program-level behavior would sequentialexecution program. introduced pipelining reordering parts SEQto get SEQ+, adding pipeline registers create PIPE– pipeline. enhanced pipeline performance adding forwarding logic speed sending result one instruction another. Several special cases requireadditional pipeline control logic stall cancel pipeline stages. design included rudimentary mechanisms handle exceptions, make sure instructions excepting instruction affect theprogrammer-visible state. Implementing complete handling exceptions would450 Chapter 4 Processor Architecture signiﬁcantly challenging. Properly handling exceptions gets even complex systems employ greater degrees pipelining parallelism. chapter, learned several important lessons processor design: .Managing complexity top priority . want make optimum use hardware resources get maximum performance minimum cost. didthis creating simple uniform framework processing thedifferent instruction types. framework, could share hardwareunits among logic processing different instruction types. .We need implement ISA directly . direct implementation ISA would imply sequential design. achieve higher performance,we want exploit ability hardware perform many operations si-multaneously. led use pipelined design. careful design andanalysis, handle various pipeline hazards, overall effectof running program exactly matches would obtained ISA model. .Hardware designers must meticulous. chip fabricated, nearly impossible correct errors. important get thedesign right ﬁrst try. means carefully analyzing different instructiontypes combinations, even ones seem make sense, suchas popping stack pointer. Designs must thoroughly tested withsystematic simulation test programs. developing control logic PIPE, design subtle bug uncovered careful systematic analysis control combinations. Web Aside ARCH:HCL HCL descriptions Y86 processors chapter, looked portions HCL code several simple logic designs, control logic Y86 processors SEQ PIPE. reference, provide documentation HCL language complete HCL descriptions control logic two processors. ofthese descriptions requires 5–7 pages HCL code, worthwhile study theirentirety. 4.6.1 Y86 Simulators lab materials chapter include simulators SEQ PIPE processors. simulator two versions: .The GUI (graphic user interface) version displays memory, program code,and processor state graphic windows. provides way readily see instructions ﬂow processors. control panel also allows reset, single-step, run simulator interactively. .The text version runs simulator, displays information byprinting terminal. version useful debugging, itallows automated testing processor.Homework Problems 451 control logic simulators generated translating HCL declarations logic blocks C code. code compiled linkedwith rest simulation code. combination makes possible youto test variants original designs using simulators. Testing scripts arealso available thoroughly exercise different instructions differenthazard possibilities. Bibliographic Notes interested learning logic design, Katz’s logic designtextbook [56] standard introductory text, emphasizing use hardwaredescription languages. Hennessy Patterson’s computer architecture textbook [49] provides ex- tensive coverage processor design, including simple pipelines, theone presented here, advanced processors execute moreinstructions parallel. Shriver Smith [97] give thorough presentationof Intel-compatible IA32 processor manufactured AMD. Homework Problems 4.43◆ Section 3.4.2, IA32 pushl instruction described decrementing stack pointer storing register stack pointer location. So, ifwe instruction form pushl REG, register REG, would equivalent code sequence: subl $4,%esp Decrement stack pointer movl REG,(%esp) Store REG stack A. light analysis done Problem 4.6, code sequence correctly describe behavior instruction pushl %esp ? Explain. B. could rewrite code sequence correctly describes cases REGis%esp well register? 4.44◆ Section 3.4.2, IA32 popl instruction described copying result top stack destination register incrementing stackpointer. So, instruction form poplREG, would equivalent code sequence: movl (%esp), REG Read REG stack addl $4,%esp Increment stack pointer A. light analysis done Problem 4.7, code sequence correctly describe behavior instruction popl %esp ? Explain.452 Chapter 4 Processor Architecture B. could rewrite code sequence correctly describes cases REGis%esp well register? 4.45◆◆◆ assignment write Y86 program perform bubblesort. ref-erence, following C function implements bubblesort using array referencing: /* Bubble sort: Array version */ void bubble_a(int *data, int count) { int i, last; (last = count-1; last > 0; last--) { (i = 0; < last; i++) (data[i+1] < data[i]) { /* Swap adjacent elements */ int = data[i+1];data[i+1] = data[i]; data[i] = t; } } } A. Write tes C version references array elements pointers, rather using array indexing. B. Write test Y86 program consisting function test code. may ﬁnd useful pattern implementation IA32 code generatedby compiling C code. Although pointer comparisons normally done using unsigned arithmetic, use signed arithmetic exercise. 4.46◆◆ Modify code wrote Problem 4.46 implement test swap inner loop bubblesort function using conditional moves. 4.47◆ example Y86 programs, Sumfunction shown Figure 4.6, encounter many cases (e.g., lines 12 13 lines 14 15) want add constant value register. requires ﬁrst using irmovl instruction set register constant, addl instruction add value destination register. Suppose want add new instruction iaddl following format: 0 CByte iaddl V, rB12345 0FrB V instruction adds constant value Vto register rB. Describe computa- tions performed implement instruction. Use computations irmovl andOPl(Figure 4.18) guide.Homework Problems 453 4.48◆ described Section 3.7.2, IA32 instruction leave used prepare stack returning. equivalent following Y86 code sequence: 1 rrmovl %ebp, %esp Set stack pointer beginning frame 2 popl %ebp Restore saved %ebp set stack ptr end caller’s frame Suppose add instruction Y86 instruction set, using following encoding: 0 DByte leave12345 0 Describe computations performed implement instruction. Use computations popl (Figure 4.20) guide. 4.49◆◆ ﬁle seq-full.hcl contains HCL description SEQ, along dec- laration constant IIADDL hexadecimal value C, instruction code iaddl . Modify HCL descriptions control logic blocks implement iaddl instruction, described Homework Problem 4.47. See lab material directions generate simulator solution test it. 4.50◆◆ ﬁle seq-full.hcl also contains declaration constant ILEAVE hexadecimal value D, instruction code leave , well declaration constant REBP value 7, register ID %ebp . Modify HCL descriptions control logic blocks implement leave instruction, described Homework Problem 4.48. See lab material directions howto generate simulator solution test it. 4.51◆◆◆ Suppose wanted create lower-cost pipelined processor based struc-ture devised PIPE– (Figure 4.41), without bypassing. design wouldhandle data dependencies stalling instruction generating neededvalue passed write-back stage. ﬁle pipe-stall.hcl contains modiﬁed version HCL code PIPE bypassing logic disabled. is, signals e_valA e_valB simply declared follows: ## MODIFY FOLLOWING CODE. ## forwarding. valA either valP value register file int d_valA = [ D_icode { ICALL, IJX X } : D_valP; # Use incremented PC 1 : d_rvalA; # Use value read register file ]; ## forwarding. valB value register file int d_valB = d_rvalB;454 Chapter 4 Processor Architecture Modify pipeline control logic end ﬁle correctly handles possible control data hazards. part design effort, shouldanalyze different combinations control cases, design thepipeline control logic PIPE. ﬁnd many different combinationscan occur, since many conditions require pipeline stall. Make sureyour control logic handles combination correctly. See lab material fordirections generate simulator solution test it. 4.52◆◆ ﬁle pipe-full.hcl contains copy PIPE HCL description, along declaration constant value IIADDL . Modify ﬁle implement iaddl instruction, described Homework Problem 4.47. See lab material fordirections generate simulator solution test it. 4.53◆◆◆ ﬁle pipe-full.hcl also contains declarations constants ILEAVE andREBP . Modify ﬁle implement leave instruction, described Homework Problem 4.48. See lab material directions generate simulatorfor solution test it. 4.54◆◆◆ ﬁle pipe-nt.hcl contains copy HCL code PIPE, plus declaration constant J_YES value 0, function code unconditional jump instruction. Modify branch prediction logic predicts conditionaljumps not-taken continuing predict unconditional jumps andcall taken. need devise way get valC , jump target address, pipeline register recover mispredicted branches. See labmaterial directions generate simulator solution howto test it. 4.55◆◆◆ ﬁle pipe-btfnt.hcl contains copy HCL code PIPE, plus decla- ration constant J_YES value 0, function code unconditional jump instruction. Modify branch prediction logic predicts conditional jumps taken valC<valP (backward branch) not-taken valC≥valP (forward branch). (Since Y86 support unsigned arith- metic, implement test using signed comparison.) Continue topredict unconditional jumps call taken. need devise way get valC valP pipeline register recover mispredicted branches. See lab material directions generate simulator foryour solution test it. 4.56◆◆◆ design PIPE, generate stall whenever one instruction performs aload , reading value memory register, next instruction register source operand. source gets used execute stage,this stalling way avoid hazard.Homework Problems 455 cases second instruction stores source operand memory, rmmovl orpushl instruction, stalling necessary. Consider following code examples: 1 mrmovl 0(%ecx),%edx # Load 1 2 pushl %edx # Store 1 3 nop 4 popl %edx # Load 2 5 rmmovl %eax,0(%edx) # Store 2 lines 1 2, mrmovl instruction reads value memory %edx , pushl instruction pushes value onto stack. design PIPE would stall pushl instruction avoid load/use hazard. Observe, however, value %edx required pushl instruction reaches memory stage. add additional bypass path, diagrammedin Figure 4.69, forward memory output (signal m_valM )t ot h e valA ﬁeld e_CndE_icode W_stat m_statM_dstM E_srcAm_valM E_valAW icode stat stat statvalE valM dstE dstM icode Cnd valE valA dstE dstM E icode ifun valC valA valB dstM srcA srcBALU ASet CCALU BALU fun. ALU CCconddata data inreaddmem_error write Addr Fwd AMem. read Mem. writestat dstE dstEData memory Figure 4.69 Execute memory stages capable load forwarding. adding bypass path memory output source valA pipeline register M, canuse forwarding rather stalling one form load/use hazard. subject Homework Problem 4.56.456 Chapter 4 Processor Architecture pipeline register M. next clock cycle, forwarded value written memory. technique known load forwarding . Note second example (lines 4 5) code sequence cannot make use load forwarding. value loaded popl instruction used part address computation next instruction, value isrequired execute stage rather memory stage. A. Write logic formula describing detection condition load/use haz- ard, similar one given Figure 4.64, except cause astall cases load forwarding used. B. ﬁle pipe-lf.hcl contains modiﬁed version control logic PIPE. contains deﬁnition signal e_valA implement block labeled “Fwd A” Figure 4.69. also conditions load/use haz-ard pipeline control logic set zero, pipeline control logicwill detect forms load/use hazards. Modify HCL descriptionto implement load forwarding. See lab material directions togenerate simulator solution test it. 4.57◆◆◆ pipelined design bit unrealistic two write ports theregister ﬁle, popl instruction requires two simultaneous writes register ﬁle. instructions could therefore use single write port, sharingthis writing valE valM . following ﬁgure shows modiﬁed version write-back logic, merge write-back register IDs ( W_dstE W_ dstM ) single signal w_dstE write-back values ( W_valE W_valM ) single signal w_valE : Stat stat W icode valE valM dstE dstMvalEdstEw_valE w_dstE W_icode stat logic performing merges written HCL follows: ## Set E port register ID int w_dstE = [ ## writing valM W_dstM != RNONE : W_dstM;1: W_dstE; ]; ## Set E port value int w_valE = [ W_dstM != RNONE : W_valM; 1: W_valE; ];Solutions Practice Problems 457 control multiplexors determined dstE—when indicates register, selects value port E, otherwise selectsthe value port M. simulation model, disable register port M, shown following HCL code: ## Disable register port ## Set port register IDint w_dstM = RNONE; ## Set port value int w_valM = 0; challenge becomes devise way handle popl . One method use control logic dynamically process instruction popl rAso effect two-instruction sequence iaddl $4, %esp mrmovl -4(%esp), rA (See Homework Problem 4.47 description iaddl instruction.) Note ordering two instructions make sure popl %esp works properly. logic decode stage treat popl would iaddl listed above, except predicts next PC equal current PC. next cycle, popl instruction refetched, instruction code converted special value IPOP2 . treated special instruction behavior mrmovl instruction listed above. ﬁle pipe-1w.hcl contains modiﬁed write-port logic described above. contains declaration constant IPOP2 hexadecimal value E.I also contains deﬁnition signal f_icode generates icode ﬁeld pipeline register D. deﬁnition modiﬁed insert instruction codeIPOP2 second time popl instruction fetched. HCL ﬁle also contains declaration signal f_pc, value program counter generated fetch stage block labeled “Select PC” (Figure 4.55). Modify control logic ﬁle process popl instructions manner described. See lab material directions generate asimulator solution test it. 4.58◆◆ Compare performance two versions bubblesort (Problems 4.45 and4.46). Explain one version performs better other. Solutions Practice Problems Solution Problem 4.1 (page 341) Encoding instructions hand rather tedious, solidify under-standing idea assembly code gets turned byte sequences assembler. following output Y86 assembler, line shows address byte sequence starts address:458 Chapter 4 Processor Architecture 1 0x100: | .pos 0x100 # Start code address 0x100 2 0x100: 30f30f000000 | irmovl $15,%ebx # Load 15 %ebx 3 0x106: 2031 | rrmovl %ebx,%ecx # Copy 15 %ecx 4 0x108: | loop: # loop: 5 0x108: 4013fdffffff | rmmovl %ecx,-3(%ebx) # Save %ecx address 15-3 = 12 6 0x10e: 6031 | addl %ebx,%ecx # Increment %ecx 15 7 0x110: 7008010000 | jmp loop # Goto loop Several features encoding worth noting: .Decimal 15 (line 2) hex representation 0x0000000f . Writing bytes reverse order gives 0f 00 00 00 . .Decimal −3 (line 5) hex representation 0xfffffffd . Writing bytes reverse order gives fd ff ff ff . .The code starts address 0x100 . ﬁrst instruction requires 6 bytes, second requires 2. Thus, loop target 0x00000108 . Writing bytes reverse order gives 08 01 00 00 . Solution Problem 4.2 (page 341) Decoding byte sequence hand helps understand task faced processor. must read byte sequences determine instructions tobe executed. following, show assembly code used generate eachof byte sequences. left assembly code, see address byte sequence instruction. A. operations immediate data address displacements: 0x100: 30f3fcffffff | irmovl $-4,%ebx 0x106: 406300080000 | rmmovl %esi,0x800(%ebx) 0x10c: 00 | halt B. Code including function call: 0x200: a06f | pushl %esi0x202: 8008020000 | call proc 0x207: 00 | halt 0x208: | proc: 0x208: 30f30a000000 | irmovl $10,%ebx 0x20e: 90 | ret C. Code containing illegal instruction speciﬁer byte 0xf0 : 0x300: 505407000000 | mrmovl 7(%esp),%ebp 0x306: 10 | nop 0x307: f0 | .byte 0xf0 # invalid instruction code 0x308: b01f | popl %ecxSolutions Practice Problems 459 D. Code containing jump operation: 0x400: | loop: 0x400: 6113 | subl %ecx, %ebx 0x402: 7300040000 | je loop0x407: 00 | halt E. Code containing invalid second byte pushl instruction: 0x500: 6362 | xorl %esi,%edx 0x502: a0 | .byte 0xa0 # pushl instruction code0x503: f0 | .byte 0xf0 # Invalid register specifier byte Solution Problem 4.3 (page 350) suggested problem, adapted code generated gccfor IA32 machine: # int Sum(int *Start, int Count) rSum: pushl %ebp rrmovl %esp,%ebp pushl %ebx # Save value %ebxmrmovl 8(%ebp),%ebx # Get Startmrmovl 12(%ebp),%eax # Get Count andl %eax,%eax # Test value Countjle L38 # <= 0, goto zreturn irmovl $-1,%edx addl %edx,%eax # Count-- pushl %eax # Push Count irmovl $4,%edx rrmovl %ebx,%eax addl %edx,%eaxpushl %eax # Push Start+1 call rSum # Sum(Start+1, Count-1) mrmovl (%ebx),%edx addl %edx,%eax # Add *Start jmp L39 # goto done L38: xorl %eax,%eax # zreturn: L39: mrmovl -4(%ebp),%ebx # done: Restore %ebx rrmovl %ebp,%esp # Deallocate stack frame popl %ebp # Restore %ebpret Solution Problem 4.4 (page 350) problem gives chance try hand writing assembly code. int AbsSum(int *Start, int Count) 1AbsSum: 2 pushl %ebp460 Chapter 4 Processor Architecture 3 rrmovl %esp,%ebp 4 mrmovl 8(%ebp),%ecx ecx = Start 5 mrmovl 12(%ebp),%edx edx = Count 6 irmovl $0, %eax u m=0 7 andl %edx,%edx 8 je End 9Loop: 10 mrmovl (%ecx),%esi get x = *Start 11 irmovl $0,%edi 0 12 subl %esi,%edi -x 13 jle Pos Skip -x <= 0 14 rrmovl %edi,%esi x=- x 15 Pos: 16 addl %esi,%eax add x sum 17 irmovl $4,%ebx 18 addl %ebx,%ecx Start++ 19 irmovl $-1,%ebx 20 addl %ebx,%edx Count-- 21 jne Loop Stop 0 22 End: 23 popl %ebp 24 ret Solution Problem 4.5 (page 350) problem gives chance try hand writing assembly code conditional moves. show code loop. rest forProblem 4.4: 9Loop: 10 mrmovl (%ecx),%esi get x = *Start 11 irmovl $0,%edi 0 12 subl %esi,%edi -x 13 cmovg %edi,%esi f- x>0t h e nx=- x 14 addl %esi,%eax add x sum 15 irmovl $4,%ebx 16 addl %ebx,%ecx Start++ 17 irmovl $-1,%ebx 18 addl %ebx,%edx Count-- 19 jne Loop Stop 0 Solution Problem 4.6 (page 350) Although hard imagine practical use particular instruction, isimportant designing system avoid ambiguities speciﬁcation.We want determine reasonable convention instruction’s behavior andmake sure implementations adheres convention. Thesubl instruction test compares starting value %esp value pushed onto stack. fact result subtraction zeroimplies old value %esp gets pushed.Solutions Practice Problems 461 Solution Problem 4.7 (page 351) even difﬁcult imagine anyone would want pop stack pointer. Still, decide convention stick it. codesequence pushes 0xabcd onto stack, pops %esp , returns popped value. Since result equals 0xabcd , deduce popl %esp sets stack pointer value read memory. therefore equivalent instructionmrmovl (%esp),%esp . Solution Problem 4.8 (page 354) Exclusive-Or function requires 2 bits opposite values: bool xor = (!a && b) || (a && !b); general, signals eqandxorwill complements other. is, one equal 1 whenever 0. Solution Problem 4.9 (page 356) outputs Exclusive-Or circuits complements bit equal- ity values. Using DeMorgan’s laws (Web Aside data:bool ), implement using Orand Not, yielding following circuit: Xor Xor Xor Xorb31 a31 b30 a30 b1 a1 b0 a0! eq31 ! eq1 ! eq0! eq30 Eq . . .. . . Solution Problem 4.10 (page 359) design simple variant one ﬁnd minimum three inputs: int Med3 = [ A< =B& &B< =C:B ; C< =B& &B< =A:B ; B< =A& &A< =C:A ; C< =A& &A< =B:A ; 1: C ; ];462 Chapter 4 Processor Architecture Solution Problem 4.11 (page 367) exercises help make stage computations concrete. see object code instruction located address 0x00e . consists 6 bytes, ﬁrst two 0x30 and0x84 . last 4 bytes byte-reversed version 0x00000080 (decimal 128). Generic Speciﬁc Stage irmovl V,rB irmovl $128, %esp Fetch icode :ifun←M1[PC] icode :ifun←M1[0x00e ]=3:0 rA:rB←M1[PC+1] rA:rB←M1[0x00f ]=8:4 valC←M4[PC+2] valC←M4[0x010 ]=128 valP←PC+6 valP←0x00e +6=0x014 Decode Execute valE←0+valC valE ←0+128=128 Memory Write back R[rB]←valE R [%esp ]←valE=128 PC update PC←valP PC ←valP=0x014 instruction sets register %esp 128 increments PC 6. Solution Problem 4.12 (page 371) see instruction located address 0x01c consists 2 bytes values 0xb0 and0x08 . Register %esp set 124 pushl instruction (line 6), also stored 9 memory location. Generic Speciﬁc Stage popl rA popl %eax Fetch icode :ifun←M1[PC] icode :ifun←M1[0x01c ]=b:0 rA:rB←M1[PC+1] rA:rB←M1[0x01d ]=0:8 valP←PC+2 valP←0x01c +2=0x01e Decode valA←R[%esp ] valA←R[%esp ]=124 valB←R[%esp ] valB←R[%esp ]=124 Execute valE←valB+4 valE←124+4=128Solutions Practice Problems 463 Memory valM←M4[valA] valM←M4[124]=9 Write back R[%esp ]←valE R [%esp ]←128 R[rA]←valM R [%eax ]←9 PC update PC←valP PC ←0x01e instruction sets %eax 9, sets %esp 128, increments PC 2. Solution Problem 4.13 (page 372) Tracing steps listed Figure 4.20 rAequal %esp , see memory stage, instruction store valA, original value stack pointer, memory, found IA32. Solution Problem 4.14 (page 372) Tracing steps listed Figure 4.20 rAequal %esp , see write-back operations update %esp . Since one writing valM would occur last, net effect instruction write value read frommemory %esp , saw IA32. Solution Problem 4.15 (page 373) Implementing conditional moves requires minor changes register-to- register moves. simply condition write-back step outcome theconditional test: Stage cmovXX rA,rB Fetch icode :ifun←M1[PC] rA:rB←M1[PC+1] valP←PC+2 Decode valA←R[rA] Execute valE←0+valA Cnd←Cond(CC,ifun) Memory Write back ( Cnd) R[rB]←valE PC update PC←valP Solution Problem 4.16 (page 374) see instruction located address 0x023 5 bytes long. ﬁrst byte value 0x80 , last four byte-reversed version of0x00000029 , call target. stack pointer set 128 popl instruction (line 7).464 Chapter 4 Processor Architecture Generic Speciﬁc Stage call Dest call 0x029 Fetch icode :ifun←M1[PC] icode :ifun←M1[0x023 ]=8:0 valC←M4[PC+1] valC←M4[0x024 ]=0x029 valP←PC+5 valP←0x023 +5=0x028 Decode valB←R[%esp ] valB←R[%esp ]=128 Execute valE←valB+−4 valE←128+−4=124 Memory M4[valE]←valP 4[124]←0x028 Write back R[%esp ]←valE R [%esp ]←124 PC update PC←valC PC ←0x029 effect instruction set %esp 124, store 0x028 (the return address) memory address, set PC 0x029 (the call target). Solution Problem 4.17 (page 384) HCL code practice problems straightforward, trying generate help think different instructionsand processed. problem, simply look set ofY86 instructions (Figure 4.2) determine constant ﬁeld. bool need_valC = icode { IIRMOVL, IRMMOVL, IMRMOVL, IJXX, ICALL }; Solution Problem 4.18 (page 386) code similar code srcA. int srcB = [ icode { IOPL, IRMMOVL, IMRMOVL } : rB; icode { IPUSHL, IPOPL, ICALL, IRE } : RESP; 1 : RNONE; # Don’t need register ]; Solution Problem 4.19 (page 387) code similar code dstE. int dstM = [ icode { IMRMOVL, IPOP L}:r ; 1 : RNONE; # Don’t write register ];Solutions Practice Problems 465 Solution Problem 4.20 (page 387) found Practice Problem 4.14, want write via port take priority write via E port order store value read memoryinto%esp . Solution Problem 4.21 (page 388) code similar code aluA . int aluB = [ icode { IRMMOVL, IMRMOVL, IOPL, ICALL, IPUSHL, IRET, IPOP L } : valB; icode { IRRMOVL, IIRMOV L}:0 ; # instructions don’t need ALU ]; Solution Problem 4.22 (page 389) Implementing conditional moves surprisingly simple: disable writing register ﬁle setting destination register RNONE condition hold. int dstE = [ icode { IRRMOVL } && Cnd : rB; icode { IIRMOVL, IOPL} : rB; icode { IPUSHL, IPOPL, ICALL, IRE } : RESP; 1 : RNONE; # Don’t write register ]; Solution Problem 4.23 (page 389) code similar code mem_addr . int mem_data = [ # Value registericode { IRMMOVL, IPUSH L } : valA; # Return PCicode == ICALL : valP; # Default: Don’t write anything ]; Solution Problem 4.24 (page 390) code similar code mem_read . bool mem_write = icode { IRMMOVL, IPUSHL, ICALL }; Solution Problem 4.25 (page 390) Computing Statﬁeld requires collecting status information several stages:466 Chapter 4 Processor Architecture ## Determine instruction status int Stat = [ imem_error || dmem_error : SADR; !instr_valid: SINS; icode == IHALT : SHLT;1 : SAOK; ]; Solution Problem 4.26 (page 396) problem interesting exercise trying ﬁnd optimal balance among set partitions. provides number opportunities compute throughputsand latencies pipelines. A. two-stage pipeline, best partition would blocks A, B, C ﬁrst stage D, E, F second. ﬁrst stage hasa delay 170 ps, giving total cycle time 170 +20=190 picoseconds. therefore throughput 5 .26 GOPS latency 380 ps. B. three-stage pipeline, blocks B ﬁrst stage, blocks C second, blocks E F third. ﬁrsttwo stages delay 110 ps, giving total cycle time 130 ps athroughput 7 .69 GOPS. latency 390 ps. C. four-stage pipeline, block ﬁrst stage, blocks B C second, block third, blocks E F fourth.The second stage requires 90 ps, giving total cycle time 110 ps athroughput 9 .09 GOPS. latency 440 ps. D. optimal design would ﬁve-stage pipeline, block stage, except ﬁfth stage blocks E F. cycle time is80+20=100 picoseconds, throughput around 10 .00 GOPS latency 500 ps. Adding stages would help, since cannot runthe pipeline faster one cycle every 100 ps. Solution Problem 4.27 (page 398) stage would combinational logic requiring 300 /kps, pipeline register requiring 20 ps. A. total latency would 300 +20kps, throughput (in GIPS) would 1000 300 k+20=1000k 300+20K B. let kgo inﬁnity, throughput becomes 1000 /20=50 GIPS. course, would give us inﬁnite latency, well. exercise quantiﬁes diminishing returns deep pipelining. try subdivide logic many stages, latency pipeline registers becomesa limiting factor.Solutions Practice Problems 467 Solution Problem 4.28 (page 425) code similar corresponding code SEQ, except cannot yet determine whether data memory generate error signal thisinstruction. # Determine status code fetched instruction int f_stat = [ imem_error: SADR; !instr_valid : SINS; f_icode == IHALT : SHLT;1 : SAOK; ]; Solution Problem 4.29 (page 426) code simply involves preﬁxing signal names code SEQ “d_” “ D_”. int d_dstE = [ D_icode { IRRMOVL, IIRMOVL, IOPL} : D_rB;D_icode { IPUSHL, IPOPL, ICALL, IRE } : RESP; 1 : RNONE; # Don’t write register ]; Solution Problem 4.30 (page 429) Therrmovl instruction (line 5) would stall one cycle due load-use hazard caused popl instruction (line 4). enters decode stage, popl instruction would memory stage, giving M_dstE M_dstM equal to%esp . two cases reversed, write back M_valE would take priority, causing incremented stack pointer passed argumentto rrmovl instruction. would consistent convention handling popl %esp determined Practice Problem 4.7. Solution Problem 4.31 (page 429) problem lets experience one important tasks processor design— devising test programs new processor. general, test pro-grams exercise different hazard possibilities generateincorrect results dependency handled properly. example, use slightly modiﬁed version program shown Practice Problem 4.30: 1 irmovl $5, %edx 2 irmovl $0x100,%esp 3 rmmovl %edx,0(%esp) 4 popl %esp 5 nop 6 nop 7 rrmovl %esp,%eax468 Chapter 4 Processor Architecture two nopinstructions cause popl instruction write-back stage rrmovl instruction decode stage. two forwarding sources write-back stage given wrong priority, register %eax set incremented program counter rather value read frommemory. Solution Problem 4.32 (page 429) logic needs check ﬁve forwarding sources: int d_valB = [ d_srcB == e_dstE : e_valE; # Forward valE execute d_srcB == M_dstM : m_valM; # Forward valM memory d_srcB == M_dstE : M_valE; # Forward valE memory d_srcB == W_dstM : W_valM; # Forward valM write backd_srcB == W_dstE : W_valE; # Forward valE write back 1 : d_rvalB; # Use value read register file ]; Solution Problem 4.33 (page 430) change would handle case conditional move fails satisfy condition, therefore sets dstE value RNONE . resulting value could get forwarded next instruction, even though conditional transfer doesnot occur. 1 irmovl $0x123,%eax 2 irmovl $0x321,%edx 3 xorl %ecx,%ecx # CC = 100 4 cmovne %eax,%edx # transferred 5 addl %edx,%edx # 0x642 6 halt code initializes register %edx to0x321 . conditional data transfer take place, ﬁnal addl instruction double value %edx 0x642 . altered design, however, conditional move source value 0x321 gets forwarded ALU input valA, input valB correctly gets operand value 0x123 . inputs get added produce result 0x444 . Solution Problem 4.34 (page 431) code completes computation status code instruction. ## Update status int m_stat = [ dmem_error : SADR; 1 : M_stat; ]; Solution Problem 4.35 (page 439) following test program designed set control combination (Fig- ure 4.67) detect whether something goes wrong:Solutions Practice Problems 469 1# Code generate combination not-taken branch ret 2 irmovl Stack, %esp 3 irmovl rtnp,%eax 4 pushl %eax # Set return pointer 5 xorl %eax,%eax # Set Z condition code 6 jne target # taken (First part combination) 7 irmovl $1,%eax # execute 8 halt 9target: ret # Second part combination 10 irmovl $2,%ebx # execute 11 halt 12 rtnp: irmovl $3,%edx # execute 13 halt 14 .pos 0x40 15 Stack: program designed something goes wrong (for example, ret instruction actually executed), program execute one extra irmovl instructions halt. Thus, error pipeline would cause register updated incorrectly. code illustrates care required toimplement test program. must set potential error condition thendetect whether error occurs. Solution Problem 4.36 (page 440) following test program designed set control combination B (Fig-ure 4.67). simulator detect case bubble stall control signalsfor pipeline register set zero, test program need setup combination detected. biggest challenge make theprogram something sensible handled correctly. 1# Test instruction modifies %esp followed ret 2 irmovl mem,%ebx 3 mrmovl 0(%ebx),%esp # Sets %esp point return point 4 ret # Returns return point 5 halt # 6rtnpt: irmovl $5,%esi # Return point 7 halt 8.pos 0x40 9mem: .long stack # Holds desired stack pointer 10 .pos 0x50 11 stack: .long rtnpt # Top stack: Holds return point program uses two initialized word memory. ﬁrst word ( mem) holds address second ( stack —the desired stack pointer). second word holds address desired return point retinstruction. program loads stack pointer %esp executes retinstruction.470 Chapter 4 Processor Architecture Solution Problem 4.37 (page 441) Figure 4.66, see pipeline register must stalled load/use hazard. bool D_stall = # Conditions load/use hazard E_icode { IMRMOVL, IPOPL } && E_dstM { d_srcA, d_srcB }; Solution Problem 4.38 (page 442) Figure 4.66, see pipeline register E must set bubble load/use hazard mispredicted branch: bool E_bubble = # Mispredicted branch (E_icode == IJXX && !e_Cnd) || # Conditions load/use hazard E_icode { IMRMOVL, IPOPL } && E_dstM { d_srcA, d_srcB}; Solution Problem 4.39 (page 442) control requires examining code executing instruction checking exceptions pipeline. ## condition codes updated? bool set_cc = E_icode == IOPL && # State changes normal operation!m_stat { SADR, SINS, SHLT } && !W_stat { SADR, SINS, SHLT }; Solution Problem 4.40 (page 442) Injecting bubble memory stage next cycle involves checking exception either memory write-back stage current cycle. # Start injecting bubbles soon exception passes memory stage boolM_bubble=m_statin{SADR,SINS,SHLT}||W_statin{SADR,SINS,SHLT}; stalling write-back stage, check status instruction stage. also stalled excepting instruction memorystage, instruction would able enter write-back stage. bool W_stall = W_stat { SADR, SINS, SHLT }; Solution Problem 4.41 (page 446) would misprediction frequency 0 .35, giving mp=0.20×0.35× 2=0.14, giving overall CPI 1 .25. seems like fairly marginal gain, would worthwhile cost implementing new branch prediction strategy high.Solutions Practice Problems 471 Solution Problem 4.42 (page 446) simpliﬁed analysis, focus inner loop, useful way estimate program performance. long array sufﬁciently large, timespent parts code negligible. A. inner loop code using conditional jump 11 instructions, executed array element zero negative, 10 ofwhich executed array element positive. average 10.5.The inner loop code using conditional move 10 instructions,all executed every time. B. loop-closing jump predicted correctly, except loop terminates. long array, one misprediction negligibleeffect performance. source bubbles jump-based code conditional jump depending whether arrayelement positive. cause two bubbles, occurs 50% ofthe time, average 1.0. bubbles conditional move code. C. conditional jump code requires average 10 .5+1.0=11.5 cycles per array element (11 cycles best case 12 cycles worst),while conditional move code requires 10 .0 cycles cases. pipeline branch misprediction penalty two cycles—far better deep pipelines higher-performance processors. result,using conditional moves affect program performance much.This page intentionally left blank CHAPTER5 Optimizing Program Performance 5.1 Capabilities Limitations Optimizing Compilers 476 5.2 Expressing Program Performance 480 5.3 Program Example 482 5.4 Eliminating Loop Inefﬁciencies 486 5.5 Reducing Procedure Calls 490 5.6 Eliminating Unneeded Memory References 491 5.7 Understanding Modern Processors 496 5.8 Loop Unrolling 509 5.9 Enhancing Parallelism 513 5.10 Summary Results Optimizing Combining Code 524 5.11 Limiting Factors 525 5.12 Understanding Memory Performance 531 5.13 Life Real World: Performance Improvement Techniques 539 5.14 Identifying Eliminating Performance Bottlenecks 540 5.15 Summary 547 Bibliographic Notes 548 Homework Problems 549 Solutions Practice Problems 552 473474 Chapter 5 Optimizing Program Performance biggest speedup you’ll ever get program ﬁrst get working. —John K. Ousterhout primary objective writing program must make work correctly possible conditions. program runs fast gives incorrect resultsserves useful purpose. Programmers must write clear concise code, make sense it, also others read understand code code reviews modiﬁcations required later. hand, many occasions making program run fast also important consideration. program must process video frames ornetwork packets real time, slow-running program provide theneeded functionality. computation task demanding requiresdays weeks execute, making run 20% faster signiﬁcantimpact. chapter, explore make programs run faster via several different types program optimization. Writing efﬁcient program requires several types activities. First, must select appropriate set algorithms data structures. Second, wemust write source code compiler effectively optimize turn intoefﬁcient executable code. second part, important understand thecapabilities limitations optimizing compilers. Seemingly minor changes inhow program written make large differences well compiler canoptimize it. programming languages easily optimized others.Some features C, ability perform pointer arithmetic casting,make challenging compiler optimize. Programmers often write theirprograms ways make easier compilers generate efﬁcient code. Athird technique dealing especially demanding computations dividea task portions computed parallel, combination ofmultiple cores multiple processors. defer aspect performanceenhancement Chapter 12. Even exploiting parallelism, important thateach parallel thread execute maximum performance, material ofthis chapter remains relevant case. approaching program development optimization, must consider code used critical factors affect it. general, program- mers must make trade-off easy program implement andmaintain, fast runs. algorithmic level, simple insertion sort canbe programmed matter minutes, whereas highly efﬁcient sort routinemay take day implement optimize. coding level, manylow-level optimizations tend reduce code readability modularity, makingthe programs susceptible bugs difﬁcult modify extend.For code executed repeatedly performance-critical environment, extensive optimization may appropriate. One challenge maintain somedegree elegance readability code despite extensive transformations. describe number techniques improving code performance. Ideally, compiler would able take whatever code write generate mostChapter 5 Optimizing Program Performance 475 efﬁcient possible machine-level program speciﬁed behavior. Modern compilers employ sophisticated forms analysis optimization, keepgetting better. Even best compilers, however, thwarted optimization blockers —aspects program’s behavior depend strongly execu- tion environment. Programmers must assist compiler writing code canbe optimized readily. ﬁrst step optimizing program eliminate unnecessary work, mak- ing code perform intended task efﬁciently possible. includeseliminating unnecessary function calls, conditional tests, memory references.These optimizations depend speciﬁc properties target ma-chine. maximize performance program, programmer compiler require model target machine, specifying instructions areprocessed timing characteristics different operations. example, compiler must know timing information able decide whether shoulduse multiply instruction combination shifts adds. Modern com- puters use sophisticated techniques process machine-level program, executingmany instructions parallel possibly different order appear inthe program. Programmers must understand processors work beable tune programs maximum speed. present high-level modelof machine based recent designs Intel AMD processors. alsodevise graphical data-ﬂow notation visualize execution instructions processor, predict program performance. understanding processor operation, take second step program optimization, exploiting capability processors provideinstruction-level parallelism , executing multiple instructions simultaneously. cover several program transformations reduce data dependencies be-tween different parts computation, increasing degree parallelism withwhich executed. conclude chapter discussing issues related optimizing large pro- grams. describe use code proﬁlers —tools measure performance different parts program. analysis help ﬁnd inefﬁciencies codeand identify parts program focus optimizationefforts. Finally, present important observation, known Amdahl’s law , quantiﬁes overall effect optimizing portion system. presentation, make code optimization look like simple linear process applying series transformations code particular order.In fact, task nearly straightforward. fair amount trial-and-error experimentation required. especially true approach lateroptimization stages, seemingly small changes cause major changes inperformance, promising techniques prove ineffective. wewill see examples follow, difﬁcult explain exactly aparticular code sequence particular execution time. Performance dependon many detailed features processor design relativelylittle documentation understanding. another reason try number ofdifferent variations combinations techniques.476 Chapter 5 Optimizing Program Performance Studying assembly-code representation program one effective means gaining understanding compiler gen-erated code run. good strategy start looking carefully codefor inner loops, identifying performance-reducing attributes excessivememory references poor use registers. Starting assembly code, wecan also predict operations performed parallel well theywill use processor resources. see, often determine time(or least lower bound time) required execute loop identifyingcritical paths , chains data dependencies form repeated executions loop. go back modify source code try steer thecompiler toward efﬁcient implementations. major compilers, including gcc, continually updated im- proved, especially terms optimization abilities. One useful strategy todo much rewriting program required get point compiler generate efﬁcient code. means, avoid compro-mising readability, modularity, portability code much work compiler minimal capabilities. Again, helps iterativelymodify code analyze performance measurements byexamining generated assembly code. novice programmers, might seem strange keep modifying source code attempt coax compiler generating efﬁcient code, thisis indeed many high-performance programs written. Compared thealternative writing code assembly language, indirect approach theadvantage resulting code still run machines, although per-haps peak performance. 5.1 Capabilities Limitations Optimizing Compilers Modern compilers employ sophisticated algorithms determine values arecomputed program used. exploit opportuni-ties simplify expressions, use single computation several different places,and reduce number times given computation must performed. Mostcompilers, including gcc, provide users control optimiza- tions apply. discussed Chapter 3, simplest control specify theoptimization level . example, invoking gcc command-line ﬂag ‘ -O1’ cause apply basic set optimizations. discussed Web Asideasm:opt , invoking gccwith ﬂag ‘ -O2’o r‘-O3’ cause apply extensive optimizations. improve program performance, may ex-pand program size may make program difﬁcult debug using standard debugging tools. presentation, mostly consider code compiled optimization level 1, even though optimization level 2 becomethe accepted standard gcc users. purposely limit level opti- mization demonstrate different ways writing function C affectthe efﬁciency code generated compiler. ﬁnd writeC code that, compiled optimization level 1, vastly outperforms amore naive version compiled highest possible optimization levels.Section 5.1 Capabilities Limitations Optimizing Compilers 477 Compilers must careful apply safe optimizations program, meaning resulting program exact behavior wouldan unoptimized version possible cases program may encounter, tothe limits guarantees provided C language standards. Constrainingthe compiler perform safe optimizations eliminates possible sources ofundesired run-time behavior, also means programmer must makemore effort write programs way compiler transforminto efﬁcient machine-level code. appreciate challenges deciding whichprogram transformations safe not, consider following two procedures: 1void twiddle1(int *xp, int *yp) 2{ 3 *xp += *yp; 4 *xp += *yp; 5} 6 7void twiddle2(int *xp, int *yp) 8{ 9 *xp += 2* *yp; 10 } ﬁrst glance, procedures seem identical behavior. add twice value stored location designated pointer ypto desig- nated pointer xp. hand, function twiddle2 efﬁcient. requires three memory references (read *xp, read *yp, write *xp), whereas twiddle1 requires six (two reads *xp, two reads *yp, two writes *xp). Hence, compiler given procedure twiddle1 compile, one might think could generate efﬁcient code based computations performed bytwiddle2 . Consider, however, case xpandypare equal. function twiddle1 perform following computations: 3 *xp += *xp; /* Double value xp */ 4 *xp += *xp; /* Double value xp */ result value xpwill increased factor 4. hand, function twiddle2 perform following computation: 9 *xp += 2* *xp; /* Triple value xp */ result value xpwill increased factor 3. compiler knows nothing twiddle1 called, must assume arguments xpandypcan equal. therefore cannot generate code style oftwiddle2 optimized version twiddle1 . case two pointers may designate memory location known memory aliasing . performing safe optimizations, compiler478 Chapter 5 Optimizing Program Performance must assume different pointers may aliased. another example, program pointer variables pandq, consider following code sequence: x = 1000 ; = 3000; * q=y ; /* 3000 */ * p=x ; /* 1000 */ t1 = *q; /* 1000 3000 */ value computed t1depends whether pointers pandqare aliased—if not, equal 3000, equal 1000. leads oneof major optimization blockers , aspects programs severely limit opportunities compiler generate optimized code. compiler cannotdetermine whether two pointers may aliased, must assume eithercase possible, limiting set possible optimizations. Practice Problem 5.1 following problem illustrates way memory aliasing cause unexpected program behavior. Consider following procedure swap two values: 1/* Swap value x xp value yp */ 2void swap(int *xp, int *yp) 3{ 4 *xp = *xp + *yp; /* x+y */ 5 *yp = *xp - *yp; /* x+y- y=x* / 6 *xp = *xp - *yp; /* x+y- x=y* / 7} procedure called xpequal yp, effect have? second optimization blocker due function calls. example, con- sider following two procedures: 1int f(); 2 3int func1() { 4 return f() + f() + f() + f(); 5} 6 7int func2() { 8 return 4*f(); 9} might seem ﬁrst compute result, func2 calling f once, whereas func1 calls four times. tempting generate code style func2 given func1 source.Section 5.1 Capabilities Limitations Optimizing Compilers 479 Consider, however, following code f: 1int counter = 0; 2 3int f() { 4 return counter++; 5} function side effect —it modiﬁes part global program state. Changing number times gets called changes program behavior. Inparticular, call func1 would return 0 +1+2+3=6, whereas call func2 would return 4 .0=0, assuming started global variable counter set 0. compilers try determine whether function free side ef- fects hence candidate optimizations attempted func2 . Instead, compiler assumes worst case leaves function calls intact. Aside Optimizing function calls inline substitution described Web Aside asm:opt , code involving function calls optimized process known asinline substitution (or simply “inlining”), function call replaced code body function. example, expand code func1 substituting four instantiations function f: 1/* Result inlining f func1 */ 2int func1in() { 3 int = counter++; /* +0 */ 4 += counter++; /* +1 */ 5 += counter++; /* +2 */ 6 += counter++; /* +3 */ 7 return t; 8} transformation reduces overhead function calls allows optimization expanded code. example, compiler consolidate updates global variable counter infunc1in generate optimized version function: 1/* Optimization inlined code */ 2int func1opt() { 3 n tt=4* counter + 6; 4 counte r=t+4 ; 5 return t; 6} code faithfully reproduces behavior func1 particular deﬁnition function f. Recent versions gcc attempt form optimization, either directed command-line option ‘ -finline ’ optimization levels 2 higher. Since considering optimization level 1 presentation, assume compiler perform inline substitution.480 Chapter 5 Optimizing Program Performance Among compilers, gccis considered adequate, exceptional, terms optimization capabilities. performs basic optimizations, per-form radical transformations programs “aggressive” compilersdo. consequence, programmers using gccmust put effort writing programs way simpliﬁes compiler’s task generating efﬁcient code. 5.2 Expressing Program Performance introduce metric cycles per element , abbreviated “CPE,” way express program performance way guide us improving code.CPE measurements help us understand loop performance iterative program detailed level. appropriate programs perform repetitive computation, processing pixels image computing elementsin matrix product. sequencing activities processor controlled clock providing regular signal frequency, usually expressed gigahertz (GHz), billions cycles per second. example, product literature characterizes system “4 GHz” processor, means processor clock runs 4 .0×10 9cycles per second. time required clock cycle given reciprocal ofthe clock frequency. typically expressed nanoseconds (1 nanosecond 10 −9seconds), picoseconds (1 picosecond 10−12seconds). example, period f 4 GHz clock expressed either 0.25 nanoseconds 250 picoseconds. programmer’s perspective, instructive expressmeasurements clock cycles rather nanoseconds picoseconds. way,the measurements express many instructions executed rather thanhow fast clock runs. Many procedures contain loop iterates set elements. example, functions psum1 andpsum2 Figure 5.1 compute preﬁx sum vector length n. vector /vectora=/angbracketlefta 0,a1,...,a n−1/angbracketright, preﬁx sum /vectorp= /angbracketleftp0,p1,...,pn−1/angbracketrightis deﬁned p0=a0 pi=pi−1+ai,1≤i<n(5.1) Function psum1 computes one element result vector per iteration. second uses technique known loop unrolling compute two elements per iteration. explore beneﬁts loop unrolling later chapter. SeeProblems 5.11, 5.12, 5.21 analyzing optimizing preﬁx-sum computation. time required procedure characterized constant plus factor proportional number elements processed. example, Figure 5.2 shows plot number clock cycles required two functions arange values n. Using least squares ﬁt , ﬁnd run times (in clock cycles) psum1 andpsum2 approximated equations 496 +10.0n 500 +6.5n, respectively. equations indicate overhead 496 5001/* Compute prefix sum vector */ 2void psum1(float a[], float p[], long int n) 3{ 4 long int i; 5 p[0] = a[0]; 6 f r( i=1 ;i<n ; i++) 7 p[i] = p[i-1] + a[i]; 8} 9 10 void psum2(float a[], float p[], long int n) 11 { 12 long int i; 13 p[0] = a[0]; 14 (i = 1; < n-1; i+=2) { 15 float mid_val = p[i-1] + a[i]; 16 p[i] = mid_val; 17 p[i+1] = mid_val + a[i+1]; 18 } 19 /* odd n, finish remaining element */ 20 (i < n) 21 p[i] = p[i-1] + a[i]; 22 } Figure 5.1 Preﬁx-sum functions. provide examples express program performance. 3000 25002000 1500 1000 500 0 05 0psum1 Slope = 10.0 psum2 Slope = 6.5 100 150 200 ElementsCycles Figure 5.2 Performance preﬁx-sum functions. slope lines indicates number clock cycles per element (CPE).482 Chapter 5 Optimizing Program Performance cycles due timing code initiate procedure, set loop, complete procedure, plus linear factor 6.5 10.0 cycles per element. Forlarge values n(say, greater 200), run times dominated linear factors. refer coefﬁcients terms effective number ofcycles per element , abbreviated “CPE.” prefer measuring number cycles perelement rather number cycles per iteration , techniques loop unrolling allow us use fewer iterations complete computation,but ultimate concern fast procedure run given vector length. focus efforts minimizing CPE computations. thismeasure, psum2 , CPE 6.50, superior psum1 , CPE 10.0. Aside least squares ﬁt? set data points (x1,y1), . . . (x n,yn), often try draw line best approximates X-Y trend represented data. least squares ﬁt, look line form y=mx+bthat minimizes following error measure: E(m, b) =/summationdisplay i=1,n(mxi+b−yi)2 algorithm computing mandbcan derived ﬁnding derivatives E(m, b) respect tomandband setting 0. Practice Problem 5.2 Later chapter, start single function generate many differ- ent variants preserve function’s behavior, different performancecharacteristics. three variants, found run times (in clockcycles) approximated following functions: Version 1: 60 +35n Version 2: 136 +4n Version 3: 157 +1.25n values nwould version fastest three? Remember thatnwill always integer. 5.3 Program Example demonstrate abstract program systematically transformed efﬁcient code, use running example based vector data structure shown Figure 5.3. vector represented two blocks memory: header data array. header structure declared follows:Section 5.3 Program Example 483 012lenlen/H110021 len data . . . Figure 5.3 Vector abstract data type. vector represented header information plus array designated length. code/opt/vec.h 1/* Create abstract data type vector */ 2typedef struct { 3 long int len; 4 data_t *data; 5} vec_rec, *vec_ptr; code/opt/vec.h declaration uses data type data_t designate data type un- derlying elements. evaluation, measure performance code forinteger (C int), single-precision ﬂoating-point (C float ), double-precision ﬂoating-point (C double ) data. compiling running program separately different type declarations, following data type int: typedef int data_t; allocate data array block store vector elements array lenobjects type data_t . Figure 5.4 shows basic procedures generating vectors, accessing vec- tor elements, determining length vector. important feature noteis get_vec_element , vector access routine, performs bounds checking every vector reference. code similar array representations used inmany languages, including Java. Bounds checking reduces chances ofprogram error, also slow program execution. optimization example, consider code shown Figure 5.5, combines elements vector single value according someoperation. using different deﬁnitions compile-time constants IDENT OP, code recompiled perform different operations data. particular, using declarations #define IDENT 0 #define OP + sums elements vector. Using declarations #define IDENT 1 #define OP * computes product vector elements. presentation, proceed series transformations code, writing different versions combining function. gauge progress,484 Chapter 5 Optimizing Program Performance code/opt/vec.c 1/* Create vector specified length */ 2vec_ptr new_vec(long int len) 3{ 4 /* Allocate header structure */ 5 vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec)); 6 (!result) 7 return NULL; /* Couldn’t allocate storage */ 8 result->len = len; 9 /* Allocate array */ 10 (len > 0) { 11 data_t *data = (data_t *)calloc(len, sizeof(data_t)); 12 (!data) { 13 free((void *) result); 14 return NULL; /* Couldn’t allocate storage */ 15 } 16 result->data = data; 17 } 18 else 19 result->data = NULL; 20 return result; 21 } 22 23 /* 24 * Retrieve vector element store dest. 25 * Return 0 (out bounds) 1 (successful) 26 */ 27 int get_vec_element(vec_ptr v, long int index, data_t *dest) 28 { 29 (inde x<0| | index >= v->len) 30 return 0; 31 *dest = v->data[index]; 32 return 1; 33 } 34 35 /* Return length vector */ 36 long int vec_length(vec_ptr v) 37 { 38 return v->len; 39 } code/opt/vec.c Figure 5.4 Implementation vector abstract data type. actual program, data typedata_t declared int ,float ,o rdouble .Section 5.3 Program Example 485 1/* Implementation maximum use data abstraction */ 2void combine1(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 6 *dest = IDENT; 7 (i = 0; < vec_length(v); i++) { 8 data_t val; 9 get_vec_element(v, i, &val); 10 *dest = *dest OP val; 11 } 12 } Figure 5.5 Initial implementation combining operation. Using different declara- tions identity element IDENT combining operation OP, measure routine different operations. measure CPE performance functions machine Intel Core i7 processor, refer reference machine . characteristics processor given Section 3.1. measurementscharacterize performance terms programs run one particularmachine, guarantee comparable performance othercombinations machine compiler. However, compared resultswith number different compiler/processor combinations foundthem quite comparable. proceed set transformations, ﬁnd many lead minimal performance gains, others dramatic effects. Determining combinations transformations apply indeed part ofthe “black art” writing fast code. combinations provide measurable beneﬁts indeed ineffective, others important ways toenable optimizations compiler. experience, best approachinvolves combination experimentation analysis: repeatedly attemptingdifferent approaches, performing measurements, examining assembly-code representations identify underlying performance bottlenecks. starting point, following CPE measurements combine1 run- ning reference machine, trying combinations data type combiningoperation. single-precision double-precision ﬂoating-point data, ex-periments machine gave identical performance addition, differingperformance multiplication. therefore report ﬁve CPE values: integer ad-dition multiplication, ﬂoating-point addition, single-precision multiplication(labeled “F *”), double-precision multiplication (labeled “D *”). Integer Floating point Function Page Method +*+ F* D* combine1 485 Abstract unoptimized 29.02 29.21 27.40 27.90 27.36 combine1 485 Abstract -O1 12.00 12.00 12.00 12.01 13.00486 Chapter 5 Optimizing Program Performance see measurements somewhat imprecise. likely CPE number integer sum product 29.00, rather 29.02 29.21.Rather “fudging” numbers make look good, present themeasurements actually obtained. many factors complicate thetask reliably measuring precise number clock cycles required somecode sequence. helps examining numbers mentally round theresults hundredths clock cycle. unoptimized code provides direct translation C code machine code, often obvious inefﬁciencies. simply giving command-line option‘-O1’, enable basic set optimizations. seen, signiﬁcantly improves program performance—more factor two—with efforton behalf programmer. general, good get habit enablingat least level optimization. remainder measurements, useoptimization levels 1 higher generating measuring programs. 5.4 Eliminating Loop Inefﬁciencies Observe procedure combine1 , shown Figure 5.5, calls function vec_ length test condition forloop. Recall discussion translate code containing loops machine-level programs (Section 3.6.5)that test condition must evaluated every iteration loop. theother hand, length vector change loop proceeds. Wecould therefore compute vector length use value testcondition. Figure 5.6 shows modiﬁed version called combine2 , calls vec_length beginning assigns result local variable length . transfor- mation noticeable effect overall performance data types 1/* Move call vec_length loop */ 2void combine2(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 7 *dest = IDENT; 8 (i = 0; < length; i++) { 9 data_t val; 10 get_vec_element(v, i, &val); 11 *dest = *dest OP val; 12 } 13 } Figure 5.6 Improving efﬁciency loop test. moving call vec_ length loop test, eliminate need execute every iteration.Section 5.4 Eliminating Loop Inefﬁciencies 487 operations, minimal even none others. case, transformation required eliminate inefﬁciencies would become bottlenecks attemptfurther optimizations. Integer Floating point Function Page Method +*+ F* D* combine1 485 Abstract -O1 12.00 12.00 12.00 12.01 13.00 combine2 486 Move vec_length 8.03 8.09 10.09 11.09 12.08 optimization instance general class optimizations known code motion . involve identifying computation performed multiple times (e.g., within loop), result computation notchange. therefore move computation earlier section codethat get evaluated often. case, moved call vec_length within loop loop. Optimizing compilers attempt perform code motion. Unfortunately, dis- cussed previously, typically cautious making transformationsthat change many times procedure called. cannot reliablydetect whether function side effects, assume thatit might. example, vec_length side effect, combine1 combine2 could different behaviors. improve code, programmer must often help compiler explicitly performing code motion. extreme example loop inefﬁciency seen combine1 , consider procedure lower1 shown Figure 5.7. procedure styled routines sub- mitted several students part network programming project. purposeis convert uppercase letters string lowercase. proceduresteps string, converting uppercase character lowercase. Thecase conversion involves shifting characters range ‘ A’t o‘Z’ range ‘ a’ ‘z.’ library function strlen called part loop test lower1 . Al- though strlen typically implemented special x86 string-processing instruc- tions, overall execution similar simple version also shown inFigure 5.7. Since strings C null-terminated character sequences, strlen determine length string stepping sequence ithits null character. string length n,strlen takes time proportional n. Since strlen called niterations lower1 , overall run time oflower1 quadratic string length, proportional n 2. analysis conﬁrmed actual measurements functions differ- ent length strings, shown Figure 5.8 (and using library version strlen ). graph run time lower1 rises steeply string length increases (Figure 5.8(a)). Figure 5.8(b) shows run times seven different lengths (notthe shown graph), power 2. Observe forlower1 doubling string length causes quadrupling run time. clear indicator quadratic run time. string length 1,048,576,lower1 requires 13 minutes CPU time.488 Chapter 5 Optimizing Program Performance 1/* Convert string lowercase: slow */ 2void lower1(char *s) 3{ 4 int i; 5 6 (i = 0; < strlen(s); i++) 7 (s[i] >= ’A’ && s[i] <= ’Z’) 8 s[i] -= (’A’ - ’a’); 9} 1011 /* Convert string lowercase: faster */ 12 void lower2(char *s) 13 { 14 int i; 15 int len = strlen(s); 1617 (i = 0; < len; i++) 18 (s[i] >= ’A’ && s[i] <= ’Z’) 19 s[i] -= (’A’ - ’a’); 20 } 2122 /* Sample implementation library function strlen */ 23 /* Compute length string */ 24 size_t strlen(const char *s) 25 { 26 int length = 0; 27 (*s != ’\0’) { 28 s++; 29 length++; 30 } 31 return length; 32 } Figure 5.7 Lowercase conversion routines. two procedures radically different performance. Function lower2 shown Figure 5.7 identical lower1 , except moved call strlen loop. performance im- proves dramatically. string length 1,048,576, function requires 1.5milliseconds—over 500,000 times faster lower1 . doubling string length causes doubling run time—a clear indicator linear run time. Forlonger strings, run-time improvement even greater. ideal world, compiler would recognize call strlen loop test return result, thus call could moved loop. would require sophisticated analysis, since strlen checksSection 5.4 Eliminating Loop Inefﬁciencies 489 200 180160140120 100 80604020 0 0 100,000 200,000 300,000 400,000 500,000 String lengthCPU secondslower1 lower2 (a) String length Function 16,384 32,768 65,536 131,072 262,144 524,288 1,048,576 lower1 0.19 0.77 3.08 12.34 49.39 198.42 791.22 lower2 0.0000 0.0000 0.0001 0.0002 0.0004 0.0008 0.0015 (b) Figure 5.8 Comparative performance lowercase conversion routines. original codelower1 quadratic run time due inefﬁcient loop structure. modiﬁed codelower2 linear run time. elements string values changing lower1 proceeds. compiler would need detect even though characters within string arechanging, none set nonzero zero, vice versa. analysisis well beyond ability even sophisticated compilers, even theyemploy inlining, programmers must transformations themselves. example illustrates common problem writing programs, seemingly trivial piece code hidden asymptotic inefﬁciency. One wouldnot expect lowercase conversion routine limiting factor program’sperformance. Typically, programs tested analyzed small data sets, performance lower1 adequate. program ultimately deployed, however, entirely possible procedure could applied tostrings one million characters. sudden benign piece codehas become major performance bottleneck. contrast, performance oflower2 adequate strings arbitrary length. Stories abound major programming projects problems sort occur. Part job acompetent programmer avoid ever introducing asymptotic inefﬁciency.490 Chapter 5 Optimizing Program Performance Practice Problem 5.3 Consider following functions: int min(int x, int y) { retur nx<y?x:y ;} int max(int x, int y) { retur nx<y?y:x ;} void incr(int *xp, int v) { *xp += v; }int square(int x) { return x*x; } following three code fragments call functions: A. (i = min(x, y) ; < max(x, y); incr(&i, 1)) += square(i); B. (i = max(x, y) - 1; >= min(x, y); incr(&i, -1)) += square(i); C. int low = min(x, y);int high = max(x, y); (i = low; < high; incr(&i, 1)) += square(i); Assume xequals 10 yequals 100. Fill following table indicating number times four functions called code fragments A–C: Code min max incr square A. B. C. 5.5 Reducing Procedure Calls seen, procedure calls incur overhead also block forms ofprogram optimization. see code combine2 (Figure 5.6) get_ vec_element called every loop iteration retrieve next vector element. function checks vector index iagainst loop bounds every vector reference, clear source inefﬁciency. Bounds checking might useful featurewhen dealing arbitrary array accesses, simple analysis code combine2 shows references valid. Suppose instead add function get_vec_start abstract data type. function returns starting address data array, shown inFigure 5.9. could write procedure shown combine3 ﬁgure, function calls inner loop. Rather making function call toretrieve vector element, accesses array directly. purist might say thatthis transformation seriously impairs program modularity. principle, theuser vector abstract data type even need know vectorSection 5.6 Eliminating Unneeded Memory References 491 code/opt/vec.c 1data_t *get_vec_start(vec_ptr v) 2{ 3 return v->data; 4} code/opt/vec.c 1/* Direct access vector data */ 2void combine3(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 data_t *data = get_vec_start(v); 7 8 *dest = IDENT; 9 (i = 0; < length; i++) { 10 *dest = *dest OP data[i]; 11 } 12 } Figure 5.9 Eliminating function calls within loop. resulting code runs much faster, cost program modularity. contents stored array, rather data structure linked list. pragmatic programmer would argue transformation necessary step toward achieving high-performance results. Integer Floating point Function Page Method +* + F* D* combine2 486 Move vec_length 8.03 8.09 10.09 11.09 12.08 combine3 491 Direct data access 6.01 8.01 10.01 11.01 12.02 resulting improvement surprisingly modest, improving per- formance integer sum. Again, however, inefﬁciency would become bot-tleneck attempt optimizations. return function later(Section 5.11.2) see repeated bounds checking combine2 make performance much worse. applications performance sig- niﬁcant issue, one must often compromise modularity abstraction speed. wise include documentation transformations applied, well theassumptions led them, case code needs modiﬁed later. 5.6 Eliminating Unneeded Memory References code combine3 accumulates value computed combining operation location designated pointer dest . attribute seen examining assembly code generated compiled loop. show492 Chapter 5 Optimizing Program Performance x86-64 code generated data type float multiplication combining operation: combine3: data_t = float, OP = * ii n %rdx, data %rax, dest %rbp 1.L498: loop: 2 movss (%rbp), %xmm0 Read product dest 3 mulss (%rax,%rdx,4), %xmm0 Multiply product data[i] 4 movss %xmm0, (%rbp) Store product dest 5 addq $1, %rdx Increment 6 cmpq %rdx, %r12 Compare i:limit 7 jg .L498 >, goto loop Aside Understanding x86-64 ﬂoating-point code cover ﬂoating-point code x86-64, 64-bit version Intel instruction set Web Aside asm:sse , program examples show chapter readily understood anyone familiar IA32 code. Here, brieﬂy review relevant aspects x86-64 ﬂoating-pointinstructions. x86-64 instruction set extends 32-bit registers IA32, %eax ,%edi , %esp ,t 64-bit versions, ‘ r’ replacing ‘ e’, e.g., %rax ,%rdi , %rsp . Eight registers available, named %r8–%r15 , greatly improving ability hold temporary values registers. Sufﬁx ‘ q’ used integer instructions (e.g., addq ,cmpq ) indicate 64-bit operations. Floating-point data held set XMM registers, named %xmm0 –%xmm15 . registers 128 bits long, able hold four single-precision ( float ) two double-precision ( double ) ﬂoating-point numbers. initial presentation, make use instructions operate single values held SSE registers. Themovss instruction copies one single-precision number. Like various mov instructions IA32, source destination memory locations registers, uses XMM registers, rather general-purpose registers. mulss instruction multiplies single-precision num- bers, updating second operand product. Again, source destination operands memory locations XMM registers. see loop code address corresponding pointer dest held register %rbp (unlike IA32, %ebp special use frame pointer, 64-bit counterpart %rbp used hold arbitrary data). iteration i, program reads value location, multiplies data[ i], stores result back dest . reading writing wasteful, since value read dest beginning iteration simply value written end previous iteration. eliminate needless reading writing memory rewriting code style combine4 Figure 5.10. introduce temporary variable accthat used loop accumulate computed value. result stored atdest loop completed. assembly code follows shows, compiler use register %xmm0 hold accumulated value.Section 5.6 Eliminating Unneeded Memory References 493 1/* Accumulate result local variable */ 2void combine4(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 data_t *data = get_vec_start(v); 7 data_t acc = IDENT; 8 9 (i = 0; < length; i++) { 10 acc = acc OP data[i]; 11 } 12 *dest = acc; 13 } Figure 5.10 Accumulating result temporary. Holding accumulated value local variable acc (short “accumulator”) eliminates need retrieve memory write back updated value every loop iteration. Compared loop combine3 , reduced memory operations per iteration two reads one write single read. combine4: data_t = float, OP = * ii n %rdx, data %rax, limit %rbp, acc %xmm0 1.L488: loop: 2 mulss (%rax,%rdx,4), %xmm0 Multiply acc data[i] 3 addq $1, %rdx Increment 4 cmpq %rdx, %rbp Compare limit:i 5 jg .L488 >, goto loop see signiﬁcant improvement program performance, shown following table: Integer Floating point Function Page Method +* + F* D* combine3 491 Direct data access 6.01 8.01 10.01 11.01 12.02 combine4 493 Accumulate temporary 2.00 3.00 3.00 4.00 5.00 times improve least factor 2.4 ×, integer addition case dropping two clock cycles per element. Aside Expressing relative performance best way express performance improvement ratio form Told/Tnew, Toldis time required original version Tnewis time required modiﬁed version. number greater 1.0 real improvement occurred. use sufﬁx ‘ ×’ indicate ratio, factor “2.4 ×” expressed verbally “2.4 times.”494 Chapter 5 Optimizing Program Performance traditional way expressing relative change percentage works well change small, deﬁnition ambiguous. 100 .(Told−Tnew)/T newor possibly 100 .(Told− Tnew)/T old, something else? addition, less instructive large changes. Saying “perfor- mance improved 140%” difﬁcult comprehend simply saying performanceimproved factor 2.4. Again, one might think compiler able automatically trans- form combine3 code shown Figure 5.9 accumulate value register, code combine4 shown Figure 5.10. fact, however, two functions different behaviors due memory aliasing. Consider, example, case integer data multiplication operation 1 theidentity element. Let v=[2,3,5] vector three elements consider following two function calls: combine3(v, get_vec_start(v) + 2); combine4(v, get_vec_start(v) + 2); is, create alias last element vector destina- tion storing result. two functions would execute follows: Function Initial loop i=0 i=1 i=2 Final combine3 [2,3,5] [2 ,3,1] [2 ,3,2] [2 ,3,6] [2 ,3,36] [2 ,3,36] combine4 [2,3,5] [2 ,3,5] [2 ,3,5] [2 ,3,5] [2 ,3,5] [2 ,3,30] shown previously, combine3 accumulates result destination, case ﬁnal vector element. value therefore set ﬁrst to1, 2 .1=2, 3 .2=6. ﬁnal iteration, value multiplied yield ﬁnal value 36. case combine4 , vector remains unchanged end, ﬁnal element set computed result 1 .2.3.5=30. course, example showing distinction combine3 combine4 highly contrived. One could argue behavior combine4 closely matches intention function description. Unfortunately, acompiler cannot make judgment conditions functionmight used programmer’s intentions might be. Instead, whengiven combine3 compile, conservative approach keep reading writing memory, even though less efﬁcient. Practice Problem 5.4 use gccto compile combine3 command-line option ‘ -O2’, get code substantially better CPE performance -O1:Section 5.6 Eliminating Unneeded Memory References 495 Integer Floating point Function Page Method +* + F* D* combine3 491 Compiled -O1 6.01 8.01 10.01 11.01 12.02 combine3 491 Compiled -O2 3.00 3.00 3.00 4.02 5.03 combine4 493 Accumulate temporary 2.00 3.00 3.00 4.00 5.00 achieve performance comparable combine4 , except case integer sum, even improves signiﬁcantly. examining assembly codegenerated compiler, ﬁnd interesting variant inner loop: combine3: data_t = float, OP = *, compiled -O2 ii n %rdx, data %rax, limit %rbp, dest %rx12 Product %xmm0 1.L560: loop: 2 mulss (%rax,%rdx,4), %xmm0 Multiply product data[i] 3 addq $1, %rdx Increment 4 cmpq %rdx, %rbp Compare limit:i 5 movss %xmm0, (%r12) Store product dest 6 jg .L560 >, goto loop compare version created optimization level 1: combine3: data_t = float, OP = *, compiled -O1 ii n %rdx, data %rax, dest %rbp 1.L498: loop: 2 movss (%rbp), %xmm0 Read product dest 3 mulss (%rax,%rdx,4), %xmm0 Multiply product data[i] 4 movss %xmm0, (%rbp) Store product dest 5 addq $1, %rdx Increment 6 cmpq %rdx, %r12 Compare i:limit 7 jg .L498 >, goto loop see that, besides reordering instructions, difference optimized version contain movss implementing read location designated dest (line 2). A. role register %xmm0 differ two loops? B. optimized version faithfully implement C code com- bine3 , including memory aliasing dest vector data? C. Explain either optimization preserves desired behavior, give example would produce different results less optimizedcode.496 Chapter 5 Optimizing Program Performance ﬁnal transformation, reached point require 2–5 clock cycles element computed. considerable improvementover original 11–13 cycles ﬁrst enabled optimization. would nowlike see factors constraining performance code howwe improve things even further. 5.7 Understanding Modern Processors point, applied optimizations rely featuresof target machine. simply reduced overhead procedure calls andeliminated critical “optimization blockers” cause difﬁcultiesfor optimizing compilers. seek push performance further, mustconsider optimizations exploit microarchitecture processor, is, underlying system design processor executes instructions. Gettingevery last bit performance requires detailed analysis program well ascode generation tuned target processor. Nonetheless, apply somebasic optimizations yield overall performance improvement largeclass processors. detailed performance results report may holdfor machines, general principles operation optimization applyto wide variety machines. understand ways improve performance, require basic understand- ing microarchitectures modern processors. Due large number transistors integrated onto single chip, modern microprocessors em-ploy complex hardware attempts maximize program performance. Oneresult actual operation far different view perceivedby looking machine-level programs. code level, appears instruc-tions executed one time, instruction involves fetching valuesfrom registers memory, performing operation, storing results back toa register memory location. actual processor, number instructionsare evaluated simultaneously, phenomenon referred instruction-level paral- lelism . designs, 100 instructions “in ﬂight.” Elaborate mechanisms employed make sure behavior parallel executionexactly captures sequential semantic model required machine-levelprogram. one remarkable feats modern microprocessors: theyemploy complex exotic microarchitectures, multiple instructions canbe executed parallel, presenting operational view simple sequentialinstruction execution. Although detailed design modern microprocessor well beyond scope book, general idea principles operate sufﬁces understand achieve instruction-level parallelism. Wewill ﬁnd two different lower bounds characterize maximum performanceof program. latency bound encountered series operations must performed strict sequence, result one operation isrequired next one begin. bound limit program performancewhen data dependencies code limit ability processor toSection 5.7 Understanding Modern Processors 497 Figure 5.11 Block diagram amodern processor. instruction control unitis responsible reading instructions memory generating sequenceof primitive operations.The execution unit performs operations indicates whether thebranches correctlypredicted.Instruction control Address InstructionsRetirement unitFetch control Instruction decode OperationsInstruction cache Prediction OK?Register updates Operation results Addr. Addr. Data Data Data cache ExecutionFunctional unitsStore LoadFP add +integerFP mul/div +integerBranch +integerRegister file exploit instruction-level parallelism. throughput bound characterizes raw computing capacity processor’s functional units. bound becomes theultimate limit program performance. 5.7.1 Overall Operation Figure 5.11 shows simpliﬁed view modern microprocessor. hy- pothetical processor design based loosely structure Intel Core i7processor design, often referred project code name “Nehalem”[99]. Nehalem microarchitecture typiﬁes high-end processors produced number manufacturers since late 1990s. described industry superscalar , means perform multiple operations every clock cycle, out-of-order , meaning order instructions execute need correspond ordering machine-level program. overall designhas two main parts: instruction control unit (ICU), responsible reading sequence instructions memory generating setof primitive operations perform program data, execution unit (EU), executes operations. Compared simple in-order pipeline studied Chapter 4, out-of-order processors require far greater more498 Chapter 5 Optimizing Program Performance complex hardware, better achieving higher degrees instruction- level parallelism. ICU reads instructions instruction cache —a special high- speed memory containing recently accessed instructions. general,the ICU fetches well ahead currently executing instructions, hasenough time decode send operations EU. One problem, however, program hits branch, 1there two possible directions program might go. branch taken , control passing branch target. Alternatively, branch taken , control passing next instruction instruction sequence. Modern processors employ techniqueknown branch prediction , guess whether branch taken also predict target address branch. Using technique knownasspeculative execution , processor begins fetching decoding instructions predicts branch go, even begins executing operationsbefore determined whether branch prediction correct.If later determines branch predicted incorrectly, resets stateto branch point begins fetching executing instructions theother direction. block labeled “Fetch control” incorporates branch predictionto perform task determining instructions fetch. instruction decoding logic takes actual program instructions con- verts set primitive operations (sometimes referred micro- operations ). operations performs simple computational task adding two numbers, reading data memory, writing data mem-ory. machines complex instructions, x86 processors, instructioncan decoded variable number operations. details instruc-tions decoded sequences primitive operations varies betweenmachines, information considered highly proprietary. Fortunately, wecan optimize programs without knowing low-level details particularmachine implementation. typical x86 implementation, instruction operates registers, addl %eax,%edx converted single operation. hand, instruction involvingone memory references, addl %eax,4(%edx) yields multiple operations, separating memory references arithmeticoperations. particular instruction would decoded three operations: onetoload value memory processor, one add loaded value 1. use term “branch” speciﬁcally refer conditional jump instructions. instructions transfer control multiple destinations, procedure return indirect jumps, provide similar challenges processor.Section 5.7 Understanding Modern Processors 499 value register %eax , one store result back memory. decoding splits instructions allow division labor among set dedicated hardwareunits. units execute different parts multiple instructions inparallel. EU receives operations instruction fetch unit. Typically, receive number clock cycle. operations dispatched toa set functional units perform actual operations. functional units specialized handle speciﬁc types operations. ﬁgure illustrates typicalset functional units, based Intel Core i7. see threefunctional units dedicated computation, remaining two forreading (load) writing (store) memory. computational unit performmultiple different operations: perform least basic integer operations,such addition bit-wise logical operations. Floating-point operations andinteger multiplication require complex hardware, behandled speciﬁc functional units. Reading writing memory implemented load store units. load unit handles operations read data memory processor.This unit adder perform address computations. Similarly, store unithandles operations write data processor memory. also hasan adder perform address computations. shown ﬁgure, load andstore units access memory via data cache , high-speed memory containing recently accessed data values. speculative execution, operations evaluated, ﬁnal results stored program registers data memory processor certain instructions actually executed. Branchoperations sent EU, determine branch go, butrather determine whether predicted correctly. predictionwas incorrect, EU discard results computed beyond thebranch point. also signal branch unit prediction incorrectand indicate correct branch destination. case, branch unit beginsfetching new location. saw Section 3.6.6, misprediction incurs signiﬁcant cost performance. takes new instructions canbe fetched, decoded, sent execution units. Within ICU, retirement unit keeps track ongoing processing makes sure obeys sequential semantics machine-level program.Our ﬁgure shows register ﬁle containing integer, ﬂoating-point, recently SSE registers part retirement unit, unit controlsthe updating registers. instruction decoded, information aboutit placed ﬁrst-in, ﬁrst-out queue. information remains queueuntil one two outcomes occurs. First, operations instructionhave completed branch points leading instruction conﬁrmed ashaving correctly predicted, instruction retired , updates program registers made. branch point leading instructionwas mispredicted, hand, instruction ﬂushed , discarding results may computed. means, mispredictions notalter program state.500 Chapter 5 Optimizing Program Performance described, updates program registers occur instructions retired, takes place processor becertain branches leading instruction correctly predicted.To expedite communication results one instruction another, muchof information exchanged among execution units, shown ﬁgure as“Operation results.” arrows ﬁgure show, execution units sendresults directly other. elaborate form data forwardingtechniques incorporated simple processor design Section 4.5.7. common mechanism controlling communication operands among execution units called register renaming . instruction up- dates register ris decoded, tagtis generated giving unique identiﬁer re- sult operation. entry (r, t) added table maintaining association program register rand tag tfor operation update register. subsequent instruction using register ras operand decoded, oper- ation sent execution unit contain tas source operand value. execution unit completes ﬁrst operation, generates result (v, t) indicating operation tag tproduced value v. operation waiting fortas source use vas source value, form data forwarding. mechanism, values forwarded directly one operation another,rather written read register ﬁle, enabling secondoperation begin soon ﬁrst completed. renaming table onlycontains entries registers pending write operations. decodedinstruction requires register r, tag associated register, operand retrieved directly register ﬁle. register renaming, entire sequence operations performed speculatively, even though theregisters updated processor certain branch outcomes. Aside history out-of-order processing Out-of-order processing ﬁrst implemented Control Data Corporation 6600 processor 1964. Instructions processed ten different functional units, could operatedindependently. day, machine, clock rate 10 Mhz, considered premiummachine scientiﬁc computing. IBM ﬁrst implemented out-of-order processing IBM 360/91 processor 1966, execute ﬂoating-point instructions. around 25 years, out-of-order processing considered exotic technology, found machines striving highest possible performance, IBM reintroduced RS/6000 line workstations 1990. design became basis IBM/Motorola PowerPC line, model 601, introduced 1993, becoming ﬁrst single- chip microprocessor use out-of-order processing. Intel introduced out-of-order processing PentiumPro model 1995, underlying microarchitecture similar Core i7. 5.7.2 Functional Unit Performance Figure 5.12 documents performance arithmetic operations Intel Core i7, determined measurements reference Intel liter-Section 5.7 Understanding Modern Processors 501 Integer Single-precision Double-precision Operation Latency Issue Latency Issue Latency Issue Addition 1 0.33 3131 Multiplication 314151 Division 11–21 5–13 10–15 6–11 10–23 6–19 Figure 5.12 Latency issue time characteristics Intel Core i7 arithmetic operations. Latency indicates total number clock cycles required perform actual operations, issue time indicates minimum number cycles betweentwo operations. times division depend data values. ature [26]. timings typical processors well. operation characterized latency , meaning total time required perform op- eration, issue time , meaning minimum number clock cycles two successive operations type. see latencies increase word sizes increase (e.g., single double precision), complex data types (e.g., integer ﬂoating point), complex operations (e.g., addition multiplication). see also forms addition multiplication operations issue times 1, meaning clock cycle, processor start newone operations. short issue time achieved use ofpipelining . pipelined function unit implemented series stages , performs part operation. example, typical ﬂoating-pointadder contains three stages (and hence three-cycle latency): one processthe exponent values, one add fractions, one round result. Thearithmetic operations proceed stages close succession ratherthan waiting one operation complete next begins. capabilitycan exploited successive, logically independent operations tobe performed. Functional units issue times 1 cycle said fully pipelined : start new operation every clock cycle. issue time 0.33 given integer addition due fact hardware three fullypipelined functional units capable performing integer addition. processorhas potential perform three additions every clock cycle. see also thatthe divider (used integer ﬂoating-point division, well ﬂoating-pointsquare root) fully pipelined—its issue time cycles less thanits latency. means divider must complete last fewsteps division begin new one. also see latencies issuetimes division given ranges, combinations dividend anddivisor require steps others. long latency issue times divisionmake comparatively costly operation. common way expressing issue time specify maximum throughput unit, deﬁned reciprocal issue time. fully pipelined functional unit maximum throughput one operation per clock cycle, whileunits higher issue times lower maximum throughput.502 Chapter 5 Optimizing Program Performance Circuit designers create functional units wide ranges performance characteristics. Creating unit short latency pipelining requiresmore hardware, especially complex functions multiplication andﬂoating-point operations. Since limited amount space theseunits microprocessor chip, CPU designers must carefully balance num-ber functional units individual performance achieve optimal overallperformance. evaluate many different benchmark programs dedicatethe resources critical operations. Figure 5.12 indicates, inte-ger multiplication ﬂoating-point multiplication addition consideredimportant operations design Core i7, even though signiﬁcant amountof hardware required achieve low latencies high degree pipelin-ing shown. hand, division relatively infrequent difﬁcult toimplement either short latency full pipelining. latencies issue times (or equivalently, maximum through- put) arithmetic operations affect performance combiningfunctions. express effects terms two fundamental bounds CPE values: Integer Floating point Bound +*+ F* D* Latency 1.00 3.00 3.00 4.00 5.00 Throughput 1.00 1.00 1.00 1.00 1.00 latency bound gives minimum value CPE function must perform combining operation strict sequence. throughput bound gives minimum bound CPE based maximum rate functional units produce results. example, since one multiplier, issue time 1 clock cycle, processor cannot possibly sustain rate one multiplication per clock cycle. noted earlier thatthe processor three functional units capable performing integer addition,and listed issue time operation 0.33. Unfortunately, needto read elements memory creates additional throughput bound theCPE 1.00 combining functions. demonstrate effect bothof latency throughput bounds different versions combiningfunctions. 5.7.3 Abstract Model Processor Operation tool analyzing performance machine-level program executing modern processor, use data-ﬂow representation programs, graphical notation showing data dependencies different operationsconstrain order executed. constraints lead tocritical paths graph, putting lower bound number clock cycles required execute set machine instructions.Section 5.7 Understanding Modern Processors 503 proceeding technical details, instructive examine CPE measurements obtained function combine4 , fastest code point: Integer Floating point Function Page Method +*+ F* D* combine4 493 Accumulate temporary 2.00 3.00 3.00 4.00 5.00 Latency bound 1.00 3.00 3.00 4.00 5.00 Throughput bound 1.00 1.00 1.00 1.00 1.00 see measurements match latency bound processor, except case integer addition. coincidence—it indicatesthat performance functions dictated latency sumor product computation performed. Computing product sum n elements requires around L.n+Kclock cycles, Lis latency combining operation Krepresents overhead calling function initiating terminating loop. CPE therefore equal latencybound L. Machine-Level Code Data-Flow Graphs data-ﬂow representation programs informal. want use way visualize data dependencies program dictate perfor-mance. present data-ﬂow notation working combine4 (Figure 5.10, page 493) example. focus computation performed loop,since dominating factor performance large vectors. considerthe case ﬂoating-point data multiplication combining operation,although combinations data type operation nearly identicalstructure. compiled code loop consists four instructions, reg-isters %rdx holding loop index i,%rax holding array address data ,%rcx holding loop bound limit , %xmm0 holding accumulator value acc. combine4: data_t = float, OP = * ii n %rdx, data %rax, limit %rbp, acc %xmm0 1.L488: loop: 2 mulss (%rax,%rdx,4), %xmm0 Multiply acc data[i] 3 addq $1, %rdx Increment 4 cmpq %rdx, %rbp Compare limit:i 5 jg .L488 >, goto loop Figure 5.13 indicates, hypothetical processor design, four in- structions expanded instruction decoder series ﬁve operations , initial multiplication instruction expanded load operation read source operand memory, mul operation perform multiplication.504 Chapter 5 Optimizing Program Performance Figure 5.13 Graphical representationof inner-loop code combine4 .Instructions dynamically translatedinto one two operations,each receives values opera- tions registers andproduces values otheroperations regis- ters. show target ﬁnal instruction thelabel loop . jumps ﬁrst instruction shown.%rax %rbp %rdx %xmm0 mulss (%rax,%rdx,4), %xmm0 addq $1,%rdx cmpq %rdx,%rbp jg loop %rax %rbp %rdx %xmm0load mul add cmp jg step toward generating data-ﬂow graph representation program, boxes lines along left-hand side Figure 5.13 show registersare used updated different operations, boxes along toprepresenting register values beginning loop, along thebottom representing values end. example, register %rax used source value load operation performing address calculation, register value end loop beginning. Similarly,register %rcx used cmp operation. Register %rdx , hand, used updated within loop. initial value used load add operations; new value generated add operation, used cmp operation. Register %xmm0 also updated within loop mul operation, ﬁrst uses initial value source value. operations Figure 5.13 produce values correspond registers. show arcs operations right-hand side. load operation reads value memory passes directly mul operation. Since two operations arise decoding single mulss instruction, register associated intermediate value passingbetween them. cmp operation updates condition codes, tested jgoperation. code segment forming loop, classify registers accessed four categories: Read-only: used source values, either data compute memory addresses, modiﬁed within loop. read-only registers loop combine4 are%rax and%rcx . Write-only: used destinations data-movement operations. registers loop. Local: updated used within loop, dependency one iteration another. condition code registers examplesSection 5.7 Understanding Modern Processors 505 Figure 5.14 Abstracting combine4 operations data-ﬂowgraph. (a) rearrange operators Figure 5.13to clearly show thedata dependencies, andthen (b) show thoseoperations use valuesfrom one iteration produce new values next.%rax %rbp %rdx%xmm0 %rdx %xmm0data[ i]load (a) (b)mul add cmp jg%rdx %xmm0 %rdx %xmm0load mul add loop: updated cmp operation used jl operation, dependency contained within individual iterations. Loop: used source values destinations loop, value generated one iteration used another. cansee %rdx and%xmm0 loop registers combine4 , corresponding program values iandacc. see, chains operations loop registers determine performance-limiting data dependencies. Figure 5.14 shows reﬁnements graphical representation Fig- ure 5.13, goal showing operations data dependencies thataffect program execution time. see Figure 5.14(a) rearrangedthe operators show clearly ﬂow data source registers atthe top (both read-only loop registers), destination registers bottom (both write-only loop registers). Figure 5.14(a), also color operators white part chain dependencies loop registers. example, compare(cmp ) branch ( jl) operations directly affect ﬂow data program. assume Instruction Control Unit predicts branch betaken, hence program continue looping. purpose compareand branch operations test branch condition notify ICU isnot. assume checking done quickly enough slow processor. Figure 5.14(b), eliminated operators colored white left, retained loop registers. left anabstract template showing data dependencies form among loop registersdue one iteration loop. see diagram twodata dependencies one iteration next. Along one side, see thedependencies successive values program value acc, stored register %xmm0 . loop computes new value acc multiplying old value by506 Chapter 5 Optimizing Program Performance Figure 5.15 Data-ﬂow representationof computation n iterations innerloop combine4 .The sequence multiplicationoperations forms criticalpath limits program performance.data[0] loadCritical path mul add data[1] load mul add data[ n-2] load mul add data[ n-1] load mul add data element, generated load operation. Along side, see dependencies successive values loop index i. iteration, old value used compute address load operation, also incremented add operation compute new value. Figure 5.15 shows data-ﬂow representation niterations inner loop function combine4 . see graph obtained simply replicating template shown right-hand side Figure 5.14 ntimes. see program two chains data dependencies, corresponding tothe updating program values accandiwith operations mul add, respec- tively. Given single-precision multiplication latency 4 cycles, whileinteger addition latency 1, see chain left form acritical path , requiring 4 ncycles execute. chain left would require onlyncycles execute, limit program performance. Figure 5.15 demonstrates achieved CPE equal latency bound 4 cycles combine4 , performing single-precision ﬂoating-point multi- plication. executing function, ﬂoating-point multiplier becomes thelimiting resource. operations required loop—manipulatingSection 5.7 Understanding Modern Processors 507 testing loop index i, computing address next data elements, reading data memory—proceed parallel multiplier. suc-cessive value accis computed, fed back around compute next value, completed four cycles later. ﬂow combinations data type operation identical shown Figure 5.15, different data operation forming chain ofdata dependencies shown left. cases operation hasa latency Lgreater 1, see measured CPE simply L, indicating chain forms performance-limiting critical path. Performance Factors case integer addition, hand, measurements combine4 show CPE 2.00, slower CPE 1.00 would predict based thechains dependencies formed along either left- right-hand side thegraph Figure 5.15. illustrates principle critical paths data-ﬂow representation provide lower bound many cycles program require. factors also limit performance, including total numberof functional units available number data values passedamong functional units given step. case integer addition asthe combining operation, data operation sufﬁciently fast rest theoperations cannot supply data fast enough. Determining exactly programrequires 2.00 cycles per element would require much detailed knowledgeof hardware design publicly available. summarize performance analysis combine4 : abstract data-ﬂow representation program operation showed combine4 critical path length L.ncaused successive updating program value acc, path limits CPE least L. indeed CPE measure cases except integer addition, measured CPE 2.00 rather CPE 1.00we would expect critical path length. may seem latency bound forms fundamental limit fast combining operations performed. next task restructurethe operations enhance instruction-level parallelism. want transform theprogram way limitation becomes throughput bound,yielding CPEs close 1.00. Practice Problem 5.5 Suppose wish write function evaluate polynomial, polynomialof degree nis deﬁned set coefﬁcients 0,a1,a2,...,an. value x, evaluate polynomial computing a0+a1x+a2x2+...+anxn(5.2) evaluation implemented following function, argu- ments array coefﬁcients a, value x, polynomial degree, degree508 Chapter 5 Optimizing Program Performance (the value nin Equation 5.2). function, compute successive terms equation successive powers xwithin single loop: 1double poly(double a[], double x, int degree) 2{ 3 long int i; 4 double result = a[0]; 5 double xpwr = x; /* Equals x^i start loop */ 6 (i = 1; <= degree; i++) { 7 result += a[i] * xpwr; 8 x p w r=x* xpwr; 9 } 10 return result; 11 12 } A. degree n, many additions many multiplications code perform? B. reference machine, arithmetic operations latencies shown Figure 5.12, measure CPE function 5.00. Ex-plain CPE arises based data dependencies formed betweeniterations due operations implementing lines 7–8 function. Practice Problem 5.6 Let us continue exploring ways evaluate polynomials, described Prob-lem 5.5. reduce number multiplications evaluating polyno- mial applying Horner’s method , named British mathematician William G. Horner (1786–1837). idea repeatedly factor powers xto get following evaluation: 0+x(a1+x(a2+...+x(an−1+xan)...)) (5.3) Using Horner’s method, implement polynomial evaluation using fol- lowing code: 1/* Apply Horner’s method */ 2double polyh(double a[], double x, int degree) 3{ 4 long int i; 5 double result = a[degree]; 6 (i = degree-1; >= 0; i--) 7 result = a[i] + x*result; 8 return result; 9}Section 5.8 Loop Unrolling 509 A. degree n, many additions many multiplications code perform? B. reference machine, arithmetic operations laten- cies shown Figure 5.12, measure CPE function 8.00.Explain CPE arises based data dependencies formed be-tween iterations due operations implementing line 7 function. C. Explain function shown Problem 5.5 run faster, even though requires operations. 5.8 Loop Unrolling Loop unrolling program transformation reduces number iterationsfor loop increasing number elements computed iteration. Wesaw example function psum2 (Figure 5.1), iteration computes two elements preﬁx sum, thereby halving total number iterations required. Loop unrolling improve performance two ways. First,it reduces number operations contribute directly program result, loop indexing conditional branching. Second, exposes waysin transform code reduce number operationsin critical paths overall computation. section, examinesimple loop unrolling, without transformations. Figure 5.16 shows version combining code using two-way loop un- rolling. ﬁrst loop steps array two elements time. is, theloop index iis incremented 2 iteration, combining operation applied array elements iandi+1 single iteration. general, vector length multiple 2. want code work correctly arbitrary vector lengths. account requirement intwo ways. First, make sure ﬁrst loop overrun array bounds.For vector length n, set loop limit n−1. assured loop executed loop index isatisﬁes i<n−1, hence maximum array index i+1 satisfy i+1<( n−1)+1=n. generalize idea unroll loop factor k.T od os ,w e set upper limit n−k+1, within loop apply combining operation elements ithrough i+k−1. Loop index iis incremented kin iteration. maximum array index i+k−1 less n. include second loop step ﬁnal elements vector one time.The body loop executed 0 k−1 times. k=2, could use simple conditional statement optionally add ﬁnal iteration, wedid function psum2 (Figure 5.1). k>2, ﬁnishing cases better expressed loop, adopt programming convention k=2 well.510 Chapter 5 Optimizing Program Performance 1/* Unroll loop 2 */ 2void combine5(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 long int limit = length-1; 7 data_t *data = get_vec_start(v); 8 data_t acc = IDENT; 9 10 /* Combine 2 elements time */ 11 (i = 0; < limit; i+=2) { 12 acc = (acc OP data[i]) OP data[i+1]; 13 } 1415 /* Finish remaining elements */ 16 (; < length; i++) { 17 acc = acc OP data[i]; 18 } 19 *dest = acc; 20 } Figure 5.16 Unrolling loop factor k=2.Loop unrolling reduce effect loop overhead. Practice Problem 5.7 Modify code combine5 unroll loop factor k=5. measure performance unrolled code unrolling factors k=2(combine5 ) k=3, get following results: Integer Floating point Function Page Method +*+ F* D* combine4 493 unrolling 2.00 3.00 3.00 4.00 5.00 combine5 510 Unroll ×2 2.00 1.50 3.00 4.00 5.00 Unroll ×3 1.00 1.00 3.00 4.00 5.00 Latency bound 1.00 3.00 3.00 4.00 5.00 Throughput bound 1.00 1.00 1.00 1.00 1.00 see CPEs integer addition multiplication improve, ﬂoating-point operations not. Figure 5.17 shows CPE measure- ments unrolling loop factor 6. see trends weSection 5.8 Loop Unrolling 511 Figure 5.17 CPE performance fordifferent degrees loopunrolling. integer addition multiplication improve loop unrolling.6.00 5.00 4.003.002.00 1.00 0.00 1 2 3 4 Unrolling factor KCPE 5 6double * float *float + int * int + observed unrolling 2 3 continue—it help ﬂoating-point operations, integer addition multiplication drop CPEs of1.00. Several phenomena contribute measured values CPE. caseof integer addition, see unrolling factor 2 makes difference, butunrolling factor 3 drops CPE 1.00, achieving latency thethroughput bounds operation. result attributed beneﬁtsof reducing loop overhead operations. reducing number overhead op-erations relative number additions required compute vector sum,we reach point one-cycle latency integer addition becomesthe performance-limiting factor. improving CPE integer multiplication surprising. see un- rolling factor kbetween 1 3, CPE 3 .00/k. turns compiler making optimization based reassociation transformation , altering order values combined. cover transformation Section 5.9.2.The fact gccapplies transformation integer multiplication ﬂoating-point addition multiplication due associativity properties ofthe different operations data types, also discussed later. understand three ﬂoating-point cases improve loop unrolling, consider graphical representation inner loop, shown inFigure 5.18 case single-precision multiplication. see themulss instructions get translated two operations: one load array element memory, one multiply value accumulated value.We see register %xmm0 gets read written twice execution loop. rearrange, simplify, abstract graph, following process shown Figure 5.19 obtain template shown Figure 5.19(b). thenreplicate template n/2 times show computation vector length n, obtaining data-ﬂow representation shown Figure 5.20. see still critical path nmuloperations graph—there half many iterations, iteration two multiplication operations sequence. Sincethe critical path limiting factor performance code withoutloop unrolling, remains simple loop unrolling.512 Chapter 5 Optimizing Program Performance Figure 5.18 Graphical representationof inner-loop code combine5 .Each iteration two mulss instructions, translatedinto load muloperation.%rax %rbp %rdx %xmm0 mulss (%rax,%rdx,4), %xmm0 mulss 4(%rax,%rdx,4), %xmm0 addq $2,%rdx cmpq %rdx,%rbp jg loop %rax %rbp %rdx %xmm0load mul load mul add cmp jg Figure 5.19 Abstracting combine5 operations data-ﬂowgraph. rearrange, sim- plify, abstract therepresentation Fig- ure 5.18 show data dependencies betweensuccessive iterations (a).We see iteration must perform two multipli- cations sequence (b).%rax %rbp %rdx%xmm0 %rdx %xmm0data[ i] data[ i+1]load loadmul mul add cmp (a) (b)jg%rdx %xmm0 %rdx %xmm0load mul addload mul Aside Getting compiler unroll loops Loop unrolling easily performed compiler. Many compilers routinely whenever optimization level set sufﬁciently high. gccwill perform loop unrolling invoked command- line option ‘ -funroll-loops ’.Section 5.9 Enhancing Parallelism 513 Figure 5.20 Data-ﬂow representationof combine5 operating vector lengthn.Even though loop unrolled afactor 2, still n mul operations along thecritical path.data[0] loadCritical path mul data[1] load mul add data[2] load mul data[3] load mul add data[ n-2] load mul data[ n-1] load mul add 5.9 Enhancing Parallelism point, functions hit bounds imposed latencies arithmetic units. noted, however, functional units performing addition multiplication fully pipelined, meaning start newoperations every clock cycle. code cannot take advantage capability,even loop unrolling, since accumulating value single variableacc. cannot compute new value accuntil preceding computation has514 Chapter 5 Optimizing Program Performance completed. Even though functional unit start new operation every clock cycle, start one every Lcycles, Lis latency combining operation. investigate ways break sequential dependency andget performance better latency bound. 5.9.1 Multiple Accumulators combining operation associative commutative, integer addition multiplication, improve performance splitting set ofcombining operations two parts combining results theend. example, let P ndenote product elements a0,a1,...,a n−1: Pn=n−1/productdisplay i=0ai Assuming nis even, also write Pn=PEn×POn, PEnis product elements even indices, POnis product elements odd indices: PEn=n/2−1/productdisplay i=0a2i POn=n/2−1/productdisplay i=0a2i+1 Figure 5.21 shows code uses method. uses two-way loop unrolling, combine elements per iteration, two-way parallelism, accumulating elements even index variable acc0 elements odd index variable acc1 . before, include second loop accumulate remaining array elements case vector length multiple 2. applythe combining operation acc0 andacc1 compute ﬁnal result. Comparing loop unrolling alone loop unrolling two-way parallelism, obtain following performance: Integer Floating point Function Page Method +*+ F* D* combine4 493 Accumulate temporary 2.00 3.00 3.00 4.00 5.00 combine5 510 Unroll ×2 2.00 1.50 3.00 4.00 5.00 combine6 515 Unroll ×2, parallelism ×2 1.50 1.50 1.50 2.00 2.50 Latency bound 1.00 3.00 3.00 4.00 5.00 Throughput bound 1.00 1.00 1.00 1.00 1.00 Figure 5.22 demonstrates effect applying transformation achieve k- way loop unrolling k-way parallelism values k=6. see thatSection 5.9 Enhancing Parallelism 515 1/* Unroll loop 2, 2-way parallelism */ 2void combine6(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 long int limit = length-1; 7 data_t *data = get_vec_start(v); 8 data_t acc0 = IDENT; 9 data_t acc1 = IDENT; 10 11 /* Combine 2 elements time */ 12 (i = 0; < limit; i+=2) { 13 acc0 = acc0 OP data[i]; 14 acc1 = acc1 OP data[i+1]; 15 } 1617 /* Finish remaining elements */ 18 (; < length; i++) { 19 acc0 = acc0 OP data[i]; 20 } 21 *dest = acc0 OP acc1; 22 } Figure 5.21 Unrolling loop 2 using two-way parallelism. approach makes use pipelining capability functional units. CPEs combining cases improve increasing values k.F r integer multiplication, ﬂoating-point operations, see CPE value L/k, Lis latency operation, throughput bound 1.00. also see integer addition reaching throughput bound 1.00 k=3. course, also reached bound integer addition standard unrolling. Figure 5.22 CPE performance k- way loop unrolling withk-way parallelism. CPEs improve transformation, thelimiting value 1.00.6.00 5.004.003.002.00 1.00 0.00 1 2 3 4 Unrolling factor KCPE 5 6double * float *float +int * int +516 Chapter 5 Optimizing Program Performance %rax %rbp %rdx %xmm0 mulss (%rax,%rdx,4), %xmm0 mulss 4(%rax,%rdx,4), %xmm1 addq $2,%rdx cmpq %rdx,%rbp jg loop %rax %rbp %rdx %xmm0%xmm1 %xmm1load mul load mul add cmp jg Figure 5.23 Graphical representation inner-loop code combine6 .Each iteration two mulss instructions, translated load mul operation. %rax %rbp %rdx %xmm0 %xmm1 %xmm1 %rdx %xmm0data[ i] data[ i+1]load load (a) (b)add cmp jg%rdx %xmm0 %rdx %xmm0load mul%xmm1 %xmm1load mul addmul mul Figure 5.24 Abstracting combine6 operations data-ﬂow graph. rearrange, simplify, abstract representation Figure 5.23 show data dependencies successive iterations (a). see dependency two mul operations (b). understand performance combine6 , start code oper- ation sequence shown Figure 5.23. derive template showing datadependencies iterations process shown Figure 5.24. withcombine5 , inner loop contains two mulss operations, instruc- tions translate mul operations read write separate registers, data dependency (Figure 5.24(b)). replicate tem-platen/2 times (Figure 5.25), modeling execution function vectorSection 5.9 Enhancing Parallelism 517 Figure 5.25 Data-ﬂow representationof combine6 operating vector length n. two criticalpaths, containing n/2 operations.data[0] data[1]load mulload mul add data[2] data[3]load mulload mul add data[ n-2] data[ n-1]load mulload mul addCritical paths length n. see two critical paths, one corresponding computing product even-numbered elements (program value acc0 ) one odd-numbered elements (program value acc1 ). criti- cal paths contain n/2 operations, thus leading CPE 4 .00/2. similar analysis explains observed CPE L/2 operations latency Lfor different combinations data type combining operation. Operationally, weare exploiting pipelining capabilities functional unit increase theirutilization factor 2. apply transformation larger values ofk, ﬁnd cannot reduce CPE 1.00. reach point, several functional units operating maximum capacity. seen Chapter 2 two’s-complement arithmetic commuta- tive associative, even overﬂow occurs. Hence, integer data type, result computed combine6 identical computed combine5518 Chapter 5 Optimizing Program Performance possible conditions. Thus, optimizing compiler could potentially con- vert code shown combine4 ﬁrst two-way unrolled variant combine5 loop unrolling, combine6 introducing parallelism. Many compilers loop unrolling automatically, relatively introduce thisform parallelism. hand, ﬂoating-point multiplication addition as- sociative. Thus, combine5 andcombine6 could produce different results due rounding overﬂow. Imagine, example, product computation allof elements even indices numbers large absolute value,while odd indices close 0.0. case, product PE n might overﬂow, POnmight underﬂow, even though computing product Pnpro- ceeds normally. real-life applications, however, patterns unlikely.Since physical phenomena continuous, numerical data tend reason-ably smooth well-behaved. Even discontinuities, notgenerally cause periodic patterns lead condition sketched ear-lier. unlikely multiplying elements strict order gives fundamentallybetter accuracy multiplying two groups independently mul-tiplying products together. applications, achieving performancegain 2 ×outweighs risk generating different results strange data pat- terns. Nevertheless, program developer check potential users seeif particular conditions may cause revised algorithm un-acceptable. 5.9.2 Reassociation Transformation explore another way break sequential dependencies thereby improve performance beyond latency bound. saw simple loop un-rolling combine5 change set operations performed combining vector elements form sum product. small change thecode, however, fundamentally change way combining performed,and also greatly increase program performance. Figure 5.26 shows function combine7 differs unrolled code combine5 (Figure 5.16) way elements combined inner loop. combine5 , combining performed statement 12 acc = (acc OP data[i]) OP data[i+1]; combine7 performed statement 12 acc = acc OP (data[i] OP data[i+1]); differing two parentheses placed. call reassociation trans- formation , parentheses shift order vector elements combined accumulated value acc. untrained eye, two statements may seem essentially same, measure CPE, get surprising results:Section 5.9 Enhancing Parallelism 519 Integer Floating point Function Page Method +*+ F* D* combine4 493 Accumulate temporary 2.00 3.00 3.00 4.00 5.00 combine5 510 Unroll ×2 2.00 1.50 3.00 4.00 5.00 combine6 515 Unroll ×2, parallelism ×2 1.50 1.50 1.50 2.00 2.50 combine7 519 Unroll ×2 reassociate 2.00 1.51 1.50 2.00 2.97 Latency bound 1.00 3.00 3.00 4.00 5.00 Throughput bound 1.00 1.00 1.00 1.00 1.00 integer multiplication case nearly matches performance ver- sion simple unrolling ( combine5 ), ﬂoating-point cases match performance version parallel accumulators ( combine6 ), doubling performance relative simple unrolling. (The CPE 2.97 shown double-precision multiplication likely result measurement error, withthe true value 2.50. experiments, found measured CPEs forcombine7 variable functions.) Figure 5.27 demonstrates effect applying reassociation transforma- tion achieve k-way loop unrolling reassociation. see CPEs combining cases improve increasing values k. integer 1/* Change associativity combining operation */ 2void combine7(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 long int limit = length-1; 7 data_t *data = get_vec_start(v); 8 data_t acc = IDENT; 9 10 /* Combine 2 elements time */ 11 (i = 0; < limit; i+=2) { 12 acc = acc OP (data[i] OP data[i+1]); 13 } 1415 /* Finish remaining elements */ 16 (; < length; i++) { 17 acc = acc OP data[i]; 18 } 19 *dest = acc; 20 } Figure 5.26 Unrolling loop 2 reassociating combining operation. approach also increases number operations performed parallel.520 Chapter 5 Optimizing Program Performance Figure 5.27 CPE performance k- way loop unrolling withreassociation. CPEs improve transformation, limiting value 1.00.6.00 5.004.003.002.001.000.00 1 2 3 4 Unrolling factor KCPE 5 6double * float * float +int *int + multiplication ﬂoating-point operations, see CPE value nearly L/k, Lis latency operation, throughput bound 1.00. also see integer addition reaching CPE 1.00 k=3, achieving throughput latency bounds. Figure 5.28 illustrates code inner loop combine7 (for case single-precision product) gets decoded operations resultingdata dependencies. see load operations resulting movss ﬁrst mulss instructions load vector elements iandi+1 memory, ﬁrst mul operation multiplies together. second mul operation multiples result accumulated value acc. Figure 5.29 shows rearrange, reﬁne, abstract operations Figure 5.28 get template rep-resenting data dependencies one iteration (Figure 5.29(b)). templates combine5 andcombine7 , two load two mul operations, %rax %rbp %rdx %xmm0 mulss 4(%rax,%rdx,4), %xmm0 mulss %xmm0, %xmm1movss (%rax,%rdx,4), %xmm0 addq $2,%rdx cmpq %rdx,%rbp jg loop %rax %rbp %rdx %xmm0%xmm1 %xmm1load load mulmul add cmp jg Figure 5.28 Graphical representation inner-loop code combine7 .Each iteration gets decoded similar operations combine5 orcombine6 , different data dependencies.Section 5.9 Enhancing Parallelism 521 %rax %rbp %rdx %xmm1 %xmm1 %rdxdata[ i] data[ i+1]load load mul muladd cmp (a) (b)jg%rdx %xmm1 %xmm1 %rdxload load mul mul add Figure 5.29 Abstracting combine7 operations data-ﬂow graph. rearrange, simplify, abstract representation Figure 5.28 show data dependencies successive iterations (a). ﬁrst mul operation multiplies two vector elements, second one multiplies result loop variable acc (b). one mul operations forms data-dependency chain loop registers. replicate template n/2 times show computa- tions performed multiplying nvector elements (Figure 5.30), see n/2 operations along critical path. ﬁrst multiplication within iteration performed without waiting accumulated value fromthe previous iteration. Thus, reduce minimum possible CPE factorof 2. increase k, continue one operation per iteration along critical path. performing reassociation transformation, change order vector elements combined together. integer additionand multiplication, fact operations associative implies thatthis reordering effect result. ﬂoating-point cases, wemust assess whether reassociation likely signiﬁcantly affectthe outcome. would argue difference would immaterial mostapplications. explain surprising improvement saw simple loop unrolling ( combine5 ) case integer multiplication. compiling code, gcc performed reassociation shown combine7 , hence achieved performance. also performed transformation forcode higher degrees unrolling. gccrecognizes safely perform transformation integer operations, also recognizes cannot transform ﬂoating-point cases due lack associativity. would begratifying ﬁnd gcc performed transformation recognizing resulting code would run faster, unfortunately seems case.In experiments, found minor changes C code caused gcc522 Chapter 5 Optimizing Program Performance Figure 5.30 Data-ﬂow representationof combine7 operating vector length n. single criticalpath, contains onlyn/2operations.data[0] data[1]load load mul mul add data[2] data[3]load load mul mul add data[ n-2] data[ n-1]load load mul mul addCritical path associate operations differently, sometimes causing generated code speed up, sometimes slow down, relative would achieved bya straightforward compilation. Optimizing compilers must choose factorsthey try optimize, appears gccdoes use maximizing instruction- level parallelism one optimization criteria selecting associateinteger operations. summary, reassociation transformation reduce number opera- tions along critical path computation, resulting better performance bybetter utilizing pipelining capabilities functional units. compilerswill attempt reassociations ﬂoating-point operations, since oper-ations guaranteed associative. Current versions gccdo perform reassociations integer operations, always good effects. general,we found unrolling loop accumulating multiple values parallel reliable way achieve improved program performance.Section 5.9 Enhancing Parallelism 523 Practice Problem 5.8 Consider following function computing product array ninte- gers. unrolled loop factor 3. double aprod(double a[], int n) { int i;double x, y, z; doubl er=1 ; (i = 0; < n-2; i+= 3) { x = a[i] ; = a[i+1] ; z = a[i+2]; r=r*x*y*z ; /* Product computation */ } f r( ;i<n ; i++) r *= a[i]; return r; } line labeled Product computation , use parentheses create ﬁve different associations computation, follows: r=( ( r*x )*y )*z ; /* A1 */ r=( r*( x*y ) )*z ; /* A2 */ r=r*( ( x*y )*z ) ; /* A3 */ r=r*( x*( y* z)); /* A4 */ r=( r*x )*( y*z ) ; /* A5 */ Assume run functions machine double-precision multi- plication latency 5 clock cycles. Determine lower bound CPE setby data dependencies multiplication. ( Hint: helps draw pictorial representation ris computed every iteration.) Web Aside OPT:SIMD Achieving greater parallelism SIMD instructions described Section 3.1, Intel introduced SSE instructions 1999, SSE acronym “Streaming SIMD Extensions,” and, turn, SIMD (pronounced “sim-dee”) acronym “Single-Instruction, Multiple-Data.” idea behind SIMD execution model 16-byte XMM register hold multiple values. examples, consider cases hold either four integer single-precision values, two double-precision values. SSE instructions canthen perform vector operations registers, adding multiplying four two sets values parallel. example, XMM register %xmm0 contains four single-precision ﬂoating-point numbers, denote 0,...,a 3, %rcx contains memory address sequence four single-precision ﬂoating-point numbers, denote b0,...,b 3, instruction mulps (%rcs), %xmm0524 Chapter 5 Optimizing Program Performance read four values memory perform four multiplications parallel, computing ai← ai.bi, 0 ≤i≤3. see single instruction able generate computation multiple data values, hence term “SIMD.” gcc supports extensions C language let programmers express program terms vector operations compiled SIMD instructions SSE. coding style ispreferable writing code directly assembly language, since gcccan also generate code SIMD instructions found processors. Using combination gccinstructions, loop unrolling, multiple accumulators, able achieve following performance combining functions: Integer Floating point Method +*+ F* D* SSE + 8-way unrolling 0.25 0.55 0.25 0.24 0.58 Throughput bound 0.25 0.50 0.25 0.25 0.50 chart shows, using SSE instructions lowers throughput bound, nearly achieved bounds ﬁve cases. throughput bound 0.25 integer addition single- precision addition multiplication due fact SSE instruction perform four parallel, issue time 1. double-precision instructions perform twoin parallel, giving throughput bound 0.50. integer multiplication operation throughputbound 0.50 different reason—although perform four parallel, issue timeof 2. fact, instruction available SSE versions 4 higher (requiring command-line ﬂag ‘-msse4 ’). 5.10 Summary Results Optimizing Combining Code efforts maximizing performance routine adds multiplies elements vector clearly paid off. following summarizes resultswe obtain scalar code, making use SIMD parallelism provided SSE vector instructions: Integer Floating point Function Page Method +*+ F* D* combine1 485 Abstract -O1 12.00 12.00 12.00 12.01 13.00 combine6 515 Unroll ×2, parallelism ×2 1.50 1.50 1.50 2.00 2.50 Unroll ×5, parallelism ×5 1.01 1.00 1.00 1.00 1.00 Latency bound 1.00 3.00 3.00 4.00 5.00 Throughput bound 1.00 1.00 1.00 1.00 1.00 using multiple optimizations, able achieve CPE close 1.00 combinations data type operation using ordinary C code, per-formance improvement 10X compared original version combine1 .Section 5.11 Limiting Factors 525 covered Web Aside opt:simd , improve performance even making use gcc’s support SIMD vector instructions: Integer Floating point Function Method +*+ F* D* SIMD code SIMD + 8-way unrolling 0.25 0.55 0.25 0.24 0.58 Throughput bound 0.25 0.50 0.25 0.25 0.50 processor sustain four combining operations per cycle integer single-precision data, two per cycle double-precision data. Thisrepresents performance 6 gigaﬂops (billions ﬂoating-point operations per second) processor commonly found laptop desktop machines. Compare performance Cray 1S, breakthrough supercom- puter introduced 1976. machine cost around $8 million consumed 115kilowatts electricity get peak performance 0.25 gigaﬂops, 20 timesslower measured here. Several factors limit performance computation CPE 1.00 using scalar instructions, CPE either 0.25 (32-bit data) 0.50(64-bit data) using SIMD instructions. First, processor read16 bytes data cache cycle, reading XMMregister. Second, multiplier adder units start new operationevery clock cycle (in case SIMD instructions, “operations”actually computes two four sums products). Thus, succeeded inproducing fastest possible versions combining function machine. 5.11 Limiting Factors seen critical path data-ﬂow graph representation aprogram indicates fundamental lower bound time required execute aprogram. is, chain data dependencies program wherethe sum latencies along chain equals T, program require least Tcycles execute. also seen throughput bounds functional units also impose lower bound execution time program. is, assumethat program requires total Ncomputations operation, microprocessor mfunctional units capable performing operation, units issue time i. program require least N.i/m cycles execute. section, consider factors limit performance programs actual machines. 5.11.1 Register Spilling beneﬁts loop parallelism limited ability express compu- tation assembly code. particular, IA32 instruction set small526 Chapter 5 Optimizing Program Performance number registers hold values accumulated. degree parallelism pthat exceeds number available registers, compiler resort spilling , storing temporary values stack. happens, performance drop signiﬁcantly. illustration, compare theperformance parallel accumulator code integer sum x86-64 vs. IA32: Degree unrolling Machine 123456 IA32 2.12 1.76 1.45 1.39 1.90 1.99 x86-64 2.00 1.50 1.00 1.00 1.01 1.00 see IA32, lowest CPE achieved k=4 values accumulated parallel, gets worse higher values k. also see cannot get CPE 1.00 achieved x86-64. Examining IA32 code case k=5 shows effect small number registers IA32: IA32 code. Unroll X5, accumulate X5, data_t = int, OP = + ii n %edx, data %eax, limit %ebp-20 1.L291: loop: 2 imull (%eax,%edx,4), %ecx x0 = x0 * data[i] 3 movl -16(%ebp), %ebx Get x1 4 imull 4(%eax,%edx,4), %ebx x1 = x1 * data[i+1] 5 movl %ebx, -16(%ebp) Store x1 6 imull 8(%eax,%edx,4), %edi x2 = x2 * data[i+2] 7 imull 12(%eax,%edx,4), %esi x3 = x3 * data[i+3] 8 movl -28(%ebp), %ebx Get x4 9 imull 16(%eax,%edx,4), %ebx x4 = x4 * daa[i+4] 10 movl %ebx, -28(%ebp) Store x4 11 addl $5, %edx i+= 5 12 cmpl %edx, -20(%ebp) Compare limit:i 13 jg .L291 >, goto loop see accumulator values acc1 andacc4 “spilled” onto stack, offsets −16 −28 relative %ebp . addition, termination value limit kept stack offset −20. loads stores associated reading values memory storing back negates anyvalue obtained accumulating multiple values parallel. see merit adding eight additional registers extension IA32 x86-64. x86-64 code able accumulate 12 values parallelwithout spilling registers. 5.11.2 Branch Prediction Misprediction Penalties demonstrated via experiments Section 3.6.6 conditional branch incur signiﬁcant misprediction penalty branch prediction logic doesSection 5.11 Limiting Factors 527 correctly anticipate whether branch taken. learned something processors operate, understand thispenalty arises. Modern processors work well ahead currently executing instructions, reading new instructions memory decoding determine whatoperations perform operands. instruction pipelining works well long instructions follow simple sequence. branch encountered,the processor must guess way branch go. case conditional jump, means predicting whether branch taken. aninstruction indirect jump (as saw code jump addressspeciﬁed jump table entry) procedure return, means predicting thetarget address. discussion, focus conditional branches. processor employs speculative execution , processor begins exe- cuting instructions predicted branch target. way thatavoids modifying actual register memory locations actual out-come determined. prediction correct, processor then“commit” results speculatively executed instructions storing themin registers memory. prediction incorrect, processor must discardall speculatively executed results restart instruction fetch processat correct location. misprediction penalty incurred this, be-cause instruction pipeline must reﬁlled useful results gener-ated. saw Section 3.6.6 recent versions x86 processors conditional move instructions gcc generate code uses instructions compiling conditional statements expressions, rather moretraditional realizations based conditional transfers control. basic idea fortranslating conditional moves compute values along branchesof conditional expression statement, use conditional moves selectthe desired value. saw Section 4.5.10 conditional move instructions canbe implemented part pipelined processing ordinary instructions. Thereis need guess whether condition hold, hence penaltyfor guessing incorrectly. ca n C programmer make sure branch misprediction penalties hamper program’s efﬁciency? Given 44 clock-cycle mispredictionpenalty saw Intel Core i7, stakes high. simpleanswer question, following general principles apply. Overly Concerned Predictable Branches seen effect mispredicted branch high, thatdoes mean program branches slow program down. fact, thebranch prediction logic found modern processors good discerningregular patterns long-term trends different branch instructions. Forexample, loop-closing branches combining routines would typically bepredicted taken, hence would incur misprediction penalty onthe last time around.528 Chapter 5 Optimizing Program Performance another example, consider small performance gain observed shifting combine2 tocombine3 , took function get_vec_ element inner loop function, reproduced below: Integer Floating point Function Page Method +* + F* D* combine2 486 Move vec_length 8.03 8.09 10.09 11.09 12.08 combine3 491 Direct data access 6.01 8.01 10.01 11.01 12.02 CPE hardly changed, even though function uses two conditionals check whether vector index within bounds. checks always determinethat index within bounds, hence highly predictable. way measure performance impact bounds checking, consider following combining code, modiﬁed inner loop combine4 replacing access data element result performing inline substitution code get_vec_element . call new version combine4b . code performs bounds checking also references vector elements vector data structure. 1/* Include bounds check loop */ 2void combine4b(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 data_t acc = IDENT; 7 8 (i = 0; < length; i++) { 9 (i >= 0 && < v->len) { 10 acc = acc OP v->data[i]; 11 } 12 } 13 *dest = acc; 14 } directly compare CPE functions without bounds checking: Integer Floating point Function Page Method +*+ F* D* combine4 493 bounds checking 1.00 3.00 3.00 4.00 5.00 combine4b 493 Bounds checking 4.00 4.00 4.00 4.00 5.00 Although performance version bounds checking quite asgood, increases CPE 2 clock cycles. fairly small difference,considering bounds checking code performs two conditional branchesSection 5.11 Limiting Factors 529 also requires load operation implement expression v->len .T h e processor able predict outcomes branches, none thisevaluation much effect fetching processing instructions thatform critical path program execution. Write Code Suitable Implementation Conditional Moves Branch prediction reliable regular patterns. Many tests programare completely unpredictable, dependent arbitrary features data, aswhether number negative positive. these, branch prediction logic willdo poorly, possibly giving prediction rate 50%—no better randomguessing. (In principle, branch predictors prediction rates less than50%, cases rare.) inherently unpredictable cases, programperformance greatly enhanced compiler able generate codeusing conditional data transfers rather conditional control transfers. Thiscannot controlled directly C programmer, ways expressingconditional behavior directly translated conditional moves thanothers. found gccis able generate conditional moves code written “functional” style, use conditional operations computevalues update program state values, opposed amore “imperative” style, use conditionals selectively update programstate. strict rules two styles, illustrate example. Suppose given two arrays integers aandb, position i, want set a[i]to minimum a[i]andb[i], b[i]to maximum. imperative style implementing function check position iand swap two elements order: 1/* Rearrange two vectors i, b[i] >= a[i] */ 2void minmax1(int a[], int b[], int n) { 3 int i; 4 f r( i=0 ;i<n ; i++) { 5 (a[i] > b[i]) { 6 int = a[i]; 7 a[i] = b[i]; 8 b[i] = t; 9 } 10 } 11 } measurements function random data show CPE around 14.50 random data, 3.00–4.00 predictable data, clear sign highmisprediction penalty.530 Chapter 5 Optimizing Program Performance functional style implementing function compute minimum maximum values position iand assign values a[i]and b[i], respectively: 1/* Rearrange two vectors i, b[i] >= a[i] */ 2void minmax2(int a[], int b[], int n) { 3 int i; 4 f r( i=0 ;i<n ; i++) { 5 int min = a[i] < b[i] ? a[i] : b[i]; 6 int max = a[i] < b[i] ? b[i] : a[i]; 7 a[i] = min; 8 b[i] = max; 9 } 10 } measurements function show CPE around 5.0 regardless whether data arbitrary predictable. (We also examined generated assembly code make sure indeed used conditional moves.) discussed Section 3.6.6, conditional behavior implemented conditional data transfers, inevitably cases program-mers cannot avoid writing code lead conditional branches whichthe processor poorly branch prediction. But, shown, alittle cleverness part programmer sometimes make code moreamenable translation conditional data transfers. requires amountof experimentation, writing different versions function examiningthe generated assembly code measuring performance. Practice Problem 5.9 traditional implementation merge step mergesort requires threeloops: 1void merge(int src1[], int src2[], int dest[], int n) { 2 int i1 = 0; 3 int i2 = 0; 4 int id = 0; 5 (i 1<n& &i 2<n ){ 6 (src1[i1] < src2[i2]) 7 dest[id++] = src1[i1++]; 8 else 9 dest[id++] = src2[i2++]; 10 } 11 (i1 < n) 12 dest[id++] = src1[i1++]; 13 (i2 < n) 14 dest[id++] = src2[i2++]; 15 }Section 5.12 Understanding Memory Performance 531 branches caused comparing variables i1andi2tonhave good pre- diction performance—the mispredictions occur ﬁrst become false.The comparison values src1[i1] andsrc2[i2] (line 6), hand, highly unpredictable typical data. comparison controls condi-tional branch, yielding CPE (where number elements 2 n) around 17.50. Rewrite code effect conditional statement ﬁrst loop (lines 6–9) implemented conditional move. 5.12 Understanding Memory Performance code written thus far, tests run, accessrelatively small amounts memory. example, combining routines weremeasured vectors length less 1000 elements, requiring than8000 bytes data. modern processors contain one cache memories provide fast access small amounts memory. section, willfurther investigate performance programs involve load (reading frommemory registers) store (writing registers memory) operations, considering cases data held cache. Chapter 6, gointo much detail caches work, performance characteristics, write code makes best use caches. Figure 5.11 shows, modern processors dedicated functional units perform load store operations, units internal buffers holdsets outstanding requests memory operations. example, Intel Core i7load unit’s buffer hold 48 read requests, store unit’s buffer canhold 32 write requests [99]. units typically initiate oneoperation every clock cycle. 5.12.1 Load Performance performance program containing load operations depends pipelining capability latency load unit. experiments com-bining operations Core i7, saw CPE never got 1.00, exceptwhen using SIMD operations. One factor limiting CPE examples isthat require reading one value memory element computed.Since load unit initiate one load operation every clock cycle, CPEcannot less 1.00. applications must load kvalues every element computed, never achieve CPE lower k(see, example, Problem 5.17). examples far, seen performance effects due latency load operations. addresses load operations depended onlyon loop index i, load operations form part performance- limiting critical path. determine latency load operation machine, set computation sequence load operations, outcome one532 Chapter 5 Optimizing Program Performance 1typedef struct ELE { 2 struct ELE *next; 3 int data; 4} list_ele, *list_ptr; 5 6int list_len(list_ptr ls) { 7 int len = 0; 8 (ls) { 9 len++; 10 ls = ls->next; 11 } 12 return len; 13 } Figure 5.31 Linked list functions. illustrate latency load operation. determines address next. example, consider function list_ lenin Figure 5.31, computes length linked list. loop function, successive value variable lsdepends value read pointer reference ls->next . measurements show function list_len CPE 4.00, claim direct indication latency loadoperation. see this, consider assembly code loop. (We show thex86-64 version code. IA32 code similar.) len %eax,l si n %rdi 1.L11: loop: 2 addl $1, %eax Increment len 3 movq (%rdi), %rdi ls = ls->next 4 testq %rdi, %rdi Test ls 5 jne .L11 nonnull, goto loop Themovq instruction line 3 forms critical bottleneck loop. successive value register %rdi depends result load operation value %rdi address. Thus, load operation one iteration cannot begin one previous iteration completed. CPE 4.00 function determined latency load operation. 5.12.2 Store Performance examples thus far, analyzed functions reference mem- ory mostly load operations, reading memory location register.Its counterpart, store operation, writes register value memory. per- formance operation, particularly relation interactions loadoperations, involves several subtle issues. load operation, cases, store operation operate fully pipelined mode, beginning new store every cycle. example, considerthe functions shown Figure 5.32 set elements array dest lengthSection 5.12 Understanding Memory Performance 533 1/* Set elements array 0 */ 2void clear_array(int *dest, int n) { 3 int i; 4 f r( i=0 ;i<n ; i++) 5 dest[i] = 0; 6} 1/* Set elements array 0, Unrolled X4 */ 2void clear_array_4(int *dest, int n) { 3 int i; 4 int limit = n-3; 5 (i = 0; < limit; i+= 4) { 6 dest[i] = 0; 7 dest[i+1] = 0; 8 dest[i+2] = 0; 9 dest[i+3] = 0; 10 } 11 (; < limit; i++) 12 dest[i] = 0; 13 } Figure 5.32 Functions set array elements 0. illustrate pipelining store operation. nto zero. measurements ﬁrst version show CPE 2.00. unrolling loop four times, shown code clear_array_4 , achieve CPE 1.00. Thus, achieved optimum one new store operation per cycle. Unlike operations considered far, store operation affect register values. Thus, nature series storeoperations cannot create data dependency. load operation affected bythe result store operation, since load read back memory valuethat written store. function write_read shown Figure 5.33 illustrates potential interactions loads stores. ﬁgure alsoshows two example executions function, called two-element array a, initial contents −10 17, argument cntequal 3. executions illustrate subtleties load store operations. Example Figure 5.33, argument src pointer array element a[0] , dest pointer array element a[1] . case, load pointer reference *src yield value −10. Hence, two iterations, array elements remain ﬁxed −10 −9, respectively. result read srcis affected write dest . Measuring example larger number iterations gives CPE 2.00. Example B Figure 5.33, arguments src anddest pointers array element a[0] . case, load pointer reference *src yield value stored previous execution pointer reference *dest .A sa consequence, series ascending values stored location. general,534 Chapter 5 Optimizing Program Performance 1/* Write dest, read src */ 2void write_read(int *src, int *dest, int n) 3{ 4 int cnt = n; 5 int val = 0; 6 7 (cnt--) { 8 *dest = val; 9 val = (*src)+1; 10 } 11 } InitialExample A: write_read(&a[0],&a[1],3) 3cnt val 0/H1100210 17Iter. 1 2 /H110029/H1100210 0Iter. 2 1 /H110029/H1100210 /H110029Iter. 3 0 /H110029/H1100210 /H110029 InitialExample B: write_read(&a[0],&a[0],3) 3cnt val 0/H1100210 17Iter. 1 2 101 7Iter. 2 1 211 7Iter. 3 0 321 7 Figure 5.33 Code write read memory locations, along illustrative executions. function highlights interactions stores loads arguments src anddest equal. function write_read called arguments srcanddest pointing memory location, argument cnthaving value n>0, net effect set location n−1. example illustrates phenomenon call awrite/read dependency —the outcome memory read depends recent memory write. performance measurements show Example B CPE 6.00. write/read dependency causes slowdown processing. see processor distinguish two cases one runs slower other, must take detailed look load andstore execution units, shown Figure 5.34. store unit contains store buffer containing addresses data store operations issuedto store unit, yet completed, completion involvesupdating data cache. buffer provided series store operationscan executed without wait one update cache. WhenSection 5.12 Understanding Memory Performance 535 Figure 5.34 Detail load storeunits. store unit maintains buffer ofpending writes. load unit must check address storeunit detect write/readdependency.Load unit Store unit Store buffer Address AddressAddressData DataDataMatching addresses Address Data Data cache load operation occurs, must check entries store buffer matching addresses. ﬁnds match (meaning bytes written thesame address bytes read), retrieves corresponding dataentry result load operation. Figure 5.35 shows assembly code inner loop write_read , graphical representation operations generated instruction decoder.The instruction movl %eax,(%ecx) translated two operations: s_addr instruction computes address store operation, creates entry thestore buffer, sets address ﬁeld entry. s_data operation sets data ﬁeld entry. see, fact two computations areperformed independently important program performance. addition data dependencies operations caused writing reading registers, arcs right operators denotea set implicit dependencies operations. particular, addresscomputation s_addr operation must clearly precede s_data operation. addition, load operation generated decoding instruction movl (%ebx), Figure 5.35 Graphical representation inner-loop codefor write_read .The ﬁrstmovl instruction decoded separateoperations compute store address store data memory.%eax %ebx %ecx %edx movl %eax,(%ecx) movl (%ebx),%eax addl $1,%eax subl $1,%edx jne loop %eax %ebx %ecx %edxs_addr s_data load add sub jne536 Chapter 5 Optimizing Program Performance Figure 5.36 Abstracting opera-tions write_read .We ﬁrst rearrange opera-tors Figure 5.35 (a) andthen show oper-ations use values fromone iteration producenew values next (b).%eax %ebx %ecx %edx %eax %edxs_addr1 2 3s_data load (a) (b)addsub jne%eax %edx %eax %edxs_data load add sub %eax must check addresses pending store operations, creating data dependency s_addr operation. ﬁgure shows dashed arc s_data load operations. dependency conditional: two addresses match, load operation must wait s_data deposited result store buffer, two addresses differ, two operationscan proceed independently. Figure 5.36 illustrates clearly data dependencies oper- ations inner loop write_read . Figure 5.36(a), rearranged operations allow dependencies seen clearly. la-beled three dependencies involving load store operations specialattention. arc labeled (1) represents requirement store address must computed data stored. arc labeled (2) representsthe need load operation compare address pend- ing store operations. Finally, dashed arc labeled (3) represents conditionaldata dependency arises load store addresses match. Figure 5.36(b) illustrates happens take away operations directly affect ﬂow data one iteration next. Thedata-ﬂow graph shows two chains dependencies: one left, withdata values stored, loaded, incremented (only case matchingaddresses), one right, decrementing variable cnt. understand performance characteristics function write_ read . Figure 5.37 illustrates data dependencies formed multiple iterations inner loop. case Example Figure 5.33, differing source anddestination addresses, load store operations proceed independently,and hence critical path formed decrementing variable cnt. would lead us predict CPE 1.00, rather measured CPE of2.00. found similar behavior function data beingstored loaded within loop. Apparently effort compare load addresses pending store operations forms additional bottleneck. ForSection 5.12 Understanding Memory Performance 537 Figure 5.37 Data-ﬂow representationof function write_read. two addressesdo match, onlycritical path formed decrementing cnt (Example A). theydo match, chain data stored, loaded, incremented forms thecritical path (Example B).s_data load adds_data load s_data load add subs_data load add sub s_data load add subs_data load add subsub sub addCritical pathExample Example B Critical path case Example B, matching source destination addresses, data dependency s_data load instructions causes critical path form involving data stored, loaded, incremented. found threeoperations sequence require total 6 clock cycles. two examples show, implementation memory operations in- volves many subtleties. operations registers, processor determinewhich instructions affect others decoded opera-tions. memory operations, hand, processor cannot predictwhich affect others load store addresses com-puted. Efﬁcient handling memory operations critical performance ofmany programs. memory subsystem makes use many optimizations, potential parallelism operations proceed independently.538 Chapter 5 Optimizing Program Performance Practice Problem 5.10 another example code potential load-store interactions, consider following function copy contents one array another: 1void copy_array(int *src, int *dest, int n) 2{ 3 int i; 4 f r( i=0 ;i<n ; i++) 5 dest[i] = src[i]; 6} Suppose ais array length 1000 initialized element a[i]equals i. A. would effect call copy_array(a+1,a,999) ? B. would effect call copy_array(a,a+1,999) ? C. performance measurements indicate call part CPE 2.00, call part B CPE 5.00. factor attribute performance difference? D. performance would expect call copy_array(a,a,999) ? Practice Problem 5.11 saw measurements preﬁx-sum function psum1 (Figure 5.1) yield CPE 10.00 machine basic operation performed, ﬂoating-point addition, latency 3 clock cycles. Let us try understand whyour function performs poorly. following assembly code inner loop function: psum1. %rdi,pi n %rsi,ii n %rax, cnt %rdx 1.L5: loop: 2 movss -4(%rsi,%rax,4), %xmm0 Get p[i-1] 3 addss (%rdi,%rax,4), %xmm0 Add a[i] 4 movss %xmm0, (%rsi,%rax,4) Store p[i] 5 addq $1, %rax Increment 6 cmpq %rax, %rdx Compare cnt:i 7 jg .L5 >, goto loop Perform analysis similar shown combine3 (Figure 5.14) write_read (Figure 5.36) diagram data dependencies created loop, hence critical path forms computation proceeds. Explain CPE high. (You may able justify exact CPE, able describe runs slowly one mightexpect.)Section 5.13 Life Real World: Performance Improvement Techniques 539 Practice Problem 5.12 Rewrite code psum1 (Figure 5.1) need repeatedly retrieve value p[i] memory. need use loop unrolling. measured resulting code CPE 3.00, limited latency ofﬂoating-point addition. 5.13 Life Real World: Performance Improvement Techniques Although considered limited set applications, draw important lessons write efﬁcient code. described numberof basic strategies optimizing program performance: 1.High-level design. Choose appropriate algorithms data structures problem hand. especially vigilant avoid algorithms coding tech- niques yield asymptotically poor performance. 2.Basic coding principles. Avoid optimization blockers compiler generate efﬁcient code. Eliminate excessive function calls. Move computations loops whenpossible. Consider selective compromises program modularity gain greater efﬁciency. Eliminate unnecessary memory references. Introduce temporary variablesto hold intermediate results. Store result array global variableonly ﬁnal value computed. 3.Low-level optimizations. Unroll loops reduce overhead enable optimizations. Find ways increase instruction-level parallelism techniques multiple accumulators reassociation. Rewrite conditional operations functional style enable compilationvia conditional data transfers. ﬁnal word advice reader vigilant avoid introducing errors rewrite programs interest efﬁciency. easy makemistakes introducing new variables, changing loop bounds, making thecode complex overall. One useful technique use checking code testeach version function optimized, ensure bugs introducedduring process. Checking code applies series tests new versions ofa function makes sure yield results original. set test cases must become extensive highly optimized code, since cases consider. example, checking code uses loop unrollingrequires testing many different loop bounds make sure handles thedifferent possible numbers single-step iterations required end.540 Chapter 5 Optimizing Program Performance 5.14 Identifying Eliminating Performance Bottlenecks point, considered optimizing small programs, clear place program limits performance therefore shouldbe focus optimization efforts. working large programs, evenknowing focus optimization efforts difﬁcult. sectionwe describe use code proﬁlers , analysis tools collect performance data program executes. also present general principle systemoptimization known Amdahl’s law . 5.14.1 Program Proﬁling Program proﬁling involves running version program instrumenta- tion code incorporated determine much time different partsof program require. useful identifying parts programwe focus optimization efforts. One strength proﬁling itcan performed running actual program realistic benchmark data. Unix systems provide proﬁling program gprof . program generates two forms information. First, determines much CPU time spentfor functions program. Second, computes count howmany times function gets called, categorized function performs call. forms information quite useful. timings give sense ofthe relative importance different functions determining overall runtime. calling information allows us understand dynamic behavior theprogram. Proﬁling gprof requires three steps, shown fo r C program prog.c , runs command line argument file.txt : 1.The program must compiled linked proﬁling. gcc(and C compilers) involves simply including run-time ﬂag ‘ -pg’ command line: unix> gcc -O1 -pg prog.c -o prog 2.The program executed usual: unix> ./prog file.txt runs slightly (around factor 2) slower normal, otherwise difference generates ﬁle gmon.out . 3.gprof invoked analyze data gmon.out . unix> gprof prog ﬁrst part proﬁle report lists times spent executing different functions, sorted descending order. example, following listing showsthis part report three time-consuming functions program:Section 5.14 Identifying Eliminating Performance Bottlenecks 541 % cumulative self self total time seconds seconds calls s/call s/call name 97.58 173.05 173.05 1 173.05 173.05 sort_words 2.36 177.24 4.19 965027 0.00 0.00 find_ele_rec 0.12 177.46 0.22 12511031 0.00 0.00 Strlen row represents time spent calls function. ﬁrst column indicates percentage overall time spent function. Thesecond shows cumulative time spent functions includingthe one row. third shows time spent particular function,and fourth shows many times called (not counting recursive calls).In example, function sort_words called once, single call required 173.05 seconds, function find_ele_rec called 965,027 times (not including recursive calls), requiring total 4.19 seconds. FunctionStrlen computes length string calling library function strlen . Library function calls normally shown results gprof . times usually reported part function calling them. creating “wrapperfunction” Strlen , reliably track calls strlen , showing called 12,511,031 times, requiring total 0.22 seconds. second part proﬁle report shows calling history functions. following history recursive function find_ele_rec : 158655725 find_ele_rec [5] 4.19 0.02 965027/965027 insert_string [4] [5] 2.4 4.19 0.02 965027+158655725 find_ele_rec [5] 0.01 0.01 363039/363039 new_ele [10] 0.00 0.01 363039/363039 save_string [13] 158655725 find_ele_rec [5] history shows functions called find_ele_rec , well functions called. ﬁrst two lines show calls function:158,655,725 calls recursively, 965,027 calls function insert_string (which called 965,027 times). Function find_ele_rec turn called two functions, save_string andnew_ele , total 363,039 times. calling information, often infer useful information program behavior. example, function find_ele_rec recursive procedure scans linked list hash bucket looking particular string. function, comparing number recursive calls number oftop-level calls provides statistical information lengths traversalsthrough lists. Given ratio 164.4, infer programscanned average around 164 elements time. properties gprof worth noting: .The timing precise. based simple interval counting scheme compiled program maintains counter function record-ing time spent executing function. operating system causes theprogram interrupted regular time interval δ. Typical values of542 Chapter 5 Optimizing Program Performance δrange 1.0 10.0 milliseconds. determines function program executing interrupt occurred increments thecounter function δ. course, may happen function started executing shortly completed, assigned full costof execution since previous interrupt. function may runbetween two interrupts therefore charged time all. long duration, scheme works reasonably well. Statistically, ev- ery function charged according relative time spent executingit. programs run less around 1 second, however, numbersshould viewed rough estimates. .The calling information quite reliable. compiled program maintains acounter combination caller callee. appropriate counter isincremented every time procedure called. .By default, timings library functions shown. Instead, thesetimes incorporated times calling functions. 5.14.2 Using Proﬁler Guide Optimization example using proﬁler guide program optimization, created ap- plication involves several different tasks data structures. applicationanalyzes n-gram statistics text document, n-gram sequence ofnwords occurring document. n=1, collect statistics individual words, n=2 pairs words, on. given value n, program reads text ﬁle, creates table unique n-grams specifying many times eachone occurs, sorts n-grams descending order occurrence. benchmark, ran ﬁle consisting complete works William Shakespeare totaling 965,028 words, 23,706 unique. found thatforn=1 even poorly written analysis program readily process entire ﬁle 1 second, set n=2 make things challenging. case n=2, n-grams referred bigrams (pronounced “bye-grams”). determined Shakespeare’s works contain 363,039 unique bigrams. mostcommon “I am,” occurring 1,892 times. phrase “to be” occurs 1,020 times.Fully 266,018 bigrams occur once. program consists following parts. created multiple versions, starting simple algorithms different parts replacing themwith sophisticated ones: 1.Each word read ﬁle converted lowercase. initial version used function lower1 (Figure 5.7), know quadratic run time due repeated calls strlen . 2.A hash function applied string create number 0 s−1, hash table sbuckets. initial function simply summed ASCII codes characters modulo s. 3.Each hash bucket organized linked list. program scans list looking matching entry. one found, frequency n-gramSection 5.14 Identifying Eliminating Performance Bottlenecks 543 Initial Quicksort Iter first Iter last (a) versions (b) slowest versionBig table Better hash Linear lower200 180160 140 120100 8060 40 20 0 6 543210CPU secondsSort ListLowerStrlenHashRest Better hash Quicksort Iter first Iter last Big table Linear lowerCPU secondsSort ListLowerStrlenHashRest Figure 5.38 Proﬁle resultss different versions n-gram frequency counting program. Time divided according different major operations program. incremented. Otherwise, new list element created. initial version performed operation recursively, inserting new elements end ofthe list. 4.Once table generated, sort elements according frequencies. initial version used insertion sort. Figure 5.38 shows proﬁle results six different versions n-gram- frequency analysis program. version, divide time follow-ing categories: Sort: Sorting n-grams frequency List: Scanning linked list matching n-gram, inserting new element necessary Lower: Converting strings lowercase544 Chapter 5 Optimizing Program Performance Strlen: Computing string lengths Hash: Computing hash function Rest: sum functions part (a) ﬁgure shows, initial version required nearly 3 minutes, time spent sorting. surprising, since insertion sort hasquadratic run time, program sorted 363,039 values. next version, performed sorting using library function qsort , based quicksort algorithm, run time O(n logn). version labeled “Quicksort” ﬁgure. efﬁcient sorting algorithm reducesthe time spent sorting become negligible, overall run time around4.7 seconds. Part (b) ﬁgure shows times remaining version ascale see clearly. improved sorting, ﬁnd list scanning becomes bottleneck. Thinking inefﬁciency due recursive structure function,we replaced iterative one, shown “Iter ﬁrst.” Surprisingly, runtime increases around 5.9 seconds. closer study, ﬁnd subtle differencebetween two list functions. recursive version inserted new elements theend list, iterative one inserted front. maximizeperformance, want frequent n-grams occur near beginnings ofthe lists. way, function quickly locate common cases. Assumingthat n-grams spread uniformly throughout document, would expectthe ﬁrst occurrence frequent one come less frequentone. inserting new n-grams end, ﬁrst function tended order n-grams descending order frequency, second function tended dojust opposite. therefore created third list-scanning function usesiteration, inserts new elements end list. version, shownas “Iter last,” time dropped around 4.2 seconds, slightly better therecursive version. measurements demonstrate importance runningexperiments program part optimization effort. initially assumedthat converting recursive code iterative code would improve performanceand consider distinction adding end beginningof list. Next, consider hash table structure. initial version 1021 buckets (typically, number buckets chosen prime number toenhance ability hash function distribute keys uniformly among thebuckets). table 363,039 entries, would imply average load 363039 /1021=355.6. explains much time spent performing list operations—the searches involve testing signiﬁcant number candidate n-grams. also explains performance sensitive list ordering. increased number buckets 199,999, reducing average load 1.8. Oddly enough, however, overall run time drops 3.9 seconds, difference 0.3 seconds. inspection, see minimal performance gain larger table due poor choice hash function. Simply summing charac-ter codes string produce wide range values. particular,Section 5.14 Identifying Eliminating Performance Bottlenecks 545 maximum code value letter 122, string ncharacters generate sum 122 n. longest bigram document, “honoriﬁca- bilitudinitatibus thou,” sums 3371, buckets hashtable go unused. addition, commutative hash function, addition,does differentiate among different possible orderings characters astring. example, words “rat” “tar” generate sums. switched hash function uses shift Exclusive-Or operations. version, shown “Better hash,” time drops 0.4 seconds. moresystematic approach would study distribution keys among bucketsmore carefully, making sure comes close one would expect thehash function uniform output distribution. Finally, reduced run time point time spent strlen , calls strlen occur part lowercase con- version. already seen function lower1 quadratic performance, especially long strings. words document short enough avoidthe disastrous consequences quadratic performance; longest bigram 32 characters. Still, switching lower2 , shown “Linear lower,” yields signif- icant performance, overall time dropping around 0.2 seconds. exercise, shown code proﬁling help drop time required simple application nearly 3 minutes well under1 second. proﬁler helps us focus attention time-consumingparts program also provides useful information procedurecall structure. bottlenecks code, using quadratic sortroutine, easy anticipate, others, whether append thebeginning end list, emerge careful analysis. see proﬁling useful tool toolbox, one. timing measurements imperfect, especially shorter(less 1 second) run times. signiﬁcantly, results apply theparticular data tested. example, run original function dataconsisting smaller number longer strings, would found thelowercase conversion routine major performance bottleneck. Even worse,if proﬁled documents short words, might never detect hidden bottlenecks quadratic performance lower1 . general, proﬁling help us optimize typical cases, assuming run program representative data, also make sure program respectable performancefor possible cases. mainly involves avoiding algorithms (such insertionsort) bad programming practices (such lower1 ) yield poor asymptotic performance. 5.14.3 Amdahl’s Law Gene Amdahl, one early pioneers computing, made simple insight- ful observation effectiveness improving performance one partof system. observation come known Amdahl’s law . main idea speed one part system, effect overall sys-tem performance depends signiﬁcant part much sped up. Consider system executing application requires time546 Chapter 5 Optimizing Program Performance Told. Suppose part system requires fraction αof time, improve performance factor k. is, component originally re- quired time αTold, requires time (αTold)/k. overall execution time would thus Tnew=(1−α)T old+(αT old)/k =Told[(1−α)+α/k] this, compute speedup S=Told/Tnewas S=1 (1−α)+α/k(5.4) example, consider case part system initially consumed 60% time ( α=0.6) sped factor 3 ( k=3). get speedup 1 /[0.4+0.6/3]=1.67. Thus, even though made substantial improvement major part system, net speedup signiﬁcantly less. major insight Amdahl’s law—to signiﬁcantly speed theentire system, must improve speed large fraction overallsystem. Practice Problem 5.13 Suppose work truck driver, hired carry load potatoes Boise, Idaho, Minneapolis, Minnesota, total distance 2500kilometers. estimate average 100 km/hr driving within speed limits, requiring total 25 hours trip. A. hear news Montana abolished speed limit, constitutes 1500 km trip. truck travel 150 km/hr. willbe speedup trip? B. buy new turbocharger truck www.fasttrucks.com . stock variety models, faster want go, willcost. fast must travel Montana get overall speedupfor trip 5/3? Practice Problem 5.14 marketing department company promised customers thatthe next software release show 2 ×performance improvement. assigned task delivering promise. determined thatonly 80% system improved. much (i.e., value k) would need improve part meet overall performance target?Section 5.15 Summary 547 One interesting special case Amdahl’s law consider effect setting kto∞. is, able take part system speed point takes negligible amount time. get S∞=1 (1−α)(5.5) So, example, speed 60% system point re- quires close time, net speedup still 1 /0.4=2.5. saw performance dictionary program replaced insertion sort quick-sort. initial version spent 173.05 177.57 seconds performing insertionsort, giving α=0.975. quicksort, time spent sorting becomes negligible, giving predicted speedup 39.3. fact, actual measured speedup abit less: 173 .05/4.72=37.6, due inaccuracies proﬁling measurements. able gain large speedup sorting constituted large fraction overall execution time. Amdahl’s law describes general principle improving process. addition applying speeding computer systems, guide companytrying reduce cost manufacturing razor blades, student trying toimprove gradepoint average. Perhaps meaningful worldof computers, routinely improve performance factors 2 more.Such high factors achieved optimizing large parts system. 5.15 Summary Although presentations code optimization describe compilers cangenerate efﬁcient code, much done application programmer assistthe compiler task. compiler replace inefﬁcient algorithm datastructure good one, aspects program design remaina primary concern programmers. also seen optimization block-ers, memory aliasing procedure calls, seriously restrict ability ofcompilers perform extensive optimizations. Again, programmer must takeprimary responsibility eliminating these. simply consideredparts good programming practice, since serve eliminate unneeded work. Tuning performance beyond basic level requires understanding processor’s microarchitecture, describing underlying mechanisms whichthe processor implements instruction set architecture. case out-of-order processors, knowing something operations, latencies, andissue times functional units establishes baseline predicting programperformance. studied series techniques, including loop unrolling, creating multiple accumulators, reassociation, exploit instruction-levelparallelism provided modern processors. get deeper optimiza-tion, becomes important study generated assembly code, try tounderstand computation performed machine. Much canbe gained identifying critical paths determined data dependencies548 Chapter 5 Optimizing Program Performance program, especially different iterations loop. also compute throughput bound computation, based number oper-ations must computed number issue times units thatperform operations. Programs involve conditional branches complex interactions memory system difﬁcult analyze optimize simpleloop programs ﬁrst considered. basic strategy try make branchesmore predictable make amenable implementation using conditionaldata transfers. must also watch interactions store andload operations. Keeping values local variables, allowing stored inregisters, often helpful. working large programs, becomes important focus op- timization efforts parts consume time. Code proﬁlers andrelated tools help us systematically evaluate improve program perfor- mance. described gprof , standard Unix proﬁling tool. sophisticated proﬁlers available, vtune program development system In- tel, valgrind , commonly available Linux systems. tools break execution time procedure level, estimate performanceof basic block program. (A basic block sequence instructions transfers control middle, block always executedin entirety.) Amdahl’s law provides simple powerful insight performance gains obtained improving one part system. gain depends bothon much improve part large fraction overall timethis part originally required. Bibliographic Notes focus describe code optimization programmer’s per-spective, demonstrating write code make easier compilers togenerate efﬁcient code. extended paper Chellappa, Franchetti, P ¨uschel [19] takes similar approach, goes detail respect pro-cessor’s characteristics. Many publications describe code optimization compiler’s perspective, formulating ways compilers generate efﬁcient code. Muchnick’sbook considered comprehensive [76]. Wadleigh Crawford’s bookon software optimization [114] covers material presented,but also describes process getting high performance parallel machines.An early paper Mahlke et al. [71] describes several techniques developedfor compilers map programs onto parallel machines adapted exploitthe instruction-level parallelism modern processors. paper covers code transformations presented, including loop unrolling, multiple accumulators (which refer accumulator variable expansion ), reassociation (which refer tree height reduction ). presentation operation out-of-order processor fairly brief abstract. complete descriptions general principles found inHomework Problems 549 advanced computer architecture textbooks, one Hennessy Pat- terson [49, Ch. 2–3]. Shen Lipasti’s book [96] provides in-depth treatmentof modern processor design. Amdahl’s law presented books computer architecture. major focus quantitative system evaluation, Hennessy Patterson’s book[49, Ch. 1] provides particularly good treatment subject. Homework Problems 5.15◆◆ Suppose wish write procedure computes inner product twovectors uandv. abstract version function CPE 16–17 x86- 64 26–29 IA32 integer, single-precision, double-precision data. Bydoing sort transformations transform abstract programcombine1 efﬁcient combine4 , get following code: 1/* Accumulate temporary */ 2void inner4(vec_ptr u, vec_ptr v, data_t *dest) 3{ 4 long int i; 5 int length = vec_length(u); 6 data_t *udata = get_vec_start(u); 7 data_t *vdata = get_vec_start(v); 8 data_t sum = (data_t) 0; 9 10 (i = 0; < length; i++) { 11 sum = sum + udata[i] * vdata[i]; 12 } 13 *dest = sum; 14 } measurements show function CPE 3.00 integer ﬂoating-point data. data type float , x86-64 assembly code inner loop follows: inner4: data_t = float udata %rbx, vdata %rax, limit %rcx, ii n %rdx, sum %xmm1 1.L87: loop: 2 movss (%rbx,%rdx,4), %xmm0 Get udata[i] 3 mulss (%rax,%rdx,4), %xmm0 Multiply vdata[i] 4 addss %xmm0, %xmm1 Add sum 5 addq $1, %rdx Increment 6 cmpq %rcx, %rdx Compare i:limit 7 jl .L87 <, goto loop550 Chapter 5 Optimizing Program Performance Assume functional units characteristics listed Figure 5.12. A. Diagram instruction sequence would decoded operations show data dependencies would create criticalpath operations, style Figures 5.13 5.14. B. data type float , lower bound CPE determined critical path? C. Assuming similar instruction sequences integer code well, lower bound CPE determined critical path integer data? D. Explain two ﬂoating-point versions CPEs 3.00, even though multiplication operation requires either 4 5 clock cycles. 5.16◆ Write version inner product procedure described Problem 5.15 uses four-way loop unrolling. x86-64, measurements unrolled version give CPE 2.00 integer data still 3.00 single double precision. A. Explain version inner product procedure cannot achieve CPE less 2.00. B. Explain performance ﬂoating-point data improve loop unrolling. 5.17◆ Write version inner product procedure described Problem 5.15 thatuses four-way loop unrolling four parallel accumulators. measurementsfor function x86-64 give CPE 2.00 types data. A. factor limits performance CPE 2.00? B. Explain version integer data IA32 achieves CPE 2.75, worse CPE 2.25 achieved four-way loop unrolling. 5.18◆ Write version inner product procedure described Problem 5.15 usesfour-way loop unrolling along reassociation enable greater parallelism. measurements function give CPE 2.00 x86-64 2.25 withIA32 types data. 5.19◆◆ library function memset following prototype: void *memset(void *s, int c, size_t n); function ﬁlls nbytes memory area starting swith copies low- order byte c. example, used zero region memory giving argument 0 c, values possible.Homework Problems 551 following straightforward implementation memset : 1/* Basic implementation memset */ 2void *basic_memset(void *s, int c, size_t n) 3{ 4 size_t cnt = 0; 5 unsigned char *schar = s; 6 (cnt < n) { 7 *schar++ = (unsigned char) c; 8 cnt++; 9 } 10 return s; 11 } Implement efﬁcient version function using word data typeunsigned long pack four (for IA32) eight (for x86-64) copies c, step region using word-level writes. might ﬁnd helpful additional loop unrolling well. Intel Core i7 machine, ableto reduce CPE 2.00 straightforward implementation 0.25 forIA32 0.125 x86-64, i.e., writing either 4 8 bytes every clock cycle. additional guidelines. discussion, let Kdenote value ofsizeof(unsigned long) machine run program. .You may call library functions. .Your code work arbitrary values n, including multiple K. manner similar way ﬁnish last iterations loop unrolling. .You write code compile run correctly regardlessof value K. Make use operation sizeof this. .On machines, unaligned writes much slower aligned ones. (On non-x86 machines, even cause segmentation faults.) Writeyour code starts byte-level writes destination addressis multiple K, word-level writes, (if necessary) ﬁnish byte-level writes. .Beware case cnt small enough upper bounds loops become negative. expressions involving sizeof operator, testing may performed unsigned arithmetic. (See Sec-tion 2.2.8 Problem 2.72.) 5.20◆◆◆ considered task polynomial evaluation Problems 5.5 5.6, withboth direct evaluation evaluation Horner’s method. Try writefaster versions function using optimization techniques explored,including loop unrolling, parallel accumulation, reassociation. ﬁndmany different ways mixing together Horner’s scheme direct evaluationwith optimization techniques.552 Chapter 5 Optimizing Program Performance Ideally, able reach CPE close number cycles successive ﬂoating-point additions multiplications machine(typically 1). least, able achieve CPE less thelatency ﬂoating-point addition machine. 5.21◆◆◆ Problem 5.12, able reduce CPE preﬁx-sum computationto 3.00, limited latency ﬂoating-point addition machine. Simpleloop unrolling improve things. Using combination loop unrolling reassociation, write code pre- ﬁx sum achieves CPE less latency ﬂoating-point addition onyour machine. requires actually increasing number additions per-formed. example, version two-way unrolling requires three additionsper iteration, version three-way unrolling requires ﬁve. 5.22◆ Suppose given task improving performance programconsisting three parts. Part requires 20% overall run time, part Brequires 30%, part C requires 50%. determine $1000 couldeither speed part B factor 3.0 part C factor 1.5. choicewould maximize performance? Solutions Practice Problems Solution Problem 5.1 (page 478) problem illustrates subtle effects memory aliasing. following commented code shows, effect set value xpto zero: 4 *xp = *xp + *xp; /* 2x */ 5 *xp = *xp - *xp; /* 2x-2 x=0* / 6 *xp = *xp - *xp; / *0 - 0=0* / example illustrates intuition program behavior often wrong. naturally think case xpandypare distinct overlook possibility might equal. Bugs often arise due conditions theprogrammer anticipate. Solution Problem 5.2 (page 482) problem illustrates relationship CPE absolute performance.It solved using elementary algebra. ﬁnd n≤2, Version 1 fastest. Version 2 fastest 3 ≤n≤7, Version 3 fastest n≥8. Solution Problem 5.3 (page 490) simple exercise, important recognize four statements aforloop—initial, test, update, body—get executed different numbers times.Solutions Practice Problems 553 Code min max incr square A. 1 91 90 90 B. 91 1 90 90 C. 1 1 90 90 Solution Problem 5.4 (page 494) assembly code demonstrates clever optimization opportunity detected gcc. worth studying code carefully better understand subtleties code optimization. A. less optimized code, register %xmm0 simply used temporary value, set used loop iteration. optimized code, itis used manner variable xincombine4 , accumulating product vector elements. difference combine4 , however, location dest updated iteration second movss instruction. see optimized version operates much like following C code: 1/* Make sure dest updated iteration */ 2void combine3w(vec_ptr v, data_t *dest) 3{ 4 long int i; 5 long int length = vec_length(v); 6 data_t *data = get_vec_start(v); 7 data_t acc = IDENT; 8 9 (i = 0; < length; i++) { 10 acc = acc OP data[i]; 11 *dest = acc; 12 } 13 } B. two versions combine3 identical functionality, even memory aliasing. C. transformation made without changing program behavior, because, exception ﬁrst iteration, value read dest beginning iteration value written registerat end previous iteration. Therefore, combining instructioncan simply use value already %xmm0 beginning loop. Solution Problem 5.5 (page 507) Polynomial evaluation core technique solving many problems. example, polynomial functions commonly used approximate trigonometric functionsin math libraries.554 Chapter 5 Optimizing Program Performance A. function performs 2 nmultiplications nadditions. B. see performance limiting computation repeated computation expression x p w r=x* xpwr . requires double- precision, ﬂoating-point multiplication (5 clock cycles), computationfor one iteration cannot begin one previous iteration hascompleted. updating result requires ﬂoating-point addition (3 clock cycles) successive iterations. Solution Problem 5.6 (page 508) problem demonstrates minimizing number operations com- putation may improve performance. A. function performs nmultiplications nadditions, half number multiplications original function poly . B. see performance limiting computation repeated computation expression result = a[i] + x*result . Starting value result previous iteration, must ﬁrst multiply x (5 clock cycles) add a[i] (3 cycles) value iteration. Thus, iteration imposes minimum latency 8 cycles,exactly measured CPE. C. Although iteration function poly requires two multiplications rather one, single multiplication occurs along critical path periteration. Solution Problem 5.7 (page 510) following code directly follows rules stated unrolling loopby factor k: 1void unroll5(vec_ptr v, data_t *dest) 2{ 3 long int i; 4 long int length = vec_length(v); 5 long int limit = length-4; 6 data_t *data = get_vec_start(v); 7 data_t acc = IDENT; 8 9 /* Combine 5 elements time */ 10 (i = 0; < limit; i+=5) { 11 acc = acc OP data[i] OP data[i+1]; 12 acc = acc OP data[i+2] OP data[i+3]; 13 acc = acc OP data[i+4]; 14 } 1516 /* Finish remaining elements */ 17 (; < length; i++) { 18 acc = acc OP data[i];Solutions Practice Problems 555 rA1:((r*x)*y)*z rxyz * * * *rA2:(r*(x*y))*z rxyz * * *rA3:r*((x*y)*z) rxyz * * *rA4:r*(x*(y*z)) rxyz * * *rA5:(r*x)*(y*z) rxyz * * Figure 5.39 Data dependencies among multiplication operations cases Problem 5.8. operations shown blue boxes form critical path iteration. 19 } 20 *dest = acc; 21 } Solution Problem 5.8 (page 523) problem demonstrates small changes program yield dramatic performance differences, especially machine out-of-order execution.Figure 5.39 diagrams three multiplication operations single iteration ofthe function. ﬁgure, operations shown blue boxes along criticalpath—they need computed sequence compute new value loopvariable r. operations shown light boxes computed parallel critical path operations. loop coperations along critical path, iteration require minimum 5 cclock cycles compute product three elements, giving lower bound CPE 5 c/3. implies lower bounds 5.00 A1, 3.33 A2 A5, 1.67 A3 A4. ran functions Intel Core i7, indeed obtained CPEs 5.00 A1, 1.67 A3 A4. reason, A2 A5 achieved CPEs ofjust 3.67, indicating functions required 11 clock cycles per iteration ratherthan predicted 10. Solution Problem 5.9 (page 530) another demonstration slight change coding style make mucheasier compiler detect opportunities use conditional moves: (i 1<n& &i 2<n ){ int v1 = src1[i1]; int v2 = src2[i2]; int take1 = v1 < v2; dest[id++] = take1 ? v1 : v2; i1 += take1; i2 += (1-take1); }556 Chapter 5 Optimizing Program Performance measured CPE around 11.50 version code, signiﬁcant improvement original CPE 17.50. Solution Problem 5.10 (page 538) problem requires analyze potential load-store interactions aprogram. A. set element a[i]toi+1, 0 ≤i≤998. B. set element a[i]to 0, 1 ≤i≤999. C. second case, load one iteration depends result store previous iteration. Thus, write/read dependency betweensuccessive iterations. interesting note CPE 5.00 1 lessthan measured Example B function write_read . due fact write_read increments value storing it, requiring one clock cycle. D. give CPE 2.00, Example A, since dependencies stores subsequent loads. Solution Problem 5.11 (page 538) see function write/read dependency successiveiterations—the destination value p[i] one iteration matches source value p[i-1] next. Solution Problem 5.12 (page 539) revised version function: 1void psum1a(float a[], float p[], long int n) 2{ 3 long int i; 4 /* last_val holds p[i-1]; val holds p[i] */ 5 float last_val, val; 6 last_val = p[0] = a[0]; 7 f r( i=1 ;i<n ; i++) { 8 val = last_val + a[i]; 9 p[i] = val; 10 last_val = val; 11 } 12 } introduce local variable last_val . start iteration i, holds value p[i-1] . compute valto value p[i] new value last_val . version compiles following assembly code: psum1a. %rdi,pi n %rsi,ii n %rax, cnt %rdx, last_val %xmm0 1.L18: loop: 2 addss (%rdi,%rax,4), %xmm0 last_val = val = last_val + a[i]Solutions Practice Problems 557 3 movss %xmm0, (%rsi,%rax,4) Store val p[i] 4 addq $1, %rax Increment 5 cmpq %rax, %rdx Compare cnt:i 6 jg .L18 >, goto loop code holds last_val in%xmm0 , avoiding need read p[i-1] memory, thus eliminating write/read dependency seen psum1 . Solution Problem 5.13 (page 546) problem illustrates Amdahl’s law applies computer systems. A. terms Equation 5.4, α=0.6 k=1.5. directly, travel- ing 1500 kilometers Montana require 10 hours, restof trip also requires 10 hours. give speedup 25 /(10+10)= 1.25. B. terms Equation 5.4, α=0.6, require S=5/3, solve k. directly, speed trip 5/3, must decrease overall time 15 hours. parts outside Montana stillrequire 10 hours, must drive Montana 5 hours. requires traveling 300 km/hr, pretty fast truck! Solution Problem 5.14 (page 546) Amdahl’s law best understood working examples. onerequires look Equation 5.4 unusual perspective. problem simple application equation. given S=2 α=.8, must solve k: 2=1 (1−0.8)+0.8/k 0.4+1.6/k=1.0 k=2.67This page intentionally left blank CHAPTER6 Memory Hierarchy 6.1 Storage Technologies 561 6.2 Locality 586 6.3 Memory Hierarchy 591 6.4 Cache Memories 596 6.5 Writing Cache-friendly Code 615 6.6 Putting Together: Impact Caches Program Performance 620 6.7 Summary 629 Bibliographic Notes 630Homework Problems 631Solutions Practice Problems 642 559560 Chapter 6 Memory Hierarchy point study systems, relied simple model computer system CPU executes instructions memory system thatholds instructions data CPU. simple model, memory systemis linear array bytes, CPU access memory location aconstant amount time. effective model far goes, doesnot reﬂect way modern systems really work. practice, memory system hierarchy storage devices different capacities, costs, access times. CPU registers hold frequently useddata. Small, fast cache memories nearby CPU act staging areas subset data instructions stored relatively slow main memory. mainmemory stages data stored large, slow disks, turn often serve asstaging areas data stored disks tapes machines connected bynetworks. Memory hierarchies work well-written programs tend access storage particular level frequently access storage thenext lower level. storage next level slower, thus larger cheaper per bit. overall effect large pool memory costs asmuch cheap storage near bottom hierarchy, serves datato programs rate fast storage near top hierarchy. programmer, need understand memory hierarchy big impact performance applications. data programneeds stored CPU register, accessed zero cycles duringthe execution instruction. stored cache, 1 30 cycles. stored mainmemory, 50 200 cycles. stored disk tens millions cycles! Here, then, fundamental enduring idea computer systems: understand system moves data memory hierarchy, thenyou write application programs data items stored higherin hierarchy, CPU access quickly. idea centers around fundamental property computer programs known locality . Programs good locality tend access set data items again, tend access sets nearby data items.Programs good locality tend access data items upper levels memory hierarchy programs poor locality, thus run faster. example, running times different matrix multiplication kernels performthe number arithmetic operations, different degrees locality,can vary factor 20! chapter, look basic storage technologies—SRAM mem- ory, DRAM memory, ROM memory, rotating solid state disks—anddescribe organized hierarchies. particular, focus thecache memories act staging areas CPU main memory, be-cause impact application program performance. showyou analyze C programs locality introduce techniquesfor improving locality programs. also learn interestingway characterize performance memory hierarchy particularmachine “memory mountain” shows read access times function oflocality.Section 6.1 Storage Technologies 561 6.1 Storage Technologies Much success computer technology stems tremendous progress storage technology. Early computers kilobytes random-accessmemory. earliest IBM PCs didn’t even hard disk. changed withthe introduction IBM PC-XT 1982, 10-megabyte disk. year2010, typical machines 150,000 times much disk storage, amount ofstorage increasing factor 2 every couple years. 6.1.1 Random-Access Memory Random-access memory (RAM) comes two varieties— static dynamic .Static RAM (SRAM) faster signiﬁcantly expensive Dynamic RAM (DRAM). SRAM used cache memories, CPU chip.DRAM used main memory plus frame buffer graphics system.Typically, desktop system megabytes SRAM,but hundreds thousands megabytes DRAM. Static RAM SRAM stores bit bistable memory cell. cell implemented six-transistor circuit. circuit property stay indeﬁnitelyin either two different voltage conﬁgurations, states. state unstable—starting there, circuit quickly move toward one thestable states. memory cell analogous inverted pendulum illustratedin Figure 6.1. pendulum stable tilted either way left way right. position, pendulum fall one side theother. principle, pendulum could also remain balanced vertical positionindeﬁnitely, state metastable —the smallest disturbance would make start fall, fell would never return vertical position. Due bistable nature, SRAM memory cell retain value indef- initely, long kept powered. Even disturbance, electrical noise, perturbs voltages, circuit return stable value disturbance removed. Figure 6.1 Inverted pendulum.Like SRAM cell, pendulum two stable conﬁgurations, orstates .Stable left Stable right Unstable562 Chapter 6 Memory Hierarchy Transistors Relative Relative per bit access time Persistent? Sensitive? cost Applications SRAM 6 1 × Yes 100 × Cache memory DRAM 1 10 × Yes 1 × Main mem, frame buffers Figure 6.2 Characteristics DRAM SRAM memory. Dynamic RAM DRAM stores bit charge capacitor. capacitor small— typically around 30 femtofarads, is, 30 ×10−15farads. Recall, however, farad large unit measure. DRAM storage made dense—each cell consists capacitor single access transistor. Unlike SRAM,however, DRAM memory cell sensitive disturbance. thecapacitor voltage disturbed, never recover. Exposure light rays willcause capacitor voltages change. fact, sensors digital cameras andcamcorders essentially arrays DRAM cells. Various sources leakage current cause DRAM cell lose charge within time period around 10 100 milliseconds. Fortunately, computersoperating clock cycle times measured nanoseconds, retention time isquite long. memory system must periodically refresh every bit memory byreading rewriting it. systems also use error-correcting codes,where computer words encoded bits (e.g., 32-bit word mightbe encoded using 38 bits), circuitry detect correct singleerroneous bit within word. Figure 6.2 summarizes characteristics SRAM DRAM memory. SRAM persistent long power applied. Unlike DRAM, refresh isnecessary. SRAM accessed faster DRAM. SRAM sensitive todisturbances light electrical noise. trade-off SRAM cellsuse transistors DRAM cells, thus lower densities, moreexpensive, consume power. Conventional DRAMs cells (bits) DRAM chip partitioned dsupercells , consisting ofwDRAM cells. d×wDRAM stores total dwbits information. supercells organized rectangular array rrows ccolumns, rc=d. supercell address form (i, j) , idenotes row, andjdenotes column. example, Figure 6.3 shows organization 16 ×8 DRAM chip d=16 supercells, w=8 bits per supercell, r=4 rows, c=4 columns. shaded box denotes supercell address (2,1). Information ﬂows chip via external connectors called pins. pin carries 1-bit signal. Figure 6.3 shows two sets pins: eight data pins transfer 1 byteSection 6.1 Storage Technologies 563 Figure 6.3 High-level view 128-bit 16 ×8 DRAM chip. Memory controller2 addr 8 data(to CPU)DRAM chip Cols 0 0 1 2 3123 Supercell (2,1) Internal row bufferRows chip, two addr pins carry two-bit row column supercell addresses. pins carry control information shown. Aside note terminology storage community never settled standard name DRAM array element. Computer architects tend refer “cell,” overloading term DRAM storage cell. Circuitdesigners tend refer “word,” overloading term word main memory. avoidconfusion, adopted unambiguous term “supercell.” DRAM chip connected circuitry, known memory controller , transfer wbits time DRAM chip. read contents supercell (i, j) , memory controller sends row address ito DRAM, followed column address j. DRAM responds sending contents supercell (i, j) back controller. row address iis called RAS (Row Access Strobe) request . column address jis called CAS (Column Access Strobe) request . Notice RAS CAS requests share DRAM address pins. example, read supercell (2,1)from 16 ×8 DRAM Figure 6.3, memory controller sends row address 2, shown Figure 6.4(a). DRAMresponds copying entire contents row 2 internal row buffer. Next,the memory controller sends column address 1, shown Figure 6.4(b). TheDRAM responds copying 8 bits supercell (2,1)from row buffer sending memory controller. One reason circuit designers organize DRAMs two-dimensional arrays instead linear arrays reduce number address pins chip. Forexample, example 128-bit DRAM organized linear array 16supercells addresses 0 15, chip would need four address pinsinstead two. disadvantage two-dimensional array organization isthat addresses must sent two distinct steps, increases access time.564 Chapter 6 Memory Hierarchy Memory controllerRASRAS /H1100522 8 dataDRAM chip Cols 0 0 1 2 3123 Internal row buffer (a) Select row 2 (RAS request).Rows Row 22 addr (b) Select column 1 (CAS request).Memory controller2CASCAS /H1100511 addr 8 dataSupercell (2,1)DRAM chip Cols 0 0 1 2 3123 Internal row bufferRows Figure 6.4 Reading contents DRAM supercell. Memory Modules DRAM chips packaged memory modules plug expansion slots main system board (motherboard). Common packages include 168-pindual inline memory module (DIMM), transfers data memory controller 64-bit chunks, 72-pin single inline memory module (SIMM), transfers data 32-bit chunks. Figure 6.5 shows basic idea memory module. example module stores total 64 MB (megabytes) using eight 64-Mbit 8 M×8 DRAM chips, numbered 0 7. supercell stores 1 byte main memory , 64- bit doubleword 1at byte address main memory represented eight supercells whose corresponding supercell address (i, j) . example Figure 6.5, DRAM 0 stores ﬁrst (lower-order) byte, DRAM 1 stores nextbyte, on. retrieve 64-bit doubleword memory address A, memory controller converts Ato supercell address (i, j) sends memory module, broadcasts iandjto DRAM. response, DRAM outputs 8- bit contents (i, j) supercell. Circuitry module collects outputs forms 64-bit doubleword, returns memory controller. Main memory aggregated connecting multiple memory modules memory controller. case, controller receives address A, controller selects module kthat contains A, converts Ato its(i, j) form, sends (i, j) module k. 1. IA32 would call 64-bit quantity “quadword.”Section 6.1 Storage Technologies 565 addr (row = i, col = j) DRAM 7DRAM 0 data: Supercell (i,j) 64 MB memory moduleconsisting of8 8M /H110038 DRAMs Memory controller 64-bit doubleword CPU chip64-bit doubleword main memory address Abits 0-7bits 8-15bits 16-23bits 24-31bits 32-39bits 40-47bits 48-55bits 56-63 63 56 55 48 47 40 39 32 31 24 23 16 15 8 7 0 Figure 6.5 Reading contents memory module. Practice Problem 6.1 following, let rbe number rows DRAM array, cthe number columns, brthe number bits needed address rows, bcthe number bits needed address columns. following DRAMs, deter-mine power-of-two array dimensions minimize max (b r,bc), maximum number bits needed address rows columns array. Organization rc b r bc max(br,bc) 16×1 16×4 128×8 512×4 1024×4 Enhanced DRAMs many kinds DRAM memories, new kinds appear mar- ket regularity manufacturers attempt keep rapidly increasing566 Chapter 6 Memory Hierarchy processor speeds. based conventional DRAM cell, optimiza- tions improve speed basic DRAM cells accessed. .Fast page mode DRAM (FPM DRAM) . conventional DRAM copies entire row supercells internal row buffer, uses one, discardsthe rest. FPM DRAM improves allowing consecutive accesses tothe row served directly row buffer. example, readfour supercells row iof conventional DRAM, memory controller must send four RAS/CAS requests, even though row address iis identical case. read supercells row FPM DRAM, thememory controller sends initial RAS/CAS request, followed three CASrequests. initial RAS/CAS request copies row iinto row buffer returns supercell addressed CAS. next three supercells areserved directly row buffer, thus quickly initialsupercell. .Extended data DRAM (EDO DRAM) . enhanced form FPM DRAM allows individual CAS signals spaced closer together time. .Synchronous DRAM (SDRAM) . Conventional, FPM, EDO DRAMs asynchronous sense communicate memory controllerusing set explicit control signals. SDRAM replaces many controlsignals rising edges external clock signal drives thememory controller. Without going detail, net effect SDRAM output contents supercells faster rate asynchronous counterparts. .Double Data-Rate Synchronous DRAM (DDR SDRAM) . DDR SDRAM enhancement SDRAM doubles speed DRAM usingboth clock edges control signals. Different types DDR SDRAMs arecharacterized size small prefetch buffer increases effectivebandwidth: DDR (2 bits), DDR2 (4 bits), DDR3 (8 bits). .Rambus DRAM (RDRAM) . alternative proprietary technology higher maximum bandwidth DDR SDRAM. .Video RAM (VRAM) . Used frame buffers graphics systems. VRAM similar spirit FPM DRAM. Two major differences (1) VRAMoutput produced shifting entire contents internal buffer insequence, (2) VRAM allows concurrent reads writes memory.Thus, system painting screen pixels frame buffer(reads) concurrently writing new values next update (writes). Aside Historical popularity DRAM technologies 1995, PCs built FPM DRAMs. 1996 1999, EDO DRAMs dominated market, FPM DRAMs disappeared. SDRAMs ﬁrst appeared 1995 high-end systems, 2002 PCs built SDRAMs DDR SDRAMs. 2010, server desktop systems built DDR3 SDRAMs. fact, Intel Core i7 supports DDR3 SDRAM.Section 6.1 Storage Technologies 567 Nonvolatile Memory DRAMs SRAMs volatile sense lose information supply voltage turned off. Nonvolatile memories , hand, retain information even powered off. variety nonvolatilememories. historical reasons, referred collectively read-only memories (ROMs), even though types ROMs written well read. ROMs distinguished number times reprogrammed(written to) mechanism reprogramming them. Aprogrammable ROM (PROM) programmed exactly once. PROMs include sort fuse memory cell blown zapping itwith high current. Anerasable programmable ROM (EPROM) transparent quartz window permits light reach storage cells. EPROM cells cleared zerosby shining ultraviolet light window. Programming EPROM doneby using special device write ones EPROM. EPROM beerased reprogrammed order 1000 times. electrically erasable PROM (EEPROM) akin EPROM, require physically separate programming device, thus reprogrammed in-place printed circuit cards. EEPROM reprogrammed order 10 5times wears out. Flash memory type nonvolatile memory, based EEPROMs, become important storage technology. Flash memories everywhere,providing fast durable nonvolatile storage slew electronic devices, including digital cameras, cell phones, music players, PDAs, laptop, desktop, server computer systems. Section 6.1.3, look detail new formof ﬂash-based disk drive, known solid state disk (SSD), provides faster, sturdier, less power-hungry alternative conventional rotating disks. Programs stored ROM devices often referred ﬁrmware . computer system powered up, runs ﬁrmware stored ROM. Somesystems provide small set primitive input output functions ﬁrmware, forexample, PC’s BIOS (basic input/output system) routines. Complicated devicessuch graphics cards disk drive controllers also rely ﬁrmware translate I/O (input/output) requests CPU. Accessing Main Memory Data ﬂows back forth processor DRAM main memory shared electrical conduits called buses . transfer data CPU memory accomplished series steps called bus transaction . Aread transaction transfers data main memory CPU. write transaction transfers data CPU main memory. Abusis collection parallel wires carry address, data, control signals. Depending particular bus design, data address signals sharethe set wires, use different sets. Also, two devices canshare bus. control wires carry signals synchronize transactionand identify kind transaction currently performed. example,568 Chapter 6 Memory Hierarchy Figure 6.6 Example bus structurethat connects CPUand main memory.CPU chip Register file System busMemory bus Main memoryBus interfaceI/O bridgeALU transaction interest main memory, I/O device disk controller? transaction read write? informationon bus address data item? Figure 6.6 shows conﬁguration example computer system. main components CPU chip, chipset call I/O bridge (which includes memory controller), DRAM memory modules make upmain memory. components connected pair buses: system bus connects CPU I/O bridge, memory bus connects I/O bridge main memory. I/O bridge translates electrical signals system bus electrical signals memory bus. see, I/O bridge also connectsthe system bus memory bus I/O bus shared I/O devices suchas disks graphics cards. now, though, focus memory bus. Aside note bus designs Bus design complex rapidly changing aspect computer systems. Different vendors develop different bus architectures way differentiate products. example, Intel systems use chipsets known northbridge southbridge connect CPU memory I/O devices, respectively. older Pentium Core 2 systems, front side bus (FSB) connects CPU northbridge. Systems AMD replace FSB HyperTransport interconnect, newer Intel Core i7 systems use QuickPath interconnect. details different bus architectures beyond scope text. Instead, use high-level bus architecture Figure 6.6 running example throughout text. simple useful abstraction allows us concrete,and captures main ideas without tied closely detail proprietary designs. Consider happens CPU performs load operation movl A,%eax contents address Aare loaded register %eax . Circuitry CPU chip called bus interface initiates read transaction bus. read transaction consists three steps. First, CPU places address system bus. I/O bridge passes signal along memory bus(Figure 6.7(a)). Next, main memory senses address signal memorySection 6.1 Storage Technologies 569 (a) CPU places address Aon memory bus.Main memory Bus interfaceRegister file I/O bridgeALU X0 A%eax (b) Main memory reads Afrom bus, retrieves word x, places bus.Register file Main memory Bus interfaceI/O bridgeALU x X0 A%eax (c) CPU reads word xfrom bus, copies register %eax .Register file Main memory Bus interfaceI/O bridgeALU XX 0 A%eax Figure 6.7 Memory read transaction load operation: movl A,%eax . bus, reads address memory bus, fetches data word DRAM, writes data memory bus. I/O bridge translates memory bus signal system bus signal, passes along system bus(Figure 6.7(b)). Finally, CPU senses data system bus, reads fromthe bus, copies register %eax (Figure 6.7(c)). Conversely, CPU performs store instruction movl %eax,A contents register %eax written address A, CPU initiates write transaction. Again, three basic steps. First, CPU places theaddress system bus. memory reads address memory bus waits data arrive (Figure 6.8(a)). Next, CPU copies data word in%eax system bus (Figure 6.8(b)). Finally, main memory reads data word memory bus stores bits DRAM (Figure 6.8(c)).570 Chapter 6 Memory Hierarchy (a) CPU places address Aon memory bus. Main memory reads waits data word.Register file Main memory Bus interfaceI/O bridgeALU Ay 0 A%eax (b) CPU places data word yon bus.Register file Main memory Bus interfaceI/O bridgeALU yy 0 A%eax (c) Main memory reads data word yfrom bus stores address A.Register file Main memory Bus interfaceI/O bridgeALUy 0 y%eax Figure 6.8 Memory write transaction store operation: movl %eax,A . 6.1.2 Disk Storage Disks workhorse storage devices hold enormous amounts data, order hundreds thousands gigabytes, opposed hundreds orthousands megabytes RAM-based memory. However, takes order milliseconds read information disk, hundred thousand times longer DRAM million times longer SRAM. Disk Geometry Disks constructed platters . platter consists two sides, surfaces , coated magnetic recording material. rotating spindle center platter spins platter ﬁxed rotational rate , typically 5400 andSection 6.1 Storage Technologies 571 Tracks (a) Single-platter viewTrack k GapsSurface Spindle Sectors (b) Multiple-platter viewCylinder k Platter 0Surface 0 Surface 1 Surface 2 Platter 1 Platter 2 SpindleSurface 3 Surface 4 Surface 5 Figure 6.9 Disk geometry. 15,000 revolutions per minute (RPM). disk typically contain one platters encased sealed container. Figure 6.9(a) shows geometry typical disk surface. surface consists collection concentric rings called tracks . track partitioned collection sectors . sector contains equal number data bits (typically 512 bytes) encoded magnetic material sector. Sectors areseparated gaps data bits stored. Gaps store formatting bits identify sectors. disk consists one platters stacked top encased sealed package, shown Figure 6.9(b). entire assembly isoften referred disk drive , although usually refer simply disk. sometime refer disks rotating disks distinguish ﬂash-based solid state disks (SSDs), moving parts. Disk manufacturers describe geometry multiple-platter drives terms ofcylinders , cylinder collection tracks surfaces equidistant center spindle. example, drive three platters six surfaces, tracks surface numbered consistently, cylinder kis collection six instances track k. Disk Capacity maximum number bits recorded disk known max- imum capacity , simply capacity . Disk capacity determined following technology factors: .Recording density (bits/in): number bits squeezed 1-inch segment track. .Track density (tracks /in): number tracks squeezed 1-inch segment radius extending center platter.572 Chapter 6 Memory Hierarchy .Areal density (bits/in2): product recording density track density. Disk manufacturers work tirelessly increase areal density (and thus capac- ity), doubling every years. original disks, designed age oflow areal density, partitioned every track number sectors, whichwas determined number sectors could recorded innermosttrack. maintain ﬁxed number sectors per track, sectors spaced far-ther apart outer tracks. reasonable approach areal densitieswere relatively low. However, areal densities increased, gaps sec-tors (where data bits stored) became unacceptably large. Thus, modernhigh-capacity disks use technique known multiple zone recording , set cylinders partitioned disjoint subsets known recording zones . zone consists contiguous collection cylinders. track cylinder ina zone number sectors, determined number sec-tors packed innermost track zone. Note diskettes(ﬂoppy disks) still use old-fashioned approach, constant number ofsectors per track. capacity disk given following formula: Disk capacity =# bytes sector×average # sectors track×# tracks surface×# surfaces platter×# platters disk example, suppose disk 5 platters, 512 bytes per sector, 20,000 tracks per surface, average 300 sectors per track. capacityof disk is: Disk capacity =512 bytes sector×300 sectors track×20,000 tracks surface×2 surfaces platter×5 platters disk =30,720,000,000 bytes =30.72 GB . Notice manufacturers express disk capacity units gigabytes (GB), 1G B=109bytes. Aside much gigabyte? Unfortunately, meanings preﬁxes kilo ( K), mega ( M), giga ( G), tera ( T) depend context. measures relate capacity DRAMs SRAMs, typically K=210, M=220,G=230, andT=240. measures related capacity I/O devices disks networks, typically K=103,M=106,G=109, andT=1012. Rates throughputs usually use preﬁx values well. Fortunately, back-of-the-envelope estimates typically rely on, either assump- tion works ﬁne practice. example, relative difference 220=1,048,576 106= 1,000,000 small: (220−106)/106≈5%. Similarly 230=1,073,741,824 109=1,000,000,000: (230−109)/109≈7%.Section 6.1 Storage Technologies 573 SpindleThe disk surface spins fixedrotational rateThe read/write head attached endof arm flies disk surface ona thin cushion air moving radially, arm position read/writehead track (a) Single-platter viewRead/write heads Arm Spindle (b) Multiple-platter view Figure 6.10 Disk dynamics. Practice Problem 6.2 capacity disk two platters, 10,000 cylinders, average 400 sectors per track, 512 bytes per sector? Disk Operation Disks read write bits stored magnetic surface using read/write head connected end actuator arm , shown Figure 6.10(a). moving arm back forth along radial axis, drive position head overany track surface. mechanical motion known seek. head positioned desired track, bit track passesunderneath, head either sense value bit (read bit) alterthe value bit (write bit). Disks multiple platters separateread/write head surface, shown Figure 6.10(b). heads linedup vertically move unison. point time, heads positionedon cylinder. read/write head end arm ﬂies (literally) thin cushion air disk surface height 0.1 microns speed 80km/h. analogous placing Sears Tower side ﬂying around world height 2.5 cm (1 inch) ground, orbit earth taking 8 seconds! tolerances, tiny piece dust surfaceis like huge boulder. head strike one boulders, headwould cease ﬂying crash surface (a so-called head crash ). reason, disks always sealed airtight packages. Disks read write data sector-sized blocks. access time sector three main components: seek time ,rotational latency , transfer time :574 Chapter 6 Memory Hierarchy .Seek time: read contents target sector, arm ﬁrst positions head track contains target sector. time required tomove arm called seek time . seek time, seek, depends previous position head speed arm moves across thesurface. average seek time modern drives, avg seek , measured taking mean several thousand seeks random sectors, typically orderof 3 9 ms. maximum time single seek, max seek , high 20 ms. .Rotational latency: head position track, drive waits ﬁrst bit target sector pass head. performanceof step depends position surface head arrivesat target sector rotational speed disk. worst case, thehead misses target sector waits disk make full rotation.Thus, maximum rotational latency, seconds, given max rotation =1 RPM×60 secs 1 min average rotational latency, Tavg rotation , simply half Tmax rotation . .Transfer time: ﬁrst bit target sector head, drive begin read write contents sector. transfer timefor one sector depends rotational speed number sectors pertrack. Thus, roughly estimate average transfer time one sectorin seconds avg transf er =1 RPM×1 (average # sectors/track )×60 secs 1 min estimate average time access contents disk sector sum average seek time, average rotational latency, averagetransfer time. example, consider disk following parameters: Parameter Value Rotational rate 7200 RPM Tavg seek 9m Average # sectors/track 400 disk, average rotational latency (in ms) Tavg rotation =1/2×Tmax rotation =1/2×(60 secs / 7200 RPM )×1000 ms/sec ≈4m average transfer time Tavg transf er =60 / 7200 RPM ×1 / 400 sectors/track ×1000 ms/sec ≈0.02 msSection 6.1 Storage Technologies 575 Putting together, total estimated access time Taccess=Tavg seek +Tavg rotation +Tavg transf er =9m s+4m s+0.02 ms =13.02 ms example illustrates important points: .The time access 512 bytes disk sector dominated seek time rotational latency. Accessing ﬁrst byte sector takes longtime, remaining bytes essentially free. .Since seek time rotational latency roughly same, twice theseek time simple reasonable rule estimating disk access time. .The access time doubleword stored SRAM roughly 4 ns, 60 nsfor DRAM. Thus, time read 512-byte sector-sized block memoryis roughly 256 ns SRAM 4000 ns DRAM. disk access time,roughly 10 ms, 40,000 times greater SRAM, 2500 timesgreater DRAM. difference access times even dramatic ifwe compare times access single word. Practice Problem 6.3 Estimate average time (in ms) access sector following disk: Parameter Value Rotational rate 15,000 RPM Tavg seek 8m Average # sectors/track 500 Logical Disk Blocks seen, modern disks complex geometries, multiple surfaces different recording zones surfaces. hide complexity fromthe operating system, modern disks present simpler view geometry asa sequence Bsector-sized logical blocks , numbered 0 ,1,...,B −1. small hardware/ﬁrmware device disk package, called disk controller , maintains mapping logical block numbers actual (physical) disk sectors. operating system wants perform I/O operation reading disk sector main memory, sends command disk controller askingit read particular logical block number. Firmware controller performsa fast table lookup translates logical block number (surface, track, sector) triple uniquely identiﬁes corresponding physical sector. Hardware controller interprets triple move heads appropriatecylinder, waits sector pass head, gathers bits sensed576 Chapter 6 Memory Hierarchy head small memory buffer controller, copies main memory. Aside Formatted disk capacity disk used store data, must formatted disk controller. involves ﬁlling gaps sectors information identiﬁes sectors, identifying cylinders surface defects taking action, setting aside set cylinders zone spares called action one cylinders zone goes bad lifetime disk. formatted capacity quoted disk manufacturers less maximum capacity existence spare cylinders. Practice Problem 6.4 Suppose tha ta1M Bﬁ l e consisting 512-byte logical blocks stored disk drive following characteristics: Parameter Value Rotational rate 10,000 RPM Tavg seek 5m Average # sectors/track 1000Surfaces 4 Sector size 512 bytes case below, suppose program reads logical blocks ﬁle sequentially, one other, time position head overthe ﬁrst block avg seek +Tavg rotation . A.Best case: Estimate optimal time (in ms) required read ﬁle given best possible mapping logical blocks disk sectors (i.e., sequential). B.Random case: Estimate time (in ms) required read ﬁle blocks mapped randomly disk sectors. Connecting I/O Devices Input/output (I/O) devices graphics cards, monitors, mice, keyboards, disks connected CPU main memory using I/O bus Intel’s Peripheral Component Interconnect (PCI) bus. Unlike system bus memory buses, CPU-speciﬁc, I/O buses PCI designed beindependent underlying CPU. example, PCs Macs incorporatethe PCI bus. Figure 6.11 shows typical I/O bus structure (modeled PCI) thatconnects CPU, main memory, I/O devices. Although I/O bus slower system memory buses, accommodate wide variety third-party I/O devices. example, bus Figure 6.11 three different types devices attached it.Section 6.1 Storage Technologies 577 Figure 6.11 Example bus structurethat connects CPU,main memory, I/Odevices.CPU Register file System bus Memory bus I/O bus Monitor Key- boardMouse Disk driveMain memory Expansion slots devices suchas network adaptersBus interfaceI/O bridge USB controllerGraphics adapter Disk controllerHost bus adaptor (SCSI/SATA)ALU Solid state disk .AUniversal Serial Bus (USB) controller conduit devices attached USB bus, wildly popular standard connecting variety ofperipheral I/O devices, including keyboards, mice, modems, digital cameras,game controllers, printers, external disk drives, solid state disks. USB 2.0buses maximum bandwidth 60 MB/s. USB 3.0 buses maximum bandwidth 600 MB/s. .Agraphics card (oradapter ) contains hardware software logic responsible painting pixels display monitor behalf theCPU. .Ahost bus adapter connects one disks I/O bus using communication protocol deﬁned particular host bus interface .T h e two popular interfaces disks SCSI (pronounced “scuzzy”) SATA (pronounced “sat-uh”). SCSI disks typically faster expensive SATA drives. SCSI host bus adapter (often called SCSI controller ) support multiple disk drives, opposed SATA adapters, support one drive. Additional devices network adapters attached I/O bus plugging adapter empty expansion slots motherboard provide direct electrical connection bus.578 Chapter 6 Memory Hierarchy Keyboard MouseUSB controllerCPU chip (a) CPU initiates disk read writing command, logical block number, destination memory address memory-mapped address associated disk.Register file I/O bus Monitor DiskMain memoryBus interface Graphics adapterDisk controllerALU Keyboard MouseUSB controllerCPU chip Register file I/O bus Monitor DiskMain memoryBus interface Graphics adapterDisk controllerALU (b) disk controller reads sector performs DMA transfer main memory. Figure 6.12 Reading disk sector. Accessing Disks detailed description I/O devices work pro- grammed outside scope here, give general idea. example,Figure 6.12 summarizes steps take place CPU reads data adisk. CPU issues commands I/O devices using technique called memory- mapped I/O (Figure 6.12(a)). system memory-mapped I/O, block ofSection 6.1 Storage Technologies 579 Keyboard MouseUSB controllerCPU chip Register file Interrupt I/O bus Monitor DiskMain memoryBus interface Graphics adapterDisk controllerALU (c) DMA transfer complete, disk controller notiﬁes CPU interrupt. Figure 6.12 (continued) Reading disk sector. addresses address space reserved communicating I/O devices. addresses known I/O port . device associated (or mapped to) one ports attached bus. simple example, suppose disk controller mapped port 0xa0 . CPU might initiate disk read executing three store instructions toaddress 0xa0 : ﬁrst instructions sends command word tells disk initiate read, along parameters whether interruptthe CPU read ﬁnished. (We discuss interrupts Section 8.1.)The second instruction indicates logical block number read.The third instruction indicates main memory address contents ofthe disk sector stored. issues request, CPU typically work disk performing read. Recall tha 1 GHz processor wit ha1n clock cycle potentially execute 16 million instructions 16 ms takes read thedisk. Simply waiting nothing transfer taking place would beenormously wasteful. disk controller receives read command CPU, trans- lates logical block number sector address, reads contents sector,and transfers contents directly main memory, without intervention fromthe CPU (Figure 6.12(b)). process, whereby device performs read write bus transaction own, without involvement CPU, known direct memory access (DMA). transfer data known DMA transfer . DMA transfer complete contents disk sector safely stored main memory, disk controller notiﬁes CPU sending aninterrupt signal CPU (Figure 6.12(c)). basic idea interruptsignals external pin CPU chip. causes CPU stop is580 Chapter 6 Memory Hierarchy Geometry attribute Value Platters 4 Surfaces (read/write heads) 8 Surface diameter 3.5 in. Sector size 512 bytesZones 15Cylinders 50,864 Recording density (max) 628,000 bits/in. Track density 85,000 tracks/in.Areal density (max) 53.4 Gbits/sq. in. Formatted capacity 146.8 GBPerformance attribute Value Rotational rate 15,000 RPM Avg. rotational latency 2 msAvg. seek time 4 ms Sustained transfer rate 58–96 MB/s Figure 6.13 Seagate Cheetah 15K.4 geometry performance. Source: www.seagate.com . currently working jump operating system routine. routine records fact I/O ﬁnished returns control point theCPU interrupted. Anatomy Commercial Disk Disk manufacturers publish lot useful high-level technical information ontheir Web pages. example, Cheetah 15K.4 SCSI disk ﬁrst manufacturedby Seagate 2005. consult online product manual SeagateWeb page, glean geometry performance information shown inFigure 6.13. Disk manufacturers rarely publish detailed technical information geometry individual recording zones. However, storage researchers atCarnegie Mellon University developed useful tool, called DIXtrac, thatautomatically discovers wealth low-level information geometryand performance SCSI disks [92]. example, DIXtrac able discover thedetailed zone geometry example Seagate disk, we’ve shown Fig-ure 6.14. row table characterizes one 15 zones. ﬁrst columngives zone number, zone 0 outermost zone 14 inner-most. second column gives number sectors contained trackin zone. third column shows number cylinders assigned thatzone, cylinder consists eight tracks, one surface. Simi-larly, fourth column gives total number logical blocks assigned eachzone, across eight surfaces. (The tool able extract valid data theinnermost zone, omitted.) zone map reveals interesting facts Seagate disk. First, sectors packed outer zones (which larger circumference)than inner zones. Second, zone sectors logical blocksSection 6.1 Storage Technologies 581 Zone Sectors Cylinders Logical blocks number per track per zone per zone (outer) 0 864 3201 22,076,928 1 844 3200 21,559,1362 816 3400 22,149,5043 806 3100 19,943,6644 795 3100 19,671,4805 768 3400 20,852,7366 768 3450 21,159,9367 725 3650 21,135,2008 704 3700 20,804,6089 672 3700 19,858,944 10 640 3700 18,913,280 11 603 3700 17,819,85612 576 3707 17,054,208 13 528 3060 12,900,096 (inner) 14 — — — Figure 6.14 Seagate Cheetah 15K.4 zone map. Source: DIXtrac automatic disk drive characterization tool [92]. Data zone 14 available. (check yourself). spare sectors form pool spare cylinders .I ft h e recording material sector goes bad, disk controller automaticallyremap logical blocks cylinder available spare. see thenotion logical block provides simpler interface operatingsystem, also provides level indirection enables disk morerobust. general idea indirection powerful, see westudy virtual memory Chapter 9. Practice Problem 6.5 Use zone map Figure 6.14 determine number spare cylinders inthe following zones: A. Zone 0 B. Zone 8 6.1.3 Solid State Disks Asolid state disk (SSD) storage technology, based ﬂash memory (Sec- tion 6.1.1), situations attractive alternative conventional rotating disk. Figure 6.15 shows basic idea. SSD package plugs stan-dard disk slot I/O bus (typically USB SATA) behaves like other582 Chapter 6 Memory Hierarchy Page 0 Page 1 . . . . . .Page P-1Block 0 Page 0 Page 1 . . .Page P-1Block B-1Flash memorySolid state disk (SSD)I/O bus Flash translation layerRequests read write logical disk blocks Figure 6.15 Solid state disk (SSD). Reads Writes Sequential read throughput 250 MB/s Sequential write throughput 170 MB/s Random read throughput 140 MB/s Random write throughput 14 MB/sRandom read access time 30 μs Random write access time 300 μs Figure 6.16 Performance characteristics typical solid state disk. Source: Intel X25-E SATA solid state drive product manual. disk, processing requests CPU read write logical disk blocks. SSD package consists one ﬂash memory chips, replace me-chanical drive conventional rotating disk, ﬂash translation layer , hardware/ﬁrmware device plays role disk controller, trans-lating requests logical blocks accesses underlying physical device. SSDs different performance characteristics rotating disks. shown Figure 6.16, sequential reads writes (where CPU accesses logical diskblocks sequential order) comparable performance, sequential read-ing somewhat faster sequential writing. However, logical blocks areaccessed random order, writing order magnitude slower reading. difference random reading writing performance caused fundamental property underlying ﬂash memory. shown Figure 6.15,a ﬂash memory consists sequence Bblocks , block consists P pages. Typically, pages 512–4KB size, block consists 32–128 pages, total block sizes ranging 16 KB 512 KB. Data read writtenin units pages. page written entire block itbelongs erased (typically means bits block set 1). However, block erased, page block written oncewith erasing. blocks wears roughly 100,000 repeated writes.Once block wears longer used.Section 6.1 Storage Technologies 583 Random writes slow two reasons. First, erasing block takes rela- tively long time, order 1 ms, order magnitudelonger takes access page. Second, write operation attempts tomodify page pthat contains existing data (i.e., ones), pages block useful data must copied new (erased) block beforethe write page pcan occur. Manufacturers developed sophisticated logic ﬂash translation layer attempts amortize high cost erasingblocks minimize number internal copies writes, unlikely random writing ever perform well reading. SSDs number advantages rotating disks. built semiconductor memory, moving parts, thus much faster randomaccess times rotating disks, use less power, rugged. However,there disadvantages. First, ﬂash blocks wear repeatedwrites, SSDs potential wear well. Wear leveling logic ﬂash translation layer attempts maximize lifetime block spreadingerasures evenly across blocks, fundamental limit remains. Second, SSDs 100 times expensive per byte rotating disks, thus thetypical storage capacities 100 times less rotating disks. However, SSDprices decreasing rapidly become popular, gap betweenthe two appears decreasing. SSDs completely replaced rotating disks portable music devices, popular disk replacements laptops, even begun appear desk-tops servers. rotating disks stay, clear SSDs important new storage technology. Practice Problem 6.6 seen, potential drawback SSDs underlying ﬂash memory wear out. example, one major manufacturer guarantees 1 petabyte (1015 bytes) random writes SSDs wear out. Given assump- tion, estimate lifetime (in years) SSD Figure 6.16 followingworkloads: A.Worst case sequential writes: SSD written continuously rate 170 MB/s (the average sequential write throughput device). B.Worst case random writes: SSD written continuously rate 14 MB/s (the average random write throughput device). C.Average case: SSD written rate 20 GB/day (the average daily write rate assumed computer manufacturers mobilecomputer workload simulations). 6.1.4 Storage Technology Trends several important concepts take away discussion storage technologies.584 Chapter 6 Memory Hierarchy Metric 1980 1985 1990 1995 2000 2005 2010 2010:1980 $/MB 19,200 2900 320 256 100 75 60 320 Access (ns) 300 150 35 15 3 2 1.5 200 (a) SRAM trends Metric 1980 1985 1990 1995 2000 2005 2010 2010:1980 $/MB 8000 880 100 30 1 .1 0.06 130,000Access (ns) 375 200 100 70 60 50 40 9Typical size (MB) 0.064 0.256 4 16 64 2000 8,000 125,000 (b) DRAM trends Metric 1980 1985 1990 1995 2000 2005 2010 2010:1980 $/MB 500 100 8 0.30 0.01 0.005 0.0003 1,600,000Seek time (ms) 87 75 28 10 8 5 3 29Typical size (MB) 1 10 160 1000 20,000 160,000 1,500,000 1,500,000 (c) Rotating disk trends Metric 1980 1985 1990 1995 2000 2003 2005 2010 2010:1980 Intel CPU 8080 80286 80386 Pent. P-III Pent. 4 Core 2 Core i7 — Clock rate (MHz) 1 6 20 150 600 3300 2000 2500 2500Cycle time (ns) 1000 166 50 6 1.6 0.30 0.50 0.4 2500Cores 1 1 1 1 1 1 2 4 4Eff. cycle time (ns) 1000 166 50 6 1.6 0.30 0.25 0.10 10,000 (d) CPU trends Figure 6.17 Storage processing technology trends. Different storage technologies different price performance trade-offs. SRAM somewhat faster DRAM, DRAM much faster disk. Onthe hand, fast storage always expensive slower storage. SRAMcosts per byte DRAM. DRAM costs much disk. SSDs splitthe difference DRAM rotating disk. price performance properties different storage technologies changing dramatically different rates. Figure 6.17 summarizes price performance properties storage technologies since 1980, ﬁrst PCs introduced. numbers culled back issues trade magazines Web. Although collected informal survey, numbersreveal interesting trends. Since 1980, cost performance SRAM technology im- proved roughly rate. Access times decreased factor about200 cost per megabyte factor 300 (Figure 6.17(a)). However, trendsSection 6.1 Storage Technologies 585 DRAM disk much dramatic divergent. cost per megabyte DRAM decreased factor 130,000 (more ﬁve orders ofmagnitude!), DRAM access times decreased factor 10 (Fig-ure 6.17(b)). Disk technology followed trend DRAM evenmore dramatic fashion. cost megabyte disk storage plum-meted factor 1,000,000 (more six orders magnitude!)since 1980, access times improved much slowly, factor 30or (Figure 6.17(c)). startling long-term trends highlight basic truth ofmemory disk technology: easier increase density (and thereby reducecost) decrease access time. DRAM disk performance lagging behind CPU performance. see Figure 6.17(d), CPU cycle times improved factor 2500 1980 and2010. look effective cycle time —which deﬁne cycle time individual CPU (processor) divided number processor cores—thenthe improvement 1980 2010 even greater, factor 10,000. Thesplit CPU performance curve around 2003 reﬂects introduction multi-core processors (see aside next page). split, cycle times individualcores actually increased bit starting decrease again, albeit slowerrate before. Note SRAM performance lags, roughly keeping up. However, gap DRAM disk performance CPU performance actuallywidening. advent multi-core processors around 2003, performancegap function latency, DRAM disk access times increasingmore slowly cycle time individual processor. However, theintroduction multiple cores, performance gap increasingly function ofthroughput, multiple processor cores issuing requests DRAM diskin parallel. various trends shown quite clearly Figure 6.18, plots access cycle times Figure 6.17 semi-log scale. 100,000,000.0 10,000,000.0 1,000,000.0 100,000.0 10,000.0 1000.0 100.0 10.0 1.00.10.0 1980 1985 1990 1995 2000 2003 2005 2010 YearTime (ns)Disk seek time SSD write timeSSD read timeDRAM access timeSRAM access timeCPU cycle timeEffective CPU cycle time Figure 6.18 increasing gap disk, DRAM, CPU speeds.586 Chapter 6 Memory Hierarchy see Section 6.4, modern computers make heavy use SRAM- based caches try bridge processor-memory gap. approach worksbecause fundamental property application programs known locality , discuss next. Aside cycle time stood still: advent multi-core processors history computers marked singular events caused profound changes industry world. Interestingly, inﬂection points tend occur per decade: development Fortran 1950s, introduction IBM 360 early 1960s, dawn Internet (then called ARPANET) early 1970s, introduction IBM PC early 1980s, creation World Wide Web early 1990s. recent event occurred early 21st century, computer manufacturers ran headlong so-called “power wall,” discovering could longer increase CPU clockfrequencies quickly chips would consume much power. solution improve performance replacing single large processor multiple smaller processor cores , complete processor capable executing programs independently parallel cores. multi-core approach works part power consumed processor proportional P=fCv 2, fis clock frequency, Cis capacitance, vis voltage. capacitance Cis roughly proportional area, power drawn multiple cores held constant long total area cores constant. long feature sizes continue shrink exponential Moore’s law rate, number cores processor, thus effective performance, continue increase. point forward, computers get faster clock frequency increases, number cores processor increases, architectural innovations increase efﬁciency programs running cores. see trend clearly Figure 6.18. CPU cycle time reached lowest point 2003 actually started rise leveling starting decline slower rate before. However, advent multi-core processors (dual-core 2004 quad-core 2007), effective cycle time continues decrease atclose previous rate. Practice Problem 6.7 Using data years 2000 2010 Figure 6.17(c), estimate year able buy petabyte (1015bytes) rotating disk storage $500. Assume constant dollars (no inﬂation). 6.2 Locality Well-written computer programs tend exhibit good locality . is, tend reference data items near recently referenced data items, recently referenced themselves. tendency, known principle locality , enduring concept enormous impact design performance hardware software systems.Section 6.2 Locality 587 Locality typically described two distinct forms: temporal locality spatial locality . program good temporal locality, memory location referenced likely referenced multiple times nearfuture. program good spatial locality, memory location referencedonce, program likely reference nearby memory location nearfuture. Programmers understand principle locality because, general, programs good locality run faster programs poor locality . levels modern computer systems, hardware, operating system, toapplication programs, designed exploit locality. hardware level, theprinciple locality allows computer designers speed main memory accessesby introducing small fast memories known cache memories hold blocks recently referenced instructions data items. operating systemlevel, principle locality allows system use main memory cache recently referenced chunks virtual address space. Similarly, theoperating system uses main memory cache recently used disk blocks disk ﬁle system. principle locality also plays crucial role designof application programs. example, Web browsers exploit temporal locality bycaching recently referenced documents local disk. High-volume Web servershold recently requested documents front-end disk caches satisfy requestsfor documents without requiring intervention server. 6.2.1 Locality References Program Data Consider simple function Figure 6.19(a) sums elements vector. function good locality? answer question, look thereference pattern variable. example, sumvariable referenced loop iteration, thus good temporal locality respecttosum. hand, since sum scalar, spatial locality respect sum. see Figure 6.19(b), elements vector vare read sequentially, one other, order stored memory (we assume conveniencethat array starts address 0). Thus, respect variable v, function good spatial locality poor temporal locality since vector element 1int sumvec(int v[N]) 2{ 3 int i, sum = 0; 4 5 f r( i=0 ;i<N ; i++) 6 sum += v[i]; 7 return sum; 8} (a)Address 0 4 8 12 16 20 24 28 Contents v0v1v2v3v4v5v6v7 Access order 1 2 3 45678 (b) Figure 6.19 (a) function good locality. (b) Reference pattern vector v(N= 8). Notice vector elements accessed order stored memory.588 Chapter 6 Memory Hierarchy 1int sumarrayrows(int a[M][N]) 2{ 3 int i, j, sum = 0; 4 5 f r( i=0 ;i<M ; i++) 6 f r( j=0 ;j<N ; j++) 7 sum += a[i][j]; 8 return sum; 9} (a)Address 0 4 8 12 16 20 Contents a00a01a02a10a11a12 Access order 1 2 3 4 5 6 (b) Figure 6.20 (a) Another function good locality. (b) Reference pattern array a(M=2 , N= 3). good spatial locality array accessed row-major order storedin memory. accessed exactly once. Since function either good spatial temporal locality respect variable loop body, conclude thesumvec function enjoys good locality. function sumvec visits element vector sequentially said stride-1 reference pattern (with respect element size). sometimes refer stride-1 reference patterns sequential reference patterns . Visiting every kth element contiguous vector called stride- k reference pattern . Stride-1 reference patterns common important source spatial locality programs. general, stride increases, spatial localitydecreases. Stride also important issue programs reference multidimensional arrays. example, consider sumarrayrows function Figure 6.20(a) sums elements two-dimensional array. doubly nested loop reads theelements array row-major order . is, inner loop reads elements ﬁrst row, second row, on. sumarrayrows function enjoys good spatial locality references array row-major orderthat array stored (Figure 6.20(b)). result nice stride-1 referencepattern excellent spatial locality. Seemingly trivial changes program big impact locality. example, sumarraycols function Figure 6.21(a) computes result sumarrayrows function Figure 6.20(a). difference interchanged iandjloops. impact interchanging loops locality? sumarraycols function suffers poor spatial locality scans array column-wise instead row-wise. Since C arrays arelaid memory row-wise, result stride- Nreference pattern, shown Figure 6.21(b). 6.2.2 Locality Instruction Fetches Since program instructions stored memory must fetched (read) CPU, also evaluate locality program respect instruction fetches. example, Figure 6.19 instructions body theSection 6.2 Locality 589 1int sumarraycols(int a[M][N]) 2{ 3 int i, j, sum = 0; 4 5 f r( j=0 ;j<N ; j++) 6 f r( i=0 ;i<M ; i++) 7 sum += a[i][j]; 8 return sum; 9} (a)Address 0 4 8 12 16 20 Contents a00a01a02a10a11a12 Access order 1 3 5 2 4 6 (b) Figure 6.21 (a) function poor spatial locality. (b) Reference pattern array a(M=2 , N= 3). function poor spatial locality scans memory stride- Nreference pattern. forloop executed sequential memory order, thus loop enjoys good spatial locality. Since loop body executed multiple times, also enjoys goodtemporal locality. important property code distinguishes program data rarely modiﬁed run time. program executing, CPU reads instructions memory. CPU rarely overwrites modiﬁes theseinstructions. 6.2.3 Summary Locality section, introduced fundamental idea locality identiﬁed simple rules qualitatively evaluating locality aprogram: .Programs repeatedly reference variables enjoy good temporallocality. .For programs stride- kreference patterns, smaller stride better spatial locality. Programs stride-1 reference patterns good spa-tial locality. Programs hop around memory large strides poorspatial locality. .Loops good temporal spatial locality respect instruction fetches. smaller loop body greater number loop it- erations, better locality. Later chapter, learned cache memories work, show quantify idea locality terms cache hits misses. also become clear programs good locality typically run faster programs poor locality. Nonetheless, knowing to590 Chapter 6 Memory Hierarchy glance source code getting high-level feel locality program useful important skill programmer master. Practice Problem 6.8 Permute loops following function scans three-dimensionalarray awith stride-1 reference pattern. 1int sumarray3d(int a[N][N][N]) 2{ 3 int i, j, k, sum = 0; 4 5 f r( i=0 ;i<N ; i++) { 6 f r( j=0 ;j<N ; j++) { 7 f r( k=0 ;k<N ; k++) { 8 sum += a[k][i][j]; 9 } 10 } 11 } 12 return sum; 13 } Practice Problem 6.9 three functions Figure 6.22 perform operation varying de- grees spatial locality. Rank-order functions respect spatial local-ity enjoyed each. Explain arrived ranking. (a) array structs 1#define N 1000 2 3typedef struct { 4 int vel[3]; 5 int acc[3]; 6} point; 7 8point p[N];(b) clear1 function 1void clear1(point *p, int n) 2{ 3 int i, j; 45 f r( i=0 ;i<n ; i++) { 6 f r( j=0 ;j<3 ; j++) 7 p[i].vel[j] = 0; 8 f r( j=0 ;j<3 ; j++) 9 p[i].acc[j] = 0; 10 } 11 } Figure 6.22 Code examples Practice Problem 6.9.Section 6.3 Memory Hierarchy 591 (c) clear2 function 1void clear2(point *p, int n) 2{ 3 int i, j; 4 5 f r( i=0 ;i<n ; i++) { 6 f r( j=0 ;j<3 ; j++) { 7 p[i].vel[j] = 0; 8 p[i].acc[j] = 0; 9 } 10 } 11 }(d) clear3 function 1void clear3(point *p, int n) 2{ 3 int i, j; 4 5 f r( j=0 ;j<3 ; j++) { 6 f r( i=0 ;i<n ; i++) 7 p[i].vel[j] = 0; 8 f r( i=0 ;i<n ; i++) 9 p[i].acc[j] = 0; 10 } 11 } Figure 6.22 (continued) Code examples Practice Problem 6.9. 6.3 Memory Hierarchy Sections 6.1 6.2 described fundamental enduring properties storage technology computer software: .Storage technology: Different storage technologies widely different ac- cess times. Faster technologies cost per byte slower ones less capacity. gap CPU main memory speed widening. .Computer software: Well-written programs tend exhibit good locality. one happier coincidences computing, fundamental properties hardware software complement beautifully. complemen-tary nature suggests approach organizing memory systems, known thememory hierarchy , used modern computer systems. Figure 6.23 shows typical memory hierarchy. general, storage devices get slower, cheaper,and larger move higher lower levels . highest level (L0) small number fast CPU registers CPU access single clock cycle.Next one small moderate-sized SRAM-based cache memories thatcan accessed CPU clock cycles. followed large DRAM-based main memory accessed tens hundreds clock cycles. Nextare slow enormous local disks. Finally, systems even include addi- tional level disks remote servers accessed network. example, distributed ﬁle systems Andrew File System (AFS) theNetwork File System (NFS) allow program access ﬁles stored re-mote network-connected servers. Similarly, World Wide Web allows programsto access remote ﬁles stored Web servers anywhere world.592 Chapter 6 Memory Hierarchy CPU registers hold words retrieved cache memory. L1 cache holds cache lines retrieved L2 cache. L2 cache holds cache lines retrieved L3 cache. Main memory holds disk blocks retrieved local disks. Local disks hold files retrieved disks onremote network servers.Regs L3 cache (SRAM)L2 cache (SRAM)L1 cache (SRAM) Main memory (DRAM) Local secondary storage (local disks) Remote secondary storage (distributed file systems, Web servers)Smaller, faster, costlier (per byte) storage devices Larger, slower, cheaper (per byte) storage devicesL0: L1: L2: L3: L4: L5: L6:L3 cache holds cache lines retrieved memory. Figure 6.23 memory hierarchy. Aside memory hierarchies shown one example memory hierarchy, combinations possible, indeed common. example, many sites back local disks onto archival magnetic tapes. ofthese sites, human operators manually mount tapes onto tape drives needed. sites, taperobots handle task automatically. either case, collection tapes represents level thememory hierarchy, local disk level, general principles apply. Tapes cheaper per byte disks, allows sites archive multiple snapshots local disks. trade- tapes take longer access disks. another example, solid state disks playing increasingly important role memory hierarchy, bridging gulf DRAM rotating disk. 6.3.1 Caching Memory Hierarchy general, cache (pronounced “cash”) small, fast storage device acts staging area data objects stored larger, slower device. process ofusing cache known caching (pronounced “cashing”). central idea memory hierarchy k, faster smaller storage device level kserves cache larger slower storage device level k+1. words, level hierarchy caches data objects next lower level. example, local disk serves cache ﬁles (suchas Web pages) retrieved remote disks network, main memory serves cache data local disks, on, get smallest cache all, set CPU registers.Section 6.3 Memory Hierarchy 593 4 9 14 3 0123 4567 89 1 0 1 1 12 13 14 15Level k: Level k/H110011:Smaller, faster, expensive device level k caches subset blocks level k/H110011. Larger, slower, cheaper storage device level k/H110011 partitioned blocks. Data copied levels block-sized transfer units. Figure 6.24 basic principle caching memory hierarchy. Figure 6.24 shows general concept caching memory hierarchy. storage level k+1 partitioned contiguous chunks data objects called blocks . block unique address name distinguishes blocks. Blocks either ﬁxed-sized (the usual case) variable-sized (e.g., theremote HTML ﬁles stored Web servers). example, level k+1 storage Figure 6.24 partitioned 16 ﬁxed-sized blocks, numbered 0 15. Similarly, storage level kis partitioned smaller set blocks size blocks level k+1. point time, cache levelkcontains copies subset blocks level k+1. example, Figure 6.24, cache level khas room four blocks currently contains copies blocks 4, 9, 14, 3. Data always copied back forth level kand level k+1 block- sized transfer units . important realize block size ﬁxed particular pair adjacent levels hierarchy, pairs levelscan different block sizes. example, Figure 6.23, transfers L1and L0 typically use one-word blocks. Transfers L2 L1 (and L3 andL2, L4 L3) typically use blocks 8 16 words. transfers betweenL5 L4 use blocks hundreds thousands bytes. general, deviceslower hierarchy (further CPU) longer access times, thus tend use larger block sizes order amortize longer access times. Cache Hits program needs particular data object dfrom level k+1, ﬁrst looks fordin one blocks currently stored level k.I fdhappens cached level k, called cache hit . program reads ddirectly level k, nature memory hierarchy faster reading level k+1. example, program good temporal locality might read data object block 14, resulting cache hit level k.594 Chapter 6 Memory Hierarchy Cache Misses If, hand, data object dis cached level k, called cache miss . miss, cache level kfetches block containing dfrom cache level k+1, possibly overwriting existing block level kcache already full. process overwriting existing block known replacing orevicting block. block evicted sometimes referred victim block . decision block replace governed cache’s replacement policy . example, cache random replacement policy would choose random victim block. cache least-recently used (LRU) replacementpolicy would choose block last accessed furthest past. cache level khas fetched block level k+1, program read dfrom level kas before. example, Figure 6.24, reading data object block 12 level kcache would result cache miss block 12 currently stored level kcache. copied level k+1 level k, block 12 remain expectation later accesses. Kinds Cache Misses sometimes helpful distinguish different kinds cache misses. cache level kis empty, access data object miss. empty cache sometimes referred cold cache , misses kind called compulsory misses orcold misses . Cold misses important often transient events might occur steady state, cache hasbeen warmed repeated memory accesses. Whenever miss, cache level kmust implement placement policy determines place block retrieved level k+1. ﬂexible placement policy allow block level k+1t ob e stored block level k. caches high memory hierarchy (close CPU) implemented hardware speed premium,this policy usually expensive implement randomly placed blocksare expensive locate. Thus, hardware caches typically implement restricted placement policy restricts particular block level k+1 small subset (sometimes singleton) blocks level k. example, Figure 6.24, might decide block iat level k+1 must placed block ( imod 4) level k. example, blocks 0, 4, 8, 12 level k+1 would map block 0 level k; blocks 1, 5, 9, 13 would map block 1; on. Notice example cache inFigure 6.24 uses policy. Restrictive placement policies kind lead type miss known aconﬂict miss , cache large enough hold referenced data objects, map cache block, cache keeps missing.For example, Figure 6.24, program requests block 0, block 8, thenblock 0, block 8, on, references two blocks wouldmiss cache level k, even though cache hold total four blocks.Section 6.3 Memory Hierarchy 595 Programs often run sequence phases (e.g., loops) phase accesses reasonably constant set cache blocks. example, nested loopmight access elements array again. set blocksis called working set phase. size working set exceeds size cache, cache experience known capacity misses . words, cache small handle particular working set. Cache Management noted, essence memory hierarchy storage deviceat level cache next lower level. level, form logicmust manage cache. mean something partition cache storage blocks, transfer blocks different levels, decide arehits misses, deal them. logic manages cache behardware, software, combination two. example, compiler manages register ﬁle, highest level cache hierarchy. decides issue loads misses, anddetermines register store data in. caches levels L1, L2, andL3 managed entirely hardware logic built caches. systemwith virtual memory, DRAM main memory serves cache data blocksstored disk, managed combination operating system softwareand address translation hardware CPU. machine distributedﬁle system AFS, local disk serves cache managed theAFS client process running local machine. cases, caches operateautomatically require speciﬁc explicit actions program. 6.3.2 Summary Memory Hierarchy Concepts summarize, memory hierarchies based caching work slower storage cheaper faster storage programs tend exhibit locality: .Exploiting temporal locality. temporal locality, data ob- jects likely reused multiple times. data object copiedinto cache ﬁrst miss, expect number subsequent hits onthat object. Since cache faster storage next lower level,these subsequent hits served much faster original miss. .Exploiting spatial locality. Blocks usually contain multiple data objects. Be- cause spatial locality, expect cost copying block amiss amortized subsequent references objects within thatblock. Caches used everywhere modern systems. see Fig- ure 6.25, caches used CPU chips, operating systems, distributed ﬁle systems,and World Wide Web. built managed various com-binations hardware software. Note number terms andacronyms Figure 6.25 haven’t covered yet. include todemonstrate common caches are.596 Chapter 6 Memory Hierarchy Type cached cached Latency (cycles) Managed CPU registers 4-byte 8-byte word On-chip CPU registers 0 Compiler TLB Address translations On-chip TLB 0 Hardware MMUL1 cache 64-byte block On-chip L1 cache 1 HardwareL2 cache 64-byte block On/off-chip L2 cache 10 HardwareL3 cache 64-byte block On/off-chip L3 cache 30 HardwareVirtual memory 4-KB page Main memory 100 Hardware + OSBuffer cache Parts ﬁles Main memory 100 OSDisk cache Disk sectors Disk controller 100,000 Controller ﬁrmwareNetwork cache Parts ﬁles Local disk 10,000,000 AFS/NFS clientBrowser cache Web pages Local disk 10,000,000 Web browserWeb cache Web pages Remote server disks 1,000,000,000 Web proxy server Figure 6.25 ubiquity caching modern computer systems. Acronyms: TLB: translation lookaside buffer, MMU: memory management unit, OS: operating system, AFS: Andrew File System, NFS: Network FileSystem. 6.4 Cache Memories memory hierarchies early computer systems consisted three levels: CPU registers, main DRAM memory, disk storage. However, increasing gap CPU main memory, system designers compelledto insert small SRAM cache memory , called L1 cache (Level 1 cache) CPU register ﬁle main memory, shown Figure 6.26. L1 cache canbe accessed nearly fast registers, typically 2 4 clock cycles. performance gap CPU main memory continued increase, system designers responded inserting additional larger cache,called L2 cache , L1 cache main memory, accessed 10 clock cycles. modern systems include additional even largercache, called L3 cache , sits L2 cache main memory Figure 6.26 Typical bus structure forcache memories. I/O bridgeCPU chip Cache memoriesRegister file System bus Memory bus Bus interfaceMain memoryALUSection 6.4 Cache Memories 597 memory hierarchy accessed 30 40 cycles. considerable variety arrangements, general principles same. Forour discussion next section, assume simple memory hierarchy witha single L1 cache CPU main memory. 6.4.1 Generic Cache Memory Organization Consider computer system memory address mbits form M=2munique addresses. illustrated Figure 6.27(a), cache machine organized array S=2scache sets . set consists Ecache lines . line consists data block ofB=2bbytes, valid bit indicates whether line contains meaningful information, t=m−(b+s)tag bits(a subset bits current block’s memory address) uniquely identify block stored cache line. general, cache’s organization characterized tuple ( ,E ,B ,m ) . size (or capacity) cache, C, stated terms ag- gregate size blocks. tag bits valid bit included. Thus,C=S×E×B. CPU instructed load instruction read word ad- dressAof main memory, sends address Ato cache. cache holding copy word address A, sends word immediately back CPU. Figure 6.27 General organization cache ( S,E ,B ,m ) . (a) cache anarray sets. Eachset contains one lines. line contains valid bit,some tag bits, ablock data. (b) cache organization induces partition ofthemaddress bits ttag bits, sset index bits, bblock offset bits.Valid Tag 0 1 B/H110021 . . .. . .Valid Tag 0 1 B/H110021 . . . Set 0: Valid Tag 0 1 B/H110021 . . .. . .Valid Tag 0 1 B/H110021 . . . Set 1: Valid Tag Cache size: C/H11005B/H11003E/H11003 Sdata bytes01 B/H110021 . . .. . . . . .Valid Tag 0 1 B/H110021 . . . SetS/H110021:1 valid bit per linet tag bits per lineB/H110052b bytes per cache block S/H110052s setsElines per set (a) m/H1100210t bits Address: Tag Set index Block offsets bits (b)b bits598 Chapter 6 Memory Hierarchy Fundamental parameters Parameter Description S=2sNumber sets E Number lines per set B=2bBlock size (bytes) m=log2(M) Number physical (main memory) address bits Derived quantities Parameter Description M=2mMaximum number unique memory addresses s=log2(S) Number set index bits b=log2(B) Number block offset bits t=m−(s+b) Number tag bits C=B×E×S Cache size (bytes) including overhead valid tag bits Figure 6.28 Summary cache parameters. cache know whether contains copy word address A? cache organized ﬁnd requested word simply inspect-ing bits address, similar hash table extremely simple hashfunction. works: parameters SandBinduce partitioning maddress bits three ﬁelds shown Figure 6.27(b). sset index bits inAform index array Ssets. ﬁrst set set 0, second set set 1, on. interpreted unsigned integer, set index bits tell us set wordmust stored in. know set word must contained in, tag bits Atell us line (if any) set contains word. line set contains word valid bit set tag bits linematch tag bits address A. located line identiﬁed tag set identiﬁed set index, bblock offset bits give us offset word B-byte data block. may noticed, descriptions caches use lot symbols. Fig- ure 6.28 summarizes symbols reference. Practice Problem 6.10 following table gives parameters number different caches. Foreach cache, determine number cache sets ( S), tag bits ( t), set index bits ( s), block offset bits ( b).Section 6.4 Cache Memories 599 Cache mCB E b 1. 32 1024 4 1 2. 32 1024 8 4 3. 32 1024 32 32 6.4.2 Direct-Mapped Caches Caches grouped different classes based E, number cache lines per set. cache exactly one line per set ( E=1) known direct-mapped cache (see Figure 6.29). Direct-mapped caches simplest implementand understand, use illustrate general concepts abouthow caches work. Suppose system CPU, register ﬁle, L1 cache, main memory. CPU executes instruction reads memory word w, requests word L1 cache. L1 cache cached copy w, L1 cache hit, cache quickly extracts wand returns CPU. Otherwise, cache miss, CPU must wait L1cache requests copy block containing wfrom main memory. requested block ﬁnally arrives memory, L1 cache stores block inone cache lines, extracts word wfrom stored block, returns CPU. process cache goes determining whether request ahit miss extracting requested word consists three steps: (1) set selection , (2) line matching , (3) word extraction . Set Selection Direct-Mapped Caches step, cache extracts sset index bits middle address forw. bits interpreted unsigned integer corresponds set number. words, think cache one-dimensional array sets, set index bits form index array. Figure 6.30 shows howset selection works direct-mapped cache. example, set index bits00001 2are interpreted integer index selects set 1. Line Matching Direct-Mapped Caches selected set iin previous step, next step determine copy word wis stored one cache lines contained Figure 6.29 Direct-mapped cache(E= 1). exactly one line per set.Valid Tag Cache block Set 0: Valid Tag Cache block Set 1: Valid Tag Cache block SetS/H110021: . . .E/H110051line per set600 Chapter 6 Memory Hierarchy m/H1100210t bits Tag Set index Block offsets bits b bitsSelected set 0 0 0 0 1Valid Tag Cache block Set 0: Valid Tag Cache block Set 1: Valid Tag Cache block SetS/H110021: . . . Figure 6.30 Set selection direct-mapped cache. seti. direct-mapped cache, easy fast exactly one line per set. copy wis contained line valid bit set tag cache line matches tag address w. Figure 6.31 shows line matching works direct-mapped cache. example, exactly one cache line selected set. valid bit thisline set, know bits tag block meaningful. Since tag bits cache line match tag bits address, know copy word want indeed stored line. words, cache hit.On hand, either valid bit set tags match,then would cache miss. Word Selection Direct-Mapped Caches hit, know wis somewhere block. last step determines desired word starts block. shown Figure 6.31,the block offset bits provide us offset ﬁrst byte desired word.Similar view cache array lines, think block anarray bytes, byte offset index array. example, theblock offset bits 100 2indicate copy wstarts byte 4 block. (We assuming words 4 bytes long.) Line Replacement Misses Direct-Mapped Caches cache misses, needs retrieve requested block nextlevel memory hierarchy store new block one cache lines Figure 6.31 Line matching wordselection direct-mapped cache. Within cache block, w 0denotes low-order byte word w,w1the next byte, on.01 m/H1100210234567 10 1 1 0 bits Tag Set index Block offsets bits b bits/H11005 ?w0w1w2w3 0110 100/H11005 1? (1) valid bit must set. Selected set (i): tag bits cache line must match tag bits address.(3) (1) (2), cache hit, block offset selects starting byte.(2)Section 6.4 Cache Memories 601 Address bits Address Tag bits Index bits Offset bits Block number (decimal) ( t=1) ( s=2) ( b=1) (decimal) 0 0 00 0 0 1 0 00 1 0 2 0 01 0 1 3 0 01 1 1 4 0 10 0 2 5 0 10 1 2 6 0 11 0 3 7 0 11 1 3 8 1 00 0 4 9 1 00 1 4 10 1 01 0 5 11 1 01 1 5 12 1 10 0 6 13 1 10 1 6 14 1 11 0 7 15 1 11 1 7 Figure 6.32 4-bit address space example direct-mapped cache. set indicated set index bits. general, set full valid cache lines, one existing lines must evicted. direct-mapped cache, whereeach set contains exactly one line, replacement policy trivial: current lineis replaced newly fetched line. Putting Together: Direct-Mapped Cache Action mechanisms cache uses select sets identify lines extremelysimple. be, hardware must perform fewnanoseconds. However, manipulating bits way confusing ushumans. concrete example help clarify process. Suppose adirect-mapped cache described ( S,E ,B,m ) =(4,1,2,4) words, cache four sets, one line per set, 2 bytes per block, 4- bit addresses. also assume word single byte. course, assumptions totally unrealistic, help us keep example simple. ﬁrst learning caches, instructive enumer- ate entire address space partition bits, we’ve done Figure 6.32 forour 4-bit example. interesting things notice enumer-ated space:602 Chapter 6 Memory Hierarchy .The concatenation tag index bits uniquely identiﬁes block memory. example, block 0 consists addresses 0 1, block 1 consistsof addresses 2 3, block 2 consists addresses 4 5, on. .Since eight memory blocks four cache sets, multiple blocksmap cache set (i.e., set index). example,blocks 0 4 map set 0, blocks 1 5 map set 1, on. .Blocks map cache set uniquely identiﬁed tag. Forexample, block 0 tag bit 0 block 4 tag bit 1, block 1 hasa tag bit 0 block 5 tag bit 1, on. Let us simulate cache action CPU performs sequence reads. Remember example, assuming CPU reads 1-bytewords. kind manual simulation tedious may temptedto skip it, experience students really understand caches workuntil work way them. Initially, cache empty (i.e., valid bit zero): Set Valid Tag block[0] block[1] 0 0 1 0 2 0 3 0 row table represents cache line. ﬁrst column indicates setthat line belongs to, keep mind provided convenience really part cache. next three columns represent actual bits ineach cache line. Now, let us see happens CPU performs sequenceof reads: 1. Read word address 0. Since valid bit set 0 zero, cache miss. cache fetches block 0 memory (or lower-level cache) stores theblock set 0. cache returns m[0] (the contents memory location 0)from block[0] newly fetched cache line. Set Valid Tag block[0] block[1] 0 1 0 m[0] m[1] 1 0 2 0 3 0 2. Read word address 1. cache hit. cache immediately returns m[1] block[1] cache line. state cache change. 3. Read word address 13. Since cache line set 2 valid, cache miss. cache loads block 6 set 2 returns m[13] block[1]of new cache line.Section 6.4 Cache Memories 603 Set Valid Tag block[0] block[1] 0 1 0 m[0] m[1] 1 0 2 1 1 m[12] m[13] 3 0 4. Read word address 8. miss. cache line set 0 indeed valid, tags match. cache loads block 4 set 0 (replacing theline read address 0) returns m[8] block[0]of new cache line. Set Valid Tag block[0] block[1] 0 1 1 m[8] m[9] 1 0 2 1 1 m[12] m[13] 3 0 5. Read word address 0. another miss, due unfortunate fact replaced block 0 previous reference address 8. Thiskind miss, plenty room cache keep alternatingreferences blocks map set, example conﬂict miss. Set Valid Tag block[0] block[1] 0 1 0 m[0] m[1] 1 0 2 1 1 m[12] m[13] 3 0 Conﬂict Misses Direct-Mapped Caches Conﬂict misses common real programs cause bafﬂing performanceproblems. Conﬂict misses direct-mapped caches typically occur programsaccess arrays whose sizes power 2. example, consider function thatcomputes dot product two vectors: 1float dotprod(float x[8], float y[8]) 2{ 3 float sum = 0.0; 4 int i; 5 6 f r( i=0 ;i<8 ; i++) 7 sum += x[i] * y[i]; 8 return sum; 9}604 Chapter 6 Memory Hierarchy function good spatial locality respect xandy, might expect enjoy good number cache hits. Unfortunately, alwaystrue. Suppose ﬂoats 4 bytes, xis loaded 32 bytes contiguous memory starting address 0, ystarts immediately xat address 32. simplicity, suppose block 16 bytes (big enough hold four ﬂoats)and cache consists two sets, total cache size 32 bytes. willassume variable sumis actually stored CPU register thus require memory reference. Given assumptions, x[i] andy[i] map identical cache set: Element Address Set index Element Address Set index x[0] 0 0 y[0] 32 0 x[1] 4 0 y[1] 36 0 x[2] 8 0 y[2] 40 0 x[3] 12 0 y[3] 44 0 x[4] 16 1 y[4] 48 1 x[5] 20 1 y[5] 52 1 x[6] 24 1 y[6] 56 1 x[7] 28 1 y[7] 60 1 run time, ﬁrst iteration loop references x[0] , miss causes block containing x[0] –x[3] loaded set 0. next reference y[0] , another miss causes block containing y[0] –y[3] copied set 0, overwriting values xthat copied previous reference. next iteration, reference x[1] misses, causes x[0] – x[3] block loaded back set 0, overwriting y[0] –y[3] block. conﬂict miss, fact subsequent reference xandywill result conﬂict miss thrash back forth blocks xandy. term thrashing describes situation cache repeatedly loading evicting sets cache blocks. bottom line even though program good spatial locality room cache hold blocks x[i] andy[i] , reference results conﬂict miss blocks map cache set. Itis unusual kind thrashing result slowdown factor 2 or3. Also, aware even though example extremely simple, problemis real larger realistic direct-mapped caches. Luckily, thrashing easy programmers ﬁx recognize going on. One easy solution put Bbytes padding end array. example, instead deﬁning xto float x[8] , deﬁne float x[12] . Assuming ystarts immediately xin memory, following mapping array elements sets:Section 6.4 Cache Memories 605 Element Address Set index Element Address Set index x[0] 0 0 y[0] 48 1 x[1] 4 0 y[1] 52 1 x[2] 8 0 y[2] 56 1 x[3] 12 0 y[3] 60 1 x[4] 16 1 y[4] 64 0 x[5] 20 1 y[5] 68 0 x[6] 24 1 y[6] 72 0 x[7] 28 1 y[7] 76 0 padding end x,x[i] andy[i] map different sets, eliminates thrashing conﬂict misses. Practice Problem 6.11 previous dotprod example, fraction total references xandy hits padded array x? Practice Problem 6.12 general, high-order sbits address used set index, contigu- ous chunks memory blocks mapped cache set. A. many blocks contiguous array chunks? B. Consider following code runs system cache form ( S,E ,B,m ) =(512,1,32,32): int array[4096]; (i = 0; < 4096; i++) sum += array[i]; maximum number array blocks stored cache point time? Aside index middle bits? may wondering caches use middle bits set index instead high-order bits. good reason middle bits better. Figure 6.33 shows why. high-order bits used index, contiguous memory blocks map cache set. example, ﬁgure, ﬁrst four blocks map ﬁrst cache set, second four blocks map second set, on. program good spatial locality scans elements array sequentially, cache hold block-sized chunk array point time. inefﬁcient use cache. Contrast middle-bit indexing, adjacent blocks always map different cache lines. case, cache hold entire C-sized chunk array, Cis cache size.606 Chapter 6 Memory Hierarchy Set index bitsFour-set cacheHigh-order bit indexingMiddle-order bit indexing 00 01 10 110000 1100 1101 1110 11110101 0110 0111 1000 1001 1010 10110001 0010 0011 01000000 1100 1101 1110 11110101 0110 0111 1000 1001 1010 10110001 0010 0011 0100 Figure 6.33 caches index middle bits. 6.4.3 Set Associative Caches problem conﬂict misses direct-mapped caches stems con- straint set exactly one line (or terminology, E=1). set associative cache relaxes constraint set holds one cache line. cache 1 <E<C / B often called E-way set associative cache. discuss special case, E=C/B , next section. Figure 6.34 shows organization two-way set associative cache. Figure 6.34 Set associative cache (1<E<C / B) .In set associative cache, eachset contains one line. particular example shows two-wayset associative cache.Valid Tag Cache block Set 0: Valid Tag Cache block SetS/H110021: . . .E/H11005 2 lines per set Valid Tag Cache block Valid Tag Cache block Valid Tag Cache block Valid Tag Cache blockSet 1:Section 6.4 Cache Memories 607 Valid Tag Cache block Set 0: Valid Tag Cache block SetS/H110021: . . .Valid Tag Cache block Valid Tag Cache block Valid Tag Cache block Valid Tag Cache blockSet 1: m/H1100210t bits Tag Set index Block offsets bits b bitsSelected set 0 0 0 0 1 Figure 6.35 Set selection set associative cache. Set Selection Set Associative Caches Set selection identical direct-mapped cache, set index bits identi- fying set. Figure 6.35 summarizes principle. Line Matching Word Selection Set Associative Caches Line matching involved set associative cache direct-mapped cache must check tags valid bits multiple lines order todetermine requested word set. conventional memory array ofvalues takes address input returns value stored address.Anassociative memory , hand, array (key, value) pairs takes input key returns value one (key, value) pairs thatmatches input key. Thus, think set set associative cache asa small associative memory keys concatenation tag andvalid bits, values contents block. Figure 6.36 shows basic idea line matching associative cache. important idea line set contain memory blocks Figure 6.36 Line matching word selection set associative cache.01 m/H1100210234567 1 11001 0110 bits Tag Set index Block offsets bits b bits/H11005 ?w0w1w2w3 0110 100/H11005 1? (1) valid bit must set. Selected set (i): (2) tag bits one cache lines must match tag bits address.(3) (1) (2), cache hit, block offset selects starting byte.608 Chapter 6 Memory Hierarchy map set. cache must search line set, searching valid line whose tag matches tag address. cache ﬁnds line,then hit block offset selects word block, before. Line Replacement Misses Set Associative Caches word requested CPU stored lines set, thenwe cache miss, cache must fetch block contains wordfrom memory. However, cache retrieved block, line shouldit replace? course, empty line, would good candidate.But empty lines set, must choose one nonemptylines hope CPU reference replaced line anytime soon. difﬁcult programmers exploit knowledge cache replace- ment policy codes, go much detail here. Thesimplest replacement policy choose line replace random. moresophisticated policies draw principle locality try minimize prob-ability replaced line referenced near future. example, aleast-frequently-used (LFU) policy replace line referenced fewest times past time window. least-recently-used (LRU) policy replace line last accessed furthest past. thesepolicies require additional time hardware. move thememory hierarchy, away CPU, cost miss becomes expen-sive becomes worthwhile minimize misses good replacementpolicies. 6.4.4 Fully Associative Caches Afully associative cache consists single set (i.e., E=C/B ) contains cache lines. Figure 6.37 shows basic organization. Set Selection Fully Associative Caches Set selection fully associative cache trivial one set,summarized Figure 6.38. Notice set index bits address,which partitioned tag block offset. Line Matching Word Selection Fully Associative Caches Line matching word selection fully associative cache work aswith set associative cache, show Figure 6.39. difference mainlya question scale. cache circuitry must search many matching Figure 6.37 Fully associative cache (E=C/B) .In fully associative cache, singleset contains lines.Valid Tag Cache block Set 0:Valid Tag Cache block . . .E/H11005 C/B lines one set Valid Tag Cache blockSection 6.4 Cache Memories 609 Valid Tag Cache block Set 0:Valid Tag Cache block . . . Valid Tag Cache block m/H1100210t bits Tag Block offsetb bitsThe entire cache one set, default set 0 always selected. Figure 6.38 Set selection fully associative cache. Notice set index bits. m/H11002101 00110 1110 bits Tag Block offsetb bits/H11005 ?w0w1w2w3 0110 10001234567 1 01001 0110/H11005 1? (1) valid bit must set. Entire cache (2) tag bits one cache lines must match tag bits address.(3) (1) (2), cache hit, block offset selects starting byte. Figure 6.39 Line matching word selection fully associative cache. tags parallel, difﬁcult expensive build associative cache large fast. result, fully associative caches appropriate forsmall caches, translation lookaside buffers (TLBs) virtual memorysystems cache page table entries (Section 9.6.2). Practice Problem 6.13 problems follow help reinforce understanding cacheswork. Assume following: .The memory byte addressable. .Memory accesses 1-byte words (not 4-byte words). .Addresses 13 bits wide. .The cache two-way set associative ( E=2), 4-byte block size ( B=4) eight sets ( S=8). contents cache follows, numbers given hexadecimal notation.610 Chapter 6 Memory Hierarchy 2-way set associative cache Line 0 Line 1 Set index Tag Valid Byte 0 Byte 1 Byte 2 Byte 3 Tag Valid Byte 0 Byte 1 Byte 2 Byte 3 0 09 1 86 30 3F 10 00 0 ———— 1 45 1 60 4F E0 23 38 1 00 BC 0B 37 2 EB 0 ———— 0B 0 ———— 3 06 0 ———— 32 1 12 08 7B AD 4 C7 1 06 78 07 C5 05 1 40 67 C2 3B 5 71 1 0B DE 18 4B 6E 0 ———— 6 91 1 A0 B7 26 2D F0 0 ———— 7 46 0 ———— DE 1 12 C0 88 37 following ﬁgure shows format address (one bit per box). Indicate (by labeling diagram) ﬁelds would used determine following: CO cache block offset CI cache set index CT cache tag 1 21 11 09876543210 Practice Problem 6.14 Suppose program running machine Problem 6.13 references 1-byte word address 0x0E34 . Indicate cache entry accessed cache byte value returned hex . Indicate whether cache miss occurs. cache miss, enter “–” “Cache byte returned.” A. Address format (one bit per box): 1 21 11 09876543210 B. Memory reference: Parameter Value Cache block offset (CO) 0x Cache set index (CI) 0x Cache tag (CT) 0x Cache hit? (Y/N) Cache byte returned 0xSection 6.4 Cache Memories 611 Practice Problem 6.15 Repeat Problem 6.14 memory address 0x0DD5 . A. Address format (one bit per box): 1 21 11 09876543210 B. Memory reference: Parameter Value Cache block offset (CO) 0x Cache set index (CI) 0x Cache tag (CT) 0x Cache hit? (Y/N) Cache byte returned 0x Practice Problem 6.16 Repeat Problem 6.14 memory address 0x1FE4 . A. Address format (one bit per box): 1 21 11 09876543210 B. Memory reference: Parameter Value Cache block offset (CO) 0x Cache set index (CI) 0x Cache tag (CT) 0x Cache hit? (Y/N) Cache byte returned 0x Practice Problem 6.17 cache Problem 6.13, list hex memory addresses hit set 3. 6.4.5 Issues Writes seen, operation cache respect reads straightforward. First, look copy desired word win cache. hit, return612 Chapter 6 Memory Hierarchy wimmediately. miss, fetch block contains wfrom next lower level memory hierarchy, store block cache line (possiblyevicting valid line), return w. situation writes little complicated. Suppose write word wthat already cached (a write hit ). cache updates copy w, updating copy win next lower level hierarchy? simplest approach, known write-through , immediately write w’s cache block next lower level. simple, write-through disadvantageof causing bus trafﬁc every write. Another approach, known write-back , defers update long possible writing updated block next lowerlevel evicted cache replacement algorithm. Becauseof locality, write-back signiﬁcantly reduce amount bus trafﬁc, hasthe disadvantage additional complexity. cache must maintain additionaldirty bit cache line indicates whether cache block modiﬁed. Another issue deal write misses. One approach, known write- allocate , loads corresponding block next lower level cache updates cache block. Write-allocate tries exploit spatial localityof writes, disadvantage every miss results block transferfrom next lower level cache. alternative, known no-write-allocate , bypasses cache writes word directly next lower level. Write-through caches typically no-write-allocate. Write-back caches typicallywrite-allocate. Optimizing caches writes subtle difﬁcult issue, scratching surface here. details vary system system oftenproprietary poorly documented. programmer trying write reason-ably cache-friendly programs, suggest adopting mental model assumeswrite-back write-allocate caches. several reasons suggestion. rule, caches lower levels memory hierarchy likely use write-back instead write-through larger transfer times.For example, virtual memory systems (which use main memory cache theblocks stored disk) use write-back exclusively. logic densities increase,the increased complexity write-back becoming less impediment weare seeing write-back caches levels modern systems. assumptionmatches current trends. Another reason assuming write-back write-allocateapproach symmetric way reads handled, write-backwrite-allocate tries exploit locality. Thus, develop programs highlevel exhibit good spatial temporal locality rather trying optimizefor particular memory system. 6.4.6 Anatomy Real Cache Hierarchy far, assumed caches hold program data. fact, caches hold instructions well data. cache holds instructions calledani-cache . cache holds program data called d-cache . cache holds instructions data known uniﬁed cache . Modern processorsSection 6.4 Cache Memories 613 Figure 6.40 Intel Core i7 cachehierarchy.Processor package Core 0 Core 3 . . .Regs L1 d-cache L2 unified cache L3 unified cache (shared cores) Main memoryL1 i-cacheRegs L1 d-cache L2 unified cacheL1 i-cache include separate i-caches d-caches. number reasons this. two separate caches, processor read instruction word dataword time. I-caches typically read-only, thus simpler. Thetwo caches often optimized different access patterns differentblock sizes, associativities, capacities. Also, separate caches ensuresthat data accesses create conﬂict misses instruction accesses, viceversa, cost potential increase capacity misses. Figure 6.40 shows cache hierarchy Intel Core i7 processor. CPU chip four cores. core private L1 i-cache, L1 d-cache, L2 uniﬁed cache. cores share on-chip L3 uniﬁed cache. interestingfeature hierarchy SRAM cache memories contained inthe CPU chip. Figure 6.41 summarizes basic characteristics Core i7 caches. Cache type Access time (cycles) Cache size ( C) Assoc. ( E) Block size ( B) Sets ( S) L1 i-cache 4 32 KB 8 64 B 64 L1 d-cache 4 32 KB 8 64 B 64L2 uniﬁed cache 11 256 KB 8 64 B 512L3 uniﬁed cache 30–40 8 MB 16 64 B 8192 Figure 6.41 Characteristics Intel Core i7 cache hierarchy.614 Chapter 6 Memory Hierarchy 6.4.7 Performance Impact Cache Parameters Cache performance evaluated number metrics: .Miss rate. fraction memory references execution pro- gram, part program, miss. computed # misses /#references . .Hit rate. fraction memory references hit. computed 1 − miss rate . .Hit time. time deliver word cache CPU, including time set selection, line identiﬁcation, word selection. Hit time onthe order several clock cycles L1 caches. .Miss penalty. additional time required miss. penalty L1 misses served L2 order 10 cycles; L3, 40 cycles; andfrom main memory, 100 cycles. Optimizing cost performance trade-offs cache memories subtle exercise requires extensive simulation realistic benchmark codes thusis beyond scope. However, possible identify qualitativetrade-offs. Impact Cache Size one hand, larger cache tend increase hit rate. otherhand, always harder make large memories run faster. result, largercaches tend increase hit time. especially important on-chip L1caches must short hit time. Impact Block Size Large blocks mixed blessing. one hand, larger blocks helpincrease hit rate exploiting spatial locality might exist program. However, given cache size, larger blocks imply smaller number cache lines, hurt hit rate programs temporal locality thanspatial locality. Larger blocks also negative impact miss penalty, sincelarger blocks cause larger transfer times. Modern systems usually compromisewith cache blocks contain 32 64 bytes. Impact Associativity issue impact choice parameter E, number cache lines per set. advantage higher associativity (i.e., larger values E) decreases vulnerability cache thrashing due conﬂict misses.However, higher associativity comes signiﬁcant cost. Higher associativity isexpensive implement hard make fast. requires tag bits perline, additional LRU state bits per line, additional control logic. Higherassociativity increase hit time, increased complexity, canalso increase miss penalty increased complexity choosing avictim line.Section 6.5 Writing Cache-friendly Code 615 choice associativity ultimately boils trade-off hit time miss penalty. Traditionally, high-performance systems pushedthe clock rates would opt smaller associativity L1 caches (where misspenalty cycles) higher degree associativity lowerlevels, miss penalty higher. example, Intel Core i7 systems, theL1 L2 caches 8-way associative, L3 cache 16-way. Impact Write Strategy Write-through caches simpler implement use write buffer works independently cache update memory. Furthermore, read missesare less expensive trigger memory write. otherhand, write-back caches result fewer transfers, allows bandwidthto memory I/O devices perform DMA. Further, reducing number oftransfers becomes increasingly important move hierarchy thetransfer times increase. general, caches hierarchy morelikely use write-back write-through. Aside Cache lines, sets, blocks: What’s difference? easy confuse distinction cache lines, sets, blocks. Let’s review ideas make sure clear: .Ablock ﬁxed-sized packet information moves back forth cache main memory (or lower-level cache). .Alineis container cache stores block, well information valid bit tag bits. .Asetis collection one lines. Sets direct-mapped caches consist single line. Sets set associative fully associative caches consist multiple lines. direct-mapped caches, sets lines indeed equivalent. However, associative caches, sets lines different things terms cannot used interchangeably. Since line always stores single block, terms “line” “block” often used interchange- ably. example, systems professionals usually refer “line size” cache, really mean block size. usage common, shouldn’t cause confusion, long understand distinction blocks lines. 6.5 Writing Cache-friendly Code Section 6.2, introduced idea locality talked qualitative terms constitutes good locality. understand cache memo- ries work, precise. Programs better locality tend lower miss rates, programs lower miss rates tend run faster thanprograms higher miss rates. Thus, good programmers always try to616 Chapter 6 Memory Hierarchy write code cache friendly , sense good locality. basic approach use try ensure code cache friendly. 1.Make common case go fast. Programs often spend time core functions. functions often spend time fewloops. focus inner loops core functions ignore rest. 2.Minimize number cache misses inner loop. things equal, total number loads stores, loops better miss rateswill run faster. see works practice, consider sumvec function Section 6.2: 1int sumvec(int v[N]) 2{ 3 int i, sum = 0; 4 5 f r( i=0 ;i<N ; i++) 6 sum += v[i]; 7 return sum; 8} function cache friendly? First, notice good temporal locality loop body respect local variables iandsum. fact, local variables, reasonable optimizing compiler cache theregister ﬁle, highest level memory hierarchy. consider stride-1references vector v. general, cache block size Bbytes, stride- kreference pattern (where kis expressed words) results average min(1,(wordsize ×k)/B)misses per loop iteration. minimized k=1, stride-1 references vare indeed cache friendly. example, suppose thatvis block aligned, words 4 bytes, cache blocks 4 words, cache initially empty (a cold cache). Then, regardless cache organization, references vwill result following pattern hits misses: v[i] i=0i=1i=2i=3i=4i=5i=6i=7 Access order, [h]it [m]iss 1[m] 2 [h] 3 [h] 4 [h] 5[m] 6 [h] 7 [h] 8 [h] example, reference v[0] misses corresponding block, contains v[0] –v[3] , loaded cache memory. Thus, next three references hits. reference v[4] causes another miss new block loaded cache, next three references hits, on. Ingeneral, three four references hit, best thiscase cold cache. summarize, simple sumvec example illustrates two important points writing cache-friendly code: .Repeated references local variables good compiler cancache register ﬁle (temporal locality).Section 6.5 Writing Cache-friendly Code 617 .Stride-1 reference patterns good caches levels memory hierarchy store data contiguous blocks (spatial locality). Spatial locality especially important programs operate multi- dimensional arrays. example, consider sumarrayrows function Sec- tion 6.2, sums elements two-dimensional array row-major order: 1int sumarrayrows(int a[M][N]) 2{ 3 int i, j, sum = 0; 4 5 f r( i=0 ;i<M ; i++) 6 f r( j=0 ;j<N ; j++) 7 sum += a[i][j]; 8 return sum; 9} Since C stores arrays row-major order, inner loop function desirable stride-1 access pattern sumvec . example, suppose make assumptions cache sumvec . references array awill result following pattern hits misses: a[i][j] j=0j=1j=2j=3j=4 j=5j=6j=7 i=0 1[m] 2 [h] 3 [h] 4 [h] 5[m] 6 [h] 7 [h] 8 [h] i=1 9[m] 10 [h] 11 [h] 12 [h] 13[m] 14 [h] 15 [h] 16 [h] i=2 17[m] 18 [h] 19 [h] 20 [h] 21[m] 22 [h] 23 [h] 24 [h] i=3 25[m] 26 [h] 27 [h] 28 [h] 29[m] 30 [h] 31 [h] 32 [h] consider happens make seemingly innocuous change permuting loops: 1int sumarraycols(int a[M][N]) 2{ 3 int i, j, sum = 0; 4 5 f r( j=0 ;j<N ; j++) 6 f r( i=0 ;i<M ; i++) 7 sum += a[i][j]; 8 return sum; 9} case, scanning array column column instead row row. lucky entire array ﬁts cache, enjoy samemiss rate 1/4. However, array larger cache (the likelycase), every access a[i][j] miss!618 Chapter 6 Memory Hierarchy a[i][j] j=0j=1j=2j=3j=4j=5j=6j=7 i=0 1[m] 5[m] 9[m] 13[m] 17[m] 21[m] 25[m] 29[m] i=1 2[m] 6[m] 10[m] 14[m] 18[m] 22[m] 26[m] 30[m] i=2 3[m] 7[m] 11[m] 15[m] 19[m] 23[m] 27[m] 31[m] i=3 4[m] 8[m] 12[m] 16[m] 20[m] 24[m] 28[m] 32[m] Higher miss rates signiﬁcant impact running time. example, desktop machine, sumarrayrows runs twice fast sumarraycols .T summarize, programmers aware locality programs try towrite programs exploit it. Practice Problem 6.18 Transposing rows columns matrix important problem signalprocessing scientiﬁc computing applications. also interesting local-ity point view reference pattern row-wise column-wise.For example, consider following transpose routine: 1typedef int array[2][2]; 2 3void transpose1(array dst, array src) 4{ 5 int i, j; 6 7 f r( i=0 ;i<2 ; i++) { 8 f r( j=0 ;j<2 ; j++) { 9 dst[j][i] = src[i][j]; 10 } 11 } 12 } Assume code runs machine following properties: .sizeof(int) == 4 . .Thesrc array starts address 0 dst array starts address 16 (decimal). .There single L1 data cache direct-mapped, write-through, write-allocate, block size 8 bytes. .The cache total size 16 data bytes cache initially empty. .Accesses src anddst arrays sources read write misses, respectively. A. row andcol, indicate whether access src[row][col] dst[row][col] hit (h) miss (m). example, reading src[0][0] miss writing dst[0][0] also miss.Section 6.5 Writing Cache-friendly Code 619 dstarray srcarray Col 0 Col 1 Col 0 Col 1 Row 0 Row 0 Row 1 Row 1 B. Repeat problem cache 32 data bytes. Practice Problem 6.19 heart recent hit game SimAquarium tight loop calculates average position 256 algae. evaluating cache performance amachine 1024-byte direct-mapped data cache 16-byte blocks ( B=16). given following deﬁnitions: 1struct algae_position { 2 int x; 3 int y; 4}; 5 6struct algae_position grid[16][16]; 7int total_x = 0, total_y = 0; 8int i, j; also assume following: .sizeof(int) == 4 . .grid begins memory address 0. .The cache initially empty. .The memory accesses entries array grid . Variables i,j, total_x , total_y stored registers. Determine cache performance following code: 1 (i = 0; < 16; i++) { 2 (j = 0; j < 16; j++) { 3 total_x += grid[i][j].x; 4 } 5 } 6 7 (i = 0; < 16; i++) { 8 (j = 0; j < 16; j++) { 9 total_y += grid[i][j].y; 10 } 11 }620 Chapter 6 Memory Hierarchy A. total number reads? B. total number reads miss cache?C. miss rate? Practice Problem 6.20 Given assumptions Problem 6.19, determine cache performance following code: 1 (i = 0; < 16; i++){ 2 (j = 0; j < 16; j++) { 3 total_x += grid[j][i].x; 4 total_y += grid[j][i].y; 5 } 6 } A. total number reads? B. total number reads miss cache? C. miss rate? D. would miss rate cache twice big? Practice Problem 6.21 Given assumptions Problem 6.19, determine cache performance following code: 1 (i = 0; < 16; i++){ 2 (j = 0; j < 16; j++) { 3 total_x += grid[i][j].x; 4 total_y += grid[i][j].y; 5 } 6 } A. total number reads? B. total number reads miss cache?C. miss rate?D. would miss rate cache twice big? 6.6 Putting Together: Impact Caches Program Performance section wraps discussion memory hierarchy studying im- pact caches performance programs running real machines.Section 6.6 Putting Together: Impact Caches Program Performance 621 6.6.1 Memory Mountain rate program reads data memory system called read throughput , sometimes read bandwidth . program reads nbytes period sseconds, read throughput period n/s, typically expressed units megabytes per second (MB/s). write program issued sequence read requests tight program loop, measured read throughput would give us someinsight performance memory system particular sequence reads. Figure 6.42 shows pair functions measure read throughputfor particular read sequence. Thetest function generates read sequence scanning ﬁrst elems elements array stride stride .T h e runfunction wrapper calls test function returns measured read throughput. call test function line 29 warms cache. fcyc2 function line 30 calls test function arguments elems estimates running time test function CPU cycles. Notice size argument run function units bytes, corresponding elems argument test function units array elements. Also, notice line 31 computes MB/s 10 6bytes/s, opposed 220bytes/s. Thesize andstride arguments runfunction allow us control degree temporal spatial locality resulting read sequence. Smallervalues size result smaller working set size, thus better temporal locality. Smaller values stride result better spatial locality. call run function repeatedly different values size andstride , recover fascinating two-dimensional function read throughput versus temporal andspatial locality. function called memory mountain . Every computer unique memory mountain characterizes ca- pabilities memory system. example, Figure 6.43 shows memorymountain Intel Core i7 system. example, size varies 2 KB 64 MB, stride varies 1 64 elements, element 8-byte double . geography Core i7 mountain reveals rich structure. Perpendicular size axis four ridges correspond regions temporal locality working set ﬁts entirely L1 cache, L2 cache, L3 cache, andmain memory, respectively. Notice order magnitude differencebetween highest peak L1 ridge, CPU reads rate over6 GB/s, lowest point main memory ridge, CPU reads ata rate 600 MB/s. feature L1 ridge pointed out. large strides, notice read throughput drops working set size approaches2 KB (falling back side ridge). Since L1 cache holds entireworking set, feature reﬂect true L1 cache performance. anartifact overheads calling test function setting execute loop. large strides small working set sizes, overheads amortized, asthey larger sizes.622 Chapter 6 Memory Hierarchy code/mem/mountain/mountain.c 1double data[MAXELEMS]; /* global array we’ll traversing */ 2 3/* 4 * test - Iterate first "elems" elements array "data" 5 * stride "stride". 6 */ 7void test(int elems, int stride) /* test function */ 8{ 9 int i; 10 double result = 0.0; 11 volatile double sink; 12 13 (i = 0; < elems; += stride) { 14 result += data[i]; 15 } 16 sink = result; /* compiler doesn’t optimize away loop */ 17 } 18 19 /* 20 * run - Run test(elems, stride) return read throughput (MB/s). 21 * "size" bytes, "stride" array elements, 22 * Mhz CPU clock frequency Mhz. 23 */ 24 double run(int size, int stride, double Mhz) 25 { 26 double cycles; 27 int elems = size / sizeof(double); 2829 test(elems, stride); /* warm cache */ 30 cycles = fcyc2(test, elems, stride, 0); /* call test(elems,stride) */ 31 return (size / stride) / (cycles / Mhz); /* convert cycles MB/s */ 32 } code/mem/mountain/mountain.c Figure 6.42 Functions measure compute read throughput. generate memory mountain particular computer calling run function different values size (which corresponds temporal locality) stride (which corresponds spatial locality). L2, L3, main memory ridges, slope spatial locality falls downhill stride increases, spatial locality decreases. Notice even working set large ﬁt caches, thehighest point main memory ridge factor 7 higher lowest point.So even program poor temporal locality, spatial locality still cometo rescue make signiﬁcant difference.Section 6.6 Putting Together: Impact Caches Program Performance 623s1 s3 s5 s7 s9 s11 s13 s15 s32 16M64M 4M 1M 256k 64k 16k 4k7000 6000 5000 30004000 2000 1000 0Read throughput (MB/s) Stride (x8 bytes) Size (bytes)Core i7 2.67 GHz32 KB L1 d-cache256 KB L2 cache8 MB L3 cache Slopes spatiallocalityRidges temporallocalityL1 MemL2 L3 Figure 6.43 memory mountain. particularly interesting ﬂat ridge line extends perpendicular stride axis strides 1 2, read throughput relativelyconstant 4.5 GB/s. apparently due hardware prefetching mechanism Core i7 memory system automatically identiﬁes memory referencingpatterns attempts fetch blocks cache accessed. details particular prefetching algorithm documented, isclear memory mountain algorithm works best small strides—yet another reason favor sequential accesses code. take slice mountain, holding stride constant Fig- ure 6.44, see impact cache size temporal locality performance.For sizes 32 KB, working set ﬁts entirely L1 d-cache, thus readsare served L1 peak throughput 6 GB/s. sizes 256 KB, working set ﬁts entirely uniﬁed L2 cache, sizes 8M, working set ﬁts entirely uniﬁed L3 cache. Larger working set sizes servedprimarily main memory. dips read throughputs leftmost edges L1, L2, L3 cache regions—where working set sizes 32 KB, 256 KB, 8 MB equal totheir respective cache sizes—are interesting. entirely clear dipsoccur. way sure perform detailed cache simulation, it624 Chapter 6 Memory Hierarchy 7000 600050004000300020001000 0 64M 32M16M 8M4M2M1M 512k256k128k 64k32k16k 8k4k2kWorking set size (bytes)Read throughput (MB/s)L1 cache regionL2 cache regionL3 cache regionMain memory region Figure 6.44 Ridges temporal locality memory mountain. graph shows slice Figure 6.43 stride=16 . likely drops caused data code blocks make impossible ﬁt entire array respective cache. Slicing memory mountain opposite direction, holding working set size constant, gives us insight impact spatial locality onthe read throughput. example, Figure 6.45 shows slice ﬁxed workingset size 4 MB. slice cuts along L3 ridge Figure 6.43, workingset ﬁts entirely L3 cache, large L2 cache. Notice read throughput decreases steadily stride increases one eight doublewords. region mountain, read miss L2 causesa block transferred L3 L2. followed number hits block L2, depending stride. stride increases, ratio ofL2 misses L2 hits increases. Since misses served slowly hits, theread throughput decreases. stride reaches eight doublewords, onthis system equals block size 64 bytes, every read request misses L2 andmust served L3. Thus, read throughput strides least eightdoublewords constant rate determined rate cache blocks transferred L3 L2. summarize discussion memory mountain, performance memory system characterized single number. Instead, mountainof temporal spatial locality whose elevations vary order ofmagnitude. Wise programmers try structure programs run inthe peaks instead valleys. aim exploit temporal locality thatSection 6.6 Putting Together: Impact Caches Program Performance 625 5000 45004000350030002500200015001000 500 0 s1 s2s3s4s5s6s7s8s9 s10 s11 s12s13s14s15s16s32s64Read throughput (MB/s) Stride (x8 bytes)One access per cache line Figure 6.45 slope spatial locality. graph shows slice Figure 6.43 size=4 MB . heavily used words fetched L1 cache, exploit spatial locality many words possible accessed single L1 cache line. Practice Problem 6.22 Use memory mountain Figure 6.43 estimate time, CPU cycles, read 8-byte word L1 d-cache. 6.6.2 Rearranging Loops Increase Spatial Locality Consider problem multiplying pair n×nmatrices: C=AB. exam- ple, n=2, /bracketleftbiggc11c12 c21c22/bracketrightbigg =/bracketleftbigga11a12 a21a22/bracketrightbigg/bracketleftbiggb11b12 b21b22/bracketrightbigg c11=a11b11+a12b21 c12=a11b12+a12b22 c21=a21b11+a22b21 c22=a21b12+a22b22 matrix multiply function usually implemented using three nested loops, identiﬁed indexes i,j, andk. permute loops make minor code changes, create six functionally equivalent versions626 Chapter 6 Memory Hierarchy (a) Version ijk code/mem/matmult/mm.c 1f r( i=0 ;i<n ; i++) 2 f r( j=0 ;j<n ; j++) { 3 sum = 0.0; 4 f r( k=0 ;k<n ; k++) 5 sum += A[i][k]*B[k][j]; 6 C[i][j] += sum; 7 } code/mem/matmult/mm.c (c) Version jki code/mem/matmult/mm.c 1f r( j=0 ;j<n ; j++) 2 f r( k=0 ;k<n ; k++) { 3 r = B[k][j]; 4 f r( i=0 ;i<n ; i++) 5 C[i][j] += A[i][k]*r; 6 } code/mem/matmult/mm.c (e) Version kij code/mem/matmult/mm.c 1f r( k=0 ;k<n ; k++) 2 f r( i=0 ;i<n ; i++) { 3 r = A[i][k]; 4 f r( j=0 ;j<n ; j++) 5 C[i][j] += r*B[k][j]; 6 } code/mem/matmult/mm.c(b) Version jik code/mem/matmult/mm.c 1f r( j=0 ;j<n ; j++) 2 f r( i=0 ;i<n ; i++) { 3 sum = 0.0; 4 f r( k=0 ;k<n ; k++) 5 sum += A[i][k]*B[k][j]; 6 C[i][j] += sum; 7 } code/mem/matmult/mm.c (d) Version kj code/mem/matmult/mm.c 1f r( k=0 ;k<n ; k++) 2 f r( j=0 ;j<n ; j++) { 3 r = B[k][j]; 4 f r( i=0 ;i<n ; i++) 5 C[i][j] += A[i][k]*r; 6 } code/mem/matmult/mm.c (f) Version ikj code/mem/matmult/mm.c 1f r( i=0 ;i<n ; i++) 2 f r( k=0 ;k<n ; k++) { 3 r = A[i][k]; 4 f r( j=0 ;j<n ; j++) 5 C[i][j] += r*B[k][j]; 6 } code/mem/matmult/mm.c Figure 6.46 Six versions matrix multiply. version uniquely identiﬁed ordering loops. matrix multiply shown Figure 6.46. version uniquely identiﬁed ordering loops. high level, six versions quite similar. addition associative, version computes identical result.2Each version performs O(n3)total 2. learned Chapter 2, ﬂoating-point addition commutative, general associative. practice, matrices mix extremely large values extremely small ones, often true matrices store physical properties, assumption associativity reasonable.Section 6.6 Putting Together: Impact Caches Program Performance 627 Matrix multiply Loads Stores misses B misses C misses Total misses version (class) per iter. per iter. per iter. per iter. per iter. per iter. ijk&jik(AB) 2 0 0.25 1.00 0.00 1.25 jki&kj i(AC) 2 1 1.00 0.00 1.00 2.00 kij&ikj(BC) 2 1 0.00 0.25 0.25 0.50 Figure 6.47 Analysis matrix multiply inner loops. six versions partition three equivalence classes, denoted pair arrays accessed innerloop. operations identical number adds multiplies. n2elements ofAandBis read ntimes. n2elements Cis computed summing nvalues. However, analyze behavior innermost loop iterations, ﬁnd differences number accesses locality. thepurposes analysis, make following assumptions: .Each array n×narray double , sizeof(double) == 8 . .There single cache 32-byte block size ( B=32). .The array size nis large single matrix row ﬁt L1 cache. .The compiler stores local variables registers, thus references local variables inside loops require load store instructions. Figure 6.47 summarizes results inner loop analysis. Notice six versions pair three equivalence classes, denote pair ofmatrices accessed inner loop. example, versions ijkandjikare members Class ABbecause reference arrays AandB(but C) innermost loop. class, counted number loads (reads) andstores (writes) inner loop iteration, number references A,B, Cthat miss cache loop iteration, total number cache misses per iteration. inner loops Class ABroutines (Figure 6.46(a) (b)) scan row array Awith stride 1. Since cache block holds four doublewords, miss rate Ais 0.25 misses per iteration. hand, inner loop scans column Bwith stride n. Since nis large, access array Bresults miss, total 1 .25 misses per iteration. inner loops Class ACroutines (Figure 6.46(c) (d)) problems. iteration performs two loads store (as opposed theClass ABroutines, perform two loads stores). Second, inner loop scans columns AandCwith stride n. result miss load, total two misses per iteration. Notice interchanging loopshas decreased amount spatial locality compared Class ABroutines. TheBCroutines (Figure 6.46(e) (f)) present interesting trade-off: two loads store, require one memory operation AB routines. hand, since inner loop scans BandCrow-wise628 Chapter 6 Memory Hierarchy Figure 6.48 Core i7 matrix multiplyperformance. Legend: jki andkj i: Class AC;ijkand jik: Class AB;kijandikj: Class BC. 0102030405060 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 Array size ( n)Cycles per inner loop iterationjki kjiijkjikkijikj stride-1 access pattern, miss rate array 0.25 misses per iteration, total 0.50 misses per iteration. Figure 6.48 summarizes performance different versions matrix mul- tiply Core i7 system. graph plots measured number CPU cyclesper inner loop iteration function array size ( n). number interesting points notice graph: .For large values n, fastest version runs almost 20 times faster slowest version, even though performs number ﬂoating-pointarithmetic operations. .Pairs versions number memory references misses periteration almost identical measured performance. .The two versions worst memory behavior, terms number ofaccesses misses per iteration, run signiﬁcantly slower fourversions, fewer misses fewer accesses, both. .Miss rate, case, better predictor performance totalnumber memory accesses. example, Class BCroutines, 0.5 misses per iteration, perform much better Class ABroutines, 1.25 misses per iteration, even though Class BCroutines perform memory references inner loop (two loads one store) theClass ABroutines (two loads). .For large values n, performance fastest pair versions ( kijand ikj) constant. Even though array much larger SRAM cache memories, prefetching hardware smart enough recognize stride-1 access pattern, fast enough keep memory accesses tight inner loop. stunning accomplishment Intel engi-Section 6.7 Summary 629 neers designed memory system, providing even incentive programmers develop programs good spatial locality. Web Aside MEM:BLOCKING Using blocking increase temporal locality interesting technique called blocking improve temporal locality inner loops. general idea blocking organize data structures program large chunks calledblocks . (In context, “block” refers application-level chunk data, notto cache block.) program structured loads chunk L1 cache, reads writes itneeds chunk, discards chunk, loads next chunk, on. Unlike simple loop transformations improving spatial locality, blocking makes code harder read understand. reason, best suited optimizing compilers frequentlyexecuted library routines. Still, technique interesting study understand ageneral concept produce big performance gains systems. 6.6.3 Exploiting Locality Programs seen, memory system organized hierarchy storage devices, smaller, faster devices toward top larger, slower devicestoward bottom. hierarchy, effective rate programcan access memory locations characterized single number. Rather, isa wildly varying function program locality (what dubbed memorymountain) vary orders magnitude. Programs good localityaccess data fast cache memories. Programs poor localityaccess data relatively slow DRAM main memory. Programmers understand nature memory hierarchy ex- ploit understanding write efﬁcient programs, regardless speciﬁcmemory system organization. particular, recommend following tech-niques: .Focus attention inner loops, bulk computationsand memory accesses occur. .Try maximize spatial locality programs reading data objectssequentially, stride 1, order stored memory. .Try maximize temporal locality programs using data object often possible read memory. 6.7 Summary basic storage technologies random-access memories (RAMs), nonvolatile memories (ROMs), disks. RAM comes two basic forms. Static RAM(SRAM) faster expensive, used cache memories onand CPU chip. Dynamic RAM (DRAM) slower less expensive, andis used main memory graphics frame buffers. Nonvolatile memories, also called read-only memories (ROMs), retain information even sup- ply voltage turned off, used store ﬁrmware. Rotating disks are630 Chapter 6 Memory Hierarchy mechanical nonvolatile storage devices hold enormous amounts data low cost per bit, much longer access times DRAM. Solid state disks(SSDs) based nonvolatile ﬂash memory becoming increasingly attractivealternatives rotating disks applications. general, faster storage technologies expensive per bit smaller capacities. price performance properties technologiesare changing dramatically different rates. particular, DRAM disk accesstimes much larger CPU cycle times. Systems bridge gaps orga-nizing memory hierarchy storage devices, smaller, faster devices atthe top larger, slower devices bottom. well-written programshave good locality, data served higher levels, effect isa memory system runs rate higher levels, cost andcapacity lower levels. Programmers dramatically improve running times programs writing programs good spatial temporal locality. Exploiting SRAM-based cache memories especially important. Programs fetch data pri- marily cache memories run much faster programs fetch dataprimarily memory. Bibliographic Notes Memory disk technologies change rapidly. experience, best sourcesof technical information Web pages maintained manufacturers.Companies Micron, Toshiba, Samsung provide wealth currenttechnical information memory devices. pages Seagate, Maxtor, Western Digital provide similarly useful information disks. Textbooks circuit logic design provide detailed information memory technology [56, 85]. IEEE Spectrum published series survey articleson DRAM [53]. International Symposium Computer Architecture (ISCA)is common forum characterizations DRAM memory performance [34, 35]. Wilkes wrote ﬁrst paper cache memories [116]. Smith wrote clas- sic survey [101]. Przybylski wrote authoritative book cache design [82].Hennessy Patterson provide comprehensive discussion cache design is-sues [49]. Stricker introduced idea memory mountain comprehensive characterization memory system [111], suggested term “memorymountain” informally later presentations work. Compiler researcherswork increase locality automatically performing kinds manual codetransformations discussed Section 6.6 [22, 38, 63, 68, 75, 83, 118]. Carter andcolleagues proposed cache-aware memory controller [18]. Seward devel-oped open-source cache proﬁler, called cacheprof , characterizes miss behavior C programs arbitrary simulated cache ( www.cacheprof.org ). researchers developed cache oblivious algorithms designed run well without explicit knowledge structure underlying cachememory [36, 42, 43].Homework Problems 631 large body literature building using disk storage. Many storage researchers look ways aggregate individual disks larger, morerobust, secure storage pools [20, 44, 45, 79, 119]. Others look waysto use caches locality improve performance disk accesses [12, 21].Systems Exokernel provide increased user-level control disk mem-ory resources [55]. Systems Andrew File System [74] Coda [91]extend memory hierarchy across computer networks mobile notebookcomputers. Schindler Ganger developed interesting tool automaticallycharacterizes geometry performance SCSI disk drives [92]. Researchersare investigating techniques building using Flash-based SSDs [8, 77]. Homework Problems 6.23◆◆ Suppose asked design rotating disk number bits per track constant. know number bits per track determinedby circumference innermost track, assume also thecircumference hole. Thus, make hole center disklarger, number bits per track increases, total number tracksdecreases. let rdenote radius platter, x.rthe radius hole, value xmaximizes capacity disk? 6.24◆ Estimate average time (in ms) access sector following disk: Parameter Value Rotational rate 15,000 RPM Tavg seek 4m Average # sectors/track 800 6.25◆◆ Suppose tha ta2M Bﬁ l e consisting 512-byte logical blocks stored disk drive following characteristics: Parameter Value Rotational rate 15,000 RPM Tavg seek 4m Average # sectors/track 1000 Surfaces 8Sector size 512 bytes case below, suppose program reads logical blocks ﬁle sequentially, one other, time position head overthe ﬁrst block avg seek +Tavg rotation .632 Chapter 6 Memory Hierarchy A.Best case: Estimate optimal time (in ms) required read ﬁle possible mappings logical blocks disk sectors. B.Random case: Estimate time (in ms) required read ﬁle blocks mapped randomly disk sectors. 6.26◆ following table gives parameters number different caches. Foreach cache, ﬁll missing ﬁelds table. Recall mis number physical address bits, Cis cache size (number data bytes), Bis block size bytes, Eis associativity, Sis number cache sets, tis number tag bits, sis number set index bits, bis number block offset bits. Cache mCB E b 1. 32 1024 4 4 2. 32 1024 4 256 3. 32 1024 8 1 4. 32 1024 8 128 5. 32 1024 32 1 6. 32 1024 32 4 6.27◆ following table gives parameters number different caches. Yourtask ﬁll missing ﬁelds table. Recall mis number physical address bits, Cis cache size (number data bytes), Bis block size bytes, Eis associativity, Sis number cache sets, tis number tag bits, sis number set index bits, bis number block offset bits. Cache CBE b 1. 32 81 21 8 3 2. 32 2048 128 23 7 2 3. 32 1024 2 8 64 1 4. 32 1024 21 6 2 3 4 6.28◆ problem concerns cache Problem 6.13. A. List hex memory addresses hit set 1. B. List hex memory addresses hit set 6. 6.29◆◆ problem concerns cache Problem 6.13. A. List hex memory addresses hit set 2. B. List hex memory addresses hit set 4.Homework Problems 633 C. List hex memory addresses hit set 5. D. List hex memory addresses hit set 7. 6.30◆◆ Suppose system following properties: .The memory byte addressable. .Memory accesses 1-byte words (not 4-byte words). .Addresses 12 bits wide. .The cache two-way set associative ( E=2), 4-byte block size ( B=4) four sets ( S=4). contents cache follows, addresses, tags, values given hexadecimal notation: Set index Tag Valid Byte 0 Byte 1 Byte 2 Byte 3 0 00 1 40 41 42 43 83 1 FE 97 CC D0 1 00 1 44 45 46 47 83 0 ———— 2 00 1 48 49 4A 4B 40 0 ———— 3 FF 1 9A C0 03 FF 00 0 ———— A. following diagram shows format address (one bit per box). Indicate (by labeling diagram) ﬁelds would used determinethe following: CO cache block offset CI cache set index CT cache tag 1 11 09876543210 B. following memory accesses indicate cache hit miss carried sequence listed. Also give value read inferred information cache. Operation Address Hit? Read value (or unknown) Read 0x834 Write 0x836 Read 0xFFD634 Chapter 6 Memory Hierarchy 6.31◆ Suppose system following properties: .The memory byte addressable. .Memory accesses 1-byte words (not 4-byte words). .Addresses 13 bits wide. .The cache four-way set associative ( E=4), 4-byte block size ( B=4) eight sets ( S=8). Consider following cache state. addresses, tags, values given hexadecimal format. Index column contains set index set four lines. Tagcolumns contain tag value line. Vcolumns contain valid bit line. Bytes 0–3 columns contain data line, numbered left-to-right starting byte 0 left. 4-way set associative cache Index Tag V Bytes 0–3 Tag V Bytes 0–3 Tag V Bytes 0–3 Tag V Bytes 0–3 0 F0 1 ED 32 0A A2 8A 1 BF 80 1D FC 14 1 EF 09 86 2A BC 0 25 44 6F 1A 1 BC 0 03 3E CD 38 A0 0 16 7B ED 5A BC 1 8E 4C DF 18 E4 1 FB B7 12 02 2 BC 1 54 9E 1E FA B6 1 DC 81 B2 14 00 0 B6 1F 7B 44 74 0 10 F5 B8 2E 3 0 2F 7E 3D A8 C0 1 27 95 A4 74 C4 0 07 11 6B D8 BC 0 C7 B7 AF C2 4 7E 1 32 21 1C 2C 8A 1 22 C2 DC 34 BC 1 BA DD 37 D8 DC 0 E7 A2 39 BA 5 98 0 A9 76 2B EE 54 0 BC 91 D5 92 98 1 80 BA 9B F6 BC 1 48 16 81 0A 6 38 0 5D 4D F7 DA BC 1 69 C2 8C 74 8A 1 A8 CE 7F DA 38 1 FA 93 EB 48 7 8A 1 04 2A 32 6A 9E 0 B1 86 56 0E CC 1 96 30 47 F2 BC 1 F8 1D 42 30 A. size ( C) cache bytes? B. box follows shows format address (one bit per box). Indicate (by labeling diagram) ﬁelds would used determinethe following: CO cache block offset CI cache set index CT cache tag 1 21 11 09876543210 6.32◆◆ Supppose program using cache Problem 6.31 references 1-byteword address 0x071A . Indicate cache entry accessed cache byte value returned hex . Indicate whether cache miss occurs. cache miss, enter “–” “Cache byte returned”. Hint: Pay attention valid bits! A. Address format (one bit per box): 1 21 11 09876543210Homework Problems 635 B. Memory reference: Parameter Value Block offset (CO) 0x Index (CI) 0x Cache tag (CT) 0x Cache hit? (Y/N) Cache byte returned 0x 6.33◆◆ Repeat Problem 6.32 memory address 0x16E8 . A. Address format (one bit per box): 1 21 11 09876543210 B. Memory reference: Parameter Value Cache offset (CO) 0x Cache index (CI) 0x Cache tag (CT) 0x Cache hit? (Y/N) Cache byte returned 0x 6.34◆◆ cache Problem 6.31, list eight memory addresses (in hex) willhit set 2. 6.35◆◆ Consider following matrix transpose routine: 1typedef int array[4][4]; 2 3void transpose2(array dst, array src) 4{ 5 int i, j; 67 f r( i=0 ;i<4 ; i++) { 8 f r( j=0 ;j<4 ; j++) { 9 dst[j][i] = src[i][j]; 10 } 11 } 12 }636 Chapter 6 Memory Hierarchy Assume code runs machine following properties: .sizeof(int) == 4 . .Thesrc array starts address 0 dst array starts address 64 (decimal). .There single L1 data cache direct-mapped, write-through, write-allocate, block size 16 bytes. .The cache total size 32 data bytes cache initially empty. .Accesses src anddst arrays sources read write misses, respectively. A. row andcol, indicate whether access src[row][col] dst[row][col] hit (h) miss (m). example, reading src[0][0] miss writing dst[0][0] also miss. dstarray srcarray Col 0 Col 1 Col 2 Col 3 Col 0 Col 1 Col 2 Col 3 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 Row 3 Row 3 6.36◆◆ Repeat Problem 6.35 cache total size 128 data bytes. dstarray srcarray Col 0 Col 1 Col 2 Col 3 Col 0 Col 1 Col 2 Col 3 Row 0 Row 0 Row 1 Row 1 Row 2 Row 2 Row 3 Row 3 6.37◆◆ problem tests ability predict cache behavior C code. aregiven following code analyze: 1 int x[2][128]; 2 int i; 3 int sum = 0; 4 5 (i = 0; < 128; i++) { 6 sum += x[0][i] * x[1][i]; 7 }Homework Problems 637 Assume execute following conditions: .sizeof(int) = 4 . .Array xbegins memory address 0x0and stored row-major order. .In case below, cache initially empty. .The memory accesses entries array x. variables stored registers. Given assumptions, estimate miss rates following cases: A. Case 1: Assume cache 512 bytes, direct-mapped, 16-byte cache blocks. miss rate? B. Case 2: miss rate double cache size 1024 bytes?C. Case 3: assume cache 512 bytes, two-way set associative using LRU replacement policy, 16-byte cache blocks. cache missrate? D. Case 3, larger cache size help reduce miss rate? not? E. Case 3, larger block size help reduce miss rate? not? 6.38◆◆ another problem tests ability analyze cache behavior Ccode. Assume execute three summation functions Figure 6.49 thefollowing conditions: .sizeof(int) == 4 . .The machine 4KB direct-mapped cache 16-byte block size. .Within two loops, code uses memory accesses array data. loop indices value sumare held registers. .Array ais stored starting memory address 0x08000000 . Fill table approximate cache miss rate two cases N=64 andN=60. Function N=6 4 N=6 0 sumA sumB sumC 6.39◆ 3M™decides make Post-It®notes printing yellow squares white pieces paper. part printing process, need set CMYK (cyan, magenta, yellow, black) value every point square. 3M hires determine638 Chapter 6 Memory Hierarchy 1typedef int array_t[N][N]; 2 3int sumA(array_t a) 4{ 5 int i, j; 6 int sum = 0; 7 f r( i=0 ;i<N ; i++) 8 f r( j=0 ;j<N ; j++) { 9 sum += a[i][j]; 10 } 11 return sum; 12 } 13 14 int sumB(array_t a) 15 { 16 int i, j; 17 int sum = 0; 18 f r( j=0 ;j<N ; j++) 19 f r( i=0 ;i<N ; i++) { 20 sum += a[i][j]; 21 } 22 return sum; 23 } 24 25 int sumC(array_t a) 26 { 27 int i, j; 28 int sum = 0; 29 f r( j=0 ;j<N ; j+=2) 30 f r( i=0 ;i<N ; i+=2) { 31 sum += (a[i][j] + a[i+1][j] 32 + a[i][j+1] + a[i+1][j+1]); 33 } 34 return sum; 35 } Figure 6.49 Functions referenced Problem 6.38. efﬁciency following algorithms machine 2048-byte direct- mapped data cache 32-byte blocks. given following deﬁnitions: 1struct point_color { 2 int c; 3 int m; 4 int y; 5 int k; 6};Homework Problems 639 7 8struct point_color square[16][16]; 9int i, j; Assume following: .sizeof(int) == 4 . .square begins memory address 0. .The cache initially empty. .The memory accesses entries array square . Variables andjare stored registers. Determine cache performance following code: 1 (i = 0; < 16; i++){ 2 (j = 0; j < 16; j++) { 3 square[i][j].c = 0; 4 square[i][j].m = 0; 5 square[i][j].y = 1; 6 square[i][j].k = 0; 7 } 8 } A. total number writes? B. total number writes miss cache? C. miss rate? 6.40◆ Given assumptions Problem 6.39, determine cache performance thefollowing code: 1 (i = 0; < 16; i++){ 2 (j = 0; j < 16; j++) { 3 square[j][i].c = 0; 4 square[j][i].m = 0; 5 square[j][i].y = 1; 6 square[j][i].k = 0; 7 } 8 } A. total number writes? B. total number writes miss cache?C. miss rate?640 Chapter 6 Memory Hierarchy 6.41◆ Given assumptions Problem 6.39, determine cache performance thefollowing code: 1 (i = 0; < 16; i++) { 2 (j = 0; j < 16; j++) { 3 square[i][j].y = 1; 4 } 5 } 6 (i = 0; < 16; i++) { 7 (j = 0; j < 16; j++) { 8 square[i][j].c = 0; 9 square[i][j].m = 0; 10 square[i][j].k = 0; 11 } 12 } A. total number writes? B. total number writes miss cache?C. miss rate? 6.42◆◆ writing new 3D game hope earn fame fortune. Youare currently working function blank screen buffer drawing next frame. screen working 640 ×480 array pixels. machine working 64 KB direct-mapped cache 4-byte lines.The C structures using follows: 1struct pixel { 2 char r; 3 char g; 4 char b; 5 char a; 6}; 7 8struct pixel buffer[480][640]; 9int i, j; 10 char *cptr; 11 int *iptr; Assume following: .sizeof(char) == 1 andsizeof(int) == 4 . .buffer begins memory address 0. .The cache initially empty. .The memory accesses entries array buffer . Variables i, j,cptr , iptr stored registers.Homework Problems 641 percentage writes following code miss cache? 1 (j = 0; j < 640; j++) { 2 (i = 0; < 480; i++){ 3 buffer[i][j].r = 0; 4 buffer[i][j].g = 0; 5 buffer[i][j].b = 0; 6 buffer[i][j].a = 0; 7 } 8 } 6.43◆◆ Given assumptions Problem 6.42, percentage writes followingcode miss cache? 1 char *cptr = (char *) buffer; 2 (; cptr < (((char *) buffer) + 640 * 480 * 4); cptr++) 3 *cptr = 0; 6.44◆◆ Given assumptions Problem 6.42, percentage writes followingcode miss cache? 1 int *iptr = (int *)buffer; 2 (; iptr < ((int *)buffer + 640*480); iptr++) 3 *iptr = 0; 6.45◆◆◆ Download mountain program CS:APP2 Web site run favorite PC/Linux system. Use results estimate sizes caches onyour system. 6.46◆◆◆◆ assignment, apply concepts learned Chapters 5 6 problem optimizing code memory-intensive application. Consider procedure copy transpose elements N×Nmatrix type int. is, source matrix Sand destination matrix D, want copy element si,jtodj,i. code written simple loop, 1void transpose(int *dst, int *src, int dim) 2{ 3 int i, j; 4 5 (i = 0; < dim; i++) 6 (j = 0; j < dim; j++) 7 dst[j*dim + i] = src[i*dim + j]; 8}642 Chapter 6 Memory Hierarchy arguments procedure pointers destination ( dst) source ( src) matrices, well matrix size N(dim). job devise transpose routine runs fast possible. 6.47◆◆◆◆ assignment intriguing variation Problem 6.46. Consider problemof converting directed graph ginto undirected counterpart g /prime. graph g/primehas edge vertex uto vertex vif edge u tovor vtouin original graph g. graph gis represented adjacency matrix Gas follows. Nis number vertices g, Gis N×Nmatrix entries either 0 1. Suppose vertices gare named v0,v1,v2,...,vN−1. G[i][j] 1 edge vitovjand 0 otherwise. Observe elements diagonal adjacency matrixare always 1 adjacency matrix undirected graph symmetric. code written simple loop: 1void col_convert(int *G, int dim) { 2 int i, j; 3 4 (i = 0; < dim; i++) 5 (j = 0; j < dim; j++) 6 G[j*dim + i] = G[j*dim + i] || G[i*dim + j]; 7} job devise conversion routine runs fast possible. before, need apply concepts learned Chapters 5 6 comeup good solution. Solutions Practice Problems Solution Problem 6.1 (page 565) idea minimize number address bits minimizing aspectratio max (r, c)/ min(r, c) . words, squarer array, fewer address bits. Organization rc b rbc max(br,bc) 16×14 4 2 2 2 16×44 4 2 2 2 128×81 6 8 4 34 512×43 2 1 6 5 45 1024×43 2 3 2 5 5 5 Solution Problem 6.2 (page 573) point little drill make sure understand relationship cylinders tracks. straight, plug chug:Solutions Practice Problems 643 Disk capacity =512 bytes sector×400 sectors track×10,000 tracks surface×2 surfaces platter×2 platters disk =8,192,000,000 bytes =8.192 GB Solution Problem 6.3 (page 575) solution problem straightforward application formula disk access time. average rotational latency (in ms) Tavg rotation =1/2×Tmax rotation =1/2×(60 secs / 15,000 RPM )×1000 ms/sec ≈2m average transfer time Tavg transf er =(60 secs / 15,000 RPM )×1/500 sectors/track ×1000 ms/sec ≈0.008 ms Putting together, total estimated access time Taccess=Tavg seek +Tavg rotation +Tavg transf er =8m s+2m s+0.008 ms ≈10 ms Solution Problem 6.4 (page 576) good check understanding factors affect disk perfor- mance. First need determine basic properties ﬁle disk.The ﬁle consists 2000, 512-byte logical blocks. disk, avg seek =5m , Tmax rotation =6m ,a n Tavg rotation =3m . A.Best case: optimal case, blocks mapped contiguous sectors, cylinder, read one without movingthe head. head positioned ﬁrst sector takes two fullrotations (1000 sectors per rotation) disk read 2000 blocks. Sothe total time read ﬁle avg seek +Tavg rotation +2∗Tmax rotation = 5+3+12=20 ms. B.Random case: case, blocks mapped randomly sectors, reading 2000 blocks requires Tavg seek +Tavg rotation ms, to- tal time read ﬁle ( Tavg seek +Tavg rotation )∗2000=16,000 ms (16 sec- onds!). see it’s often good idea defragment disk drive!644 Chapter 6 Memory Hierarchy Solution Problem 6.5 (page 581) problem, based zone map Figure 6.14, good test understanding disk geometry, also enables derive interestingcharacteristic real disk drive. A. Zone 0. total 864 ×8×3201=22,125,312 sectors 22,076,928 logical blocks assigned zone 0, total 22 ,125,312− 22,076,928=48,384 spare sectors. Given 864 ×8=6912 sec- tors per cylinder, 48 ,384/6912=7 spare cylinders zone 0. B. Zone 8. similar analysis reveals ((3700×5632)−20,804,608)/ 5632=6 spare cylinders zone 8. Solution Problem 6.6 (page 583) simple problem give interesting insights feasibility SSDs. Recall disks, 1 PB = 109MB. following straightforward translation units yields following predicted times case: A. Worst case sequential writes (170 MB/s): 109×(1/170)×(1/(86,400×365)) ≈0.2 years. B. Worst case random writes (14 MB/s): 109×(1/14)×(1/(86,400×365)) ≈2.25 years. C. Average case (20 GB/day): 109×(1/20,000)×(1/365)≈140 years. Solution Problem 6.7 (page 586) 10-year period 2000 2010, unit price rotating disk dropped factor 30, means price dropping roughlya factor 2 every 2 years. Assuming trend continues, petabyte storage,which costs $300,000 2010, drop $500 ten thesefactor-of-2 reductions. Since occurring every 2 years, expect apetabyte storage available $500 around year 2030. Solution Problem 6.8 (page 590) create stride-1 reference pattern, loops must permuted therightmost indices change rapidly. 1int sumarray3d(int a[N][N][N]) 2{ 3 int i, j, k, sum = 0; 4 5 f r( k=0 ;k<N ; k++) { 6 f r( i=0 ;i<N ; i++) { 7 f r( j=0 ;j<N ; j++) { 8 sum += a[k][i][j]; 9 } 10 } 11 } 12 return sum; 13 }Solutions Practice Problems 645 important idea. Make sure understand particular loop permutation results stride-1 access pattern. Solution Problem 6.9 (page 590) key solving problem visualize array laid memoryand analyze reference patterns. Function clear1 accesses array using stride-1 reference pattern thus clearly best spatial locality. Functionclear2 scans Nstructs order, good, within struct hops around non-stride-1 pattern following offsets beginningof struct: 0, 12, 4, 16, 8, 20. clear2 worse spatial locality clear1 . Function clear3 hops around within struct, also hops struct struct. clear3 exhibits worse spatial locality clear2 andclear1 . Solution Problem 6.10 (page 598) solution straightforward application deﬁnitions various cache parameters Figure 6.28. exciting, need understand howthe cache organization induces partitions address bits canreally understand caches work. Cache mCB E St b 1. 32 1024 4 1 256 22 8 2 2. 32 1024 8 4 32 24 5 33. 32 1024 32 32 1 27 0 5 Solution Problem 6.11 (page 605) padding eliminates conﬂict misses. Thus, three-fourths references hits. Solution Problem 6.12 (page 605) Sometimes, understanding something bad idea helps understand whythe alternative good idea. Here, bad idea looking indexing thecache high-order bits instead middle bits. A. high-order bit indexing, contiguous array chunk consists 2 blocks, tis number tag bits. Thus, ﬁrst 2tcontiguous blocks array would map set 0, next 2tblocks would map set 1, on. B. direct-mapped cache ( S,E ,B ,m ) =(512,1,32,32), cache capacity 512 32-byte blocks, t=18 tag bits cache line. Thus, ﬁrst 218blocks array would map set 0, next 218blocks set 1. Since array consists (4096∗4)/32=512 blocks, blocks array map set 0. Thus, cache hold onearray block point time, even though array small enough ﬁt646 Chapter 6 Memory Hierarchy entirely cache. Clearly, using high-order bit indexing makes poor use cache. Solution Problem 6.13 (page 609) 2 low-order bits block offset (CO), followed 3 bits set index (CI),with remaining bits serving tag (CT): 1 2 1 1 1 0 98765 4 3 21 0 CT CT CT CT CT CT CT CT CI CI CI CO CO Solution Problem 6.14 (page 610) Address: 0x0E34 A. Address format (one bit per box): 1 2 1 1 1 0 98765 4 3 21 0 0 1 1 1 0 0 0 1 1 0 1 0 0 CT CT CT CT CT CT CT CT CI CI CI CO CO B. Memory reference: Parameter Value Cache block offset (CO) 0x0 Cache set index (CI) 0x5 Cache tag (CT) 0x71 Cache hit? (Y/N) Cache byte returned 0xB Solution Problem 6.15 (page 611) Address: 0x0DD5 A. Address format (one bit per box): 1 2 1 1 1 0 98765 4 3 21 0 0 1 1 0 1 1 1 0 1 0 1 0 1 CT CT CT CT CT CT CT CT CI CI CI CO CO B. Memory reference: Parameter Value Cache block offset (CO) 0x1 Cache set index (CI) 0x5 Cache tag (CT) 0x6E Cache hit? (Y/N) N Cache byte returned —Solutions Practice Problems 647 Solution Problem 6.16 (page 611) Address: 0x1FE4 A. Address format (one bit per box): 1 2 1 1 1 0 98765 4 3 21 0 1 1 1 1 1 1 1 1 0 0 1 0 0 CT CT CT CT CT CT CT CT CI CI CI CO CO B. Memory reference: Parameter Value Cache block offset 0x0 Cache set index 0x1 Cache tag 0xFF Cache hit? (Y/N) N Cache byte returned — Solution Problem 6.17 (page 611) problem sort inverse version Problems 6.13–6.16 requires work backward contents cache derive addresses willhit particular set. case, set 3 contains one valid line tag 0x32 . Since one valid line set, four addresses hit. addresseshave binary form 0 0110 0100 11xx . Thus, four hex addresses hit set 3 0x064C ,0x064D ,0x064E , 0x064F Solution Problem 6.18 (page 618) A. key solving problem visualize picture Figure 6.50. Notice cache line holds exactly one row array, cacheis exactly large enough hold one array, i, rowiofsrcand dstmaps cache line. cache small hold arrays, references one array keep evicting useful lines array.For example, write dst[0][0] evicts line loaded read src[0][0] . next read src[0][1] , miss. dstarray srcarray Col 0 Col 1 Col 0 Col 1 Row 0 Row 0 Row 1 Row 1 h Figure 6.50 Figure Problem 6.18.Main memory 0 16Line 0 Line 1src dstCache648 Chapter 6 Memory Hierarchy B. cache 32 bytes, large enough hold arrays. Thus, misses initial cold misses. dstarray srcarray Col 0 Col 1 Col 0 Col 1 Row 0 h Row 0 h Row 1 h Row 1 h Solution Problem 6.19 (page 619) 16-byte cache line holds two contiguous algae_position structures. loop visits structures memory order, reading one integer element eachtime. pattern loop miss, hit, miss, hit, on. Notice forthis problem could predicted miss rate without actually enumeratingthe total number reads misses. A. total number read accesses? 512 reads. B. total number read accesses miss cache? 256 misses.C. miss rate? 256 /512=50%. Solution Problem 6.20 (page 620) key problem noticing cache hold 1 /2 ar- ray. column-wise scan second half array evicts lines loaded scan ﬁrst half. example, reading ﬁrst ele-ment grid[8][0] evicts line loaded read elements grid[0][0] . line also contained grid[0][1] . begin scanning next column, reference ﬁrst element grid[0][1] misses. A. total number read accesses? 512 reads. B. total number read accesses miss cache? 256 misses.C. miss rate? 256 /512=50%. D. would miss rate cache twice big? cache twice big, could hold entire grid array. misses would initial cold misses, miss rate would 1 /4=25%. Solution Problem 6.21 (page 620) loop nice stride-1 reference pattern, thus misses initial cold misses. A. total number read accesses? 512 reads. B. total number read accesses miss cache? 128 misses.C. miss rate? 128 /512=25%.Solutions Practice Problems 649 D. would miss rate cache twice big? Increasing cache size amount would change miss rate, since cold missesare unavoidable. Solution Problem 6.22 (page 625) peak throughput L1 6500 MB/s, clock frequency 2670MHz, individual read accesses units 8-byte double s. Thus, graph estimate takes roughly 2670 /6500×8=3.2≈4 cycles access word L1 machine.This page intentionally left blank Part II Running Programs System exploration computer systems continues closer look systems software builds runs application programs.The linker combines different parts programs sin- gle ﬁle loaded memory executed processor.Modern operating systems cooperate hardware provide eachprogram illusion exclusive use processor themain memory, reality, multiple programs running sys-tem point time. ﬁrst part book, developed good understanding interaction programs hardware. Part II thebook broaden view systems giving solid understand-ing interactions programs operating system.You learn use services provided operating system tobuild system-level programs Unix shells dynamic memoryallocation packages. 651This page intentionally left blank CHAPTER7 Linking 7.1 Compiler Drivers 655 7.2 Static Linking 657 7.3 Object Files 657 7.4 Relocatable Object Files 658 7.5 Symbols Symbol Tables 660 7.6 Symbol Resolution 663 7.7 Relocation 672 7.8 Executable Object Files 678 7.9 Loading Executable Object Files 679 7.10 Dynamic Linking Shared Libraries 681 7.11 Loading Linking Shared Libraries Applications 683 7.12 Position-Independent Code (PIC) 687 7.13 Tools Manipulating Object Files 690 7.14 Summary 691 Bibliographic Notes 691Homework Problems 692 Solutions Practice Problems 698 653654 Chapter 7 Linking Linking process collecting combining various pieces code data single ﬁle loaded (copied) memory executed. Linking performed compile time , source code translated machine code; load time , program loaded memory executed loader ; even run time , application programs. early computer systems, linking performed manually. modern systems, linkingis performed automatically programs called linkers . Linkers play crucial role software development enable separate compilation . Instead organizing large application one monolithic source ﬁle, decompose smaller, manageable modules canbe modiﬁed compiled separately. change one modules, wesimply recompile relink application, without recompile theother ﬁles. Linking usually handled quietly linker, important issue students building small programs introductory programmingclasses. bother learning linking? .Understanding linkers help build large programs. Programmers build large programs often encounter linker errors caused missing modules, missing libraries, incompatible library versions. Unless understand howa linker resolves references, library is, linker uses library resolve references, kinds errors bafﬂing frustrating. .Understanding linkers help avoid dangerous programming errors. decisions Unix linkers make resolve symbol references cansilently affect correctness programs. Programs incorrectly de-ﬁne multiple global variables pass linker without warnings inthe default case. resulting programs exhibit bafﬂing run-time behav-ior extremely difﬁcult debug. show happensand avoid it. .Understanding linking help understand language scoping rulesare implemented. example, difference global local variables? really mean deﬁne variable functionwith static attribute? .Understanding linking help understand important systems con- cepts. executable object ﬁles produced linkers play key roles impor- tant systems functions loading running programs, virtual memory,paging, memory mapping. .Understanding linking enable exploit shared libraries. many years, linking considered fairly straightforward uninteresting. However, increased importance shared libraries dynamiclinking modern operating systems, linking sophisticated process thatprovides knowledgeable programmer signiﬁcant power. exam-ple, many software products use shared libraries upgrade shrink-wrappedbinaries run time. Also, Web servers rely dynamic linking sharedlibraries serve dynamic content.Section 7.1 Compiler Drivers 655 chapter provides thorough discussion aspects linking, traditional static linking, dynamic linking shared libraries load time,to dynamic linking shared libraries run time. describe basicmechanisms using real examples, identify situations linkingissues affect performance correctness programs. keep things concrete understandable, couch discussion context x86 system running Linux using standard ELF objectﬁle format. clarity, focus discussion linking 32-bit code, easier understand linking 64-bit code. 1However, important realize basic concepts linking universal, regardless operating system,the ISA, object ﬁle format. Details may vary, concepts same. 7.1 Compiler Drivers Consider C program Figure 7.1. consists two source ﬁles, main.c swap.c . Function main() callsswap , swaps two elements external global array buf. Granted, strange way swap two numbers, serve small running example throughout chapter allow us tomake important points linking works. compilation systems provide compiler driver invokes language preprocessor, compiler, assembler, linker, needed behalf user. Forexample, build example program using GNU compilation system, wemight invoke gccdriver typing following command shell: unix> gcc -O2 -g -o p main.c swap.c Figure 7.2 summarizes activities driver translates example program ASCII source ﬁle executable object ﬁle. (If wantto see steps yourself, run gccwith -voption.) driver ﬁrst runs C preprocessor ( cpp), translates C source ﬁle main.c ASCII intermediate ﬁle main.i : cpp [other arguments] main.c /tmp/main.i Next, driver runs C compiler ( cc1), translates main.i ASCII assembly language ﬁle main.s . cc1 /tmp/main.i main.c -O2 [other arguments] -o /tmp/main.s Then, driver runs assembler ( as), translates main.s relocatable object ﬁle main.o : [other arguments] -o /tmp/main.o /tmp/main.s 1. generate 32-bit code x86-64 system using gcc -m32 .656 Chapter 7 Linking (a)main.c code/link/main.c 1/* main.c */ 2void swap(); 3 4int buf[2] = {1, 2}; 5 6int main() 7{ 8 swap(); 9 return 0; 10 } code/link/main.c(b)swap.c code/link/swap.c 1/* swap.c */ 2extern int buf[]; 3 4int *bufp0 = &buf[0]; 5int *bufp1; 6 7void swap() 8{ 9 int temp; 10 11 bufp1 = &buf[1]; 12 temp = *bufp0; 13 *bufp0 = *bufp1; 14 *bufp1 = temp; 15 } code/link/swap.c Figure 7.1 Example program 1: example program consists two source ﬁles, main.c andswap.c . Themain function initializes two-element array ints, calls swap function swap pair. main.c main.oTranslators (cpp, cc1, ) Linker (ld) pFully linked executable object fileRelocatabl e object filesSource files swap.c swap.oTranslators (cpp, cc1, ) Figure 7.2 Static linking. linker combines relocatable object ﬁles form executable object ﬁle p. driver goes process generate swap.o . Finally, runs linker program ld, combines main.o andswap.o , along necessary system object ﬁles, create executable object ﬁle p: ld -o p [system object files args] /tmp/main.o /tmp/swap.o run executable p, type name Unix shell’s command line: unix> ./pSection 7.3 Object Files 657 shell invokes function operating system called loader , copies code data executable ﬁle pinto memory, transfers control beginning program. 7.2 Static Linking Static linkers Unix ldprogram take input collection relocatable object ﬁles command-line arguments generate output fully linkedexecutable object ﬁle loaded run. input relocatable objectﬁles consist various code data sections. Instructions one section,initialized global variables another section, uninitialized variables arein yet another section. build executable, linker must perform two main tasks: .Symbol resolution. Object ﬁles deﬁne reference symbols . purpose symbol resolution associate symbol reference exactly one symbol deﬁnition. .Relocation. Compilers assemblers generate code data sections start address 0. linker relocates sections associating memory location symbol deﬁnition, modifying referencesto symbols point memory location. sections follow describe tasks detail. read, keep mind basic facts linkers: Object ﬁles merely collections blocksof bytes. blocks contain program code, others contain programdata, others contain data structures guide linker loader. linkerconcatenates blocks together, decides run-time locations concatenatedblocks, modiﬁes various locations within code data blocks. Linkershave minimal understanding target machine. compilers assemblersthat generate object ﬁles already done work. 7.3 Object Files Object ﬁles come three forms: .Relocatable object ﬁle. Contains binary code data form combined relocatable object ﬁles compile time create anexecutable object ﬁle. .Executable object ﬁle. Contains binary code data form copied directly memory executed. .Shared object ﬁle. special type relocatable object ﬁle loaded memory linked dynamically, either load time run time. Compilers assemblers generate relocatable object ﬁles (including shared object ﬁles). Linkers generate executable object ﬁles. Technically, object module658 Chapter 7 Linking sequence bytes, object ﬁle object module stored disk ﬁle. However, use terms interchangeably. Object ﬁle formats vary system system. ﬁrst Unix systems Bell Labs used a.out format. (To day, executables still referred a.out ﬁles.) Early versions System V Unix used Common Object File format (COFF). Windows NT uses variant COFF called Portable Executable(PE) format. Modern Unix systems—such Linux, later versions System VUnix, BSD Unix variants, Sun Solaris—use Unix Executable Linkable Format (ELF). Although discussion focus ELF, basic concepts similar, regardless particular format. 7.4 Relocatable Object Files Figure 7.3 shows format typical ELF relocatable object ﬁle. ELF header begins 16-byte sequence describes word size byte ordering system generated ﬁle. rest ELF header containsinformation allows linker parse interpret object ﬁle. includesthe size ELF header, object ﬁle type (e.g., relocatable, executable, orshared), machine type (e.g., IA32), ﬁle offset section header table,and size number entries section header table. locationsand sizes various sections described section header table , contains ﬁxed sized entry section object ﬁle. Sandwiched ELF header section header table sections themselves. typical ELF relocatable object ﬁle contains followingsections: .text: machine code compiled program. .rodata: Read-only data format strings printf statements, jump tables switch statements (see Problem 7.14). Figure 7.3 Typical ELF relocatableobject ﬁle. Section header table Describes object file sectionsSections .strtab.line.debug.rel.data.rel.text.symtab.bss.data.rodata.textELF header0Section 7.4 Relocatable Object Files 659 .data: Initialized global C variables. Local C variables maintained run time stack, notappear either .data or.bss sections. .bss: Uninitialized global C variables. section occupies actual space object ﬁle; merely place holder. Object ﬁle formats distin-guish initialized uninitialized variables space efﬁciency:uninitialized variables occupy actual disk space theobject ﬁle. .symtab: Asymbol table information functions global vari- ables deﬁned referenced program. programmersmistakenly believe program must compiled -goption get symbol table information. fact, every relocatable object ﬁle hasa symbol table .symtab . However, unlike symbol table inside compiler, .symtab symbol table contain entries local variables. .rel.text: list locations .text section need modiﬁed linker combines object ﬁle others. general, anyinstruction calls external function references global variablewill need modiﬁed. hand, instructions call localfunctions need modiﬁed. Note relocation informationis needed executable object ﬁles, usually omitted unless user explicitly instructs linker include it. .rel.data: Relocation information global variables refer- enced deﬁned module. general, initialized global variable whose initial value address global variable externally deﬁnedfunction need modiﬁed. .debug: debugging symbol table entries local variables typedefs deﬁned program, global variables deﬁned referenced theprogram, original C source ﬁle. present compilerdriver invoked -goption. .line: mapping line numbers original C source program machine code instructions .text section. present thecompiler driver invoked -goption. .strtab: string table symbol tables .symtab and.debug sections, section names section headers. string tableis sequence null-terminated character strings. Aside uninitialized data called .bss ? use term .bss denote uninitialized data universal. originally acronym “Block Storage Start” instruction IBM 704 assembly language (circa 1957) acronym stuck. simple way remember difference .data and.bss sections think “bss” abbreviation “Better Save Space!”660 Chapter 7 Linking 7.5 Symbols Symbol Tables relocatable object module, m, symbol table contains information symbols deﬁned referenced m. context linker, three different kinds symbols: .Global symbols deﬁned module mand referenced modules. Global linker symbols correspond nonstatic C functions global variables deﬁned without C static attribute. .Global symbols referenced module mbut deﬁned module. symbols called externals correspond C functions variables deﬁned modules. .Local symbols deﬁned referenced exclusively module m. local linker symbols correspond C functions global variables aredeﬁned static attribute. symbols visible anywhere within module m, cannot referenced modules. sections object ﬁle name source ﬁle corresponds module malso get local symbols. important realize local linker symbols local program variables. symbol table .symtab contain symbols correspond local nonstatic program variables. managed runtime stack interest linker. Interestingly, local procedure variables deﬁned C static attribute managed stack. Instead, compiler allocates space in.data or.bss deﬁnition creates local linker symbol symbol table unique name. example, suppose pair functions samemodule deﬁne static local variable x: 1int f() 2{ 3 static tx=0 ; 4 return x; 5} 6 7int g() 8{ 9 static tx=1 ; 10 return x; 11 } case, compiler allocates space two integers .data exports pair unique local linker symbols assembler. example, might use x.1 deﬁnition function fandx.2for deﬁnition function g.Section 7.5 Symbols Symbol Tables 661 New C? Hiding variable function names static C programmers use static attribute hide variable function declarations inside modules, much would use public private declarations Java C++. C source ﬁles play role modules. global variable function declared static attribute private module. Similarly, global variable function declared without static attribute public accessed module. good programming practice protect variables functions static attribute wherever possible. Symbol tables built assemblers, using symbols exported compiler assembly-language .sﬁle. ELF symbol table contained .symtab section. contains array entries. Figure 7.4 shows format entry. Thename byte offset string table points null-terminated string name symbol. value symbol’s address. relocatable modules, value offset beginning section object deﬁned. executable object ﬁles, value absolute run-time address. Thesize size (in bytes) object. type usually either data function. symbol table also contain entries individual sections andfor path name original source ﬁle. distinct types theseobjects well. binding ﬁeld indicates whether symbol local global. symbol associated section object ﬁle, denoted thesection ﬁeld, index section header table. three special pseudo sections don’t entries section header table:ABS symbols relocated. UNDEF undeﬁned sym-bols, is, symbols referenced object module deﬁned else-where. COMMON uninitialized data objects yet allocated. ForCOMMON symbols, value ﬁeld gives alignment requirement, size gives minimum size. code/link/elfstructs.c 1typedef struct { 2 int name; /* String table offset */ 3 int value; /* Section offset, VM address */ 4 int size; /* Object size bytes */ 5 char type:4, /* Data, func, section, src file name (4 bits) */ 6 binding:4; /* Local global (4 bits) */ 7 char reserved; /* Unused */ 8 char section; /* Section header index, ABS, UNDEF, */ 9 /* COMMON */ 10 } Elf_Symbol; code/link/elfstructs.c Figure 7.4 ELF symbol table entry. type andbinding four bits each.662 Chapter 7 Linking example, last three entries symbol table main.o ,a displayed GNU readelf tool. ﬁrst eight entries, shown, local symbols linker uses internally. Num: Value Size Type Bind Ot Ndx Name 8: 0 8 OBJECT GLOBAL 0 3 buf 9: 0 17 FUNC GLOBAL 0 1 main 10: 0 0 NOTYPE GLOBAL 0 UND swap example, see entry deﬁnition global symbol buf,a n8 - byte object located offset (i.e., value ) zero .data section. followed deﬁnition global symbol main , 17-byte function located offset zero .text section. last entry comes reference external symbol swap .Readelf identiﬁes section integer index. Ndx=1 denotes .text section, Ndx=3 denotes .data section. Similarly, symbol table entries swap.o : Num: Value Size Type Bind Ot Ndx Name 8: 0 4 OBJECT GLOBAL 0 3 bufp09: 0 0 NOTYPE GLOBAL 0 UND buf 10: 0 39 FUNC GLOBAL 0 1 swap 11: 4 4 OBJECT GLOBAL 0 COM bufp1 First, see entry deﬁnition global symbol bufp0 , 4- byte initialized object starting offset 0 .data . next symbol comes reference external bufsymbol initialization code bufp0 . followed global symbol swap , 39-byte function offset zero .text . last entry global symbol bufp1 , 4-byte uninitialized data object (with 4-byte alignment requirement) eventually allocated .bss object module linked. Practice Problem 7.1 problem concerns swap.o module Figure 7.1(b). symbol deﬁned referenced swap.o , indicate whether symbol table entry .symtab section module swap.o . so, indicate module deﬁnes symbol ( swap.o ormain.o ), symbol type (local, global, extern), section ( .text ,.data ,o r.bss ) occupies module. Symbol swap.o .symtab entry? Symbol type Module deﬁned Section buf bufp0 bufp1 swap tempSection 7.6 Symbol Resolution 663 7.6 Symbol Resolution linker resolves symbol references associating reference exactly one symbol deﬁnition symbol tables input relocatable object ﬁles.Symbol resolution straightforward references local symbols de-ﬁned module reference. compiler allows one deﬁnitionof local symbol per module. compiler also ensures static local vari-ables, get local linker symbols, unique names. Resolving references global symbols, however, trickier. com- piler encounters symbol (either variable function name) deﬁnedin current module, assumes deﬁned module, gener-ates linker symbol table entry, leaves linker handle. linkeris unable ﬁnd deﬁnition referenced symbol input modules, prints (often cryptic) error message terminates. example, try tocompile link following source ﬁle Linux machine, 1void foo(void); 2 3int main() { 4 foo(); 5 return 0; 6} compiler runs without hitch, linker terminates cannot resolve reference foo: unix> gcc -Wall -O2 -o linkerror linkerror.c /tmp/ccSz5uti.o: function ‘main’:/tmp/ccSz5uti.o(.text+0x7): undefined reference ‘foo’collect2: ld returned 1 exit status Symbol resolution global symbols also tricky symbol might deﬁned multiple object ﬁles. case, linker must either ﬂag anerror somehow choose one deﬁnitions discard rest. approachadopted Unix systems involves cooperation compiler, assembler,and linker, introduce bafﬂing bugs unwary programmer. Aside Mangling linker symbols C++ Java C++ Java allow overloaded methods name source code different parameter lists. linker tell difference different overloaded functions? Overloaded functions C++ Java work compiler encodes unique method parameter list combination unique name linker. encoding process called mangling , inverse process demangling . Happily, C++ Java use compatible mangling schemes. mangled class name consists integer number characters name followed original name. example, class Foo encoded 3Foo . method encoded original method name, followed __, followed664 Chapter 7 Linking mangled class name, followed single letter encodings argument. example, Foo::bar(int, long) encoded bar__3Fooil . Similar schemes used mangle global variable template names. 7.6.1 Linkers Resolve Multiply Deﬁned Global Symbols compile time, compiler exports global symbol assembler either strong orweak , assembler encodes information implicitly symbol table relocatable object ﬁle. Functions initialized globalvariables get strong symbols. Uninitialized global variables get weak symbols. Forthe example program Figure 7.1, buf,bufp0 ,main , andswap strong symbols; bufp1 weak symbol. Given notion strong weak symbols, Unix linkers use following rules dealing multiply deﬁned symbols: .Rule 1: Multiple strong symbols allowed. .Rule 2: Given strong symbol multiple weak symbols, choose strong symbol. .Rule 3: Given multiple weak symbols, choose weak symbols. example, suppose attempt compile link following two C modules: 1/* foo1.c */ 2int main() 3{ 4 return 0; 5}1/* bar1.c */ 2int main() 3{ 4 return 0; 5} case, linker generate error message strong symbol main deﬁned multiple times (rule 1): unix> gcc foo1.c bar1.c /tmp/cca015022.o: function ‘main’:/tmp/cca015022.o(.text+0x0): multiple definition ‘main’ /tmp/cca015021.o(.text+0x0): first defined Similarly, linker generate error message following modules strong symbol xis deﬁned twice (rule 1): 1/* foo2.c */ 2int x = 15213; 3 4int main() 5{ 6 return 0; 7}1/* bar2.c */ 2int x = 15213; 34 void f() 5{ 6}Section 7.6 Symbol Resolution 665 However, xis uninitialized one module, linker quietly choose strong symbol deﬁned (rule 2): 1/* foo3.c */ 2#include <stdio.h> 3void f(void); 4 5int x = 15213; 67 int main() 8{ 9 f(); 10 printf("x = %d\n", x); 11 return 0; 12 }1/* bar3.c */ 2int x; 34 void f() 5{ 6 x = 15212; 7} run time, function fchanges value xfrom 15213 15212, might come unwelcome surprise author function main ! Notice linker normally gives indication detected multiple deﬁnitionsofx: unix> gcc -o foobar3 foo3.c bar3.c unix> ./foobar3 x = 15212 thing happen two weak deﬁnitions x(rule 3): 1/* foo4.c */ 2#include <stdio.h> 3void f(void); 4 5int x; 67 int main() 8{ 9 x = 15213; 10 f(); 11 printf("x = %d\n", x); 12 return 0; 13 }1/* bar4.c */ 2int x; 34 void f() 5{ 6 x = 15212; 7} application rules 2 3 introduce insidious run-time bugs incomprehensible unwary programmer, especially duplicatesymbol deﬁnitions different types. Consider following example, whichxis deﬁned intin one module double another:666 Chapter 7 Linking 1/* foo5.c */ 2#include <stdio.h> 3void f(void); 4 5int x = 15213; 6int = 15212; 78 int main() 9{ 10 f(); 11 printf("x = 0x% x = 0x%x \n", 12 x, y); 13 return 0; 14 }1/* bar5.c */ 2double x; 3 4void f() 5{ 6 x = -0.0; 7} IA32/Linux machine, double 8 bytes ints 4 bytes. Thus, assignment x = -0.0 line 6 bar5.c overwrite memory locations forxandy(lines 5 6 foo5.c ) double-precision ﬂoating-point representation negative zero! linux> gcc -o foobar5 foo5.c bar5.c linux> ./foobar5 x = 0x0 = 0x80000000 subtle nasty bug, especially occurs silently, warning compilation system, typically manifests much later execution program, far away erroroccurred. large system hundreds modules, bug kind isextremely hard ﬁx, especially many programmers aware ofhow linkers work. doubt, invoke linker ﬂag gcc -fno-common ﬂag, triggers error encounters multiply deﬁned global symbols. Practice Problem 7.2 problem, let REF(x.i) --> DEF(x.k) denote linker associate arbitrary reference symbol xin module ito deﬁnition xin module k. example follows, use notation indicate linker wouldresolve references multiply deﬁned symbol module. link-time error (rule 1), write “ERROR.” linker arbitrarily chooses one thedeﬁnitions (rule 3), write “UNKNOWN.” A. /* Module 1 */ int main() { }/* Module 2 */ int main; int p2() {}Section 7.6 Symbol Resolution 667 (a)REF(main.1) --> DEF( .) (b)REF(main.2) --> DEF( .) B./* Module 1 */ void main(){}/* Module 2 */ int main=1;int p2(){ } (a)REF(main.1) --> DEF( .) (b)REF(main.2) --> DEF( .) C./* Module 1 */ int x; void main() {}/* Module 2 */ double x=1.0; int p2() { } (a)REF(x.1) --> DEF( .) (b)REF(x.2) --> DEF( .) 7.6.2 Linking Static Libraries far, assumed linker reads collection relocatable object ﬁles links together output executable ﬁle. practice, compilationsystems provide mechanism packaging related object modules single ﬁle called static library , supplied input linker. builds output executable, linker copies object modules thelibrary referenced application program. systems support notion libraries? Consider ANSI C, deﬁnes extensive collection standard I/O, string manipulation, integermath functions atoi ,printf ,scanf ,strcpy , andrand . available every C program libc.a library. ANSI C also deﬁnes extensive collection ﬂoating-point math functions sin,cos, andsqrt libm.a library. Consider different approaches compiler developers might use pro- vide functions users without beneﬁt static libraries. One approachwould compiler recognize calls standard functions togenerate appropriate code directly. Pascal, provides small set stan-dard functions, takes approach, feasible C, largenumber standard functions deﬁned C standard. would add signiﬁcantcomplexity compiler would require new compiler version time afunction added, deleted, modiﬁed. application programmers, however,this approach would quite convenient standard functions wouldalways available.668 Chapter 7 Linking Another approach would put standard C functions single relocatable object module, say, libc.o , application programmers could link executables: unix> gcc main.c /usr/lib/libc.o approach advantage would decouple implementation standard functions implementation compiler, wouldstill reasonably convenient programmers. However, big disadvantageis every executable ﬁle system would contain complete copyof collection standard functions, would extremely wasteful ofdisk space. (On typical system, libc.a 8 MB libm.a 1 MB.) Worse, running program would contain copy functions memory, would extremely wasteful memory. Another bigdisadvantage change standard function, matter small,would require library developer recompile entire source ﬁle, time-consuming operation would complicate development maintenanceof standard functions. could address problems creating separate relocatable ﬁle standard function storing well-known directory. How-ever, approach would require application programmers explicitly link theappropriate object modules executables, process would error prone time consuming: unix> gcc main.c /usr/lib/printf.o /usr/lib/scanf.o ... notion static library developed resolve disadvantages various approaches. Related functions compiled separate objectmodules packaged single static library ﬁle. Application programscan use functions deﬁned library specifying single ﬁlename command line. example, program uses functions fromthe standard C library math library could compiled linked witha command form unix> gcc main.c /usr/lib/libm.a /usr/lib/libc.a link time, linker copy object modules referenced program, reduces size executable disk memory.On hand, application programmer needs include namesof library ﬁles. (In fact, C compiler drivers always pass libc.a linker, reference libc.a mentioned previously unnecessary.) Unix systems, static libraries stored disk particular ﬁle format known archive . archive collection concatenated relocatable object ﬁles, header describes size location member objectﬁle. Archive ﬁlenames denoted .asufﬁx. make discussion libraries concrete, suppose want provide vector routines Figure 7.5in static library called libvector.a .Section 7.6 Symbol Resolution 669 (a)addvec.o code/link/addvec.c 1void addvec(int *x, int *y, 2 int *z, int n) 3{ 4 int i; 5 6 f r( i=0 ;i<n ; i++) 7 z[i] = x[i] + y[i]; 8} code/link/addvec.c(b)multvec.o code/link/multvec.c 1void multvec(int *x, int *y, 2 int *z, int n) 3{ 4 int i; 5 6 f r( i=0 ;i<n ; i++) 7 z[i] = x[i] * y[i]; 8} code/link/multvec.c Figure 7.5 Member object ﬁles libvector.a . create library, would use artool follows: unix> gcc -c addvec.c multvec.c unix> ar rcs libvector.a addvec.o multvec.o use library, might write application main2.c Figure 7.6, invokes addvec library routine. (The include (header) ﬁle vector.h deﬁnes function prototypes routines libvector.a .) code/link/main2.c 1/* main2.c */ 2#include <stdio.h> 3#include "vector.h" 4 5int x[2] = {1, 2}; 6int y[2] = {3, 4}; 7int z[2]; 89 int main() 10 { 11 addvec(x, y, z, 2); 12 printf("z = [%d %d]\n", z[0], z[1]); 13 return 0; 14 } code/link/main2.c Figure 7.6 Example program 2: program calls member functions static libvector.a library.670 Chapter 7 Linking main2.c vector.h libvector.a libc.a addvec.o printf.o modules called printf.omain2.oTranslators (cpp, cc1, ) Linker (ld) p2 Fully linked executable object fileRelocatableobject filesSource files Static libraries Figure 7.7 Linking static libraries. build executable, would compile link input ﬁles main.o libvector.a : unix> gcc -O2 -c main2.c unix> gcc -static -o p2 main2.o ./libvector.a Figure 7.7 summarizes activity linker. -static argument tells compiler driver linker build fully linked executable object ﬁlethat loaded memory run without linking load time.When linker runs, determines addvec symbol deﬁned addvec.o referenced main.o , copies addvec.o executable. Since program doesn’t reference symbols deﬁned multvec.o , linker notcopy module executable. linker also copies printf.o module libc.a , along number modules C run-time system. 7.6.3 Linkers Use Static Libraries Resolve References static libraries useful essential tools, also source confusion programmers way Unix linker uses resolveexternal references. symbol resolution phase, linker scans therelocatable object ﬁles archives left right sequential order thatthey appear compiler driver’s command line. (The driver automatically translates .cﬁles command line .oﬁles.) scan, linker maintains set Eof relocatable object ﬁles merged form executable, set Uof unresolved symbols (i.e., symbols referred to, yet deﬁned), set Dof symbols deﬁned previous input ﬁles. Initially, E,U, andDare empty. .For input ﬁle fon command line, linker determines fis object ﬁle archive. fis object ﬁle, linker adds ftoE, updates UandDto reﬂect symbol deﬁnitions references f, proceeds next input ﬁle.Section 7.6 Symbol Resolution 671 .Iffis archive, linker attempts match unresolved symbols U symbols deﬁned members archive. archivemember, m, deﬁnes symbol resolves reference U, mis added toE, linker updates UandDto reﬂect symbol deﬁnitions references m. process iterates member object ﬁles archive ﬁxed point reached UandDno longer change. point, member object ﬁles contained Eare simply discarded linker proceeds next input ﬁle. .IfUis nonempty linker ﬁnishes scanning input ﬁles command line, prints error terminates. Otherwise, merges andrelocates object ﬁles Eto build output executable ﬁle. Unfortunately, algorithm result bafﬂing link-time errors ordering libraries object ﬁles command line signiﬁcant. thelibrary deﬁnes symbol appears command line object ﬁlethat references symbol, reference resolved linkingwill fail. example, consider following: unix> gcc -static ./libvector.a main2.c /tmp/cc9XH6Rp.o: function ‘main’: /tmp/cc9XH6Rp.o(.text+0x18): undefined reference ‘addvec’ happened? libvector.a processed, Uis empty, member object ﬁles libvector.a added E. Thus, reference addvec never resolved linker emits error message terminates. general rule libraries place end command line. members different libraries independent, member references symbol deﬁned another member, libraries placedat end command line order. If, hand, libraries independent, must ordered symbol sthat referenced externally member archive, least one deﬁnition sfollows reference son command line. example, suppose foo.c calls functions libx.a andlibz.a call func- tions liby.a . libx.a andlibz.a must precede liby.a command line: unix> gcc foo.c libx.a libz.a liby.a Libraries repeated command line necessary satisfy dependence requirements. example, suppose foo.c calls function libx.a calls function liby.a calls function libx.a . libx.a must repeated command line: unix> gcc foo.c libx.a liby.a libx.a Alternatively, could combine libx.a andliby.a single archive.672 Chapter 7 Linking Practice Problem 7.3 Letaandbdenote object modules static libraries current directory, leta→bdenote adepends b, sense bdeﬁnes symbol referenced a. following scenarios, show minimal command line (i.e., one least number object ﬁle library arguments) allow static linker resolve symbol references. A.p.o→libx.a . B.p.o→libx.a →liby.a . C.p.o→libx.a →liby.a andliby.a →libx.a →p.o. 7.7 Relocation linker completed symbol resolution step, associated symbol reference code exactly one symbol deﬁnition (i.e., symboltable entry one input object modules). point, linker knowsthe exact sizes code data sections input object modules. nowready begin relocation step, merges input modules assigns run-time addresses symbol. Relocation consists two steps: .Relocating sections symbol deﬁnitions. step, linker merges sections type new aggregate section type.For example, .data sections input modules merged one section become .data section output executable object ﬁle. linker assigns run-time memory addresses newaggregate sections, section deﬁned input modules, toeach symbol deﬁned input modules. step complete, everyinstruction global variable program unique run-time memoryaddress. .Relocating symbol references within sections. step, linker modiﬁes every symbol reference bodies code data sections thatthey point correct run-time addresses. perform step, linkerrelies data structures relocatable object modules known relocationentries, describe next. 7.7.1 Relocation Entries assembler generates object module, know code data ultimately stored memory. know locations anyexternally deﬁned functions global variables referenced module.So whenever assembler encounters reference object whose ultimateSection 7.7 Relocation 673 code/link/elfstructs.c 1typedef struct { 2 int offset; /* Offset reference relocate */ 3 int symbol:24, /* Symbol reference point */ 4 type:8; /* Relocation type */ 5} Elf32_Rel; code/link/elfstructs.c Figure 7.8 ELF relocation entry. entry identiﬁes reference must relocated. location unknown, generates relocation entry tells linker modify reference merges object ﬁle executable. Relocation entries code placed .rel.text . Relocation entries initialized data placed .rel.data . Figure 7.8 shows format ELF relocation entry. offset section offset reference need modiﬁed. symbol identiﬁes symbol modiﬁed reference point to. type tells linker modify new reference. ELF deﬁnes 11 different relocation types, quite arcane. con- cerned two basic relocation types: .R_386_PC32 : Relocate reference uses 32-bit PC-relative address. Recall Section 3.6.3 PC-relative address offset thecurrent run-time value program counter (PC). CPU executesan instruction using PC-relative addressing, forms effective address (e.g., target call instruction) adding 32-bit value encoded instruction current run-time value PC, always address next instruction memory. .R_386_32 : Relocate reference uses 32-bit absolute address. absolute addressing, CPU directly uses 32-bit value encoded theinstruction effective address, without modiﬁcations. 7.7.2 Relocating Symbol References Figure 7.9 shows pseudo code linker’s relocation algorithm. Lines 1 2 iterate section sand relocation entry rassociated section. concreteness, assume section sis array bytes relocation entry ris astruct type Elf32_Rel , deﬁned Figure 7.8. Also, assume algorithm runs, linker alreadychosen run-time addresses section (denoted ADDR(s) ) sym- bol (denoted ADDR(r.symbol) ). Line 3 computes address sarray 4-byte reference needs relocated. reference uses PC-relative674 Chapter 7 Linking 1foreach section { 2 foreach relocation entry r { 3 refpt r=s+ r.offset; /* ptr reference relocated */ 4 5 /* Relocate PC-relative reference */ 6 (r.type == R_386_PC32) { 7 refaddr = ADDR(s) + r.offset; /* ref’s run-time address */ 8 *refptr = (unsigned) (ADDR(r.symbol) + *refptr - refaddr); 9 } 10 11 /* Relocate absolute reference */ 12 (r.type == R_386_32) 13 *refptr = (unsigned) (ADDR(r.symbol) + *refptr); 14 } 15 } Figure 7.9 Relocation algorithm. addressing, relocated lines 5–9. reference uses absolute address- ing, relocated lines 11–13. Relocating PC-Relative References Recall running example Figure 7.1(a) main routine .text section main.o calls swap routine, deﬁned swap.o . disassembled listing call instruction, generated GNU objdump tool: 6: e8 fc ff ff ff call 7 <main+0x7> swap(); 7: R_386_PC32 swap relocation entry listing, see call instruction begins section offset 0x6and consists 1-byte opcode 0xe8 , followed 32-bit reference 0xfffffffc (−4 decimal), stored little-endian byte order. also see relocation entry reference displayed following line. (Recall relocationentries instructions actually stored different sections object ﬁle.The objdump tool displays together convenience.) relocation entry rconsists three ﬁelds: r.offset = 0x7 r.symbol = swap r.type = R_386_PC32 ﬁelds tell linker modify 32-bit PC-relative reference starting offset 0x7so point swap routine run time. Now, suppose linker determined ADDR(s) = ADDR(.text) = 0x80483b4Section 7.7 Relocation 675 ADDR(r.symbol) = ADDR(swap) = 0x80483c8 Using algorithm Figure 7.9, linker ﬁrst computes run-time address reference (line 7): refaddr = ADDR(s) + r.offset = 0x80483b4 + 0x7 = 0x80483bb updates reference current value ( −4) to0x9so point swap routine run time (line 8): *refptr = (unsigned) (ADDR(r.symbol) + *refptr - refaddr) = (unsigned) (0x80483c8 + (-4) - 0x80483bb)= (unsigned) (0x9) resulting executable object ﬁle, call instruction following relocated form: 80483ba: e8 09 00 00 00 call 80483c8 <swap> swap(); run time, call instruction stored address 0x80483ba . CPU executes call instruction, PC value 0x80483bf , address instruction immediately following call instruction. execute instruction, CPU performs following steps: 1. push PC onto stack 2. PC <- PC + 0x9 = 0x80483bf + 0x9 = 0x80483c8 Thus, next instruction execute ﬁrst instruction swap routine, course want! may wonder assembler created reference call instruc- tion initial value −4. assembler uses value bias account fact PC always points instruction following current in-struction. different machine different instruction sizes encodings,the assembler machine would use different bias. powerful trickthat allows linker blindly relocate references, blissfully unaware in-struction encodings particular machine. Relocating Absolute References Recall example program Figure 7.1, swap.o module initializes global pointer bufp0 address ﬁrst element global bufarray: int *bufp0 = &buf[0];676 Chapter 7 Linking Since bufp0 initialized data object, stored .data section swap.o relocatable object module. Since initialized address global array, need relocated. disassembled listing .data section swap.o : 00000000 <bufp0>: 0: 00 00 00 00 int *bufp0 = &buf[0]; 0: R_386_32 buf Relocation entry see .data section contains single 32-bit reference, bufp0 pointer, value 0x0. relocation entry tells linker 32-bit absolute reference, beginning offset 0, must relocated thatit points symbol buf. Now, suppose linker determined ADDR(r.symbol) = ADDR(buf) = 0x8049454 linker updates reference using line 13 algorithm Figure 7.9: *refptr = (unsigned) (ADDR(r.symbol) + *refptr) = (unsigned) (0x8049454 + 0) = (unsigned) (0x8049454) resulting executable object ﬁle, reference following relocated form: 0804945c <bufp0>: 804945c: 54 94 04 08 Relocated! words, linker decided run time variable bufp0 located memory address 0x804945c initialized 0x8049454 , run-time address bufarray. The.text section swap.o module contains ﬁve absolute references relocated similar way (see Problem 7.12). Figure 7.10 shows relocated.text and.data sections ﬁnal executable object ﬁle. Practice Problem 7.4 problem concerns relocated program Figure 7.10. A. hex address relocated reference swap line 5? B. hex value relocated reference swap line 5? C. Suppose linker decided reason locate .text sec- tion 0x80483b8 instead 0x80483b4 . would hex value relocated reference line 5 case?(a) Relocated .text section code/link/p-exe.d 1080483b4 <main>: 2 80483b4: 55 push %ebp 3 80483b5: 89 e5 mov %esp,%ebp 4 80483b7: 83 ec 08 sub $0x8,%esp 5 80483ba: e8 09 00 00 00 call 80483c8 <swap> swap(); 6 80483bf: 31 c0 xor %eax,%eax 7 80483c1: 89 ec mov %ebp,%esp 8 80483c3: 5d pop %ebp 9 80483c4: c3 ret 10 80483c5: 90 nop 11 80483c6: 90 nop 12 80483c7: 90 nop 13 080483c8 <swap>: 14 80483c8: 55 push %ebp 15 80483c9: 8b 15 5c 94 04 08 mov 0x804945c,%edx Get *bufp0 16 80483cf: a1 58 94 04 08 mov 0x8049458,%eax Get buf[1] 17 80483d4: 89 e5 mov %esp,%ebp 18 80483d6: c7 05 48 95 04 08 58 movl $0x8049458,0x8049548 bufp1 = &buf[1] 19 80483dd: 94 04 08 20 80483e0: 89 ec mov %ebp,%esp 21 80483e2: 8b 0a mov (%edx),%ecx 22 80483e4: 89 02 mov %eax,(%edx) 23 80483e6: a1 48 95 04 08 mov 0x8049548,%eax Get *bufp1 24 80483eb: 89 08 mov %ecx,(%eax) 25 80483ed: 5d pop %ebp 26 80483ee: c3 ret code/link/p-exe.d (b) Relocated .data section code/link/pdata-exe.d 108049454 <buf>: 2 8049454: 01 00 00 00 02 00 00 00 30804945c <bufp0>: 4 804945c: 54 94 04 08 Relocated! code/link/pdata-exe.d Figure 7.10 Relocated .text and.data sections executable ﬁle p.The original C code Figure 7.1.678 Chapter 7 Linking 7.8 Executable Object Files seen linker merges multiple object modules single exe- cutable object ﬁle. C program, began life collection ASCII textﬁles, transformed single binary ﬁle contains informa-tion needed load program memory run it. Figure 7.11 summarizesthe kinds information typical ELF executable ﬁle. format executable object ﬁle similar relocatable object ﬁle. ELF header describes overall format ﬁle. also includes theprogram’s entry point , address ﬁrst instruction execute program runs. .text ,.rodata , .data sections similar relocatable object ﬁle, except sections relocated theireventual run-time memory addresses. .init section deﬁnes small function, called _init , called program’s initialization code. Since executable fully linked (relocated), needs .rel sections. ELF executables designed easy load memory, contigu- ous chunks executable ﬁle mapped contiguous memory segments. Thismapping described segment header table . Figure 7.12 shows segment header table example executable p, displayed objdump . segment header table, see two memory segments initialized contents executable object ﬁle. Lines 1 2 tell us ﬁrst segment (the code segment ) aligned oa4K B( 2 12) boundary, read/execute permissions, starts memory address 0x08048000 , total memory size 0x448 bytes, initialized ﬁrst 0x448 bytes executable object ﬁle, includes ELF header, segment header table,and .init ,.text , .rodata sections. Section header table Describes object file sectionsMaps contiguous file sections runtime memory segments .strtab.line.debug.symtab.bss.data.rodata.text.initSegment header tableELF header0 Read-only memory segment (code segment) Read/write memory segment (data segment) Symbol table debugging info notloaded memory Figure 7.11 Typical ELF executable object ﬁle.Section 7.9 Loading Executable Object Files 679 code/link/p-exe.d Read-only code segment 1 LOAD 0x00000000 vaddr 0x08048000 paddr 0x08048000 align 2**12 2 filesz 0x00000448 memsz 0x00000448 flags r-x Read/write data segment 3 LOAD 0x00000448 vaddr 0x08049448 paddr 0x08049448 align 2**12 4 filesz 0x000000e8 memsz 0x00000104 flags rw- code/link/p-exe.d Figure 7.12 Segment header table example executable p.Legend: off: ﬁle offset, vaddr/paddr: virtual/physical address, align: segment alignment, filesz: segment size object ﬁle, memsz: segment size memory, flags: run-time permissions. Lines 3 4 tell us second segment (the data segment ) aligned 4 KB boundary, read/write permissions, starts memory address 0x08049448 , total memory size 0x104 bytes, initialized 0xe8 bytes starting ﬁle offset 0x448 , case beginning .data section. remaining bytes segment correspond .bss data initialized zero run time. 7.9 Loading Executable Object Files run executable object ﬁle p, type name Unix shell’s command line: unix> ./p Since pdoes correspond built-in shell command, shell assumes pis executable object ﬁle, runs us invoking memory- resident operating system code known loader . Unix program invoke loader calling execve function, describe detail Section 8.4.5. loader copies code data executable object ﬁle fromdisk memory, runs program jumping ﬁrst instruction, orentry point . process copying program memory running known loading . Every Unix program run-time memory image similar one Fig- ure 7.13. 32-bit Linux systems, code segment starts address 0x08048000 . data segment follows next 4 KB aligned address. run-time heap fol- lows ﬁrst 4 KB aligned address past read/write segment grows upvia calls malloc library. (We describe malloc heap detail Section 9.9.) also segment reserved shared libraries. Theuser stack always starts largest legal user address grows (towardlower memory addresses). segment starting stack reserved for680 Chapter 7 Linking Figure 7.13 Linux run-time memoryimage. 0x08048000 0Memory invisible touser code %esp (stack pointer) brk Loaded theexecutable fileUser stack (created run time) Memory-mapped region shared libraries Run-time heap (created malloc ) Read/write segment (.data,.bss ) Read-only segment (.init,.text,.rodata )Kernel memory code data memory-resident part operating system known thekernel . loader runs, creates memory image shown Figure 7.13. Guided segment header table executable, copies chunks theexecutable code data segments. Next, loader jumps pro-gram’s entry point, always address _start symbol. startup code _start address deﬁned object ﬁle crt1.o C programs. Figure 7.14 shows speciﬁc sequence calls startup code. calling initialization routines .text and.init sections, startup code calls atexit routine, appends list routines called application terminates normally. exit function runs functions registered atexit , returns control operating system 10x080480c0 <_start>: /* Entry point .text */ 2 call __libc_init_first /* Startup code .text */ 3 call _init /* Startup code .init */ 4 call atexit /* Startup code .text */ 5 call main /* Application main routine */ 6 call _exit /* Returns control OS */ 7/* Control never reaches */ Figure 7.14 Pseudo-code crt1.o startup routine every C program. Note: code pushes arguments function shown.Section 7.10 Dynamic Linking Shared Libraries 681 calling _exit . Next, startup code calls application’s main routine, begins executing C code. application returns, startup code callsthe_exit routine, returns control operating system. Aside loaders really work? description loading conceptually correct, intentionally entirely accurate. understand loading really works, must understand concepts processes ,virtual memory , memory mapping , haven’t discussed yet. encounter concepts later Chapters 8 9, revisit loading gradually reveal mystery you. impatient reader, preview loading really works: program Unix system runs context process virtual address space. shell runs program,the parent shell process forks child process duplicate parent. child process invokesthe loader via execve system call. loader deletes child’s existing virtual memory segments, creates new set code, data, heap, stack segments. new stack heap segments initialized zero. new code data segments initialized contents executableﬁle mapping pages virtual address space page-sized chunks executable ﬁle. Finally,the loader jumps _start address, eventually calls application’s main routine. Aside header information, copying data disk memory loading. copying deferred CPU references mapped virtual page, point operating systemautomatically transfers page disk memory using paging mechanism. Practice Problem 7.5 A. every C program need routine called main ? B. ever wondered C main routine end call exit ,a return statement, neither, yet program still terminates properly? Explain. 7.10 Dynamic Linking Shared Libraries static libraries studied Section 7.6.2 address many issuesassociated making large collections related functions available applica-tion programs. However, static libraries still signiﬁcant disadvantages.Static libraries, like software, need maintained updated periodically.If application programmers want use recent version library, theymust somehow become aware library changed, explicitlyrelink programs updated library. Another issue almost every C program uses standard I/O functions asprintf andscanf . run time, code functions duplicated text segment running process. typical system running 50–100682 Chapter 7 Linking processes, signiﬁcant waste scarce memory system resources. (An interesting property memory always scarce resource, regardless much system. Disk space kitchen trash cans share sameproperty.) Shared libraries modern innovations address disadvantages static libraries. shared library object module that, run time , loaded arbitrary memory address linked program memory.This process known dynamic linking performed program called dynamic linker . Shared libraries also referred shared objects , Unix systems typically denoted .sosufﬁx. Microsoft operating systems make heavy use shared libraries, refer DLLs (dynamic link libraries). Shared libraries “shared” two different ways. First, given ﬁle system, exactly one .soﬁle particular library. code data this.soﬁle shared executable object ﬁles reference library, opposed contents static libraries, copied embedded inthe executables reference them. Second, single copy .text section shared library memory shared different running processes. willexplore detail study virtual memory Chapter 9. Figure 7.15 summarizes dynamic linking process example program Figure 7.6. build shared library libvector.so example vector arithmetic routines Figure 7.5, would invoke compiler driver thefollowing special directive linker: unix> gcc -shared -fPIC -o libvector.so addvec.c multvec.c The-fPIC ﬂag directs compiler generate position-independent code (more next section). -shared ﬂag directs linker create shared object ﬁle. created library, would link example program Figure 7.6: unix> gcc -o p2 main2.c ./libvector.so creates executable object ﬁle p2in form linked libvector.so run time. basic idea linking statically executable ﬁle created, complete linking process dynam-ically program loaded. important realize none code data sections libvector.so actually copied executable p2at point. Instead, linker copies relocation symbol table information allowreferences code data libvector.so resolved run time. loader loads runs executable p2, loads partially linked executable p2, using techniques discussed Section 7.9. Next, notices p2Section 7.11 Loading Linking Shared Libraries Applications 683 Figure 7.15 Dynamic linking withshared libraries.main2.c libc.so libvector.so libc.so libvector.somain2.o p2Translators (cpp,cc1,as ) Linker (ld) Fully linked executable memoryPartially linked executable object filevector.h Loader (execve ) Dynamic linker ( ld-linux.so )Relocatable object fileRelocation symbol table inf Code data contains .interp section, contains path name dynamic linker, shared object (e.g., ld-linux.so Linux systems). Instead passing control application, would normally do, loader loads andruns dynamic linker. dynamic linker ﬁnishes linking task performing following relocations: .Relocating text data libc.so memory segment. .Relocating text data libvector.so another memory segment. .Relocating references p2to symbols deﬁned libc.so andlibvec- tor.so . Finally, dynamic linker passes control application. point on, locations shared libraries ﬁxed change execution program. 7.11 Loading Linking Shared Libraries Applications point, discussed scenario dynamic linker loadsand links shared libraries application loaded, executes.However, also possible application request dynamic linker toload link arbitrary shared libraries application running, withouthaving link applications libraries compile time.684 Chapter 7 Linking Dynamic linking powerful useful technique. examples real world: .Distributing software. Developers Microsoft Windows applications fre- quently use shared libraries distribute software updates. generatea new copy shared library, users download use areplacement current version. next time run application,it automatically link load new shared library. .Building high-performance Web servers. Many Web servers generate dynamic content , personalized Web pages, account balances, banner ads. Early Web servers generated dynamic content using fork andexecve create child process run “CGI program” context child. However, modern high-performance Web servers generate dynamiccontent using efﬁcient sophisticated approach based dynamiclinking. idea package function generates dynamic content shared library. request arrives Web browser, serverdynamically loads links appropriate function calls directly,as opposed using fork andexecve run function context child process. function remains cached server’s address space, subsequent requests handled cost simple function call. Thiscan signiﬁcant impact throughput busy site. Further, existing functions updated new functions added run time, withoutstopping server. Linux systems provide simple interface dynamic linker allows appli- cation programs load link shared libraries run time. #include <dlfcn.h> void *dlopen(const char *filename, int flag); Returns: ptr handle OK, NULL error Thedlopen function loads links shared library filename . external symbols filename resolved using libraries previously opened RTLD_ GLOBAL ﬂag. current executable compiled -rdynamic ﬂag, global symbols also available symbol resolution. flag argument must include either RTLD_NOW , tells linker resolve references external symbols immediately, RTLD_LAZY ﬂag, instructs linker defer symbol resolution code library executed. Either thesevalues or’d RTLD_GLOBAL ﬂag.Section 7.11 Loading Linking Shared Libraries Applications 685 #include <dlfcn.h> void *dlsym(void *handle, char *symbol); Returns: ptr symbol OK, NULL error Thedlsym function takes handle previously opened shared library asymbol name, returns address symbol, exists, NULL otherwise. #include <dlfcn.h> int dlclose (void *handle); Returns: 0 OK, −1 error Thedlclose function unloads shared library shared libraries still using it. #include <dlfcn.h> const char *dlerror(void); Returns: error msg previous call dlopen, dlsym, dlclose failed, NULL previous call OK Thedlerror function returns string describing recent error oc- curred result calling dlopen ,dlsym ,o rdlclose , NULL error occurred. Figure 7.16 shows would use interface dynamically link libvector.so shared library (Figure 7.5), invoke addvec routine. compile program, would invoke gccin following way: unix> gcc -rdynamic -O2 -o p3 dll.c -ldl Aside Shared libraries Java Native Interface Java deﬁnes standard calling convention called Java Native Interface (JNI) allows “native” C C++ functions called Java programs. basic idea JNI compile native C function, say, foo, shared library, say foo.so . running Java program attempts invoke function foo, Java interpreter uses dlopen interface (or something like it) dynamically link load foo.so , call foo.686 Chapter 7 Linking code/link/dll.c 1#include <stdio.h> 2#include <stdlib.h> 3#include <dlfcn.h> 4 5int x[2] = {1, 2}; 6int y[2] = {3, 4}; 7int z[2]; 8 9int main() 10 { 11 void *handle; 12 void (*addvec)(int *, int *, int *, int); 13 char *error; 1415 /* Dynamically load shared library contains addvec() */ 16 handle = dlopen("./libvector.so", RTLD_LAZY); 17 (!handle) { 18 fprintf(stderr, "%s\n", dlerror()); 19 exit(1); 20 } 2122 /* Get pointer addvec() function loaded */ 23 addvec = dlsym(handle, "addvec"); 24 ((error = dlerror()) != NULL) { 25 fprintf(stderr, "%s\n", error); 26 exit(1); 27 } 2829 /* call addvec() like function */ 30 addvec(x, y, z, 2); 31 printf("z = [%d %d]\n", z[0], z[1]); 3233 /* Unload shared library */ 34 (dlclose(handle) < 0) { 35 fprintf(stderr, "%s\n", dlerror()); 36 exit(1); 37 } 38 return 0; 39 } code/link/dll.c Figure 7.16 application program dynamically loads links shared library libvector.so .Section 7.12 Position-Independent Code (PIC) 687 7.12 Position-Independent Code (PIC) key purpose shared libraries allow multiple running processes share library code memory thus save precious memory resources. Sohow multiple processes share single copy program? One approach wouldbe assign priori dedicated chunk address space shared library, require loader always load shared library address.While straightforward, approach creates serious problems. would bean inefﬁcient use address space portions space would allocated even process didn’t use library. Second, would difﬁcult tomanage. would ensure none chunks overlapped. Everytime library modiﬁed, would make sure still ﬁt itsassigned chunk. not, would ﬁnd new chunk. created new library, would ﬁnd room it. time, given hundredsof libraries versions libraries system, would difﬁcult keep theaddress space fragmenting lots small unused unusable holes. Evenworse, assignment libraries memory would different system,thus creating even management headaches. better approach compile library code loaded executed address without modiﬁed linker. code knownasposition-independent code (PIC). Users direct GNU compilation systems generate PIC code -fPIC option gcc. IA32 systems, calls procedures object module require special treatment, since references PC-relative, known offsets, thus already PIC (see Problem 7.4). However, calls externally deﬁnedprocedures references global variables normally PIC, since theyrequire relocation link time. PIC Data References Compilers generate PIC references global variables exploiting followinginteresting fact: matter load object module (including shared object modules) memory, data segment always allocated immediatelyafter code segment. Thus, distance instruction code segment variable data segment run-time constant, independentof absolute memory locations code data segments. exploit fact, compiler creates table called global offset table (GOT) beginning data segment. GOT contains entry foreach global data object referenced object module. compileralso generates relocation record entry GOT. load time, thedynamic linker relocates entry GOT contains appropriateabsolute address. object module references global data ownGOT. run time, global variable referenced indirectly GOT using code form688 Chapter 7 Linking call L1 L1: popl %ebx ebx contains current PC addl $VAROFF, %ebx ebx points GOT entry var movl (%ebx), %eax reference indirect GOT movl (%eax), %eax fascinating piece code, call L1pushes return address (which happens address popl instruction) stack. popl instruc- tion pops address %ebx . net effect two instructions move value PC register %ebx . Theaddl instruction adds constant offset %ebx points appropriate entry GOT, contains absolute address dataitem. point, global variable referenced indirectly theGOT entry contained %ebx . example, two movl instructions load contents global variable (indirectly GOT) register %eax . PIC code performance disadvantages. global variable reference requires ﬁve instructions instead one, additional memory referenceto GOT. Also, PIC code uses additional register hold address ofthe GOT entry. machines large register ﬁles, major issue.On register-starved IA32 systems, however, losing even one register triggerspilling registers onto stack. PIC Function Calls would certainly possible PIC code use approach resolvingexternal procedure calls: call L1 L1: popl %ebx ebx contains current PC addl $PROCOFF, %ebx ebx points GOT entry proc call *(%ebx) call indirect GOT However, approach would require three additional instructions run- time procedure call. Instead, ELF compilation systems use interesting tech-nique, called lazy binding , defers binding procedure addresses ﬁrst time procedure called. nontrivial run-time overhead ﬁrsttime procedure called, call thereafter costs single instructionand memory reference indirection. Lazy binding implemented compact yet somewhat complex interac- tion two data structures: GOT procedure linkage table (PLT). object module calls functions deﬁned shared libraries, GOT PLT. GOT part .data section. PLT part .text section. Figure 7.17 shows format GOT example program main2.o Figure 7.6. ﬁrst three GOT entries special: GOT[0] contains theaddress .dynamic segment, contains information dynamic linker uses bind procedure addresses, location symbol tableSection 7.12 Position-Independent Code (PIC) 689 Address Entry Contents Description 08049674 GOT[0] 0804969c address .dynamic section 08049678 GOT[1] 4000a9f8 identifying info linker 0804967c GOT[2] 4000596f entry point dynamic linker 08049680 GOT[3] 0804845a address pushl PLT[1] ( printf ) 08049684 GOT[4] 0804846a address pushl PLT[2] ( addvec ) Figure 7.17 global offset table (GOT) executable p2.The original code Figures 7.5 7.6. relocation information. GOT[1] contains information deﬁnes module. GOT[2] contains entry point lazy binding code dynamiclinker. procedure deﬁned shared object called main2.o gets entry GOT, starting entry GOT[3]. example program, wehave shown GOT entries printf , deﬁned libc.so , andaddvec , deﬁned libvector.so . Figure 7.18 shows PLT example program p2. PLT array 16-byte entries. ﬁrst entry, PLT[0], special entry jumps thedynamic linker. called procedure entry PLT, starting PLT[1].In ﬁgure, PLT[1] corresponds printf PLT[2] corresponds addvec . PLT[0] 08048444: ff 35 78 96 04 08 pushl 0x8049678 push &GOT[1] 804844a: ff 25 7c 96 04 08 jmp *0x804967c jmp *GOT[2](linker) 8048450: 00 00 padding 8048452: 00 00 padding PLT[1] <printf> 8048454: ff 25 80 96 04 08 jmp *0x8049680 jmp *GOT[3] 804845a: 68 00 00 00 00 pushl $0x0 ID printf 804845f: e9 e0 ff ff ff jmp 8048444 jmp PLT[0] PLT[2] <addvec> 8048464: ff 25 84 96 04 08 jmp *0x8049684 jump *GOT[4] 804846a: 68 08 00 00 00 pushl $0x8 ID addvec 804846f: e9 d0 ff ff ff jmp 8048444 jmp PLT[0] <other PLT entries> Figure 7.18 procedure linkage table (PLT) executable p2.The original code Figures 7.5 7.6.690 Chapter 7 Linking Initially, program dynamically linked begins executing, procedures printf andaddvec bound ﬁrst instruction respective PLT entries. example, call addvec form 80485bb: e8 a4 fe ff ff call 8048464 <addvec> addvec called ﬁrst time, control passes ﬁrst instruction PLT[2], indirect jump GOT[4]. Initially, GOT entrycontains address pushl entry corresponding PLT entry. indirect jump PLT simply transfers control back next instruction PLT[2]. instruction pushes ID addvec symbol onto stack. last instruction jumps PLT[0], pushes another word identifyinginformation stack GOT[1], jumps dynamic linkerindirectly GOT[2]. dynamic linker uses two stack entries todetermine location addvec , overwrites GOT[4] address, passes control addvec . next time addvec called program, control passes PLT[2] before. However, time indirect jump GOT[4] transfers control toaddvec . additional overhead point memory reference indirect jump. 7.13 Tools Manipulating Object Files number tools available Unix systems help understandand manipulate object ﬁles. particular, GNU binutils package especially helpful runs every Unix platform. ar: Creates static libraries, inserts, deletes, lists, extracts members. strings : Lists printable strings contained object ﬁle. strip : Deletes symbol table information object ﬁle. nm: Lists symbols deﬁned symbol table object ﬁle. size: Lists names sizes sections object ﬁle. readelf : Displays complete structure object ﬁle, including information encoded ELF header; subsumes functionality ofsize nm. objdump : mother binary tools. display information object ﬁle. useful function disassembling binary instructionsin .text section. Unix systems also provide ldd program manipulating shared libraries: ldd: Lists shared libraries executable needs run time.Bibliographic Notes 691 7.14 Summary Linking performed compile time static linkers, load time run time dynamic linkers. Linkers manipulate binary ﬁles called objectﬁles, come three different forms: relocatable, executable, shared.Relocatable object ﬁles combined static linkers executable objectﬁle loaded memory executed. Shared object ﬁles (sharedlibraries) linked loaded dynamic linkers run time, either implicitlywhen calling program loaded begins executing, demand, theprogram calls functions dlopen library. two main tasks linkers symbol resolution, global symbol object ﬁle bound unique deﬁnition, relocation, ultimatememory address symbol determined references thoseobjects modiﬁed. Static linkers invoked compiler drivers gcc. combine multiple relocatable object ﬁles single executable object ﬁle. Multiple objectﬁles deﬁne symbol, rules linkers use silently resolvingthese multiple deﬁnitions introduce subtle bugs user programs. Multiple object ﬁles concatenated single static library. Linkers use libraries resolve symbol references object modules. left-to-right sequential scan many linkers use resolve symbol references anothersource confusing link-time errors. Loaders map contents executable ﬁles memory run pro- gram. Linkers also produce partially linked executable object ﬁles un- resolved references routines data deﬁned shared library. loadtime, loader maps partially linked executable memory callsa dynamic linker, completes linking task loading shared libraryand relocating references program. Shared libraries compiled position-independent code loaded anywhere shared run time multiple processes. Applications also usethe dynamic linker run time order load, link, access functions anddata shared libraries. Bibliographic Notes Linking well documented computer systems literature. Since lies intersection compilers, computer architecture, operating systems,linking requires understanding code generation, machine-language program-ming, program instantiation, virtual memory. ﬁt neatly usual computer systems specialties thus well covered clas- sic texts areas. However, Levine’s monograph provides good generalreference subject [66]. original speciﬁcations ELF DWARF(a speciﬁcation contents .debug and.line sections) described [52]. interesting research commercial activity centers around notion ofbinary translation , contents object ﬁle parsed, analyzed,692 Chapter 7 Linking modiﬁed. Binary translation used three different purposes [64]: emulate one system another system, observe program behavior, toperform system-dependent optimizations possible compile time.Commercial products VTune, Purify, BoundsChecker use binarytranslation provide programmers detailed observations programs.Valgrind popular open-source alternative. Atom system provides ﬂexible mechanism instrumenting Alpha executable object ﬁles shared libraries arbitrary C functions [103]. Atomhas used build myriad analysis tools trace procedure calls, proﬁleinstruction counts memory referencing patterns, simulate memory systembehavior, isolate memory referencing errors. Etch [90] EEL [64] provideroughly similar capabilities different platforms. Shade system uses binarytranslation instruction proﬁling [23]. Dynamo [5] Dyninst [15] providemechanisms instrumenting optimizing executables memory run time.Smith colleagues investigated binary translation program proﬁlingand optimization [121]. Homework Problems 7.6◆ Consider following version swap.c function counts number times called: 1extern int buf[]; 2 3int *bufp0 = &buf[0]; 4static int *bufp1; 56 static void incr() 7{ 8 static int count=0; 9 10 count++; 11 } 1213 void swap() 14 { 15 int temp; 1617 incr(); 18 bufp1 = &buf[1]; 19 temp = *bufp0; 20 *bufp0 = *bufp1; 21 *bufp1 = temp; 22 }Homework Problems 693 symbol deﬁned referenced swap.o , indicate symbol table entry .symtab section module swap.o . so, indicate module deﬁnes symbol ( swap.o ormain.o ), symbol type (local, global, extern), section ( .text ,.data ,o r.bss ) occupies module. Symbol swap.o .symtab entry? Symbol type Module deﬁned Section buf bufp0 bufp1 swap temp incr count 7.7◆ Without changing variable names, modify bar5.c page 666 foo5.c prints correct values xandy(i.e., hex representations integers 15213 15212). 7.8◆ problem, let REF(x.i) --> DEF(x.k) denote linker associate arbitrary reference symbol xin module ito deﬁnition xin module k. example below, use notation indicate linker would resolvereferences multiply deﬁned symbol module. link-time error (rule 1), write “ERROR.” linker arbitrarily chooses one thedeﬁnitions (rule 3), write “UNKNOWN.” A. /* Module 1 */ int main() { }/* Module 2 */ static int main=1;int p2() { } (a)REF(main.1) --> DEF( .) (b)REF(main.2) --> DEF( .) B./* Module 1 */ int x; void main() { }/* Module 2 */ double x; int p2() { } (a)REF(x.1) --> DEF( .) (b)REF(x.2) --> DEF( .)694 Chapter 7 Linking C./* Module 1 */ int x=1; void main() { }/* Module 2 */ double x=1.0;int p2(){ } (a)REF(x.1) --> DEF( .) (b)REF(x.2) --> DEF( .) 7.9◆ Consider following program, consists two object modules: 1/* foo6.c */ 2void p2(void); 3 4int main() 5{ 6 p2(); 7 return 0; 8}1/* bar6.c */ 2#include <stdio.h> 34 char main; 5 6void p2() 7{ 8 printf("0x%x\n", main); 9} program compiled executed Linux system, prints string “0x55\n ” terminates normally, even though p2never initializes variable main . explain this? 7.10◆ Letaandbdenote object modules static libraries current directory, leta→bdenote adepends b, sense bdeﬁnes symbol referenced a. following scenarios, show minimal command line (i.e., one least number object ﬁle library arguments) willallow static linker resolve symbol references: A.p.o→libx.a →p.o B.p.o→libx.a →liby.a andliby.a →libx.a C.p.o→libx.a →liby.a →libz.a andliby.a →libx.a →libz.a 7.11◆ segment header Figure 7.12 indicates data segment occupies 0x104 bytes memory. However, ﬁrst 0xe8 bytes come sections executable ﬁle. causes discrepancy? 7.12◆◆ Theswap routine Figure 7.10 contains ﬁve relocated references. relo- cated reference, give line number Figure 7.10, run-time memory address,and value. original code relocation entries swap.o module shown Figure 7.19.Homework Problems 695 100000000 <swap>: 2 0: 55 push %ebp 3 1: 8b 15 00 00 00 00 mov 0x0,%edx Get *bufp0=&buf[0] 4 3: R_386_32 bufp0 Relocation entry 5 7: a1 04 00 00 00 mov 0x4,%eax Get buf[1] 6 8: R_386_32 buf Relocation entry 7 c: 89 e5 mov %esp,%ebp 8 e: c7 05 00 00 00 00 04 movl $0x4,0x0 bufp1 = &buf[1]; 9 15: 00 00 00 10 10: R_386_32 bufp1 Relocation entry 11 14: R_386_32 buf Relocation entry 12 18: 89 ec mov %ebp,%esp 13 1a: 8b 0a mov (%edx),%ecx temp = buf[0]; 14 1c: 89 02 mov %eax,(%edx) buf[0]=buf[1]; 15 1e: a1 00 00 00 00 mov 0x0,%eax Get *bufp1=&buf[1] 16 1f: R_386_32 bufp1 Relocation entry 17 23: 89 08 mov %ecx,(%eax) buf[1]=temp; 18 25: 5d pop %ebp 19 26: c3 ret Figure 7.19 Code relocation entries Problem 7.12. Line # Fig. 7.10 Address Value 7.13◆◆◆ Consider C code corresponding relocatable object module Figure 7.20. A. Determine instructions .text need modiﬁed linker module relocated. instruction, list informationin relocation entry: section offset, relocation type, symbol name. B. Determine data objects .data need modiﬁed linker module relocated. instruction, list informationin relocation entry: section offset, relocation type, symbol name. Feel free use tools objdump help solve problem. 7.14◆◆◆ Consider C code corresponding relocatable object module Figure 7.21. A. Determine instructions .text need modiﬁed linker module relocated. instruction, list informationin relocation entry: section offset, relocation type, symbol name.696 Chapter 7 Linking (a) C code 1extern int p3(void); 2i n tx=1 ; 3int *xp = &x; 4 5void p2(int y) { 6} 7 8void p1() { 9 p2(*xp + p3()); 10 } (b).text section relocatable object ﬁle 100000000 <p2>: 2 0: 55 push %ebp 3 1: 89 e5 mov %esp,%ebp 4 3: 89 ec mov %ebp,%esp 5 5: 5d pop %ebp 6 6: c3 ret 700000008 <p1>: 8 8: 55 push %ebp 9 9: 89 e5 mov %esp,%ebp 10 b: 83 ec 08 sub $0x8,%esp 11 e: 83 c4 f4 add $0xfffffff4,%esp 12 11: e8 fc ff ff ff call 12 <p1+0xa> 13 16: 89 c2 mov %eax,%edx 14 18: a1 00 00 00 00 mov 0x0,%eax 15 1d: 03 10 add (%eax),%edx 16 1f: 52 push %edx 17 20: e8 fc ff ff ff call 21 <p1+0x19> 18 25: 89 ec mov %ebp,%esp 19 27: 5d pop %ebp 20 28: c3 ret (c).data section relocatable object ﬁle 100000000 <x>: 2 0: 01 00 00 00 300000004 <xp>: 4 4: 00 00 00 00 Figure 7.20 Example code Problem 7.13.Homework Problems 697 (a) C code 1int relo3(int val) { 2 switch (val) { 3 case 100: 4 return(val); 5 case 101: 6 return(val+1); 7 case 103: case 104: 8 return(val+3); 9 case 105: 10 return(val+5); 11 default: 12 return(val+6); 13 } 14 } (b).text section relocatable object ﬁle 100000000 <relo3>: 2 0: 55 push %ebp 3 1: 89 e5 mov %esp,%ebp 4 3: 8b 45 08 mov 0x8(%ebp),%eax 5 6: 8d 50 9c lea 0xffffff9c(%eax),%edx 6 9: 83 fa 05 cmp $0x5,%edx 7 c: 77 17 ja 25 <relo3+0x25> 8 e: ff 24 95 00 00 00 00 jmp *0x0(,%edx,4) 9 15: 40 inc %eax 10 16: eb 10 jmp 28 <relo3+0x28> 11 18: 83 c0 03 add $0x3,%eax 12 1b: eb 0b jmp 28 <relo3+0x28> 13 1d: 8d 76 00 lea 0x0(%esi),%esi 14 20: 83 c0 05 add $0x5,%eax 15 23: eb 03 jmp 28 <relo3+0x28> 16 25: 83 c0 06 add $0x6,%eax 17 28: 89 ec mov %ebp,%esp 18 2a: 5d pop %ebp 19 2b: c3 ret (c).rodata section relocatable object ﬁle jump table switch statement 10000 28000000 15000000 25000000 18000000 4 words offsets 0x0,0x4,0x8, 0xc 20010 18000000 20000000 2 words offsets 0x10 0x14 Figure 7.21 Example code Problem 7.14.698 Chapter 7 Linking B. Determine data objects .rodata need modiﬁed linker module relocated. instruction, list in-formation relocation entry: section offset, relocation type, symbolname. Feel free use tools objdump help solve problem. 7.15◆◆◆ Performing following tasks help become familiar thevarious tools manipulating object ﬁles. A. many object ﬁles contained versions libc.a andlibm.a system? B. gcc -O2 produce different executable code gcc -O2 -g ? C. shared libraries gccdriver system use? Solutions Practice Problems Solution Problem 7.1 (page 662) purpose problem help understand relationship linker symbols C variables functions. Notice C local variable temp nothave symbol table entry. Symbol swap.o .symtab entry? Symbol type Module deﬁned Section buf yes extern main.o .data bufp0 yes global swap.o .data bufp1 yes global swap.o .bss swap yes global swap.o .text temp — — — Solution Problem 7.2 (page 666) simple drill checks understanding rules Unix linker uses resolves global symbols deﬁned one module. Understanding rules help avoid nasty programming bugs. A. linker chooses strong symbol deﬁned module 1 weak symbol deﬁned module 2 (rule 2): (a)REF(main.1) --> DEF(main.1) (b)REF(main.2) --> DEF(main.1) B. ERROR, module deﬁnes strong symbol main (rule 1).Solutions Practice Problems 699 C. linker chooses strong symbol deﬁned module 2 weak symbol deﬁned module 1 (rule 2): (a)REF(x.1) --> DEF(x.2) (b)REF(x.2) --> DEF(x.2) Solution Problem 7.3 (page 672) Placing static libraries wrong order command line common source linker errors confuses many programmers. However, understandhow linkers use static libraries resolve references, it’s pretty straightforward. little drill checks understanding idea: A.gcc p.o libx.a B.gcc p.o libx.a liby.a C.gcc p.o libx.a liby.a libx.a Solution Problem 7.4 (page 676) problem concerns disassembly listing Figure 7.10. purpose give practice reading disassembly listings check under-standing PC-relative addressing. A. hex address relocated reference line 5 0x80483bb . B. hex value relocated reference line 5 0x9. Remember disassembly listing shows value reference little-endian byteorder. C. key observation matter linker locates .text section, distance reference swap function always same. Thus, reference PC-relative address, value willbe0x9, regardless linker locates .text section. Solution Problem 7.5 (page 681) C programs actually start mystery programmers. questions check understanding startup process. answer themby referring C startup code Figure 7.14. A. Every program needs main function, C startup code, common every C program, jumps function called main . B. main terminates return statement, control passes back startup routine, returns control operating system calling_exit . behavior occurs user omits return statement. main terminates call exit , exit eventually returns control operating system calling _exit . net effect three cases: main ﬁnished, control passes back operating system.This page intentionally left blank CHAPTER8 Exceptional Control Flow 8.1 Exceptions 703 8.2 Processes 712 8.3 System Call Error Handling 717 8.4 Process Control 718 8.5 Signals 736 8.6 Nonlocal Jumps 759 8.7 Tools Manipulating Processes 762 8.8 Summary 763 Bibliographic Notes 763 Homework Problems 764 Solutions Practice Problems 771 701702 Chapter 8 Exceptional Control Flow time ﬁrst apply power processor time shut off, program counter assumes sequence values a0,a1,...,an−1 akis address corresponding instruction Ik. transition fromaktoak+1is called control transfer . sequence control transfers called ﬂow control ,o rcontrol ﬂow processor. simplest kind control ﬂow “smooth” sequence Ikand Ik+1are adjacent memory. Typically, abrupt changes smooth ﬂow, Ik+1is adjacent Ik, caused familiar program instructions jumps, calls, returns. instructions necessary mechanisms allow programsto react changes internal program state represented program variables. systems must also able react changes system state captured internal program variables necessarily related tothe execution program. example, hardware timer goes regularintervals must dealt with. Packets arrive network adapter mustbe stored memory. Programs request data disk sleep theyare notiﬁed data ready. Parent processes create child processesmust notiﬁed children terminate. Modern systems react situations making abrupt changes control ﬂow. general, refer abrupt changes exceptional control ﬂow (ECF). Exceptional control ﬂow occurs levels computer system. example, hardware level, events detected hardware trigger abrupt control transfers exception handlers. operating systems level, kerneltransfers control one user process another via context switches. theapplication level, process send signal another process abruptly transfers control signal handler recipient. individual program canreact errors sidestepping usual stack discipline making nonlocaljumps arbitrary locations functions. programmers, number reasons important understand ECF: .Understanding ECF help understand important systems concepts. ECF basic mechanism operating systems use implement I/O, processes, virtual memory. really understand important ideas,you need understand ECF. .Understanding ECF help understand applications interact operating system. Applications request services operating system using form ECF known trap orsystem call . example, writing data disk, reading data network, creating new process, terminatingthe current process accomplished application programs invokingsystem calls. Understanding basic system call mechanism help youunderstand services provided applications. .Understanding ECF help write interesting new application programs. operating system provides application programs powerful ECFSection 8.1 Exceptions 703 mechanisms creating new processes, waiting processes terminate, notifying processes exceptional events system, detectingand responding events. understand ECF mechanisms,then use write interesting programs Unix shells andWeb servers. .Understanding ECF help understand concurrency. ECF basic mechanism implementing concurrency computer systems. exceptionhandler interrupts execution application program, processes andthreads whose execution overlap time, signal handler interruptsthe execution application program examples concurrency inaction. Understanding ECF ﬁrst step understanding concurrency. Wewill return study detail Chapter 12. .Understanding ECF help understand software exceptions work.Languages C++ Java provide software exception mechanisms viatry,catch , throw statements. Software exceptions allow program make nonlocal jumps (i.e., jumps violate usual call/return stack discipline) response error conditions. Nonlocal jumps form ofapplication-level ECF, provided C via setjmp andlongjmp functions. Understanding low-level functions help understandhow higher-level software exceptions implemented. point study systems, learned applications interact hardware. chapter pivotal sense beginto learn applications interact operating system. Interestingly,these interactions revolve around ECF. describe various forms ECF exist levels computer system. start exceptions, lie atthe intersection hardware operating system. also discuss system calls, exceptions provide applications entry points theoperating system. move level abstraction describe processesand signals, lie intersection applications operating system.Finally, discuss nonlocal jumps, application-level form ECF. 8.1 Exceptions Exceptions form exceptional control ﬂow implemented partlyby hardware partly operating system. partlyimplemented hardware, details vary system system. However, thebasic ideas every system. aim section give general understanding exceptions exception handling, help demystify often confusing aspect modern computer systems. exception abrupt change control ﬂow response change processor’s state. Figure 8.1 shows basic idea. ﬁgure, theprocessor executing current instruction currwhen signiﬁcant change processor’s state occurs. state encoded various bits signals inside processor. change state known event . event might directly704 Chapter 8 Exceptional Control Flow Figure 8.1 Anatomy exception.A change processor’sstate (event) triggers anabrupt control transfer(an exception) application program anexception handler. Afterit ﬁnishes processing, handler either returns control interruptedprogram aborts.Application programException handler Exception Exception processin g Exception return (optional)Event occurs hereIcurr Inext related execution current instruction. example, virtual memory page fault occurs, arithmetic overﬂow occurs, instruction attempts divideby zero. hand, event might unrelated execution ofthe current instruction. example, system timer goes I/O requestcompletes. case, processor detects event occurred, makes indirect procedure call (the exception), jump table called exception table , operating system subroutine (the exception handler ) speciﬁcally designed process particular kind event. exception handler ﬁnishes processing, one three things happens, depending type event caused exception: 1.The handler returns control current instruction curr, instruction executing event occurred. 2.The handler returns control Inext, instruction would executed next exception occurred. 3.The handler aborts interrupted program. Section 8.1.2 says possibilities. Aside Hardware vs. software exceptions C++ Java programmers noticed term “exception” also used describe application-level ECF mechanism provided C++ Java form catch ,throw , try statements. wanted perfectly clear, might distinguish “hardware” “software” exceptions, usually unnecessary meaning clear context. 8.1.1 Exception Handling Exceptions difﬁcult understand handling involves close cooperation hardware software. easy get confused component performs task. Let’s look division labor betweenhardware software detail.Section 8.1 Exceptions 705 Figure 8.2 Exception table. exception table ajump table entrykcontains address handler code exception k.Code exception handler 0 Code exception handler 1 Code exception handler 2 Code exception handler n/H11002 1 . . . . . .0 12 n/H11002 1Exception table type possible exception system assigned unique nonnegative integer exception number . numbers assigned designers processor. numbers assigned designers operatingsystem kernel (the memory-resident part operating system). Examples former include divide zero, page faults, memory access violations, break-points, arithmetic overﬂows. Examples latter include system calls andsignals external I/O devices. system boot time (when computer reset powered on), operat- ing system allocates initializes jump table called exception table , entry kcontains address handler exception k. Figure 8.2 shows format exception table. run time (when system executing program), processor detects event occurred determines corresponding exceptionnumber k. processor triggers exception making indirect pro- cedure call, entry kof exception table, corresponding handler. Figure 8.3 shows processor uses exception table form address ofthe appropriate exception handler. exception number index ex-ception table, whose starting address contained special CPU register calledtheexception table base register . exception akin procedure call, important differences. .As procedure call, processor pushes return address stackbefore branching handler. However, depending class excep-tion, return address either current instruction (the instruction Figure 8.3 Generating address exception handler. exception number isan index exceptiontable.. . .0 1 2 n/H11002 1Exception table Address entry exception # kException number (x 4) Exception table base register/H11001706 Chapter 8 Exceptional Control Flow executing event occurred) next instruction (the instruc- tion would executed current instruction event notoccurred). .The processor also pushes additional processor state onto stack thatwill necessary restart interrupted program handler returns.For example, IA32 system pushes EFLAGS register containing, amongother things, current condition codes, onto stack. .If control transferred user program kernel, items pushed onto kernel’s stack rather onto user’s stack. .Exception handlers run kernel mode (Section 8.2.4), means complete access system resources. hardware triggers exception, rest work done software exception handler. handler processed event, optionallyreturns interrupted program executing special “return interrupt”instruction, pops appropriate state back processor’s controland data registers, restores state user mode (Section 8.2.4) exception interrupted user program, returns control interrupted program. 8.1.2 Classes Exceptions Exceptions divided four classes: interrupts ,traps ,faults , aborts . table Figure 8.4 summarizes attributes classes. Interrupts Interrupts occur asynchronously result signals I/O devices external processor. Hardware interrupts asynchronous sensethat caused execution particular instruction. Exceptionhandlers hardware interrupts often called interrupt handlers . Figure 8.5 summarizes processing interrupt. I/O devices network adapters, disk controllers, timer chips trigger interrupts signaling pin processor chip placing onto system bus exception numberthat identiﬁes device caused interrupt. Class Cause Async/Sync Return behavior Interrupt Signal I/O device Async Always returns next instruction Trap Intentional exception Sync Always returns next instructionFault Potentially recoverable error Sync Might return current instruction Abort Nonrecoverable error Sync Never returns Figure 8.4 Classes exceptions. Asynchronous exceptions occur result events I/O devices external processor. Synchronous exceptions occur direct result ofexecuting instruction.Section 8.1 Exceptions 707 Figure 8.5 Interrupt handling.The interrupt handlerreturns control thenext instruction theapplication program’s control ﬂow.(2) Control passes handler current instruction finishes (3) Interrupt handler run (4) Handler returns next instruction(1) Interrupt pin goes high execution current instructionIcurr Inext current instruction ﬁnishes executing, processor notices interrupt pin gone high, reads exception number system bus, calls appropriate interrupt handler. handler returns, returnscontrol next instruction (i.e., instruction would followed thecurrent instruction control ﬂow interrupt occurred). effect isthat program continues executing though interrupt never happened. remaining classes exceptions (traps, faults, aborts) occur syn- chronously result executing current instruction. refer in- struction faulting instruction . Traps System Calls Traps areintentional exceptions occur result executing instruction. Like interrupt handlers, trap handlers return control next instruction. Themost important use traps provide procedure-like interface userprograms kernel known system call . User programs often need request services kernel reading ﬁle ( read ), creating new process ( fork ), loading new program ( execve ), terminating current process ( exit ). allow controlled access kernel services, processors provide special “ syscall n” instruction user programs execute want request service n. Executing syscall instruction causes trap exception handler decodes argument andcalls appropriate kernel routine. Figure 8.6 summarizes processing fora system call. programmer’s perspective, system call identical Figure 8.6 Trap handling. trap handler returns controlto next instruction inthe application program’s control ﬂow.(2) Control passes handler (3) Trap handler run (4) Handler returns instruction following syscall(1) Application makes system callsyscall Inext708 Chapter 8 Exceptional Control Flow Figure 8.7 Fault handling. Depend- ing whether faultcan repaired not,the fault handler eitherreexecutes faultinginstruction aborts.(2) Control passes handler (3) Fault handler runs (4) Handler either reexecutes current instruction aborts(1) Current instruction causes faultIcurr abort regular function call. However, implementations quite different. Regular functions run user mode , restricts types instructions execute, access stack calling function. system call runsinkernel mode , allows execute instructions, accesses stack deﬁned kernel. Section 8.2.4 discusses user kernel modes detail. Faults Faults result error conditions handler might able correct. Whena fault occurs, processor transfers control fault handler. handleris able correct error condition, returns control faulting instruction,thereby reexecuting it. Otherwise, handler returns abort routine kernel terminates application program caused fault. Figure 8.7 summarizes processing fault. classic example fault page fault exception, occurs instruction references virtual address whose corresponding physical page notresident memory must therefore retrieved disk. see inChapter 9, page contiguous block (typically 4 KB) virtual memory. Thepage fault handler loads appropriate page disk returns controlto instruction caused fault. instruction executes again, theappropriate physical page resident memory instruction able runto completion without faulting. Aborts Aborts result unrecoverable fatal errors, typically hardware errors suchas parity errors occur DRAM SRAM bits corrupted. Aborthandlers never return control application program. shown Figure 8.8,the handler returns control abort routine terminates application program. 8.1.3 Exceptions Linux/IA32 Systems help make things concrete, let’s look exceptions deﬁned IA32 systems. 256 different exception types [27]. Numbersin range 0 31 correspond exceptions deﬁned Intelarchitects, thus identical IA32 system. Numbers range fromSection 8.1 Exceptions 709 Figure 8.8 Abort handling. abort handler passes control akernel abort routine terminates applicationprogram.(2) Control passes handler (3) Abort handler runs (4) Handler returns toabort routine(1) Fatal hardware error occursIcurr abort Exception number Description Exception class 0 Divide error Fault 13 General protection fault Fault 14 Page fault Fault18 Machine check Abort 32–127 OS-deﬁned exceptions Interrupt trap 128 ( 0x80 ) System call Trap 129–255 OS-deﬁned exceptions Interrupt trap Figure 8.9 Examples exceptions IA32 systems. 32 255 correspond interrupts traps deﬁned operating system. Figure 8.9 shows examples. Linux/IA32 Faults Aborts Divide error. divide error (exception 0) occurs application attempts divide zero, result divide instruction big destina-tion operand. Unix attempt recover divide errors, opting insteadto abort program. Linux shells typically report divide errors “Floating ex-ceptions.” General protection fault. infamous general protection fault (exception 13) occurs many reasons, usually program references undeﬁned areaof virtual memory, program attempts write read-only textsegment. Linux attempt recover fault. Linux shells typicallyreport general protection faults “Segmentation faults.” Page fault. page fault (exception 14) example exception faulting instruction restarted. handler maps appropriate page ofphysical memory disk page virtual memory, restarts thefaulting instruction. see page faults work detail Chapter 9. Machine check. machine check (exception 18) occurs result fatal hardware error detected execution faulting instruction.Machine check handlers never return control application program.710 Chapter 8 Exceptional Control Flow Number Name Description Number Name Description 1 exit Terminate process 27 alarm Set signal delivery alarm clock 2 fork Create new process 29 pause Suspend process signal arrives 3 read Read ﬁle 37 kill Send signal another process 4 write Write ﬁle 48 signal Install signal handler5 open Open ﬁle 63 dup2 Copy ﬁle descriptor6 close Close ﬁle 64 getppid Get parent’s process ID 7 waitpid Wait child terminate 65 getpgrp Get process group 11 execve Load run program 67 sigaction Install portable signal handler19 lseek Go ﬁle offset 90 mmap Map memory page ﬁle 20 getpid Get process ID 106 stat Get information ﬁle Figure 8.10 Examples popular system calls Linux/IA32 systems. Linux provides hundreds system calls. Source: /usr/include/sys/syscall.h . Linux/IA32 System Calls Linux provides hundreds system calls application programs use want request services kernel, reading ﬁle, writing ﬁle, orcreating new process. Figure 8.10 shows popular Linux systemcalls. system call unique integer number corresponds offsetin jump table kernel. System calls provided IA32 systems via trapping instruction called intn, ncan index 256 entries IA32 exception table. Historically, system calls provided exception 128 ( 0x80 ). C programs invoke system call directly using syscall function. However, rarely necessary practice. standard C library provides aset convenient wrapper functions system calls. wrapper functionspackage arguments, trap kernel appropriate system callnumber, pass return status system call back callingprogram. Throughout text, refer system calls associatedwrapper functions interchangeably system-level functions . quite interesting study programs use int instruction invoke Linux system calls directly. parameters Linux system calls arepassed general purpose registers rather stack. convention,register %eax contains syscall number, registers %ebx ,%ecx ,%edx ,%esi , %edi , %ebp contain six arbitrary arguments. stack pointer %esp cannot used overwritten kernel enters kernel mode. example, consider following version familiar hello program, written using write system-level function: 1int main() 2{ 3 write(1, "hello, world\n", 13); 4 exit(0); 5}Section 8.1 Exceptions 711 code/ecf/hello-asm.sa 1.section .data 2string: 3 .ascii "hello, world\n" 4string_end: 5 .equ len, string_end - string 6.section .text 7.globl main 8main: First, call write(1, "hello, world\n", 13) 9 movl $4, %eax System call number 4 10 movl $1, %ebx stdout descriptor 1 11 movl $string, %ecx Hello world string 12 movl $len, %edx String length 13 int $0x80 System call code Next, call exit(0) 14 movl $1, %eax System call number 0 15 movl $0, %ebx Argument 0 16 int $0x80 System call code code/ecf/hello-asm.sa Figure 8.11 Implementing hello program directly Linux system calls. ﬁrst argument write sends output stdout . second argument sequence bytes write, third argument gives number bytes write. Figure 8.11 shows assembly language version hello uses int instruction invoke write andexit system calls directly. Lines 9–13 invoke thewrite function. First, line 9 stores number write system call %eax , lines 10–12 set argument list. line 13 uses intinstruction invoke system call. Similarly, lines 14–16 invoke exit system call. Aside note terminology terminology various classes exceptions varies system system. Processor macroar- chitecture speciﬁcations often distinguish asynchronous “interrupts” synchronous “excep- tions,” yet provide umbrella term refer similar concepts. avoid constantly refer “exceptions interrupts” “exceptions interrupts,” use word “exception” general term distinguish asynchronous exceptions (interrupts) synchronous ex- ceptions (traps, faults, aborts) appropriate. noted, basic ideas arethe every system, aware manufacturers’ manuals use word “exception” refer changes control ﬂow caused synchronous events.712 Chapter 8 Exceptional Control Flow 8.2 Processes Exceptions basic building blocks allow operating system provide notion process , one profound successful ideas computer science. run program modern system, presented illusion program one currently running system. Ourprogram appears exclusive use processor memory.The processor appears execute instructions program, one other, without interruption. Finally, code data program appear tobe objects system’s memory. illusions provided us bythe notion process. classic deﬁnition process instance program execution . program system runs context process. context consists state program needs run correctly. state includes theprogram’s code data stored memory, stack, contents general-purpose registers, program counter, environment variables, set openﬁle descriptors. time user runs program typing name executable object ﬁle shell, shell creates new process runs executable objectﬁle context new process. Application programs also create newprocesses run either code applications context thenew process. detailed discussion operating systems implement processes be- yond scope. Instead, focus key abstractions processprovides application: .An independent logical control ﬂow provides illusion pro- gram exclusive use processor. .A private address space provides illusion program exclu-sive use memory system. Let’s look closely abstractions. 8.2.1 Logical Control Flow process provides program illusion exclusive use processor, even though many programs typically running concurrentlyon system. use debugger single step execution ofour program, would observe series program counter (PC) values corresponded exclusively instructions contained program’s executable object ﬁle shared objects linked program dynamically run time.This sequence PC values known logical control ﬂow , simply logical ﬂow. Consider system runs three processes, shown Figure 8.12. single physical control ﬂow processor partitioned three logical ﬂows,one process. vertical line represents portion logical ﬂow forSection 8.2 Processes 713 Figure 8.12 Logical control ﬂows.Processes provide eachprogram illusionthat exclusive use ofthe processor. vertical bar represents portion ofthe logical control ﬂow fora process.Process Process B Process C Time process. example, execution three logical ﬂows interleaved. Process runs while, followed B, runs completion. Process Cthen runs awhile, followed A, runs completion. Finally, C ableto run completion. key point Figure 8.12 processes take turns using processor. process executes portion ﬂow preempted (temporarily suspended) processes take turns. program running thecontext one processes, appears exclusive use proces-sor. evidence contrary precisely measure theelapsed time instruction, would notice CPU appears peri-odically stall execution instructions program.However, time processor stalls, subsequently resumes execution ourprogram without change contents program’s memory locationsor registers. 8.2.2 Concurrent Flows Logical ﬂows take many different forms computer systems. Exception handlers, processes, signal handlers, threads, Java processes examples logicalﬂows. logical ﬂow whose execution overlaps time another ﬂow called aconcurrent ﬂow , two ﬂows said run concurrently . precisely, ﬂows X concurrent respect X beginsafter begins ﬁnishes, begins X begins Xﬁnishes. example, Figure 8.12, processes B run concurrently, doA C. hand, B C run concurrently, lastinstruction B executes ﬁrst instruction C. general phenomenon multiple ﬂows executing concurrently known asconcurrency . notion process taking turns processes also known multitasking . time period process executes portion ﬂow called time slice . Thus, multitasking also referred time slicing .F r example, Figure 8.12, ﬂow Process consists two time slices. Notice idea concurrent ﬂows independent number processor cores computers ﬂows running on. two ﬂows overlapin time, concurrent, even running processor.However, sometimes ﬁnd useful identify proper subset concurrent714 Chapter 8 Exceptional Control Flow ﬂows known parallel ﬂows . two ﬂows running concurrently different processor cores computers, say parallel ﬂows , arerunning parallel , parallel execution . Practice Problem 8.1 Consider three processes following starting ending times: Process Start time End time A0 2 B1 4C3 5 pair processes, indicate whether run concurrently (y) (n): Process pair Concurrent? AB AC BC 8.2.3 Private Address Space process provides program illusion exclusive use system’s address space. machine n-bit addresses, address space set 2npossible addresses, 0, 1 ,..., 2n−1. process provides program private address space . space private sense byte memory associated particular address space cannot general beread written process. Although contents memory associated private address space different general, space general organization.For example, Figure 8.13 shows organization address space x86Linux process. bottom portion address space reserved userprogram, usual text, data, heap, stack segments. Code segments beginat address 0x08048000 32-bit processes, address 0x00400000 64-bit processes. top portion address space reserved kernel. Thispart address space contains code, data, stack kernel useswhen executes instructions behalf process (e.g., applicationprogram executes system call). 8.2.4 User Kernel Modes order operating system kernel provide airtight process abstraction, processor must provide mechanism restricts instructions anapplication execute, well portions address space canaccess.Section 8.2 Processes 715 Figure 8.13 Process address space. 0x08048000 (32) 0x00400000 (64) 0Memory invisible touser code %esp (stack pointer) brk Loaded theexecutable fileUser stack (created run time) Memory-mapped region shared libraries Run-time heap (created malloc ) Read/write segment (.data,.bss ) Read-only segment (.init,.text,.rodata )Kernel virtual memory (code, data, heap, stack) Processors typically provide capability mode bit control register characterizes privileges process currently enjoys. mode bit set, process running kernel mode (sometimes called supervisor mode ). process running kernel mode execute instruction instruction set access memory location system. mode bit set, process running user mode . process user mode allowed execute privileged instructions things halt processor, change mode bit, initiate I/O operation. itallowed directly reference code data kernel area address space.Any attempt results fatal protection fault. User programs must insteadaccess kernel code data indirectly via system call interface. process running application code initially user mode. way process change user mode kernel mode via exception suchas interrupt, fault, trapping system call. exception occurs, andcontrol passes exception handler, processor changes mode usermode kernel mode. handler runs kernel mode. returns theapplication code, processor changes mode kernel mode back usermode. Linux provides clever mechanism, called /proc ﬁlesystem, allows user mode processes access contents kernel data structures. /proc ﬁlesystem exports contents many kernel data structures hierarchy textﬁles read user programs. example, use /proc ﬁlesys- tem ﬁnd general system attributes CPU type ( /proc/cpuinfo ), memory segments used particular process ( /proc/<process id>/maps ).716 Chapter 8 Exceptional Control Flow 2.6 version Linux kernel introduced /sys ﬁlesystem, exports additional low-level information system buses devices. 8.2.5 Context Switches operating system kernel implements multitasking using higher-level form exceptional control ﬂow known context switch . context switch mecha- nism built top lower-level exception mechanism discussed Section 8.1. kernel maintains context process. context state kernel needs restart preempted process. consists valuesof objects general purpose registers, ﬂoating-point registers, theprogram counter, user’s stack, status registers, kernel’s stack, various kerneldata structures page table characterizes address space, process table contains information current process, ﬁle table contains information ﬁles process opened. certain points execution process, kernel decide preempt current process restart previously preempted process. Thisdecision known scheduling , handled code kernel called scheduler . kernel selects new process run, say kernel hasscheduled process. kernel scheduled new process run, preempts current process transfers control new process usinga mechanism called context switch (1) saves context current process, (2) restores saved context previously preempted process, (3) passes control newly restored process. context switch occur kernel executing system call behalf user. system call blocks waiting event occur,then kernel put current process sleep switch another process.For example, read system call requires disk access, kernel opt perform context switch run another process instead waiting datato arrive disk. Another example sleep system call, explicit request put calling process sleep. general, even systemcall block, kernel decide perform context switch rather thanreturn control calling process. context switch also occur result interrupt. example, systems mechanism generating periodic timer interrupts, typicallyevery 1 ms 10 ms. time timer interrupt occurs, kernel decide thatthe current process run long enough switch new process. Figure 8.14 shows example context switching pair processes B. example, initially process running user mode traps tothe kernel executing read system call. trap handler kernel requests DMA transfer disk controller arranges disk interrupt processor disk controller ﬁnished transferring data disk tomemory. disk take relatively long time fetch data (on order tens milliseconds), instead waiting nothing interim, thekernel performs context switch process B. Note switch,Section 8.3 System Call Error Handling 717 Figure 8.14 Anatomy processcontext switch. Process Process B User code Kernel code Kernel codeUser code User codeContex switch Contex switchTime read Disk interrupt Return fromread kernel executing instructions user mode behalf process A. ﬁrst part switch, kernel executing instructions kernel mode behalf process A. point begins executing instructions (still inkernel mode) behalf process B. switch, kernel executinginstructions user mode behalf process B. Process B runs user mode disk sends interrupt signal data transferred disk memory. kernel decidesthat process B run long enough performs context switch process Bto A, returning control process instruction immediately following theread system call. Process continues run next exception occurs, on. Aside Cache pollution exceptional control ﬂow general, hardware cache memories interact well exceptional control ﬂows interrupts context switches. current process interrupted brieﬂy interrupt, thecache cold interrupt handler. handler accesses enough items main memory, cache also cold interrupted process resumes. case, say handler polluted cache. similar phenomenon occurs context switches. process resumes context switch, cache cold application program must warmed again. 8.3 System Call Error Handling Unix system-level functions encounter error, typically return −1 set global integer variable errno indicate went wrong. Program- mers always check errors, unfortunately, many skip error checking bloats code makes harder read. example, howwe might check errors call Linux fork function: 1 ((pid = fork()) < 0) { 2 fprintf(stderr, "fork error: %s\n", strerror(errno)); 3 exit(0); 4 }718 Chapter 8 Exceptional Control Flow Thestrerror function returns text string describes error associated particular value errno . simplify code somewhat deﬁning following error-reporting function : 1void unix_error(char *msg) /* Unix-style error */ 2{ 3 fprintf(stderr, "%s: %s\n", msg, strerror(errno)); 4 exit(0); 5} Given function, call fork reduces four lines two lines: 1 ((pid = fork()) < 0) 2 unix_error("fork error"); simplify code even using error-handling wrappers . given base function foo, deﬁne wrapper function Foo identical arguments, ﬁrst letter name capitalized. wrapper calls thebase function, checks errors, terminates problems. Forexample, error-handling wrapper fork function: 1pid_t Fork(void) 2{ 3 pid_t pid; 4 5 ((pid = fork()) < 0) 6 unix_error("Fork error"); 7 return pid; 8} Given wrapper, call fork shrinks single compact line: 1 pid = Fork(); use error-handling wrappers throughout remainder book. allow us keep code examples concise, without giving mistakenimpression permissible ignore error checking. Note wediscuss system-level functions text, always refer theirlowercase base names, rather uppercase wrapper names. See Appendix discussion Unix error handling error- handling wrappers used throughout book. wrappers deﬁned ﬁlecalled csapp.c , prototypes deﬁned header ﬁle called csapp.h ; available online CS:APP Web site. 8.4 Process Control Unix provides number system calls manipulating processes C pro-grams. section describes important functions gives examples used.Section 8.4 Process Control 719 8.4.1 Obtaining Process IDs process unique positive (nonzero) process ID (PID). getpid function returns PID calling process. getppid function returns PID parent (i.e., process created calling process). #include <sys/types.h> #include <unistd.h> pid_t getpid(void); pid_t getppid(void); Returns: PID either caller parent Thegetpid andgetppid routines return integer value type pid_t , Linux systems deﬁned types.h int. 8.4.2 Creating Terminating Processes programmer’s perspective, think process one three states: .Running. process either executing CPU waiting executed eventually scheduled kernel. .Stopped. execution process suspended scheduled. process stops result receiving SIGSTOP , SIGTSTP , SIGTTIN, orSIGTTOU signal, remains stopped receives SIGCONT signal,at point begin running again. (A signal form software interrupt described detail Section 8.5.) .Terminated. process stopped permanently. process becomes termi- nated one three reasons: (1) receiving signal whose default action isto terminate process, (2) returning main routine, (3) callingtheexit function: #include <stdlib.h> void exit(int status); function return Theexit function terminates process exit status ofstatus . (The way set exit status return integer value main routine.)720 Chapter 8 Exceptional Control Flow Aparent process creates new running child process calling fork function. #include <sys/types.h> #include <unistd.h> pid_t fork(void); Returns: 0 child, PID child parent, −1 error newly created child process almost, quite, identical par- ent. child gets identical (but separate) copy parent’s user-level virtualaddress space, including text, data, bss segments, heap, user stack. Thechild also gets identical copies parent’s open ﬁle descriptors, whichmeans child read write ﬁles open parent whenit called fork . signiﬁcant difference parent newly created child different PIDs. Thefork function interesting (and often confusing) called returns twice : calling process (the parent), newly created child process. parent, fork returns PID child. child, fork returns value 0. Since PID child always nonzero, return value provides unambiguous way tell whether program executing inthe parent child. Figure 8.15 shows simple example parent process uses fork create child process. fork call returns line 8, xhas value 1 parent child. child increments prints copy xin line 10. Similarly, parent decrements prints copy xin line 15. run program Unix system, get following result: unix> ./fork parent: x=0 child : x=2 subtle aspects simple example. .Call once, return twice. Thefork function called parent, returns twice: parent newly created child. fairly straightforward programs create single child. programs multiple instances fork confusing need reasoned carefully. .Concurrent execution. parent child separate processes run concurrently. instructions logical control ﬂows inter-leaved kernel arbitrary way. run program oursystem, parent process completes printf statement ﬁrst, followed child. However, another system reverse might true. general,as programmers never make assumptions interleaving theinstructions different processes.Section 8.4 Process Control 721 code/ecf/fork.c 1#include "csapp.h" 2 3int main() 4{ 5 pid_t pid; 6 n tx=1 ; 78 pid = Fork(); 9 (pid == 0) { /* Child */ 10 printf("child : x=%d\n", ++x); 11 exit(0); 12 } 13 14 /* Parent */ 15 printf("parent: x=%d\n", --x); 16 exit(0); 17 } code/ecf/fork.c Figure 8.15 Using fork create new process. .Duplicate separate address spaces. could halt parent child immediately fork function returned process, would see address space process identical. processhas user stack, local variable values, heap, thesame global variable values, code. Thus, example program,local variable xhas value 1 parent child fork function returns line 8. However, since parent child separateprocesses, private address spaces. subsequentchanges parent child makes xare private reﬂected memory process. variable xhas different values parent child call respective printf statements. .Shared ﬁles. run example program, notice parent child print output screen. reason child inheritsall parent’s open ﬁles. parent calls fork , stdout ﬁle open directed screen. child inherits ﬁle thus outputis also directed screen. ﬁrst learning fork function, often helpful sketch process graph , horizontal arrow corresponds process executes instructions left right, vertical arrow corresponds execution fork function. example, many lines output would program Figure 8.16(a) generate? Figure 8.16(b) shows corresponding process graph. parent722 Chapter 8 Exceptional Control Flow (a) Calls fork 1#include "csapp.h" 2 3int main() 4{ 5 Fork(); 6 printf("hello\n"); 7 exit(0); 8}(b) Prints two output lines hello hello forkfork (c) Calls fork twice 1#include "csapp.h" 2 3int main() 4{ 5 Fork(); 6 Fork(); 7 printf("hello\n"); 8 exit(0); 9}(d) Prints four output lines hello hello forkforkforkforkhello hello (e) Calls fork three times 1#include "csapp.h" 2 3int main() 4{ 5 Fork(); 6 Fork(); 7 Fork(); 8 printf("hello\n"); 9 exit(0); 10 }(f) Prints eight output lines hello hello forkforkforkforkforkforkhello hellohellohellohellohello Figure 8.16 Examples fork programs process graphs. creates child executes ﬁrst (and only) fork program. calls printf once, program prints two output lines. call fork twice, shown Figure 8.16(c)? see Figure 8.16(d), parent calls fork create child, parent child call fork , results two processes. Thus, four processes, calls printf , program generates four output lines.Section 8.4 Process Control 723 Continuing line thought, would happen call fork three times, Figure 8.16(e)? see process graph Fig-ure 8.16(f), total eight processes. process calls printf ,s program produces eight output lines. Practice Problem 8.2 Consider following program: code/ecf/forkprob0.c 1#include "csapp.h" 2 3int main() 4{ 5 n tx=1 ; 6 7 (Fork() == 0) 8 printf("printf1: x=%d\n", ++x); 9 printf("printf2: x=%d\n", --x); 10 exit(0); 11 } code/ecf/forkprob0.c A. output child process? B. output parent process? 8.4.3 Reaping Child Processes process terminates reason, kernel remove system immediately. Instead, process kept around terminated stateuntil reaped parent. parent reaps terminated child, kernel passes child’s exit status parent, discards terminated process, point ceases exist. terminated process yet beenreaped called zombie . Aside terminated children called zombies? folklore, zombie living corpse, entity half alive half dead. zombie process similar sense already terminated, kernel maintains state reaped parent. parent process terminates without reaping zombie children, kernel arranges init process reap them. init process PID 1 created kernel system initialization. Long-running programs724 Chapter 8 Exceptional Control Flow shells servers always reap zombie children. Even though zombies running, still consume system memory resources. process waits children terminate stop calling waitpid function. #include <sys/types.h> #include <sys/wait.h> pid_t waitpid(pid_t pid, int *status, int options); Returns: PID child OK, 0 (if WNOHANG) −1 error Thewaitpid function complicated. default (when options = 0 ),waitpid suspends execution calling process child process wait set terminates. process wait set already terminated time thecall, waitpid returns immediately. either case, waitpid returns PID terminated child caused waitpid return, terminated child removed system. Determining Members Wait Set members wait set determined pidargument: .Ifp d>0 , wait set singleton child process whose process ID equal pid. .Ifp d=- 1 , wait set consists parent’s child processes. Thewaitpid function also supports kinds wait sets, involving Unix process groups, discuss. Modifying Default Behavior default behavior modiﬁed setting options various combinations WNOHANG WUNTRACED constants: .WNOHANG: Return immediately (with return value 0) none thechild processes wait set terminated yet. default behavior sus-pends calling process child terminates. option useful thosecases want continue useful work waiting childto terminate. .WUNTRACED: Suspend execution calling process process inthe wait set becomes either terminated stopped. Return PID theterminated stopped child caused return. default behaviorreturns terminated children. option useful want tocheck terminated stopped children. .WNOHANG |WUNTRACED: Return immediately, return value 0, none children wait set stopped terminated, return value equal PID one stopped terminated children.Section 8.4 Process Control 725 Checking Exit Status Reaped Child status argument non-NULL, waitpid encodes status information child caused return status argument. wait.h include ﬁle deﬁnes several macros interpreting status argument: .WIFEXITED( status ): Returns true child terminated normally, via call exit return. .WEXITSTATUS( status ): Returns exit status normally terminated child. status deﬁned WIFEXITED returned true. .WIFSIGNALED( status ): Returns true child process terminated be- cause signal caught. (Signals explained Section 8.5.) .WTERMSIG( status ): Returns number signal caused child process terminate. status deﬁned WIFSIGNALED( status ) returned true. .WIFSTOPPED( status ): Returns true child caused return currently stopped. .WSTOPSIG( status ): Returns number signal caused child stop. status deﬁned WIFSTOPPED( status ) returned true. Error Conditions calling process children, waitpid returns −1 sets errno ECHILD. waitpid function interrupted signal, returns −1 sets errno EINTR. Aside Constants associated Unix functions Constants WNOHANG WUNTRACED deﬁned system header ﬁles. example, WNOHANG WUNTRACED deﬁned (indirectly) wait.h header ﬁle: /* Bits third argument ‘waitpid’. */ #define WNOHANG 1 /* Don’t block waiting. */ #define WUNTRACED 2 /* Report status stopped children. */ order use constants, must include wait.h header ﬁle code: #include <sys/wait.h> Themanpage Unix function lists header ﬁles include whenever use function code. Also, order check return codes ECHILD EINTR, must include errno.h . simplify code examples, include single header ﬁle called csapp.h includes header ﬁles functions used book. csapp.h header ﬁle available online CS:APP Web site.726 Chapter 8 Exceptional Control Flow Practice Problem 8.3 List possible output sequences following program: code/ecf/waitprob0.c 1int main() 2{ 3 (Fork() == 0) { 4 printf("a"); 5 } 6 else { 7 printf("b"); 8 waitpid(-1, NULL, 0); 9 } 10 printf("c"); 11 exit(0); 12 } code/ecf/waitprob0.c Thewait Function Thewait function simpler version waitpid : #include <sys/types.h> #include <sys/wait.h> pid_t wait(int *status); Returns: PID child OK −1 error Calling wait(&status) equivalent calling waitpid(-1, &status, 0) . Examples Using waitpid waitpid function somewhat complicated, helpful look examples. Figure 8.17 shows program uses waitpid wait, particular order, Nchildren terminate. line 11, parent creates Nchildren, line 12, child exits unique exit status. moving on, make sure understand whyline 12 executed children, parent. line 15, parent waits children terminate using waitpid test condition loop. ﬁrst argument −1, call waitpid blocks arbitrary child terminated. child terminates, call waitpid returns nonzero PID child. Line 16 checks exit status child. child terminated normally, case calling theexit function, parent extracts exit status prints stdout .Section 8.4 Process Control 727 code/ecf/waitpid1.c 1#include "csapp.h" 2#define N 2 3 4int main() 5{ 6 int status, i; 7 pid_t pid; 89 /* Parent creates N children */ 10 f r( i=0 ;i<N ; i++) 11 ((pid = Fork()) == 0) /* Child */ 12 exit(100+i); 13 14 /* Parent reaps N children particular order */ 15 ((pid = waitpid(-1, &status, 0)) > 0) { 16 (WIFEXITED(status)) 17 printf("child %d terminated normally exit status=%d\n", 18 pid, WEXITSTATUS(status)); 19 else 20 printf("child %d terminated abnormally\n", pid); 21 } 2223 /* normal termination children */ 24 (errno != ECHILD) 25 unix_error("waitpid error"); 2627 exit(0); 28 } code/ecf/waitpid1.c Figure 8.17 Using waitpid function reap zombie children particular order. children reaped, next call waitpid returns −1 sets errno ECHILD. Line 24 checks waitpid function terminated normally, prints error message otherwise. run program onour Unix system, produces following output: unix> ./waitpid1 child 22966 terminated normally exit status=100child 22967 terminated normally exit status=101 Notice program reaps children particular order. order reaped property speciﬁc computer system. another728 Chapter 8 Exceptional Control Flow code/ecf/waitpid2.c 1#include "csapp.h" 2#define N 2 3 4int main() 5{ 6 int status, i; 7 pid_t pid[N], retpid; 89 /* Parent creates N children */ 10 f r( i=0 ;i<N ; i++) 11 ((pid[i] = Fork()) == 0) /* Child */ 12 exit(100+i); 13 14 /* Parent reaps N children order */ 15 i=0 ; 16 ((retpid = waitpid(pid[i++], &status, 0)) > 0) { 17 (WIFEXITED(status)) 18 printf("child %d terminated normally exit status=%d\n", 19 retpid, WEXITSTATUS(status)); 20 else 21 printf("child %d terminated abnormally\n", retpid); 22 } 2324 /* normal termination children */ 25 (errno != ECHILD) 26 unix_error("waitpid error"); 2728 exit(0); 29 } code/ecf/waitpid2.c Figure 8.18 Using waitpid reap zombie children order created. system, even another execution system, two children might reaped opposite order. example nondeterministic behavior make reasoning concurrency difﬁcult. Either twopossible outcomes equally correct, programmer may never assume one outcome always occur, matter unlikely outcomeappears be. correct assumption possible outcome equallylikely. Figure 8.18 shows simple change eliminates nondeterminism output order reaping children order created parent. line 11, parent stores PIDs children order, waits child order calling waitpid appropriate PID ﬁrst argument.Section 8.4 Process Control 729 Practice Problem 8.4 Consider following program: code/ecf/waitprob1.c 1int main() 2{ 3 int status; 4 pid_t pid; 5 6 printf("Hello\n"); 7 pid = Fork(); 8 printf("%d\n", !pid); 9 (pid != 0) { 10 (waitpid(-1, &status, 0) > 0) { 11 (WIFEXITED(status) != 0) 12 printf("%d\n", WEXITSTATUS(status)); 13 } 14 } 15 printf("Bye\n"); 16 exit(2); 17 } code/ecf/waitprob1.c A. many output lines program generate? B. one possible ordering output lines? 8.4.4 Putting Processes Sleep Thesleep function suspends process speciﬁed period time. #include <unistd.h> unsigned int sleep(unsigned int secs); Returns: seconds left sleep Sleep returns zero requested amount time elapsed, number seconds still left sleep otherwise. latter case possible sleep function returns prematurely interrupted signal . discuss signals detail Section 8.5.730 Chapter 8 Exceptional Control Flow Another function ﬁnd useful pause function, puts calling function sleep signal received process. #include <unistd.h> int pause(void); Always returns −1 Practice Problem 8.5 Write wrapper function sleep , called snooze , following interface: unsigned int snooze(unsigned int secs); Thesnooze function behaves exactly sleep function, except prints message describing long process actually slept: Slept 4 5 secs. 8.4.5 Loading Running Programs Theexecve function loads runs new program context current process. #include <unistd.h> int execve(const char *filename, const char *argv[], const char *envp[]); return OK, returns −1 error Theexecve function loads runs executable object ﬁle filename argument list argv environment variable list envp .Execve returns calling program error able ﬁnd filename . unlike fork , called returns twice, execve called never returns. argument list represented data structure shown Figure 8.19. Theargv variable points null-terminated array pointers, Figure 8.19 Organization anargument list.…argv[]argv[] argv[0] "ls" "-lt" "/user/include"argv argv[1] argv[argc /H110021] NULLSection 8.4 Process Control 731 Figure 8.20 Organization anenvironment variablelist.…envp[]envp[] envp[0] "PWD /H11005/usr/droh" "PRINTER /H11005iron" "USER /H11005droh"envp envp[1] envp[n /H110021] NULL points argument string. convention, argv[0] name executable object ﬁle. list environment variables represented similar datastructure, shown Figure 8.20. envp variable points null-terminated array pointers environment variable strings, name-value pair form “ NAME=VALUE ”. execve loads filename , calls startup code described Section 7.9. startup code sets stack passes control main routine thenew program, prototype form int main(int argc, char **argv, char **envp); equivalently, int main(int argc, char *argv[], char *envp[]); main begins executing 32-bit Linux process, user stack organization shown Figure 8.21. Let’s work way bottom thestack (the highest address) top (the lowest address). First argument Figure 8.21 Typical organization ofthe user stack anew program starts. 0xbffffa7c0xbfffffff Bottom stack Top stackNull-terminated environment variable strings Null-terminated command-line arg strings Stack frame mainUnused envp[n] /H11005/H11005NULL envp[n /H110021] envp[0] argv[argc] /H11005/H11005NULL argv[argc /H110021] argv[0] (Dynamic linker variables) envpargvenviron argc……732 Chapter 8 Exceptional Control Flow environment strings, stored contiguously stack, one without gaps. followed stack null-terminated array pointers, points environment variablestring stack. global variable environ points ﬁrst pointers, envp[0] . environment array followed immediately null-terminated argv[] array, element pointing argument string stack. top stack three arguments main routine: (1) envp , points envp[] array, (2) argv , points argv[] array, (3) argc , gives number non-null pointers argv[] array. Unix provides several functions manipulating environment array: #include <stdlib.h> char *getenv(const char *name); Returns: ptr name exists, NULL match getenv function searches environment array string “name=value ”. found, returns pointer value , otherwise returns NULL . #include <stdlib.h> int setenv(const char *name, const char *newvalue, int overwrite); Returns: 0 success, −1 error void unsetenv(const char *name); Returns: nothing environment array contains string form “ name=oldvalue ”, unsetenv deletes setenv replaces oldvalue newvalue , overwrite nonzero. name exist, setenv adds “ name=newvalue ” array. Aside Programs vs. processes good place pause make sure understand distinction program process. program collection code data; programs exist object modules disk segments address space. process speciﬁc instance program execution; program always runs context process. Understanding distinction important want tounderstand fork andexecve functions. fork function runs program new child process duplicate parent. execve function loads runs new program theSection 8.4 Process Control 733 context current process. overwrites address space current process, create new process. new program still PID, inherits ﬁle descriptors open time call execve function. Practice Problem 8.6 Write program called myecho prints command line arguments envi- ronment variables. example: unix> ./myecho arg1 arg2 Command line arguments: argv[ 0]: myechoargv[ 1]: arg1argv[ 2]: arg2 Environment variables: envp[ 0]: PWD=/usr0/droh/ics/code/ecf envp[ 1]: TERM=emacs ... envp[25]: USER=droh envp[26]: SHELL=/usr/local/bin/tcsh envp[27]: HOME=/usr0/droh 8.4.6 Using fork andexecve Run Programs Programs Unix shells Web servers (Chapter 11) make heavy use thefork andexecve functions. shell interactive application-level program runs programs behalf user. original shell sh program, followed variants csh,tcsh ,ksh, bash .A shell performs sequence read/evaluate steps, terminates. read step reads command line user. evaluate step parses commandline runs programs behalf user. Figure 8.22 shows main routine simple shell. shell prints command-line prompt, waits user type command line stdin , evaluates command line. Figure 8.23 shows code evaluates command line. ﬁrst task call parseline function (Figure 8.24), parses space-separated command-line arguments builds argv vector eventually passed toexecve . ﬁrst argument assumed either name built-in shell command interpreted immediately, executable object ﬁle beloaded run context new child process. last argument “&” character, parseline returns 1, indicating program executed background (the shell wait734 Chapter 8 Exceptional Control Flow code/ecf/shellex.c 1#include "csapp.h" 2#define MAXARGS 128 3 4/* Function prototypes */ 5void eval(char *cmdline); 6int parseline(char *buf, char **argv); 7int builtin_command(char **argv); 89 int main() 10 { 11 char cmdline[MAXLINE]; /* Command line */ 12 13 (1) { 14 /* Read */ 15 printf("> "); 16 Fgets(cmdline, MAXLINE, stdin); 17 (feof(stdin)) 18 exit(0); 19 20 /* Evaluate */ 21 eval(cmdline); 22 } 23 } code/ecf/shellex.c Figure 8.22 main routine simple shell program. complete). Otherwise returns 0, indicating program run foreground (the shell waits complete). parsing command line, eval function calls builtin_command function, checks whether ﬁrst command line argument built-in shellcommand. so, interprets command immediately returns 1. Otherwise,it returns 0. simple shell one built-in command, quit command, terminates shell. Real shells numerous commands, pwd, jobs , fg. Ifbuiltin_command returns 0, shell creates child process executes requested program inside child. user asked theprogram run background, shell returns top loop waits next command line. Otherwise shell uses waitpid function wait job terminate. job terminates, shell goes thenext iteration. Notice simple shell ﬂawed reap background children. Correcting ﬂaw requires use signals, wedescribe next section.Section 8.4 Process Control 735 code/ecf/shellex.c 1/* eval - Evaluate command line */ 2void eval(char *cmdline) 3{ 4 char *argv[MAXARGS]; /* Argument list execve() */ 5 char buf[MAXLINE]; /* Holds modified command line */ 6 int bg; /* job run bg fg? */ 7 pid_t pid; /* Process id */ 8 9 strcpy(buf, cmdline); 10 bg = parseline(buf, argv); 11 (argv[0] == NULL) 12 return; /* Ignore empty lines */ 13 14 (!builtin_command(argv)) { 15 ((pid = Fork()) == 0) { /* Child runs user job */ 16 (execve(argv[0], argv, environ) < 0) { 17 printf("%s: Command found.\n", argv[0]); 18 exit(0); 19 } 20 } 21 22 /* Parent waits foreground job terminate */ 23 (!bg) { 24 int status; 25 (waitpid(pid, &status, 0) < 0) 26 unix_error("waitfg: waitpid error"); 27 } 28 else 29 printf("%d %s", pid, cmdline); 30 } 31 return; 32 } 3334 /* first arg builtin command, run return true */ 35 int builtin_command(char **argv) 36 { 37 (!strcmp(argv[0], "quit")) /* quit command */ 38 exit(0); 39 (!strcmp(argv[0], "&")) /* Ignore singleton & */ 40 return 1; 41 return 0; /* builtin command */ 42 } code/ecf/shellex.c Figure 8.23 eval : Evaluates shell command line.736 Chapter 8 Exceptional Control Flow code/ecf/shellex.c 1/* parseline - Parse command line build argv array */ 2int parseline(char *buf, char **argv) 3{ 4 char *delim; /* Points first space delimiter */ 5 int argc; /* Number args */ 6 int bg; /* Background job? */ 7 8 buf[strlen(buf)-1 ]=’’ ; /* Replace trailing ’\n’ space */ 9 (*buf && (*buf == ’ ’)) /* Ignore leading spaces */ 10 buf++; 11 12 /* Build argv list */ 13 argc = 0; 14 ((delim = strchr(buf, ’ ’))) { 15 argv[argc++] = buf; 16 *delim = ’\0’; 17 buf = delim + 1; 18 (*buf && (*buf == ’ ’)) /* Ignore spaces */ 19 buf++; 20 } 21 argv[argc] = NULL; 22 23 (argc == 0) /* Ignore blank line */ 24 return 1; 25 26 /* job run background? */ 27 ((bg = (*argv[argc-1] == ’&’)) != 0) 28 argv[--argc] = NULL; 2930 return bg; 31 } code/ecf/shellex.c Figure 8.24 parseline : Parses line input shell. 8.5 Signals point study exceptional control ﬂow, seen hardware software cooperate provide fundamental low-level exception mecha- nism. also seen operating system uses exceptions support aform exceptional control ﬂow known process context switch. sec-tion, study higher-level software form exceptional control ﬂow, knownas Unix signal , allows processes kernel interrupt processes.Section 8.5 Signals 737 Number Name Default action Corresponding event 1 SIGHUP Terminate Terminal line hangup 2 SIGINT Terminate Interrupt keyboard 3 SIGQUIT Terminate Quit keyboard 4 SIGILL Terminate Illegal instruction5 SIGTRAP Terminate dump core (1) Trace trap6 SIGABRT Terminate dump core (1) Abort signal abort function 7 SIGBUS Terminate Bus error 8 SIGFPE Terminate dump core (1) Floating point exception 9 SIGKILL Terminate (2) Kill program 10 SIGUSR1 Terminate User-deﬁned signal 1 11 SIGSEGV Terminate dump core (1) Invalid memory reference (seg fault) 12 SIGUSR2 Terminate User-deﬁned signal 213 SIGPIPE Terminate Wrote pipe reader 14 SIGALRM Terminate Timer signal alarm function 15 SIGTERM Terminate Software termination signal 16 SIGSTKFLT Terminate Stack fault coprocessor17 SIGCHLD Ignore child process stopped terminated 18 SIGCONT Ignore Continue process stopped 19 SIGSTOP Stop next SIGCONT (2) Stop signal terminal20 SIGTSTP Stop next SIGCONT Stop signal terminal 21 SIGTTIN Stop next SIGCONT Background process read terminal 22 SIGTTOU Stop next SIGCONT Background process wrote terminal23 SIGURG Ignore Urgent condition socket 24 SIGXCPU Terminate CPU time limit exceeded 25 SIGXFSZ Terminate File size limit exceeded26 SIGVTALRM Terminate Virtual timer expired 27 SIGPROF Terminate Proﬁling timer expired 28 SIGWINCH Ignore Window size changed29 SIGIO Terminate I/O possible descriptor30 SIGPWR Terminate Power failure Figure 8.25 Linux signals. Notes: (1) Years ago, main memory implemented technology known core memory . “Dumping core” historical term means writing image code data memory segments disk. (2) signal neither caught ignored. Asignal small message notiﬁes process event type occurred system. example, Figure 8.25 shows 30 different types signals supported Linux systems. Typing “ man 7 signal ” shell command line gives list. signal type corresponds kind system event. Low-level hard- ware exceptions processed kernel’s exception handlers would not738 Chapter 8 Exceptional Control Flow normally visible user processes. Signals provide mechanism exposing occurrence exceptions user processes. example, process at-tempts divide zero, kernel sends SIGFPE signal (number 8).If process executes illegal instruction, kernel sends SIGILL signal(number 4). process makes illegal memory reference, kernel sends ita SIGSEGV signal (number 11). signals correspond higher-level soft-ware events kernel user processes. example, type actrl-c (i.e., press ctrl key ckey time) process running foreground, kernel sends SIGINT (number 2) theforeground process. process forcibly terminate another process sendingit SIGKILL signal (number 9). child process terminates stops, thekernel sends SIGCHLD signal (number 17) parent. 8.5.1 Signal Terminology transfer signal destination process occurs two distinct steps: .Sending signal. kernel sends (delivers ) signal destination process updating state context destination process. signalis delivered one two reasons: (1) kernel detected systemevent divide-by-zero error termination child process.(2) process invoked kill function (discussed next section) explicitly request kernel send signal destination process. Aprocess send signal itself. .Receiving signal. destination process receives signal forced kernel react way delivery signal. process caneither ignore signal, terminate, catch signal executing user-level function called signal handler . Figure 8.26 shows basic idea handler catching signal. signal sent yet received called pending signal .A point time, one pending signal particular type. process pending signal type k, subsequent signals type ksent process notqueued; simply discarded. process selectively block receipt certain signals. signal blocked, delivered, resulting pending signal received process unblocks thesignal. Figure 8.26 Signal handling. Receipt signal triggers controltransfer signal handler.After ﬁnishes processing, handler returns control interrupted program.(2) Control passes signal handler (3) Signal handler run (4) Signal handler returns next instruction(1) Signal received process Icurr InextSection 8.5 Signals 739 pending signal received once. process, kernel main- tains set pending signals pending bit vector, set blocked signals blocked bit vector. kernel sets bit kinpending whenever sig- nal type kis delivered clears bit kinpending whenever signal type k received. 8.5.2 Sending Signals Unix systems provide number mechanisms sending signals processes. mechanisms rely notion process group . Process Groups Every process belongs exactly one process group , identiﬁed positive integer process group ID .T h e getpgrp function returns process group ID current process. #include <unistd.h> pid_t getpgrp(void); Returns: process group ID calling process default, child process belongs process group parent. process change process group another process using thesetpgid function: #include <unistd.h> int setpgid(pid_t pid, pid_t pgid); Returns: 0 success, −1 error Thesetpgid function changes process group process pidtopgid .I fpidis zero, PID current process used. pgid zero, PID process speciﬁed pidis used process group ID. example, process 15213 calling process, setpgid(0, 0); creates new process group whose process group ID 15213, adds process15213 new group. Sending Signals /bin/kill Program The/bin/kill program sends arbitrary signal another process. example, command unix> /bin/kill -9 15213740 Chapter 8 Exceptional Control Flow Figure 8.27 Foreground back-ground process groups. Back- ground job #1Fore- ground job Background process group 32 Foreground process group 20Shell Child ChildBack- ground job #2 Background process group 40pid/H1100520 pgid /H1100520pid/H1100510 pgid /H1100510 pid/H1100521 pgid /H1100520pid/H1100522 pgid /H1100520pid/H1100532 pgid /H1100532pid/H1100540 pgid /H1100540 sends signal 9 (SIGKILL) process 15213. negative PID causes signal sent every process process group PID. example, command unix> /bin/kill -9 -15213 sends SIGKILL signal every process process group 15213. Note use complete path /bin/kill Unix shells built-in kill command. Sending Signals Keyboard Unix shells use abstraction jobto represent processes created result evaluating single command line. point time, atmost one foreground job zero background jobs. example, typing unix> ls | sort creates foreground job consisting two processes connected Unix pipe: one running lsprogram, running sort program. shell creates separate process group job. Typically, process group ID taken one parent processes job. example,Figure 8.27 shows shell one foreground job two background jobs. Theparent process foreground job PID 20 process group ID of20. parent process created two children, also membersof process group 20. Typing ctrl-c keyboard causes SIGINT signal sent shell. shell catches signal (see Section 8.5.3) sends SIGINT every process foreground process group. default case, result isSection 8.5 Signals 741 terminate foreground job. Similarly, typing crtl-z sends SIGTSTP signal shell, catches sends SIGTSTP signal every process theforeground process group. default case, result stop (suspend) theforeground job. Sending Signals kill Function Processes send signals processes (including themselves) calling thekill function. #include <sys/types.h> #include <signal.h> int kill(pid_t pid, int sig); Returns: 0 OK, −1 error Ifpidis greater zero, kill function sends signal number sigto process pid.I fpidis less zero, kill sends signal sigto every process process group abs( pid). Figure 8.28 shows example parent uses kill function send SIGKILL signal child. code/ecf/kill.c 1#include "csapp.h" 2 3int main() 4{ 5 pid_t pid; 6 7 /* Child sleeps SIGKILL signal received, dies */ 8 ((pid = Fork()) == 0) { 9 Pause(); /* Wait signal arrive */ 10 printf("control never reach here!\n"); 11 exit(0); 12 } 13 14 /* Parent sends SIGKILL signal child */ 15 Kill(pid, SIGKILL); 16 exit(0); 17 } code/ecf/kill.c Figure 8.28 Using kill function send signal child.742 Chapter 8 Exceptional Control Flow Sending Signals alarm Function process send SIGALRM signals calling alarm function. #include <unistd.h> unsigned int alarm(unsigned int secs); Returns: remaining secs previous alarm, 0 previous alarm Thealarm function arranges kernel send SIGALRM signal calling process secs seconds. secs zero, new alarm scheduled. event, call alarm cancels pending alarms, returns number seconds remaining pending alarm due delivered (had notthis call alarm canceled it), 0 pending alarms. Figure 8.29 shows program called alarm arranges interrupted SIGALRM signal every second ﬁve seconds. sixth SIGALRMis delivered terminates. run program Figure 8.29, get thefollowing output: “BEEP” every second ﬁve seconds, followed “BOOM”when program terminates. unix> ./alarm BEEP BEEPBEEPBEEP BEEPBOOM! Notice program Figure 8.29 uses signal function install signal handler function ( handler ) called asynchronously, interrupting inﬁnite loop main , whenever process receives SIGALRM signal. handler function returns, control passes back main , picks interrupted arrival signal. Installing using signalhandlers quite subtle, topic next sections. 8.5.3 Receiving Signals kernel returning exception handler ready pass control process p, checks set unblocked pending signals ( pending & ~blocked ) process p. set empty (the usual case), kernel passes control next instruction ( Inext) logical control ﬂow p. However, set nonempty, kernel chooses signal kin set (typically smallest k) forces ptoreceive signal k. receipt signal triggers action process. process completes action, control passes back next instruction ( Inext) logical control ﬂow p. signal type predeﬁned default action , one following: .The process terminates. .The process terminates dumps core.Section 8.5 Signals 743 code/ecf/alarm.c 1#include "csapp.h" 2 3void handler(int sig) 4{ 5 static int beeps = 0; 67 printf("BEEP\n"); 8 (++beeps < 5) 9 Alarm(1); /* Next SIGALRM delivered 1 second */ 10 else { 11 printf("BOOM!\n"); 12 exit(0); 13 } 14 } 15 16 int main() 17 { 18 Signal(SIGALRM, handler); /* Install SIGALRM handler */ 19 Alarm(1); /* Next SIGALRM delivered 1s */ 20 21 (1) { 22 ;/* Signal handler returns control time */ 23 } 24 exit(0); 25 } code/ecf/alarm.c Figure 8.29 Using alarm function schedule periodic events. .The process stops restarted SIGCONT signal. .The process ignores signal. Figure 8.25 shows default actions associated type signal. ex- ample, default action receipt SIGKILL terminate receivingprocess. hand, default action receipt SIGCHLD toignore signal. process modify default action associated signalby using signal function. exceptions SIGSTOP SIGKILL, whose default actions cannot changed. #include <signal.h> typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); Returns: ptr previous handler OK, SIG_ERR error (does set errno)744 Chapter 8 Exceptional Control Flow Thesignal function change action associated signal signum one three ways: .Ifhandler SIG_IGN, signals type signum ignored. .Ifhandler SIG_DFL, action signals type signum reverts default action. .Otherwise, handler address user-deﬁned function, called signal handler , called whenever process receives signal type signum . Changing default action passing address handler thesignal function known installing handler . invocation handler called catching signal . execution handler referred handling signal . process catches signal type k, handler installed signal kis invoked single integer argument set k. argument allows handler function catch different types signals. handler executes return statement, control (usually) passes back instruction control ﬂow process interrupted thereceipt signal. say “usually” systems, interrupted systemcalls return immediately error. Figure 8.30 shows program catches SIGINT signal sent shell whenever user types ctrl-c keyboard. default action SIGINT immediately terminate process. example, modify default behavior catch signal, print message, terminate process. handler function deﬁned lines 3–7. main routine installs handler lines 12– 13, goes sleep signal received (line 15).When SIGINT signal received, handler runs, prints message (line 5),and terminates process (line 6). Signal handlers yet another example concurrency computer system. execution signal handler interrupts execution main C routine,akin way low-level exception handler interrupts control ﬂow thecurrent application program. Since logical control ﬂow signal handleroverlaps logical control ﬂow main routine, signal handler themain routine run concurrently. Practice Problem 8.7 Write program, called snooze , takes single command line argument, calls thesnooze function Problem 8.5 argument, terminates. Write program user interrupt snooze function typing ctrl-c keyboard. example: unix> ./snooze 5 Slept 3 5 secs. User hits crtl-c 3 seconds unix>Section 8.5 Signals 745 code/ecf/sigint1.c 1#include "csapp.h" 2 3void handler(int sig) /* SIGINT handler */ 4{ 5 printf("Caught SIGINT\n"); 6 exit(0); 7} 8 9int main() 10 { 11 /* Install SIGINT handler */ 12 (signal(SIGINT, handler) == SIG_ERR) 13 unix_error("signal error"); 1415 pause(); /* Wait receipt signal */ 16 17 exit(0); 18 } code/ecf/sigint1.c Figure 8.30 program uses signal handler catch SIGINT signal. 8.5.4 Signal Handling Issues Signal handling straightforward programs catch single signal terminate. However, subtle issues arise program catches multiple signals. .Pending signals blocked. Unix signal handlers typically block pending signals type currently processed handler. example,suppose process caught SIGINT signal currently running itsSIGINT handler. another SIGINT signal sent process, theSIGINT become pending, received handlerreturns. .Pending signals queued. one pending signal particular type. Thus, two signals type kare sent destination process signal kis blocked destination process currently executing handler signal k, second signal simply discarded; queued. key idea existence pending signal merelyindicates least one signal arrived. .System calls interrupted. System calls read ,wait , accept potentially block process long period time called slow system calls . systems, slow system calls interrupted handler catches signal resume signal handler returns, butinstead return immediately user error condition errno set EINTR.746 Chapter 8 Exceptional Control Flow Let’s look closely subtleties signal handling, using simple application similar nature real programs shells Webservers. basic structure parent process creates children runindependently terminate. parent must reap childrento avoid leaving zombies system. also want parent free doother work children running. decide reap children witha SIGCHLD handler, instead explicitly waiting children terminate.(Recall kernel sends SIGCHLD signal parent whenever one ofits children terminates stops.) Figure 8.31 shows ﬁrst attempt. parent installs SIGCHLD handler, creates three children, runs 1 second ter-minates. meantime, parent waits line input terminaland processes it. processing modeled inﬁnite loop. eachchild terminates, kernel notiﬁes parent sending SIGCHLD signal. parent catches SIGCHLD, reaps one child, additional cleanupwork (modeled sleep(2) statement), returns. Thesignal1 program Figure 8.31 seems fairly straightforward. run Linux system, however, get following output: linux> ./signal1 Hello child 10320 Hello child 10321Hello child 10322 Handler reaped child 10320 Handler reaped child 10322 <cr>Parent processing input output, note although three SIGCHLD signals sent parent, two signals received, thus parent reaped two children. suspend parent process, see that, indeed, child process10321 never reaped remains zombie (indicated string “ defunct ” output pscommand): <ctrl-z> Suspended linux> ps PID TTY STAT TIME COMMAND ... 10319 p5 0:03 signal1 10321 p5 Z 0:00 signal1 <defunct>10323 p5 R 0:00 ps went wrong? problem code failed account facts signals block signals queued. Here’s happened: ﬁrstsignal received caught parent. handler still processing ﬁrst signal, second signal delivered added set pending signals. However, since SIGCHLD signals blocked SIGCHLD handler,Section 8.5 Signals 747 code/ecf/signal1.c 1#include "csapp.h" 2 3void handler1(int sig) 4{ 5 pid_t pid; 67 ((pid = waitpid(-1, NULL, 0)) < 0) 8 unix_error("waitpid error"); 9 printf("Handler reaped child %d\n", (int)pid); 10 Sleep(2); 11 return; 12 } 1314 int main() 15 { 16 int i, n; 17 char buf[MAXBUF]; 1819 (signal(SIGCHLD, handler1) == SIG_ERR) 20 unix_error("signal error"); 2122 /* Parent creates children */ 23 f r( i=0 ;i<3 ; i++) { 24 (Fork() == 0) { 25 printf("Hello child %d\n", (int)getpid()); 26 Sleep(1); 27 exit(0); 28 } 29 } 30 31 /* Parent waits terminal input processes */ 32 ((n = read(STDIN_FILENO, buf, sizeof(buf))) < 0) 33 unix_error("read"); 3435 printf("Parent processing input\n"); 36 (1) 37 ; 38 39 exit(0); 40 } code/ecf/signal1.c Figure 8.31 signal1 :This program ﬂawed fails deal facts signals block, signals queued, system calls interrupted.748 Chapter 8 Exceptional Control Flow second signal received. Shortly thereafter, handler still processing ﬁrst signal, third signal arrives. Since already pendingSIGCHLD, third SIGCHLD signal discarded. Sometime later, thehandler returned, kernel notices pending SIGCHLD signaland forces parent receive signal. parent catches signal andexecutes handler second time. handler ﬁnishes processing thesecond signal, pending SIGCHLD signals, neverwill be, knowledge third SIGCHLD lost. crucial lesson signals cannot used count occurrence events otherprocesses. ﬁx problem, must recall existence pending signal implies least one signal delivered since last time processreceived signal type. must modify SIGCHLD handler reapas many zombie children possible time invoked. Figure 8.32 shows themodiﬁed SIGCHLD handler. run signal2 Linux system, correctly reaps zombie children: linux> ./signal2 Hello child 10378Hello child 10379 Hello child 10380 Handler reaped child 10379 Handler reaped child 10378Handler reaped child 10380<cr>Parent processing input However, ﬁnished yet. run signal2 program older version Solaris operating system, correctly reaps zombiechildren. However, blocked read system call returns prematurely error, able type input keyboard: solaris> ./signal2 Hello child 18906 Hello child 18907 Hello child 18908Handler reaped child 18906 Handler reaped child 18908 Handler reaped child 18907 read: Interrupted system call went wrong? problem arises particular Solaris system, slow system calls read restarted automatically interrupted delivery signal. Instead, return prematurely thecalling application error condition, unlike Linux systems, restartinterrupted system calls automatically. order write portable signal handling code, must allow pos- sibility system calls return prematurely restart manuallySection 8.5 Signals 749 code/ecf/signal2.c 1#include "csapp.h" 2 3void handler2(int sig) 4{ 5 pid_t pid; 67 ((pid = waitpid(-1, NULL, 0)) > 0) 8 printf("Handler reaped child %d\n", (int)pid); 9 (errno != ECHILD) 10 unix_error("waitpid error"); 11 Sleep(2); 12 return; 13 } 1415 int main() 16 { 17 int i, n; 18 char buf[MAXBUF]; 1920 (signal(SIGCHLD, handler2) == SIG_ERR) 21 unix_error("signal error"); 2223 /* Parent creates children */ 24 f r( i=0 ;i<3 ; i++) { 25 (Fork() == 0) { 26 printf("Hello child %d\n", (int)getpid()); 27 Sleep(1); 28 exit(0); 29 } 30 } 31 32 /* Parent waits terminal input processes */ 33 ((n = read(STDIN_FILENO, buf, sizeof(buf))) < 0) 34 unix_error("read error"); 35 36 printf("Parent processing input\n"); 37 (1) 38 ; 3940 exit(0); 41 } code/ecf/signal2.c Figure 8.32 signal2 :An improved version Figure 8.31 correctly accounts facts signals block queued. However, allow possibility system calls interrupted.750 Chapter 8 Exceptional Control Flow occurs. Figure 8.33 shows modiﬁcation signal2 manually restarts aborted read calls. EINTR return code errno indicates read system call returned prematurely interrupted. run new signal3 program Solaris system, program runs correctly: solaris> ./signal3 Hello child 19571Hello child 19572Hello child 19573 Handler reaped child 19571 Handler reaped child 19572Handler reaped child 19573 <cr> Parent processing input Practice Problem 8.8 output following program? code/ecf/signalprob0.c 1pid_t pid; 2int counter = 2; 3 4void handler1(int sig) { 5 counter = counter - 1; 6 printf("%d", counter); 7 fflush(stdout); 8 exit(0); 9} 1011 int main() { 12 signal(SIGUSR1, handler1); 1314 printf("%d", counter); 15 fflush(stdout); 1617 ((pid = fork()) == 0) { 18 while(1) {}; 19 } 20 kill(pid, SIGUSR1); 21 waitpid(-1, NULL, 0); 22 counter = counter + 1; 23 printf("%d", counter); 24 exit(0); 25 } code/ecf/signalprob0.ccode/ecf/signal3.c 1#include "csapp.h" 2 3void handler2(int sig) 4{ 5 pid_t pid; 6 7 ((pid = waitpid(-1, NULL, 0)) > 0) 8 printf("Handler reaped child %d\n", (int)pid); 9 (errno != ECHILD) 10 unix_error("waitpid error"); 11 Sleep(2); 12 return; 13 } 1415 int main() { 16 int i, n; 17 char buf[MAXBUF]; 18 pid_t pid; 1920 (signal(SIGCHLD, handler2) == SIG_ERR) 21 unix_error("signal error"); 22 23 /* Parent creates children */ 24 f r( i=0 ;i<3 ; i++) { 25 pid = Fork(); 26 (pid == 0) { 27 printf("Hello child %d\n", (int)getpid()); 28 Sleep(1); 29 exit(0); 30 } 31 } 32 33 /* Manually restart read call interrupted */ 34 ((n = read(STDIN_FILENO, buf, sizeof(buf))) < 0) 35 (errno != EINTR) 36 unix_error("read error"); 37 38 printf("Parent processing input\n"); 39 (1) 40 ; 4142 exit(0); 43 } code/ecf/signal3.c Figure 8.33 signal3 :An improved version Figure 8.32 correctly accounts fact system calls interrupted.752 Chapter 8 Exceptional Control Flow 8.5.5 Portable Signal Handling differences signal handling semantics system system—such whether interrupted slow system call restarted aborted pre-maturely—is ugly aspect Unix signal handling. deal problem,the Posix standard deﬁnes sigaction function, allows users Posix- compliant systems Linux Solaris clearly specify signal handlingsemantics want. #include <signal.h> int sigaction(int signum, struct sigaction *act, struct sigaction *oldact); Returns: 0 OK, −1 error Thesigaction function unwieldy requires user set entries structure. cleaner approach, originally proposed W. RichardStevens [109], deﬁne wrapper function, called Signal , calls sigaction us. Figure 8.34 shows deﬁnition Signal , invoked way signal function. Signal wrapper installs signal handler following signal handling semantics: .Only signals type currently processed handler blocked. .As signal implementations, signals queued. .Interrupted system calls automatically restarted whenever possible. code/src/csapp.c 1handler_t *Signal(int signum, handler_t *handler) 2{ 3 struct sigaction action, old_action; 4 5 action.sa_handler = handler; 6 sigemptyset(&action.sa_mask); /* Block sigs type handled */ 7 action.sa_flags = SA_RESTART; /* Restart syscalls possible */ 8 9 (sigaction(signum, &action, &old_action) < 0) 10 unix_error("Signal error"); 11 return (old_action.sa_handler); 12 } code/src/csapp.c Figure 8.34 Signal :A wrapper sigaction provides portable signal handling Posix-compliant systems.Section 8.5 Signals 753 .Once signal handler installed, remains installed Signal called handler argument either SIG_IGN SIG_DFL. (Some older Unix systems restore signal action default action signal beenprocessed handler.) Figure 8.35 shows version signal2 program Figure 8.32 uses Signal wrapper get predictable signal handling semantics different computer systems. difference installed handler witha call Signal rather call signal . program runs correctly Solaris Linux systems, longer need manually restart interrupted read system calls. 8.5.6 Explicitly Blocking Unblocking Signals Applications explicitly block unblock selected signals using sigproc- mask function: #include <signal.h> int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); Returns: 0 OK, −1 error int sigismember(const sigset_t *set, int signum); Returns: 1 member, 0 not, −1 error Thesigprocmask function changes set currently blocked signals (the blocked bit vector described Section 8.5.1). speciﬁc behavior depends value how: .SIG_BLOCK: Add signals settoblocked (blocked = blocked | set ). .SIG_UNBLOCK: Remove signals set blocked (blocked = blocked & ~set ). .SIG_SETMASK: blocked = set . Ifoldset non-NULL, previous value blocked bit vector stored oldset . Signal sets set manipulated using following functions. sigemptyset initializes setto empty set. sigfillset function adds every signal set.T h e sigaddset function adds signum toset,sigdelset deletes signum set, sigismember returns 1 signum member set, 0 not.754 Chapter 8 Exceptional Control Flow code/ecf/signal4.c 1#include "csapp.h" 2 3void handler2(int sig) 4{ 5 pid_t pid; 67 ((pid = waitpid(-1, NULL, 0)) > 0) 8 printf("Handler reaped child %d\n", (int)pid); 9 (errno != ECHILD) 10 unix_error("waitpid error"); 11 Sleep(2); 12 return; 13 } 1415 int main() 16 { 17 int i, n; 18 char buf[MAXBUF]; 19 pid_t pid; 2021 Signal(SIGCHLD, handler2); /* sigaction error-handling wrapper */ 22 23 /* Parent creates children */ 24 f r( i=0 ;i<3 ; i++) { 25 pid = Fork(); 26 (pid == 0) { 27 printf("Hello child %d\n", (int)getpid()); 28 Sleep(1); 29 exit(0); 30 } 31 } 32 33 /* Parent waits terminal input processes */ 34 ((n = read(STDIN_FILENO, buf, sizeof(buf))) < 0) 35 unix_error("read error"); 3637 printf("Parent processing input\n"); 38 (1) 39 ; 40 exit(0); 41 } code/ecf/signal4.c Figure 8.35 signal4 :A version Figure 8.32 uses Signal wrapper get portable signal handling semantics.Section 8.5 Signals 755 8.5.7 Synchronizing Flows Avoid Nasty Concurrency Bugs problem program concurrent ﬂows read write storage locations challenged generations computer scientists. general,the number potential interleavings ﬂows exponential number ofinstructions. interleavings produce correct answers, otherswill not. fundamental problem somehow synchronize concurrent ﬂows allow largest set feasible interleavings thefeasible interleavings produces correct answer. Concurrent programming deep important problem discuss detail Chapter 12. However, use you’ve learned aboutexceptional control ﬂow chapter give sense interestingintellectual challenges associated concurrency. example, consider theprogram Figure 8.36, captures structure typical Unix shell. Theparent keeps track current children using entries job list, one entryper job. addjob anddeletejob functions add remove entries job list, respectively. parent creates new child process, adds child job list. parent reaps terminated (zombie) child SIGCHLD signalhandler, deletes child job list. ﬁrst glance, code appears tobe correct. Unfortunately, following sequence events possible: 1.The parent executes fork function kernel schedules newly created child run instead parent. 2.Before parent able run again, child terminates becomes zombie, causing kernel deliver SIGCHLD signal parent. 3.Later, parent becomes runnable executed, kernel notices pending SIGCHLD causes received runningthe signal handler parent. 4.The signal handler reaps terminated child calls deletejob , nothing parent added child list yet. 5.After handler completes, kernel runs parent, returns fork incorrectly adds (nonexistent) child job list calling addjob . Thus, interleavings parent’s main routine signal handling ﬂows, possible deletejob called addjob . results incorrect entry job list, job longer exists never removed.On hand, also interleavings events occur correctorder. example, kernel happens schedule parent run thefork call returns instead child, parent correctly add child job list child terminates signal handler removes jobfrom list. example classic synchronization error known race. case, race call addjob main routine call deletejob handler. addjob wins race, answer correct. If756 Chapter 8 Exceptional Control Flow code/ecf/procmask1.c 1void handler(int sig) 2{ 3 pid_t pid; 4 ((pid = waitpid(-1, NULL, 0)) > 0) /* Reap zombie child */ 5 deletejob(pid); /* Delete child job list */ 6 (errno != ECHILD) 7 unix_error("waitpid error"); 8} 9 10 int main(int argc, char **argv) 11 { 12 int pid; 1314 Signal(SIGCHLD, handler); 15 initjobs(); /* Initialize job list */ 16 17 (1) { 18 /* Child process */ 19 ((pid = Fork()) == 0) { 20 Execve("/bin/date", argv, NULL); 21 } 2223 /* Parent process */ 24 addjob(pid); /* Add child job list */ 25 } 26 exit(0); 27 } code/ecf/procmask1.c Figure 8.36 shell program subtle synchronization error. child terminates parent able run, addjob anddeletejob called wrong order. not, answer incorrect. errors enormously difﬁcult debug often impossible test every interleaving. may run code billiontimes without problem, next test results interleaving thattriggers race. Figure 8.37 shows one way eliminate race Figure 8.36. blocking SIGCHLD signals call fork unblocking called addjob , guarantee child reaped added job list. Notice children inherit blocked set parents, must careful unblock SIGCHLD signal child calling execve .Section 8.5 Signals 757 code/ecf/procmask2.c 1void handler(int sig) 2{ 3 pid_t pid; 4 ((pid = waitpid(-1, NULL, 0)) > 0) /* Reap zombie child */ 5 deletejob(pid); /* Delete child job list */ 6 (errno != ECHILD) 7 unix_error("waitpid error"); 8} 9 10 int main(int argc, char **argv) 11 { 12 int pid; 13 sigset_t mask; 1415 Signal(SIGCHLD, handler); 16 initjobs(); /* Initialize job list */ 17 18 (1) { 19 Sigemptyset(&mask); 20 Sigaddset(&mask, SIGCHLD); 21 Sigprocmask(SIG_BLOCK, &mask, NULL); /* Block SIGCHLD */ 22 23 /* Child process */ 24 ((pid = Fork()) == 0) { 25 Sigprocmask(SIG_UNBLOCK, &mask, NULL); /* Unblock SIGCHLD */ 26 Execve("/bin/date", argv, NULL); 27 } 28 29 /* Parent process */ 30 addjob(pid); /* Add child job list */ 31 Sigprocmask(SIG_UNBLOCK, &mask, NULL); /* Unblock SIGCHLD */ 32 } 33 exit(0); 34 } code/ecf/procmask2.c Figure 8.37 Using sigprocmask synchronize processes. example, parent ensures addjob executes corresponding deletejob .code/ecf/rfork.c 1 #include <stdio.h> 2 #include <stdlib.h> 3 #include <unistd.h> 4 #include <sys/time.h> 5 #include <sys/types.h> 6 7 /* Sleep random period [0, MAX_SLEEP] us. */ 8 #define MAX_SLEEP 100000 9 10 /* Macro maps val range [0, RAND_MAX] */ 11 #define CONVERT(val) (((double)val)/(double)RAND_MAX) 1213 pid_t Fork(void) 14 { 15 static struct timeval time; 16 unsigned bool, secs; 17 pid_t pid; 18 19 /* Generate different seed time function called */ 20 gettimeofday(&time, NULL); 21 srand(time.tv_usec); 2223 /* Determine whether sleep parent child long */ 24 bool = (unsigned)(CONVERT(rand()) + 0.5); 25 secs = (unsigned)(CONVERT(rand()) * MAX_SLEEP); 2627 /* Call real fork function */ 28 ((pid = fork()) < 0) 29 return pid; 30 31 /* Randomly decide sleep parent child */ 32 (pid == 0) { /* Child */ 33 if(bool) { 34 usleep(secs); 35 } 36 } 37 else { /* Parent */ 38 (!bool) { 39 usleep(secs); 40 } 41 } 42 43 /* Return PID like normal fork call */ 44 return pid; 45 } code/ecf/rfork.c Figure 8.38 wrapper fork randomly determines order parent child execute. parent child ﬂip coin determine sleep, thus giving process chance scheduled.Section 8.6 Nonlocal Jumps 759 Aside handy trick exposing races code Races Figure 8.36 difﬁcult detect depend kernel-speciﬁc scheduling decisions. call fork , kernels schedule child run ﬁrst, kernels schedule parent run ﬁrst. run code Figure 8.36 one latter systems, would never fail, matter many times tested it. soon ran one former systems, race would exposed code would fail. Figure 8.38 shows wrapper function help expose hidden assumptions execution ordering parent child processes. basic idea call fork , parent child ﬂip coin determine sleep bit, thus giving process opportunity torun ﬁrst. run code multiple times, high probability would exercise bothorderings child parent executions, regardless particular kernel’s scheduling policy. 8.6 Nonlocal Jumps C provides form user-level exceptional control ﬂow, called nonlocal jump , transfers control directly one function another currently executing function without go normal call-and-return sequence. Non-local jumps provided setjmp andlongjmp functions. #include <setjmp.h> int setjmp(jmp_buf env); int sigsetjmp(sigjmp_buf env, int savesigs); Returns: 0 setjmp, nonzero longjmps Thesetjmp function saves current calling environment envbuffer, later use longjmp , returns 0. calling environment includes program counter, stack pointer, general purpose registers. #include <setjmp.h> void longjmp(jmp_buf env, int retval); void siglongjmp(sigjmp_buf env, int retval); Never returns Thelongjmp function restores calling environment env buffer triggers return recent setjmp call initialized env. Thesetjmp returns nonzero return value retval . interactions setjmp andlongjmp confusing ﬁrst glance. Thesetjmp function called once, returns multiple times: setjmp ﬁrst called calling environment stored env buffer,760 Chapter 8 Exceptional Control Flow corresponding longjmp call. hand, longjmp function called once, never returns. important application nonlocal jumps permit immediate return deeply nested function call, usually result detecting errorcondition. error condition detected deep nested function call, canuse nonlocal jump return directly common localized error handler instead laboriously unwinding call stack. Figure 8.39 shows example might work. main routine ﬁrst callssetjmp save current calling environment, calls function foo, turn calls function bar.I ffoo orbar encounter error, return immediately setjmp via alongjmp call. nonzero return value setjmp indicates error type, decoded handled one place code. Another important application nonlocal jumps branch signal handler speciﬁc code location, rather returning instruction wasinterrupted arrival signal. Figure 8.40 shows simple program illustrates basic technique. program uses signals nonlocal jumps todo soft restart whenever user types ctrl-c keyboard. sigsetjmp andsiglongjmp functions versions setjmp andlongjmp used signal handlers. initial call sigsetjmp function saves calling environment signal context (including pending blocked signal vectors) pro-gram ﬁrst starts. main routine enters inﬁnite processing loop. user types ctrl-c , shell sends SIGINT signal process, catches it. Instead returning signal handler, would pass controlback interrupted processing loop, handler performs nonlocal jumpback beginning main program. ran program system, got following output: unix> ./restart starting processing... processing... restarting User hits ctrl-c processing... restarting User hits ctrl-c processing... Aside Software exceptions C++ Java exception mechanisms provided C++ Java higher-level, more-structured versions theCsetjmp andlongjmp functions. think catch clause inside trystatement akin asetjmp function. Similarly, throw statement similar longjmp function.Section 8.6 Nonlocal Jumps 761 code/ecf/setjmp.c 1#include "csapp.h" 2 3jmp_buf buf; 4 5int error1 = 0; 6int error2 = 1; 7 8void foo(void), bar(void); 9 10 int main() 11 { 12 int rc; 1314 rc = setjmp(buf); 15 (rc == 0) 16 foo(); 17 else (rc == 1) 18 printf("Detected error1 condition foo\n"); 19 else (rc == 2) 20 printf("Detected error2 condition foo\n"); 21 else 22 printf("Unknown error condition foo\n"); 23 exit(0); 24 } 2526 /* Deeply nested function foo */ 27 void foo(void) 28 { 29 (error1) 30 longjmp(buf, 1); 31 bar(); 32 } 3334 void bar(void) 35 { 36 (error2) 37 longjmp(buf, 2); 38 } code/ecf/setjmp.c Figure 8.39 Nonlocal jump example. example shows framework using nonlocal jumps recover error conditions deeply nested functions withouthaving unwind entire stack.762 Chapter 8 Exceptional Control Flow code/ecf/restart.c 1#include "csapp.h" 2 3sigjmp_buf buf; 4 5void handler(int sig) 6{ 7 siglongjmp(buf, 1); 8} 9 10 int main() 11 { 12 Signal(SIGINT, handler); 1314 (!sigsetjmp(buf, 1)) 15 printf("starting\n"); 16 else 17 printf("restarting\n"); 1819 while(1) { 20 Sleep(1); 21 printf("processing...\n"); 22 } 23 exit(0); 24 } code/ecf/restart.c Figure 8.40 program uses nonlocal jumps restart user types ctrl-c . 8.7 Tools Manipulating Processes Linux systems provide number useful tools monitoring manipulating processes: strace : Prints trace system call invoked running program children. fascinating tool curious student. Compile yourprogram -static get cleaner trace without lot output related shared libraries. ps: Lists processes (including zombies) currently system. top: Prints information resource usage current processes. pmap : Displays memory map process. /proc : virtual ﬁlesystem exports contents numerous kernel data structures ASCII text form read user programs. ForBibliographic Notes 763 example, type “ cat /proc/loadavg ” see current load average Linux system. 8.8 Summary Exceptional control ﬂow (ECF) occurs levels computer system abasic mechanism providing concurrency computer system. hardware level, exceptions abrupt changes control ﬂow triggered events processor. control ﬂow passes softwarehandler, processing returns control interrupted control ﬂow. four different types exceptions: interrupts, faults, aborts, traps. Interrupts occur asynchronously (with respect instructions) anexternal I/O device timer chip disk controller sets interrupt pinon processor chip. Control returns instruction following faultinginstruction. Faults aborts occur synchronously result executionof instruction. Fault handlers restart faulting instruction, abort han-dlers never return control interrupted ﬂow. Finally, traps like functioncalls used implement system calls provide applications withcontrolled entry points operating system code. operating system level, kernel uses ECF provide funda- mental notion process. process provides applications two importantabstractions: (1) logical control ﬂows give program illusion ithas exclusive use processor, (2) private address spaces provide theillusion program exclusive use main memory. interface operating system applications, applications create child processes, wait child processes stop terminate, runnew programs, catch signals processes. semantics signalhandling subtle vary system system. However, mechanisms existon Posix-compliant systems allow programs clearly specify expectedsignal handling semantics. Finally, application level, C programs use nonlocal jumps bypass normal call/return stack discipline branch directly one function toanother. Bibliographic Notes Intel macroarchitecture speciﬁcation contains detailed discussion excep-tions interrupts Intel processors [27]. Operating systems texts [98, 104, 112]contain additional information exceptions, processes, signals. classicwork W. Richard Stevens [110] valuable highly readable descriptionof work processes signals application programs. Bovet andCesati [11] give wonderfully clear description Linux kernel, including de-tails process signal implementations. Blum [9] excellent referencefor x86 assembly language, describes detail x86 syscall interface.764 Chapter 8 Exceptional Control Flow Homework Problems 8.9◆ Consider four processes following starting ending times: Process Start time End time A5 7 B2 4 C3 6 D1 8 pair processes, indicate whether run concurrently (y) (n): Process pair Concurrent? AB AC AD BC BD CD 8.10◆ chapter, introduced functions unusual call returnbehaviors: setjmp ,longjmp ,execve , fork . Match function one following behaviors: A. Called once, returns twice. B. Called once, never returns.C. Called once, returns one times. 8.11◆ many “hello” output lines program print? code/ecf/forkprob1.c 1#include "csapp.h" 2 3int main() 4{ 5 int i; 67 f r( i=0 ;i<2 ; i++) 8 Fork(); 9 printf("hello\n"); 10 exit(0); 11 } code/ecf/forkprob1.cHomework Problems 765 8.12◆ many “hello” output lines program print? code/ecf/forkprob4.c 1#include "csapp.h" 2 3void doit() 4{ 5 Fork(); 6 Fork(); 7 printf("hello\n"); 8 return; 9} 10 11 int main() 12 { 13 doit(); 14 printf("hello\n"); 15 exit(0); 16 } code/ecf/forkprob4.c 8.13◆ one possible output following program? code/ecf/forkprob3.c 1#include "csapp.h" 2 3int main() 4{ 5 n tx=3 ; 67 (Fork() != 0) 8 printf("x=%d\n", ++x); 9 10 printf("x=%d\n", --x); 11 exit(0); 12 } code/ecf/forkprob3.c 8.14◆ many “hello” output lines program print? code/ecf/forkprob5.c 1#include "csapp.h" 2 3void doit()766 Chapter 8 Exceptional Control Flow 4{ 5 (Fork() == 0) { 6 Fork(); 7 printf("hello\n"); 8 exit(0); 9 } 10 return; 11 } 12 13 int main() 14 { 15 doit(); 16 printf("hello\n"); 17 exit(0); 18 } code/ecf/forkprob5.c 8.15◆ many “hello” lines program print? code/ecf/forkprob6.c 1#include "csapp.h" 2 3void doit() 4{ 5 (Fork() == 0) { 6 Fork(); 7 printf("hello\n"); 8 return; 9 } 10 return; 11 } 12 13 int main() 14 { 15 doit(); 16 printf("hello\n"); 17 exit(0); 18 } code/ecf/forkprob6.c 8.16◆ output following program? code/ecf/forkprob7.c 1#include "csapp.h" 2int counter = 1;Homework Problems 767 3 4int main() 5{ 6 (fork() == 0) { 7 counter--; 8 exit(0); 9 } 10 else { 11 Wait(NULL); 12 printf("counter = %d\n", ++counter); 13 } 14 exit(0); 15 } code/ecf/forkprob7.c 8.17◆ Enumerate possible outputs program Problem 8.4. 8.18◆◆ Consider following program: code/ecf/forkprob2.c 1#include "csapp.h" 2 3void end(void) 4{ 5 printf("2"); 6} 7 8int main() 9{ 10 (Fork() == 0) 11 atexit(end); 12 (Fork() == 0) 13 printf("0"); 14 else 15 printf("1"); 16 exit(0); 17 } code/ecf/forkprob2.c Determine following outputs possible. Note: atexit function takes pointer function adds list functions (initiallyempty) called exit function called. A. 112002 B. 211020768 Chapter 8 Exceptional Control Flow C. 102120 D. 122001E. 100212 8.19◆◆ many lines output following function print? Give answer function n. Assume n≥1. code/ecf/forkprob8.c 1void foo(int n) 2{ 3 int i; 4 5 f r( i=0 ;i<n ; i++) 6 Fork(); 7 printf("hello\n"); 8 exit(0); 9} code/ecf/forkprob8.c 8.20◆◆ Useexecve write program called myls whose behavior identical /bin/ls program. program accept command line argu- ments, interpret identical environment variables, produce identicaloutput. Thelsprogram gets width screen COLUMNS environ- ment variable. COLUMNS unset, lsassumes screen 80 columns wide. Thus, check handling environment variablesby setting COLUMNS environment something smaller 80: unix> setenv COLUMNS 40 unix> ./myls ...output 40 columns wide unix> unsetenv COLUMNS unix> ./myls ...output 80 columns wide 8.21◆◆ possible output sequences following program? code/ecf/waitprob3.c 1int main() 2{ 3 (fork() == 0) { 4 printf("a"); 5 exit(0); 6 }Homework Problems 769 7 else { 8 printf("b"); 9 waitpid(-1, NULL, 0); 10 } 11 printf("c"); 12 exit(0); 13 } code/ecf/waitprob3.c 8.22◆◆◆ Write version Unix system function int mysystem(char *command); Themysystem function executes command calling “ /bin/sh -c command ”, returns command completed. command exits normally (by calling theexit function executing return statement), mysystem returns command exit status. example, command terminates calling exit(8) , system returns value 8. Otherwise, command terminates abnormally, mysystem returns status returned shell. 8.23◆◆ One colleagues thinking using signals allow parent process tocount events occur child process. idea notify parent eachtime event occurs sending signal, letting parent’s signal handlerincrement global counter variable, parent inspect child terminated. However, runs test program Figure 8.41 onhis system, discovers parent calls printf ,counter always value 2, even though child sent ﬁve signals parent. Perplexed, hecomes help. explain bug? 8.24◆◆◆ Modify program Figure 8.17 following two conditions met: 1.Each child terminates abnormally attempting write location read-only text segment. 2.The parent prints output identical (except PIDs) follow- ing: child 12255 terminated signal 11: Segmentation fault child 12254 terminated signal 11: Segmentation fault Hint: Read manpage psignal(3) . 8.25◆◆◆ Write version fgets function, called tfgets , times 5 seconds. Thetfgets function accepts inputs fgets . user doesn’t type input line within 5 seconds, tfgets returns NULL. Otherwise, returns pointer input line.770 Chapter 8 Exceptional Control Flow code/ecf/counterprob.c 1#include "csapp.h" 2 3int counter = 0; 4 5void handler(int sig) 6{ 7 counter++; 8 sleep(1); /* work handler */ 9 return; 10 } 11 12 int main() 13 { 14 int i; 15 16 Signal(SIGUSR2, handler); 17 18 (Fork() == 0) { /* Child */ 19 f r( i=0 ;i<5 ; i++) { 20 Kill(getppid(), SIGUSR2); 21 printf("sent SIGUSR2 parent\n"); 22 } 23 exit(0); 24 } 25 26 Wait(NULL); 27 printf("counter=%d\n", counter); 28 exit(0); 29 } code/ecf/counterprob.c Figure 8.41 Counter program referenced Problem 8.23. 8.26◆◆◆◆ Using example Figure 8.22 starting point, write shell program thatsupports job control. shell following features: .The command line typed user consists name zero argu- ments, separated one spaces. name built-in command, shell handles immediately waits next command line. Otherwise, shell assumes name executable ﬁle, loads runs context initial child process (job). process group ID job isidentical PID child. .Each job identiﬁed either process ID (PID) job ID (JID), whichis small arbitrary positive integer assigned shell. JIDs denoted onSolutions Practice Problems 771 command line preﬁx ‘ %’. example, “ %5” denotes JID 5, “ 5” denotes PID 5. .If command line ends ampersand, shell runs job inthe background. Otherwise, shell runs job foreground. .Typing ctrl-c (ctrl-z ) causes shell send SIGINT (SIGTSTP) signal every process foreground process group. .Thejobs built-in command lists background jobs. .Thebg <job> built-in command restarts <job> sending SIGCONT signal, runs background. <job> argument either PID JID. .Thefg <job> built-in command restarts <job> sending SIGCONT signal, runs foreground. .The shell reaps zombie children. job terminates itreceives signal caught, shell prints message terminal job’s PID description offending signal. Figure 8.42 shows example shell session. Solutions Practice Problems Solution Problem 8.1 (page 714) Processes B concurrent respect other, B C, respective executions overlap, is, one process starts theother ﬁnishes. Processes C concurrent, executions donot overlap; ﬁnishes C begins. Solution Problem 8.2 (page 723) example program Figure 8.15, parent child execute disjoint sets ofinstructions. However, program, parent child execute non-disjointsets instructions, possible parent child identicalcode segments. difﬁcult conceptual hurdle, sure understandthe solution problem. A. key idea child executes printf statements. thefork returns, executes printf line 8. falls statement executes printf line 9. output produced child: printf1: x=2 printf2: x=1 B. parent executes printf line 9: printf2: x=0772 Chapter 8 Exceptional Control Flow unix> ./shell Run shell program >bogus bogus: Command found. Execve can’t find executable >foo 10 Job 5035 terminated signal: Interrupt User types ctrl-c >foo 100 & [1] 5036 foo 100 & >foo 200 & [2] 5037 foo 200 &>jobs [1] 5036 Running foo 100 &[2] 5037 Running foo 200 & >fg %1 Job [1] 5036 stopped signal: Stopped User types ctrl-z >jobs [1] 5036 Stopped foo 100 &[2] 5037 Running foo 200 &>bg 5035 5035: process>bg 5036 [1] 5036 foo 100 & >/bin/kill 5036 Job 5036 terminated signal: Terminated>f g % 2 Wait fg job finish. >quit unix> Back Unix shell Figure 8.42 Sample shell session Problem 8.26. Solution Problem 8.3 (page 726) parent prints band c. child prints aand c. It’s important realize cannot make assumption execution theparent child interleaved. Thus, topological sort b→canda→cis possible output sequence. four sequences: acbc ,bcac ,abcc , bacc . Solution Problem 8.4 (page 729) A. time run program, generates six output lines. B. ordering output lines vary system system, depending kernel interleaves instructions parent child.In general, topological sort following graph valid ordering: --> ‘‘0’’ --> ‘‘2’’ --> ‘‘Bye’’ Parent process / ‘‘Hello’’ \ --> ‘‘1’’ --> ‘‘Bye’’ Child processSolutions Practice Problems 773 example, run program system, get following output: unix> ./waitprob1 Hello0 1 Bye 2 Bye case, parent runs ﬁrst, printing “ Hello ” line 6 “ 0” line 8. call wait blocks child yet terminated, kernel context switch passes control child, prints “ 1” line 8 “ Bye” line 15, terminates exit status 2 line 16. child terminates, parent resumes, printing child’s exit statusin line 12 “ Bye” line 15. Solution Problem 8.5 (page 730) code/ecf/snooze.c 1unsigned int snooze(unsigned int secs) { 2 unsigned int rc = sleep(secs); 3 printf("Slept %u %u secs.\n", secs - rc, secs); 4 return rc; 5} code/ecf/snooze.c Solution Problem 8.6 (page 733) code/ecf/myecho.c 1#include "csapp.h" 2 3int main(int argc, char *argv[], char *envp[]) 4{ 5 int i; 67 printf("Command line arguments:\n"); 8 (i=0; argv[i] != NULL; i++) 9 printf(" argv[%2d]: %s\n", i, argv[i]); 1011 printf("\n"); 12 printf("Environment variables:\n"); 13 (i=0; envp[i] != NULL; i++) 14 printf(" envp[%2d]: %s\n", i, envp[i]); 1516 exit(0); 17 } code/ecf/myecho.c774 Chapter 8 Exceptional Control Flow Solution Problem 8.7 (page 744) Thesleep function returns prematurely whenever sleeping process receives signal ignored. since default action upon receipt SIGINT isto terminate process (Figure 8.25), must install SIGINT handler allow thesleep function return. handler simply catches SIGNAL returns control sleep function, returns immediately. code/ecf/snooze.c 1#include "csapp.h" 2 3/* SIGINT handler */ 4void handler(int sig) 5{ 6 return; /* Catch signal return */ 7} 8 9unsigned int snooze(unsigned int secs) { 10 unsigned int rc = sleep(secs); 11 printf("Slept %u %u secs.\n", secs - rc, secs); 12 return rc; 13 } 1415 int main(int argc, char **argv) { 16 17 (argc != 2) { 18 fprintf(stderr, "usage: %s <secs>\n", argv[0]); 19 exit(0); 20 } 21 22 (signal(SIGINT, handler) == SIG_ERR) /* Install SIGINT handler */ 23 unix_error("signal error\n"); 24 (void)snooze(atoi(argv[1])); 25 exit(0); 26 } code/ecf/snooze.c Solution Problem 8.8 (page 750) program prints string “213”, shorthand name CS:APP course Carnegie Mellon. parent starts printing “2”, forks child,which spins inﬁnite loop. parent sends signal child, andwaits terminate. child catches signal (interrupting inﬁnite loop), decrements counter (from initial value 2), prints “1”, terminates. parent reaps child, increments counter (from aninitial value 2), prints “3”, terminates.CHAPTER9 Virtual Memory 9.1 Physical Virtual Addressing 777 9.2 Address Spaces 778 9.3 VM Tool Caching 779 9.4 VM Tool Memory Management 785 9.5 VM Tool Memory Protection 786 9.6 Address Translation 787 9.7 Case Study: Intel Core i7/Linux Memory System 799 9.8 Memory Mapping 807 9.9 Dynamic Memory Allocation 812 9.10 Garbage Collection 838 9.11 Common Memory-Related Bugs C Programs 843 9.12 Summary 848 Bibliographic Notes 848 Homework Problems 849 Solutions Practice Problems 853 775776 Chapter 9 Virtual Memory Processes system share CPU main memory processes. However, sharing main memory poses special challenges. demandon CPU increases, processes slow reasonably smooth way. Butif many processes need much memory, simplynot able run. program space, luck. Memory isalso vulnerable corruption. process inadvertently writes memoryused another process, process might fail bewildering fashion totallyunrelated program logic. order manage memory efﬁciently fewer errors, modern systems provide abstraction main memory known virtual memory (VM). Virtual memory elegant interaction hardware exceptions, hardware ad-dress translation, main memory, disk ﬁles, kernel software provides eachprocess large, uniform, private address space. one clean mech-anism, virtual memory provides three important capabilities. (1) uses main memory efﬁciently treating cache address space stored disk,keeping active areas main memory, transferring data back forth disk memory needed. (2) simpliﬁes memory managementby providing process uniform address space. (3) protects addressspace process corruption processes. Virtual memory one great ideas computer systems. major reason success works silently automatically, without interventionfrom application programmer. Since virtual memory works well behind thescenes, would programmer need understand it? several reasons. .Virtual memory central. Virtual memory pervades levels computer systems, playing key roles design hardware exceptions, assemblers,linkers, loaders, shared objects, ﬁles, processes. Understanding virtualmemory help better understand systems work general. .Virtual memory powerful. Virtual memory gives applications powerful ca- pabilities create destroy chunks memory, map chunks memory toportions disk ﬁles, share memory processes. example,did know read modify contents disk ﬁle readingand writing memory locations? load contents ﬁle intomemory without explicit copying? Understanding virtual memorywill help harness powerful capabilities applications. .Virtual memory dangerous. Applications interact virtual memory ev- ery time reference variable, dereference pointer, make call adynamic allocation package malloc . virtual memory used improp- erly, applications suffer perplexing insidious memory-relatedbugs. example, program bad pointer crash immediately witha “Segmentation fault” “Protection fault,” run silently hours crashing, scariest all, run completion incorrect results. Under- standing virtual memory, allocation packages malloc manage it, help avoid errors. chapter looks virtual memory two angles. ﬁrst half chapter describes virtual memory works. second half describes howSection 9.1 Physical Virtual Addressing 777 virtual memory used managed applications. avoiding fact VM complicated, discussion reﬂects places. goodnews work details, able simulate virtualmemory mechanism small system hand, virtual memory idea willbe forever demystiﬁed. second half builds understanding, showing use manage virtual memory programs. learn manage virtualmemory via explicit memory mapping calls dynamic storage allocators malloc package. also learn host common memory- related errors C programs avoid them. 9.1 Physical Virtual Addressing main memory computer system organized array Mcontiguous byte-sized cells. byte unique physical address (PA). ﬁrst byte address 0, next byte address 1, next byte address 2,and on. Given simple organization, natural way CPU toaccess memory would use physical addresses. call approach physical addressing . Figure 9.1 shows example physical addressing context load instruction reads word starting physical address 4. CPU executes load instruction, generates effective physical address passes main memory memory bus. main memoryfetches 4-byte word starting physical address 4 returns CPU, stores register. Early PCs used physical addressing, systems digital signal pro- cessors, embedded microcontrollers, Cray supercomputers continue so.However, modern processors use form addressing known virtual address- ing, shown Figure 9.2. virtual addressing, CPU accesses main memory generating vir- tual address (VA), converted appropriate physical address sent memory. task converting virtual address physical one known address translation . Like exception handling, address translation Figure 9.1 system usesphysical addressing.. . .Main memory 0: 1: 2: 3: 4: 5:6:7:8:Physical address (PA) CPU 4 M/H110021: Data word778 Chapter 9 Virtual Memory Figure 9.2 system uses virtualaddressing.Main memory 0: 1: 2: 3:4: 5:6:7:Physical address (PA)Virtual address (VA)Address translation CPUCPU chip MMU 4100 4 M/H110021: Data word. . . requires close cooperation CPU hardware operating sys- tem. Dedicated hardware CPU chip called memory management unit (MMU) translates virtual addresses ﬂy, using look-up table stored mainmemory whose contents managed operating system. 9.2 Address Spaces Anaddress space ordered set nonnegative integer addresses {0,1,2,...} integers address space consecutive, say linear address space . simplify discussion, always assume linear address spaces. system virtual memory, CPU generates virtual addresses froman address space N=2 naddresses called virtual address space : {0,1,2,...,N −1} size address space characterized number bits needed represent largest address. example, virtual address space N=2n addresses called n-bit address space. Modern systems typically support either 32-bit 64-bit virtual address spaces. system also physical address space corresponds Mbytes physical memory system: {0,1,2,...,M −1} Mis required power two, simplify discussion assume M=2m. concept address space important makes clean dis- tinction data objects (bytes) attributes (addresses). recognize distinction, generalize allow data object multiple independent addresses, chosen different address space.Section 9.3 VM Tool Caching 779 Figure 9.3 VM system usesmain memory cache. VP 0 VP 1 PP 0 PP 1 PP 2m/H11002p/H11002 1 VP 2n/H11002p/H11002 1UnallocatedVirtual memory Physical memory Virtual pages (VPs) stored diskPhysical pages (PPs) cached DRAMCached Uncached Unallocated Cached UncachedEmpty Empty Empty N/H11002 1M/H11002 10 0 Cached Uncached basic idea virtual memory. byte main memory virtual address chosen virtual address space, physical address chosen fromthe physical address space. Practice Problem 9.1 Complete following table, ﬁlling missing entries replacing question mark appropriate integer. Use following units: K =210 (Kilo), =220(Mega), G =230(Giga), =240(Tera), P =250(Peta), E =260 (Exa). No. virtual address bits ( n) No. virtual addresses ( N) Largest possible virtual address 8 2?=64K 232−1=?G−1 2?=256T 64 9.3 VM Tool Caching Conceptually, virtual memory organized array Ncontiguous byte-sized cells stored disk. byte unique virtual address serves indexinto array. contents array disk cached main memory. Aswith cache memory hierarchy, data disk (the lower level)is partitioned blocks serve transfer units disk main memory (the upper level). VM systems handle partitioning virtual memory ﬁxed-sized blocks called virtual pages (VPs). virtual page P=2 pbytes size. Similarly, physical memory partitioned physical pages (PPs), also Pbytes size. (Physical pages also referred page frames .) point time, set virtual pages partitioned three disjoint subsets: .Unallocated: Pages yet allocated (or created) VM system. Unallocated blocks data associated them, thus occupy space disk.780 Chapter 9 Virtual Memory .Cached: Allocated pages currently cached physical memory. .Uncached: Allocated pages cached physical memory. example Figure 9.3 shows small virtual memory eight virtual pages. Virtual pages 0 3 allocated yet, thus yet existon disk. Virtual pages 1, 4, 6 cached physical memory. Pages 2, 5, 7are allocated, currently cached main memory. 9.3.1 DRAM Cache Organization help us keep different caches memory hierarchy straight, use term SRAM cache denote L1, L2, L3 cache memories CPU main memory, term DRAM cache denote VM system’s cache caches virtual pages main memory. position DRAM cache memory hierarchy big impact way organized. Recall DRAM least 10 times slowerthan SRAM disk 100,000 times slower DRAM. Thus,misses DRAM caches expensive compared misses SRAM cachesbecause DRAM cache misses served disk, SRAM cache misses areusually served DRAM-based main memory. Further, cost reading theﬁrst byte disk sector 100,000 times slower reading successivebytes sector. bottom line organization DRAM cacheis driven entirely enormous cost misses. large miss penalty expense accessing ﬁrst byte, virtual pages tend large, typically 4 KB 2 MB. Due large miss penalty,DRAM caches fully associative, is, virtual page placed physical page. replacement policy misses also assumes greater importance, penalty associated replacing wrong virtual page high.Thus, operating systems use much sophisticated replacement algorithms forDRAM caches hardware SRAM caches. (These replacementalgorithms beyond scope here.) Finally, large access timeof disk, DRAM caches always use write-back instead write-through. 9.3.2 Page Tables cache, VM system must way determine virtual page cached somewhere DRAM. so, system must determine whichphysical page cached in. miss, system must determine wherethe virtual page stored disk, select victim page physical memory, andcopy virtual page disk DRAM, replacing victim page. capabilities provided combination operating system soft- ware, address translation hardware MMU (memory management unit), anda data structure stored physical memory known page table maps vir- tual pages physical pages. address translation hardware reads page tableeach time converts virtual address physical address. operating systemSection 9.3 VM Tool Caching 781 Figure 9.4 Page table. PTE 0PP 0 PP 31 10 1 00 10 PTE 7null VP 1VP 4VP 7VP 2VP 1 VP 2 VP 3VP 4VP 6VP 7nullPhysical page number disk address Memory resident page table (DRAM)Virtual memory (disk)Physical memory (DRAM) Valid responsible maintaining contents page table transferring pages back forth disk DRAM. Figure 9.4 shows basic organization page table. page table array ofpage table entries (PTEs). page virtual address space PTE ﬁxed offset page table. purposes, assume PTEconsists valid bit n-bit address ﬁeld. valid bit indicates whether virtual page currently cached DRAM. valid bit set, addressﬁeld indicates start corresponding physical page DRAM thevirtual page cached. valid bit set, null address indicates thatthe virtual page yet allocated. Otherwise, address points start virtual page disk. example Figure 9.4 shows page table system eight virtual pages four physical pages. Four virtual pages (VP 1, VP 2, VP 4, VP 7)are currently cached DRAM. Two pages (VP 0 VP 5) yet beenallocated, rest (VP 3 VP 6) allocated, currentlycached. important point notice Figure 9.4 DRAMcache fully associative, physical page contain virtual page. Practice Problem 9.2 Determine number page table entries (PTEs) needed thefollowing combinations virtual address size ( n) page size ( P): nP =2pNo. PTEs 16 4K 16 8K 32 4K 32 8K782 Chapter 9 Virtual Memory Figure 9.5 VM page hit. reference word VP 2 hit. PTE 0PP 0 PP 31 10 1 0 0 10 PTE 7null VP 1VP 4VP 7VP 2VP 1 VP 2 VP 3VP 4VP 6VP 7nullPhysical page number disk address Memory resident page table (DRAM)Virtual memory (disk)Physical memory (DRAM) Virtual address Valid 9.3.3 Page Hits Consider happens CPU reads word virtual memory contained VP 2, cached DRAM (Figure 9.5). Using technique describein detail Section 9.6, address translation hardware uses virtual addressas index locate PTE 2 read memory. Since valid bit set, theaddress translation hardware knows VP 2 cached memory. uses thephysical memory address PTE (which points start cached pagein PP 1) construct physical address word. 9.3.4 Page Faults virtual memory parlance, DRAM cache miss known page fault . Fig- ure 9.6 shows state example page table fault. CPU hasreferenced word VP 3, cached DRAM. address transla-tion hardware reads PTE 3 memory, infers valid bit VP 3 notcached, triggers page fault exception. page fault exception invokes page fault exception handler kernel, selects victim page, case VP 4 stored PP 3. VP 4 beenmodiﬁed, kernel copies back disk. either case, kernel modiﬁesthe page table entry VP 4 reﬂect fact VP 4 longer cached inmain memory. Next, kernel copies VP 3 disk PP 3 memory, updates PTE 3, returns. handler returns, restarts faulting instruction, resends faulting virtual address address translation hardware.But now, VP 3 cached main memory, page hit handled normally bythe address translation hardware. Figure 9.7 shows state example pagetable page fault. Virtual memory invented early 1960s, long widening CPU-memory gap spawned SRAM caches. result, virtual memory systemsSection 9.3 VM Tool Caching 783 Figure 9.6 VM page fault (before).The reference word inVP 3 miss triggersa page fault. PTE 0PP 0 PP 31 10 1 00 10 PTE 7null VP 1VP 4VP 7VP 2VP 1 VP 2 VP 3VP 4VP 6VP 7nullPhysical page number disk address Memory resident page table (DRAM)Virtual memory (disk)Physical memory (DRAM) Virtual address Valid Figure 9.7 VM page fault (after). page fault handler selects VP 4 victim replaces copy ofVP 3 disk. thepage fault handler restarts faulting instruction, read word frommemory normally, without generating exception.PTE 0PP 0 PP 31 1 1 00 0 10 PTE 7null VP 1VP 3VP 7VP 2VP 1 VP 2 VP 3VP 4 VP 6 VP 7nullPhysical page number disk address Memory resident page table (DRAM)Virtual memory (disk)Physical memory (DRAM) ValidVirtual address use different terminology SRAM caches, even though many ideas similar. virtual memory parlance, blocks known pages. activityof transferring page disk memory known swapping orpaging . Pages swapped (paged in) disk DRAM, swapped (paged out) DRAM disk. strategy waiting last moment swap page, miss occurs, known demand paging . approaches, trying predict misses swap pages actually referenced,are possible. However, modern systems use demand paging. 9.3.5 Allocating Pages Figure 9.8 shows effect example page table operating system allocates new page virtual memory, example, result calling malloc .784 Chapter 9 Virtual Memory Figure 9.8 Allocating new virtualpage. kernel allocates VP 5 disk pointsPTE 5 new location. PTE 0PP 0 PP 31 1 1 00 0 10 PTE 7null VP 1VP 3VP 7VP 2VP 1 VP 2 VP 3 VP 4VP 5VP 6 VP 7Physical page number disk address Memory resident page table (DRAM)Virtual memory (disk)Physical memory (DRAM) Valid example, VP 5 allocated creating room disk updating PTE 5 point newly created page disk. 9.3.6 Locality Rescue many us learn idea virtual memory, ﬁrst impression often must terribly inefﬁcient. Given large miss penalties, worry paging destroy program performance. practice, virtual memory workswell, mainly old friend locality . Although total number distinct pages programs reference entire run might exceed total size physical memory, principle localitypromises point time tend work smaller set active pages known working set orresident set . initial overhead working set paged memory, subsequent references working setresult hits, additional disk trafﬁc. long programs good temporal locality, virtual memory systems work quite well. course, programs exhibit good temporal locality. working set size exceeds size physical memory, program canproduce unfortunate situation known thrashing , pages swapped continuously. Although virtual memory usually efﬁcient, program’sperformance slows crawl, wise programmer consider possibilitythat thrashing. Aside Counting page faults monitor number page faults (and lots information) Unix getrusage function.Section 9.4 VM Tool Memory Management 785 9.4 VM Tool Memory Management last section, saw virtual memory provides mechanism using DRAM cache pages typically larger virtual address space. Interestingly,some early systems DEC PDP-11/70 supported virtual address spacethat smaller available physical memory. Yet virtual memory still useful mechanism greatly simpliﬁed memory management andprovided natural way protect memory. Thus far, assumed single page table maps single virtual address space physical address space. fact, operating systems providea separate page table, thus separate virtual address space, process.Figure 9.9 shows basic idea. example, page table process imaps VP 1 PP 2 VP 2 PP 7. Similarly, page table process jmaps VP 1 PP 7 VP 2 PP 10. Notice multiple virtual pages mapped tothe shared physical page. combination demand paging separate virtual address spaces profound impact way memory used managed system. Inparticular, VM simpliﬁes linking loading, sharing code data, andallocating memory applications. .Simplifying linking. separate address space allows process use basic format memory image, regardless code anddata actually reside physical memory. example, saw Figure 8.13,every process given Linux system similar memory format. text section always starts virtual address 0x08048000 (for 32-bit address spaces), address 0x400000 (for 64-bit address spaces). data bss sections follow immediately text section. stack occupies highestportion process address space grows downward. uniformitygreatly simpliﬁes design implementation linkers, allowing toproduce fully linked executables independent ultimate locationof code data physical memory. .Simplifying loading. Virtual memory also makes easy load executable shared object ﬁles memory. Recall Chapter 7 .text Figure 9.9 VM providesprocesses separateaddress spaces. operating system maintains separate page table foreach process system.Virtual address spacesPhysical memory Shared pageAddress translation Process i: Process j:0 N/H110021 0 VP 1 VP 2VP 1 VP 2 N/H1100210 M/H110021786 Chapter 9 Virtual Memory and.data sections ELF executables contiguous. load sections newly created process, Linux loader allocates contiguous chunkof virtual pages starting address 0x08048000 (32-bit address spaces) 0x400000 (64-bit address spaces), marks invalid (i.e., cached), points page table entries appropriate locations objectﬁle. interesting point loader never actually copies data fromdisk memory. data paged automatically demand thevirtual memory system ﬁrst time page referenced, either theCPU fetches instruction, executing instruction itreferences memory location. notion mapping set contiguous virtual pages arbitrary location arbitrary ﬁle known memory mapping . Unix provides system call called mmap allows application programs memory mapping. describe application-level memory mapping inmore detail Section 9.8. .Simplifying sharing. Separate address spaces provide operating system consistent mechanism managing sharing user processesand operating system itself. general, process privatecode, data, heap, stack areas shared process. Inthis case, operating system creates page tables map correspondingvirtual pages disjoint physical pages. However, instances desirable processes share code data. example, every process must call operating system kernel code, every C program makes calls routines standard C library printf . Rather including separate copies kernel standard C library process, operating system arrangefor multiple processes share single copy code mapping theappropriate virtual pages different processes physical pages,as saw Figure 9.9. .Simplifying memory allocation. Virtual memory provides simple mechanism allocating additional memory user processes. program runningin user process requests additional heap space (e.g., result callingmalloc ), operating system allocates appropriate number, say, k,o f contiguous virtual memory pages, maps karbitrary physical pages located anywhere physical memory. way page tables work,there need operating system locate kcontiguous pages physical memory. pages scattered randomly physical memory. 9.5 VM Tool Memory Protection modern computer system must provide means operating systemto control access memory system. user process allowedto modify read-only text section. allowed read modifyany code data structures kernel. allowed reador write private memory processes, allowed toSection 9.6 Address Translation 787 Physical memory PP 0 PP 2 PP 4 PP 6 PP 9 PP 11Process i: Process j:Page tables permission bits SUP READ WRITE Address VP 0: VP 1:VP 2:No YesYes Yes YesNo Yes YesPP 6 PP 4 PP 2 SUP READ WRITE Address VP 0: VP 1:VP 2:No Yes NoYes Yes YesNo Yes YesPP 9 PP 6 PP 11 . . . . . .. . . Figure 9.10 Using VM provide page-level memory protection. modify virtual pages shared processes, unless parties explicitly allow (via calls explicit interprocess communication system calls). seen, providing separate virtual address spaces makes easy isolate private memories different processes. address translationmechanism extended natural way provide even ﬁner access control.Since address translation hardware reads PTE time CPU generatesan address, straightforward control access contents virtual page byadding additional permission bits PTE. Figure 9.10 shows generalidea. example, added three permission bits PTE. SUP bit indicates whether processes must running kernel (supervisor) mode accessthe page. Processes running kernel mode access page, processesrunning user mode allowed access pages SUP 0. TheREAD WRITE bits control read write access page. example,if process iis running user mode, permission read VP 0 read write VP 1. However, allowed access VP 2. instruction violates permissions, CPU triggers general protection fault transfers control exception handler kernel. Unixshells typically report exception “segmentation fault.” 9.6 Address Translation section covers basics address translation. aim give anappreciation hardware’s role supporting virtual memory, enoughdetail work concrete examples hand. However,keep mind omitting number details, especially related timing,that important hardware designers beyond scope. your788 Chapter 9 Virtual Memory Basic parameters Symbol Description N=2nNumber addresses virtual address space M=2mNumber addresses physical address space P=2pPage size (bytes) Components virtual address (VA) Symbol Description VPO Virtual page offset (bytes) VPN Virtual page number TLBI TLB index TLBT TLB tag Components physical address (PA) Symbol Description PPO Physical page offset (bytes) PPN Physical page numberCO Byte offset within cache block CI Cache index CT Cache tag Figure 9.11 Summary address translation symbols. reference, Figure 9.11 summarizes symbols using throughout section. Formally, address translation mapping elements N- element virtual address space (VAS) M-element physical address space (PAS), MAP: VAS →PAS∪∅ MAP(A)=/braceleftbiggA/primeif data virtual addr Ais present physical addr A/primein PAS ∅ data virtual addr Ais present physical memory Figure 9.12 shows MMU uses page table perform mapping. control register CPU, page table base register (PTBR) points current page table. n-bit virtual address two components: p-bit virtual page offset (VPO) (n−p)-bitvirtual page number (VPN). MMU uses VPN select appropriate PTE. example, VPN 0 selects PTE 0, VPN 1selects PTE 1, on. corresponding physical address concatenationof physical page number (PPN) page table entry VPO fromSection 9.6 Address Translation 789 Page table base register (PTBR) Physical addressVirtual address Virtual page number (VPN) Virtual page offset (VPO) Page tableValid Physical page number (PPN) VPN acts index intothe page table valid /H11005 0 pagenot memory(page fault)Physical page number (PPN) Physical page offset (PPO)n/H110021 pp /H110021 pp /H1100210 m/H110021 0 Figure 9.12 Address translation page table. virtual address. Notice since physical virtual pages P bytes, physical page offset (PPO) identical VPO. Figure 9.13(a) shows steps CPU hardware performs page hit. .Step 1: processor generates virtual address sends MMU. .Step 2: MMU generates PTE address requests cache/main memory. .Step 3: cache/main memory returns PTE MMU. .Step 3: MMU constructs physical address sends cache/main memory. .Step 4: cache/main memory returns requested data word pro- cessor. Unlike page hit, handled entirely hardware, handling page fault requires cooperation hardware operating system kernel(Figure 9.13(b)). .Steps 1 3: Steps 1 3 Figure 9.13(a). .Step 4: valid bit PTE zero, MMU triggers exception, transfers control CPU page fault exception handler theoperating system kernel. .Step 5: fault handler identiﬁes victim page physical memory, page modiﬁed, pages disk. .Step 6: fault handler pages new page updates PTE memory.790 Chapter 9 Virtual Memory 5CPU chip Processor MMU VA Data (a) Page hitPAPTEPTEA2 13 4Cache/ memory CPU chip Processor MMU Disk VAPTEVictim page New pagePTEA2Exception4 1 75 63 Cache/ memoryPage fault exception handler (b) Page fault Figure 9.13 Operational view page hits page faults. VA: virtual address. PTEA: page table entry address. PTE: page table entry. PA: physical address. .Step 7: fault handler returns original process, causing faulting instruction restarted. CPU resends offending virtual address MMU. virtual page cached physical memory, thereis hit, MMU performs steps Figure 9.13(b), main memory returns requested word processor. Practice Problem 9.3 Given 32-bit virtual address space 24-bit physical address, determine thenumber bits VPN, VPO, PPN, PPO following page sizes P: P No. VPN bits No. VPO bits No. PPN bits No. PPO bits 1K B 2K B 4K B 8K BSection 9.6 Address Translation 791 CPU chip Processor MMU Memory VA DataL1 CachePAPTEAPTE PTE PTEA PA DataPTEA hit PA hitPTEA miss PA miss Figure 9.14 Integrating VM physically addressed cache. VA: virtual address. PTEA: page table entry address. PTE: page table entry. PA: physical address. 9.6.1 Integrating Caches VM system uses virtual memory SRAM caches, issue whether use virtual physical addresses access SRAM cache.Although detailed discussion trade-offs beyond scope here, mostsystems opt physical addressing. physical addressing, straightforwardfor multiple processes blocks cache time shareblocks virtual pages. Further, cache dealwith protection issues access rights checked part addresstranslation process. Figure 9.14 shows physically addressed cache might integrated virtual memory. main idea address translation occurs thecache lookup. Notice page table entries cached, like otherdata words. 9.6.2 Speeding Address Translation TLB seen, every time CPU generates virtual address, MMU must refer PTE order translate virtual address physical address. Inthe worst case, requires additional fetch memory, cost tensto hundreds cycles. PTE happens cached L1, cost goesdown one two cycles. However, many systems try eliminate even costby including small cache PTEs MMU called translation lookaside buffer (TLB). TLB small, virtually addressed cache line holds block consisting single PTE. TLB usually high degree associativity. Asshown Figure 9.15, index tag ﬁelds used set selection linematching extracted virtual page number virtual address. theTLB T=2 tsets, TLB index (TLBI) consists tleast signiﬁcant bits VPN, TLB tag (TLBT) consists remaining bits VPN.792 Chapter 9 Virtual Memory Figure 9.15 Components virtualaddress used toaccess TLB.n/H110021 p/H11001tp p /H1100210 p/H11001t/H110021 TLB tag (TLBT) TLB index (TLBI) VPO VPN Figure 9.16(a) shows steps involved TLB hit (the usual case). key point address translation steps performedinside on-chip MMU, thus fast. .Step 1: CPU generates virtual address. .Steps 2 3: MMU fetches appropriate PTE TLB. .Step 4: MMU translates virtual address physical address sends cache/main memory. .Step 5: cache/main memory returns requested data word CPU. TLB miss, MMU must fetch PTE L1 cache, shown Figure 9.16(b). newly fetched PTE stored TLB, possiblyoverwriting existing entry. 9.6.3 Multi-Level Page Tables point assumed system uses single page table address translation. 32-bit address space, 4 KB pages, 4-byte PTE, would nee da4M B page table resident memory times, even application referenced small chunk virtual address space. Theproblem compounded systems 64-bit address spaces. common approach compacting page table use hierarchy page tables instead. idea easiest understand concrete example.Consider 32-bit virtual address space partitioned 4 KB pages, pagetable entries 4 bytes each. Suppose also point time virtualaddress space following form: ﬁrst 2K pages memory allocatedfor code data, next 6K pages unallocated, next 1023 pages also unallocated, next page allocated user stack. Figure 9.17 shows might construct two-level page table hierarchy virtual addressspace. PTE level-1 table responsible mappin ga4M B chunk virtual address space, chunk consists 1024 contiguous pages. Forexample, PTE 0 maps ﬁrst chunk, PTE 1 next chunk, on. Giventhat address space 4 GB, 1024 PTEs sufﬁcient cover entire space. every page chunk iis unallocated, level 1 PTE iis null. example, Figure 9.17, chunks 2–7 unallocated. However, least one page chunk allocated, level 1 PTE ipoints base level 2 page table. example, Figure 9.17, portions chunks 0, 1, 8 allocated, theirlevel 1 PTEs point level 2 page tables.Section 9.6 Address Translation 793 2 13 4 5CPU chip Processor Trans- lationTLB Cache/ memory VAVPN PTE Data (a) TLB hitPA 2 14 3 5 6 (b) TLB missCPU chip Processor Trans- lationTLB Cache/ memory VA PAVPNPTE DataPTEA Figure 9.16 Operational view TLB hit miss. PTE level 2 page table responsible mappin ga4K B page virtual memory, looked single-level page tables. Noticethat 4-byte PTEs, level 1 level 2 page table 4K bytes, whichconveniently size page. scheme reduces memory requirements two ways. First, PTE level 1 table null, corresponding level 2 page table even exist. represents signiﬁcant potential savings, since 4 GB virtualaddress space typical program unallocated. Second, level 1 tableneeds main memory times. level 2 page tables created and794 Chapter 9 Virtual Memory. . .VP 1023 VP 1024 VP 2047 GapPTE 0 PTE 1 PTE 2 (null)VP 0 1023 unallocated pagesPTE 3 (null) PTE 4 (null)PTE 5 (null)PTE 6 (null)PTE 0 PTE 1023PTE 0 PTE 1023 1023 null PTEsPTE 7 (null) PTE 8 (1K– 9) null PTEs PTE 1023. . . . . . VP 92152K allocated VM pages code data 6K unallocated VM page 1023 unallocated pages 1 allocated VM page stackVirtual memoryLevel 2 page tablesLevel 1 page table 0 . . . . . . Figure 9.17 two-level page table hierarchy. Notice addresses increase top bottom. paged VM system needed, reduces pressure main memory. heavily used level 2 page tables need cached main memory. Figure 9.18 summarizes address translation k-level page table hierarchy. virtual address partitioned kVPNs VPO. VPN i,1≤i≤k, index page table level i. PTE level- jtable, 1 ≤j≤k−1, points base page table level j+1. PTE level- ktable contains either PPN physical page address disk block.To construct physical address, MMU must access kPTEs determine PPN. single-level hierarchy, PPO identical theVPO. Accessing kPTEs may seem expensive impractical ﬁrst glance. How- ever, TLB comes rescue caching PTEs page tables atthe different levels. practice, address translation multi-level page tables isnot signiﬁcantly slower single-level page tables. 9.6.4 Putting Together: End-to-end Address Translation section, put together concrete example end-to-end address translation small system TLB L1 d-cache. keep thingsmanageable, make following assumptions: .The memory byte addressable. .Memory accesses 1-byte words (not 4-byte words).Section 9.6 Address Translation 795 Figure 9.18 Address translation withak-level page table. PPN PPO. . . . . . . . . m/H110021n/H110021 p/H1100210 p/H1100210Virtual address Physical addressVPN 1 VPN 2 VPN k VPO Level 1 page tableLevel 2 page tableLevel k page table PPN .Virtual addresses 14 bits wide ( n=14). .Physical addresses 12 bits wide ( m=12). .The page size 64 bytes ( P=64). .The TLB four-way set associative 16 total entries. .The L1 d-cache physically addressed direct mapped, 4-byte line size 16 total sets. Figure 9.19 shows formats virtual physical addresses. Since page 26=64 bytes, low-order 6 bits virtual physical addresses serve VPO PPO respectively. high-order 8 bits virtual address serve VPN. high-order 6 bits physical address serve PPN. Figure 9.20 shows snapshot little memory system, including TLB (Figure 9.20(a)), portion page table (Figure 9.20(b)), L1 cache(Figure 9.20(c)). ﬁgures TLB cache, also shownhow bits virtual physical addresses partitioned hardwareas accesses devices. 13 12 11 10 9 8 7 6 5 4 3 2 1 0 VPN (Virtual page number)VPO (Virtual page offset)Virtual address 1 1 1 0 987 65432 10 PPN (Physical page number)PPO (Physical page offset)Physical address Figure 9.19 Addressing small memory system. Assume 14-bit virtual addresses (n=14), 12-bit physical addresses ( m=12), 64-byte pages ( P=64).13 0312 11 10 9 8 7 6 5 4 3 2 1 0 VPNTLBT TLBI (a) TLB: Four sets, 16 entries, four-way set associativeVPOVirtual address 03 02 07/H11002 2D /H11002 /H110020 1 0 009 02 08 030D /H11002 /H11002 0D1 0 0 100 04 06 0A/H11002 /H11002 /H11002 340 0 0 107 0A 03 0202 /H11002 /H11002 /H110021Tag 0 1 2 3Set PPN Valid Tag PPN Valid Tag PPN Valid Tag PPN Valid 0 0 0 28 — 33 021 0 1 1 — 16 — —04 05 06 070 1 0 0PPN 00 01 02 03VPN Valid 13 17 09 /H110021 1 1 0 /H11002 2D 11 0D0C 0D 0E 0F0 1 1 1PPN 08 09 0A 0BVPN Valid (b) Page table: first 16 PTEs shown 19 15 1B 361 0 10 32 0D 31 164 5 6 71 1 0 1 24 1 2D 02D 1 0B 0 12 0 16 1 13 1 148 9 B CD E F0Tag 0 1 2 3Idx Valid 99 — 00 —11 — 02 — 43 36 — 116D 72 — C2 3A 00 —— 93 15 —— —— 04 96 83 77 ——Blk 0 Blk 1 23 — 04 —11 — 08 — 8F F0 — DF09 1D — 03 51 89 —— DA 3B —— —— 34 15 1B D3 ——Blk 2 Blk 31 1 1 0 987 6543210 PPNCT CI CO PPOPhysical address (c) Cache: Sixteen sets, 4-byte blocks, direct mapped Figure 9.20 TLB, page table, cache small memory system. values TLB, page table, cache hexadecimal notation.Section 9.6 Address Translation 797 .TLB : TLB virtually addressed using bits VPN. Since TLB four sets, 2 low-order bits VPN serve set index (TLBI).The remaining 6 high-order bits serve tag (TLBT) distinguishesthe different VPNs might map TLB set. .Page table. page table single-level design total 28=256 page table entries (PTEs). However, interested ﬁrst sixteen ofthese. convenience, labeled PTE VPN indexesit; keep mind VPNs part page table notstored memory. Also, notice PPN invalid PTE denotedwith dash reinforce idea whatever bit values might happen bestored meaningful. .Cache. direct-mapped cache addressed ﬁelds physical address. Since block 4 bytes, low-order 2 bits physical addressserve block offset (CO). Since 16 sets, next 4 bits serve asthe set index (CI). remaining 6 bits serve tag (CT). Given initial setup, let’s see happens CPU executes load instruction reads byte address 0x03d4 . (Recall hypothetical CPU reads one-byte words rather four-byte words.) begin kind manual simulation, ﬁnd helpful write bits virtual address,identify various ﬁelds need, determine hex values. Thehardware performs similar task decodes address. TLBT TLBI 0x03 0x03 bit position 13 12 11 1 09876543210 VA = 0x03d4 0000 1 1 1 1 010100 VPN VPO 0x0f 0x14 begin, MMU extracts VPN ( 0x0F ) virtual address checks TLB see cached copy PTE 0x0F previous memory reference. TLB extracts TLB index ( 0x03 ) TLB tag ( 0x3) VPN, hits valid match second entry Set 0x3, returns cached PPN ( 0x0D ) MMU. TLB missed, MMU would need fetch PTE main memory. However, case got lucky TLB hit. MMU haseverything needs form physical address. concatenating thePPN ( 0x0D ) PTE VPO ( 0x14 ) virtual address, forms physical address ( 0x354 ). Next, MMU sends physical address cache, extracts cache offset CO ( 0x0), cache set index CI ( 0x5), cache tag CT ( 0x0D ) physical address.798 Chapter 9 Virtual Memory CT CI CO 0x0d 0x05 0x0 bit position 11 1 09876543210 PA = 0x354 0 0 1101010100 PPN PPO 0x0d 0x14 Since tag Set 0x5matches CT, cache detects hit, reads data byte ( 0x36 ) offset CO, returns MMU, passes back CPU. paths translation process also possible. example, TLB misses, MMU must fetch PPN PTE page table.If resulting PTE invalid, page fault kernel must pagein appropriate page rerun load instruction. Another possibility thatthe PTE valid, necessary memory block misses cache. Practice Problem 9.4 Show example memory system Section 9.6.4 translates virtual addressinto physical address accesses cache. given virtual address,indicate TLB entry accessed, physical address, cache byte value returned.Indicate whether TLB misses, whether page fault occurs, whether cachemiss occurs. cache miss, enter “–” “Cache byte returned.” thereis page fault, enter “–” “PPN” leave parts C blank. Virtual address: 0x03d7 A. Virtual address format 1 3 1 2 1 1 1 0 9876543210 B. Address translation Parameter Value VPN TLB index TLB tag TLB hit? (Y/N) Page fault? (Y/N) PPN C. Physical address format 1 1 1 0 9876543210Section 9.7 Case Study: Intel Core i7/Linux Memory System 799 D. Physical memory reference Parameter Value Byte offset Cache index Cache tag Cache hit? (Y/N) Cache byte returned 9.7 Case Study: Intel Core i7/Linux Memory System conclude discussion virtual memory mechanisms case study real system: Intel Core i7 running Linux. Core i7 based Nehalemmicroarchitecture. Although Nehalem design allows full 64-bit virtual andphysical address spaces, current Core i7 implementations (and theforeseeable future) support 48-bit (256 TB) virtual address space 52-bit(4 PB) physical address space, along compatability mode supports 32-bit (4 GB) virtual physical address spaces. Figure 9.21 gives highlights Core i7 memory system. processor package includes four cores, large L3 cache shared cores, DDR3 memory controller 3 × 64 bit @ 10.66 GB/s 32 GB/s total (shared cores)L2 unified TLB 512 entries, 4-way Main memoryMMU (addr translation) cores I/O bridgeL1 i-TLB 128 entries, 4-wayL1 d-TLB 64 entries, 4-way L2 unified cache 256 KB, 8-way L3 unified cache 8 MB, 16-way (shared cores)L1 i-cache 32 KB, 8-wayL1 d-cache 32 KB, 8-wayInstruction fetchRegisters QuickPath interconnect 4 links @ 25.6 GB/s 102.4 GB/s totalProcessor package Core ×4 Figure 9.21 Core i7 memory system.800 Chapter 9 Virtual Memory DDR3 memory controller. core contains hierarchy TLBs, hierarchy data instruction caches, set fast point-to-point links, based onthe Intel QuickPath technology, communicating directly coresand external I/O bridge. TLBs virtually addressed, four-way setassociative. L1, L2, L3 caches physically addressed, eight-wayset associative, block size 64 bytes. page size conﬁgured atstart-up time either 4 KB 4 MB. Linux uses 4-KB pages. 9.7.1 Core i7 Address Translation Figure 9.22 summarizes entire Core i7 address translation process, time CPU generates virtual address data word arrives memory.The Core i7 uses four-level page table hierarchy. process privatepage table hierarchy. Linux process running, page tables associatedwith allocated pages memory-resident, although Core i7 architectureallows page tables swapped out. CR3 control register points beginning level 1 (L1) page table. value CR3 part process context, restored context switch.. . . . . .CPU VPN VPO36 12 TLBT TLBI32 4 VPN1 VPN2 PTE PTE PTE PTEPPN PPO40 1299 VPN3 VPN499TLB missVirtual address (VA) TLB hit L1 TLB (16 sets, 4 entries/set) Page tablesResult CR332/64 CT CI CO40 6 6L1 hit L1 d-cache (64 sets, 8 lines/set)L2, L3, main memory L1 miss Physical address (PA) Figure 9.22 Summary Core i7 address translation. simplicity, i-caches, i-TLB, L2 uniﬁed TLB shown.Section 9.7 Case Study: Intel Core i7/Linux Memory System 801 R/WU/SWT CDA PSG Page table physical base addr Unused Unused P=1 Available OS (page table location disk) P=00 1 2 3 XD63 4 5 6 7 89 1112 5152 62 Field Description P Child page table present physical memory (1) (0). R/W Read-only read-write access permission reachable pages.U/S User supervisor (kernel) mode access permission reachable pages.WT Write-through write-back cache policy child page table.CD Caching disabled enabled child page table.A Reference bit (set MMU reads writes, cleared software). PS Page size either 4 KB 4 MB (deﬁned Level 1 PTEs only).Base addr 40 signiﬁcant bits physical base address child page table. XD Disable enable instruction fetches pages reachable PTE. Figure 9.23 Format level 1, level 2, level 3 page table entries. entry reference sa4K B child page table. Figure 9.23 shows format entry level 1, level 2, level 3 page table. P=1 (which always case Linux), address ﬁeld contains 40-bit physical page number (PPN) points beginning theappropriate page table. Notice impose sa4K B alignment requirement page tables. Figure 9.24 shows format entry level 4 page table. P=1, address ﬁeld contains 40-bit PPN points base page inphysical memory. Again, impose sa4K B alignment requirement physical pages. PTE three permission bits control access page. R/W bit determines whether contents page read/write read/only. U/S bit, determines whether page accessed user mode, protectscode data operating system kernel user programs. XD (exe- cute disable) bit, introduced 64-bit systems, used disableinstruction fetches individual memory pages. important new fea-ture allows operating system kernel reduce risk buffer overﬂowattacks restricting execution read-only text segment. MMU translates virtual address, also updates two bits used kernel’s page fault handler. MMU sets Abit, known reference bit , time page accessed. kernel use reference bit implement page replacement algorithm. MMU sets bit, dirty bit , time page written to. page modiﬁed sometimes called dirty page . dirty bit tells kernel whether must write-back victim page copies replacement page. kernel cancall special kernel-mode instruction clear reference dirty bits.802 Chapter 9 Virtual Memory R/WU/SWT CDA 0D G Page physical base addr Unused Unused P=1 Available OS (page table location disk) P=00 1 2 3 XD63 4 5 6 7 89 1112 5152 62 Field Description P Child page present physical memory (1) (0). R/W Read-only read/write access permission child page.U/S User supervisor mode (kernel mode) access permission child page.WT Write-through write-back cache policy child page.CD Cache disabled enabled.A Reference bit (set MMU reads writes, cleared software). Dirty bit (set MMU writes, cleared software).G Global page (don’t evict TLB task switch). Base addr 40 signiﬁcant bits physical base address child page. XD Disable enable instruction fetches child page. Figure 9.24 Format level 4 page table entries. entry reference sa4K B child page. Figure 9.25 shows Core i7 MMU uses four levels page tables translate virtual address physical address. 36-bit VPN partitionedinto four 9-bit chunks, used offset page table. TheCR3 register contains physical address L1 page table. VPN 1 providesan offset L1 PTE, contains base address L2 page table. VPN2 provides offset L2 PTE, on. Aside Optimizing address translation discussion address translation, described sequential two-step process MMU (1) translates virtual address physical address, (2) passes physical address L1 cache. However, real hardware implementations use neat trick allows steps partially overlapped, thus speeding accesses L1 cache. example, virtual address ona Core i7 4 KB pages 12 bits VPO, bits identical 12 bits PPO corresponding physical address. Since eight-way set-associative physically addressed L1 caches 64 sets 64-byte cache blocks, physical address 6 (log 264) cache offset bits 6 (log264) index bits. 12 bits ﬁt exactly 12-bit VPO virtual address, accident! CPU needs virtual address translated, sends VPN MMU VPO L1 cache. MMU requesting page table entry TLB, L1 cache busy using VPO bits ﬁnd appropriate set read eight tags corresponding data words set. MMU gets PPN back TLB, cache ready try match PPN one eight tags.Section 9.7 Case Study: Intel Core i7/Linux Memory System 803 VPO L4 PT Page table 4 KB region per entry2 MB region per entry1 GB region per entry512 GB region per entryL3 PT Page middle directoryL2 PT Page upper directoryL1 PT Page global directory Physical address L1 PT Physical address pageCR3 Physical addressVirtual address PPNOffset physical andvirtual pageL4 PTE 401212 PPO1240 409L3 PTE40 9L2 PTE40 9L1 PTE40 9VPN 4 9 VPN 3 9 VPN 2 9 VPN 1 9 Figure 9.25 Core i7 page table translation. Legend: PT: page table, PTE: page table entry, VPN: virtual page number, VPO: virtual page offset, PPN: physical page number, PPO: physical page offset. Linux names four levels page tables also shown. 9.7.2 Linux Virtual Memory System virtual memory system requires close cooperation hardware kernel. Details vary version version, complete description isbeyond scope. Nonetheless, aim section describe enough Linux virtual memory system give sense real operating systemorganizes virtual memory handles page faults. Linux maintains separate virtual address space process form shown Figure 9.26. seen picture number times already, withits familiar code, data, heap, shared library, stack segments. weunderstand address translation, ﬁll details kernelvirtual memory lies user stack. kernel virtual memory contains code data structures kernel. regions kernel virtual memory mapped physical pages thatare shared processes. example, process shares kernel’s codeand global data structures. Interestingly, Linux also maps set contiguousvirtual pages (equal size total amount DRAM system) thecorresponding set contiguous physical pages. provides kernel aconvenient way access speciﬁc location physical memory, example,804 Chapter 9 Virtual Memory Figure 9.26 virtual memory aLinux process. 0x08048000 (32) 0x40000000 (64) 0Process-specific data structures (e.g., page tables, task mm structs, kernel stack) Physical memory Kernel code data Memory mapped region shared libraries Run-time heap (via malloc ) Uninitialized data ( .bss ) Initialized data ( .data ) Program text ( .text )User stackDifferent process Identical process Process virtualmemoryKernel virtualmemory %esp brk needs access page tables, perform memory-mapped I/O operations devices mapped particular physical memory locations. regions kernel virtual memory contain data differs process. Examples include page tables, stack kernel uses isexecuting code context process, various data structures keeptrack current organization virtual address space. Linux Virtual Memory Areas Linux organizes virtual memory collection areas (also called segments ). area contiguous chunk existing (allocated) virtual memory whose pagesare related way. example, code segment, data segment, heap,shared library segment, user stack distinct areas. existing virtualpage contained area, virtual page part area exist cannot referenced process. notion area isimportant allows virtual address space gaps. kernel keep track virtual pages exist, pages consumeany additional resources memory, disk, kernel itself. Figure 9.27 highlights kernel data structures keep track virtual memory areas process. kernel maintains distinct task structure ( task_ struct source code) process system. elements taskSection 9.7 Case Study: Intel Core i7/Linux Memory System 805 mmtask_struct pgdvm_end vm_start vm_prot vm_flags vm_next vm_end vm_start vm_prot vm_flags vm_next vm_endShared libraries 0Data Text vm_start vm_prot vm_flags vm_nextmmapmm_structvm_area_structProcess virtual memory Figure 9.27 Linux organizes virtual memory. structure either contain point information kernel needs run process (e.g., PID, pointer user stack, name executableobject ﬁle, program counter). One entries task structure points mm_struct charac- terizes current state virtual memory. two ﬁelds interest us arepgd, points base level 1 table (the page global directory), andmmap , points list vm_area_structs (area structs), characterizes area current virtual address space. kernel runsthis process, stores pgdin CR3 control register. purposes, area struct particular area contains following ﬁelds: .vm_start : Points beginning area .vm_end : Points end area .vm_prot : Describes read/write permissions pages contained area .vm_flags : Describes (among things) whether pages area shared processes private process .vm_next : Points next area struct list806 Chapter 9 Virtual Memory Linux Page Fault Exception Handling Suppose MMU triggers page fault trying translate virtual address A. exception results transfer control kernel’s page fault handler, performs following steps: 1.Is virtual address Alegal? words, Alie within area deﬁned area struct? answer question, fault handler searches list ofarea structs, comparing Awith vm_start andvm_end area struct. instruction legal, fault handler triggers segmentationfault, terminates process. situation labeled “1” Figure 9.28. process create arbitrary number new virtual memory areas (using mmap function described next section), sequential search list area structs might costly. practice, Linuxsuperimposes tree list, using ﬁelds shown, andperforms search tree. 2.Is attempted memory access legal? words, process permission read, write, execute pages area? example, page fault result store instruction trying write read-onlypage text segment? page fault result process runningin user mode attempting read word kernel virtual memory?If attempted access legal, fault handler triggers protec-tion exception, terminates process. situation labeled “2” inFigure 9.28. Process virtual memory Shared libraries Data TextSegmentation fault: accessing non-existing page Normal page fault Protection exception: e.g., violating permission writing read-only page1 3 2vm_area_struct 0vm_end vm_start r/o vm_next vm_end vm_start r/w vm_next vm_end vm_start r/o vm_next Figure 9.28 Linux page fault handling.Section 9.8 Memory Mapping 807 3.At point, kernel knows page fault resulted legal operation legal virtual address. handles fault selecting victimpage, swapping victim page dirty, swapping new page,and updating page table. page fault handler returns, CPUrestarts faulting instruction, sends Ato MMU again. time, MMU translates Anormally, without generating page fault. 9.8 Memory Mapping Linux (along forms Unix) initializes contents virtual memory area associating object disk, process known memory mapping . Areas mapped one two types objects: 1.Regular ﬁle Unix ﬁle system: area mapped contiguous section regular disk ﬁle, executable object ﬁle. ﬁle section divided page-sized pieces, piece containing initial contentsof virtual page. demand paging, none virtual pages isactually swapped physical memory CPU ﬁrst touches page (i.e., issues virtual address falls within page’s region addressspace). area larger ﬁle section, area padded withzeros. 2.Anonymous ﬁle: area also mapped anonymous ﬁle, created kernel, contains binary zeros. ﬁrst time CPU touchesa virtual page area, kernel ﬁnds appropriate victim pagein physical memory, swaps victim page dirty, overwrites thevictim page binary zeros, updates page table mark pageas resident. Notice data actually transferred disk andmemory. reason, pages areas mapped anonymous ﬁlesare sometimes called demand-zero pages . either case, virtual page initialized, swapped back forth special swap ﬁle maintained kernel. swap ﬁle also known swap space swap area . important point realize point time, swap space bounds total amount virtual pages beallocated currently running processes. 9.8.1 Shared Objects Revisited idea memory mapping resulted clever insight virtual memory system could integrated conventional ﬁle system, could provide simple efﬁcient way load programs data memory. seen, process abstraction promises provide process private virtual address space protected errant writesor reads processes. However, many processes identical read-onlytext areas. example, process runs Unix shell program tcsh text area. Further, many programs need access identical copies of808 Chapter 9 Virtual Memory Process 1 virtual memoryProcess 2 virtual memoryPhysical memory Shared object (a)Process 1 virtual memoryProcess 2 virtual memoryPhysical memory Shared object (b) Figure 9.29 shared object. (a) process 1 maps shared object. (b) process 2 maps shared object. (Note physical pages necessarily contiguous.) read-only run-time library code. example, every C program requires functions standard C library printf . would extremely wasteful process keep duplicate copies commonly used codes physicalmemory. Fortunately, memory mapping provides us clean mechanism forcontrolling objects shared multiple processes. object mapped area virtual memory either shared object private object . process maps shared object area virtual address space, writes process makes area visible toany processes also mapped shared object virtualmemory. Further, changes also reﬂected original object disk. Changes made area mapped private object, hand, visible processes, writes process makes areaarenotreﬂected back object disk. virtual memory area shared object mapped often called shared area . Similarly private area . Suppose process 1 maps shared object area virtual memory, shown Figure 9.29(a). suppose process 2 maps shared ob-ject address space (not necessarily virtual address process 1),as shown Figure 9.29(b). Since object unique ﬁle name, kernel quickly determine process 1 already mapped object point page table entriesin process 2 appropriate physical pages. key point singlecopy shared object needs stored physical memory, even though theobject mapped multiple shared areas. convenience, shown thephysical pages contiguous, course true general. Private objects mapped virtual memory using clever technique known copy-on-write . private object begins life exactly way aSection 9.8 Memory Mapping 809 Process 1 virtual memoryProcess 2 virtual memoryPhysical memory Private copy-on-write object (a)Process 1 virtual memoryProcess 2 virtual memoryPhysical memory Private copy-on-write object (b)copy-on-write Write private copy-on-write page Figure 9.30 private copy-on-write object. (a) processes mapped private copy-on-write object. (b) process 2 writes page private area. shared object, one copy private object stored physical memory. example, Figure 9.30(a) shows case two processes mapped aprivate object different areas virtual memories share samephysical copy object. process maps private object, pagetable entries corresponding private area ﬂagged read-only, thearea struct ﬂagged private copy-on-write . long neither process attempts write respective private area, continue share single copy theobject physical memory. However, soon process attempts write tosome page private area, write triggers protection fault. fault handler notices protection exception caused process trying write page private copy-on-write area, creates anew copy page physical memory, updates page table entry pointto new copy, restores write permissions page, shown inFigure 9.30(b). fault handler returns, CPU reexecutes write,which proceeds normally newly created page. deferring copying pages private objects last possible moment, copy-on-write makes efﬁcient use scarce physical memory. 9.8.2 Thefork Function Revisited understand virtual memory memory mapping, get clear idea fork function creates new process independent virtual address space. fork function called current process , kernel creates various data structures new process assigns unique PID. create virtual memory new process, creates exact copies current810 Chapter 9 Virtual Memory process’s mm_struct , area structs, page tables. ﬂags page processes read-only, ﬂags area struct processes private copy-on-write. fork returns new process, new process exact copy virtual memory existed fork called. eitherof processes performs subsequent writes, copy-on-write mechanismcreates new pages, thus preserving abstraction private address space foreach process. 9.8.3 Theexecve Function Revisited Virtual memory memory mapping also play key roles process loading programs memory. understand concepts, under-stand execve function really loads executes programs. Suppose program running current process makes following call: Execve("a.out", NULL, NULL); learned Chapter 8, execve function loads runs program contained executable object ﬁle a.out within current process, effectively replacing current program a.out program. Loading running a.out requires following steps: .Delete existing user areas. Delete existing area structs user portion current process’s virtual address. .Map private areas. Create new area structs text, data, bss, stack areas new program. new areas private copy-on-write.The text data areas mapped text data sections a.out ﬁle. bss area demand-zero, mapped anonymous ﬁle whose size iscontained a.out . stack heap area also demand-zero, initially zero-length. Figure 9.31 summarizes different mappings privateareas. .Map shared areas. a.out program linked shared objects, standard C library libc.so , objects dynamically linked program, mapped shared region user’s virtualaddress space. .Set program counter (PC). last thing execve set program counter current process’s context point entry pointin text area. next time process scheduled, begin execution entry point. Linux swap code data pages needed. 9.8.4 User-level Memory Mapping mmap Function Unix processes use mmap function create new areas virtual memory map objects areas.Section 9.8 Memory Mapping 811 Figure 9.31 loader maps theareas user addressspace. Memory mapped region shared librariesUser stack 0Run-time heap (via malloc) Uninitialized data ( .bss ) Initialized data ( .data ) Program text ( .text )Private, demand-zer Shared, file-backed Private, demand-zer Private, demand-zer Private, file-backed.data .textlibc.so .data .texta.out #include <unistd.h> #include <sys/mman.h> void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); Returns: pointer mapped area OK, MAP_FAILED ( −1) error Themmap function asks kernel create new virtual memory area, preferably one starts address start , map contiguous chunk object speciﬁed ﬁle descriptor fdto new area. contiguous object chunk size length bytes starts offset offset bytes beginning ﬁle. start address merely hint, usually speciﬁed NULL. purposes, always assume NULL start address. Figure 9.32depicts meaning arguments. Theprot argument contains bits describe access permissions newly mapped virtual memory area (i.e., vm_prot bits corresponding area struct). .PROT_EXEC: Pages area consist instructions may executedby CPU. .PROT_READ: Pages area may read. .PROT_WRITE: Pages area may written. .PROT_NONE: Pages area cannot accessed.812 Chapter 9 Virtual Memory Figure 9.32 Visual interpretation mmap arguments. length (bytes)length (bytes) offset (bytes) Disk file specified file descriptor fdProcess virtual memorystart (or address chosen kernel) 0 0 Theflags argument consists bits describe type mapped object. MAP_ANON ﬂag bit set, backing store anonymousobject corresponding virtual pages demand-zero. MAP_PRIVATEindicates private copy-on-write object, MAP_SHARED indicates sharedobject. example, bufp = Mmap(-1, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0); asks kernel create new read-only, private, demand-zero area virtualmemory containing size bytes. call successful, bufp contains address new area. Themunmap function deletes regions virtual memory: #include <unistd.h> #include <sys/mman.h> int munmap(void *start, size_t length); Returns: 0 OK, −1 error Themunmap function deletes area starting virtual address start consist- ing next length bytes. Subsequent references deleted region result segmentation faults. Practice Problem 9.5 Writ e C program mmapcopy.c uses mmap copy arbitrary-sized disk ﬁle stdout . name input ﬁle passed command line argument. 9.9 Dynamic Memory Allocation certainly possible use low-level mmap andmunmap functions create delete areas virtual memory, C programmers typically ﬁnd moreSection 9.9 Dynamic Memory Allocation 813 Figure 9.33 heap. Memory mapped region shared librariesUser stack 0Heap Uninitialized data ( .bss ) Initialized data ( .data ) Program text ( .text )Top heap (brk ptr ) convenient portable use dynamic memory allocator need acquire additional virtual memory run time. dynamic memory allocator maintains area process’s virtual memory known heap (Figure 9.33). Details vary system system, without loss generality, assume heap area demand-zero mem-ory begins immediately uninitialized bss area grows upward(toward higher addresses). process, kernel maintains variable brk (pronounced “break”) points top heap. allocator maintains heap collection various-sized blocks . block contiguous chunk virtual memory either allocated orfree.A n allocated block explicitly reserved use application. free blockis available allocated. free block remains free explicitly allocated application. allocated block remains allocated freed, eitherexplicitly application, implicitly memory allocator itself. Allocators come two basic styles. styles require application explicitly allocate blocks. differ entity responsible freeingallocated blocks. .Explicit allocators require application explicitly free allocated blocks. example, C standard library provides explicit allocatorcalled malloc package. C programs allocate block calling malloc function, free block calling free function. newanddelete calls C++are comparable. .Implicit allocators , hand, require allocator detect allocated block longer used program free block. Implicit allocators also known garbage collectors , the814 Chapter 9 Virtual Memory process automatically freeing unused allocated blocks known garbage collection . example, higher-level languages Lisp, ML, Java rely garbage collection free allocated blocks. remainder section discusses design implementation explicit allocators. discuss implicit allocators Section 9.10. concrete-ness, discussion focuses allocators manage heap memory. However,you aware memory allocation general idea arises vari-ety contexts. example, applications intensive manipulation graphswill often use standard allocator acquire large block virtual memory,and use application-speciﬁc allocator manage memory within thatblock nodes graph created destroyed. 9.9.1 Themalloc andfree Functions C standard library provides explicit allocator known malloc package. Programs allocate blocks heap calling malloc function. #include <stdlib.h> void *malloc(size_t size); Returns: ptr allocated block OK, NULL error Themalloc function returns pointer block memory least size bytes suitably aligned kind data object might contained theblock. Unix systems familiar with, malloc returns block aligned 8-byte (double word) boundary. Aside big word? Recall discussion machine code Chapter 3 Intel refers 4-byte objects double words . However, throughout section, assume words 4-byte objects double words 8-byte objects, consistent conventional terminology. Ifmalloc encounters problem (e.g., program requests block memory larger available virtual memory), returns NULL sets errno .Malloc initialize memory returns. Applications want initialized dynamic memory use calloc , thin wrapper around malloc function initializes allocated memory zero. Applications want tochange size previously allocated block use realloc function. Dynamic memory allocators malloc allocate deallocate heap memory explicitly using mmap andmunmap functions, use sbrk function:Section 9.9 Dynamic Memory Allocation 815 #include <unistd.h> void *sbrk(intptr_t incr); Returns: old brkpointer success, −1 error Thesbrk function grows shrinks heap adding incr kernel’s brk pointer. successful, returns old value brk, otherwise returns −1 setserrno ENOMEM. incr zero, sbrk returns current value brk. Calling sbrk negative incr legal tricky return value (the old value brk) points abs(incr) bytes past new top heap. Programs free allocated heap blocks calling free function. #include <stdlib.h> void free(void *ptr); Returns: nothing Theptr argument must point beginning allocated block obtained malloc ,calloc ,o rrealloc . not, behavior free undeﬁned. Even worse, since returns nothing, free gives indication application something wrong. shall see Section 9.11, canproduce bafﬂing run-time errors. Figure 9.34 shows implementation malloc andfree might manage (very) small heap 16 words fo r C program. box represents 4-byte word. heavy-lined rectangles correspond allocated blocks (shaded) andfree blocks (unshaded). Initially, heap consists single 16-word double-word aligned free block. .Figure 9.34(a): program asks four-word block. Malloc responds carving four-word block front free block returninga pointer ﬁrst word block. .Figure 9.34(b): program requests ﬁve-word block. Malloc responds allocating six-word block front free block. example,malloc pads block extra word order keep free block aligned double-word boundary. .Figure 9.34(c): program requests six-word block malloc responds carving six-word block free block. .Figure 9.34(d): program frees six-word block allocated Figure 9.34(b). Notice call free returns, pointer p2still points freed block. responsibility application usep2again reinitialized new call malloc .816 Chapter 9 Virtual Memory p1 (a)p1 = malloc(4*sizeof(int)) p1 p2 (b)p2 = malloc(5*sizeof(int)) p1 p2 p3 (c)p3 = malloc(6*sizeof(int)) p1 p2 p3 (d)free(p2) p1 p2p4 p3 (e)p4 = malloc(2*sizeof(int)) Figure 9.34 Allocating freeing blocks malloc andfree .Each square corresponds word. heavy rectangle corresponds block. Allocated blocks shaded. Padded regions allocated blocks shaded stripes. Free blocks unshaded. Heap addresses increase left right. .Figure 9.34(e): program requests two-word block. case, malloc allocates portion block freed previous step returnsa pointer new block. 9.9.2 Dynamic Memory Allocation? important reason programs use dynamic memory allocation often know sizes certain data structures program actually runs. example, suppose asked writ e C program reads list nASCII integers, one integer per line, stdin C array. input consists integer n, followed nintegers read stored array. simplest approach deﬁne array statically somehard-coded maximum array size: 1#include "csapp.h" 2#define MAXN 15213 3 4int array[MAXN];Section 9.9 Dynamic Memory Allocation 817 5 6int main() 7{ 8 int i, n; 9 10 scanf("%d", &n); 11 (n > MAXN) 12 app_error("Input file big"); 13 f r( i=0 ;i<n ; i++) 14 scanf("%d", &array[i]); 15 exit(0); 16 } Allocating arrays hard-coded sizes like often bad idea. value MAXN arbitrary relation actual amount available virtualmemory machine. Further, user program wanted read ﬁlethat larger MAXN, recourse would recompile programwith larger value MAXN. problem simple example, thepresence hard-coded array bounds become maintenance nightmare forlarge software products millions lines code numerous users. better approach allocate array dynamically, run time, value nbecomes known. approach, maximum size array limited amount available virtual memory. 1#include "csapp.h" 2 3int main() 4{ 5 int *array, i, n; 6 7 scanf("%d", &n); 8 array = (int *)Malloc(n * sizeof(int)); 9 f r( i=0 ;i<n ; i++) 10 scanf("%d", &array[i]); 11 exit(0); 12 } Dynamic memory allocation useful important programming tech- nique. However, order use allocators correctly efﬁciently, programmersneed understanding work. discuss grue-some errors result improper use allocators Section 9.11. 9.9.3 Allocator Requirements Goals Explicit allocators must operate within rather stringent constraints. .Handling arbitrary request sequences. application make arbitrary sequence allocate free requests, subject constraint each818 Chapter 9 Virtual Memory free request must correspond currently allocated block obtained previous allocate request. Thus, allocator cannot make assumptionsabout ordering allocate free requests. example, allocatorcannot assume allocate requests accompanied matching freerequest, matching allocate free requests nested. .Making immediate responses requests. allocator must respond imme- diately allocate requests. Thus, allocator allowed reorder orbuffer requests order improve performance. .Using heap. order allocator scalable, non-scalar data structures used allocator must stored heap itself. .Aligning blocks (alignment requirement). allocator must align blocks way hold type data object. systems, thismeans block returned allocator aligned 8-byte (double-word) boundary. .Not modifying allocated blocks. Allocators manipulate change free blocks. particular, allowed modify move blocks theyare allocated. Thus, techniques compaction allocated blocks notpermitted. Working within constraints, author allocator attempts meet often conﬂicting performance goals maximizing throughput memoryutilization. .Goal 1: Maximizing throughput. Given sequence nallocate free requests R0,R1,...,Rk,...,Rn−1 would like maximize allocator’s throughput , deﬁned number requests completes per unit time. example, allo- cator completes 500 allocate requests 500 free requests 1 second, thenits throughput 1,000 operations per second. general, maximize throughput minimizing average time satisfy allocate free re-quests. we’ll see, difﬁcult develop allocators reasonablygood performance worst-case running time allocate requestis linear number free blocks running time free requestis constant. .Goal 2: Maximizing memory utilization. Naive programmers often incorrectly assume virtual memory unlimited resource. fact, total amountof virtual memory allocated processes system limited amount swap space disk. Good programmers know virtual memoryis ﬁnite resource must used efﬁciently. especially true fora dynamic memory allocator might asked allocate free largeblocks memory. number ways characterize efﬁciently allocator uses heap. experience, useful metric peak utilization .A sSection 9.9 Dynamic Memory Allocation 819 before, given sequence nallocate free requests R0,R1,...,R k,...,R n−1 application requests block pbytes, resulting allocated block payload ofpbytes. request Rkhas completed, let aggregate payload , denoted Pk, sum payloads currently allocated blocks, let Hkdenote current (monotonically nondecreasing) size heap. peak utilization ﬁrst krequests, denoted Uk,i given Uk=maxi≤kPi Hk objective allocator maximize peak utilization Un−1 entire sequence. see, tension maximiz- ing throughput utilization. particular, easy write allocatorthat maximizes throughput expense heap utilization. One in-teresting challenges allocator design ﬁnding appropriate balancebetween two goals. Aside Relaxing monotonicity assumption could relax monotonically nondecreasing assumption deﬁnition Ukand allow heap grow letting Hkbe highwater mark ﬁrst krequests. 9.9.4 Fragmentation primary cause poor heap utilization phenomenon known fragmen- tation , occurs otherwise unused memory available satisfy allocate requests. two forms fragmentation: internal fragmentation external fragmentation . Internal fragmentation occurs allocated block larger pay- load. might happen number reasons. example, implementationof allocator might impose minimum size allocated blocks greaterthan requested payload. Or, saw Figure 9.34(b), allocator mightincrease block size order satisfy alignment constraints. Internal fragmentation straightforward quantify. simply sum differences sizes allocated blocks payloads. Thus, point time, amount internal fragmentation depends pattern previous requests allocator implementation. External fragmentation occurs isenough aggregate free memory satisfy allocate request, single free block large enough handle therequest. example, request Figure 9.34(e) six words rather thantwo words, request could satisﬁed without requesting additionalvirtual memory kernel, even though six free words remaining820 Chapter 9 Virtual Memory heap. problem arises six words spread two free blocks. External fragmentation much difﬁcult quantify internal frag- mentation depends pattern previous requests theallocator implementation, also pattern future requests. example, suppose krequests free blocks exactly four words size. heap suffer external fragmentation? answer depends thepattern future requests. future allocate requests blocks smaller equal four words, external fragmentation.On hand, one requests ask blocks larger four words,then heap suffer external fragmentation. Since external fragmentation difﬁcult quantify impossible predict, allocators typically employ heuristics attempt maintain small numbers oflarger free blocks rather large numbers smaller free blocks. 9.9.5 Implementation Issues simplest imaginable allocator would organize heap large array bytes pointer pthat initially points ﬁrst byte array. allocate size bytes, malloc would save current value pon stack, increment pby size , return old value pto caller. Free would simply return caller without anything. naive allocator extreme point design space. Since malloc andfree execute handful instructions, throughput would extremely good. However, since allocator never reuses blocks, memory utilizationwould extremely bad. practical allocator strikes better balance betweenthroughput utilization must consider following issues: .Free block organization: keep track free blocks? .Placement: choose appropriate free block place newly allocated block? .Splitting: place newly allocated block free block, remainder free block? .Coalescing: block freed? rest section looks issues detail. Since basic techniques placement, splitting, coalescing cut across many different freeblock organizations, introduce context simple free block organization known implicit free list. 9.9.6 Implicit Free Lists practical allocator needs data structure allows distinguish block boundaries distinguish allocated free blocks. Mostallocators embed information blocks themselves. One simple approachis shown Figure 9.35.Section 9.9 Dynamic Memory Allocation 821 Header Block size Payload (allocated block only) Padding (optional)0 0 block size includes header, payload, andany paddinga = 1: Allocated = 0: Free malloc returns pointer beginningof payload31 3 2 1 0 Figure 9.35 Format simple heap block. case, block consists one-word header , payload, possibly additional padding .T h e header encodes block size (including header padding) well whether block allocated free. imposea double-word alignment constraint, block size always multiple ofeight 3 low-order bits block size always zero. Thus, need tostore 29 high-order bits block size, freeing remaining 3 bitsto encode information. case, using least signiﬁcant ofthese bits (the allocated bit ) indicate whether block allocated free. example, suppose allocated block block size 24 ( 0x18 ) bytes. header would 0x00000018 | 0x1 = 0x00000019 Similarly, free block block size 40 ( 0x28 ) bytes would header 0x00000028 | 0x0 = 0x00000028 header followed payload application requested called malloc . payload followed chunk unused padding size. number reasons padding. example, paddingmight part allocator’s strategy combating external fragmentation. Orit might needed satisfy alignment requirement. Given block format Figure 9.35, organize heap sequence contiguous allocated free blocks, shown Figure 9.36. Unused Start heap8/0 16/1 32/0 16/1 0/1Double- word aligned Figure 9.36 Organizing heap implicit free list. Allocated blocks shaded. Free blocks unshaded. Headers labeled (size (bytes)/allocated bit).822 Chapter 9 Virtual Memory call organization implicit free list free blocks linked implicitly size ﬁelds headers. allocator indirectly traversethe entire set free blocks traversing allof blocks heap. Notice need kind specially marked end block, example terminatingheader allocated bit set size zero. (As see Section 9.9.12,setting allocated bit simpliﬁes coalescing free blocks.) advantage implicit free list simplicity. signiﬁcant disadvantage cost operation, placing allocated blocks, requires asearch free list linear total number allocated free blocks heap. important realize system’s alignment requirement allocator’s choice block format impose minimum block size allocator. allocated free block may smaller minimum. example, weassume double-word alignment requirement, size block must multiple two words (8 bytes). Thus, block format Figure 9.35 inducesa minimum block size two words: one word header, another maintain alignment requirement. Even application request asingle byte, allocator would still create two-word block. Practice Problem 9.6 Determine block sizes header values would result followingsequence malloc requests. Assumptions: (1) allocator maintains double- word alignment, uses implicit free list block format Fig- ure 9.35. (2) Block sizes rounded nearest multiple 8 bytes. Request Block size (decimal bytes) Block header (hex) malloc(1) malloc(5) malloc(12) malloc(13) 9.9.7 Placing Allocated Blocks application requests block kbytes, allocator searches free list free block large enough hold requested block. mannerin allocator performs search determined placement policy . common policies ﬁrst ﬁt ,next ﬁt , best ﬁt . First ﬁt searches free list beginning chooses ﬁrst free block ﬁts. Next ﬁt similar ﬁrst ﬁt, instead starting search beginning list, starts search previous search left off.Best ﬁt examines every free block chooses free block smallest size ﬁts. advantage ﬁrst ﬁt tends retain large free blocks end list. disadvantage tends leave “splinters” small free blocksSection 9.9 Dynamic Memory Allocation 823 Unused Start heap8/0 16/1 16/1 16/1 16/0 0/1Double- word aligned Figure 9.37 Splitting free block satisfy three-word allocation request. Allocated blocks shaded. Free blocks unshaded. Headers labeled (size (bytes)/allocated bit). toward beginning list, increase search time larger blocks. Next ﬁt ﬁrst proposed Donald Knuth alternative ﬁrst ﬁt,motivated idea found ﬁt free block last time, thereis good chance ﬁnd ﬁt next time remainder block.Next ﬁt run signiﬁcantly faster ﬁrst ﬁt, especially front listbecomes littered many small splinters. However, studies suggest thatnext ﬁt suffers worse memory utilization ﬁrst ﬁt. Studies foundthat best ﬁt generally enjoys better memory utilization either ﬁrst ﬁt nextﬁt. However, disadvantage using best ﬁt simple free list organizationssuch implicit free list, requires exhaustive search heap.Later, look sophisticated segregated free list organizations thatapproximate best-ﬁt policy without exhaustive search heap. 9.9.8 Splitting Free Blocks allocator located free block ﬁts, must make another policy decision much free block allocate. One option usethe entire free block. Although simple fast, main disadvantage itintroduces internal fragmentation. placement policy tends produce goodﬁts, additional internal fragmentation might acceptable. However, ﬁt good, allocator usually opt split free block two parts. ﬁrst part becomes allocated block, theremainder becomes new free block. Figure 9.37 shows allocator mightsplit eight-word free block Figure 9.36 satisfy application’s request forthree words heap memory. 9.9.9 Getting Additional Heap Memory happens allocator unable ﬁnd ﬁt requested block? One option try create larger free blocks merging (coalescing) freeblocks physically adjacent memory (next section). However, thisdoes yield sufﬁciently large block, free blocks already maximallycoalesced, allocator asks kernel additional heap memory callingthesbrk function. allocator transforms additional memory one large free block, inserts block free list, places requested blockin new free block.824 Chapter 9 Virtual Memory Unused Start heap8/0 16/1 16/0 16/1 16/0 0/1Double- word aligned Figure 9.38 example false fragmentation. Allocated blocks shaded. Free blocks unshaded. Headers labeled (size (bytes)/allocated bit). 9.9.10 Coalescing Free Blocks allocator frees allocated block, might free blocks adjacent newly freed block. adjacent free blocks causea phenomenon known false fragmentation , lot available free memory chopped small, unusable free blocks. example, Figure 9.38shows result freeing block allocated Figure 9.37. resultis two adjacent free blocks payloads three words each. result, asubsequent request payload four words would fail, even though theaggregate size two free blocks large enough satisfy request. combat false fragmentation, practical allocator must merge adjacent free blocks process known coalescing . raises important policy decision perform coalescing. allocator opt immediate coalescing merging adjacent blocks time block freed. opt fordeferred coalescing waiting coalesce free blocks later time. example, allocator might defer coalescing allocation request fails,and scan entire heap, coalescing free blocks. Immediate coalescing straightforward performed constant time, request patterns introduce form thrashing block repeatedly coalesced split soon thereafter. example, Fig- ure 9.38 repeated pattern allocating freeing three-word block wouldintroduce lot unnecessary splitting coalescing. discussion allo-cators, assume immediate coalescing, aware fastallocators often opt form deferred coalescing. 9.9.11 Coalescing Boundary Tags allocator implement coalescing? Let us refer block want free current block . coalescing next free block (in memory) straightforward efﬁcient. header current block points headerof next block, checked determine next block free. so, size simply added size current header blocks arecoalesced constant time. would coalesce previous block? Given implicit free list blocks headers, option would search entire list, remember-ing location previous block, reached current block. anSection 9.9 Dynamic Memory Allocation 825 Figure 9.39 Format heap block thatuses boundary tag. Block size Payload (allocated block only) Padding (optional)a/fa = 001: Allocate = 000: Free Block size a/f31 3 2 1 0 Header Footer implicit free list, means call free would require time linear size heap. Even sophisticated free list organizations, searchtime would constant. Knuth developed clever general technique, known boundary tags , allows constant-time coalescing previous block. idea, isshown Figure 9.39, add footer (the boundary tag) end block, footer replica header. block includes footer, allocator determine starting location status previousblock inspecting footer, always one word away start current block. Consider cases exist allocator frees current block: 1.The previous next blocks allocated. 2.The previous block allocated next block free. 3.The previous block free next block allocated. 4.The previous next blocks free. Figure 9.40 shows would coalesce four cases. case 1, adjacent blocks allocated thus coalescing possible. status thecurrent block simply changed allocated free. case 2, current blockis merged next block. header current block footer ofthe next block updated combined sizes current next blocks.In case 3, previous block merged current block. header previous block footer current block updated combinedsizes two blocks. case 4, three blocks merged form singlefree block, header previous block footer next blockupdated combined sizes three blocks. case, coalescingis performed constant time. idea boundary tags simple elegant one generalizes many different types allocators free list organizations. However, isa potential disadvantage. Requiring block contain header footer introduce signiﬁcant memory overhead application manipulates826 Chapter 9 Virtual Memory m1 n m2 m2m1m1 f f n m2 m2 Case 1m1m1 f fn n m2 m2m1m1 f fn/H11001m2 n/H11001m2m1 Case 2 m1 f f n m2 m2m1n/H11001m1 f f an/H11001m1 m2 m2 Case 3m1 f f f fnn m2 m2m1n/H11001m1/H11001m2 f f n/H11001m1/H11001m2 Case 4 Figure 9.40 Coalescing boundary tags. Case 1: prev next allocated. Case 2: prev allocated, next free. Case 3: prev free, next allocated. Case 4: next prev free. many small blocks. example, graph application dynamically creates destroys graph nodes making repeated calls malloc andfree , graph node requires couple words memory, header footerwill consume half allocated block. Fortunately, clever optimization boundary tags eliminates need footer allocated blocks. Recall attempt coalescethe current block previous next blocks memory, size ﬁeld inthe footer previous block needed previous block free.I fw e store allocated/free bit previous block one excess low-order bits current block, allocated blocks would need footers, andwe could use extra space payload. Note, however, free blocks stillneed footers. Practice Problem 9.7 Determine minimum block size following combinations alignment requirements block formats. Assumptions: Implicit free list, zero- sized payloads allowed, headers footers stored 4-byte words.Section 9.9 Dynamic Memory Allocation 827 Alignment Allocated block Free block Minimum block size (bytes) Single word Header footer Header footer Single word Header, footer Header footer Double word Header footer Header footer Double word Header, footer Header footer 9.9.12 Putting Together: Implementing Simple Allocator Building allocator challenging task. design space large, nu- merous alternatives block format free list format, well placement,splitting, coalescing policies. Another challenge often forcedto program outside safe, familiar conﬁnes type system, relying theerror-prone pointer casting pointer arithmetic typical low-level sys-tems programming. allocators require enormous amounts code, subtle unforgiving. Students familiar higher-level languages C++ Javaoften hit conceptual wall ﬁrst encounter style programming. Tohelp clear hurdle, work implementation simpleallocator based implicit free list immediate boundary-tag coalescing. maximum block size 2 32=4 GB. code 64-bit clean, running without modiﬁcation 32-bit ( gcc -m32 ) 64-bit ( gcc -m64 ) processes. General Allocator Design allocator uses model memory system provided memlib.c package shown Figure 9.41. purpose model allow us runour allocator without interfering existing system-level malloc package. Themem_init function models virtual memory available heap large, double-word aligned array bytes. bytes mem_heap andmem_ brk represent allocated virtual memory. bytes following mem_brk represent unallocated virtual memory. allocator requests additional heap memory bycalling mem_sbrk function, interface system’s sbrk function, well semantics, except rejects requests shrinkthe heap. allocator contained source ﬁle ( mm.c ) users compile link applications. allocator exports three functions applica-tion programs: 1extern int mm_init(void); 2extern void *mm_malloc (size_t size); 3extern void mm_free (void *ptr); Themm_init function initializes allocator, returning 0 successful −1 otherwise. mm_malloc andmm_free functions interfaces semantics system counterparts. allocator uses block format828 Chapter 9 Virtual Memory code/vm/malloc/memlib.c 1/* Private global variables */ 2static char *mem_heap; /* Points first byte heap */ 3static char *mem_brk; /* Points last byte heap plus 1 */ 4static char *mem_max_addr; /* Max legal heap addr plus 1*/ 5 6/* 7 * mem_init - Initialize memory system model 8 */ 9void mem_init(void) 10 { 11 mem_heap = (char *)Malloc(MAX_HEAP); 12 mem_brk = (char *)mem_heap; 13 mem_max_addr = (char *)(mem_heap + MAX_HEAP); 14 } 1516 /* 17 * mem_sbrk - Simple model sbrk function. Extends heap 18 * incr bytes returns start address new area. 19 * model, heap cannot shrunk. 20 */ 21 void *mem_sbrk(int incr) 22 { 23 char *old_brk = mem_brk; 24 25 ( (incr < 0) || ((mem_brk + incr) > mem_max_addr)) { 26 errno = ENOMEM; 27 fprintf(stderr, "ERROR: mem_sbrk failed. Ran memory...\n"); 28 return (void *)-1; 29 } 30 mem_brk += incr; 31 return (void *)old_brk; 32 } code/vm/malloc/memlib.c Figure 9.41 memlib.c : Memory system model. shown Figure 9.39. minimum block size 16 bytes. free list organized implicit free list, invariant form shown Figure 9.42. ﬁrst word unused padding word aligned double-word boundary. padding followed special prologue block , 8-byte allocated block consisting header footer. prologue block createdduring initialization never freed. Following prologue block zeroor regular blocks created calls malloc orfree . heapSection 9.9 Dynamic Memory Allocation 829 Prologue blockRegular block 1Regular block 2 Start heap8/1 8/1 hdr hdr ftr ftrRegular block nEpilogue block hdr hdr ftr 0/1 static char *heap_listp Double- word aligned. . . Figure 9.42 Invariant form implicit free list. always ends special epilogue block , zero-sized allocated block consists header. prologue epilogue blocks tricks thateliminate edge conditions coalescing. allocator uses single private (static ) global variable ( heap_listp ) always points prologue block. (As minor optimization, could make point next block instead theprologue block.) Basic Constants Macros Manipulating Free List Figure 9.43 shows basic constants macros use throughoutthe allocator code. Lines 2–4 deﬁne basic size constants: sizes words(WSIZE) double words (DSIZE), size initial free block andthe default size expanding heap (CHUNKSIZE). Manipulating headers footers free list troublesome demands extensive use casting pointer arithmetic. Thus, ﬁndit helpful deﬁne small set macros accessing traversing free list (lines 9–25). PACK macro (line 9) combines size allocate bit andreturns value stored header footer. GET macro (line 12) reads returns word referenced argu- ment p. casting crucial. argument pis typically ( void * ) pointer, cannot dereferenced directly. Similarly, PUT macro (line 13) storesvalin word pointed argument p. GET_SIZE GET_ALLOC macros (lines 16–17) return size allocated bit, respectively, header footer address p. remaining macros operate block pointers (denoted bp) point ﬁrst payload byte. Given block pointer bp, HDRP FTRP macros (lines 20–21) return pointers block header footer, respectively. NEXT_BLKP andPREV_BLKP macros (lines 24–25) return block pointers next andprevious blocks, respectively. macros composed various ways manipulate free list. example, given pointer bpto current block, could use following line code determine size next block memory: size_t size = GET_SIZE(HDRP(NEXT_BLKP(bp)));830 Chapter 9 Virtual Memory code/vm/malloc/mm.c 1/* Basic constants macros */ 2#define WSIZE 4 /* Word header/footer size (bytes) */ 3#define DSIZE 8 /* Double word size (bytes) */ 4#define CHUNKSIZE (1<<12) /* Extend heap amount (bytes) */ 5 6#define MAX(x, y) ((x) > (y)? (x) : (y)) 78 /* Pack size allocated bit word */ 9#define PACK(size, alloc) ((size) | (alloc)) 1011 /* Read write word address p */ 12 #define GET(p) (*(unsigned int *)(p)) 13 #define PUT(p, val) (*(unsigned int *)(p) = (val)) 1415 /* Read size allocated fields address p */ 16 #define GET_SIZE(p) (GET(p) & ~0x7) 17 #define GET_ALLOC(p) (GET(p) & 0x1) 1819 /* Given block ptr bp, compute address header footer */ 20 #define HDRP(bp) ((char *)(bp) - WSIZE) 21 #define FTRP(bp) ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE) 2223 /* Given block ptr bp, compute address next previous blocks */ 24 #define NEXT_BLKP(bp) ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE))) 25 #define PREV_BLKP(bp) ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE))) code/vm/malloc/mm.c Figure 9.43 Basic constants macros manipulating free list. Creating Initial Free List calling mm_malloc ormm_free , application must initialize heap calling mm_init function (Figure 9.44). mm_init function gets four words memory system initializes create empty free list(lines 4–10). calls extend_heap function (Figure 9.45), extends heap CHUNKSIZE bytes creates initial free block. point, allocator initialized ready accept allocate free requests application. Theextend_heap function invoked two different circumstances: (1) heap initialized, (2) mm_malloc unable ﬁnd suitable ﬁt. maintain alignment, extend_heap rounds requested size nearest multiple 2 words (8 bytes), requests additional heap space fromthe memory system (lines 7–9). remainder extend_heap function (lines 12–17) somewhat subtle. heap begins double-word aligned boundary, every call extend_ heap returns block whose size integral number double words. Thus, everySection 9.9 Dynamic Memory Allocation 831 code/vm/malloc/mm.c 1int mm_init(void) 2{ 3 /* Create initial empty heap */ 4 ((heap_listp = mem_sbrk(4*WSIZE)) == (void *)-1) 5 return -1; 6 PUT(heap_listp, 0); /* Alignment padding */ 7 PUT(heap_listp + (1*WSIZE), PACK(DSIZE, 1)); /* Prologue header */ 8 PUT(heap_listp + (2*WSIZE), PACK(DSIZE, 1)); /* Prologue footer */ 9 PUT(heap_listp + (3*WSIZE), PACK(0, 1)); /* Epilogue header */ 10 heap_listp += (2*WSIZE); 11 12 /* Extend empty heap free block CHUNKSIZE bytes */ 13 (extend_heap(CHUNKSIZE/WSIZE) == NULL) 14 return -1; 15 return 0; 16 } code/vm/malloc/mm.c Figure 9.44 mm_init : Creates heap initial free block. code/vm/malloc/mm.c 1static void *extend_heap(size_t words) 2{ 3 char *bp; 4 size_t size; 5 6 /* Allocate even number words maintain alignment */ 7 size = (words % 2) ? (words+1) * WSIZE : words * WSIZE; 8 ((long)(bp = mem_sbrk(size)) == -1) 9 return NULL; 1011 /* Initialize free block header/footer epilogue header */ 12 PUT(HDRP(bp), PACK(size, 0)); /* Free block header */ 13 PUT(FTRP(bp), PACK(size, 0)); /* Free block footer */ 14 PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1)); /* New epilogue header */ 15 16 /* Coalesce previous block free */ 17 return coalesce(bp); 18 } code/vm/malloc/mm.c Figure 9.45 extend_heap : Extends heap new free block.832 Chapter 9 Virtual Memory call mem_sbrk returns double-word aligned chunk memory immediately following header epilogue block. header becomes header ofthe new free block (line 12), last word chunk becomes newepilogue block header (line 14). Finally, likely case previous heapwas terminated free block, call coalesce function merge two free blocks return block pointer merged blocks (line 17). Freeing Coalescing Blocks application frees previously allocated block calling mm_free function (Figure 9.46), frees requested block ( bp) merges adjacent free blocks using boundary-tags coalescing technique described Section 9.9.11. code coalesce helper function straightforward implementation four cases outlined Figure 9.40. one somewhat subtle aspect. Thefree list format chosen—with prologue epilogue blocks arealways marked allocated—allows us ignore potentially troublesome edgeconditions requested block bpis beginning end heap. Without special blocks, code would messier, error prone, andslower, would check rare edge conditions eachand every free request. Allocating Blocks application requests block size bytes memory calling mm_malloc function (Figure 9.47). checking spurious requests, allocator mustadjust requested block size allow room header footer, tosatisfy double-word alignment requirement. Lines 12–13 enforce minimumblock size 16 bytes: 8 bytes satisfy alignment requirement, 8 morefor overhead header footer. requests 8 bytes (line 15),the general rule add overhead bytes round nearest multiple 8. allocator adjusted requested size, searches free list suitable free block (line 18). ﬁt, allocator places requestedblock optionally splits excess (line 19), returns address thenewly allocated block. allocator cannot ﬁnd ﬁt, extends heap new free block (lines 24–26), places requested block new free block, optionally splittingthe block (line 27), returns pointer newly allocated block. Practice Problem 9.8 Implement find_fit function simple allocator described Section 9.9.12. static void *find_fit(size_t asize) solution perform ﬁrst-ﬁt search implicit free list.Section 9.9 Dynamic Memory Allocation 833 code/vm/malloc/mm.c 1void mm_free(void *bp) 2{ 3 size_t size = GET_SIZE(HDRP(bp)); 4 5 PUT(HDRP(bp), PACK(size, 0)); 6 PUT(FTRP(bp), PACK(size, 0)); 7 coalesce(bp); 8} 9 10 static void *coalesce(void *bp) 11 { 12 size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp))); 13 size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp))); 14 size_t size = GET_SIZE(HDRP(bp)); 1516 (prev_alloc && next_alloc) { /* Case 1 */ 17 return bp; 18 } 19 20 else (prev_alloc && !next_alloc) { /* Case 2 */ 21 size += GET_SIZE(HDRP(NEXT_BLKP(bp))); 22 PUT(HDRP(bp), PACK(size, 0)); 23 PUT(FTRP(bp), PACK(size,0)); 24 } 25 26 else (!prev_alloc && next_alloc) { /* Case 3 */ 27 size += GET_SIZE(HDRP(PREV_BLKP(bp))); 28 PUT(FTRP(bp), PACK(size, 0)); 29 PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0)); 30 bp = PREV_BLKP(bp); 31 } 32 33 else { /* Case 4 */ 34 size += GET_SIZE(HDRP(PREV_BLKP(bp))) + 35 GET_SIZE(FTRP(NEXT_BLKP(bp))); 36 PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0)); 37 PUT(FTRP(NEXT_BLKP(bp)), PACK(size, 0)); 38 bp = PREV_BLKP(bp); 39 } 40 return bp; 41 } code/vm/malloc/mm.c Figure 9.46 mm_free : Frees block uses boundary-tag coalescing merge adjacent free blocks constant time.834 Chapter 9 Virtual Memory code/vm/malloc/mm.c 1void *mm_malloc(size_t size) 2{ 3 size_t asize; /* Adjusted block size */ 4 size_t extendsize; /* Amount extend heap fit */ 5 char *bp; 6 7 /* Ignore spurious requests */ 8 (size == 0) 9 return NULL; 1011 /* Adjust block size include overhead alignment reqs. */ 12 (size <= DSIZE) 13 asize = 2*DSIZE; 14 else 15 asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE); 1617 /* Search free list fit */ 18 ((bp = find_fit(asize)) != NULL) { 19 place(bp, asize); 20 return bp; 21 } 2223 /* fit found. Get memory place block */ 24 extendsize = MAX(asize,CHUNKSIZE); 25 ((bp = extend_heap(extendsize/WSIZE)) == NULL) 26 return NULL; 27 place(bp, asize); 28 return bp; 29 } code/vm/malloc/mm.c Figure 9.47 mm_malloc : Allocates block free list. Practice Problem 9.9 Implement place function example allocator. static void place(void *bp, size_t asize) solution place requested block beginning free block, splitting size remainder would equal exceed minimumblock size.Section 9.9 Dynamic Memory Allocation 835 Block size Payload (a) Allocated blockPadding (optional)a/f Block size a/f31 3 2 1 0 Header FooterBlock size pred (Predecessor) (b) Free blocksucc (Successor) Padding (optional)a/f Block size a/f31 3 2 1 0 Header Old payload Footer Figure 9.48 Format heap blocks use doubly linked free lists. 9.9.13 Explicit Free Lists implicit free list provides us simple way introduce basic allocator concepts. However, block allocation time linear total number heap blocks, implicit free list appropriate general-purpose allocator (although might ﬁne special-purpose allocator wherethe number heap blocks known beforehand small). better approach organize free blocks form explicit data structure. Since deﬁnition body free block needed theprogram, pointers implement data structure stored within thebodies free blocks. example, heap organized doublylinked free list including pred (predecessor) succ (successor) pointer free block, shown Figure 9.48. Using doubly linked list instead implicit free list reduces ﬁrst ﬁt allocation time linear total number blocks linear numberoffreeblocks. However, time free block either linear constant, depending policy choose ordering blocks free list. One approach maintain list last-in ﬁrst-out (LIFO) order insert- ing newly freed blocks beginning list. LIFO ordering aﬁrst ﬁt placement policy, allocator inspects recently used blocks ﬁrst.In case, freeing block performed constant time. boundary tags used, coalescing also performed constant time. Another approach maintain list address order , address block list less address successor. case, freeinga block requires linear-time search locate appropriate predecessor. Thetrade-off address-ordered ﬁrst ﬁt enjoys better memory utilization thanLIFO-ordered ﬁrst ﬁt, approaching utilization best ﬁt. disadvantage explicit lists general free blocks must large enough contain necessary pointers, well header possibly footer. results larger minimum block size, increases potential internal fragmentation.836 Chapter 9 Virtual Memory 9.9.14 Segregated Free Lists seen, allocator uses single linked list free blocks requires time linear number free blocks allocate block. popular approach forreducing allocation time, known generally segregated storage , maintain multiple free lists, list holds blocks roughly size. Thegeneral idea partition set possible block sizes equivalence classescalled size classes . many ways deﬁne size classes. example, might partition block sizes powers two: {1},{2},{3,4},{5−8},...,{1025−2048},{2049−4096},{4097−∞} might assign small blocks size classes partition large blocks powers two: {1},{2},{3},...,{1023},{1024},{1025−2048},{2049−4096},{4097−∞} allocator maintains array free lists, one free list per size class, ordered increasing size. allocator needs block size n, searches appropriate free list. cannot ﬁnd block ﬁts, searches next list, on. dynamic storage allocation literature describes dozens variants seg- regated storage differ deﬁne size classes, performcoalescing, request additional heap memory operating sys-tem, whether allow splitting, forth. give sense ispossible, describe two basic approaches: simple segregated storage segregated ﬁts . Simple Segregated Storage simple segregated storage, free list size class contains same-sized blocks, size largest element size class. example, somesize class deﬁned {17−32}, free list class consists entirely blocks size 32. allocate block given size, check appropriate free list. list empty, simply allocate ﬁrst block entirety. Free blocks never split satisfy allocation requests. list empty, allocator requestsa ﬁxed-sized chunk additional memory operating system (typicallya multiple page size), divides chunk equal-sized blocks, linksthe blocks together form new free list. free block, allocator simplyinserts block front appropriate free list. number advantages simple scheme. Allocating freeing blocks fast constant-time operations. Further, combination same-sized blocks chunk, splitting, coalescing means little per-block memory overhead. Since chunk same-sized blocks, size allocated block inferred address. Sincethere coalescing, allocated blocks need allocated/free ﬂag theheader. Thus, allocated blocks require headers, since coalescing,Section 9.9 Dynamic Memory Allocation 837 require footers either. Since allocate free operations insert delete blocks beginning free list, list need singlylinked instead doubly linked. bottom line required ﬁeld inany block one-word succ pointer free block, thus minimum block size one word. signiﬁcant disadvantage simple segregated storage susceptible internal external fragmentation. Internal fragmentation possible becausefree blocks never split. Worse, certain reference patterns cause extreme external fragmentation free blocks never coalesced (Problem 9.10). Practice Problem 9.10 Describe reference pattern results severe external fragmentation anallocator based simple segregated storage. Segregated Fits approach, allocator maintains array free lists. free list isassociated size class organized kind explicit implicitlist. list contains potentially different-sized blocks whose sizes membersof size class. many variants segregated ﬁts allocators. wedescribe simple version. allocate block, determine size class request ﬁrst- ﬁt search appropriate free list block ﬁts. ﬁnd one, we(optionally) split insert fragment appropriate free list. cannotﬁnd block ﬁts, search free list next larger size class. repeat ﬁnd block ﬁts. none free lists yields block ﬁts,then request additional heap memory operating system, allocate block new heap memory, place remainder appropriatesize class. free block, coalesce place result appropriate freelist. segregated ﬁts approach popular choice production-quality allocators GNU malloc package provided C standard library fast memory efﬁcient. Search times reduced becausesearches limited particular parts heap instead entire heap.Memory utilization improve interesting fact simple ﬁrst-ﬁt search segregated free list approximates best-ﬁt search entire heap. Buddy Systems Abuddy system special case segregated ﬁts size class power two. basic idea given heap 2mwords, maintain separate free list block size 2k, 0 ≤k≤m. Requested block sizes rounded nearest power two. Originally, one free block size 2mwords. allocate block size 2k, ﬁnd ﬁrst available block size 2j, thatk≤j≤m.I fj=k, done. Otherwise, recursively split the838 Chapter 9 Virtual Memory block half j=k. perform splitting, remaining half (known buddy ) placed appropriate free list. free block size 2k,w e continue coalescing free. encounter allocated buddy, stopthe coalescing. key fact buddy systems given address size block, easy compute address buddy. example, block size 32 byeswith address xxx...x00000 buddy address xxx...x10000 words, addresses block buddy differ exactly one bitposition. major advantage buddy system allocator fast searching coalescing. major disadvantage power-of-two requirement theblock size cause signiﬁcant internal fragmentation. reason, buddysystem allocators appropriate general-purpose workloads. However,for certain application-speciﬁc workloads, block sizes known inadvance powers two, buddy system allocators certain appeal. 9.10 Garbage Collection explicit allocator C malloc package, application allocates frees heap blocks making calls malloc andfree . application’s responsibility free allocated blocks longer needs. Failing free allocated blocks common programming error. example, consider following C function allocates block temporary storage aspart processing: 1void garbage() 2{ 3 int *p = (int *)Malloc(15213); 4 5 return; /* Array p garbage point */ 6} Since pis longer needed program, freed garbage returned. Unfortunately, programmer forgotten free block. remains allocated lifetime program, needlessly occupying heapspace could used satisfy subsequent allocation requests. Agarbage collector dynamic storage allocator automatically frees al- located blocks longer needed program. blocks knownasgarbage (hence term garbage collector). process automatically re- claiming heap storage known garbage collection . system supportsSection 9.10 Garbage Collection 839 garbage collection, applications explicitly allocate heap blocks never explic- itly free them. context f C program, application calls malloc , never calls free . Instead, garbage collector periodically identiﬁes garbage blocks makes appropriate calls free place blocks back free list. Garbage collection dates back Lisp systems developed John McCarthy MIT early 1960s. important part modern language systems suchas Java, ML, Perl, Mathematica, remains active important area research. literature describes amazing number approaches garbagecollection. limit discussion McCarthy’s original Mark&Sweep al- gorithm, interesting built top existing malloc package provide garbage collection C C++ programs. 9.10.1 Garbage Collector Basics garbage collector views memory directed reachability graph form shown Figure 9.49. nodes graph partitioned set root nodes set heap nodes . heap node corresponds allocated block heap. directed edge p→qmeans location block ppoints location block q. Root nodes correspond locations heap contain pointers heap. locations registers, variables thestack, global variables read-write data area virtual memory. say node pisreachable exists directed path root node p. point time, unreachable nodes correspond garbage never used application. role garbage collector maintain representation reachability graph periodically reclaimthe unreachable nodes freeing returning free list. Garbage collectors languages like ML Java, exert tight con- trol applications create use pointers, maintain exact repre-sentation reachability graph, thus reclaim garbage. However,collectors languages like C C++ cannot general maintain exact repre-sentations reachability graph. collectors known conservative garbage collectors . conservative sense reachable block Root nodes Heap nodes Reachable Unreachable (garbage) Figure 9.49 garbage collector’s view memory directed graph.840 Chapter 9 Virtual Memory C application programmalloc()Conservative garbage collectorfree()Dynamic storage allocator Figure 9.50 Integrating conservative garbage collector C malloc package. correctly identiﬁed reachable, unreachable nodes might incor- rectly identiﬁed reachable. Collectors provide service demand, run separate threads parallel application, continuously updating reachabilitygraph reclaiming garbage. example, consider might incorporate aconservative collector C programs existing malloc package, shown Figure 9.50. application calls malloc usual manner whenever needs heap space. malloc unable ﬁnd free block ﬁts, calls garbage col- lector hopes reclaiming garbage free list. collector identiﬁesthe garbage blocks returns heap calling free function. key idea collector calls free instead application. call collector returns, malloc tries ﬁnd free block ﬁts. fails, ask operating system additional memory. Eventually malloc returns pointer requested block (if successful) NULL pointer (ifunsuccessful). 9.10.2 Mark&Sweep Garbage Collectors Mark&Sweep garbage collector consists mark phase , marks reachable allocated descendants root nodes, followed sweep phase , frees unmarked allocated block. Typically, one spare low-order bits block header used indicate whether block marked not. description Mark&Sweep assume following functions, ptris deﬁned typedef void *ptr . .ptr isPtr(ptr p) :I fppoints word allocated block, returns pointer bto beginning block. Returns NULL otherwise. .int blockMarked(ptr b) : Returns true block bis already marked. .int blockAllocated(ptr b) : Returns true block bis allocated. .void markBlock(ptr b) : Marks block b. .int length(ptr b) : Returns length words (excluding header) block b. .void unmarkBlock(ptr b) : Changes status block bfrom marked unmarked. .ptr nextBlock(ptr b) : Returns successor block bin heap.Section 9.10 Garbage Collection 841 (a)mark function void mark(ptr p) { ((b = isPtr(p)) == NULL) return; (blockMarked(b)) return; markBlock(b);len = length(b);for (i=0 ; < len; i++) mark(b[i]); return; }(b)sweep function void sweep(ptr b, ptr end) { (b < end) { (blockMarked(b)) unmarkBlock(b); else (blockAllocated(b)) free(b); b = nextBlock(b); } return; } Figure 9.51 Pseudo-code mark andsweep functions. mark phase calls mark function shown Figure 9.51(a) root node. mark function returns immediately pdoes point allocated unmarked heap block. Otherwise, marks block calls recursivelyon word block. call mark function marks unmarked reachable descendants root node. end mark phase, anyallocated block marked guaranteed unreachable and, hence,garbage reclaimed sweep phase. sweep phase single call sweep function shown Figure 9.51(b). Thesweep function iterates block heap, freeing unmarked allocated blocks (i.e., garbage) encounters. Figure 9.52 shows graphical interpretation Mark&Sweep small heap. Block boundaries indicated heavy lines. square corresponds aword memory. block one-word header, either marked orunmarked. 1234 5 6 mark:Root mark:Unmarked block header Marked block header sweep: Free Free Figure 9.52 Mark sweep example. Note arrows example denote memory references, free list pointers.842 Chapter 9 Virtual Memory Initially, heap Figure 9.52 consists six allocated blocks, unmarked. Block 3 contains pointer block 1. Block 4 contains pointersto blocks 3 6. root points block 4. mark phase, blocks 1,3, 4, 6 marked reachable root. Blocks 2 and5 unmarked unreachable. sweep phase, twounreachable blocks reclaimed free list. 9.10.3 Conservative Mark&Sweep C Programs Mark&Sweep appropriate approach garbage collecting C programs be- cause works place without moving blocks. However, C language poses interesting challenges implementation isPtr function. First, C tag memory locations type information. Thus, obvious way isPtr determine input parameter pis pointer not. Second, even know pwas pointer, would obvious way isPtr determine whether ppoints location payload allocated block. One solution latter problem maintain set allocated blocks balanced binary tree maintains invariant blocks leftsubtree located smaller addresses blocks right subtree located larger addresses. shown Figure 9.53, requires two additional ﬁelds ( left andright ) header allocated block. ﬁeld points header allocated block. TheisPtr(ptr p) function uses tree perform binary search allocated blocks. step, relies size ﬁeld block header todetermine pfalls within extent block. balanced tree approach correct sense guaranteed mark nodes reachable roots. necessary guarantee,as application users would certainly appreciate allocated blocksprematurely returned free list. However, conservative sense thatit may incorrectly mark blocks actually unreachable, thus may failto free garbage. affect correctness applicationprograms, result unnecessary external fragmentation. fundamental reason Mark&Sweep collectors C programs must conservative C language tag memory locations typeinformation. Thus, scalars like intso rfloat masquerade pointers. example, suppose reachable allocated block contains int payload whose value happens correspond address payload someother allocated block b. way collector infer data really intand pointer. Therefore, allocator must conservatively mark block bas reachable, fact might be. Figure 9.53 Left right pointersin balanced tree ofallocated blocks. Size Left Right Remainder blockAllocated block header /H11021/H11022Section 9.11 Common Memory-Related Bugs C Programs 843 9.11 Common Memory-Related Bugs C Programs Managing using virtual memory difﬁcult error-prone task C programmers. Memory-related bugs among frightening theyoften manifest distance, time space, source ofthe bug. Write wrong data wrong location, program run forhours ﬁnally fails distant part program. conclude ourdiscussion virtual memory discussion common memory-related bugs. 9.11.1 Dereferencing Bad Pointers learned Section 9.7.2, large holes virtual address space process mapped meaningful data. attempt dereferencea pointer one holes, operating system terminate programwith segmentation exception. Also, areas virtual memory read-only.Attempting write one areas terminates program protectionexception. common example dereferencing bad pointer classic scanf bug. Suppose want use scanf read integer stdin variable. correct way pass scanf format string address variable: scanf("%d", &val) However, easy new C programmers (and experienced ones too!) passthecontents ofvalinstead address: scanf("%d", val) case, scanf interpret contents valas address attempt write word location. best case, program terminates immediatelywith exception. worst case, contents val correspond valid read/write area virtual memory, overwrite memory, usually withdisastrous bafﬂing consequences much later. 9.11.2 Reading Uninitialized Memory bss memory locations (such uninitialized global C variables) always initialized zeros loader, true heap memory. commonerror assume heap memory initialized zero: 1/* Retur ny=A x* / 2int *matvec(int **A, int *x, int n) 3{ 4 int i, j; 5 6 int *y = (int *)Malloc(n * sizeof(int)); 7844 Chapter 9 Virtual Memory 8 f r( i=0 ;i<n ; i++) 9 f r( j=0 ;j<n ; j++) 10 y[i] += A[i][j] * x[j]; 11 return y; 12 } example, programmer incorrectly assumed vector yhas initialized zero. correct implementation would explicitly zero y[i] , use calloc . 9.11.3 Allowing Stack Buffer Overﬂows saw Section 3.12, program buffer overﬂow bug writes target buffer stack without examining size input string. example,the following function buffer overﬂow bug gets function copies arbitrary length string buffer. ﬁx this, would need use fgets function, limits size input string. 1void bufoverflow() 2{ 3 char buf[64]; 4 5 gets(buf); /* stack buffer overflow bug */ 6 return; 7} 9.11.4 Assuming Pointers Objects Point Size One common mistake assume pointers objects size objects point to: 1/* Create nxm array */ 2int **makeArray1(int n, int m) 3{ 4 int i; 5 int **A = (int **)Malloc(n * sizeof(int)); 6 7 f r( i=0 ;i<n ; i++) 8 A[i] = (int *)Malloc(m * sizeof(int)); 9 return A; 10 } intent create array npointers, points array ofmints. However, programmer written sizeof(int) instead ofsizeof(int *) line 5, code actually creates array ints. code run ﬁne machines ints pointers ints size. run code machine like Core i7, pointer isSection 9.11 Common Memory-Related Bugs C Programs 845 larger int, loop lines 7–8 write past end Aarray. Since one words likely boundary tag footer allocatedblock, may discover error free block much later theprogram, point coalescing code allocator fail dramaticallyand apparent reason. insidious example kind “action ata distance” typical memory-related programming bugs. 9.11.5 Making Off-by-One Errors Off-by-one errors another common source overwriting bugs: 1/* Create nxm array */ 2int **makeArray2(int n, int m) 3{ 4 int i; 5 int **A = (int **)Malloc(n * sizeof(int *)); 6 7 (i = 0; <= n; i++) 8 A[i] = (int *)Malloc(m * sizeof(int)); 9 return A; 10 } another version program previous section. created n-element array pointers line 5, tried initialize n+1o f elements lines 7 8, process overwriting memory followstheAarray. 9.11.6 Referencing Pointer Instead Object Points careful precedence associativity C operators, incorrectly manipulate pointer instead object points to. example,consider following function, whose purpose remove ﬁrst item abinary heap *size items, reheapify remaining *size - 1 items: 1int *binheapDelete(int **binheap, int *size) 2{ 3 int *packet = binheap[0]; 4 5 binheap[0] = binheap[*size - 1]; 6 *size--; /* (*size)-- */ 7 heapify(binheap, *size, 0); 8 return(packet); 9} line 6, intent decrement integer value pointed size pointer. However, unary --and*operators precedence associate right left, code line 6 actually decrements pointer846 Chapter 9 Virtual Memory instead integer value points to. lucky, program crash immediately; likely left scratching heads theprogram produces incorrect answer much later execution. moral hereis use parentheses whenever doubt precedence associativity. Forexample, line 6 clearly stated intent using expression(*size)-- . 9.11.7 Misunderstanding Pointer Arithmetic Another common mistake forget arithmetic operations pointers performed units size objects point to, notnecessarily bytes. example, intent following function scan anarray ints return pointer ﬁrst occurrence val: 1int *search(int *p, int val) 2{ 3 (*p && *p != val) 4 p += sizeof(int); /* p++ */ 5 return p; 6} However, line 4 increments pointer 4 (the number bytes integer) time loop, function incorrectly scans every fourthinteger array. 9.11.8 Referencing Nonexistent Variables Naive C programmers understand stack discipline sometimes reference local variables longer valid, following example: 1int *stackref () 2{ 3 int val; 4 5 return &val; 6} function returns pointer (say, p) local variable stack pops stack frame. Although pstill points valid memory address, longer points valid variable. functions called later program, thememory reused stack frames. Later, program assigns somevalue *p, might actually modifying entry another function’s stack frame, potentially disastrous bafﬂing consequences.Section 9.11 Common Memory-Related Bugs C Programs 847 9.11.9 Referencing Data Free Heap Blocks similar error reference data heap blocks already freed. example, consider following example, allocates integer array xin line 6, prematurely frees block xin line 10, later references line 14: 1int *heapref(int n, int m) 2{ 3 int i; 4 int *x, *y; 5 6 x = (int *)Malloc(n * sizeof(int)); 78 /* ... */ /* calls malloc free go */ 9 10 free(x); 11 12 = (int *)Malloc(m * sizeof(int)); 13 f r( i=0 ;i<m ; i++) 14 y[i] = x[i]++; /* Oops! x[i] word free block */ 15 16 return y; 17 } Depending pattern malloc andfree calls occur lines 6 10, program references x[i] line 14, array xmight part allocated heap block overwritten. manymemory-related bugs, error become evident later programwhen notice values yare corrupted. 9.11.10 Introducing Memory Leaks Memory leaks slow, silent killers occur programmers inadvertently create garbage heap forgetting free allocated blocks. example, thefollowing function allocates heap block xand returns without freeing it: 1void leak(int n) 2{ 3 int *x = (int *)Malloc(n * sizeof(int)); 4 5 return; /* x garbage point */ 6} Ifleak called frequently, heap gradually ﬁll garbage, worst case consuming entire virtual address space. Memory leaks areparticularly serious programs daemons servers, deﬁnitionnever terminate.848 Chapter 9 Virtual Memory 9.12 Summary Virtual memory abstraction main memory. Processors support virtual memory reference main memory using form indirection known virtual ad-dressing. processor generates virtual address, translated phys-ical address sent main memory. translation addressesfrom virtual address space physical address space requires close cooperationbetween hardware software. Dedicated hardware translates virtual addressesusing page tables whose contents supplied operating system. Virtual memory provides three important capabilities. First, automatically caches recently used contents virtual address space stored disk mainmemory. block virtual memory cache known page. referenceto page disk triggers page fault transfers control fault handlerin operating system. fault handler copies page disk mainmemory cache, writing back evicted page necessary. Second, virtual memorysimpliﬁes memory management, turn simpliﬁes linking, sharing databetween processes, allocation memory processes, program loading.Finally, virtual memory simpliﬁes memory protection incorporating protectionbits every page table entry. process address translation must integrated operation hardware caches system. page table entries located L1cache, cost accessing page table entries L1 usually eliminatedby on-chip cache page table entries called TLB. Modern systems initialize chunks virtual memory associating chunks ﬁles disk, process known memory mapping. Memory mappingprovides efﬁcient mechanism sharing data, creating new processes, andloading programs. Applications manually create delete areas virtualaddress space using mmap function. However, programs rely dynamic memory allocator malloc , manages memory area virtual address space called heap. Dynamic memory allocators application-levelprograms system-level feel, directly manipulating memory without muchhelp type system. Allocators come two ﬂavors. Explicit allocators require applications explicitly free memory blocks. Implicit allocators(garbage collectors) free unused unreachable blocks automatically. Managing using memory difﬁcult error-prone task C program- mers. Examples common errors include dereferencing bad pointers, readinguninitialized memory, allowing stack buffer overﬂows, assuming pointers andthe objects point size, referencing pointer instead theobject points to, misunderstanding pointer arithmetic, referencing nonexistentvariables, introducing memory leaks. Bibliographic Notes Kilburn colleagues published ﬁrst description virtual memory [60].Architecture texts contain additional details hardware’s role virtualmemory [49]. Operating systems texts contain additional information operating system’s role [98, 104, 112]. Bovet Cesati [11] give detailed de-Homework Problems 849 scription Linux virtual memory system. Intel Corporation provides detailed documentation 32-bit 64-bit address translation IA processors [30]. Knuth wrote classic work storage allocation 1968 [61]. Since time tremendous amount work area. Wilson, Johnstone,Neely, Boles written beautiful survey performance evaluation ofexplicit allocators [117]. general comments book throughput utilization different allocator strategies paraphrased sur-vey. Jones Lins provide comprehensive survey garbage collection [54]. Kernighan Ritchie [58] show complete code simple allocator basedon explicit free list block size successor pointer free block.The code interesting uses unions eliminate lot complicatedpointer arithmetic, expense linear-time (rather constant-time)free operation. Homework Problems 9.11◆ following series problems, show example memorysystem Section 9.6.4 translates virtual address physical address andaccesses cache. given virtual address, indicate TLB entry accessed,the physical address, cache byte value returned. Indicate whether TLB misses, whether page fault occurs, whether cache miss occurs. cache miss, enter “–” “Cache Byte returned.” page fault, enter“–” “PPN” leave parts C blank. Virtual address: 0x027c A. Virtual address format 1 3 1 2 1 1 1 0 9876543210 B. Address translation Parameter Value VPN TLB index TLB tag TLB hit? (Y/N) Page fault? (Y/N) PPN C. Physical address format 1 1 1 0 9876543210850 Chapter 9 Virtual Memory D. Physical memory reference Parameter Value Byte offset Cache index Cache tag Cache hit? (Y/N) Cache byte returned 9.12◆ Repeat Problem 9.11 following address: Virtual address: 0x03a9 A. Virtual address format 1 3 1 2 1 1 1 0 9876543210 B. Address translation Parameter Value VPN TLB index TLB tag TLB hit? (Y/N) Page fault? (Y/N) PPN C. Physical address format 1 1 1 0 9876543210 D. Physical memory reference Parameter Value Byte offset Cache index Cache tag Cache hit? (Y/N) Cache byte returnedHomework Problems 851 9.13◆ Repeat Problem 9.11 following address: Virtual address: 0x0040 A. Virtual address format 1 3 1 2 1 1 1 0 9876543210 B. Address translation Parameter Value VPN TLB index TLB tag TLB hit? (Y/N) Page fault? (Y/N) PPN C. Physical address format 1 1 1 0 9876543210 D. Physical memory reference Parameter Value Byte offset Cache index Cache tag Cache hit? (Y/N) Cache byte returned 9.14◆◆ Given input ﬁle hello.txt consists string “ Hello, world!\n ”, write C program uses mmap change contents hello.txt “Jello, world!\n ”. 9.15◆ Determine block sizes header values would result followingsequence malloc requests. Assumptions: (1) allocator maintains double- word alignment, uses implicit free list block format Fig-ure 9.35. (2) Block sizes rounded nearest multiple 8 bytes.852 Chapter 9 Virtual Memory Request Block size (decimal bytes) Block header (hex) malloc(3) malloc(11) malloc(20) malloc(21) 9.16◆ Determine minimum block size following combinations alignment requirements block formats. Assumptions: Explicit free list, 4-bytepred andsucc pointers free block, zero-sized payloads allowed, headers footers stored 4-byte words. Alignment Allocated block Free block Minimum block size (bytes) Single word Header footer Header footer Single word Header, footer Header footer Double word Header footer Header footer Double word Header, footer Header footer 9.17◆◆◆ Develop version allocator Section 9.9.12 performs next-ﬁt searchinstead ﬁrst-ﬁt search. 9.18◆◆◆ allocator Section 9.9.12 requires header footer blockin order perform constant-time coalescing. Modify allocator freeblocks require header footer, allocated blocks require header. 9.19◆ given three groups statements relating memory management andgarbage collection below. group, one statement true. task isto indicate statement true. 1.(a) buddy system, 50% space wasted due internal fragmentation. (b) ﬁrst-ﬁt memory allocation algorithm slower best-ﬁt algo- rithm (on average). (c) Deallocation using boundary tags fast list free blocks ordered according increasing memory addresses. (d) buddy system suffers internal fragmentation, external fragmentation. 2.(a) Using ﬁrst-ﬁt algorithm free list ordered according decreasing block sizes results low performance allocations, butavoids external fragmentation. (b) best-ﬁt method, list free blocks ordered according increasing memory addresses. (c) best-ﬁt method chooses largest free block re- quested segment ﬁts.Solutions Practice Problems 853 (d) Using ﬁrst-ﬁt algorithm free list ordered according increasing block sizes equivalent using best-ﬁt algorithm. 3.Mark & sweep garbage collectors called conservative if: (a) coalesce freed memory memory request cannot satisﬁed. (b) treat everything looks like pointer pointer. (c) perform garbage collection run memory. (d) free memory blocks forming cyclic list. 9.20◆◆◆◆ Write version malloc andfree , compare running time space utilization version malloc provided standard C library. Solutions Practice Problems Solution Problem 9.1 (page 779) problem gives appreciation sizes different address spaces. one point time, 32-bit address space seemed impossibly large. database scientiﬁc applications need more, expect trend continue. point lifetime, expect ﬁnd yourselfcomplaining cramped 64-bit address space personal computer! No. virtual address bits ( n) No. virtual addresses ( N) Largest possible virtual address 828=256 28−1=255 16 216=64K 216−1=64K−1 32 232=4G 232−1=4G−1 48 248=256T 248=256T−1 64 264=16,384P 264−1=16,384P−1 Solution Problem 9.2 (page 781) Since virtual page P=2pbytes, total 2n/2p=2n−ppossible pages system, needs page table entry (PTE). nP =2p# PTEs 16 4K 16 16 8K 8 32 4K 1M32 8K 512K Solution Problem 9.3 (page 790) need understand kind problem well order fully grasp address translation. solve ﬁrst subproblem: given n=32 virtual address bits m=24 physical address bits. page size P=1 KB means need log2(1K)=10 bits VPO PPO. (Recall VPO PPO identical.) remaining address bits VPN PPN, respectively.854 Chapter 9 Virtual Memory P # VPN bits # VPO bits # PPN bits # PPO bits 1K B 2 2 1 0 1 4 1 0 2K B 2 1 1 1 1 3 1 1 4K B 2 0 1 2 1 2 1 2 8K B 1 9 1 3 1 1 1 3 Solution Problem 9.4 (page 798) manual simulations great way ﬁrm under- standing address translation. might ﬁnd helpful write bitsin addresses, draw boxes around different bit ﬁelds, VPN,TLBI, etc. particular problem, misses kind: TLBhas copy PTE cache copy requested data words. SeeProblems 9.11, 9.12, 9.13 different combinations hits misses. A.00 0011 1101 0111 B. Parameter Value VPN 0xf TLB index 0x3 TLB tag 0x3 TLB hit? (Y/N) Page fault? (Y/N) N PPN 0xd C.0011 0101 0111 D.Parameter Value Byte offset 0x3 Cache index 0x5 Cache tag 0xd Cache hit? (Y/N) Cache byte returned 0x1d Solution Problem 9.5 (page 812) Solving problem give good feel idea memory mapping. Try yourself. haven’t discussed open ,fstat ,o rwrite functions, you’ll need read manpages see work. code/vm/mmapcopy.c 1#include "csapp.h" 2 3/* 4 * mmapcopy - uses mmap copy file fd stdout 5 */ 6void mmapcopy(int fd, int size) 7{ 8 char *bufp; /* Pointer memory mapped VM area */Solutions Practice Problems 855 9 10 bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE, fd, 0); 11 Write(1, bufp, size); 12 return; 13 } 1415 /* mmapcopy driver */ 16 int main(int argc, char **argv) 17 { 18 struct stat stat; 19 int fd; 20 21 /* Check required command line argument */ 22 (argc != 2) { 23 printf("usage: %s <filename>\n", argv[0]); 24 exit(0); 25 } 26 27 /* Copy input argument stdout */ 28 fd = Open(argv[1], O_RDONLY, 0); 29 fstat(fd, &stat); 30 mmapcopy(fd, stat.st_size); 31 exit(0); 32 } code/vm/mmapcopy.c Solution Problem 9.6 (page 822) problem touches core ideas alignment requirements, min- imum block sizes, header encodings. general approach determiningthe block size round sum requested payload header sizeto nearest multiple alignment requirement (in case 8 bytes). Forexample, block size malloc(1) request 4 +1=5 rounded 8. block size malloc(13) request 13 +4=17 rounded 24. Request Block size (decimal bytes) Block header (hex) malloc(1) 8 0x9 malloc(5) 16 0x11 malloc(12) 16 0x11 malloc(13) 24 0x19 Solution Problem 9.7 (page 826) minimum block size signiﬁcant effect internal fragmentation. Thus, good understand minimum block sizes associated differentallocator designs alignment requirements. tricky part realize thatthe block allocated free different points time. Thus, theminimum block size maximum minimum allocated block size and856 Chapter 9 Virtual Memory minimum free block size. example, last subproblem, minimum allocated block size 4-byte header 1-byte payload rounded eightbytes. minimum free block size 4-byte header 4-byte footer, isalready multiple 8 doesn’t need rounded. minimum blocksize allocator 8 bytes. Alignment Allocated block Free block Minimum block size (bytes) Single word Header footer Header footer 12 Single word Header, footer Header footer 8 Double word Header footer Header footer 16 Double word Header, footer Header footer 8 Solution Problem 9.8 (page 832) nothing tricky here. solution requires understand rest simple implicit-list allocator works manipulateand traverse blocks. code/vm/malloc/mm.c 1static void *find_fit(size_t asize) 2{ 3 /* First fit search */ 4 void *bp; 5 6 (bp = heap_listp; GET_SIZE(HDRP(bp)) > 0; bp = NEXT_BLKP(bp)) { 7 (!GET_ALLOC(HDRP(bp)) && (asize <= GET_SIZE(HDRP(bp)))) { 8 return bp; 9 } 10 } 11 return NULL; /* fit */ code/vm/malloc/mm.c Solution Problem 9.9 (page 834) another warm-up exercise help become familiar allocators. Notice allocator minimum block size 16 bytes. remainderof block splitting would greater equal minimum block size, go ahead split block (lines 6 10). tricky part realize need place new allocated block (lines 6 7) beforemoving next block (line 8). code/vm/malloc/mm.c 1static void place(void *bp, size_t asize) 2{ 3 size_t csize = GET_SIZE(HDRP(bp)); 4 5 ((csize - asize) >= (2*DSIZE)) { 6 PUT(HDRP(bp), PACK(asize, 1));Solutions Practice Problems 857 7 PUT(FTRP(bp), PACK(asize, 1)); 8 bp = NEXT_BLKP(bp); 9 PUT(HDRP(bp), PACK(csize-asize, 0)); 10 PUT(FTRP(bp), PACK(csize-asize, 0)); 11 } 12 else { 13 PUT(HDRP(bp), PACK(csize, 1)); 14 PUT(FTRP(bp), PACK(csize, 1)); 15 } 16 } code/vm/malloc/mm.c Solution Problem 9.10 (page 837) one pattern cause external fragmentation: application makes numerous allocation free requests ﬁrst size class, followed numer-ous allocation free requests second size class, followed numerousallocation free requests third size class, on. size class,the allocator creates lot memory never reclaimed allocatordoesn’t coalesce, application never requests blocks sizeclass again.This page intentionally left blank Part III Interaction CommunicationBetween Programs point study computer systems, assumed programs run isolation, minimal input output. How-ever, real world, application programs use services provided operating system communicate I/O devices otherprograms. part book give understanding basic I/O services provided Unix operating systems, use theseservices build applications Web clients servers com-municate Internet. learn techniques forwriting concurrent programs Web servers service mul-tiple clients time. Writing concurrent application programscan also allow execute faster modern multi-core processors.When ﬁnish part, well way becoming apower programmer mature understanding computer systemsand impact programs. 859This page intentionally left blank CHAPTER10 System-Level I/O 10.1 Unix I/O 862 10.2 Opening Closing Files 863 10.3 Reading Writing Files 865 10.4 Robust Reading Writing Rio Package 867 10.5 Reading File Metadata 873 10.6 Sharing Files 875 10.7 I/O Redirection 877 10.8 Standard I/O 879 10.9 Putting Together: I/O Functions Use? 880 10.10 Summary 881 Bibliographic Notes 882 Homework Problems 882Solutions Practice Problems 883 861862 Chapter 10 System-Level I/O Input/output (I/O) process copying data main memory external devices disk drives, terminals, networks. input operationcopies data I/O device main memory, output operation copiesdata memory device. language run-time systems provide higher-level facilities performing I/O. example, ANSI C provides standard I/O library, functions printf andscanf perform buffered I/O. C++ language provides similar functionality overloaded <<(“put to”) >>(“get from”) operators. Unix systems, higher-level I/O functions implemented using system-levelUnix I/O functions provided kernel. time, higher-level I/O functions work quite well need use Unix I/O directly. whybother learning Unix I/O? .Understanding Unix I/O help understand systems concepts. I/O integral operation system, often encountercircular dependences I/O systems ideas. example,I/O plays key role process creation execution. Conversely, processcreation plays key role ﬁles shared different processes. Thus,to really understand I/O need understand processes, vice versa.We already touched aspects I/O discussions memoryhierarchy, linking loading, processes, virtual memory. youhave better understanding ideas, close circle delveinto I/O detail. .Sometimes choice use Unix I/O. important cases using higher-level I/O functions either impossible inappro-priate. example, standard I/O library provides way access ﬁlemetadata ﬁle size ﬁle creation time. Further, problems withthe standard I/O library make risky use network programming. chapter introduces general concepts Unix I/O standard I/O, shows use reliably C programs. Besidesserving general introduction, chapter lays ﬁrm foundation oursubsequent study network programming concurrency. 10.1 Unix I/O Unix ﬁleis sequence mbytes: B0,B1,...,Bk,...,Bm−1. I/O devices, networks, disks, terminals, modeled ﬁles, input output performed reading writing appropriate ﬁles. Thiselegant mapping devices ﬁles allows Unix kernel export simple, low- level application interface, known Unix I/O , enables input output performed uniform consistent way: .Opening ﬁles . application announces intention access I/O device asking kernel open corresponding ﬁle. kernel returns aSection 10.2 Opening Closing Files 863 small nonnegative integer, called descriptor , identiﬁes ﬁle subsequent operations ﬁle. kernel keeps track informationabout open ﬁle. application keeps track descriptor. process created Unix shell begins life three open ﬁles: standard input (descriptor 0), standard output (descriptor 1), standard error (descriptor 2). header ﬁle <unistd.h> deﬁnes constants STDIN_ FILENO ,STDOUT_FILENO , STDERR_FILENO , used instead explicit descriptor values. .Changing current ﬁle position . kernel maintains ﬁle position k, ini- tially 0, open ﬁle. ﬁle position byte offset beginningof ﬁle. application set current ﬁle position kexplicitly per- forming seek operation. .Reading writing ﬁles .Aread operation copies n>0 bytes ﬁle memory, starting current ﬁle position k, incrementing kbyn. Given ﬁle size mbytes, performing read operation k≥m triggers condition known end-of-ﬁle (EOF), detected application. explicit “EOF character” end ﬁle. Similarly, write operation copies n>0 bytes memory ﬁle, starting current ﬁle position k, updating k. .Closing ﬁles . application ﬁnished accessing ﬁle, informs kernel asking close ﬁle. kernel responds freeing data structures created ﬁle opened restoring descriptor toa pool available descriptors. process terminates reason, thekernel closes open ﬁles frees memory resources. 10.2 Opening Closing Files process opens existing ﬁle creates new ﬁle calling open function: #include <sys/types.h> #include <sys/stat.h> #include <fcntl.h> int open(char *filename, int flags, mode_t mode); Returns: new ﬁle descriptor OK, −1 error Theopen function converts filename ﬁle descriptor returns descriptor number. descriptor returned always smallest descriptor thatis currently open process. flags argument indicates process intends access ﬁle: .O_RDONL Y: Reading .O_WRONL Y: Writing .O_RDWR: Reading writing example, open existing ﬁle reading:864 Chapter 10 System-Level I/O Mask Description S_IRUSR User (owner) read ﬁle S_IWUSR User (owner) write ﬁle S_IXUSR User (owner) execute ﬁle S_IRGRP Members owner’s group read ﬁle S_IWGRP Members owner’s group write ﬁleS_IXGRP Members owner’s group execute ﬁle S_IROTH Others (anyone) read ﬁle S_IWOTH Others (anyone) write ﬁle S_IXOTH Others (anyone) execute ﬁle Figure 10.1 Access permission bits. Deﬁned sys/stat.h . fd = Open("foo.txt", O_RDONLY, 0); Theflags argument also or’d one bit masks provide additional instructions writing: .O_CREAT: ﬁle doesn’t exist, create truncated (empty) version it. .O_TRUNC: ﬁle already exists, truncate it. .O_APPEND: write operation, set ﬁle position end ofthe ﬁle. example, might open existing ﬁle intent appending data: fd = Open("foo.txt", O_WRONLY|O_APPEND, 0); Themode argument speciﬁes access permission bits new ﬁles. symbolic names bits shown Figure 10.1. part context,each process umask set calling umask function. process creates new ﬁle calling open function mode argument, access permission bits ﬁle set mode & ~umask . example, suppose given following default values mode andumask : #define DEF_MODE S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH #define DEF_UMASK S_IWGRP|S_IWOTH following code fragment creates new ﬁle owner ﬁle read write permissions, users read permissions:Section 10.3 Reading Writing Files 865 umask(DEF_UMASK); fd = Open("foo.txt", O_CREAT|O_TRUNC|O_WRONLY, DEF_MODE); Finally, process closes open ﬁle calling close function. #include <unistd.h> int close(int fd); Returns: zero OK, −1 error Closing descriptor already closed error. Practice Problem 10.1 output following program? 1#include "csapp.h" 2 3int main() 4{ 5 int fd1, fd2; 67 fd1 = Open("foo.txt", O_RDONLY, 0); 8 Close(fd1); 9 fd2 = Open("baz.txt", O_RDONLY, 0); 10 printf("fd2 = %d\n", fd2); 11 exit(0); 12 } 10.3 Reading Writing Files Applications perform input output calling read andwrite functions, respectively. #include <unistd.h> ssize_t read(int fd, void *buf, size_t n); Returns: number bytes read OK, 0 EOF, −1 error ssize_t write(int fd, const void *buf, size_t n); Returns: number bytes written OK, −1 error Theread function copies nbytes current ﬁle position descriptor fdto memory location buf. return value −1 indicates error, return value 0 indicates EOF. Otherwise, return value indicates number bytes actually transferred.866 Chapter 10 System-Level I/O code/io/cpstdin.c 1#include "csapp.h" 2 3int main(void) 4{ 5 char c; 67 while(Read(STDIN_FILENO, &c, 1) != 0) 8 Write(STDOUT_FILENO, &c, 1); 9 exit(0); 10 } code/io/cpstdin.c Figure 10.2 Copies standard input standard output one byte time. Thewrite function copies nbytes memory location bufto current ﬁle position descriptor fd. Figure 10.2 shows program uses read andwrite calls copy standard input standard output, 1 byte time. Applications explicitly modify current ﬁle position calling lseek function, beyond scope. Aside What’s difference ssize_t andsize_t ? might noticed read function size_t input argument ssize_t return value. what’s difference two types? size_t deﬁned unsigned int , anssize_t (signed size ) deﬁned int.T h e read function returns signed size rather unsigned size must return −1 error. Interestingly, possibility returning single −1 reduces maximum size read factor two, 4 GB 2 GB. situations, read andwrite transfer fewer bytes application requests. short counts donotindicate error. occur number reasons: .Encountering EOF reads. Suppose ready read ﬁle contains 20 bytes current ﬁle position weare reading ﬁle 50-byte chunks. next read return short count 20, read signal EOF returning short count zero. .Reading text lines terminal. open ﬁle associated terminal (i.e., keyboard display), read function transfer one text line time, returning short count equal size text line. .Reading writing network sockets. open ﬁle corresponds network socket (Section 11.3.3), internal buffering constraints long network delays cause read andwrite return short counts. Short counts also occur call read andwrite Unix pipe, interprocess communication mechanism beyond scope.Section 10.4 Robust Reading Writing Rio Package 867 practice, never encounter short counts read disk ﬁles except EOF, never encounter short counts writeto disk ﬁles. However, want build robust (reliable) network applicationssuch Web servers, must deal short counts repeatedly callingread andwrite requested bytes transferred. 10.4 Robust Reading Writing Rio Package section, develop I/O package, called Rio (Robust I/O) package, handles short counts automatically. Riopackage provides convenient, robust, efﬁcient I/O applications networkprograms subject short counts. Rio provides two different kinds functions: .Unbuffered input output functions. functions transfer data directly memory ﬁle, application-level buffering. areespecially useful reading writing binary data networks. .Buffered input functions. functions allow efﬁciently read text lines binary data ﬁle whose contents cached application-levelbuffer, similar one provided standard I/O functions printf . Unlike buffered I/O routines presented [109], buffered Rio input functions thread-safe (Section 12.7.1) interleaved arbitrarilyon descriptor. example, read text lines adescriptor, binary data, text lines. presenting Rio routines two reasons. First, using network applications develop next two chapters. Second, studying code routines, gain deeper understanding UnixI/O general. 10.4.1 Rio Unbuffered Input Output Functions Applications transfer data directly memory ﬁle calling rio_readn andrio_writen functions. #include "csapp.h" ssize_t rio_readn(int fd, void *usrbuf, size_t n); ssize_t rio_writen(int fd, void *usrbuf, size_t n); Returns: number bytes transferred OK, 0 EOF ( rio_readn only), −1 error Therio_readn function transfers nbytes current ﬁle position descriptor fdto memory location usrbuf . Similarly, rio_writen function transfers nbytes location usrbuf descriptor fd.T h e rio_readn function return short count encounters EOF. rio_writen function never returns short count. Calls rio_readn andrio_writen interleaved arbitrarily descriptor.868 Chapter 10 System-Level I/O Figure 10.3 shows code rio_readn andrio_writen . Notice function manually restarts read orwrite function interrupted return application signal handler. portable possible, allowfor interrupted system calls restart necessary. (See Section 8.5.4for discussion interrupted system calls.) 10.4.2 Rio Buffered Input Functions Atext line sequence ASCII characters terminated newline character. Unix systems, newline character (‘ \n’) ASCII line feed character (LF) numeric value 0x0a . Suppose wanted write program counts number text lines text ﬁle. might dothis? One approach use read function transfer 1 byte time ﬁle user’s memory, checking byte newline character. Thedisadvantage approach inefﬁcient, requiring trap kernelto read byte ﬁle. better approach call wrapper function ( rio_readlineb ) copies text line internal read buffer , automatically making read call reﬁll buffer whenever becomes empty. ﬁles contain text linesand binary data (such HTTP responses described Section 11.5.3) alsoprovide buffered version rio_readn , called rio_readnb , transfers raw bytes read buffer rio_readlineb . #include "csapp.h" void rio_readinitb(rio_t *rp, int fd); Returns: nothing ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen); ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n); Returns: number bytes read OK, 0 EOF, −1 error Therio_readinitb function called per open descriptor. associates descriptor fdwith read buffer type rio_t address rp. Therio_readlineb function reads next text line ﬁle rp(including terminating newline character), copies memory location usrbuf , ter- minates text line null (zero) character. rio_readlineb function reads maxlen-1 bytes, leaving room terminating null character. Text lines exceed maxlen-1 bytes truncated terminated null character. Therio_readnb function reads nbytes ﬁle rpto memory location usrbuf . Calls rio_readlineb andrio_readnb interleaved arbitrarily descriptor. However, calls buffered functions beinterleaved calls unbuffered rio_readn function. encounter numerous examples Riofunctions remainder text. Figure 10.4 shows use Riofunctions copy text ﬁle standard input standard output, one line time.Section 10.4 Robust Reading Writing Rio Package 869 code/src/csapp.c 1ssize_t rio_readn(int fd, void *usrbuf, size_t n) 2{ 3 size_t nleft = n; 4 ssize_t nread; 5 char *bufp = usrbuf; 6 7 (nleft > 0) { 8 ((nread = read(fd, bufp, nleft)) < 0) { 9 (errno == EINTR) /* Interrupted sig handler return */ 10 nread = 0; /* call read() */ 11 else 12 return -1; /* errno set read() */ 13 } 14 else (nread == 0) 15 break; /* EOF */ 16 nleft -= nread; 17 bufp += nread; 18 } 19 return (n - nleft); /* Return >= 0 */ 20 } code/src/csapp.c code/src/csapp.c 1ssize_t rio_writen(int fd, void *usrbuf, size_t n) 2{ 3 size_t nleft = n; 4 ssize_t nwritten; 5 char *bufp = usrbuf; 6 7 (nleft > 0) { 8 ((nwritten = write(fd, bufp, nleft)) <= 0) { 9 (errno == EINTR) /* Interrupted sig handler return */ 10 nwritten = 0; /* call write() */ 11 else 12 return -1; /* errno set write() */ 13 } 14 nleft -= nwritten; 15 bufp += nwritten; 16 } 17 return n; 18 } code/src/csapp.c Figure 10.3 Therio_readn andrio_writen functions.870 Chapter 10 System-Level I/O code/io/cpﬁle.c 1#include "csapp.h" 2 3int main(int argc, char **argv) 4{ 5 int n; 6 rio_t rio; 7 char buf[MAXLINE]; 89 Rio_readinitb(&rio, STDIN_FILENO); 10 while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) 11 Rio_writen(STDOUT_FILENO, buf, n); 12 } code/io/cpﬁle.c Figure 10.4 Copying text ﬁle standard input standard output. Figure 10.5 shows format read buffer, along code rio_readinitb function initializes it. rio_readinitb function sets empty read buffer associates open ﬁle descriptor buffer. heart Rio read routines rio_read function shown Fig- ure 10.6. rio_read function buffered version Unix read function. rio_read called request read nbytes, rp->rio_cnt code/include/csapp.h 1#define RIO_BUFSIZE 8192 2typedef struct { 3 int rio_fd; /* Descriptor internal buf */ 4 int rio_cnt; /* Unread bytes internal buf */ 5 char *rio_bufptr; /* Next unread byte internal buf */ 6 char rio_buf[RIO_BUFSIZE]; /* Internal buffer */ 7} rio_t; code/include/csapp.h code/src/csapp.c 1void rio_readinitb(rio_t *rp, int fd) 2{ 3 rp->rio_fd = fd; 4 rp->rio_cnt = 0; 5 rp->rio_bufptr = rp->rio_buf; 6} code/src/csapp.c Figure 10.5 read buffer type rio_t rio_readinitb function initializes it.Section 10.4 Robust Reading Writing Rio Package 871 code/src/csapp.c 1static ssize_t rio_read(rio_t *rp, char *usrbuf, size_t n) 2{ 3 int cnt; 4 5 (rp->rio_cnt <= 0) { /* Refill buf empty */ 6 rp->rio_cnt = read(rp->rio_fd, rp->rio_buf, 7 sizeof(rp->rio_buf)); 8 (rp->rio_cnt < 0) { 9 (errno != EINTR) /* Interrupted sig handler return */ 10 return -1; 11 } 12 else (rp->rio_cnt == 0) /* EOF */ 13 return 0; 14 else 15 rp->rio_bufptr = rp->rio_buf; /* Reset buffer ptr */ 16 } 17 18 /* Copy min(n, rp->rio_cnt) bytes internal buf user buf */ 19 c n t=n ; 20 (rp->rio_cnt < n) 21 cnt = rp->rio_cnt; 22 memcpy(usrbuf, rp->rio_bufptr, cnt); 23 rp->rio_bufptr += cnt; 24 rp->rio_cnt -= cnt; 25 return cnt; 26 } code/src/csapp.c Figure 10.6 internal rio_read function. unread bytes read buffer. buffer empty, replenished call read . Receiving short count invocation read er- ror, simply effect partially ﬁlling read buffer. buffer isnonempty, rio_read copies minimum nandrp->rio_cnt bytes read buffer user buffer returns number bytes copied. application program, rio_read function semantics Unix read function. error, returns −1 sets errno appropriately. EOF, returns 0. returns short count number requested bytes exceedsthe number unread bytes read buffer. similarity two functionsmakes easy build different kinds buffered read functions substitutingrio_read forread . example, rio_readnb function Figure 10.7 structure rio_readn , rio_read substituted read . Similarly, rio_readlineb routine Figure 10.7 calls rio_read maxlen-1 times. call returns 1 byte read buffer, checked terminating newline.code/src/csapp.c 1ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen) 2{ 3 int n, rc; 4 char c, *bufp = usrbuf; 5 6 (n = 1; n < maxlen; n++) { 7 ((rc = rio_read(rp, &c, 1)) == 1) { 8 *bufp++ = c; 9 (c == ’\n’) 10 break; 11 } else (rc == 0) { 12 (n == 1) 13 return 0; /* EOF, data read */ 14 else 15 break; /* EOF, data read */ 16 } else 17 return -1; /* Error */ 18 } 19 *bufp = 0; 20 return n; 21 } code/src/csapp.c code/src/csapp.c 1ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n) 2{ 3 size_t nleft = n; 4 ssize_t nread; 5 char *bufp = usrbuf; 6 7 (nleft > 0) { 8 ((nread = rio_read(rp, bufp, nleft)) < 0) { 9 (errno == EINTR) /* Interrupted sig handler return */ 10 nread = 0; /* Call read() */ 11 else 12 return -1; /* errno set read() */ 13 } 14 else (nread == 0) 15 break; /* EOF */ 16 nleft -= nread; 17 bufp += nread; 18 } 19 return (n - nleft); /* Return >= 0 */ 20 } code/src/csapp.c Figure 10.7 Therio_readlineb andrio_readnb functions.Section 10.5 Reading File Metadata 873 Aside Origins Rio package Riofunctions inspired readline ,readn , writen functions described W. Richard Stevens classic network programming text [109]. rio_readn andrio_writen functions identical Stevens readn andwriten functions. However, Stevens readline function limitations corrected Rio. First, readline buffered readn not, two functions cannot used together descriptor. Second, uses static buffer, Stevens readline function thread-safe, required Stevens introduce different thread- safe version called readline_r . corrected ﬂaws rio_readlineb rio_readnb functions, mutually compatible thread-safe. 10.5 Reading File Metadata application retrieve information ﬁle (sometimes called ﬁle’s metadata ) calling stat andfstat functions. #include <unistd.h> #include <sys/stat.h> int stat(const char *filename, struct stat *buf); int fstat(int fd, struct stat *buf); Returns: 0 OK, −1 error Thestat function takes input ﬁle name ﬁlls members stat structure shown Figure 10.8. fstat function similar, takes ﬁle statbuf.h (included sys/stat.h) /* Metadata returned stat fstat functions */ struct stat { dev_t st_dev; /* Device */ ino_t st_ino; /* inode */ mode_t st_mode; /* Protection file type */ nlink_t st_nlink; /* Number hard links */ uid_t st_uid; /* User ID owner */ gid_t st_gid; /* Group ID owner */ dev_t st_rdev; /* Device type (if inode device) */ off_t st_size; /* Total size, bytes */ unsigned long st_blksize; /* Blocksize filesystem I/O */ unsigned long st_blocks; /* Number blocks allocated */ time_t st_atime; /* Time last access */ time_t st_mtime; /* Time last modification */ time_t st_ctime; /* Time last change */ }; statbuf.h (included sys/stat.h) Figure 10.8 Thestat structure.874 Chapter 10 System-Level I/O Macro Description S_ISREG() regular ﬁle? S_ISDIR() directory ﬁle? S_ISSOCK() network socket? Figure 10.9 Macros determining ﬁle type st_mode bits. Deﬁned sys/stat.h . descriptor instead ﬁle name. need st_mode andst_size members stat structure discuss Web servers Section 11.5. members beyond scope. Thest_size member contains ﬁle size bytes. st_mode member en- codes ﬁle permission bits (Figure 10.1) ﬁle type . Unix recognizes number different ﬁle types. regular ﬁle contains sort binary text data. kernel difference text ﬁles binary ﬁles. Adirectory ﬁle contains information ﬁles. socket ﬁle used communicate another process across network (Section 11.4). Unix provides macro predicates determining ﬁle type st_ mode member. Figure 10.9 lists subset macros. code/io/statcheck.c 1#include "csapp.h" 2 3int main (int argc, char **argv) 4{ 5 struct stat stat; 6 char *type, *readok; 7 8 Stat(argv[1], &stat); 9 (S_ISREG(stat.st_mode)) /* Determine file type */ 10 type = "regular"; 11 else (S_ISDIR(stat.st_mode)) 12 type = "directory"; 13 else 14 type = "other"; 15 ((stat.st_mode & S_IRUSR)) /* Check read access */ 16 readok = "yes"; 17 else 18 readok = "no"; 19 20 printf("type: %s, read: %s\n", type, readok); 21 exit(0); 22 } code/io/statcheck.c Figure 10.10 Querying manipulating ﬁle’s st_mode bits.Section 10.6 Sharing Files 875 Figure 10.10 shows might use macros stat function read interpret ﬁle’s st_mode bits. 10.6 Sharing Files Unix ﬁles shared number different ways. Unless clear picture kernel represents open ﬁles, idea ﬁle sharing quiteconfusing. kernel represents open ﬁles using three related data structures: .Descriptor table. process separate descriptor table whose en- tries indexed process’s open ﬁle descriptors. open descriptorentry points entry ﬁle table. .File table. set open ﬁles represented ﬁle table shared processes. ﬁle table entry consists (for purposes) current ﬁleposition, reference count number descriptor entries currently point it, pointer entry v-node table . Closing descriptor decrements reference count associated ﬁle table entry. kernel delete ﬁle table entry reference count zero. .v-node table. Like ﬁle table, v-node table shared processes. entry contains information stat structure, including thest_mode andst_size members. Figure 10.11 shows example descriptors 1 4 reference two different ﬁles distinct open ﬁle table entries. typical situation,where ﬁles shared, descriptor corresponds distinctﬁle. Multiple descriptors also reference ﬁle different ﬁle table entries, shown Figure 10.12. might happen, example, youwere call open function twice filename . key idea descriptor distinct ﬁle position, different reads differentdescriptors fetch data different locations ﬁle. Figure 10.11 Typical kernel datastructures open ﬁles. example, two descriptors referencedistinct ﬁles. nosharing.Descriptor table (one table per process)Open file table (shared processes)v-node table (shared processes) stdin fd 0 stdout fd 1 stderr fd 2 fd 3 fd 4File sizeFile access File type File B File pos refcnt /H110051 …File File pos refcnt /H110051 …… File sizeFile access File type…876 Chapter 10 System-Level I/O Figure 10.12 File sharing. example shows two descriptorssharing disk ﬁlethrough two open ﬁle tableentries.Descriptor table (one table per process)Open file table (shared processes)v-node table (shared processes) fd 0 fd 1fd 2fd 3 fd 4File sizeFile access File type File B File pos refcnt /H110051 …File File pos refcnt /H110051 …… Figure 10.13 child process inherits parent’s open ﬁles. initial situation Figure 10.11.Descriptor tables Open file table (shared processes)v-node table (shared processes) fd 0 fd 1 fd 2 fd 3 fd 4File sizeFile access File type File B File pos refcnt /H110052 …File Parent’s table fd 0 fd 1 fd 2 fd 3 fd 4Child’s tableFile pos refcnt /H110052 …… File sizeFile access File type… also understand parent child processes share ﬁles. Suppose call fork , parent process open ﬁles shown Fig- ure 10.11. Figure 10.13 shows situation call fork . child gets duplicate copy parent’s descriptor table. Parent child sharethe set open ﬁle tables, thus share ﬁle position. importantconsequence parent child must close descriptors beforethe kernel delete corresponding ﬁle table entry. Practice Problem 10.2 Suppose disk ﬁle foobar.txt consists six ASCII characters “ foobar ”. output following program? 1#include "csapp.h" 2 3int main()Section 10.7 I/O Redirection 877 4{ 5 int fd1, fd2; 6 char c; 7 8 fd1 = Open("foobar.txt", O_RDONLY, 0); 9 fd2 = Open("foobar.txt", O_RDONLY, 0); 10 Read(fd1, &c, 1); 11 Read(fd2, &c, 1); 12 printf("c = %c\n", c); 13 exit(0); 14 } Practice Problem 10.3 before, suppose disk ﬁle foobar.txt consists six ASCII characters “foobar ”. output following program? 1#include "csapp.h" 2 3int main() 4{ 5 int fd; 6 char c; 78 fd = Open("foobar.txt", O_RDONLY, 0); 9 (Fork() == 0) { 10 Read(fd, &c, 1); 11 exit(0); 12 } 13 Wait(NULL); 14 Read(fd, &c, 1); 15 printf("c = %c\n", c); 16 exit(0); 17 } 10.7 I/O Redirection Unix shells provide I/O redirection operators allow users associate standard input output disk ﬁles. example, typing unix> ls > foo.txt causes shell load execute lsprogram, standard output redi- rected disk ﬁle foo.txt . see Section 11.5, Web server performs878 Chapter 10 System-Level I/O Figure 10.14 Kernel data structuresafter redirecting stan-dard output calling dup2(4,1) .The initial situation shown Fig-ure 10.11.Descriptor table (one table per process)Open file table (shared processes)v-node table (shared processes) fd 0 fd 1 fd 2 fd 3 fd 4File sizeFile access File type File B File pos refcnt /H110052 …File File pos refcnt /H110050 …… File sizeFile access File type… similar kind redirection runs CGI program behalf client. I/O redirection work? One way use dup2 function. #include <unistd.h> int dup2(int oldfd, int newfd); Returns: nonnegative descriptor OK, −1 error Thedup2 function copies descriptor table entry oldfd descriptor table entry newfd , overwriting previous contents descriptor table entry newfd .I fnewfd already open, dup2 closes newfd copies oldfd . Suppose calling dup2(4,1) situation Figure 10.11, descriptor 1 (standard output) corresponds ﬁle A(say, terminal), descriptor 4 corresponds ﬁle B(say, disk ﬁle). reference counts AandB equal 1. Figure 10.14 shows situation calling dup2(4,1) . descriptors point ﬁle B; ﬁleAhas closed ﬁle table v-node table entries deleted; reference count ﬁle Bhas incremented. point on, data written standard output redirected ﬁle B. Aside Right left hoinkies avoid confusion bracket-type operators ‘ ]’ ‘ [’, always referred shell’s ‘ >’ operator “right hoinky”, ‘ <’ operator “left hoinky”. Practice Problem 10.4 would use dup2 redirect standard input descriptor 5?Section 10.8 Standard I/O 879 Practice Problem 10.5 Assuming disk ﬁle foobar.txt consists six ASCII characters “foobar ”, output following program? 1#include "csapp.h" 2 3int main() 4{ 5 int fd1, fd2; 6 char c; 78 fd1 = Open("foobar.txt", O_RDONLY, 0); 9 fd2 = Open("foobar.txt", O_RDONLY, 0); 10 Read(fd2, &c, 1); 11 Dup2(fd2, fd1); 12 Read(fd1, &c, 1); 13 printf("c = %c\n", c); 14 exit(0); 15 } 10.8 Standard I/O ANSI C deﬁnes set higher level input output functions, called standard I/O library , provides programmers higher-level alternative Unix I/O. library ( libc ) provides functions opening closing ﬁles ( fopen andfclose ), reading writing bytes ( fread andfwrite ), reading writing strings ( fgets andfputs ), sophisticated formatted I/O ( scanf andprintf ). standard I/O library models open ﬁle stream . programmer, stream pointer structure type FILE . Every ANSI C program begins three open streams, stdin ,stdout , stderr , correspond standard input, standard output, standard error, respectively: #include <stdio.h> extern FILE *stdin; /* Standard input (descriptor 0) */ extern FILE *stdout; /* Standard output (descriptor 1) */ extern FILE *stderr; /* Standard error (descriptor 2) */ stream type FILE abstraction ﬁle descriptor stream buffer . purpose stream buffer Rio read buffer: minimize number expensive Unix I/O system calls. example, suppose wehave program makes repeated calls standard I/O getc function, invocation returns next character ﬁle. getc called ﬁrst time, library ﬁlls stream buffer single call read function, returns ﬁrst byte buffer application. long are880 Chapter 10 System-Level I/O unread bytes buffer, subsequent calls getc served directly stream buffer. 10.9 Putting Together: I/O Functions Use? Figure 10.15 summarizes various I/O packages discussed thischapter. Unix I/O implemented operating system kernel. availableto applications functions open ,close ,lseek ,read ,write , stat functions. higher-level Rioand standard I/O functions implemented “on top of” (using) Unix I/O functions. Riofunctions robust wrappers forread andwrite developed speciﬁcally textbook. au- tomatically deal short counts provide efﬁcient buffered approach forreading text lines. standard I/O functions provide complete bufferedalternative Unix I/O functions, including formatted I/O routines. functions use programs? standard I/O functions method choice I/O disk terminal devices. MostC programmers use standard I/O exclusively throughout careers, never both-ering lower-level Unix I/O functions. Whenever possible, recommendthat likewise. Unfortunately, standard I/O poses nasty problems attempt use input output networks. see Section 11.4, theUnix abstraction network type ﬁle called socket . Like Unix ﬁle, sockets referenced ﬁle descriptors, known case socket descriptors . Application processes communicate processes running computersby reading writing socket descriptors. Standard I/O streams full duplex sense programs perform input output stream. However, poorly documentedrestrictions streams interact badly restrictions sockets: .Restriction 1: Input functions following output functions. input function cannot follow output function without intervening call fflush ,fseek , fsetpos ,o rrewind .T h e fflush function empties buffer associated C application program Standard I/O functionsRIO functions Unix I/O functions (accessed via system calls)fopen freadfscanfsscanffgetsfflushfclosefdopen fwritefprintfsprintffputsfseekrio_readn rio_writenrio_readinitbrio_readlinebrio_readnb open writestatread lseekclose Figure 10.15 Relationship Unix I/O, standard I/O, Rio.Section 10.10 Summary 881 stream. latter three functions use Unix I/O lseek function reset current ﬁle position. .Restriction 2: Output functions following input functions. output function cannot follow input function without intervening call fseek ,fsetpos , orrewind , unless input function encounters end-of-ﬁle. restrictions pose problem network applications illegal use lseek function socket. ﬁrst restriction stream I/O worked around adopting discipline ﬂushing buffer every inputoperation. However, way work around second restriction open two streams open socket descriptor, one reading one writing: FILE *fpin, *fpout; fpin = fdopen(sockfd, "r"); fpout = fdopen(sockfd, "w"); approach problems well, requires application call fclose streams order free memory resources associated stream avoid memory leak: fclose(fpin); fclose(fpout); operations attempts close underlying socket descrip- tor, second close operation fail. problem sequential programs, closing already closed descriptor threaded program arecipe disaster (see Section 12.7.4). Thus, recommend use standard I/O functions input output network sockets. Use robust Riofunctions instead. need formatted output, use sprintf function format string memory, send socket using rio_writen . need formatted input, use rio_ readlineb read entire text line, use sscanf extract different ﬁelds text line. 10.10 Summary Unix provides small number system-level functions allow applications toopen, close, read, write ﬁles; fetch ﬁle metadata; perform I/O redirection. Unix read write operations subject short counts applications must anticipate handle correctly. Instead calling Unix I/O functionsdirectly, applications use Rio package, deals short counts automatically repeatedly performing read write operations therequested data transferred. Unix kernel uses three related data structures represent open ﬁles. Entries descriptor table point entries open ﬁle table, point882 Chapter 10 System-Level I/O entries v-node table. process distinct descriptor table, processes share open ﬁle v-node tables. Understanding thegeneral organization structures clariﬁes understanding ﬁlesharing I/O redirection. standard I/O library implemented top Unix I/O provides powerful set higher-level I/O routines. applications, standard I/O thesimpler, preferred alternative Unix I/O. However, mutuallyincompatible restrictions standard I/O network ﬁles, Unix I/O, rather thanstandard I/O, used network applications. Bibliographic Notes Stevens wrote standard reference text Unix I/O [110]. Kernighan andRitchie give clear complete discussion standard I/O functions [58]. Homework Problems 10.6◆ output following program? 1#include "csapp.h" 2 3int main() 4{ 5 int fd1, fd2; 67 fd1 = Open("foo.txt", O_RDONLY, 0); 8 fd2 = Open("bar.txt", O_RDONLY, 0); 9 Close(fd2); 10 fd2 = Open("baz.txt", O_RDONLY, 0); 11 printf("fd2 = %d\n", fd2); 12 exit(0); 13 } 10.7◆ Modify cpfile program Figure 10.4 uses Riofunctions copy standard input standard output, MAXBUF bytes time. 10.8◆◆ Write version statcheck program Figure 10.10, called fstatcheck , takes descriptor number command line rather ﬁle name. 10.9◆◆ Consider following invocation fstatcheck program Problem 10.8: unix> fstatchec k 3 < foo.txtSolutions Practice Problems 883 might expect invocation fstatcheck would fetch display metadata ﬁle foo.txt . However, run system, fails “bad ﬁle descriptor.” Given behavior, ﬁll pseudo-code shellmust executing fork andexecve calls: (Fork() == 0) { /* Child */ /* code shell executing right here? */Execve("fstatcheck", argv, envp); } 10.10 ◆◆ Modify cpfile program Figure 10.4 takes optional command line argument infile .I finfile given, copy infile standard output; otherwise, copy standard input standard output before. twist yoursolution must use original copy loop (lines 9–11) cases. onlyallowed insert code, allowed change existing code. Solutions Practice Problems Solution Problem 10.1 (page 865) Unix processes begin life open descriptors assigned stdin (descriptor 0), stdout (descriptor 1), stderr (descriptor 2). open function always re- turns lowest unopened descriptor, ﬁrst call open returns descriptor 3. call close function frees descriptor 3. ﬁnal call open returns descriptor 3, thus output program “ f 2=3 ”. Solution Problem 10.2 (page 876) descriptors fd1 andfd2 open ﬁle table entry, descriptor ﬁle position foobar.txt . Thus, read fd2reads ﬁrst byte foobar.txt , output c=f c=o might thought initially. Solution Problem 10.3 (page 877) Recall child inherits parent’s descriptor table processes shared open ﬁle table. Thus, descriptor fdin parent child points open ﬁle table entry. child reads ﬁrst byte ﬁle, ﬁle position increases one. Thus, parent reads second byte, output c=o884 Chapter 10 System-Level I/O Solution Problem 10.4 (page 878) redirect standard input (descriptor 0) descriptor 5, would call dup2(5,0) , equivalently, dup2(5,STDIN_FILENO) . Solution Problem 10.5 (page 879) ﬁrst glance, might think output would c=f redirecting fd1tofd2, output really c=oCHAPTER11 Network Programming 11.1 Client-Server Programming Model 886 11.2 Networks 887 11.3 Global IP Internet 891 11.4 Sockets Interface 900 11.5 Web Servers 911 11.6 Putting Together: Tiny Web Server 919 11.7 Summary 927 Bibliographic Notes 928 Homework Problems 928 Solutions Practice Problems 929 885886 Chapter 11 Network Programming Network applications everywhere. time browse Web, send email message, pop X window, using network application.Interestingly, network applications based basic programmingmodel, similar overall logical structures, rely programminginterface. Network applications rely many concepts already learned study systems. example, processes, signals, byte ordering,memory mapping, dynamic storage allocation play important roles. new concepts master well. need understand basic client-server programming model write client-server programs use theservices provided Internet. end, tie ideas togetherby developing small functional Web server serve static anddynamic content text graphics real Web browsers. 11.1 Client-Server Programming Model Every network application based client-server model . model, application consists server process one client processes. server manages resource , provides service clients manipulating resource. example, Web server manages set disk ﬁles retrievesand executes behalf clients. FTP server manages set disk ﬁles itstores retrieves clients. Similarly, email server manages spool ﬁle reads updates clients. fundamental operation client-server model transaction (Fig- ure 11.1). client-server transaction consists four steps: 1.When client needs service, initiates transaction sending request server. example, Web browser needs ﬁle, sends requestto Web server. 2.The server receives request, interprets it, manipulates resources appropriate way. example, Web server receives request froma browser, reads disk ﬁle. 3.The server sends response client, waits next request. example, Web server sends ﬁle back client. 4.The client receives response manipulates it. example, Web browser receives page server, displays screen. 4. Client processes response1. Client sends request 3. Server sends response 2. Server processes requestClient processServer process Resource Figure 11.1 client-server transaction.Section 11.2 Networks 887 important realize clients servers processes ma- chines, hosts often called context. single host run many different clients servers concurrently, client server transaction canbe different hosts. client-server model same, regardlessof mapping clients servers hosts. Aside Client-server transactions vs. database transactions Client-server transactions notdatabase transactions share properties, atomicity. context, transaction simply sequence steps carried client server. 11.2 Networks Clients servers often run separate hosts communicate using hard- ware software resources computer network . Networks sophisticated systems, hope scratch surface here. aim give youa workable mental model programmer’s perspective. host, network another I/O device serves source sink data, shown Figure 11.2. adapter plugged expansion slot onthe I/O bus provides physical interface network. Data received thenetwork copied adapter across I/O memory buses memory,typically DMA transfer. Similarly, data also copied memory tothe network. Figure 11.2 Hardware organizationof network host.CPU chip Register file ALU Bus interfaceI/O bridgeSystem bus Memory bus Main memory I/O busExpansion slots Disk controllerNetwork adapter NetworkGraphics adapter Monitor Mouse KeyboardUSB controller Disk888 Chapter 11 Network Programming Figure 11.3 Ethernet segment.Host Host Host Hub100 Mb/s 100 Mb/s Physically, network hierarchical system organized geographical proximity. lowest level LAN (Local Area Network) spans abuilding campus. popular LAN technology far Ethernet , developed mid-1970s Xerox PARC. Ethernet proven tobe remarkably resilient, evolving 3 Mb/s 10 Gb/s. AnEthernet segment consists wires (usually twisted pairs wires) small box called hub, shown Figure 11.3. Ethernet segments typically span small areas, room ﬂoor building. wire samemaximum bit bandwidth, typically 100 Mb/s 1 Gb/s. One end attached toan adapter host, end attached port hub. hub slavishly copies every bit receives port every port. Thus,every host sees every bit. Ethernet adapter globally unique 48-bit address stored non-volatile memory adapter. host send chunk bits called aframe host segment. frame includes ﬁxed number ofheader bits identify source destination frame frame length, followed payload data bits. Every host adapter sees frame, destination host actually reads it. Multiple Ethernet segments connected larger LANs, called bridged Ethernets , using set wires small boxes called bridges , shown Figure 11.4. Bridged Ethernets span entire buildings campuses. abridged Ethernet, wires connect bridges bridges, others connectbridges hubs. bandwidths wires different. example,the bridge–bridge wire ha 1 Gb/s bandwidth, four hub–bridge wires bandwidths 100 Mb/s. Bridges make better use available wire bandwidth hubs. Using clever distributed algorithm, automatically learn time hosts arereachable ports, selectively copy frames one port toanother necessary. example, host sends frame host B,which segment, bridge X throw away frame arrivesat input port, thus saving bandwidth segments. However, host sends frame host C different segment, bridge X copy frameonly port connected bridge Y, copy frame portconnected bridge C’s segment. simplify pictures LANs, draw hubs bridges wires connect single horizontal line, shown Figure 11.5. higher level hierarchy, multiple incompatible LANs con- nected specialized computers called routers form internet (interconnected network).Section 11.2 Networks 889 Host Host Host Hub Bridge BridgeHost Host100 Mb/s 100 Mb/s 100 Mb/s100 Mb/s 1 Gb/s Host HostHub Host HostHubHost Host Hub Host CXA B Figure 11.4 Bridged Ethernet segments. Aside Internet vs. internet always use lowercase internet denote general concept, uppercase Internet denote speciﬁc implementation, namely global IP Internet. router adapter (port) network connected to. Routers also connect high-speed point-to-point phone connections, areexamples networks known WANs (Wide-Area Networks), called becausethey span larger geographical areas LANs. general, routers used build internets arbitrary collections LANs WANs. example,Figure 11.6 shows example internet pair LANs WANs connected three routers. crucial property internet consist different LANs WANs radically different incompatible technologies. host isphysically connected every host, possible source host send data bits another destination host across incompatible networks? solution layer protocol software running host router smoothes differences different networks. software Figure 11.5 Conceptual view LAN.Host Host Host . . .890 Chapter 11 Network Programming Host Host Host . . . LANHost Host Host . . . LAN WAN WANRouter Router Router Figure 11.6 small internet. Two LANs two WANs connected three routers. implements protocol governs hosts routers cooperate order transfer data. protocol must provide two basic capabilities: .Naming scheme. Different LAN technologies different incompatible ways assigning addresses hosts. internet protocol smoothes thesedifferences deﬁning uniform format host addresses. host thenassigned least one internet addresses uniquely identiﬁes it. .Delivery mechanism. Different networking technologies different incompatible ways encoding bits wires packaging bitsinto frames. internet protocol smoothes differences deﬁning auniform way bundle data bits discrete chunks called packets .A packet consists header , contains packet size addresses source destination hosts, payload , contains data bits sent source host. Figure 11.7 shows example hosts routers use internet protocol transfer data across incompatible LANs. example internet consistsof two LANs connected router. client running host A, attachedto LAN1, sends sequence data bytes server running host B, isattached LAN2. eight basic steps: 1.The client host invokes system call copies data client’s virtual address space kernel buffer. 2.The protocol software host creates LAN1 frame appending internet header LAN1 frame header data. internet headeris addressed internet host B. LAN1 frame header addressed therouter. passes frame adapter. Notice payload LAN1 frame internet packet, whose payload actual user data. kind encapsulation one fundamental insights internetworking. 3.The LAN1 adapter copies frame network. 4.When frame reaches router, router’s LAN1 adapter reads wire passes protocol software. 5.The router fetches destination internet address internet packet header uses index routing table determine forward packet, case LAN2. router strips theSection 11.3 Global IP Internet 891 Host Client Protocol software Protocol softwareLAN1 adapterHost B Server Protocol softwareData internet packet LAN1 frame LAN1 LAN2(1) Data PH FH1 (2) Lan 2 frame Data PH FH2 (5)Data PH FH1 (3) Data PH FH2 (6)Data PH FH2 (7)Data (8) Data PH FH1 (4)LAN1 adapterLAN2 adapterRouterLAN2 adapter Figure 11.7 data travels one host another internet. Key: PH: internet packet header; FH1: frame header LAN1; FH2: frame header LAN2. old LAN1 frame header, prepends new LAN2 frame header addressed host B, passes resulting frame adapter. 6.The router’s LAN2 adapter copies frame network. 7.When frame reaches host B, adapter reads frame wire passes protocol software. 8.Finally, protocol software host B strips packet header frame header. protocol software eventually copy resulting data theserver’s virtual address space server invokes system call readsthe data. course, glossing many difﬁcult issues here. different net- works different maximum frame sizes? routers know for-ward frames? routers informed network topology changes?What packet gets lost? Nonetheless, example captures essence theinternet idea, encapsulation key. 11.3 Global IP Internet global IP Internet famous successful implementation aninternet. existed one form another since 1969. internalarchitecture Internet complex constantly changing, organizationof client-server applications remained remarkably stable since early 1980s.Figure 11.8 shows basic hardware software organization Internet892 Chapter 11 Network Programming Figure 11.8 Hardware softwareorganization anInternet application. ClientInternet client host User code Sockets interface (system calls) Hardware interface (interrupts)TCP/IP Kernel code Network adapterServerInternet server host TCP/IP Network adapterHardware Global IP Internet client-server application. Internet host runs software implements TCP/IP protocol (Transmission Control Protocol/Internet Protocol), supported almost every modern computer system. Internet clients serverscommunicate using mix sockets interface functions Unix I/O functions. (We describe sockets interface Section 11.4.) sockets functions aretypically implemented system calls trap kernel call variouskernel-mode functions TCP/IP . TCP/IP actually family protocols, contributes different capabilities. example, IP protocol provides basic naming scheme anda delivery mechanism send packets, known datagrams , one Internet host host. IP mechanism unreliable sensethat makes effort recover datagrams lost duplicated thenetwork. UDP (Unreliable Datagram Protocol) extends IP slightly, packetscan transferred process process, rather host host. TCP acomplex protocol builds IP provide reliable full duplex (bidirectional)connections processes. simplify discussion, treat TCP/IPas single monolithic protocol. discuss inner workings, willonly discuss basic capabilities TCP IP provide applicationprograms. discuss UDP . programmer’s perspective, think Internet worldwide collection hosts following properties: .The set hosts mapped set 32-bit IP addresses. .The set IP addresses mapped set identiﬁers called Internet domain names. .A process one Internet host communicate process otherInternet host connection. next three sections discuss fundamental Internet ideas detail.Section 11.3 Global IP Internet 893 netinet/in.h /* Internet address structure */ struct in_addr { unsigned int s_addr; /* Network byte order (big-endian) */ }; netinet/in.h Figure 11.9 IP address structure. 11.3.1 IP Addresses IP address unsigned 32-bit integer. Network programs store IP addresses IP address structure shown Figure 11.9. Aside store scalar IP address structure? Storing scalar address structure unfortunate artifact early implementations sockets interface. would make sense deﬁne scalar type IP addresses, late change enormous installed base applications. Internet hosts different host byte orders, TCP/IP deﬁnes uniform network byte order (big-endian byte order) integer data item, IP address, carried across network packet header. Addresses inIP address structures always stored (big-endian) network byte order, even host byte order little-endian. Unix provides following functions converting network host byte order: #include <netinet/in.h> unsigned long int htonl(unsigned long int hostlong); unsigned short int htons(unsigned short int hostshort); Returns: value network byte order unsigned long int ntohl(unsigned long int netlong); unsigned short int ntohs(unsigned short int netshort); Returns: value host byte order Thehtonl function converts 32-bit integer host byte order network byte order. ntohl function converts 32-bit integer network byte or- der host byte order. htons andntohs functions perform corresponding conversions 16-bit integers. IP addresses typically presented humans form known dotted- decimal notation , byte represented decimal value sep- arated bytes period. example, 128.2.194.242 dotted-decimal representation address 0x8002c2f2 . Linux systems, you894 Chapter 11 Network Programming use hostname command determine dotted-decimal address host: linux> hostname -i 128.2.194.242 Internet programs convert back forth IP addresses dotted- decimal strings using functions inet_aton andinet_ntoa : #include <arpa/inet.h> int inet_aton(const char *cp, struct in_addr *inp); Returns: 1 OK, 0 error char *inet_ntoa(struct in_addr in); Returns: pointer dotted-decimal string Theinet_aton function converts dotted-decimal string ( cp) IP address network byte order ( inp). Similarly, inet_ntoa function converts IP address network byte order corresponding dotted-decimal string. Noticethat call inet_aton passes pointer structure, call inet_ntoa passes structure itself. Aside ntoa andaton mean? “ n” denotes network representation. “ a” denotes application representation. “ to” means to. Practice Problem 11.1 Complete following table: Hex address Dotted-decimal address 0x0 0xffffffff 0x7f000001 205.188.160.121 64.12.149.13 205.188.146.23 Practice Problem 11.2 Write program hex2dd.c converts hex argument dotted-decimal string prints result. example,Section 11.3 Global IP Internet 895 unix> ./hex2dd 0x8002c2f2 128.2.194.242 Practice Problem 11.3 Write program dd2hex.c converts dotted-decimal argument hex number prints result. example, unix> ./dd2hex 128.2.194.242 0x8002c2f2 11.3.2 Internet Domain Names Internet clients servers use IP addresses communicate other. However, large integers difﬁcult people remember, Internetalso deﬁnes separate set human-friendly domain names , well mechanism maps set domain names set IP addresses. domainname sequence words (letters, numbers, dashes) separated periods,such kittyhawk.cmcl.cs.cmu.edu set domain names forms hierarchy, domain name encodes position hierarchy. example easiest way understand this.Figure 11.10 shows portion domain name hierarchy. hierarchy mil edu gov com cmu mit cs ece kittyhawk 128.2.194.242cmclunnamed root pdl imperial 128.2.189.40amazon www 208.216.181.15First-level domain names Second-level domain name Third-level domain namesberkeley Figure 11.10 Subset Internet domain name hierarchy.896 Chapter 11 Network Programming netdb.h /* DNS host entry structure */ struct hostent { char *h_name; /* Official domain name host */ char **h_aliases; /* Null-terminated array domain names */ int h_addrtype; /* Host address type (AF_INET) */ int h_length; /* Length address, bytes */ char **h_addr_list; /* Null-terminated array in_addr structs */ }; netdb.h Figure 11.11 DNS host entry structure. represented tree. nodes tree represent domain names formed path back root. Subtrees referred subdomains .T h e ﬁrst level hierarchy unnamed root node. next level collectionofﬁrst-level domain names deﬁned nonproﬁt organization called ICANN (Internet Corporation Assigned Names Numbers). Common ﬁrst-level domains include com,edu,gov,org, net. next level second-level domain names cmu.edu , assigned ﬁrst-come ﬁrst-serve basis various authorized agents ICANN.Once organization received second-level domain name, free tocreate new domain name within subdomain. Internet deﬁnes mapping set domain names set IP addresses. 1988, mapping maintained manually sin-gle text ﬁle called HOSTS.TXT . Since then, mapping maintained distributed world-wide database known DNS (Domain Name System). Con- ceptually, DNS database consists millions host entry structures shown Figure 11.11, deﬁnes mapping set domain names(an ofﬁcial name list aliases) set IP addresses. mathematicalsense, think host entry equivalence class domain namesand IP addresses. Internet applications retrieve arbitrary host entries DNS database calling gethostbyname andgethostbyaddr functions. #include <netdb.h> struct hostent *gethostbyname(const char *name); Returns: non-NULL pointer OK, NULL pointer error h_errno set struct hostent *gethostbyaddr(const char *addr, int len, 0); Returns: non-NULL pointer OK, NULL pointer error h_errno set Thegethostbyname function returns host entry associated do- main name name .T h e gethostbyaddr function returns host entry associated IP address addr . second argument gives length bytes IPSection 11.3 Global IP Internet 897 code/netp/hostinfo.c 1#include "csapp.h" 2 3int main(int argc, char **argv) 4{ 5 char **pp; 6 struct in_addr addr; 7 struct hostent *hostp; 89 (argc != 2) { 10 fprintf(stderr, "usage: %s <domain name dotted-decimal>\n", 11 argv[0]); 12 exit(0); 13 } 1415 (inet_aton(argv[1], &addr) != 0) 16 hostp = Gethostbyaddr((const char *)&addr, sizeof(addr), AF_INET); 17 else 18 hostp = Gethostbyname(argv[1]); 1920 printf("official hostname: %s\n", hostp->h_name); 2122 (pp = hostp->h_aliases; *pp != NULL; pp++) 23 printf("alias: %s\n", *pp); 24 25 (pp = hostp->h_addr_list; *pp != NULL; pp++) { 26 addr.s_addr = ((struct in_addr *)*pp)->s_addr; 27 printf("address: %s\n", inet_ntoa(addr)); 28 } 29 exit(0); 30 } code/netp/hostinfo.c Figure 11.12 Retrieves prints DNS host entry. address, current Internet always 4 bytes. purposes, third argument always zero. explore properties DNS mapping hostinfo program Figure 11.12, reads domain name dotted-decimal address command line displays corresponding host entry. Internet host locally deﬁned domain name localhost , always maps loopback address 127.0.0.1 : unix> ./hostinfo localhost official hostname: localhost alias: localhost.localdomain address: 127.0.0.1898 Chapter 11 Network Programming Thelocalhost name provides convenient portable way reference clients servers running machine, especiallyuseful debugging. use hostname determine real domain name local host: unix> hostname bluefish.ics.cs.cmu.edu simplest case, one-to-one mapping domain name IP address: unix> ./hostinfo bluefish.ics.cs.cmu.edu official hostname: bluefish.ics.cs.cmu.edu alias: bluefish.alias.cs.cmu.edu address: 128.2.205.216 However, cases, multiple domain names mapped IP address: unix> ./hostinfo cs.mit.edu official hostname: eecs.mit.edualias: cs.mit.edu address: 18.62.1.6 general case, multiple domain names mapped multiple IP addresses: unix> ./hostinfo google.com official hostname: google.com address: 74.125.45.100 address: 74.125.67.100 address: 74.125.127.100 Finally, notice valid domain names mapped IP address: unix> ./hostinfo edu Gethostbyname error: address associated name unix> ./hostinfo cmcl.cs.cmu.edu Gethostbyname error: address associated name Aside many Internet hosts there? Twice year since 1987, Internet Software Consortium conducts Internet Domain Survey .T h e survey, estimates number Internet hosts counting number IP addresses assigned domain name, reveals amazing trend. Since 1987, 20,000 Internet hosts, number hosts roughly doubled year. June 2009, nearly 700,000,000 Internet hosts!Section 11.3 Global IP Internet 899 Practice Problem 11.4 Compile hostinfo program Figure 11.12. run hostinfo google.com three times row system. A. notice ordering IP addresses three host entries? B. might ordering useful? 11.3.3 Internet Connections Internet clients servers communicate sending receiving streams bytes connections . connection point-to-point sense connects pair processes. full-duplex sense data ﬂow directions time. reliable sense that—barring catastrophic failure cable cut proverbial careless backhoe operator—the stream bytes sent source process eventually received destination processin order sent. Asocket end point connection. socket corresponding socket address consists Internet address 16-bit integer port, denoted address:port . port client’s socket address assigned automatically kernel client makes connection request, isknown ephemeral port . However, port server’s socket address typically well-known port associated service. example, Web servers typically use port 80, email servers use port 25. Unix machines,the ﬁle /etc/services contains comprehensive list services provided machine, along well-known ports. connection uniquely identiﬁed socket addresses two end- points. pair socket addresses known socket pair denoted tuple (cliaddr:cliport, servaddr:servport) cliaddr client’s IP address, cliport client’s port, servaddr server’s IP address, servport server’s port. example, Fig- ure 11.13 shows connection Web client Web server. Client Client host address 128.2.194.242Connection socket pair (128.2.194.242:51213, 208.216.181.15:80)Server (port 80) Server host address 208.216.181.15Client socket address 128.2.194.242:51213Server socket address 208.216.181.15:80 Figure 11.13 Anatomy Internet connection.900 Chapter 11 Network Programming example, Web client’s socket address 128.2.194.242:51213 port 51213 ephemeral port assigned kernel. Web server’s socket address 208.216.181.15:80 port 80is well-known port associated Web services. Given client server socket addresses, connection client serveris uniquely identiﬁed socket pair (128.2.194.242:51213, 208.216.181.15:80) Aside Origins Internet Internet one successful examples government, university, industry partnership. Many factors contributed success, think two particularly important: sustained 30-year investment United States government, commitment passionate researchers Dave Clarke MIT dubbed “rough consensus working code.” seeds Internet sown 1957, when, height Cold War, Soviet Union shocked world launching Sputnik, ﬁrst artiﬁcial earth satellite. response, UnitedStates government created Advanced Research Projects Agency (ARPA), whose charter toreestablish U.S. lead science technology. 1967, Lawrence Roberts ARPA publishedplans new network called ARPANET. ﬁrst ARPANET nodes running 1969. 1971, 13 ARPANET nodes, email emerged ﬁrst important network application. 1972, Robert Kahn outlined general principles internetworking: collection intercon- nected networks, communication networks handled independently “best-effort basis” black boxes called “routers.” 1974, Kahn Vinton Cerf published ﬁrst details TCP/IP , 1982 become standard internetworking protocol ARPANET. January 1, 1983, every node ARPANET switched TCP/IP , marking birth global IP Internet. 1985, Paul Mockapetris invented DNS, 1000 Internet hosts. next year, National Science Foundation (NSF) built NSFNET backbone connecting 13 sites 56 Kb/s phone lines. later upgraded 1.5 Mb/s T1 links 1988, 45 Mb/s T3 links 1991. 1988, 50,000 hosts. 1989, original ARPANET ofﬁcially retired. 1995, almost 10,000,000 Internet hosts, NSF retired NSFNET replaced modern Internet architecture based private commercial backbones connected public network access points. 11.4 Sockets Interface sockets interface set functions used conjunction Unix I/O functions build network applications. implemented mostmodern systems, including Unix variants, Windows, Macintosh systems.Section 11.4 Sockets Interface 901 Client socket open_clientfdopen_listenfd connect rio_writen rio_readlineb rio_readlineb closeServer Connection request Await connection request next client EOFsocket bind listen accept rio_writen rio_readlineb close Figure 11.14 Overview sockets interface. Figure 11.14 gives overview sockets interface context typical client-server transaction. use picture road map wediscuss individual functions. Aside Origins sockets interface sockets interface developed researchers University California, Berkeley, early 1980s. reason, often referred Berkeley sockets . Berkeley researchers developed sockets interface work underlying protocol. ﬁrst implementation TCP/IP , included Unix 4.2BSD kernel distributed numerous universities labs. important event Internet history. Almost overnight, thousands people access TCP/IP source codes. generated tremendous excitement sparked ﬂurry new researchin networking internetworking. 11.4.1 Socket Address Structures perspective Unix kernel, socket end point communi- cation. perspective Unix program, socket open ﬁle acorresponding descriptor. Internet socket addresses stored 16-byte structures type sockaddr_in , shown Figure 11.15. Internet applications, sin_family member AF_INET, sin_port member 16-bit port number, sin_ addr member 32-bit IP address. IP address port number always stored network (big-endian) byte order.902 Chapter 11 Network Programming sockaddr: socketbits.h (included socket.h), sockaddr_in: netinet/in.h /* Generic socket address structure (for connect, bind, accept) */ struct sockaddr { unsigned short sa_family; /* Protocol family */ char sa_data[14]; /* Address data. */ }; /* Internet-style socket address structure */ struct sockaddr_in { unsigned short sin_family; /* Address family (always AF_INET) */ unsigned short sin_port; /* Port number network byte order */ struct in_addr sin_addr; /* IP address network byte order */ unsigned char sin_zero[8]; /* Pad sizeof(struct sockaddr) */ }; sockaddr: socketbits.h (included socket.h), sockaddr_in: netinet/in.h Figure 11.15 Socket address structures. Thein_addr struct shown Figure 11.9. Aside _in sufﬁx mean? The_insufﬁx short internet , input . Theconnect ,bind , accept functions require pointer protocol- speciﬁc socket address structure. problem faced designers socketsinterface deﬁne functions accept kind socket addressstructure. Today would use generic void * pointer, exist C time. solution deﬁne sockets functions expect pointerto generic sockaddr structure, require applications cast pointers protocol-speciﬁc structures generic structure. simplify code exam-ples, follow Stevens’s lead deﬁne following type: typedef struct sockaddr SA; use type whenever need cast sockaddr_in structure generic sockaddr structure. (See line 20 Figure 11.16 example.) 11.4.2 Thesocket Function Clients servers use socket function create socket descriptor . #include <sys/types.h> #include <sys/socket.h> int socket(int domain, int type, int protocol); Returns: nonnegative descriptor OK, −1 errorSection 11.4 Sockets Interface 903 codes, always call socket function arguments clientfd = Socket(AF_INET, SOCK_STREAM, 0); AF_INET indicates using Internet, SOCK_STREAM indicates socket end point Internet connection. Theclientfd descriptor returned socket partially opened cannot yet used reading writing. ﬁnish opening socket depends onwhether client server. next section describes ﬁnish opening socket client. 11.4.3 Theconnect Function client establishes connection server calling connect function. #include <sys/socket.h> int connect(int sockfd, struct sockaddr *serv_addr, int addrlen); Returns: 0 OK, −1 error Theconnect function attempts establish Internet connection server socket address serv_addr , addrlen issizeof(sockaddr_in) . Theconnect function blocks either connection successfully established error occurs. successful, sockfd descriptor ready reading writing, resulting connection characterized socket pair (x:y, serv_addr.sin_addr:serv_addr.sin_port) xis client’s IP address yis ephemeral port uniquely identiﬁes client process client host. 11.4.4 Theopen_clientfd Function ﬁnd convenient wrap socket andconnect functions helper function called open_clientfd client use establish connection server. #include "csapp.h" int open_clientfd(char *hostname, int port); Returns: descriptor OK, −1 Unix error, −2 DNS error Theopen_clientfd function establishes connection server running host hostname listening connection requests well-known port port . returns open socket descriptor ready input output using Unix I/O functions. Figure 11.16 shows code open_clientfd . creating socket descriptor (line 7), retrieve DNS host entry server copy ﬁrst IP address host entry (which already in904 Chapter 11 Network Programming code/src/csapp.c 1int open_clientfd(char *hostname, int port) 2{ 3 int clientfd; 4 struct hostent *hp; 5 struct sockaddr_in serveraddr; 6 7 ((clientfd = socket(AF_INET, SOCK_STREAM, 0)) < 0) 8 return -1; /* Check errno cause error */ 9 10 /* Fill server’s IP address port */ 11 ((hp = gethostbyname(hostname)) == NULL) 12 return -2; /* Check h_errno cause error */ 13 bzero((char *) &serveraddr, sizeof(serveraddr)); 14 serveraddr.sin_family = AF_INET; 15 bcopy((char *)hp->h_addr_list[0], 16 (char *)&serveraddr.sin_addr.s_addr, hp->h_length); 17 serveraddr.sin_port = htons(port); 18 19 /* Establish connection server */ 20 (connect(clientfd, (SA *) &serveraddr, sizeof(serveraddr)) < 0) 21 return -1; 22 return clientfd; 23 } code/src/csapp.c Figure 11.16 open_clientfd : helper function establishes connection server. network byte order) server’s socket address structure (lines 11–16). initializing socket address structure server’s well-known port numberin network byte order (line 17), initiate connection request server(line 20). connect function returns, return socket descriptor client, immediately begin using Unix I/O communicate theserver. 11.4.5 Thebind Function remaining sockets functions— bind ,listen , andaccept —are used servers establish connections clients. #include <sys/socket.h> int bind(int sockfd, struct sockaddr *my_addr, int addrlen); Returns: 0 OK, −1 errorSection 11.4 Sockets Interface 905 Thebind function tells kernel associate server’s socket address inmy_addr socket descriptor sockfd .T h e addrlen argument sizeof(sockaddr_in) . 11.4.6 Thelisten Function Clients active entities initiate connection requests. Servers passive entities wait connection requests clients. default, kernelassumes descriptor created socket function corresponds active socket live client end connection. server calls listen function tell kernel descriptor used server instead aclient. #include <sys/socket.h> int listen(int sockfd, int backlog); Returns: 0 OK, −1 error Thelisten function converts sockfd active socket listening socket accept connection requests clients. backlog argument hint number outstanding connection requests kernel shouldqueue starts refuse requests. exact meaning backlog argument requires understanding TCP/IP beyond scope. willtypically set large value, 1024. 11.4.7 Theopen_listenfd Function ﬁnd helpful combine socket ,bind , listen functions helper function called open_listenfd server use create listening descriptor. #include "csapp.h" int open_listenfd(int port); Returns: descriptor OK, −1 Unix error Theopen_listenfd function opens returns listening descriptor ready receive connection requests well-known port port . Figure 11.17 shows code open_listenfd . create listenfd socket descrip- tor, use setsockopt function (not described here) conﬁgure server terminated restarted immediately. default, restarted906 Chapter 11 Network Programming code/src/csapp.c 1int open_listenfd(int port) 2{ 3 int listenfd, optval=1; 4 struct sockaddr_in serveraddr; 5 6 /* Create socket descriptor */ 7 ((listenfd = socket(AF_INET, SOCK_STREAM, 0)) < 0) 8 return -1; 9 10 /* Eliminates "Address already use" error bind */ 11 (setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, 12 (const void *)&optval , sizeof(int)) < 0) 13 return -1; 1415 /* Listenfd end point requests port 16 IP address host */ 17 bzero((char *) &serveraddr, sizeof(serveraddr)); 18 serveraddr.sin_family = AF_INET; 19 serveraddr.sin_addr.s_addr = htonl(INADDR_ANY); 20 serveraddr.sin_port = htons((unsigned short)port); 21 (bind(listenfd, (SA *)&serveraddr, sizeof(serveraddr)) < 0) 22 return -1; 2324 /* Make listening socket ready accept connection requests */ 25 (listen(listenfd, LISTENQ) < 0) 26 return -1; 27 return listenfd; 28 } code/src/csapp.c Figure 11.17 open_listenfd : helper function opens returns listening socket. server deny connection requests clients approximately 30 seconds, seriously hinders debugging. Next, initialize server’s socket address structure preparation calling bind function. case, used INADDR_ANY wild- card address tell kernel server accept requests IPaddresses host (line 19), well-known port port (line 20). Notice use htonl andhtons functions convert IP address port number host byte order network byte order. Finally, convert listenfd listening descriptor (line 25) return caller.Section 11.4 Sockets Interface 907 11.4.8 Theaccept Function Servers wait connection requests clients calling accept function: #include <sys/socket.h> int accept(int listenfd, struct sockaddr *addr, int *addrlen); Returns: nonnegative connected descriptor OK, −1 error Theaccept function waits connection request client arrive listening descriptor listenfd , ﬁlls client’s socket address addr , returns connected descriptor used communicate client using Unix I/O functions. distinction listening descriptor connected descriptor confuses many students. listening descriptor serves end point clientconnection requests. typically created exists lifetime ofthe server. connected descriptor end point connection isestablished client server. created time serveraccepts connection request exists long takes server servicea client. Figure 11.18 outlines roles listening connected descriptors. Step 1, server calls accept , waits connection request ar- rive listening descriptor, concreteness assume de-scriptor 3. Recall descriptors 0–2 reserved standard ﬁles. InStep 2, client calls connect function, sends connection re- quest listenfd . Step 3, accept function opens new connected Client Connection requestclientfd Client clientfd listenfd(3) connfd(4)listenfd(3)listenfd(3) ClientServer Server Server clientfd1. Server blocks accept , waiting connection request onlistening descriptor listenfd . 2. Client makes connection request calling blocking connect . 3. Server returns connfd accept . Client returns connect . Connectio n established clientfd andconnfd . Figure 11.18 roles listening connected descriptors.908 Chapter 11 Network Programming descriptor connfd (which assume descriptor 4), establishes connec- tion clientfd andconnfd , returns connfd application. client also returns connect , point, client server pass data back forth reading writing clientfd andconnfd , respectively. Aside distinction listening connected descriptors? might wonder sockets interface makes distinction listening connected descriptors. ﬁrst glance, appears unnecessary complication. However, distinguishing two turns quite useful, allows us build concurrent servers canprocess many client connections simultaneously. example, time connection request arriveson listening descriptor, might fork new process communicates client itsconnected descriptor. You’ll learn concurrent servers Chapter 12. 11.4.9 Example Echo Client Server best way learn sockets interface study example code. Figure 11.19 shows code echo client. establishing connection server,the client enters loop repeatedly reads text line standard input, sendsthe text line server, reads echo line server, prints resultto standard output. loop terminates fgets encounters EOF standard input, either user typed ctrl-d keyboard exhausted text lines redirected input ﬁle. loop terminates, client closes descriptor. results EOF notiﬁcation sent server, detects receives areturn code zero rio_readlineb function. closing descrip- tor, client terminates. Since client’s kernel automatically closes opendescriptors process terminates, close line 24 necessary. How- ever, good programming practice explicitly close descriptors haveopened. Figure 11.20 shows main routine echo server. opening listening descriptor, enters inﬁnite loop. iteration waits con- nection request client, prints domain name IP address theconnected client, calls echo function services client. echo routine returns, main routine closes connected descriptor. Oncethe client server closed respective descriptors, connection isterminated. Notice simple echo server handle one client time. server type iterates clients, one time, called iterative server . Chapter 12, learn build sophisticated concurrent servers handle multiple clients simultaneously.Section 11.4 Sockets Interface 909 code/netp/echoclient.c 1#include "csapp.h" 2 3int main(int argc, char **argv) 4{ 5 int clientfd, port; 6 char *host, buf[MAXLINE]; 7 rio_t rio; 89 (argc != 3) { 10 fprintf(stderr, "usage: %s <host> <port>\n", argv[0]); 11 exit(0); 12 } 13 host = argv[1]; 14 port = atoi(argv[2]); 1516 clientfd = Open_clientfd(host, port); 17 Rio_readinitb(&rio, clientfd); 1819 (Fgets(buf, MAXLINE, stdin) != NULL) { 20 Rio_writen(clientfd, buf, strlen(buf)); 21 Rio_readlineb(&rio, buf, MAXLINE); 22 Fputs(buf, stdout); 23 } 24 Close(clientfd); 25 exit(0); 26 } code/netp/echoclient.c Figure 11.19 Echo client main routine. Finally, Figure 11.21 shows code echo routine, repeatedly reads writes lines text rio_readlineb function encounters EOF line 10. Aside EOF connection mean? idea EOF often confusing students, especially context Internet connections. First, need understand thing EOF character. Rather, EOF condition detected kernel. application ﬁnds EOF condition receives zero return code read function. disk ﬁles, EOF occurs current ﬁle position exceeds ﬁle length. Internet connections, EOF occurs process closes end connection. process end connection detects EOF attempts read past lastbyte stream.910 Chapter 11 Network Programming code/netp/echoserveri.c 1#include "csapp.h" 2 3void echo(int connfd); 4 5int main(int argc, char **argv) 6{ 7 int listenfd, connfd, port, clientlen; 8 struct sockaddr_in clientaddr; 9 struct hostent *hp; 10 char *haddrp; 11 (argc != 2) { 12 fprintf(stderr, "usage: %s <port>\n", argv[0]); 13 exit(0); 14 } 15 port = atoi(argv[1]); 16 17 listenfd = Open_listenfd(port); 18 (1) { 19 clientlen = sizeof(clientaddr); 20 connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen); 2122 /* Determine domain name IP address client */ 23 hp = Gethostbyaddr((const char *)&clientaddr.sin_addr.s_addr, 24 sizeof(clientaddr.sin_addr.s_addr), AF_INET); 25 haddrp = inet_ntoa(clientaddr.sin_addr); 26 printf("server connected %s (%s)\n", hp->h_name, haddrp); 2728 echo(connfd); 29 Close(connfd); 30 } 31 exit(0); 32 } code/netp/echoserveri.c Figure 11.20 Iterative echo server main routine.Section 11.5 Web Servers 911 code/netp/echo.c 1#include "csapp.h" 2 3void echo(int connfd) 4{ 5 size_t n; 6 char buf[MAXLINE]; 7 rio_t rio; 89 Rio_readinitb(&rio, connfd); 10 while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) { 11 printf("server received %d bytes\n", n); 12 Rio_writen(connfd, buf, n); 13 } 14 } code/netp/echo.c Figure 11.21 echo function reads echoes text lines. 11.5 Web Servers far discussed network programming context simple echo server. section, show use basic ideas networkprogramming build small, quite functional, Web server. 11.5.1 Web Basics Web clients servers interact using text-based application-level protocol known HTTP (Hypertext Transfer Protocol). HTTP simple protocol. Web client (known browser ) opens Internet connection server requests content . server responds requested content closes connection. browser reads content displays screen. distinguishes Web services conventional ﬁle retrieval services FTP? main difference Web content written languageknown HTML (Hypertext Markup Language). HTML program (page) contains instructions (tags) tell browser display various text andgraphical objects page. example, code <b> Make bold! </b> tells browser print text <b>and</b> tags boldface type. However, real power HTML page contain pointers (hyperlinks) content stored Internet host. example, HTML line form <a href="http://www.cmu.edu/index.html">Carnegie Mellon</a>912 Chapter 11 Network Programming tells browser highlight text object “ Carnegie Mellon ” create hyperlink HTML ﬁle called index.html stored CMU Web server. user clicks highlighted text object, browser requests thecorresponding HTML ﬁle CMU server displays it. Aside Origins World Wide Web World Wide Web invented Tim Berners-Lee, software engineer working CERN, Swiss physics lab. 1989, Berners-Lee wrote internal memo proposing distributed hypertextsystem would connect “web notes links.” intent proposed system helpCERN scientists share manage information. next 2 years, Berners-Lee implemented ﬁrst Web server Web browser, Web developed small following within CERN sites. pivotal event occurred 1993, Marc Andreesen (who later founded Netscape) colleagues NCSA released graphical browser called mosaic three major platforms: Unix, Windows, Macintosh. release mosaic , interest Web exploded, number Web sites increasing factor 10 year. 2009, 225,000,000 Web sites worldwide (source: Netcraft Web Survey). 11.5.2 Web Content Web clients servers, content sequence bytes associated MIME (Multipurpose Internet Mail Extensions) type. Figure 11.22 shows commonMIME types. Web servers provide content clients two different ways: .Fetch disk ﬁle return contents client. disk ﬁle knownasstatic content process returning ﬁle client known serving static content . .Run executable ﬁle return output client. output produced executable run time known dynamic content , process running program returning output client known serving dynamic content . MIME type Description text/html HTML page text/plain Unformatted text application/postscript Postscript document image/gif Binary image encoded GIF format image/jpeg Binary image encoded JPEG format Figure 11.22 Example MIME types.Section 11.5 Web Servers 913 Every piece content returned Web server associated ﬁle manages. ﬁles unique name known URL (Universal Resource Locator). example, URL http://www.google.com:80/index.html identiﬁes HTML ﬁle called /index.html Internet host www.google.com managed Web server listening port 80. port number optionaland defaults well-known HTTP port 80. URLs executable ﬁles caninclude program arguments ﬁle name. ‘ ?’ character separates ﬁle name arguments, argument separated ‘ &’ character. example, URL http://bluefish.ics.cs.cmu.edu:8000/cgi-bin/adder?15000&213 identiﬁes executable called /cgi-bin/adder called two argu- ment strings: 15000 and213. Clients servers use different parts URL transaction. instance, client uses preﬁx http://www.google.com:80 determine kind server contact, server is, port itis listening on. server uses sufﬁx /index.html ﬁnd ﬁle ﬁle system determine whether request staticor dynamic content. several points understand servers interpret sufﬁx URL: .There standard rules determining whether URL refers staticor dynamic content. server rules ﬁles manages. Acommon approach identify set directories, cgi-bin , executables must reside. .The initial ‘ /’ sufﬁx notdenote Unix root directory. Rather, denotes home directory whatever kind content requested. example, server might conﬁgured static content storedin directory /usr/httpd/html dynamic content stored directory /usr/httpd/cgi-bin . .The minimal URL sufﬁx ‘ /’ character, servers expand default home page /index.html . explains possible fetch home page site simply typing domain name browser.The browser appends missing ‘ /’ URL passes server, expands ‘ /’ default ﬁle name.914 Chapter 11 Network Programming 1 unix> telnet www.aol.com 80 Client: open connection server 2 Trying 205.188.146.23... Telnet prints 3 lines terminal 3 Connected aol.com. 4 Escape character ’^]’. 5 GET / HTTP/1.1 Client: request line 6 Host: www.aol.com Client: required HTTP/1.1 header 7 Client: empty line terminates headers 8 HTTP/1.0 200 OK Server: response line 9 MIME-Version: 1.0 Server: followed five response headers 10 Date: Mon, 8 Jan 2010 4:59:42 GMT 11 Server: Apache-Coyote/1.1 12 Content-Type: text/html Server: expect HTML response body 13 Content-Length: 42092 Server: expect 42,092 bytes response body 14 Server: empty line terminates response headers 15 <html> Server: first HTML line response body 16 ... Server: 766 lines HTML shown 17 </html> Server: last HTML line response body 18 Connection closed foreign host. Server: closes connection 19 unix> Client: closes connection terminates Figure 11.23 Example HTTP transaction serves static content. 11.5.3 HTTP Transactions Since HTTP based text lines transmitted Internet connections, use Unix telnet program conduct transactions Web server Internet. telnet program handy debugging servers talk clients text lines connections. example, Figure 11.23 uses telnet request home page AOL Web server. line 1, run telnet Unix shell ask open connection AOL Web server. Telnet prints three lines output terminal, opens connection, waits us enter text (line 5). time entera text line hit enter key, telnet reads line, appends carriage return line feed characters (“ \r\n ” C notation), sends line server. consistent HTTP standard, requires every text line beterminated carriage return line feed pair. initiate transaction, weenter HTTP request (lines 5–7). server replies HTTP response(lines 8–17) closes connection (line 18). HTTP Requests HTTP request consists request line (line 5), followed zero request headers (line 6), followed empty text line terminates list headers (line 7). request line form <method> <uri> <version>Section 11.5 Web Servers 915 HTTP supports number different methods , including GET, POST, OP- TIONS, HEAD, PUT, DELETE, TRACE. discuss workhorseGET method, according one study accounts 99% HTTP re-quests [107]. GET method instructs server generate return thecontent identiﬁed URI (Uniform Resource Identiﬁer). URI suf- ﬁx corresponding URL includes ﬁle name optional arguments. 1 The<version> ﬁeld request line indicates HTTP version request conforms. recent HTTP version HTTP/1.1 [41]. HTTP/1.0is previous version 1996 still use [6]. HTTP/1.1 deﬁnes additionalheaders provide support advanced features caching security,as well mechanism allows client server perform multiple trans- actions persistent connection . practice, two versions com- patible HTTP/1.0 clients servers simply ignore unknown HTTP/1.1headers. summarize, request line line 5 asks server fetch return HTML ﬁle /index.html . also informs server remainder request HTTP/1.1 format. Request headers provide additional information server, brand name browser MIME types browser understands.Request headers form <header name>: <header data> purposes, header concerned Host header (line 6), required HTTP/1.1 requests, HTTP/1.0 requests. Host header used proxy caches , sometimes serve intermediaries browser origin server manages requested ﬁle. Multiple proxies exist client origin server so-called proxy chain . data Host header, identiﬁes domain name origin server, allows proxy middle proxy chain determine might locally cachedcopy requested content. Continuing example Figure 11.23, empty text line line 7 (generated hitting enter keyboard) terminates headers instructs server send requested HTML ﬁle. HTTP Responses HTTP responses similar HTTP requests. HTTP response consists aresponse line (line 8), followed zero response headers (lines 9–13), followed empty line terminates headers (line 14), followed theresponse body (lines 15–17). response line form <version> <status code> <status message> 1. Actually, true browser requests content. proxy server requests content, URI must complete URL.916 Chapter 11 Network Programming Status code Status message Description 200 OK Request handled without error. 301 Moved permanently Content moved hostname Location header. 400 Bad request Request could understood server. 403 Forbidden Server lacks permission access requested ﬁle.404 found Server could ﬁnd requested ﬁle.501 implemented Server support request method. 505 HTTP version supported Server support version request. Figure 11.24 HTTP status codes. version ﬁeld describes HTTP version response conforms to. status code three-digit positive integer indicates disposition request. status message gives English equivalent error code. Figure 11.24 lists common status codes corresponding messages.The response headers lines 9–13 provide additional information theresponse. purposes, two important headers Content-Type (line 12), tells client MIME type content response body,andContent-Length (line 13), indicates size bytes. empty text line line 14 terminates response headers followed response body, contains requested content. 11.5.4 Serving Dynamic Content stop think moment server might provide dynamic content client, certain questions arise. example, client pass anyprogram arguments server? server pass argumentsto child process creates? server pass informationto child might need generate content? childsend output? questions addressed de facto standard called CGI (Common Gateway Interface). Client Pass Program Arguments Server? Arguments GET requests passed URI. seen, ‘ ?’ character separates ﬁle name arguments, argument isseparated ‘ &’ character. Spaces allowed arguments must represented “ %20” string. Similar encodings exist special characters. Aside Passing arguments HTTP POST requests Arguments HTTP POST requests passed request body rather URI.Section 11.5 Web Servers 917 Environment variable Description QUERY_STRING Program arguments SERVER_PORT Port parent listening REQUEST_METHOD GET POST REMOTE_HOST Domain name clientREMOTE_ADDR Dotted-decimal IP address clientCONTENT_TYPE POST only: MIME type request body CONTENT_LENGTH POST only: Size bytes request body Figure 11.25 Examples CGI environment variables. Server Pass Arguments Child? server receives request GET /cgi-bin/adder?15000&213 HTTP/1.1 calls fork create child process calls execve run /cgi-bin/adder program context child. Programs like adder program often referred CGI programs obey rules CGI standard. since many CGI programs written Perl scripts, CGI programs areoften called CGI scripts . call execve , child process sets CGI environment variable QUERY_STRING “ 15000&213 ”, adder program reference run time using Unix getenv function. Server Pass Information Child? CGI deﬁnes number environment variables CGI program expect set runs. Figure 11.25 shows subset. Child Send Output? CGI program sends dynamic content standard output. child process loads runs CGI program, uses Unix dup2 function redirect standard output connected descriptor associated withthe client. Thus, anything CGI program writes standard output goesdirectly client. Notice since parent know type size content child generates, child responsible generating Content-type Content-length response headers, well empty line terminates headers.918 Chapter 11 Network Programming code/netp/tiny/cgi-bin/adder.c 1#include "csapp.h" 2 3int main(void) { 4 char *buf, *p; 5 char arg1[MAXLINE], arg2[MAXLINE], content[MAXLINE]; 6 int n1=0, n2=0; 78 /* Extract two arguments */ 9 ((buf = getenv("QUERY_STRING")) != NULL) { 10 p = strchr(buf, ’&’); 11 *p = ’\0’; 12 strcpy(arg1, buf); 13 strcpy(arg2, p+1); 14 n1 = atoi(arg1); 15 n2 = atoi(arg2); 16 } 17 18 /* Make response body */ 19 sprintf(content, "Welcome add.com: "); 20 sprintf(content, "%sTHE Internet addition portal.\r\n<p>", content); 21 sprintf(content, "%sThe answer is: %d + %d = %d\r\n<p>", 22 content, n1, n2, n1 + n2); 23 sprintf(content, "%sThanks visiting!\r\n", content); 2425 /* Generate HTTP response */ 26 printf("Content-length: %d\r\n", (int)strlen(content)); 27 printf("Content-type: text/html\r\n\r\n"); 28 printf("%s", content); 29 fflush(stdout); 30 exit(0); 31 } code/netp/tiny/cgi-bin/adder.c Figure 11.26 CGI program sums two integers. Figure 11.26 shows simple CGI program sums two arguments returns HTML ﬁle result client. Figure 11.27 shows HTTPtransaction serves dynamic content adder program. Aside Passing arguments HTTP POST requests CGI programs POST requests, child would also need redirect standard input connected descriptor. CGI program would read arguments request body standard input.Section 11.6 Putting Together: Tiny Web Server 919 1 unix> telnet kittyhawk.cmcl.cs.cmu.edu 8000 Client: open connection 2 Trying 128.2.194.242... 3 Connected kittyhawk.cmcl.cs.cmu.edu. 4 Escape character ’^]’. 5 GET /cgi-bin/adder?15000&213 HTTP/1.0 Client: request line 6 Client: empty line terminates headers 7 HTTP/1.0 200 OK Server: response line 8 Server: Tiny Web Server Server: identify server 9 Content-length: 115 Adder: expect 115 bytes response body 10 Content-type: text/html Adder: expect HTML response body 11 Adder: empty line terminates headers 12 Welcome add.com: Internet addition portal. Adder: first HTML line 13 <p>The answer is: 15000 + 213 = 15213 Adder: second HTML line response body 14 <p>Thanks visiting! Adder: third HTML line response body 15 Connection closed foreign host. Server: closes connection 16 unix> Client: closes connection terminates Figure 11.27 HTTP transaction serves dynamic HTML content. Practice Problem 11.5 Section 10.9, warned dangers using C standard I/O functions network applications. Yet CGI program Figure 11.26 able touse standard I/O without problems. Why? 11.6 Putting Together: Tiny Web Server conclude discussion network programming developing small functioning Web server called Tiny .Tiny interesting program. combines many ideas learned about, process control, Unix I/O,the sockets interface, HTTP , 250 lines code. lacks thefunctionality, robustness, security real server, powerful enough toserve static dynamic content real Web browsers. encourage youto study implement yourself. quite exciting (even authors!) topoint real browser server watch display complicated Webpage text graphics. Tinymain Routine Figure 11.28 shows Tiny ’s main routine. Tiny iterative server listens connection requests port passed command line. Afteropening listening socket calling open_listenfd function, Tiny executes typical inﬁnite server loop, repeatedly accepting connection request (line 31), performing transaction (line 32), closing end connection (line 33).920 Chapter 11 Network Programming code/netp/tiny/tiny.c 1/* 2 * tiny. c - simple, iterative HTTP/1.0 Web server uses 3 * GET method serve static dynamic content. 4 */ 5#include "csapp.h" 6 7void doit(int fd); 8void read_requesthdrs(rio_t *rp); 9int parse_uri(char *uri, char *filename, char *cgiargs); 10 void serve_static(int fd, char *filename, int filesize); 11 void get_filetype(char *filename, char *filetype); 12 void serve_dynamic(int fd, char *filename, char *cgiargs); 13 void clienterror(int fd, char *cause, char *errnum, 14 char *shortmsg, char *longmsg); 1516 int main(int argc, char **argv) 17 { 18 int listenfd, connfd, port, clientlen; 19 struct sockaddr_in clientaddr; 2021 /* Check command line args */ 22 (argc != 2) { 23 fprintf(stderr, "usage: %s <port>\n", argv[0]); 24 exit(1); 25 } 26 port = atoi(argv[1]); 2728 listenfd = Open_listenfd(port); 29 (1) { 30 clientlen = sizeof(clientaddr); 31 connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen); 32 doit(connfd); 33 Close(connfd); 34 } 35 } code/netp/tiny/tiny.c Figure 11.28 Tiny Web server. Thedoit Function Thedoit function Figure 11.29 handles one HTTP transaction. First, read parse request line (lines 11–12). Notice using rio_ readlineb function Figure 10.7 read request line.code/netp/tiny/tiny.c 1void doit(int fd) 2{ 3 int is_static; 4 struct stat sbuf; 5 char buf[MAXLINE], method[MAXLINE], uri[MAXLINE], version[MAXLINE]; 6 char filename[MAXLINE], cgiargs[MAXLINE]; 7 rio_t rio; 8 9 /* Read request line headers */ 10 Rio_readinitb(&rio, fd); 11 Rio_readlineb(&rio, buf, MAXLINE); 12 sscanf(buf, "%s %s %s", method, uri, version); 13 (strcasecmp(method, "GET")) { 14 clienterror(fd, method, "501", "Not Implemented", 15 "Tiny implement method"); 16 return; 17 } 18 read_requesthdrs(&rio); 19 20 /* Parse URI GET request */ 21 is_static = parse_uri(uri, filename, cgiargs); 22 (stat(filename, &sbuf) < 0) { 23 clienterror(fd, filename, "404", "Not found", 24 "Tiny couldn’t find file"); 25 return; 26 } 27 28 (is_static) { /* Serve static content */ 29 (!(S_ISREG(sbuf.st_mode)) || !(S_IRUSR & sbuf.st_mode)) { 30 clienterror(fd, filename, "403", "Forbidden", 31 "Tiny couldn’t read file"); 32 return; 33 } 34 serve_static(fd, filename, sbuf.st_size); 35 } 36 else { /* Serve dynamic content */ 37 (!(S_ISREG(sbuf.st_mode)) || !(S_IXUSR & sbuf.st_mode)) { 38 clienterror(fd, filename, "403", "Forbidden", 39 "Tiny couldn’t run CGI program"); 40 return; 41 } 42 serve_dynamic(fd, filename, cgiargs); 43 } 44 } code/netp/tiny/tiny.c Figure 11.29 Tinydoit : Handles one HTTP transaction.922 Chapter 11 Network Programming Tiny supports GET method. client requests another method (such POST), send error message return main routine(lines 13–17), closes connection awaits next connectionrequest. Otherwise, read (as shall see) ignore request headers(line 18). Next, parse URI ﬁle name possibly empty CGI argument string, set ﬂag indicates whether request static dynamiccontent (line 21). ﬁle exist disk, immediately send error message client return. Finally, request static content, verify ﬁle regular ﬁle read permission (line 29). so, serve static content(line 34) client. Similarly, request dynamic content, verifythat ﬁle executable (line 37), go ahead serve dynamiccontent (line 42). Theclienterror Function Tiny lacks many error handling features real server. However, check obvious errors reports client. clienterror function Figure 11.30 sends HTTP response client appropriate code/netp/tiny/tiny.c 1void clienterror(int fd, char *cause, char *errnum, 2 char *shortmsg, char *longmsg) 3{ 4 char buf[MAXLINE], body[MAXBUF]; 5 6 /* Build HTTP response body */ 7 sprintf(body, "<html><title>Tiny Error</title>"); 8 sprintf(body, "%s<body bgcolor=""ffffff"">\r\n", body); 9 sprintf(body, "%s%s: %s\r\n", body, errnum, shortmsg); 10 sprintf(body, "%s<p>%s: %s\r\n", body, longmsg, cause); 11 sprintf(body, "%s<hr><em>The Tiny Web server</em>\r\n", body); 1213 /* Print HTTP response */ 14 sprintf(buf, "HTTP/1.0 %s %s\r\n", errnum, shortmsg); 15 Rio_writen(fd, buf, strlen(buf)); 16 sprintf(buf, "Content-type: text/html\r\n"); 17 Rio_writen(fd, buf, strlen(buf)); 18 sprintf(buf, "Content-length: %d\r\n\r\n", (int)strlen(body)); 19 Rio_writen(fd, buf, strlen(buf)); 20 Rio_writen(fd, body, strlen(body)); 21 } code/netp/tiny/tiny.c Figure 11.30 Tinyclienterror : Sends error message client.Section 11.6 Putting Together: Tiny Web Server 923 code/netp/tiny/tiny.c 1void read_requesthdrs(rio_t *rp) 2{ 3 char buf[MAXLINE]; 4 5 Rio_readlineb(rp, buf, MAXLINE); 6 while(strcmp(buf, "\r\n")) { 7 Rio_readlineb(rp, buf, MAXLINE); 8 printf("%s", buf); 9 } 10 return; 11 } code/netp/tiny/tiny.c Figure 11.31 Tinyread_requesthdrs : Reads ignores request headers. status code status message response line, along HTML ﬁle response body explains error browser’s user. Recall HTMLresponse indicate size type content body. Thus, wehave opted build HTML content single string easilydetermine size. Also, notice using robust rio_writen function Figure 10.3 output. Theread_requesthdrs Function Tiny use information request headers. simply reads ignores calling read_requesthdrs function Figure 11.31. Notice empty text line terminates request headers consists carriagereturn line feed pair, check line 6. Theparse_uri Function Tiny assumes home directory static content current directory, home directory executables ./cgi-bin . URI contains string cgi-bin assumed denote request dynamic content. default ﬁle name ./home.html . Theparse_uri function Figure 11.32 implements policies. parses URI ﬁle name optional CGI argument string. requestis static content (line 5), clear CGI argument string (line 6) thenconvert URI relative Unix pathname ./index.html (lines 7– 8). URI ends ‘ /’ character (line 9), append default ﬁle name (line 10). hand, request dynamic content (line 13),we extract CGI arguments (lines 14–20) convert remaining portion URI relative Unix ﬁle name (lines 21–22).924 Chapter 11 Network Programming code/netp/tiny/tiny.c 1int parse_uri(char *uri, char *filename, char *cgiargs) 2{ 3 char *ptr; 4 5 (!strstr(uri, "cgi-bin")) { /* Static content */ 6 strcpy(cgiargs, ""); 7 strcpy(filename, "."); 8 strcat(filename, uri); 9 (uri[strlen(uri)-1] == ’/’) 10 strcat(filename, "home.html"); 11 return 1; 12 } 13 else { /* Dynamic content */ 14 ptr = index(uri, ’?’); 15 (ptr) { 16 strcpy(cgiargs, ptr+1); 17 *ptr = ’\0’; 18 } 19 else 20 strcpy(cgiargs, ""); 21 strcpy(filename, "."); 22 strcat(filename, uri); 23 return 0; 24 } 25 } code/netp/tiny/tiny.c Figure 11.32 Tinyparse_uri : Parses HTTP URI. Theserve_static Function Tiny serves four different types static content: HTML ﬁles, unformatted text ﬁles, images encoded GIF JPEG formats. ﬁle types account forthe majority static content served Web. Theserve_static function Figure 11.33 sends HTTP response whose body contains contents local ﬁle. First, determine ﬁle type byinspecting sufﬁx ﬁle name (line 7) send response line andresponse headers client (lines 8–12). Notice blank line terminates theheaders. Next, send response body copying contents requested ﬁle connected descriptor fd. code somewhat subtle needs studied carefully. Line 15 opens filename reading gets descriptor. line 16, Unix mmap function maps requested ﬁle virtual memory area. Recall discussion mmap Section 9.8 call mmap maps theSection 11.6 Putting Together: Tiny Web Server 925 code/netp/tiny/tiny.c 1void serve_static(int fd, char *filename, int filesize) 2{ 3 int srcfd; 4 char *srcp, filetype[MAXLINE], buf[MAXBUF]; 5 6 /* Send response headers client */ 7 get_filetype(filename, filetype); 8 sprintf(buf, "HTTP/1.0 200 OK\r\n"); 9 sprintf(buf, "%sServer: Tiny Web Server\r\n", buf); 10 sprintf(buf, "%sContent-length: %d\r\n", buf, filesize); 11 sprintf(buf, "%sContent-type: %s\r\n\r\n", buf, filetype); 12 Rio_writen(fd, buf, strlen(buf)); 1314 /* Send response body client */ 15 srcfd = Open(filename, O_RDONLY, 0); 16 srcp = Mmap(0, filesize, PROT_READ, MAP_PRIVATE, srcfd, 0); 17 Close(srcfd); 18 Rio_writen(fd, srcp, filesize); 19 Munmap(srcp, filesize); 20 } 2122 /* 23 * get_filetype - derive file type file name 24 */ 25 void get_filetype(char *filename, char *filetype) 26 { 27 (strstr(filename, ".html")) 28 strcpy(filetype, "text/html"); 29 else (strstr(filename, ".gif")) 30 strcpy(filetype, "image/gif"); 31 else (strstr(filename, ".jpg")) 32 strcpy(filetype, "image/jpeg"); 33 else 34 strcpy(filetype, "text/plain"); 35 } code/netp/tiny/tiny.c Figure 11.33 Tinyserve_static : Serves static content client. ﬁrstfilesize bytes ﬁle srcfd private read-only area virtual memory starts address srcp . mapped ﬁle memory, longer need descriptor, close ﬁle (line 17). Failing would introduce potentially fatalmemory leak. Line 18 performs actual transfer ﬁle client. The926 Chapter 11 Network Programming code/netp/tiny/tiny.c 1void serve_dynamic(int fd, char *filename, char *cgiargs) 2{ 3 char buf[MAXLINE], *emptylist[ ] = { NULL }; 4 5 /* Return first part HTTP response */ 6 sprintf(buf, "HTTP/1.0 200 OK\r\n"); 7 Rio_writen(fd, buf, strlen(buf)); 8 sprintf(buf, "Server: Tiny Web Server\r\n"); 9 Rio_writen(fd, buf, strlen(buf)); 10 11 (Fork() == 0) { /* child */ 12 /* Real server would set CGI vars */ 13 setenv("QUERY_STRING", cgiargs, 1); 14 Dup2(fd, STDOUT_FILENO); /* Redirect stdout client */ 15 Execve(filename, emptylist, environ); /* Run CGI program */ 16 } 17 Wait(NULL); /* Parent waits reaps child */ 18 } code/netp/tiny/tiny.c Figure 11.34 Tinyserve_dynamic : Serves dynamic content client. rio_writen function copies filesize bytes starting location srcp (which course mapped requested ﬁle) client’s connected descriptor. Finally, line 19 frees mapped virtual memory area. important avoida potentially fatal memory leak. Theserve_dynamic Function Tiny serves type dynamic content forking child process, running CGI program context child. Theserve_dynamic function Figure 11.34 begins sending response line indicating success client, along informational Server header. CGI program responsible sending rest response. Notice robust might wish, since doesn’t allow possibility CGI program might encounter error. sending ﬁrst part response, fork new child process (line 11). child initializes QUERY_STRING environment variable withthe CGI arguments request URI (line 13). Notice real server wouldset CGI environment variables well. brevity, omittedthis step. Also, note Solaris systems use putenv function instead setenv function.Section 11.7 Summary 927 Next, child redirects child’s standard output connected ﬁle descriptor (line 14), loads runs CGI program (line 15). Sincethe CGI program runs context child, access openﬁles environment variables existed call execve function. Thus, everything CGI program writes standard output goes directly tothe client process, without intervention parent process. Meanwhile, parent blocks call wait , waiting reap child terminates (line 17). Aside Dealing prematurely closed connections Although basic functions Web server quite simple, don’t want give false impression writing real Web server easy. Building robust Web server runs extendedperiods without crashing difﬁcult task requires deeper understanding Unix systems programming we’ve learned here. example, server writes connection already closed client (say, clicked “Stop” button browser), ﬁrst write returns normally, second write causes delivery SIGPIPE signal whose defaultbehavior terminate process. SIGPIPE signal caught ignored, second writeoperation returns −1 errno set EPIPE. strerr andperror functions report EPIPE error “Broken pipe”, non-intuitive message confused generations students. bottom line robust server must catch SIGPIPE signals check write function calls EPIPE errors. 11.7 Summary Every network application based client-server model. model, application consists server one clients. server managesresources, providing service clients manipulating resources someway. basic operation client-server model client-server transaction,which consists request client, followed response server. Clients servers communicate global network known Internet. programmer’s point view, think Internet worldwidecollection hosts following properties: (1) Internet host unique 32-bit name called IP address. (2) set IP addresses mappedto set Internet domain names. (3) Processes different Internet hosts cancommunicate connections. Clients servers establish connections using sockets interface. socket end point connection presented applications theform ﬁle descriptor. sockets interface provides functions opening closing socket descriptors. Clients servers communicate reading writing descriptors. Web servers clients (such browsers) communicate using HTTP protocol. browser requests either static dynamic contentfrom server. request static content served fetching ﬁle the928 Chapter 11 Network Programming server’s disk returning client. request dynamic content served running program context child process server returningits output client. CGI standard provides set rules govern howthe client passes program arguments server, server passes thesearguments information child process, child sends itsoutput back client. simple functioning Web server serves static dynamic content implemented hundred lines C code. Bibliographic Notes ofﬁcial source information Internet contained set freelyavailable numbered documents known RFCs (Requests Comments). searchable index RFCs available Web http://rfc-editor.org RFCs typically written developers Internet infrastructure, thus usually detailed casual reader. However, authoritative infor-mation, better source. HTTP/1.1 protocol documented RFC2616. authoritative list MIME types maintained http://www.iana.org/assignments/media-types number good general texts computer networking [62, 80, 113]. great technical writer W. Richard Stevens developed series classictexts topics advanced Unix programming [110], Internet proto-cols [105, 106, 107], Unix network programming [108, 109]. Serious studentsof Unix systems programming want study them. Tragically, Stevensdied September 1, 1999. contributions greatly missed. Homework Problems 11.6◆◆ A. Modify Tiny echoes every request line request header. B. Use favorite browser make request Tiny static content. Capture output Tiny ﬁle. C. Inspect output Tiny determine version HTTP browser uses. D. Consult HTTP/1.1 standard RFC 2616 determine meaning header HTTP request browser. obtainRFC 2616 www.rfc-editor.org/rfc.html .Solutions Practice Problems 929 11.7◆◆ Extend Tiny serves MPG video ﬁles. Check work using real browser. 11.8◆◆ Modify Tiny reaps CGI children inside SIGCHLD handler instead explicitly waiting terminate. 11.9◆◆ Modify Tiny serves static content, copies requested ﬁle connected descriptor using malloc ,rio_readn , rio_writen , instead mmap andrio_writen . 11.10 ◆◆ A. Write HTML form CGI adder function Figure 11.26. form include two text boxes users ﬁll two numbers beadded together. form request content using GET method. B. Check work using real browser request form Tiny , submit ﬁlled-in form Tiny , display dynamic content generated adder . 11.11 ◆◆ Extend Tiny support HTTP HEAD method. Check work using telnet Web client. 11.12 ◆◆◆ Extend Tiny serves dynamic content requested HTTP POST method. Check work using favorite Web browser. 11.13 ◆◆◆ Modify Tiny deals cleanly (without terminating) SIGPIPE signals EPIPE errors occur write function attempts write prematurely closed connection. Solutions Practice Problems Solution Problem 11.1 (page 894) Hex address Dotted-decimal address 0x0 0.0.0.0 0xffffffff 255.255.255.255 0x7f000001 127.0.0.1 0xcdbca079 205.188.160.1210x400c950d 64.12.149.130xcdbc9217 205.188.146.23930 Chapter 11 Network Programming Solution Problem 11.2 (page 894) code/netp/hex2dd.c 1#include "csapp.h" 2 3int main(int argc, char **argv) 4{ 5 struct in_addr inaddr; /* addr network byte order */ 6 unsigned int addr; /* addr host byte order */ 7 8 (argc != 2) { 9 fprintf(stderr, "usage: %s <hex number>\n", argv[0]); 10 exit(0); 11 } 12 sscanf(argv[1], "%x", &addr); 13 inaddr.s_addr = htonl(addr); 14 printf("%s\n", inet_ntoa(inaddr)); 1516 exit(0); 17 } code/netp/hex2dd.c Solution Problem 11.3 (page 895) code/netp/dd2hex.c 1#include "csapp.h" 23 int main(int argc, char **argv) 4{ 5 struct in_addr inaddr; /* addr network byte order */ 6 unsigned int addr; /* addr host byte order */ 7 8 (argc != 2) { 9 fprintf(stderr, "usage: %s <dotted-decimal>\n", argv[0]); 10 exit(0); 11 } 12 13 (inet_aton(argv[1], &inaddr) == 0) 14 app_error("inet_aton error"); 15 addr = ntohl(inaddr.s_addr); 16 printf("0x%x\n", addr); 1718 exit(0); 19 } code/netp/dd2hex.cSolutions Practice Problems 931 Solution Problem 11.4 (page 899) time request host entry google.com , list corresponding Internet addresses returned different round-robin order. unix> ./hostinfo google.com official hostname: google.com address: 74.125.127.100 address: 74.125.45.100 address: 74.125.67.100 unix> ./hostinfo google.com official hostname: google.com address: 74.125.67.100address: 74.125.127.100address: 74.125.45.100 unix> ./hostinfo google.com official hostname: google.com address: 74.125.45.100address: 74.125.67.100address: 74.125.127.100 different ordering addresses different DNS queries known DNS round-robin . used load-balance requests heavily used domain name. Solution Problem 11.5 (page 919) reason standard I/O works CGI programs CGI programrunning child process need explicitly close inputor output streams. child terminates, kernel closes descriptorsautomatically.This page intentionally left blank CHAPTER12 Concurrent Programming 12.1 Concurrent Programming Processes 935 12.2 Concurrent Programming I/O Multiplexing 939 12.3 Concurrent Programming Threads 947 12.4 Shared Variables Threaded Programs 954 12.5 Synchronizing Threads Semaphores 957 12.6 Using Threads Parallelism 974 12.7 Concurrency Issues 979 12.8 Summary 988 Bibliographic Notes 989 Homework Problems 989 Solutions Practice Problems 994 933934 Chapter 12 Concurrent Programming learned Chapter 8, logical control ﬂows concurrent overlap time. general phenomenon, known concurrency , shows many different levels computer system. Hardware exception handlers, processes,and Unix signal handlers familiar examples. Thus far, treated concurrency mainly mechanism oper- ating system kernel uses run multiple application programs. concurrency isnot limited kernel. play important role application programsas well. example, seen Unix signal handlers allow applicationsto respond asynchronous events user typing ctrl-c program accessing undeﬁned area virtual memory. Application-level concurrency isuseful ways well: .Accessing slow I/O devices. application waiting data arrive slow I/O device disk, kernel keeps CPU busy byrunning processes. Individual applications exploit concurrency asimilar way overlapping useful work I/O requests. .Interacting humans. People interact computers demand abil- ity perform multiple tasks time. example, might wantto resize window printing document. Modern windowingsystems use concurrency provide capability. time user requestssome action (say, clicking mouse), separate concurrent logical ﬂow iscreated perform action. .Reducing latency deferring work. Sometimes, applications use concur- rency reduce latency certain operations deferring operationsand performing concurrently. example, dynamic storage allocatormight reduce latency individual free operations deferring coalesc- ing concurrent “coalescing” ﬂow runs lower priority, soaking upspare CPU cycles become available. .Servicing multiple network clients. iterative network servers stud- ied Chapter 11 unrealistic service one client ata time. Thus, single slow client deny service every client. areal server might expected service hundreds thousands clientsper second, acceptable allow one slow client deny service theothers. better approach build concurrent server creates separate logical ﬂow client. allows server service multiple clientsconcurrently, precludes slow clients monopolizing server. .Computing parallel multi-core machines. Many modern systems equipped multi-core processors contain multiple CPUs. Applica- tions partitioned concurrent ﬂows often run faster multi-core machines uniprocessor machines ﬂows execute parallelrather interleaved. Applications use application-level concurrency known concurrent programs . Modern operating systems provide three basic approaches building concurrent programs:Section 12.1 Concurrent Programming Processes 935 .Processes. approach, logical control ﬂow process scheduled maintained kernel. Since processes separate virtualaddress spaces, ﬂows want communicate must use somekind explicit interprocess communication (IPC) mechanism. .I/O multiplexing. form concurrent programming applications explicitly schedule logical ﬂows context single process.Logical ﬂows modeled state machines main program explicitlytransitions state state result data arriving ﬁle descriptors.Since program single process, ﬂows share address space. .Threads. Threads logical ﬂows run context single process scheduled kernel. think threads hybrid theother two approaches, scheduled kernel like process ﬂows, sharingthe virtual address space like I/O multiplexing ﬂows. chapter investigates three different concurrent programming tech- niques. keep discussion concrete, work motivatingapplication throughout—a concurrent version iterative echo server Section 11.4.9. 12.1 Concurrent Programming Processes simplest way build concurrent program processes, using familiarfunctions fork ,exec , waitpid . example, natural approach building concurrent server accept client connection requests parent,and create new child process service new client. see might work, suppose two clients server listening connection requests listening descriptor (say, 3). supposethat server accepts connection request client 1 returns connecteddescriptor (say, 4), shown Figure 12.1. accepting connection request, server forks child, gets complete copy server’s descriptor table. child closes copy listeningdescriptor 3, parent closes copy connected descriptor 4, since theyare longer needed. gives us situation Figure 12.2, childprocess busy servicing client. Since connected descriptors parentand child point ﬁle table entry, crucial parent close Figure 12.1 Step 1: Server acceptsconnection request fromclient.Client 1 clientfd Client 2 clientfdconnfd(4)listenfd(3) ServerConnection request936 Chapter 12 Concurrent Programming Figure 12.2 Step 2: Server forks achild process servicethe client. Client 1 clientfd Client 2 clientfdconnfd(4)Child 1 listenfd(3) ServerData transfers Figure 12.3 Step 3: Server acceptsanother connection request. Client 1 clientfd Client 2 clientfdconnfd(4) connfd(5)Child 1 listenfd(3) ServerData transfers Connection request copy connected descriptor. Otherwise, ﬁle table entry connected descriptor 4 never released, resulting memory leak eventuallyconsume available memory crash system. suppose parent creates child client 1, accepts new connection request client 2 returns new connected descriptor(say, 5), shown Figure 12.3. parent forks another child, beginsservicing client using connected descriptor 5, shown Figure 12.4. thispoint, parent waiting next connection request two childrenare servicing respective clients concurrently. 12.1.1 Concurrent Server Based Processes Figure 12.5 shows code concurrent echo server based processes. Theecho function called line 29 comes Figure 11.21. several important points make server: .First, servers typically run long periods time, must include aSIGCHLD handler reaps zombie children (lines 4–9). Since SIGCHLD signals blocked SIGCHLD handler executing, since Unix signals queued, SIGCHLD handler must prepared reapmultiple zombie children.Section 12.1 Concurrent Programming Processes 937 Figure 12.4 Step 4: Server forksanother child servicethe new client. Client 1 clientfd Client 2 clientfdconnfd(4)Child 1 connfd(5)Child 2listenfd(3) ServerData transfers Data transfers .Second, parent child must close respective copies connfd (lines 33 30, respectively). mentioned, especially im-portant parent, must close copy connected descriptorto avoid memory leak. .Finally, reference count socket’s ﬁle table entry, theconnection client terminated parent’s andchild’s copies connfd closed. 12.1.2 Pros Cons Processes Processes clean model sharing state information parents children: ﬁle tables shared user address spaces not. separateaddress spaces processes advantage disadvantage. im-possible one process accidentally overwrite virtual memory anotherprocess, eliminates lot confusing failures—an obvious advantage. hand, separate address spaces make difﬁcult pro- cesses share state information. share information, must use explicit IPC (interprocess communications) mechanisms. (See Aside.) Another disadvan-tage process-based designs tend slower overheadfor process control IPC high. Aside Unix IPC already encountered several examples IPC text. waitpid function Unix signals Chapter 8 primitive IPC mechanisms allow processes send tiny messages processes running host. sockets interface Chapter 11 important form IPC allows processes different hosts exchange arbitrary byte streams. However, term Unix IPC typically reserved hodge-podge techniques allow processes communicate processes running host. Examples include pipes, FIFOs, System Vshared memory, System V semaphores. mechanisms beyond scope. book Stevens [108] good reference.938 Chapter 12 Concurrent Programming code/conc/echoserverp.c 1#include "csapp.h" 2void echo(int connfd); 3 4void sigchld_handler(int sig) 5{ 6 (waitpid(-1, 0, WNOHANG) > 0) 7 ; 8 return; 9} 1011 int main(int argc, char **argv) 12 { 13 int listenfd, connfd, port; 14 socklen_t clientlen=sizeof(struct sockaddr_in); 15 struct sockaddr_in clientaddr; 1617 (argc != 2) { 18 fprintf(stderr, "usage: %s <port>\n", argv[0]); 19 exit(0); 20 } 21 port = atoi(argv[1]); 2223 Signal(SIGCHLD, sigchld_handler); 24 listenfd = Open_listenfd(port); 25 (1) { 26 connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen); 27 (Fork() == 0) { 28 Close(listenfd); /* Child closes listening socket */ 29 echo(connfd); /* Child services client */ 30 Close(connfd); /* Child closes connection client */ 31 exit(0); /* Child exits */ 32 } 33 Close(connfd); /* Parent closes connected socket (important!) */ 34 } 35 } code/conc/echoserverp.c Figure 12.5 Concurrent echo server based processes. parent forks child handle new connection request.Section 12.2 Concurrent Programming I/O Multiplexing 939 Practice Problem 12.1 parent closes connected descriptor line 33 concurrent server Figure 12.5, child still able communicate client using copyof descriptor. Why? Practice Problem 12.2 delete line 30 Figure 12.5, closes connected descriptor,the code would still correct, sense would memory leak.Why? 12.2 Concurrent Programming I/O Multiplexing Suppose asked write echo server also respond interactivecommands user types standard input. case, server mustrespond two independent I/O events: (1) network client making connectionrequest, (2) user typing command line keyboard. event wewait ﬁrst? Neither option ideal. waiting connection request inaccept , cannot respond input commands. Similarly, waiting input command read , cannot respond connection requests. One solution dilemma technique called I/O multiplexing . basic idea use select function ask kernel suspend process, return- ing control application one I/O events occurred, following examples: .Return descriptor set {0,4}is ready reading. .Return descriptor set {1,2,7}is ready writing. .Timeout 152 .13 seconds elapsed waiting I/O event occur. Select complicated function many different usage scenarios. discuss ﬁrst scenario: waiting set descriptors ready forreading. See [109, 110] complete discussion. #include <unistd.h> #include <sys/types.h> int select(int n, fd_set *fdset, NULL, NULL, NULL); Returns nonzero count ready descriptors, −1 error FD_ZERO(fd_set *fdset); /* Clear bits fdset */ FD_CLR(int fd, fd_set *fdset); /* Clear bit fd fdset */ FD_SET(int fd, fd_set *fdset); /* Turn bit fd fdset */ FD_ISSET(int fd, fd_set *fdset); /* bit fd fdset on? */ Macros manipulating descriptor sets940 Chapter 12 Concurrent Programming Theselect function manipulates sets type fd_set , known descriptor sets . Logically, think descriptor set bit vector (introduced Section 2.1) size n: bn−1,...,b1,b0 bit bkcorresponds descriptor k. Descriptor kis member descriptor set bk=1. allowed three things descriptor sets: (1) allocate them, (2) assign one variable type another, (3) mod-ify inspect using FD_ZERO, FD_SET, FD_CLR, FD_ISSETmacros. purposes, select function takes two inputs: descriptor set (fdset ) called read set , cardinality ( n) read set (actually maximum cardinality descriptor set). select function blocks least one descriptor read set ready reading. descriptor kisready reading request read 1 byte descriptor would block. side effect, select modiﬁes fd_set pointed argument fdset indicate subset read set called ready set , consisting descriptors read set ready reading. value returned functionindicates cardinality ready set. Note side effect, wemust update read set every time select called. best way understand select study concrete example. Figure 12.6 shows might use select implement iterative echo server also accepts user commands standard input. begin using open_ listenfd function Figure 11.17 open listening descriptor (line 17), using FD_ZERO create empty read set (line 19): listenfd stdin 3210 read_set (∅): 0 0 0 0 Next, lines 20 21, deﬁne read set consist descriptor 0 (standard input) descriptor 3 (the listening descriptor), respectively: listenfd stdin 3210 read_set ({0,3}) : 1 0 0 1 point, begin typical server loop. instead waiting connection request calling accept function, call select function, blocks either listening descriptor standard input ready forreading (line 25). example, value ready_set thatselect would return user hit enter key, thus causing standard input descriptor tobecome ready reading: listenfd stdin 3210 read_set ({0}) : 0 0 0 1code/conc/select.c 1#include "csapp.h" 2void echo(int connfd); 3void command(void); 4 5int main(int argc, char **argv) 6{ 7 int listenfd, connfd, port; 8 socklen_t clientlen = sizeof(struct sockaddr_in); 9 struct sockaddr_in clientaddr; 10 fd_set read_set, ready_set; 1112 (argc != 2) { 13 fprintf(stderr, "usage: %s <port>\n", argv[0]); 14 exit(0); 15 } 16 port = atoi(argv[1]); 17 listenfd = Open_listenfd(port); 1819 FD_ZERO(&read_set); /* Clear read set */ 20 FD_SET(STDIN_FILENO, &read_set); /* Add stdin read set */ 21 FD_SET(listenfd, &read_set); /* Add listenfd read set */ 22 23 (1) { 24 ready_set = read_set; 25 Select(listenfd+1, &ready_set, NULL, NULL, NULL); 26 (FD_ISSET(STDIN_FILENO, &ready_set)) 27 command(); /* Read command line stdin */ 28 (FD_ISSET(listenfd, &ready_set)) { 29 connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen); 30 echo(connfd); /* Echo client input EOF */ 31 Close(connfd); 32 } 33 } 34 } 35 36 void command(void) { 37 char buf[MAXLINE]; 38 (!Fgets(buf, MAXLINE, stdin)) 39 exit(0); /* EOF */ 40 printf("%s", buf); /* Process input command */ 41 } code/conc/select.c Figure 12.6 iterative echo server uses I/O multiplexing. server uses select wait connection requests listening descriptor commands standard input.942 Chapter 12 Concurrent Programming select returns, use FD_ISSET macro determine de- scriptors ready reading. standard input ready (line 26), call thecommand function, reads, parses, responds command re- turning main routine. listening descriptor ready (line 28), callaccept get connected descriptor, call echo function Fig- ure 11.21, echoes line client client closes end ofthe connection. program good example using select , still leaves something desired. problem connects client, continues echoinginput lines client closes end connection. Thus, type acommand standard input, get response server ﬁnishedwith client. better approach would multiplex ﬁner granularity,echoing (at most) one text line time server loop. Practice Problem 12.3 Unix systems, typing ctrl-d indicates EOF standard input. happens type ctrl-d program Figure 12.6 blocked call select ? 12.2.1 Concurrent Event-Driven Server Based I/O Multiplexing I/O multiplexing used basis concurrent event-driven programs, ﬂows make progress result certain events. general idea tomodel logical ﬂows state machines. Informally, state machine collection states ,input events , transitions map states input events states. transition maps (input state, input event) pair output state. self-loop transition input output state. State machines typicallydrawn directed graphs, nodes represent states, directed arcs representtransitions, arc labels represent input events. state machine begins executionin initial state. input event triggers transition current stateto next state. new client k, concurrent server based I/O multiplexing creates new state machine kand associates connected descriptor dk. shown Figure 12.7, state machine skhas one state (“waiting descriptor dkto ready reading”), one input event (“descriptor dkis ready reading”), one transition (“read text line descriptor dk”). server uses I/O multiplexing, courtesy select function, detect occurrence input events. connected descriptor becomes ready reading, server executes transition corresponding statemachine, case reading echoing text line descriptor. Figure 12.8 shows complete example code concurrent event-driven server based I/O multiplexing. set active clients maintained pool structure (lines 3–11). initializing pool calling init_pool (line 29), server enters inﬁnite loop. iteration loop, server callsSection 12.2 Concurrent Programming I/O Multiplexing 943 Figure 12.7 State machine fora logical ﬂow aconcurrent event-drivenecho server.Input event: “descriptor dk ready reading”Transition: “read text line descriptor dk” State: “waiting descriptor dkto ready reading” theselect function detect two different kinds input events: (a) connection request arriving new client, (b) connected descriptor existingclient ready reading. connection request arrives (line 36), server opens connection (line 37) calls add_client function add client pool (line 38). Finally, server calls check_clients function echo single text line ready connected descriptor (line 42). Theinit_pool function (Figure 12.9) initializes client pool. clientfd array represents set connected descriptors, integer −1 denoting available slot. Initially, set connected descriptors empty (lines 5–7), andthe listening descriptor descriptor select read set (lines 10–12). Theadd_client function (Figure 12.10) adds new client pool active clients. ﬁnding empty slot clientfd array, server adds connected descriptor array initializes corresponding Rioread buffer call rio_readlineb descriptor (lines 8–9). add connected descriptor select read set (line 12), update global properties pool. maxfd variable (lines 15–16) keeps track largest ﬁle descriptor select .T h e maxi variable (lines 17–18) keeps track largest index clientfd array check_clients functions search entire array. Thecheck_clients function echoes text line ready connected descriptor (Figure 12.11). successful reading text line thedescriptor, echo line back client (lines 15–18). Notice thatin line 15 maintaining cumulative count total bytes received allclients. detect EOF client closed end connection,then close end connection (line 23) remove descriptor fromthe pool (lines 24–25). terms ﬁnite state model Figure 12.7, select function detects input events, add_client function creates new logical ﬂow (state ma- chine). check_clients function performs state transitions echoing input lines, also deletes state machine client ﬁnished sending text lines.944 Chapter 12 Concurrent Programming code/conc/echoservers.c 1 #include "csapp.h" 2 3 typedef struct { /* Represents pool connected descriptors */ 4 int maxfd; /* Largest descriptor read_set */ 5 fd_set read_set; /* Set active descriptors */ 6 fd_set ready_set; /* Subset descriptors ready reading */ 7 int nready; /* Number ready descriptors select */ 8 int maxi; /* Highwater index client array */ 9 int clientfd[FD_SETSIZE]; /* Set active descriptors */ 10 rio_t clientrio[FD_SETSIZE]; /* Set active read buffers */ 11 } pool; 12 13 int byte_cnt = 0; /* Counts total bytes received server */ 14 15 int main(int argc, char **argv) 16 { 17 int listenfd, connfd, port; 18 socklen_t clientlen = sizeof(struct sockaddr_in); 19 struct sockaddr_in clientaddr; 20 static pool pool; 2122 (argc != 2) { 23 fprintf(stderr, "usage: %s <port>\n", argv[0]); 24 exit(0); 25 } 26 port = atoi(argv[1]); 27 28 listenfd = Open_listenfd(port); 29 init_pool(listenfd, &pool); 30 (1) { 31 /* Wait listening/connected descriptor(s) become ready */ 32 pool.ready_set = pool.read_set; 33 pool.nready = Select(pool.maxfd+1, &pool.ready_set, NULL, NULL, NULL); 3435 /* listening descriptor ready, add new client pool */ 36 (FD_ISSET(listenfd, &pool.ready_set)) { 37 connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen); 38 add_client(connfd, &pool); 39 } 40 41 /* Echo text line ready connected descriptor */ 42 check_clients(&pool); 43 } 44 } code/conc/echoservers.c Figure 12.8 Concurrent echo server based I/O multiplexing. server iteration echoes text line ready descriptor.Section 12.2 Concurrent Programming I/O Multiplexing 945 code/conc/echoservers.c 1 void init_pool(int listenfd, pool *p) 2 { 3 /* Initially, connected descriptors */ 4 int i; 5 p->maxi = -1; 6 (i=0; i< FD_SETSIZE; i++) 7 p->clientfd[i] = -1; 8 9 /* Initially, listenfd member select read set */ 10 p->maxfd = listenfd; 11 FD_ZERO(&p->read_set); 12 FD_SET(listenfd, &p->read_set); 13 } code/conc/echoservers.c Figure 12.9 init_pool : Initializes pool active clients. code/conc/echoservers.c 1 void add_client(int connfd, pool *p) 2 { 3 int i; 4 p->nready--; 5 (i = 0; < FD_SETSIZE; i++) /* Find available slot */ 6 (p->clientfd[i] < 0) { 7 /* Add connected descriptor pool */ 8 p->clientfd[i] = connfd; 9 Rio_readinitb(&p->clientrio[i], connfd); 10 11 /* Add descriptor descriptor set */ 12 FD_SET(connfd, &p->read_set); 13 14 /* Update max descriptor pool highwater mark */ 15 (connfd > p->maxfd) 16 p->maxfd = connfd; 17 (i > p->maxi) 18 p->maxi = i; 19 break; 20 } 21 (i == FD_SETSIZE) /* Couldn’t find empty slot */ 22 app_error("add_client error: many clients"); 23 } code/conc/echoservers.c Figure 12.10 add_client : Adds new client connection pool.946 Chapter 12 Concurrent Programming code/conc/echoservers.c 1void check_clients(pool *p) 2{ 3 int i, connfd, n; 4 char buf[MAXLINE]; 5 rio_t rio; 6 7 (i = 0; (i <= p->maxi) && (p->nready > 0); i++) { 8 connfd = p->clientfd[i]; 9 rio = p->clientrio[i]; 1011 /* descriptor ready, echo text line */ 12 ((connfd > 0) && (FD_ISSET(connfd, &p->ready_set))) { 13 p->nready--; 14 ((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) { 15 byte_cnt += n; 16 printf("Server received %d (%d total) bytes fd %d\n", 17 n, byte_cnt, connfd); 18 Rio_writen(connfd, buf, n); 19 } 2021 /* EOF detected, remove descriptor pool */ 22 else { 23 Close(connfd); 24 FD_CLR(connfd, &p->read_set); 25 p->clientfd[i] = -1; 26 } 27 } 28 } 29 } code/conc/echoservers.c Figure 12.11 check_clients : Services ready client connections. 12.2.2 Pros Cons I/O Multiplexing server Figure 12.8 provides nice example advantages disad- vantages event-driven programming based I/O multiplexing. One advantageis event-driven designs give programmers control behavior oftheir programs process-based designs. example, imagine writ-ing event-driven concurrent server gives preferred service clients,which would difﬁcult concurrent server based processes. Another advantage event-driven server based I/O multiplexing runs context single process, thus every logical ﬂow access tothe entire address space process. makes easy share data betweenSection 12.3 Concurrent Programming Threads 947 ﬂows. related advantage running single process debug concurrent server would sequential program, using familiardebugging tool gdb. Finally, event-driven designs often signiﬁcantly efﬁcient process-based designs require processcontext switch schedule new ﬂow. signiﬁcant disadvantage event-driven designs coding complexity. event-driven concurrent echo server requires three times code theprocess-based server. Unfortunately, complexity increases granularity concurrency decreases. granularity , mean number instructions logical ﬂow executes per time slice. instance, example concur-rent server, granularity concurrency number instructions requiredto read entire text line. long logical ﬂow busy reading text line,no logical ﬂow make progress. ﬁne example, makesour event-driver server vulnerable malicious client sends partialtext line halts. Modifying event-driven server handle partial textlines nontrivial task, handled cleanly automatically process-based design. Another signiﬁcant disadvantage event-based designs theycannot fully utilize multi-core processors. Practice Problem 12.4 server Figure 12.8, careful reinitialize pool.ready_set variable immediately every call select . Why? 12.3 Concurrent Programming Threads point, looked two approaches creating concurrent logical ﬂows. ﬁrst approach, use separate process ﬂow. kernelschedules process automatically. process private addressspace, makes difﬁcult ﬂows share data. second approach,we create logical ﬂows use I/O multiplexing explicitly schedulethe ﬂows. one process, ﬂows share entire address space.This section introduces third approach—based threads—that hybrid ofthese two. Athread logical ﬂow runs context process. Thus far book, programs consisted single thread per process. Butmodern systems also allow us write programs multiple threads runningconcurrently single process. threads scheduled automatically thekernel. thread thread context , including unique integer thread ID(TID), stack, stack pointer, program counter, general-purpose registers, condition codes. threads running process share entire virtual address space process. Logical ﬂows based threads combine qualities ﬂows based processes I/O multiplexing. Like processes, threads scheduled automatically thekernel known kernel integer ID. Like ﬂows based I/O948 Chapter 12 Concurrent Programming Figure 12.12 Concurrent threadexecution.Thread 1 (main thread)Thread 2 (peer thread)Time Thread context switc h Thread context switc h Thread context switc h multiplexing, multiple threads run context single process, thus share entire contents process virtual address space, including code, data,heap, shared libraries, open ﬁles. 12.3.1 Thread Execution Model execution model multiple threads similar ways execution model multiple processes. Consider example Figure 12.12. processbegins life single thread called main thread . point, main thread creates peer thread , point time two threads run concurrently. Eventually, control passes peer thread via context switch, themain thread executes slow system call read orsleep , interrupted system’s interval timer. peer thread executes whilebefore control passes back main thread, on. Thread execution differs processes important ways. thread context much smaller process context, thread context switch faster process context switch. Another difference threads, unlike pro-cesses, organized rigid parent-child hierarchy. threads associatedwith process form pool peers, independent threads created threads. main thread distinguished threads onlyin sense always ﬁrst thread run process. main impactof notion pool peers thread kill peers, waitfor peers terminate. Further, peer read write sameshared data. 12.3.2 Posix Threads Posix threads (Pthreads) standard interface manipulating threads C programs. adopted 1995 available Unix systems. Pthreadsdeﬁnes 60 functions allow programs create, kill, reap threads,to share data safely peer threads, notify peers changes system state.Section 12.3 Concurrent Programming Threads 949 code/conc/hello.c 1#include "csapp.h" 2void *thread(void *vargp); 3 4int main() 5{ 6 pthread_t tid; 7 Pthread_create(&tid, NULL, thread, NULL); 8 Pthread_join(tid, NULL); 9 exit(0); 10 } 11 12 void *thread(void *vargp) /* Thread routine */ 13 { 14 printf("Hello, world!\n"); 15 return NULL; 16 } code/conc/hello.c Figure 12.13 hello.c : Pthreads “Hello, world!” program. Figure 12.13 shows simple Pthreads program. main thread creates peer thread waits terminate. peer thread prints “ Hello, world!\n ” terminates. main thread detects peer thread terminated, terminates process calling exit . ﬁrst threaded program seen, let us dissect carefully. code local data thread encapsulated thread routine . shown prototype line 2, thread routine takes input single genericpointer returns generic pointer. want pass multiple arguments toa thread routine, put arguments structure pass apointer structure. Similarly, want thread routine return multiplearguments, return pointer structure. Line 4 marks beginning code main thread. main thread declares single local variable tid, used store thread ID peer thread (line 6). main thread creates new peer thread calling thepthread_create function (line 7). call pthread_create returns, main thread newly created peer thread running concurrently, tid contains ID new thread. main thread waits peer threadto terminate call pthread_join line 8. Finally, main thread callsexit (line 9), terminates threads (in case main thread) currently running process. Lines 12–16 deﬁne thread routine peer thread. simply prints string terminates peer thread executing return statement line 15.950 Chapter 12 Concurrent Programming 12.3.3 Creating Threads Threads create threads calling pthread_create function. #include <pthread.h> typedef void *(func)(void *); int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg); Returns: 0 OK, nonzero error Thepthread_create function creates new thread runs thread rou- tinefin context new thread input argument arg.T h e attr argument used change default attributes newly created thread. Changing attributes beyond scope, examples, wewill always call pthread_create NULL attr argument. pthread_create returns, argument tidcontains ID newly created thread. new thread determine thread ID calling thepthread_self function. #include <pthread.h> pthread_t pthread_self(void); Returns: thread ID caller 12.3.4 Terminating Threads thread terminates one following ways: .The thread terminates implicitly top-level thread routine returns. .The thread terminates explicitly calling pthread_exit function. main thread calls pthread_exit , waits peer threads terminate, terminates main thread entire process return value thread_return . #include <pthread.h> void pthread_exit(void *thread_return); Returns: 0 OK, nonzero error .Some peer thread calls Unix exit function, terminates process threads associated process. .Another peer thread terminates current thread calling pthread_ cancel function ID current thread.Section 12.3 Concurrent Programming Threads 951 #include <pthread.h> int pthread_cancel(pthread_t tid); Returns: 0 OK, nonzero error 12.3.5 Reaping Terminated Threads Threads wait threads terminate calling pthread_join function. #include <pthread.h> int pthread_join(pthread_t tid, void **thread_return); Returns: 0 OK, nonzero error Thepthread_join function blocks thread tid terminates, assigns generic (void *) pointer returned thread routine location pointed bythread_return , reaps memory resources held terminated thread. Notice that, unlike Unix wait function, pthread_join function wait speciﬁc thread terminate. way instruct pthread_ wait wait arbitrary thread terminate. complicate code forcing us use other, less intuitive mechanisms detect process termination.Indeed, Stevens argues convincingly bug speciﬁcation [109]. 12.3.6 Detaching Threads point time, thread joinable ordetached . joinable thread reaped killed threads. memory resources (such stack) arenot freed reaped another thread. contrast, detached thread cannotbe reaped killed threads. memory resources freed automaticallyby system terminates. default, threads created joinable. order avoid memory leaks, joinable thread either explicitly reaped another thread, detachedby call pthread_detach function. #include <pthread.h> int pthread_detach(pthread_t tid); Returns: 0 OK, nonzero error952 Chapter 12 Concurrent Programming Thepthread_detach function detaches joinable thread tid. Threads detach calling pthread_detach argument pthread_ self() . Although examples use joinable threads, good rea- sons use detached threads real programs. example, high-performanceWeb server might create new peer thread time receives connection re-quest Web browser. Since connection handled independently aseparate thread, unnecessary—and indeed undesirable—for server ex-plicitly wait peer thread terminate. case, peer thread shoulddetach begins processing request memory resourcescan reclaimed terminates. 12.3.7 Initializing Threads Thepthread_once function allows initialize state associated thread routine. #include <pthread.h> pthread_once_t once_control = PTHREAD_ONCE_INIT; int pthread_once(pthread_once_t *once_control, void (*init_routine)(void)); Always returns 0 Theonce_control variable global static variable always initial- ized PTHREAD_ONCE_INIT. ﬁrst time call pthread_once argument once_control , invokes init_routine , function input arguments returns nothing. Subsequent calls pthread_once once_control variable nothing. pthread_once function useful whenever need dynamically initialize global variables shared bymultiple threads. look example Section 12.5.5. 12.3.8 Concurrent Server Based Threads Figure 12.14 shows code concurrent echo server based threads. overall structure similar process-based design. main thread repeat-edly waits connection request creates peer thread handle therequest. code looks simple, couple general somewhatsubtle issues need look closely. ﬁrst issue pass con-nected descriptor peer thread call pthread_create . obvious approach pass pointer descriptor, following: connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen); Pthread_create(&tid, NULL, thread, &connfd);Section 12.3 Concurrent Programming Threads 953 code/conc/echoservert.c 1#include "csapp.h" 2 3void echo(int connfd); 4void *thread(void *vargp); 56 int main(int argc, char **argv) 7{ 8 int listenfd, *connfdp, port; 9 socklen_t clientlen=sizeof(struct sockaddr_in); 10 struct sockaddr_in clientaddr; 11 pthread_t tid; 12 13 (argc != 2) { 14 fprintf(stderr, "usage: %s <port>\n", argv[0]); 15 exit(0); 16 } 17 port = atoi(argv[1]); 18 19 listenfd = Open_listenfd(port); 20 (1) { 21 connfdp = Malloc(sizeof(int)); 22 *connfdp = Accept(listenfd, (SA *) &clientaddr, &clientlen); 23 Pthread_create(&tid, NULL, thread, connfdp); 24 } 25 } 2627 /* Thread routine */ 28 void *thread(void *vargp) 29 { 30 int connfd = *((int *)vargp); 31 Pthread_detach(pthread_self()); 32 Free(vargp); 33 echo(connfd); 34 Close(connfd); 35 return NULL; 36 } code/conc/echoservert.c Figure 12.14 Concurrent echo server based threads.954 Chapter 12 Concurrent Programming peer thread dereference pointer assign local variable, follows: void *thread(void *vargp) { int connfd = *((int *)vargp); ... } would wrong, however, introduces race as- signment statement peer thread accept statement main thread. assignment statement completes next accept , lo- calconnfd variable peer thread gets correct descriptor value. However, assignment completes theaccept , local connfd variable peer thread gets descriptor number next connection. unhappy result two threads performing input output descriptor.In order avoid potentially deadly race, must assign connected de-scriptor returned accept dynamically allocated memory block, shown lines 21–22. return issue races Section 12.7.4. Another issue avoiding memory leaks thread routine. Since explicitly reaping threads, must detach thread memoryresources reclaimed terminates (line 31). Further, must becareful free memory block allocated main thread (line 32). Practice Problem 12.5 process-based server Figure 12.5, careful close connecteddescriptor two places: parent child processes. However, threads-based server Figure 12.14, closed connected descriptor one place:the peer thread. Why? 12.4 Shared Variables Threaded Programs programmer’s perspective, one attractive aspects threads theease multiple threads share program variables. However,this sharing tricky. order write correctly threaded programs, musthave clear understanding mean sharing works. basic questions work order understand whether variable n C program shared not: (1) underlying memory model threads? (2) Given model, instances vari-able mapped memory? (3) Finally, many threads reference theseinstances? variable shared multiple threads reference instance variable. keep discussion sharing concrete, use program Fig- ure 12.15 running example. Although somewhat contrived, nonethelessuseful study illustrates number subtle points sharing. example program consists main thread creates two peer threads. TheSection 12.4 Shared Variables Threaded Programs 955 code/conc/sharing.c 1#include "csapp.h" 2#define N 2 3void *thread(void *vargp); 4 5char **ptr; /* Global variable */ 6 7int main() 8{ 9 int i; 10 pthread_t tid; 11 char *msgs[N] = { 12 "Hello foo", 13 "Hello bar" 14 }; 1516 ptr = msgs; 17 f r( i=0 ;i<N ; i++) 18 Pthread_create(&tid, NULL, thread, (void *)i); 19 Pthread_exit(NULL); 20 } 21 22 void *thread(void *vargp) 23 { 24 int myid = (int)vargp; 25 static int cnt = 0; 26 printf("[%d]: %s (cnt=%d)\n", myid, ptr[myid], ++cnt); 27 return NULL; 28 } code/conc/sharing.c Figure 12.15 Example program illustrates different aspects sharing. main thread passes unique ID peer thread, uses ID print personalized message, along count total number times thread routine invoked. 12.4.1 Threads Memory Model pool concurrent threads runs context process. thread separate thread context , includes thread ID, stack, stack pointer, program counter, condition codes, general-purpose register values. thread shares rest process context threads. includes entire user virtual address space, consists read-only text (code),read/write data, heap, shared library code data areas. threadsalso share set open ﬁles.956 Chapter 12 Concurrent Programming operational sense, impossible one thread read write register values another thread. hand, thread access anylocation shared virtual memory. thread modiﬁes memory location,then every thread eventually see change reads location.Thus, registers never shared, whereas virtual memory always shared. memory model separate thread stacks clean. stacks contained stack area virtual address space, usually accessed independently respective threads. say usually rather always , different thread stacks protected threads. thread somehow manages acquire pointer another thread’s stack, thenit read write part stack. example program shows inline 26, peer threads reference contents main thread’s stackindirectly global ptrvariable. 12.4.2 Mapping Variables Memory Variables threaded C programs mapped virtual memory according storage classes: .Global variables. Aglobal variable variable declared outside func- tion. run time, read/write area virtual memory contains exactly oneinstance global variable referenced thread. ex-ample, global ptrvariable declared line 5 one run-time instance read/write area virtual memory. one instance avariable, denote instance simply using variable name—inthis case, ptr. .Local automatic variables. Alocal automatic variable one declared inside function without static attribute. run time, thread’s stack contains instances local automatic variables. trueeven multiple threads execute thread routine. example, thereis one instance local variable tid, resides stack main thread. denote instance tid.m . another example, two instances local variable myid , one instance stack peer thread 0, stack peer thread 1. denote theseinstances myid.p0 andmyid.p1 , respectively. .Local static variables. Alocal static variable one declared inside function static attribute. global variables, read/write area virtual memory contains exactly one instance local staticvariable declared program. example, even though peer threadin example program declares cntin line 25, run time one instance cntresiding read/write area virtual memory. peer thread reads writes instance. 12.4.3 Shared Variables say variable visshared one instances referenced one thread. example, variable cnt example program isSection 12.5 Synchronizing Threads Semaphores 957 shared one run-time instance instance referenced peer threads. hand, myid shared two instances referenced exactly one thread. However, important realizethat local automatic variables msgs also shared. Practice Problem 12.6 A. Using analysis Section 12.4, ﬁll entry following table “Yes” “No” example program Figure 12.15. ﬁrstcolumn, notation v.tdenotes instance variable vresiding local stack thread t, tis either m(main thread), p0(peer thread 0), orp1(peer thread 1). Variable Referenced Referenced Referenced instance main thread? peer thread 0? peer thread 1? ptr cnt i.m msgs.m myid.p0 myid.p1 B. Given analysis Part A, variables ptr,cnt,i,msgs , myid shared? 12.5 Synchronizing Threads Semaphores Shared variables convenient, introduce possibility nasty synchronization errors . Consider badcnt.c program Figure 12.16, creates two threads, increments global shared counter variablecalled cnt. Since thread increments counter niters times, expect ﬁnal value 2 ×niters . seems quite simple straightforward. However, run badcnt.c Linux system, get wrong answers, get different answers time! linux> ./badcnt 1000000 BOOM! cnt=1445085 linux> ./badcnt 1000000 BOOM! cnt=1915220 linux> ./badcnt 1000000 BOOM! cnt=1404746code/conc/badcnt.c 1#include "csapp.h" 2 3void *thread(void *vargp); /* Thread routine prototype */ 4 5/* Global shared variable */ 6volatile int cnt = 0; /* Counter */ 7 8int main(int argc, char **argv) 9{ 10 int niters; 11 pthread_t tid1, tid2; 12 13 /* Check input argument */ 14 (argc != 2) { 15 printf("usage: %s <niters>\n", argv[0]); 16 exit(0); 17 } 18 niters = atoi(argv[1]); 1920 /* Create threads wait finish */ 21 Pthread_create(&tid1, NULL, thread, &niters); 22 Pthread_create(&tid2, NULL, thread, &niters); 23 Pthread_join(tid1, NULL); 24 Pthread_join(tid2, NULL); 25 26 /* Check result */ 27 (cnt != (2 * niters)) 28 printf("BOOM! cnt=%d\n", cnt); 29 else 30 printf("OK cnt=%d\n", cnt); 31 exit(0); 32 } 33 34 /* Thread routine */ 35 void *thread(void *vargp) 36 { 37 int i, niters = *((int *)vargp); 38 39 (i = 0; < niters; i++) 40 cnt++; 4142 return NULL; 43 } code/conc/badcnt.c Figure 12.16 badcnt.c : improperly synchronized counter program.Section 12.5 Synchronizing Threads Semaphores 959 C code thread iAsm code thread (i /H110050; < niters; /H11001/H11001) cnt /H11001/H11001; movl (%rdi),%ecx movl $0,%edx cmpl %ecx,%edx jge .L13 .L11: movl cnt(%rip),%eax incl %eax movl %eax,cnt(%rip) incl %edx cmpl %ecx,%edx jl .L11.L13:Hi: Head Ti: TailLi: Load cnt Ui: Update cnt Si: Store cnt Figure 12.17 Assembly code counter loop (lines 39–40) badcnt.c . went wrong? understand problem clearly, need study assembly code counter loop (lines 39–40), shown Figure 12.17.We ﬁnd helpful partition loop code thread iinto ﬁve parts: .Hi: block instructions head loop .Li: instruction loads shared variable cnt register %eax i, %eaxidenotes value register %eax thread .Ui: instruction updates (increments) %eax .Si: instruction stores updated value %eax iback shared variable cnt .Ti: block instructions tail loop Notice head tail manipulate local stack variables, Li,Ui, andSimanipulate contents shared counter variable. two peer threads badcnt.c run concurrently uniprocessor, machine instructions completed one order. Thus, concurrent execution deﬁnes total ordering (or interleaving) in-structions two threads. Unfortunately, orderings producecorrect results, others not. crucial point: general, way predict whether operating system choose correct ordering threads. example, Figure 12.18(a) shows step-by-step operation correct instruction ordering.After thread updated shared variable cnt, value memory 2, expected result. hand, ordering Figure 12.18(b) produces incorrect value cnt. problem occurs thread 2 loads cntin step 5, thread 1 loads cntin step 2, thread 1 stores up- dated value step 6. Thus, thread ends storing updated counter valueof 1. clarify notions correct incorrect instruction orderingswith help device known progress graph , introduce next section.960 Chapter 12 Concurrent Programming Step Thread Instr %eax 1%eax 2cnt 11 H1 —— 0 21 L1 0— 0 31 U1 1— 0 41 S1 1— 1 52 H2 —— 1 62 L2 —1 1 72 U2 —2 1 82 S2 —2 2 92 T2 —2 2 10 1 T1 1— 2 (a) Correct orderingStep Thread Instr %eax 1%eax 2cnt 11 H1 —— 0 21 L1 0— 0 31 U1 1— 0 42 H2 —— 0 52 L2 —0 0 61 S1 1— 1 71 T1 1— 1 82 U2 —1 1 92 S2 —1 1 10 2 T2 —1 1 (b) Incorrect ordering Figure 12.18 Instruction orderings ﬁrst loop iteration badcnt.c . Practice Problem 12.7 Complete table following instruction ordering badcnt.c : Step Thread Instr %eax 1%eax 2 cnt 11 H1 ——0 21 L1 32 H2 42 L2 52 U2 62 S2 71 U1 81 S1 91 T1 10 2 T2 ordering result correct value cnt? 12.5.1 Progress Graphs Aprogress graph models execution nconcurrent threads trajectory n-dimensional Cartesian space. axis kcorresponds progress thread k. point (I1,I2,...,I n)represents state thread k(k= 1,...,n ) completed instruction Ik. origin graph corresponds initial state none threads yet completed instruction. Figure 12.19 shows two-dimensional progress graph ﬁrst loop iteration badcnt.c program. horizontal axis corresponds thread 1, vertical axis thread 2. Point (L1,S2)corresponds state thread 1 completed L1and thread 2 completed S2.Section 12.5 Synchronizing Threads Semaphores 961 Figure 12.19 Progress graph theﬁrst loop iteration badcnt.c .Thread 2 Thread 1T2 S2 U2 L2 H2 H1 L1 U1 S1 T1(L1,S2) Figure 12.20 example trajectory.Thread 2 Thread 1T2 S2 U2 L2 H2 H1 L1 U1 S1 T1 progress graph models instruction execution transition one state another. transition represented directed edge one point anadjacent point. Legal transitions move right (an instruction thread 1completes) (an instruction thread 2 completes). Two instructions cannotcomplete time—diagonal transitions allowed. Programs never run backwards, transitions move left legal either. execution history program modeled trajectory state space. Figure 12.20 shows trajectory corresponds followinginstruction ordering: H 1,L1,U1,H2,L2,S1,T1,U2,S2,T2 thread i, instructions (Li,Ui,Si)that manipulate contents shared variable cnt constitute critical section (with respect shared variable962 Chapter 12 Concurrent Programming Figure 12.21 Safe unsafe trajec-tories. intersection critical regions formsan unsafe region. Trajec- tories skirt unsafe region correctly update thecounter variable.Thread 2 Critical section wrtcnt Critical section wrt cntThread 1T2 S2 U2 L2 H2 H1 L1 U1 S1 T1Unsafe region Unsafe trajectorySafe trajectory cnt) interleaved critical section thread. words, want ensure thread mutually exclusive access shared variable executing instructions critical section. Thephenomenon general known mutual exclusion . progress graph, intersection two critical sections deﬁnes region state space known unsafe region . Figure 12.21 shows unsafe region variable cnt. Notice unsafe region abuts, include, states along perimeter. example, states (H 1,H2)and(S1,U2) abut unsafe region, part it. trajectory skirts unsaferegion known safe trajectory . Conversely, trajectory touches part unsafe region unsafe trajectory . Figure 12.21 shows examples safe unsafe trajectories state space example badcnt.c program. upper trajectory skirts unsafe region along left top sides, thus safe. lower trajectory crosses unsafe region, thus unsafe. safe trajectory correctly update shared counter. order guarantee correct execution example threaded program—and indeed anyconcurrent program shares global data structures—we must somehow syn- chronize threads always safe trajectory. classic approach based idea semaphore, introduce next. Practice Problem 12.8 Using progress graph Figure 12.21, classify following trajectories either safe orunsafe . A.H1,L1,U1,S1,H2,L2,U2,S2,T2,T1 B.H2,L2,H1,L1,U1,S1,T1,U2,S2,T2 C.H1,H2,L2,U2,S2,L1,U1,S1,T1,T2Section 12.5 Synchronizing Threads Semaphores 963 12.5.2 Semaphores Edsger Dijkstra, pioneer concurrent programming, proposed classic solution problem synchronizing different execution threads based specialtype variable called semaphore . semaphore, s, global variable nonnegative integer value manipulated two special operations,called PandV: .P(s) :I fsis nonzero, Pdecrements sand returns immediately. sis zero, suspend thread sbecomes nonzero process restarted aVoperation. restarting, Poperation decrements sand returns control caller. .V( s) :T h e Voperation increments sby 1. threads blocked aPoperation waiting sto become nonzero, Voperation restarts exactly one threads, completes Poperation decrementing s. test decrement operations Poccur indivisibly, sense semaphore sbecomes nonzero, decrement soccurs without in- terruption. increment operation Valso occurs indivisibly, loads, increments, stores semaphore without interruption. Notice deﬁ-nition Vdoes notdeﬁne order waiting threads restarted. requirement Vmust restart exactly one waiting thread. Thus, several threads waiting semaphore, cannot predict one berestarted result V. deﬁnitions PandVensure running program never enter state properly initialized semaphore negative value. property,known semaphore invariant , provides powerful tool controlling trajectories concurrent programs, shall see next section. Posix standard deﬁnes variety functions manipulating sema- phores. #include <semaphore.h> int sem_init(sem_t *sem, 0, unsigned int value); int sem_wait(sem_t *s); /* P(s) */ int sem_post(sem_t *s); /* V(s) */ Returns: 0 OK, −1 error Thesem_init function initializes semaphore semtovalue . semaphore must initialized used. purposes, middle argumentis always 0. Programs perform PandVoperations calling sem_wait sem_post functions, respectively. conciseness, prefer use following equivalent PandVwrapper functions instead:964 Chapter 12 Concurrent Programming #include "csapp.h" void P(sem_t *s); /* Wrapper function sem_wait */ void V(sem_t *s); /* Wrapper function sem_post */ Returns: nothing Aside Origin names PandV Edsger Dijkstra (1930–2002) originally Netherlands. names PandVcome Dutch words Proberen (to test) Verhogen (to increment). 12.5.3 Using Semaphores Mutual Exclusion Semaphores provide convenient way ensure mutually exclusive access shared variables. basic idea associate semaphore s, initially 1, shared variable (or related set shared variables) surround thecorresponding critical section P(s) andV( s) operations. semaphore used way protect shared variables called binary semaphore value always 0 1. Binary semaphores whose purpose provide mutual exclusion often called mutexes . Performing Poperation mutex called locking mutex. Similarly, performing Voperation called unlocking mutex. thread locked yet unlocked mutex said holding mutex. semaphore used counter set available resources called counting semaphore . progress graph Figure 12.22 shows would use binary sema- phores properly synchronize example counter program. state la-beled value semaphore sin state. crucial idea combination PandVoperations creates collection states, called forbid- den region , s<0. semaphore invariant, feasible trajectory include one states forbidden region. since forbidden re-gion completely encloses unsafe region, feasible trajectory touch anypart unsafe region. Thus, every feasible trajectory safe, regardless ofthe ordering instructions run time, program correctly increments counter. operational sense, forbidden region created PandVop- erations makes impossible multiple threads executing instructions inthe enclosed critical region point time. words, semaphoreoperations ensure mutually exclusive access critical region. Putting together, properly synchronize example counter program Figure 12.16 using semaphores, ﬁrst declare semaphore called mutex : volatile int cnt = 0; /* Counter */ sem_t mutex; /* Semaphore protects counter */Section 12.5 Synchronizing Threads Semaphores 965 Thread 2 Thread 1S2T2 U2 L2 P(s) H2 H1 P(s) L1 U1 S1 V(s)V(s) T1110000 110000 00–1–1–1–1 00–1–1–1–1 00–1–1–1–1 00–1–1–1–1 110000 1100001100001111000011Unsafe regionForbidden region Initially s/H110051 Figure 12.22 Using semaphores mutual exclusion. infeasible states s<0deﬁne forbidden region surrounds unsafe region prevents feasible trajectory touching unsafe region. initialize unity main routine: Sem_init(&mutex, 0, 1); /* mute x=1* / Finally, protect update shared cntvariable thread routine surrounding PandVoperations: (i = 0; < niters; i++) { P(&mutex); cnt++; V(&mutex); } run properly synchronized program, produces correct answer time. linux> ./goodcnt 1000000 OK cnt=2000000 linux> ./goodcnt 1000000 OK cnt=2000000966 Chapter 12 Concurrent Programming Aside Limitations progress graphs Progress graphs give us nice way visualize concurrent program execution uniprocessors understand need synchronization. However, limitations, particularly respect concurrent execution multiprocessors, set CPU/cache pairs share main memory. Multiprocessors behave ways cannot explained progress graphs. particular, multiprocessor memory system state correspond trajectory progress graph. Regardless, message remains same: always synchronize accesses shared variables, regardless you’re running uniprocessor multiprocessor. 12.5.4 Using Semaphores Schedule Shared Resources Another important use semaphores, besides providing mutual exclusion, schedule accesses shared resources. scenario, thread uses semaphoreoperation notify another thread condition program state hasbecome true. Two classical useful examples producer-consumer readers-writers problems. Producer-Consumer Problem producer-consumer problem shown Figure 12.23. producer con- sumer thread share bounded buffer withnslots . producer thread repeatedly produces new items inserts buffer. consumer thread repeat- edly removes items buffer consumes (uses) them. Variants withmultiple producers consumers also possible. Since inserting removing items involves updating shared variables, must guarantee mutually exclusive access buffer. guaranteeing mutualexclusion sufﬁcient. also need schedule accesses buffer. thebuffer full (there empty slots), producer must wait slotbecomes available. Similarly, buffer empty (there available items),then consumer must wait item becomes available. Producer-consumer interactions occur frequently real systems. exam- ple, multimedia system, producer might encode video frames consumer decodes renders screen. purpose buffer toreduce jitter video stream caused data-dependent differences en- coding decoding times individual frames. buffer provides reservoir ofslots producer reservoir encoded frames consumer. Anothercommon example design graphical user interfaces. producer detects Producer threadConsumer threadBounded buffer Figure 12.23 Producer-consumer problem. producer generates items inserts bounded buffer. consumer removes items buffer consumes them.Section 12.5 Synchronizing Threads Semaphores 967 code/conc/sbuf.h 1typedef struct { 2 int *buf; /* Buffer array */ 3 int n; /* Maximum number slots */ 4 int front; /* buf[(front+1)%n] first item */ 5 int rear; /* buf[rear%n] last item */ 6 sem_t mutex; /* Protects accesses buf */ 7 sem_t slots; /* Counts available slots */ 8 sem_t items; /* Counts available items */ 9} sbuf_t; code/conc/sbuf.h Figure 12.24 sbuf_t : Bounded buffer used Sbuf package. mouse keyboard events inserts buffer. consumer removes events buffer priority-based manner paints screen. section, develop simple package, called Sbuf , building producer-consumer programs. next section, look use tobuild interesting concurrent server based prethreading. Sbuf manipulates bounded buffers type sbuf_t (Figure 12.24). Items stored dynamically allocated integer array ( buf) nitems. front andrear indices keep track ﬁrst last items array. Three semaphores synchronize accessto buffer. mutex semaphore provides mutually exclusive buffer access. Semaphores slots anditems counting semaphores count number empty slots available items, respectively. Figure 12.25 shows implementation Sbuf function. sbuf_init function allocates heap memory buffer, sets front andrear indicate empty buffer, assigns initial values three semaphores. functionis called once, calls three functions. sbuf_deinit function frees buffer storage application using it. sbuf_insert function waits available slot, locks mutex, adds item, unlocks mutex, announces availability new item. sbuf_ remove function symmetric. waiting available buffer item, locks mutex, removes item front buffer, unlocks mutex, andthen signals availability new slot. Practice Problem 12.9 Letpdenote number producers, cthe number consumers, nthe buffer size units items. following scenarios, indicate whether mutex semaphore sbuf_insert andsbuf_remove necessary not. A.p=1,c=1,n>1 B.p=1,c=1,n=1 C.p>1,c>1,n=1968 Chapter 12 Concurrent Programming code/conc/sbuf.c 1#include "csapp.h" 2#include "sbuf.h" 3 4/* Create empty, bounded, shared FIFO buffer n slots */ 5void sbuf_init(sbuf_t *sp, int n) 6{ 7 sp->buf = Calloc(n, sizeof(int)); 8 sp->n = n; /* Buffer holds max n items */ 9 sp->front = sp->rear = 0; /* Empty buffer iff front == rear */ 10 Sem_init(&sp->mutex, 0, 1); /* Binary semaphore locking */ 11 Sem_init(&sp->slots, 0, n); /* Initially, buf n empty slots */ 12 Sem_init(&sp->items, 0, 0); /* Initially, buf zero data items */ 13 } 14 15 /* Clean buffer sp */ 16 void sbuf_deinit(sbuf_t *sp) 17 { 18 Free(sp->buf); 19 } 2021 /* Insert item onto rear shared buffer sp */ 22 void sbuf_insert(sbuf_t *sp, int item) 23 { 24 P(&sp->slots); /* Wait available slot */ 25 P(&sp->mutex); /* Lock buffer */ 26 sp->buf[(++sp->rear)%(sp->n)] = item; /* Insert item */ 27 V(&sp->mutex); /* Unlock buffer */ 28 V(&sp->items); /* Announce available item */ 29 } 30 31 /* Remove return first item buffer sp */ 32 int sbuf_remove(sbuf_t *sp) 33 { 34 int item; 35 P(&sp->items); /* Wait available item */ 36 P(&sp->mutex); /* Lock buffer */ 37 item = sp->buf[(++sp->front)%(sp->n)]; /* Remove item */ 38 V(&sp->mutex); /* Unlock buffer */ 39 V(&sp->slots); /* Announce available slot */ 40 return item; 41 } code/conc/sbuf.c Figure 12.25 Sbuf : package synchronizing concurrent access bounded buffers.Section 12.5 Synchronizing Threads Semaphores 969 Readers-Writers Problem readers-writers problem generalization mutual exclusion problem. collection concurrent threads accessing shared object data struc-ture main memory database disk. threads read object,while others modify it. Threads modify object called writers . Threads read called readers . Writers must exclusive access ob- ject, readers may share object unlimited number readers.In general, unbounded number concurrent readers writers. Readers-writers interactions occur frequently real systems. example, online airline reservation system, unlimited number customers al-lowed concurrently inspect seat assignments, customer bookinga seat must exclusive access database. another example, mul-tithreaded caching Web proxy, unlimited number threads fetch existing pages shared page cache, thread writes new page thecache must exclusive access. readers-writers problem several variations, based priori- ties readers writers. ﬁrst readers-writers problem , favors readers, requires reader kept waiting unless writer already granted permission use object. words, reader wait simply becausea writer waiting. second readers-writers problem , favors writers, re- quires writer ready write, performs write soon possible.Unlike ﬁrst problem, reader arrives writer must wait, even thewriter also waiting. Figure 12.26 shows solution ﬁrst readers-writers problem. Like solutions many synchronization problems, subtle deceptively simple.Thewsemaphore controls access critical sections access shared object. mutex semaphore protects access shared readcnt variable, counts number readers currently critical section. writer locks wmutex time enters critical section, unlocks time leaves. guarantees one writer critical section anypoint time. hand, ﬁrst reader enter critical sectionlocks w, last reader leave critical section unlocks it. wmutex ignored readers enter leave readers present. Thismeans long single reader holds wmutex, unbounded number readers enter critical section unimpeded. correct solution either readers-writers problems result starvation , thread blocks indeﬁnitely fails make progress. example, solution Figure 12.26, writer could wait indeﬁnitely whilea stream readers arrived. Practice Problem 12.10 solution ﬁrst readers-writers problem Figure 12.26 gives priority toreaders, priority weak sense writer leaving critical sectionmight restart waiting writer instead waiting reader. Describe scenariowhere weak priority would allow collection writers starve reader.970 Chapter 12 Concurrent Programming /* Global variables */ int readcnt; /* Initiall y=0* / sem_t mutex, w; /* initiall y=1* / void reader(void) { (1) { P(&mutex); readcnt++; (readcnt == 1) /* First */ P(&w); V(&mutex); /* Critical section */ /* Reading happens */ P(&mutex); readcnt--; (readcnt == 0) /* Last */ V(&w); V(&mutex); } }void writer(void) { (1) { P(&w); /* Critical section */ /* Writing happens */ V(&w); } } Figure 12.26 Solution ﬁrst readers-writers problem. Favors readers writers. Aside synchronization mechanisms shown synchronize threads using semaphores, mainly simple, clas- sical, clean semantic model. know synchronization techniques existas well. example, Java threads synchronized mechanism called Java monitor [51], provides higher level abstraction mutual exclusion scheduling capabilities semaphores; fact monitors implemented semaphores. another example, Pthreads interface de- ﬁnes set synchronization operations mutex condition variables. Pthreads mutexes used mutual exclusion. Condition variables used scheduling accesses shared resources, bounded buffer producer-consumer program. 12.5.5 Putting Together: Concurrent Server Based Prethreading seen semaphores used access shared variables schedule accesses shared resources. help understand ideas moreclearly, let us apply concurrent server based technique calledprethreading .Section 12.5 Synchronizing Threads Semaphores 971 Client ClientMaster threadWorker threadPool worker threads Worker threadBufferRemove descriptorsAccept connectionsInsert descriptorsService client Service client . . .. . . Figure 12.27 Organization prethreaded concurrent server. set existing threads repeatedly remove process connected descriptors bounded buffer. concurrent server Figure 12.14, created new thread new client. disadvantage approach incur nontrivial costof creating new thread new client. server based prethreadingtries reduce overhead using producer-consumer model shown inFigure 12.27. server consists main thread set worker threads.The main thread repeatedly accepts connection requests clients placesthe resulting connected descriptors bounded buffer. worker threadrepeatedly removes descriptor buffer, services client, waitsfor next descriptor. Figure 12.28 shows would use Sbuf package implement prethreaded concurrent echo server. initializing buffer sbuf (line 23), main thread creates set worker threads (lines 26–27). enters theinﬁnite server loop, accepting connection requests inserting resultingconnected descriptors sbuf . worker thread simple behavior. waits able remove connected descriptor buffer (line 39),and calls echo_cnt function echo client input. Theecho_cnt function Figure 12.29 version echo function Figure 11.21 records cumulative number bytes received fromall clients global variable called byte_cnt . interesting code study shows general technique initializing packages calledfrom thread routines. case, need initialize byte_cnt counter mutex semaphore. One approach, used Sbuf Rio packages, require main thread explicitly call initialization function. Another approach, shown here, uses pthread_once function (line 19) call initialization function ﬁrst time thread calls echo_cnt function. advantage approach makes package easier use. Thedisadvantage every call echo_cnt makes call pthread_once , times nothing useful. package initialized, echo_cnt function initializes Rio buffered I/O package (line 20) echoes text line received fromthe client. Notice accesses shared byte_cnt variable lines 23–25 protected PandVoperations.code/conc/echoservert_pre.c 1#include "csapp.h" 2#include "sbuf.h" 3#define NTHREADS 4 4#define SBUFSIZE 16 5 6void echo_cnt(int connfd); 7void *thread(void *vargp); 89 sbuf_t sbuf; /* Shared buffer connected descriptors */ 10 11 int main(int argc, char **argv) 12 { 13 int i, listenfd, connfd, port; 14 socklen_t clientlen=sizeof(struct sockaddr_in); 15 struct sockaddr_in clientaddr; 16 pthread_t tid; 1718 (argc != 2) { 19 fprintf(stderr, "usage: %s <port>\n", argv[0]); 20 exit(0); 21 } 22 port = atoi(argv[1]); 23 sbuf_init(&sbuf, SBUFSIZE); 24 listenfd = Open_listenfd(port); 2526 (i = 0; < NTHREADS; i++) /* Create worker threads */ 27 Pthread_create(&tid, NULL, thread, NULL); 28 29 (1) { 30 connfd = Accept(listenfd, (SA *) &clientaddr, &clientlen); 31 sbuf_insert(&sbuf, connfd); /* Insert connfd buffer */ 32 } 33 } 34 35 void *thread(void *vargp) 36 { 37 Pthread_detach(pthread_self()); 38 (1) { 39 int connfd = sbuf_remove(&sbuf); /* Remove connfd buffer */ 40 echo_cnt(connfd); /* Service client */ 41 Close(connfd); 42 } 43 } code/conc/echoservert_pre.c Figure 12.28 prethreaded concurrent echo server. server uses producer- consumer model one producer multiple consumers.Section 12.5 Synchronizing Threads Semaphores 973 code/conc/echo_cnt.c 1#include "csapp.h" 2 3static int byte_cnt; /* Byte counter */ 4static sem_t mutex; /* mutex protects */ 5 6static void init_echo_cnt(void) 7{ 8 Sem_init(&mutex, 0, 1); 9 byte_cnt = 0; 10 } 11 12 void echo_cnt(int connfd) 13 { 14 int n; 15 char buf[MAXLINE]; 16 rio_t rio; 17 static pthread_once_t = PTHREAD_ONCE_INIT; 18 19 Pthread_once(&once, init_echo_cnt); 20 Rio_readinitb(&rio, connfd); 21 while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) { 22 P(&mutex); 23 byte_cnt += n; 24 printf("thread %d received %d (%d total) bytes fd %d\n", 25 (int) pthread_self(), n, byte_cnt, connfd); 26 V(&mutex); 27 Rio_writen(connfd, buf, n); 28 } 29 } code/conc/echo_cnt.c Figure 12.29 echo_cnt : version echo counts bytes received clients. Aside Event-driven programs based threads I/O multiplexing way write event-driven program. example, might noticed concurrent prethreaded server developed really event-driven server simple state machines main worker threads. main thread two states (“waiting connection request” “waiting available buffer slot”), two I/O events (“connection request arrives” “buffer slot becomes available”), two transitions (“accept connection request” “insert buffer item”). Similarly, worker thread one state (“waiting available buffer item”), one I/O event (“buffer item becomes available”), one transition (“remove buffer item”).974 Chapter 12 Concurrent Programming 12.6 Using Threads Parallelism Thus far study concurrency, assumed concurrent threads execut- ing uniprocessor systems. However, many modern machines multi-coreprocessors. Concurrent programs often run faster machines theoperating system kernel schedules concurrent threads parallel multi-ple cores, rather sequentially single core. Exploiting parallelismis critically important applications busy Web servers, database servers,and large scientiﬁc codes, becoming increasingly useful mainstreamapplications Web browsers, spreadsheets, document processors. Figure 12.30 shows set relationships sequential, concurrent, parallel programs. set programs partitioned disjointsets sequential concurrent programs. sequential program written asingle logical ﬂow. concurrent program written multiple concurrent ﬂows.A parallel program concurrent program running multiple processors. Thus,the set parallel programs proper subset set concurrent programs. detailed treatment parallel programs beyond scope, studying simple example program help understand important aspects ofparallel programming. example, consider might sum sequence ofintegers 0 ,...,n −1 parallel. course, closed-form solution particular problem, nonetheless concise easy-to-understand exem-plar allow us make interesting points parallel programs. straightforward approach partition sequence tdisjoint regions, assign tdifferent threads work region. simplicity, assume nis multiple t, region n/telements. main thread creates tpeer threads, peer thread kruns parallel processor core computes k, sum elements region k. peer threads completed, main thread computes ﬁnal result summing sk. Figure 12.31 shows might implement simple parallel sum algo- rithm. lines 27–32, main thread creates peer threads waits forthem terminate. Notice main thread passes small integer peerthread serves unique thread ID. peer thread use thread ID todetermine portion sequence work on. idea passinga small unique thread ID peer threads general technique used inmany parallel applications. peer threads terminated, psum vec- tor contains partial sums computed peer thread. main thread Figure 12.30 Relationships sets sequential,concurrent, parallelprograms.All programs Concurrent programs Sequential programsParallel programscode/conc/psum.c 1#include "csapp.h" 2#define MAXTHREADS 32 3 4void *sum(void *vargp); 56 /* Global shared variables */ 7long psum[MAXTHREADS]; /* Partial sum computed thread */ 8long nelems_per_thread; /* Number elements summed thread */ 9 10 int main(int argc, char **argv) 11 { 12 long i, nelems, log_nelems, nthreads, result = 0; 13 pthread_t tid[MAXTHREADS]; 14 int myid[MAXTHREADS]; 1516 /* Get input arguments */ 17 (argc != 3) { 18 printf("Usage: %s <nthreads> <log_nelems>\n", argv[0]); 19 exit(0); 20 } 21 nthreads = atoi(argv[1]); 22 log_nelems = atoi(argv[2]); 23 nelems = (1L << log_nelems); 24 nelems_per_thread = nelems / nthreads; 2526 /* Create peer threads wait finish */ 27 (i = 0; < nthreads; i++) { 28 myid[i] = i; 29 Pthread_create(&tid[i], NULL, sum, &myid[i]); 30 } 31 (i = 0; < nthreads; i++) 32 Pthread_join(tid[i], NULL); 33 34 /* Add partial sums computed thread */ 35 (i = 0; < nthreads; i++) 36 result += psum[i]; 37 38 /* Check final answer */ 39 (result != (nelems * (nelems-1))/2) 40 printf("Error: result=%ld\n", result); 4142 exit(0); 43 } code/conc/psum.c Figure 12.31 Simple parallel program uses multiple threads sum elements sequence.976 Chapter 12 Concurrent Programming code/conc/psum.c 1void *sum(void *vargp) 2{ 3 int myid = *((int *)vargp); /* Extract thread ID */ 4 long start = myid * nelems_per_thread; /* Start element index */ 5 long end = start + nelems_per_thread; /* End element index */ 6 long i, sum = 0; 7 8 (i = start ; < end; i++) { 9 sum += i; 10 } 11 psum[myid] = sum; 12 13 return NULL; 14 } code/conc/psum.c Figure 12.32 Thread routine program Figure 12.31. sums elements psum vector (lines 35–36), uses closed-form solution verify result (lines 39–40). Figure 12.32 shows function peer thread executes. line 3, thread extracts thread ID thread argument, uses ID determine region sequence work (lines 4–5). lines 8–10, thread operates portion sequence, updatesits entry partial sum vector (line 11). Notice careful give eachpeer thread unique memory location update, thus necessary tosynchronize access psum array semaphore mutexes. necessary synchronization particular case main thread must wait eachof children ﬁnish knows entry psum valid. Figure 12.33 shows total elapsed running time program Fig- ure 12.31 function number threads. case, program runs system four processor cores sums sequence n=2 31elements. see running time decreases increase number threads, tofour threads, point levels even starts increase little. theideal case, would expect running time decrease linearly num-ber cores. is, would expect running time drop half time double number threads. indeed case reach point(t>4) four cores busy running least one thread. Running time actually increases bit increase number threads theoverhead context switching multiple threads core. reason,parallel programs often written core runs exactly one thread. Although absolute running time ultimate measure program’s performance, useful relative measures, known speedup andefﬁciency, provide insight well parallel program exploitingSection 12.6 Using Threads Parallelism 977 Figure 12.33 Performance theprogram Figure 12.31on multi-core machinewith four cores. Summing sequence 2 31elements.1.8 1.61.41.21.00.80.60.40.2 0 11.56 ThreadsElapsed time (s) 20.81 40.4 0.4 81 60.45 potential parallelism. speedup parallel program typically deﬁned Sp=T1 Tp pis number processor cores Tkis running time kcores. formulation sometimes referred strong scaling . T1is execution time sequential version program, Spis called absolute speedup . T1is execution time parallel version program running one core, Spis called relative speedup . Absolute speedup truer mea- sure beneﬁts parallelism relative speedup. Parallel programs oftensuffer synchronization overheads, even run one processor, overheads artiﬁcially inﬂate relative speedup numbers increase size numerator. hand, absolute speedup moredifﬁcult measure relative speedup measuring absolute speeduprequires two different versions program. complex parallel codes, creat-ing separate sequential version might feasible, either code istoo complex source code available. related measure, known efﬁciency , deﬁned E p=Sp p=T1 pTp typically reported percentage range (0, 100]. Efﬁciency mea- sure overhead due parallelization. Programs high efﬁciency spending time useful work less time synchronizing commu- nicating programs low efﬁciency.978 Chapter 12 Concurrent Programming Threads ( t) 1 248 1 6 Cores ( p) 1 2444 Running time ( Tp) 1.56 0.81 0.40 0.40 0.45 Speedup ( Sp) 1 1.9 3.9 3.9 3.5 Efﬁciency ( Ep) 100% 95% 98% 98% 88% Figure 12.34 Speedup parallel efﬁciency execution times Figure 12.33. Figure 12.34 shows different speedup efﬁciency measures example parallel sum program. Efﬁciencies 90% good,but fooled. able achieve high efﬁciency problemwas trivially easy parallelize. practice, usually case. Parallelprogramming active area research decades. adventof commodity multi-core machines whose core count doubling every years,parallel programming continues deep, difﬁcult, active area research. another view speedup, known weak scaling , increases problem size along number processors, amount ofwork performed processor held constant number processorsincreases. formulation, speedup efﬁciency expressed termsof total amount work accomplished per unit time. example, candouble number processors twice amount work per hour, thenwe enjoying linear speedup 100% efﬁciency. Weak scaling often truer measure strong scaling accurately reﬂects desire use bigger machines work. par-ticularly true scientiﬁc codes, problem size easily increased,and bigger problem sizes translate directly better predictions nature.However, exist applications whose sizes easily increased, forthese applications strong scaling appropriate. example, amount ofwork performed real-time signal processing applications often determined bythe properties physical sensors generating signals. Changing thetotal amount work requires using different physical sensors, might befeasible necessary. applications, typically want use parallelismto accomplish ﬁxed amount work quickly possible. Practice Problem 12.11 Fill blanks parallel program following table. Assume strongscaling. Threads ( t)1 2 4 Cores ( p)1 2 4 Running time ( Tp)1 2 8 6 Speedup ( Sp) 1.5 Efﬁciency ( Ep) 100% 50%Section 12.7 Concurrency Issues 979 12.7 Concurrency Issues probably noticed life got much complicated asked synchronize accesses shared data. far, looked techniques formutual exclusion producer-consumer synchronization, tipof iceberg. Synchronization fundamentally difﬁcult problem raisesissues simply arise ordinary sequential programs. section asurvey (by means complete) issues need aware ofwhen write concurrent programs. keep things concrete, couch ourdiscussion terms threads. Keep mind, however, typical theissues arise concurrent ﬂows kind manipulate shared resources. 12.7.1 Thread Safety program threads, must careful write functions property called thread safety. function said thread-safe always produce correct results called repeatedly multiple concurrentthreads. function thread-safe, say thread-unsafe . identify four (nondisjoint) classes thread-unsafe functions: .Class 1: Functions protect shared variables. already en- countered problem thread function Figure 12.16, in- crements unprotected global counter variable. class thread-unsafe function relatively easy make thread-safe: protect shared variableswith synchronization operations PandV. advantage require changes calling program. disadvantage thesynchronization operations slow function. .Class 2: Functions keep state across multiple invocations. pseudo- random number generator simple example class thread-unsafefunction. Consider pseudo-random number generator package Fig-ure 12.35. rand function thread-unsafe result current invocation depends intermediate result previous iteration.When call rand repeatedly single thread seeding call tosrand , expect repeatable sequence numbers. However, assumption longer holds multiple threads calling rand . way make function rand thread-safe rewrite use static data, relying instead caller pass state information arguments. disadvantage programmeris forced change code calling routine well. largeprogram potentially hundreds different call sites, makingsuch modiﬁcations could nontrivial prone error. .Class 3: Functions return pointer static variable. functions, asctime andgethostbyname , compute result static variable return pointer variable. call functions concurrentthreads, disaster likely, results used one thread silentlyoverwritten another thread.980 Chapter 12 Concurrent Programming code/conc/rand.c 1unsigned int next = 1; 2 3/* rand - return pseudo-random integer 0..32767 */ 4int rand(void) 5{ 6 next = next*1103515245 + 12345; 7 return (unsigned int)(next/65536) % 32768; 8} 9 10 /* srand - set seed rand() */ 11 void srand(unsigned int seed) 12 { 13 next = seed; 14 } code/conc/rand.c Figure 12.35 thread-unsafe pseudo-random number generator [58]. two ways deal class thread-unsafe functions. One option rewrite function caller passes address variable store results. eliminates shared data, itrequires programmer access function source code. thread-unsafe function difﬁcult impossible modify (e.g., code complex source code available), another optionis use lock-and-copy technique. basic idea associate mutex thread-unsafe function. call site, lock mutex, call thethread-unsafe function, copy result returned function privatememory location, unlock mutex. minimize changes thecaller, deﬁne thread-safe wrapper function performs lock-and-copy, replace calls thread-unsafe function calls wrapper. example, Figure 12.36 shows thread-safe wrapperforctime uses lock-and-copy technique. .Class 4: Functions call thread-unsafe functions. function fcalls thread-unsafe function g,i sfthread-unsafe? depends. gis class 2 function relies state across multiple invocations, fis also thread- unsafe recourse short rewriting g. However, gis class 1 class 3 function, fcan still thread-safe protect call site resulting shared data mutex. see good example inFigure 12.36, use lock-and-copy write thread-safe function thatcalls thread-unsafe function. 12.7.2 Reentrancy important class thread-safe functions, known reentrant functions , characterized property reference anyshared dataSection 12.7 Concurrency Issues 981 code/conc/ctime_ts.c 1char *ctime_ts(const time_t *timep, char *privatep) 2{ 3 char *sharedp; 4 5 P(&mutex); 6 sharedp = ctime(timep); 7 strcpy(privatep, sharedp); /* Copy string shared private */ 8 V(&mutex); 9 return privatep; 10 } code/conc/ctime_ts.c Figure 12.36 Thread-safe wrapper function C standard library ctime function. Uses lock-and-copy technique call class 3 thread-unsafe function. Figure 12.37 Relationships betweenthe sets reentrant,thread-safe, non- thread-safe functions.All functions Thread-safe functions Thread-unsafe functions Reentrant functions called multiple threads. Although terms thread-safe reentrant sometimes used (incorrectly) synonyms, clear technical distinction worth preserving. Figure 12.37 shows set relationships be-tween reentrant, thread-safe, thread-unsafe functions. set functionsis partitioned disjoint sets thread-safe thread-unsafe functions. Theset reentrant functions proper subset thread-safe functions. Reentrant functions typically efﬁcient nonreentrant thread- safe functions require synchronization operations. Furthermore,the way convert class 2 thread-unsafe function thread-safe one isto rewrite reentrant. example, Figure 12.38 shows reentrantversion rand function Figure 12.35. key idea replaced static next variable pointer passed caller. possible inspect code function declare priori reentrant? Unfortunately, depends. function arguments passed value (i.e., pointers) data references local automatic stack variables (i.e.,no references static global variables), function explicitly reentrant , sense assert reentrancy regardless called. However, loosen assumptions bit allow parameters otherwise explicitly reentrant function passed reference (that is, weallow pass pointers) implicitly reentrant function, sense reentrant calling threads careful pass pointers982 Chapter 12 Concurrent Programming code/conc/rand_r.c 1/* rand_ r - reentrant pseudo-random integer 0..32767 */ 2int rand_r(unsigned int *nextp) 3{ 4 *nextp = *nextp * 1103515245 + 12345; 5 return (unsigned int)(*nextp / 65536) % 32768; 6} code/conc/rand_r.c Figure 12.38 rand_r : reentrant version rand function Figure 12.35. nonshared data. example, rand_r function Figure 12.38 implicitly reentrant. always use term reentrant include explicit implicit reen- trant functions. However, important realize reentrancy sometimes aproperty caller callee, callee alone. Practice Problem 12.12 Thectime_ts function Figure 12.36 thread-safe, reentrant. Explain. 12.7.3 Using Existing Library Functions Threaded Programs Unix functions, including functions deﬁned standard C library (such malloc ,free ,realloc ,printf , scanf ), thread-safe, exceptions. Figure 12.39 lists common exceptions. (See [109] com-plete list.) asctime ,ctime , andlocaltime functions popular functions converting back forth different time date formats. gethost- byname ,gethostbyaddr , inet_ntoa functions frequently used network programming functions encountered Chapter 11. strtok function deprecated function (one whose use discouraged) parsing strings. exceptions rand andstrtok , thread-unsafe functions class 3 variety return pointer static variable. need callone functions threaded program, least disruptive approach thecaller lock-and-copy. However, lock-and-copy approach numberof disadvantages. First, additional synchronization slows program.Second, functions gethostbyname return pointers complex struc- tures structures require deep copy structures order copy entire structure hierarchy. Third, lock-and-copy approach work class 2 thread-unsafe function rand relies static state across calls. Therefore, Unix systems provide reentrant versions thread-unsafe functions. names reentrant versions always end “ _r” sufﬁx. example, reentrant version gethostbyname called gethostbyname_r . recommend using functions whenever possible.Section 12.7 Concurrency Issues 983 Thread-unsafe function Thread-unsafe class Unix thread-safe version rand 2 rand_r strtok 2 strtok_r asctime 3 asctime_r ctime 3 ctime_r gethostbyaddr 3 gethostbyaddr_r gethostbyname 3 gethostbyname_r inet_ntoa 3 (none) localtime 3 localtime_r Figure 12.39 Common thread-unsafe library functions. 12.7.4 Races Arace occurs correctness program depends one thread reaching point xin control ﬂow another thread reaches point y. Races usually occur programmers assume threads take particular trajec-tory execution state space, forgetting golden rule threadedprograms must work correctly feasible trajectory. example easiest way understand nature races. Consider simple program Figure 12.40. main thread creates four peer threads andpasses pointer unique integer ID one. peer thread copies theID passed argument local variable (line 21), prints messagecontaining ID. looks simple enough, run program oursystem, get following incorrect result: unix> ./race Hello thread 1Hello thread 3Hello thread 2 Hello thread 3 problem caused race peer thread main thread. spot race? happens. main thread cre-ates peer thread line 12, passes pointer local stack variable i. point, race next call pthread_create line 12 dereferencing assignment argument line 21. peer thread exe-cutes line 21 main thread executes line 12, myid variable gets correct ID. Otherwise, contain ID thread. scarything whether get correct answer depends kernel sched-ules execution threads. system fails, systems itmight work correctly, leaving programmer blissfully unaware serious bug. eliminate race, dynamically allocate separate block integer ID, pass thread routine pointer block, shown in984 Chapter 12 Concurrent Programming code/conc/race.c 1#include "csapp.h" 2#define N 4 3 4void *thread(void *vargp); 56 int main() 7{ 8 pthread_t tid[N]; 9 int i; 1011 f r( i=0 ;i<N ; i++) 12 Pthread_create(&tid[i], NULL, thread, &i); 13 f r( i=0 ;i<N ; i++) 14 Pthread_join(tid[i], NULL); 15 exit(0); 16 } 17 18 /* Thread routine */ 19 void *thread(void *vargp) 20 { 21 int myid = *((int *)vargp); 22 printf("Hello thread %d\n", myid); 23 return NULL; 24 } code/conc/race.c Figure 12.40 program race. Figure 12.41 (lines 12–14). Notice thread routine must free block order avoid memory leak. run program system, get correct result: unix> ./norace Hello thread 0Hello thread 1 Hello thread 2 Hello thread 3 Practice Problem 12.13 Figure 12.41, might tempted free allocated memory block immedi- ately line 15 main thread, instead freeing peer thread. Butthis would bad idea. Why?Section 12.7 Concurrency Issues 985 code/conc/norace.c 1#include "csapp.h" 2#define N 4 3 4void *thread(void *vargp); 56 int main() 7{ 8 pthread_t tid[N]; 9 int i, *ptr; 1011 f r( i=0 ;i<N ; i++) { 12 ptr = Malloc(sizeof(int)); 13 *ptr = i; 14 Pthread_create(&tid[i], NULL, thread, ptr); 15 } 16 f r( i=0 ;i<N ; i++) 17 Pthread_join(tid[i], NULL); 18 exit(0); 19 } 20 21 /* Thread routine */ 22 void *thread(void *vargp) 23 { 24 int myid = *((int *)vargp); 25 Free(vargp); 26 printf("Hello thread %d\n", myid); 27 return NULL; 28 } code/conc/norace.c Figure 12.41 correct version program Figure 12.40 without race. Practice Problem 12.14 A. Figure 12.41, eliminated race allocating separate block integer ID. Outline different approach call malloc orfree functions. B. advantages disadvantages approach? 12.7.5 Deadlocks Semaphores introduce potential nasty kind run-time error, called deadlock , collection threads blocked, waiting condition that986 Chapter 12 Concurrent Programming. . . . . . . . . . . .. . . . . . . . . . . . . . .Thread 2 Thread 1A trajectory deadlocksA trajectory deadlock P(s) P(t) P(s) P(t) V(s) V(t)V(t)V(s) Initially s/H110051 t/H110051Forbidden region fors Forbidden region fortDeadlock state Deadlock region Figure 12.42 Progress graph program deadlock. never true. progress graph invaluable tool understanding deadlock. example, Figure 12.42 shows progress graph pair threadsthat use two semaphores mutual exclusion. graph, glean someimportant insights deadlock: .The programmer incorrectly ordered PandVoperations forbidden regions two semaphores overlap. executiontrajectory happens reach deadlock state d, progress possible overlapping forbidden regions block progress everylegal direction. words, program deadlocked eachthread waiting Voperation never occur. .The overlapping forbidden regions induce set states called deadlock region . trajectory happens touch state deadlock region, deadlock inevitable. Trajectories enter deadlock regions, cannever leave. .Deadlock especially difﬁcult issue always predictable.Some lucky execution trajectories skirt deadlock region, otherswill trapped it. Figure 12.42 shows example each. implications programmer scary. might run program 1000 timesSection 12.7 Concurrency Issues 987 . . . . . . . . . . . . . . . . . . . . . . . .Thread 2 Thread 1P(t) P(s) P(s) P(t) V(s) V(t)V(t)V(s) Initially s/H110051 t/H110051Forbidden region fors Forbidden region Figure 12.43 Progress graph deadlock-free program. without problem, next time deadlocks. program might work ﬁne one machine deadlock another. Worst all,the error often repeatable different executions differenttrajectories. Programs deadlock many reasons avoiding difﬁcult problem general. However, binary semaphores used mutual exclusion, asin Figure 12.42, apply following simple effective rule avoiddeadlocks: Mutex lock ordering rule: program deadlock-free if, pair mutexes (s,t) program, thread holds sandtsimultaneously locks order. example, ﬁx deadlock Figure 12.42 locking sﬁrst, tin thread. Figure 12.43 shows resulting progress graph. Practice Problem 12.15 Consider following program, attempts use pair semaphores formutual exclusion.988 Chapter 12 Concurrent Programming Initially :s=1 ,t=0 . Thread 1: Thread 2: P(s); P(s); V(s); V(s);P(t); P(t); V(t); V(t); A. Draw progress graph program. B. always deadlock?C. so, simple change initial semaphore values eliminate potential deadlock? D. Draw progress graph resulting deadlock-free program. 12.8 Summary concurrent program consists collection logical ﬂows overlap time. chapter, studied three different mechanisms building concur-rent programs: processes, I/O multiplexing, threads. used concurrentnetwork server motivating application throughout. Processes scheduled automatically kernel, separate virtual address spaces, require explicit IPC mechanisms orderto share data. Event-driven programs create concurrent logical ﬂows,which modeled state machines, use I/O multiplexing explicitly sched-ule ﬂows. program runs single process, sharing data betweenﬂows fast easy. Threads hybrid approaches. Like ﬂows basedon processes, threads scheduled automatically kernel. Like ﬂows basedon I/O multiplexing, threads run context single process, thus canshare data quickly easily. Regardless concurrency mechanism, synchronizing concurrent accesses shared data difﬁcult problem. PandVoperations semaphores developed help deal problem. Semaphore operations usedto provide mutually exclusive access shared data, well schedule access toresources bounded buffers producer-consumer systems shared objects readers-writers systems. concurrent prethreaded echo server providesa compelling example usage scenarios semaphores. Concurrency introduces difﬁcult issues well. Functions called threads must property known thread safety. identiﬁedfour classes thread-unsafe functions, along suggestions making themthread-safe. Reentrant functions proper subset thread-safe functionsthat access shared data. Reentrant functions often efﬁcientthan nonreentrant functions require synchronization primitives. difﬁcult issues arise concurrent programs races deadlocks. Races occur programmers make incorrect assumptions aboutHomework Problems 989 logical ﬂows scheduled. Deadlocks occur ﬂow waiting event never happen. Bibliographic Notes Semaphore operations introduced Dijkstra [37]. progress graphconcept introduced Coffman [24] later formalized Carson andReynolds [17]. readers-writers problem introduced Courtois et al. [31].Operating systems texts describe classical synchronization problems thedining philosophers, sleeping barber, cigarette smokers problems de-tail [98, 104, 112]. book Butenhof [16] comprehensive description ofthe Posix threads interface. paper Birrell [7] excellent introduction tothreads programming pitfalls. book Reinders [86] describes C/C++library simpliﬁes design implementation threaded programs. Sev-eral texts cover fundamentals parallel programming multi-core sys-tems [50, 67]. Pugh identiﬁes weaknesses way Java threads interactthrough memory proposes replacement memory models [84]. Gustafson pro-posed weak scaling speedup model [46] alternative strong scaling. Homework Problems 12.16 ◆ Write version hello.c (Figure 12.13) creates reaps njoinable peer threads, nis command line argument. 12.17 ◆ A. program Figure 12.44 bug. thread supposed sleep 1 second print string. However, run system,nothing prints. Why? B. ﬁx bug replacing exit function line 9 one two different Pthreads function calls. ones? 12.18 ◆ Using progress graph Figure 12.21, classify following trajectories aseither safe orunsafe . A.H 2,L2,U2,H1,L1,S2,U1,S1,T1,T2 B.H2,H1,L1,U1,S1,L2,T1,U2,S2,T2 C.H1,L1,H2,L2,U2,S2,U1,S1,T1,T2 12.19 ◆◆ solution ﬁrst readers-writers problem Figure 12.26 gives somewhatweak priority readers writer leaving critical section might restarta waiting writer instead waiting reader. Derive solution gives strongerpriority readers, writer leaving critical section always restart waiting reader one exists.990 Chapter 12 Concurrent Programming code/conc/hellobug.c 1#include "csapp.h" 2void *thread(void *vargp); 3 4int main() 5{ 6 pthread_t tid; 78 Pthread_create(&tid, NULL, thread, NULL); 9 exit(0); 10 } 11 12 /* Thread routine */ 13 void *thread(void *vargp) 14 { 15 Sleep(1); 16 printf("Hello, world!\n"); 17 return NULL; 18 } code/conc/hellobug.c Figure 12.44 Buggy program Problem 12.17. 12.20 ◆◆◆ Consider simpler variant readers-writers problem mostNreaders. Derive solution gives equal priority readers writers, sense pending readers writers equal chance grantedaccess resource. Hint: solve problem using single countingsemaphore single mutex. 12.21 ◆◆◆◆ Derive solution second readers-writers problem, favors writersinstead readers. 12.22 ◆◆ Test understanding select function modifying server Fig- ure 12.6 echoes one text line per iteration main serverloop. 12.23 ◆◆ event-driven concurrent echo server Figure 12.8 ﬂawed mali- cious client deny service clients sending partial text line. Write improved version server handle partial text lines withoutblocking.Homework Problems 991 12.24 ◆ functions Rio I/O package (Section 10.4) thread-safe. reentrant well? 12.25 ◆ prethreaded concurrent echo server Figure 12.28, thread calls theecho_cnt function (Figure 12.29). echo_cnt thread-safe? reentrant? not? 12.26 ◆◆◆ Use lock-and-copy technique implement thread-safe nonreentrant versionofgethostbyname called gethostbyname_ts . correct solution use deep copy hostent structure protected mutex. 12.27 ◆◆ network programming texts suggest following approach reading andwriting sockets: interacting client, open two standard I/O streamson open connected socket descriptor, one reading one writing: FILE *fpin, *fpout; fpin = fdopen(sockfd, "r"); fpout = fdopen(sockfd, "w"); server ﬁnished interacting client, close streams follows: fclose(fpin); fclose(fpout); However, try approach concurrent server based threads, create deadly race condition. Explain. 12.28 ◆ Figure 12.43, swapping order two Voperations effect whether program deadlocks? Justify answer drawing theprogress graphs four possible cases: Case 1 Case 2 Case 3 Case 4 Thread 1 Thread 2 Thread 1 Thread 2 Thread 1 Thread 2 Thread 1 Thread 2 P(s) P(s) P(s) P(s) P(s) P(s) P(s) P(s) P(t) P(t) P(t) P(t) P(t) P(t) P(t) P(t)V(s) V(s) V(s) V(t) V(t) V(s) V(t) V(t)V(t) V(t) V(t) V(s) V(s) V(t) V(s) V(s)992 Chapter 12 Concurrent Programming 12.29 ◆ following program deadlock? not? Initially :a=1 ,b=1 ,c=1 . Thread 1: Thread 2: P(a); P(c); P(b); P(b); V(b); V(b); P(c); V(c); V(c);V(a); 12.30 ◆ Consider following program deadlocks. Initially :a=1 ,b=1 ,c=1 . Thread 1: Thread 2: Thread 3: P(a); P(c); P(c); P(b); P(b); V(c);V(b); V(b); P(b);P(c); V(c); P(a); V(c); P(a); V(a); V(a); V(a); V(b); A. thread, list pairs mutexes holds simultaneously. B. a<b<c , threads violate mutex lock ordering rule? C. threads, show new lock ordering guarantees freedom deadlock. 12.31 ◆◆◆ Implement version standard I/O fgets function, called tfgets , times returns NULL receive input line standard input within 5 seconds. function implemented package called tfgets- proc.c using process, signals, nonlocal jumps. use Unix alarm function. Test solution using driver program Figure 12.45. 12.32 ◆◆◆ Implement version tfgets function Problem 12.31 uses select function. function implemented package called tfgets-select.c . Test solution using driver program Problem 12.31. may assume standard input assigned descriptor 0. 12.33 ◆◆◆ Implement threaded version tfgets function Problem 12.31. YourHomework Problems 993 code/conc/tfgets-main.c 1#include "csapp.h" 2 3char *tfgets(char *s, int size, FILE *stream); 4 5int main() 6{ 7 char buf[MAXLINE]; 8 9 (tfgets(buf, MAXLINE, stdin) == NULL) 10 printf("BOOM!\n"); 11 else 12 printf("%s", buf); 1314 exit(0); 15 } code/conc/tfgets-main.c Figure 12.45 Driver program Problems 12.31–12.33. function implemented package called tfgets-thread.c . Test solution using driver program Problem 12.31. 12.34 ◆◆◆ Write parallel threaded version N×Mmatrix multiplication kernel. Com- pare performance sequential case. 12.35 ◆◆◆ Implement concurrent version Tiny Web server based processes. solution create new child process new connection request. Testyour solution using real Web browser. 12.36 ◆◆◆ Implement concurrent version Tiny Web server based I/O multiplexing. Test solution using real Web browser. 12.37 ◆◆◆ Implement concurrent version Tiny Web server based threads. solution create new thread new connection request. Test yoursolution using real Web browser. 12.38 ◆◆◆◆ Implement concurrent prethreaded version Tiny Web server. solu- tion dynamically increase decrease number threads response current load. One strategy double number threads buffer994 Chapter 12 Concurrent Programming becomes full, halve number threads buffer becomes empty. Test solution using real Web browser. 12.39 ◆◆◆◆ Web proxy program acts middleman Web server andbrowser. Instead contacting server directly get Web page, browsercontacts proxy, forwards request server. serverreplies proxy, proxy sends reply browser. lab, youwill write simple Web proxy ﬁlters logs requests: A. ﬁrst part lab, set proxy accept requests, parse HTTP , forward requests server, return results back tothe browser. proxy log URLs requests log ﬁle ondisk, also block requests URL contained ﬁlter ﬁleon disk. B. second part lab, upgrade proxy deal multiple open connections spawning separate thread deal witheach request. proxy waiting remote server respond toa request serve one browser, working pendingrequest another browser. Check proxy solution using real Web browser. Solutions Practice Problems Solution Problem 12.1 (page 939) parent forks child, gets copy connected descriptor reference count associated ﬁle table incremented 1 2. parent closes copy descriptor, reference count decremented from2 1. Since kernel close ﬁle reference counter ﬁle table goes 0, child’s end connection stays open. Solution Problem 12.2 (page 939) process terminates reason, kernel closes open descriptors.Thus, child’s copy connected ﬁle descriptor closed automaticallywhen child exits. Solution Problem 12.3 (page 942) Recall descriptor ready reading request read 1 byte fromthat descriptor would block. EOF becomes true descriptor, thedescriptor ready reading read operation return immediatelywith zero return code indicating EOF. Thus, typing ctrl-d causes select function return descriptor 0 ready set. Solution Problem 12.4 (page 947) reinitialize pool.ready_set variable every call select serves input output argument. input, contains read set. output, contains ready set.Solutions Practice Problems 995 Solution Problem 12.5 (page 954) Since threads run process, share descriptor table. matter many threads use connected descriptor, reference count forthe connected descriptor’s ﬁle table equal 1. Thus, single close operation sufﬁcient free memory resources associated connected descriptor it. Solution Problem 12.6 (page 957) main idea stack variables private, global staticvariables shared. Static variables cnt little tricky sharing limited functions within scope—in case, threadroutine. A. table: Variable Referenced Referenced Referenced instance main thread? peer thread 0 ? peer thread 1? ptr yes yes yes cnt yes yes i.m yes msgs.m yes yes yes myid.p0 yes myid.p1 yes Notes: ptr: global variable written main thread read peer threads. cnt: static variable one instance memory read written two peer threads. i.m: local automatic variable stored stack main thread. Even though value passed peer threads, peer threadsnever reference stack, thus shared. msgs.m : local automatic variable stored main thread’s stack referenced indirectly ptrby peer threads. myid.0 andmyid.1 : Instances local automatic variable residing stacks peer threads 0 1, respectively. B. Variables ptr,cnt, msgs referenced one thread, thus shared. Solution Problem 12.7 (page 960) important idea cannot make assumptions theordering kernel chooses schedules threads.996 Chapter 12 Concurrent Programming Step Thread Instr %eax 1%eax 2 cnt 11 H1 —— 0 21 L1 0— 0 32 H2 —— 0 42 L2 —0 0 52 U2 —1 0 62 S2 —1 1 71 U1 1— 1 81 S1 1— 1 91 T1 1— 1 10 2 T2 1— 1 Variable cnthas ﬁnal incorrect value 1. Solution Problem 12.8 (page 962) problem simple test understanding safe unsafe trajectories progress graphs. Trajectories C skirt critical region aresafe produce correct results. A.H 1,L1,U1,S1,H2,L2,U2,S2,T2,T1: safe B.H2,L2,H1,L1,U1,S1,T1,U2,S2,T2: unsafe C.H1,H2,L2,U2,S2,L1,U1,S1,T1,T2: safe Solution Problem 12.9 (page 967) A.p=1,c=1,n>1: Yes, mutex semaphore necessary producer consumer concurrently access buffer. B.p=1,c=1,n=1: No, mutex semaphore necessary case, nonempty buffer equivalent full buffer. buffercontains item, producer blocked. buffer empty, theconsumer blocked. point time, single thread accessthe buffer, thus mutual exclusion guaranteed without using mutex. C.p> 1,c>1,n=1: No, mutex semaphore necessary case either, argument previous case. Solution Problem 12.10 (page 969) Suppose particular semaphore implementation uses LIFO stack threads semaphore. thread blocks semaphore Poperation, ID pushed onto stack. Similarly, Voperation pops top thread ID stack restarts thread. Given stack implementation, adversarialwriter critical section could simply wait another writer blocks thesemaphore releasing semaphore. scenario, waiting readermight wait forever two writers passed control back forth. Notice although might seem intuitive use FIFO queue rather LIFO stack, using stack incorrect violate semantics PandVoperations.Solutions Practice Problems 997 Solution Problem 12.11 (page 978) problem simple sanity check understanding speedup parallel efﬁciency: Threads ( t)1 2 4 Cores ( p)1 2 4 Running time ( Tp)1 2 8 6 Speedup ( Sp) 1 1.5 2 Efﬁciency ( Ep) 100% 75% 50% Solution Problem 12.12 (page 982) Thectime_ts function reentrant invocation shares static variable returned gethostbyname function. However, thread- safe accesses shared variable protected PandVopera- tions, thus mutually exclusive. Solution Problem 12.13 (page 984) free block immediately call pthread_create line 15, introduce new race, time call free main thread, assignment statement line 25 thread routine. Solution Problem 12.14 (page 985) A. Another approach pass integer idirectly, rather passing pointer i: f r( i=0 ;i<N ; i++) Pthread_create(&tid[i], NULL, thread, (void *)i); thread routine, cast argument back intand assign myid : int myid = (int) vargp; B. advantage reduces overhead eliminating calls malloc andfree . signiﬁcant disadvantage assumes pointers least large ints. assumption true modern systems, might true legacy future systems. Solution Problem 12.15 (page 987) A. progress graph original program shown Figure 12.46. B. program always deadlocks, since feasible trajectory eventually trapped deadlock state. C. eliminate deadlock potential, initialize binary semaphore tto 1 instead 0. D. progress graph corrected program shown Figure 12.47.. . . . . . . . . . . . . . .. . .. . . . . . . . . . . .Thread 2 Thread 1V(s) P(s) P(s) V(s) P(t) V(t)P(t)V(t) Initially s/H110051 t/H110050Forbidden region fort Forbidden region forsForbidden region Figure 12.46 Progress graph program deadlocks. . . . . . . . . . . . . . . . . . . . . . . . .Thread 2 Thread 1V(s) P(s) P(s) V(s) P(t) V(t)P(t)V(t) Initially s/H110051 t/H110051Forbidden region forsForbidden region fort Figure 12.47 Progress graph corrected deadlock-free program.APPENDIXA Error Handling Programmers always check error codes returned system-level func- tions. many subtle ways things go wrong, makes senseto use status information kernel able provide us. Unfortunately,programmers often reluctant error checking clutters theircode, turning single line code multi-line conditional statement. Errorchecking also confusing different functions indicate errors differentways. faced similar problem writing text. one hand, would like code examples concise simple read. otherhand, want give students wrong impression OK skiperror checking. resolve issues, adopted approach based onerror-handling wrappers pioneered W. Richard Stevens network programming text [109]. idea given base system-level function foo, deﬁne wrapper function Foowith identical arguments, ﬁrst letter capitalized. wrapper calls base function checks errors. detects error, wrapper prints informative message terminates process. Otherwise, itreturns caller. Notice errors, wrapper behaves exactlylike base function. Put another way, program runs correctly wrappers,it run correctly render ﬁrst letter wrapper lowercase andrecompile. wrappers packaged single source ﬁle ( csapp.c ) compiled linked program. separate header ﬁle ( csapp.h ) contains function prototypes wrappers. appendix gives tutorial different kinds error handling Unix systems, gives examples different styles error-handling wrappers.Copies csapp.h andcsapp.c ﬁles available CS:APP Web page. 9991000 Appendix Error Handling A.1 Error Handling Unix Systems systems-level function calls encounter book use three different styles returning errors: Unix-style ,Posix-style , DNS-style . Unix-Style Error Handling Functions fork andwait developed early days Unix (as well older Posix functions) overload function return value botherror codes useful results. example, Unix-style wait function encounters error (e.g., child process reap) returns −1 sets global variable errno error code indicates cause error. wait completes successfully, returns useful result, PID reaped child. Unix-style error-handling code typically following form: 1 ((pid = wait(NULL)) < 0) { 2 fprintf(stderr, "wait error: %s\n", strerror(errno)); 3 exit(0); 4 } Thestrerror function returns text description particular value errno . Posix-Style Error Handling Many newer Posix functions Pthreads use return value indicate success (0) failure (nonzero). useful results returned infunction arguments passed reference. refer approach asPosix-style error handling . example, Posix-style pthread_create function indicates success failure return value returns ID newly created thread (the useful result) reference ﬁrst argument. Posix-styleerror-handling code typically following form: 1 ((retcode = pthread_create(&tid, NULL, thread, NULL)) != 0) { 2 fprintf(stderr, "pthread_create error: %s\n", strerror(retcode)); 3 exit(0); 4 } DNS-Style Error Handling Thegethostbyname andgethostbyaddr functions retrieve DNS (Domain Name System) host entries yet another approach returning errors. functions return NULL pointer failure set global h_errno variable. DNS-style error handling typically following form: 1 ((p = gethostbyname(name)) == NULL) { 2 fprintf(stderr, "gethostbyname error: %s\n:", hstrerror(h_errno)); 3 exit(0); 4 }Section A.2 Error-Handling Wrappers 1001 Summary Error-Reporting Functions Thoughout book, use following error-reporting functions accommo- date different error-handling styles. #include "csapp.h" void unix_error(char *msg); void posix_error(int code, char *msg); void dns_error(char *msg); void app_error(char *msg); Returns: nothing names suggest, unix_error ,posix_error , dns_error func- tions report Unix-style, Posix-style, DNS-style errors terminate. Theapp_error function included convenience application errors. simply prints input terminates. Figure A.1 shows code error-reporting functions. A.2 Error-Handling Wrappers examples different error-handling wrappers: .Unix-style error-handling wrappers. Figure A.2 shows wrapper Unix-style wait function. wait returns error, wrapper prints informative message exits. Otherwise, returns PID thecaller. Figure A.3 shows wrapper Unix-style kill function. Notice function, unlike Wait , returns void success. .Posix-style error-handling wrappers. Figure A.4 shows wrapper Posix-style pthread_detach function. Like Posix-style functions, overload useful results error-return codes, wrapper returnsvoid success. .DNS-style error-handling wrappers. Figure A.5 shows error-handling wrapper DNS-style gethostbyname function.1002 Appendix Error Handling code/src/csapp.c 1void unix_error(char *msg) /* Unix-style error */ 2{ 3 fprintf(stderr, "%s: %s\n", msg, strerror(errno)); 4 exit(0); 5} 6 7void posix_error(int code, char *msg) /* Posix-style error */ 8{ 9 fprintf(stderr, "%s: %s\n", msg, strerror(code)); 10 exit(0); 11 } 12 13 void dns_error(char *msg) /* DNS-style error */ 14 { 15 fprintf(stderr, "%s: DNS error %d\n", msg, h_errno); 16 exit(0); 17 } 18 19 void app_error(char *msg) /* Application error */ 20 { 21 fprintf(stderr, "%s\n", msg); 22 exit(0); 23 } code/src/csapp.c Figure A.1 Error-reporting functions. code/src/csapp.c 1pid_t Wait(int *status) 2{ 3 pid_t pid; 4 5 ((pid = wait(status)) < 0) 6 unix_error("Wait error"); 7 return pid; 8} code/src/csapp.c Figure A.2 Wrapper Unix-style wait function.Section A.2 Error-Handling Wrappers 1003 code/src/csapp.c 1void Kill(pid_t pid, int signum) 2{ 3 int rc; 4 5 ((rc = kill(pid, signum)) < 0) 6 unix_error("Kill error"); 7} code/src/csapp.c Figure A.3 Wrapper Unix-style kill function. code/src/csapp.c 1void Pthread_detach(pthread_t tid) { 2 int rc; 3 4 ((rc = pthread_detach(tid)) != 0) 5 posix_error(rc, "Pthread_detach error"); 6} code/src/csapp.c Figure A.4 Wrapper Posix-style pthread_detach function. code/src/csapp.c 1struct hostent *Gethostbyname(const char *name) 2{ 3 struct hostent *p; 4 5 ((p = gethostbyname(name)) == NULL) 6 dns_error("Gethostbyname error"); 7 return p; 8} code/src/csapp.c Figure A.5 Wrapper DNS-style gethostbyname function.This page intentionally left blank References [1] Advanced Micro Devices, Inc. Software Opti- mization Guide AMD64 Processors , 2005. Publication Number 25112. [2] Advanced Micro Devices, Inc. AMD64 Arch- itecture Programmer’s Manual, Volume 1: Application Programming , 2007. Publication Number 24592. [3] Advanced Micro Devices, Inc. AMD64 Ar- chitecture Programmer’s Manual, Volume 3: General-Purpose System Instructions , 2007. Publication Number 24594. [4] K. Arnold, J. Gosling, D. Holmes. Java Programming Language, Fourth Edition . Prentice Hall, 2005. [5] V . Bala, E. Duesterwald, S. Banerjiia. Dynamo: transparent dynamic optimizationsystem. Proceedings 1995 ACM Conference Programming Language Design Implementation (PLDI) , pages 1–12, June 2000. [6] T. Berners-Lee, R. Fielding, H. Frystyk. Hypertext transfer protocol - HTTP/1.0. RFC 1945, 1996. [7] A. Birrell. introduction programming threads. Technical Report 35, DigitalSystems Research Center, 1989. [8] A. Birrell, M. Isard, C. Thacker, T. Wobber. design high-performance ﬂash disks.SIGOPS Operating Systems Review , 41(2), 2007. [9] R. Blum. Professional Assembly Language . Wiley, 2005. [10] S. Borkar. Thousand core chips—a technology perspective. Design Automation Conference , pages 746–749. ACM, 2007. [11] D. Bovet M. Cesati. Understanding Linux Kernel, Third Edition . O’Reilly Media, Inc, 2005. [12] A. Demke Brown T. Mowry. Taming memory hogs: Using compiler-inserted releasesto manage physical memory intelligently. Proceedings Fourth Symposium Operating Systems Design Implementation (OSDI) , pages 31–44, October 2000. [13] R. E. Bryant. Term-level veriﬁcation pipelined CISC microprocessor. Technical Report CMU-CS-05-195, Carnegie Mellon University, School Computer Science, 2005. [14] R. E. Bryant D. R. O’Hallaron. Introduc- ing computer systems programmer’sperspective. Proceedings Technical Symposium Computer Science Education (SIGCSE) . ACM, February 2001. [15] B. R. Buck J. K. Hollingsworth. API runtime code patching. Journal High Performance Computing Applications , 14(4):317–324, June 2000. [16] D. Butenhof. Programming Posix Threads . Addison-Wesley, 1997. [17] S. Carson P . Reynolds. geometry semaphore programs. ACM Transactions Programming Languages Systems , 9(1):25– 53, 1987. [18] J. B. Carter, W. C. Hsieh, L. B. Stoller, M. R. Swanson, L. Zhang, E. L. Brunvand, A. Davis, C.-C. Kuo, R. Kuramkote, M. A. Parker,L. Schaelicke, T. Tateyama. Impulse:Building smarter memory controller. Pro- ceedings Fifth International Symposium High Performance Computer Architecture(HPCA) , pages 70–79, January 1999. [19] S. Chellappa, F. Franchetti, M. P ¨uschel. write fast numerical code: small in- troduction. Generative Transformational Techniques Software Engineering II , volume 5235, pages 196–259. Springer-Verlag Lecture Notes Computer Science, 2008. [20] P . Chen, E. Lee, G. Gibson, R. Katz, D. Pat- terson. RAID: High-performance, reliablesecondary storage. ACM Computing Surveys , 26(2), June 1994. 10051006 References [21] S. Chen, P . Gibbons, T. Mowry. Improving index performance prefetching. InProceedings 2001 ACM SIGMODConference . ACM, May 2001. [22] T. Chilimbi, M. Hill, J. Larus. Cache- conscious structure layout. Proceedings 1999 ACM Conference ProgrammingLanguage Design Implementation (PLDI) , pages 1–12. ACM, May 1999. [23] B. Cmelik D. Keppel. Shade: fast instruction-set simulator execution pro-ﬁling. Proceedings 1994 ACM SIG- METRICS Conference Measurement Modeling Computer Systems , pages 128–137, May 1994. [24] E. Coffman, M. Elphick, A. Shoshani. System deadlocks. ACM Computing Surveys , 3(2):67–78, June 1971. [25] D. Cohen. holy wars plea peace. IEEE Computer , 14(10):48–54, October 1981. [26] Intel Corporation. Intel 64 IA-32 Archi- tectures Optimization Reference Manual , 2009. Order Number 248966. [27] Intel Corporation. Intel 64 IA-32 Archi- tectures Software Developer’s Manual, Vol-ume 1: Basic Architecture , 2009. Order Number 253665. [28] Intel Corporation. Intel 64 IA-32 Architec- tures Software Developer’s Manual, Volume 2:Instruction Set Reference A–M , 2009. Order Number 253667. [29] Intel Corporation. Intel 64 IA-32 Architec- tures Software Developer’s Manual, Volume 2:Instruction Set Reference N–Z , 2009. Order Number 253668. [30] Intel Corporation. Intel 64 IA-32 Architec- tures Software Developer’s Manual, Volume 3a:System Programming Guide, Part 1 , 2009. Order Number 253669. [31] P . J. Courtois, F. Heymans, D. L. Parnas. Concurrent control “readers” “writ-ers.” Commun. ACM , 14(10):667–668, 1971. [32] C. Cowan, P . Wagle, C. Pu, S. Beattie, J. Walpole. Buffer overﬂows: Attacks anddefenses vulnerability decade. InDARPA Information Survivability Conference Expo (DISCEX) , March 2000.[33] J. H. Crawford. i486 CPU: Executing instructions one clock cycle. IEEE Micro , 10(1):27–36, February 1990. [34] V . Cuppu, B. Jacob, B. Davis, T. Mudge. performance comparison contemporary DRAM architectures. Proceedings Twenty-Sixth International Symposium onComputer Architecture (ISCA) , Atlanta, GA, May 1999. IEEE. [35] B. Davis, B. Jacob, T. Mudge. new DRAM interfaces: SDRAM, RDRAM, variants. Proceedings Third Inter- national Symposium High PerformanceComputing (ISHPC) , Tokyo, Japan, October 2000. [36] E. Demaine. Cache-oblivious algorithms data structures. Lecture Notes Computer Science . Springer-Verlag, 2002. [37] E. W. Dijkstra. Cooperating sequential pro- cesses. Technical Report EWD-123, Technolog- ical University, Eindhoven, Netherlands,1965. [38] C. Ding K. Kennedy. Improving cache performance dynamic applications throughdata computation reorganizations run time. Proceedings 1999 ACM Conference Programming Language Designand Implementation (PLDI) , pages 229–241. ACM, May 1999. [39] M. Dowson. Ariane 5 software failure. SIG- SOFT Software Engineering Notes , 22(2):84, 1997. [40] M. W. Eichen J. A. Rochlis. micro- scope tweezers: analysis Internetvirus November, 1988. IEEE Symposium Research Security Privacy , 1989. [41] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P . Leach, T. Berners-Lee. Hypertext transfer protocol - HTTP/1.1. RFC 2616, 1999. [42] M. Frigo, C. E. Leiserson, H. Prokop, S. Ramachandran. Cache-oblivious algorithms.InProceedings 40th IEEE Symposium Foundations Computer Science (FOCS ’99) , pages 285–297. IEEE, August 1999. [43] M. Frigo V . Strumpen. cache complex- ity multithreaded cache oblivious algorithms.References 1007 InSPAA ’06: Proceedings Eighteenth Annual ACM Symposium Parallelism inAlgorithms Architectures , pages 271–280, New York, NY, USA, 2006. ACM. [44] G. Gibson, D. Nagle, K. Amiri, J. Butler, F. Chang, H. Gobioff, C. Hardin, E. Riedel,D. Rochberg, J. Zelenka. cost-effective,high-bandwidth storage architecture. Pro- ceedings International Conference Architectural Support Programming Lan-guages Operating Systems (ASPLOS) . ACM, October 1998. [45] G. Gibson R. Van Meter. Network attached storage architecture. Communications ACM , 43(11), November 2000. [46] J. Gustafson. Reevaluating Amdahl’s law. Communications ACM , 31(5), August 1988. [47] L. Gwennap. New algorithm improves branch prediction. Microprocessor Report , 9(4), March 1995. [48] S. P . Harbison G. L. Steele, Jr. C, Reference Manual, Fifth Edition . Prentice Hall, 2002. [49] J. L. Hennessy D. A. Patterson. Computer Architecture: Quantitative Approach, FourthEdition . Morgan Kaufmann, 2007. [50] M. Herlihy N. Shavit. Art Multi- processor Programming . Morgan Kaufmann, 2008. [51] C. A. R. Hoare. Monitors: operating system structuring concept. Communications ACM , 17(10):549–557, October 1974. [52] Intel Corporation. Tool Interface Standards Portable Formats Speciﬁcation, Version 1.1 , 1993. Order Number 241597. [53] F. Jones, B. Prince, R. Norwood, J. Hartigan, W. Vogley, C. Hart, D. Bondurant. new era fast dynamic RAMs. IEEE Spectrum , pages 43–39, October 1992. [54] R. Jones R. Lins. Garbage Collection: Algorithms Automatic Dynamic MemoryManagement . Wiley, 1996. [55] M. Kaashoek, D. Engler, G. Ganger, H. Briceo, R. Hunt, D. Maziers, T. Pinckney, R. Grimm,J. Jannotti, K. MacKenzie. Application per- formance ﬂexibility Exokernel systems.InProceedings Sixteenth Symposium Operating System Principles (SOSP) , October 1997. [56] R. Katz G. Borriello. Contemporary Logic Design, Second Edition . Prentice Hall, 2005. [57] B. Kernighan D. Ritchie. C Program- ming Language, First Edition . Prentice Hall, 1978. [58] B. Kernighan D. Ritchie. C Program- ming Language, Second Edition . Prentice Hall, 1988. [59] B. W. Kernighan R. Pike. Practice Programming . Addison-Wesley, 1999. [60] T. Kilburn, B. Edwards, M. Lanigan, F. Sumner. One-level storage system. IRE Transactions Electronic Computers , EC- 11:223–235, April 1962. [61] D. Knuth. Art Computer Programming, Volume 1: Fundamental Algorithms, Second Edition . Addison-Wesley, 1973. [62] J. Kurose K. Ross. Computer Networking: Top-Down Approach, Fifth Edition . Addison- Wesley, 2009. [63] M. Lam, E. Rothberg, M. Wolf. cache performance optimizations blocked al-gorithms. Proceedings International Conference Architectural Support Pro- gramming Languages Operating Systems (ASPLOS) . ACM, April 1991. [64] J. R. Larus E. Schnarr. EEL: Machine- independent executable editing. Proceedings 1995 ACM Conference ProgrammingLanguage Design Implementation (PLDI) , June 1995. [65] C. E. Leiserson J. B. Saxe. Retiming synchronous circuitry. Algorithmica , 6(1–6), June 1991. [66] J. R. Levine. Linkers Loaders . Morgan Kaufmann, San Francisco, 1999. [67] C. Lin L. Snyder. Principles Parallel Programming . Addison-Wesley, 2008. [68] Y. Lin D. Padua. Compiler analysis irregular memory accesses. Proceedings 2000 ACM Conference Programming Language Design Implementation (PLDI) , pages 157–168. ACM, June 2000.1008 References [69] J. L. Lions. Ariane 5 Flight 501 failure. Technical report, European Space Agency, July 1996. [70] S. Macguire. Writing Solid Code . Microsoft Press, 1993. [71] S. A. Mahlke, W. Y. Chen, J. C. Gyllenhal, W. W. Hwu. Compiler code transformations forsuperscalar-based high-performance systems. InSupercomputing . ACM, 1992. [72] E. Marshall. Fatal error: Patriot over- looked Scud. Science , page 1347, March 13, 1992. [73] M. Matz, J. Hubi ˇcka, A. Jaeger, M. Mitchell. System V application binary interface AMD64 architecture processor supplement. Technical report, AMD64.org, 2009. [74] J. Morris, M. Satyanarayanan, M. Conner, J. Howard, D. Rosenthal, F. Smith. Andrew: distributed personal computing environment. Communications ACM , March 1986. [75] T. Mowry, M. Lam, A. Gupta. Design evaluation compiler algorithm forprefetching. Proceedings International Conference Architectural Support Pro- gramming Languages Operating Systems(ASPLOS) . ACM, October 1992. [76] S. S. Muchnick. Advanced Compiler Design Implementation . Morgan Kaufmann, 1997. [77] S. Nath P . Gibbons. Online maintenance large random samples ﬂash storage. InProceedings VLDB’08 . ACM, August 2008. [78] M. Overton. Numerical Computing IEEE Floating Point Arithmetic . SIAM, 2001. [79] D. Patterson, G. Gibson, R. Katz. case redundant arrays inexpensive disks (RAID). InProceedings 1998 ACM SIGMOD Conference . ACM, June 1988. [80] L. Peterson B. Davie. Computer Networks: Systems Approach, Fourth Edition . Morgan Kaufmann, 2007. [81] J. Pincus B. Baker. Beyond stack smashing: Recent advances exploiting buffer overruns.IEEE Security Privacy , 2(4):20–27, 2004. [82] S. Przybylski. Cache Memory Hierarchy Design: Performance-Directed Approach . Morgan Kaufmann, 1990.[83] W. Pugh. Omega test: fast practical integer programming algorithm depen-dence analysis. Communications ACM , 35(8):102–114, August 1992. [84] W. Pugh. Fixing Java memory model. Proceedings Java Grande Conference , June 1999. [85] J. Rabaey, A. Chandrakasan, B. Nikolic. Digital Integrated Circuits: Design Perspec-tive, Second Edition . Prentice Hall, 2003. [86] J. Reinders. Intel Threading Building Blocks . O’Reilly, 2007. [87] D. Ritchie. evolution Unix time- sharing system. AT&T Bell Laboratories Technical Journal , 63(6 Part 2):1577–1593, October 1984. [88] D. Ritchie. development C language. InProceedings Second History Pro- gramming Languages Conference , Cambridge, MA, April 1993. [89] D. Ritchie K. Thompson. Unix time- sharing system. Communications ACM , 17(7):365–367, July 1974. [90] T. Romer, G. Voelker, D. Lee, A. Wolman, W. Wong, H. Levy, B. Bershad, B. Chen. In- strumentation optimization Win32/Intelexecutables using Etch. Proceedings USENIX Windows NT Workshop , Seattle, Washington, August 1997. [91] M. Satyanarayanan, J. Kistler, P . Kumar, M. Okasaki, E. Siegel, D. Steere. Coda: highly available ﬁle system distributedworkstation environment. IEEE Transactions Computers , 39(4):447–459, April 1990. [92] J. Schindler G. Ganger. Automated disk drive characterization. Technical Report CMU- CS-99-176, School Computer Science, Carnegie Mellon University, 1999. [93] F. B. Schneider K. P . Birman. monocul- ture risk put context. IEEE Security Privacy , 7(1), January 2009. [94] R. C. Seacord. Secure Coding C C++ . Addison-Wesley, 2006. [95] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, D. Boneh. effec-tiveness address-space randomization. InProceedings 11th ACM Conference onReferences 1009 Computer Communications Security (CCS ’04), pages 298–307. ACM, 2004. [96] J. P . Shen M. Lipasti. Modern Processor De- sign: Fundamentals Superscalar Processors . McGraw Hill, 2005. [97] B. Shriver B. Smith. Anatomy High-Performance Microprocessor: SystemsPerspective . IEEE Computer Society, 1998. [98] A. Silberschatz, P . Galvin, G. Gagne. Operating Systems Concepts, Eighth Edition . Wiley, 2008. [99] R. Singhal. Intel next generation Nehalem microarchitecture. Intel Developer’s Forum , 2008. [100] R. Skeel. Roundoff error Patriot missile. SIAM News , 25(4):11, July 1992. [101] A. Smith. Cache memories. ACM Computing Surveys , 14(3), September 1982. [102] E. H. Spafford. Internet worm program: analysis. Technical Report CSD-TR-823,Department Computer Science, Purdue University, 1988. [103] A. Srivastava A. Eustace. ATOM: sys- tem building customized program analysistools. Proceedings 1994 ACM Confer- ence Programming Language Design Implementation (PLDI) , June 1994. [104] W. Stallings. Operating Systems: Internals Design Principles, Sixth Edition . Prentice Hall, 2008. [105] W. R. Stevens. TCP/IP Illustrated, Volume 1: Protocols . Addison-Wesley, 1994. [106] W. R. Stevens. TCP/IP Illustrated, Volume 2: Implementation . Addison-Wesley, 1995. [107] W. R. Stevens. TCP/IP Illustrated, Volume 3: TCP Transactions, HTTP, NNTP Unix domain protocols . Addison-Wesley, 1996. [108] W. R. Stevens. Unix Network Programming: Interprocess Communications, Second Edition , volume 2. Prentice Hall, 1998. [109] W. R. Stevens, B. Fenner, A. M. Rudoff. Unix Network Programming: Sockets Networking API, Third Edition , volume 1. Prentice Hall, 2003.[110] W. R. Stevens S. A. Rago. Advanced Programming Unix Environment, Second Edition . Addison-Wesley, 2008. [111] T. Stricker T. Gross. Global address space, non-uniform bandwidth: memory systemperformance characterization parallel sys-tems. Proceedings Third International Symposium High Performance Computer Architecture (HPCA) , pages 168–179, San An- tonio, TX, February 1997. IEEE. [112] A. Tanenbaum. Modern Operating Systems, Third Edition . Prentice Hall, 2007. [113] A. Tanenbaum. Computer Networks, Fourth Edition . Prentice Hall, 2002. [114] K. P . Wadleigh I. L. Crawford. Software Optimization High-Performance Comput- ing: Creating Faster Applications . Prentice Hall, 2000. [115] J. F. Wakerly. Digital Design Principles Practices, Fourth Edition . Prentice Hall, 2005. [116] M. V . Wilkes. Slave memories dynamic storage allocation. IEEE Transactions Electronic Computers , EC-14(2), April 1965. [117] P . Wilson, M. Johnstone, M. Neely, D. Boles. Dynamic storage allocation: survey critical review. International Workshop Memory Management , Kinross, Scotland, 1995. [118] M. Wolf M. Lam. data locality algorithm. InConference Programming Language Design Implementation (SIGPLAN) , pages 30–44, June 1991. [119] J. Wylie, M. Bigrigg, J. Strunk, G. Ganger, H. Kiliccote, P . Khosla. Survivable informa- tion storage systems. IEEE Computer , August 2000. [120] T.-Y. Yeh Y. N. Patt. Alternative implemen- tation two-level adaptive branch prediction.InInternational Symposium Computer Ar- chitecture , pages 451–461, 1998. [121] X. Zhang, Z. Wang, N. Gloy, J. B. Chen, M. D. Smith. System support automatic proﬁling optimization. Proceedings Sixteenth ACM Symposium OperatingSystems Principles (SOSP) , pages 15–26, October 1997.This page intentionally left blank Index Page numbers deﬁning references italicized . Entries belong hard- ware software system followed tag brackets identiﬁes system,along brief description jog memory. list tags meanings. [C] C language construct [C Stdlib] C standard library function [CS:APP] Program function developed text[HCL] HCL language construct [IA32] IA32 machine language instruction [Unix] Unix program, function, variable, constant[x86-64] x86-64 machine language instruction [Y86] Y86 machine language instruction &[C] address operation logic gates, 353 pointers, 44, 175, 234, 252 *[C] dereference pointer operation, 175 $for immediate operands, 169 ![HCL] operation, 353 ||[HCL] Oroperation, 353 <left hoinky, 878 <<[C] left shift operator, 54–56 <<“put to” operator (C++), 862 ->[C] dereference select ﬁeld operator, 242 >right hoinky, 878 >>“get from” operator (C++), 862 >>[C] right shift operator, 54–56 . (periods) dotted-decimal notation, 893 +t wtwo’s-complement addition, 83 -t wtwo’s-complement negation, 87 *t wtwo’s-complement multiplication, 89 +u wunsigned addition, 82 -u wunsigned negation, 82 *u wunsigned multiplication, 88 .aarchive ﬁles, 668a.out ﬁles, 658 Abel, Niels Henrik, 82 abelian group, 82 ABI (Application Binary Interface), 294 abort exception class, 706 aborts, 708–709 absolute addressing relocation type, 673, 675–676 absolute speedup parallel programs, 977 abstract model processor operation, 502–508 abstractions, 24–25 accept [Unix] wait client connection request, 902, 907, 907–908 access disks, 578–580 IA32 registers, 168–169 data movement, 171–177operand speciﬁers, 169–170 main memory, 567–570x86-64 registers, 273–277 access permission bits, 864 access time disks, 573, 573–575 accumulators, multiple, 514–518Acorn RISC Machines (ARM) ISAs, 334processor architecture, 344 actions, signal, 742 active sockets, 905 actuator arms, 573 acyclic networks, 354adapters, 8, 577 add [IA32/x86-64] add, 178, 277 add-client [CS:APP] add client list, 943, 945 add every signal signal set function, 753 add operation execute stage, 387 add signal signal set function, 753 addb [IA32/x86-64] instruction, 177, 277 adder [CS:APP] CGI adder, 918 addition ﬂoating-point, 113–114 IA32, 177 two’s-complement, 83, 83–87 unsigned, 79–83, 82 x86-64, 277–278Y86, 338 additive inverse, 49 10111012 Index addl [IA32/x86-64] instruction, 177, 272, 277 addl [Y86] add, 338, 383 addq [x86-64] instruction, 272, 277 address exceptions, status code for, 384 address-of operator (&) [C] pointers, 44, 175, 234, 252 address order free lists, 835 address partitioning caches, 598 address-space layout randomization (ASLR), 262 address spaces, 778 child processes, 721private, 714 virtual, 778–779 address translation, 777, 787 caches VM integration, 791Core i7, 800–803 end-to-end, 794–799 multi-level page tables, 792– 794 optimizing, 802overview, 787–790 TLBs for, 791–793 addresses addressing byte ordering, 39–42effective, 170, 673 ﬂat, 159 Internet, 890 invalid address status code, 344I/O devices, 579IP,892, 893–895 machine-level programs, 160–161 operands, 170 out-of-bounds. Seebuffer overﬂow physical vs. virtual, 777–778pointers, 234, 252 procedure return, 220 segmented, 264sockets, 899, 901–902 structures, 241–243symbol relocation, 672–677virtual, 777 virtual memory, 33 Y86, 337, 340 addressing modes, 170 addw [IA32/x86-64] instruction, 177, 277 adjacency matrices, 642 ADR [Y86] status code indicating invalid address, 344Advanced Micro Devices (AMD), 156, 159, 267 AMD64 microprocessors, 267, 269 Intel compatibility, 159x86-64. Seex86-64 microprocessors Advanced Research Projects Agency (ARPA), 900 AFS (Andrew File System), 591aggregate data types, 161aggregate payloads, 819 %ah[IA32] bits 8–15 register %eax , 168 %ah [x86-64] bits 8–15 register %rax , 274 %al [IA32] bits 0–7 bits register %eax , 168, 170 %al[x86-64] bits 0–7 register %rax , 274 alarm [Unix] schedule alarm self, 742, 743 alarm.c [CS:APP] program, 743 algebra, Boolean, 48–51, 49 aliasing, memory, 477, 478, 494 .align directive, 346 alignment data, 248, 248–251 memory blocks, 818stack space, 226x86-64, 291 alloca [Unix] stack storage allocation function, 261 allocate initialize bounded buffer function, 968 allocate heap block function, 832, 834 allocate heap storage function, 814 allocated bit, 821 allocated blocks vs. free, 813 placement, 822–823 allocation blocks, 832 dynamic memory. Seedynamic memory allocation pages, 783–784 allocators block allocation, 832 block freeing coalescing, 832free list creation, 830–832free list manipulation, 829–830general design, 827–829 practice problems, 832–835requirements goals, 817–819 styles, 813–814 Alpha processors introduction, 268 RISC, 343 alternate representations signed integers, 63 ALUADD [Y86] function code addition operation, 384 ALUs (Arithmetic/Logic Units), 9 combinational circuits, 359–360 execute stage, 364sequential Y86 implementation, 387–389 always taken branch prediction strategy, 407 AMD (Advanced Micro Devices), 156, 159, 267 Intel compatibility, 159 x86-64. Seex86-64 microprocessors AMD64 microprocessors, 267, 269 Amdahl, Gene, 545 Amdahl’s law, 475, 540, 545, 545–547 American National Standards Institute (ANSI), 4 C standards, 4,3 2 static libraries, 667 ampersand (&) logic gates, 353 pointers, 44, 175, 234, 252 monoand [IA32/x86-64] and, 178, 277 operations Boolean, 48–49execute stage, 387HCL expressions, 354–355logic gates, 353 logical, 54 andl [Y86] and, 338 Andreesen, Marc, 912Andrew File System (AFS), 591 anonymous ﬁles, 807 ANSI (American National Standards Institute), 4 C standards, 4,3 2 static libraries, 667 AOK [Y86] status code normal operation, 344 app_error [CS:APP] reports application errors, 1001 Application Binary Interface (ABI), 294Index 1013 applications, loading linking shared libraries from, 683–686 arUnix archiver, 669, 690 Archimedes, 131architecture ﬂoating-point, 292 Y86. SeeY86 instruction set architecture archives, 668 areal density disks, 572 areas shared, 808 swap, 807 virtual memory, 804 arguments execve function, 730 IA32, 226–228Web servers, 917–918x86-64, 283–284 arithmetic, 31, 177 integer. Seeinteger arithmetic latency issue time, 501–502load effective address, 177–178pointer, 233–234, 846 saturating, 125 shift operations, 55, 96–97, 178–180 special, 182–185, 278–279unary binary, 178–179 x86-64 instructions, 277–279 arithmetic/logic units (ALUs), 9 combinational circuits, 359–360 execute stage, 364sequential Y86 implementation, 387–389 ARM (Acorn RISC Machines) ISAs, 334processor architecture, 344 arms, actuator, 573 ARPA (Advanced Research Projects Agency), 900 ARPANET, 900arrays, 232 basic principles, 232–233 declarations, 232–233, 238 DRAM, 562 ﬁxed-size, 237–238machine-code representation, 161nested, 235–236 pointer arithmetic, 233–234 pointer relationships, 43, 252stride, 588variable-sized, 238–241ASCII standard, 3 character codes, 46 limitations, 47 asctime function, 982–983 ASLR (address-space layout randomization), 262 asmdirective, 267 assembler directives, 346 assemblers, 5, 154, 160 assembly code, 5, 154 C programs, 266–267formatting, 165–167Y86, 340 assembly phase, 5 associate socket address descriptor function, 904, 904– 905 associative caches, 606–609 associative memory, 607 associativity caches, 614–615ﬂoating-point addition, 113–114ﬂoating-point multiplication, 114 integer multiplication, 30 unsigned addition, 82 asterisk ( *) dereference pointer operation, 175, 234, 252 asymmetric ranges two’s- complement representation, 61–62, 71 asynchronous interrupts, 706 atexit function, 680 Atom system, 692ATT assembly-code format, 166 arithmetic instructions, 279 cltd instruction, 184 gcc, 294 vs. Intel, 166–167 operands, 169, 178, 186Y86 instructions, 337–338 automatic variables, 956 %ax [IA32] low-order 16 bits register %eax , 168, 170 %ax [x86-64] low-order 16 bits register %rax , 274 B2T (binary two’s-complement conversion), 60, 67, 89 B2U (binary unsigned conversion), 59, 67, 76, 89 background processes, 733–734 backlogs listening sockets, 905backups disks, 592 backward taken, forward taken (BTFNT) branch predictionstrategy, 407 bad pointers virtual memory, 843 badcnt.c [CS:APP] improperly synchronized program, 957–960, 958 bandwidth, read, 621 base registers, 170 bash [Unix] Unix shell program, 733 basic blocks, 548 Bell Laboratories, 32 Berkeley sockets, 901 Berners-Lee, Tim, 912best-ﬁt block placement policy, 822, 823 %bh[IA32] bits 8–15 register %ebx , 168 %bh [x86-64] bits 8–15 register %rbx , 274 bi-endian ordering convention, 40 biased number encoding, 103, 103– 106 biasing division, 96–97big endian byte ordering, 40 bigram statistics, 542 bijections, 59,6 1 billions ﬂoating-point operations per second (gigaﬂops), 525 /bin/kill program, 739–740 binary ﬁles, 3 binary notation, 30binary points, 100, 100–101 binary representations conversions hexadecimal, 34–35signed unsigned, 65–69to two’s-complement, 60, 67, 89 unsigned, 59 fractional, 100–103 machine language, 178–179 binary semaphores, 964 binary translation, 691–692 binary tree structure, 245–246 bind [Unix] associate socket addr descriptor, 902, 904, 904–905 binding, lazy, 688, 689 binutils package, 690bistable memory cells, 561bit-level operations, 51–531014 Index bit representation, expansion, 71–75 bit vectors, 48, 49–50 bits, 3 overview, 30union access to, 246 %bl [IA32] bits 0–7 register %ebx , 168 %bl[x86-64] bits 0–7 register %rbx , 274 block unblock signals function, 753 block offset bits, 598 block pointers, 829 block size caches, 614minimum, 822 blocked bit vectors, 739 blocked signals, 738, 739, 745 blocking signals, 753–754for temporal locality, 629 blocks aligning, 818 allocated, 813, 822–823 vs. cache lines, 615caches, 593,596, 614 coalescing, 824, 832epilogue, 829 free lists, 820–822 freeing, 832heap, 813 logical disk, 575, 575–576, 582 prologue, 828 referencing data in, 847 splitting, 823in SSDs, 582 bodies, response, 915 bool [HCL] bit-level signal, 354 Boole, George, 48Boolean algebra functions, 48 HCL, 354–355 logic gates, 353 properties, 49 working with, 48–51 Boolean rings, 49 bottlenecks, 540 Amdahl’s law, 545–547 program proﬁling, 540–545 bottom stack, 173boundary tags, 824–826, 825,833 bounded buffers, 966, 966–967 bounds latency, 496, 502throughput, 497, 502 BoundsChecker product, 692 %bp [x86-64] low-order 16 bits register %rbp , 274 %bpl [x86-64] bits 0–7 register %rbp , 274 branch prediction, 208–209, 498, 499 misprediction handling, 434 performance, 526–531 Y86 pipelining, 407 branches, conditional, 161, 193, 193–197 break command gdb, 255 break statements switch , 215 breakpoints, 254–255 bridged Ethernet, 888, 889 bridges Ethernet, 888 I/O, 568 browsers, 911, 912 BSD Unix, 658 .bss section, 659 BTFNT (backward taken, forward taken) branch predictionstrategy, 407 bubbles, pipeline, 414, 414–415, 437–438 buddies, 838 buddy systems, 837, 837–838 buffer overﬂow execution code regions limits for, 266–267 memory-related bugs, 844overview, 256–261stack corruption detection for, 263–265 stack randomization for, 261–262vulnerabilities, 7 buffered I/O functions, 868–872buffers bounded, 966, 966–967 read, 868, 870–871store, 534–535streams, 879–880 bus transactions, 567 buses, 8,567 designs, 568I/O, 576 memory, 568 %bx [IA32] low-order 16 bits register %ebx , 168 %bx [x86-64] low-order 16 bits register %rbx , 274bypassing data hazards, 416–418 byte order, 39–46 disassembled code, 193network, 893 unions, 247 bytes, 3,33 copying, 125range, 34register operations, 169 Y86 encoding, 340–341 C language assembly code with, 266–267bit-level operations, 51–53 ﬂoating-point representation, 114–117 history, 4, 32logical operations, 54shift operations, 54–56 static libraries, 667–670 C++ language, 661 linker symbols, 663–664objects, 241–242 reference parameters, 226 software exceptions, 703–704, 760 .csource ﬁles, 4–5, 655 C standard library, 4–5, 5 C90 standard, 32 C99 standard, 32 integral data types, 58long long integers, 39 cache block offset (CO), 797 cache blocks, 596 cache-friendly code, 616, 616–620 cache lines cache sets, 596 vs. sets blocks, 615 cache oblivious algorithms, 630 cache pollution, 717 cache set index (CI), 797 cache tags (CT), 797 cached pages, 780caches cache memory, 592,596 address translation, 797 anatomy, 612–613associativity, 614–615cache-friendly code, 616, 616–620 data, 499, 612, 613 direct-mapped. Seedirect-mapped caches DRAM, 780 fully associative, 608–609hits, 593Index 1015 importance, 12–13 instruction, 498, 612, 613 locality in, 587, 625–629, 784 managing, 595 memory mountains, 621–625misses, 448, 594, 594–595 overview, 592–593 page allocation, 783–784page faults, 782, 782–783 page hits, 782page tables, 780, 780–781 performance, 531, 614–615, 620– 629 practice problems, 609–611proxy, 915 purpose, 560 set associative, 606, 606–608 size, 614SRAM, 780 symbols, 598virtual memory with, 779–784, 791 write issues, 611–612 write strategies, 615Y86 pipelining, 447–448 call [IA32/1486] procedure call, 221–222, 339 call [Y86] instruction deﬁnition, 339 instruction code for, 384 pipelined implementations, 407processing steps, 372 callee procedures, 220, 223–224, 285 callee saved registers, 223, 287, 289 caller procedures, 220, 223–224, 285 caller saved registers, 223, 287calling environments, 759 calloc function dynamic memory allocation, 814–815 security vulnerability, 92 callq [x86-64] procedure call, 282 calls, 17,707, 707–708 error handling, 717–718Linux/IA32 systems, 710–711performance, 490–491 slow, 745 canary values, 263–264canceling mispredicted branch handling, 434 capacity caches, 597 disks, 571, 571–573 capacity misses, 595cards, graphics, 577 carry ﬂag condition code (CF), 185 CAS (Column Access Strobe) requests, 563 case expressions HCL, 357, 357–359 casting, 42 ﬂoating-point values, 115–116pointers, 252–253, 827signed values, 65–66 catching signals, 738, 740, 744 cells DRAM, 562, 563 SRAM, 561 central processing units (CPUs), 9, 9–10, 497 Core i7. SeeCore i7 microproces- sors early instruction sets, 342effective cycle time, 585 embedded, 344 Intel. SeeIntel microprocessors logic design. Seelogic design many-core, 449multi-core, 16, 22, 158, 586, 934overview, 334–336 pipelining. Seepipelining RAM, 363sequential Y86 implementation. Seesequential Y86 implemen- tation superscalar, 24, 448–449, 497 trends, 584–585Y86. SeeY86 instruction set architecture Cerf, Vinton, 900 CERT (Computer Emergency Response Team), 92 CF[IA32/x86-64] carry ﬂag condition code, 185 CGI (Common Gateway Interface) program, 916–917 %ch[IA32] bits 8–15 register %ecx , 168 %ch [x86-64] bits 8–15 register %rcx , 274 chains, proxy, 915 char data type, 57, 270 character codes, 46 check-clients function, 943, 946 child processes, 720 creating, 721–723default behavior, 724error conditions, 725–726 exit status, 725 reaping, 723, 723–729 waitpid function, 726–729 CI (cache set index), 797 circuits combinational, 354, 354–360 retiming, 401 sequential, 361 CISC (complex instruction set computers), 342, 342–344 %cl [IA32] bits 0–7 register %ecx , 168 %cl[x86-64] bits 0–7 register %rcx , 274 Clarke, Dave, 900 classes data hazards, 412–413exceptions, 706–708instructions, 171 size, 836 storage, 956 clear signal set function, 753 client-server model, 886, 886–887 clienterror [CS:APP] Tiny helper function, 922–923 clients client-server model, 886 telnet, 20–21 clock signals, 361 clocked registers, 380–381clocking logic design, 361–363 close [Unix] close ﬁle, 865 close operations ﬁles, 863, 865 close shared library function, 685 cltd [IA32] convert double word quad word, 182, 184 cltq [x86-64] convert double word quad word, 279 cmova [IA32/x86-64] move unsigned greater, 210 cmovae [IA32/x86-64] move unsigned greater equal, 210 cmovb [IA32/x86-64] move unsigned less, 210 cmovbe [IA32/x86-64] move unsigned less equal, 210 cmove [IA32/x86-64] move equal, 210, 339 cmovg [IA32/x86-64] move greater, 210, 339 cmovge [IA32/x86-64] move greater equal, 210, 3391016 Index cmovl [IA32/x86-64] move less, 210, 339 cmovle [IA32/x86-64] move less equal, 210, 339 cmovna [IA32/x86-64] move unsigned greater, 210 cmovnae [IA32/x86-64] move unsigned greater equal, 210 cmovnb [IA32/x86-64] move unsigned less, 210 cmovnbe [IA32/x86-64] move unsigned less equal, 210 cmovne [IA32/x86-64] move equal, 210, 339 cmovng [IA32/x86-64] move greater, 210 cmovnge [IA32/x86-64] move greater equal, 210 cmovnl [IA32/x86-64] move less, 210 cmovnle [IA32/x86-64] move less equal, 210 cmovns [IA32/x86-64] move nonnegative, 210 cmovnz [IA32/x86-64] move zero, 210 cmovs [IA32/x86-64] move negative, 210 cmovz [IA32/x86-64] move zero, 210 cmp[IA32/x86-64] compare, 186, 280 cmpb [IA32/x86-64] compare byte, 186 cmpl [IA32/x86-64] compare double word, 186 cmpq [x86-64] compare quad word, 280 cmpw [IA32/x86-64] compare word, 186 cmtest script, 443CO (cache block offset), 797 coalescing blocks, 832 boundary tags, 824–826free, 824 memory, 820 Cocke, John, 342code performance strategies, 539 proﬁlers, 540–545representing, 47self-modifying, 413 Y86 instructions, 339, 341 code motion, 487code segments, 678, 679–680 COFF (Common Object File format), 658 Cohen, Danny, 41 cold caches, 594 cold misses, 594 Cold War, 900collectors, garbage, 813,838 basics, 839–840 conservative, 839, 842 Mark&Sweep, 840–842 Column Access Strobe (CAS) requests, 563 column-major sum function, 617 combinational circuits, 354, 354–360 Common Gateway Interface (CGI) program, 916–917 Common Object File format (COFF), 658 Compaq Computer Corp. RISC processors, 343 compare byte instruction ( cmpb ), 186 compare double word instruction (cmpl ), 186 compare instructions, 186, 280 compare quad word instruction (cmpq ), 280 compare word instruction ( cmpw ), 186 compilation phase, 5compilation systems, 5, 6–7 compile time, 654 compiler drivers, 4, 655–657 compilers, 5, 154 optimizing capabilities limitations, 476–480 process, 159–160 purpose, 162 complement instruction ( Not), 178 complex instruction set computers (CISC), 342, 342–344 compulsory misses, 594 computation stages pipelining, 400–401 computational pipelines, 392–393computed goto , 216 Computer Emergency Response Team (CERT), 92 computer systems, 2 concurrency, 934 ECF for, 703ﬂow synchronizing, 755–759 parallelism, 21–22run, 713 thread-level, 22–23 concurrent execution, 713 concurrent ﬂow, 713, 713–714 concurrent processes, 16 concurrent programming, 934–935 deadlocks, 985–988with I/O multiplexing, 939–947library functions in, 982–983 processes, 935–939 races, 983–985reentrancy issues, 980–982shared variables, 954–957 summary, 988–989 threads, 947–954 parallelism, 974–978safety issues, 979–980 concurrent programs, 934 concurrent servers, 934 based I/O multiplexing, 939–947based prethreading, 970–973based processes, 936–937based threads, 952–954 condition code registers deﬁnition, 185hazards, 413SEQ timing, 380–381 condition codes, 185, 185–187 accessing, 187–189 Y86, 337–338 condition variables, 970conditional branches, 161, 193, 193–197 conditional move instructions, 206– 213, 373, 388-389, 527, 529–530 conditional x86-64 operations, 270conﬂict misses, 594, 603–606 connect [Unix] establish connection server, 903 connected descriptors, 907, 908 connections EOF on, 909 Internet, 892, 899–900 I/O devices, 576–578persistent, 915 conservative garbage collectors, 839, 842 constant words, 340 constants free lists, 829–830maximum minimum values, 63multiplication, 92–95 ranges, 62Index 1017 Unix, 725 content dynamic, 916–919 serving, 912 Web, 911, 912–914 context switches, 16, 716–717 contexts, 716 processes, 16,712 thread, 947,955 continue command ADB, 255 Control Data Corporation 6600 processor, 500 control dependencies pipelining, 399, 408 control ﬂow exceptional. Seeexceptional control ﬂow (ECF) logical, 712, 712–713 control hazards, 408control instructions x86-64 processors, 279–282 control logic blocks, 377, 379, 383, 405 control logic pipelining, 431 control mechanism combinations, 438–440 control mechanisms, 437–438 design testing verifying, 442–444 implementation, 440–442special control cases, 432–436 special control conditions, 436–437 control structures, 185 condition codes, 185–189conditional branches, 193–197conditional move instructions, 206–213 jumps, 189–193loops. Seeloops optimization levels, 254 switch statements, 213–219 control transfer, 221–223, 702 controllers disk, 575, 575–576 I/O devices, 8 memory, 563, 564 conventional DRAMs, 562–564conversions binary hexadecimal, 34–35 signed unsigned, 65–69 two’s-complement, 60, 67, 89 unsigned, 59ﬂoating-point values, 115–116 lowercase, 487–489 convert active socket listening socket function, 905 convert application-to-network function, 894 convert double word quad word instruction, 182, 279 convert host-to-network long function, 893 convert host-to-network short function, 893 convert network-to-application function, 894 convert network-to-host long function, 893 convert network-to-host short function, 893 convert quad word oct word instruction ( cqto ), 279 coprocessors, 292 copy_elements function, 91–92 copy ﬁle descriptor function, 878 copy_from_kernel function, 78–79 copy-on-write technique, 808–809 copying bytes memory, 125descriptor tables, 878text ﬁles, 870 Core 2 microprocessors, 158, 568 Core i7 microprocessors, 22–23, 158 address translation, 800–803branch misprediction penalty, 208–209 caches, 613 CPE performance, 485–486functional unit performance, 500–502 load performance, 531 memory mountain, 623 operation, 497–500out-of-order processing, 500page table entries, 800–802performance, 273 QuickPath interconnect, 568 virtual memory, 799–803 core memory, 737 cores multi-core processors, 158, 586, 934 counting semaphores, 964 CPE (cycles per element) metric, 480,482, 485–486 cpfile [CS:APP] text ﬁle copy, 870CPI (cycles per instruction) ﬁve-stage pipelines, 448–449in performance analysis, 444–446 CPUs. Seecentral processing units (CPUs) cqto [x86-64] convert quad word oct word, 279 CR3 register, 800 create/change environment variable function, 732 create child process function, 720, 721–723 create thread function, 950 critical paths, 476, 502, 506–507, 513, 517, 521–522 critical sections progress graphs, 961 CS:APP header ﬁles, 725 wrapper functions, 718, 999 csapp.c [CS:APP] CS:APP wrapper functions, 718, 999 csapp.h [CS:APP] CS:APP header ﬁle, 718, 725, 999 csh[Unix] Unix shell program, 733 CT (cache tags), 797 ctest script, 443 ctime function, 982–983 ctime_ts [CS:APP] thread-safe non- reentrant wrapper ctime , 981 ctrl-c keys nonlocal jumps, 760, 762signals, 738, 740, 771 ctrl-z keys, 741, 771 %cx [IA32] low-order 16 bits register %ecx , 274 %cx [x86-64] low-order 16 bits register %rcx , 274 cycles per element (CPE) metric, 480,482, 485–486 cycles per instruction (CPI) ﬁve-stage pipelines, 448–449in performance analysis, 444–446 cylinders disk, 571 spare, 576, 581 d-caches (data caches), 499, 612, 613 data conditional transfers, 206–213 forwarding, 415–418, 416 sizes, 38–391018 Index data alignment, 248, 248–251 data caches (d-caches), 499, 612, 613 data dependencies pipelining, 398, 408–410 data-ﬂow graphs, 502–507 data formats machine-level programming, 167–168 data hazards classes, 412–413forwarding for, 415–418 load/use, 418–421 stalling, 413–415Y86 pipelining, 408–412 data memory SEQ timing, 380data movement instructions, 171– 177, 275–277 data references locality, 587–588PIC, 687–688 .data section, 659 data segments, 679 data structures heterogeneous. Seeheterogeneous data structures x86-64 processors, 290–291 data types. Seetypes database transactions, 887 datagrams, 892 ddd debugger, 254 DDR SDRAM (Double Data-Rate Synchronous DRAM), 566 deadlocks, 985, 985–988 deallocate heap storage function, 815 .debug section, 659 debugging, 254–256dec[IA32/x86-64] decrement, 178 decimal notation, 30decimal system conversions, 35–37 declarations arrays, 232–233, 238pointers, 39public private, 661structures, 241–244 unions, 244–245 decode stage instruction processing, 364, 366, 368–377 PIPE processor, 426–429SEQ, 385–387 decoding instructions, 498 decrement instruction ( dec), 178–179 deep copies, 982deep pipelining, 397–398default actions signal, 742 default behavior child processes, 724 deferred coalescing, 824 #define preprocessor directive constants, 237 macro expansion, 160 delete command GDB, 255 delete environment variable function, 732 DELETE method HTTP, 915delete signal signal set function, 753 delivering signals, 738 delivery mechanisms protocols, 890 demand paging, 783 demand-zero pages, 807 demangling process, 663, 663–664 DeMorgan’s laws, 461denormalized ﬂoating-point value, 105, 105–110 dependencies control pipelining systems, 399, 408 data pipelining systems, 398, 408–410 reassociation transformations, 521 write/read, 534–536 dereferencing pointers, 44, 175–176, 234, 252, 843 descriptor sets, 939, 940 descriptor tables, 875–876, 878 descriptors, 863 connected listening, 907, 908 socket, 902 destination hosts, 889 detach thread function, 951 detached threads, 951 detaching threads, 951–952 %dh[IA32] bits 8–15 register %edx , 168 %dh [x86-64] bits 8–15 register %rdx , 274 %di [x86-64] low-order 16 bits register %rdi , 274 diagrams hardware, 377 pipeline, 392 Digital Equipment Corporation Alpha processor, 268VAX computer Boolean operations, 53Dijkstra, Edsger, 963–964 %dil [x86-64] bits 0–7 register %rdi , 274 DIMM (Dual Inline Memory Module), 564 direct jumps, 190 direct-mapped caches, 599 conﬂict misses, 603–606example, 601–603line matching, 599–600 line replacement, 600–601 set selection, 599word selection, 600 direct memory access (DMA), 10, 579 directives, assembler, 166, 346 directory ﬁles, 874 dirty bits cache, 612 Core i7, 801 dirty pages, 801 disassemble command GDB, 255 disassemblers, 41, 64, 163, 164–165 disks, 570 accessing, 578–580 anatomy, 580–581backups, 592capacity, 571, 571–573 connecting, 576–578 controllers, 575, 575–576 geometry, 570–571 logical blocks, 575–576operation, 573–575trends, 584–585 distributing software, 684 division instructions, 182–184, 279Linux/IA32 system errors, 709by powers two, 95–98 divl [IA32/x86-64] unsigned divide, 182, 184 divq [x86-64] unsigned divide, 279 DIXtrac tool, 580, 580–581 %dl [IA32] bits 0–7 register %edx , 168 %dl[x86-64] bits 0–7 register %rdx , 274 dlclose [Unix] close shared library, 685 dlerror [Unix] report shared library error, 685 DLLs (Dynamic Link Libraries), 682Index 1019 dlopen [Unix] open shared libary, 684 dlsym [Unix] get address shared library symbol, 684 DMA (direct memory access), 10, 579 DMA transfer, 579 DNS (Domain Name System), 896 dns_error [CS:APP] reports DNS- style errors, 1001 DNS-style error handling, 1000 , 1001 do[C] variant loop, 197–200 doit [CS:APP] Tiny helper function, 920, 921 dollar signs ( $) immediate operands, 169 domain names, 892, 895–899 Domain Name System (DNS), 896 dotprod [CS:APP] vector dot product, 603 dots (.) dotted-decimal notation, 893 dotted-decimal notation, 893, 894 double [C] double-precision ﬂoating point, 114, 115 Double Data-Rate Synchronous DRAM (DDR SDRAM), 566 double data type, 270–271 double-precision representation C, 39, 114–117IEEE, 103, 104 machine-level data, 168 double words, 167 DRAM. SeeDynamic RAM (DRAM) DRAM arrays, 562 DRAM cells, 562, 563 drivers, compiler, 4, 655–657 Dual Inline Memory Module (DIMM), 564 dup2 [Unix] copy ﬁle descriptor, 878 %dx [IA32] low-order 16 bits register %edx , 168 %dx [x86-64] low-order 16 bits register %rdx , 274 dynamically generated code, 266dynamic content, 684, 916–919 Dynamic Link Libraries (DLLs), 682 dynamic linkers, 682 dynamic linking, 681–683, 682 dynamic memory allocation allocated block placement, 822– 823allocator design, 827–832 allocator requirements goals, 817–819 coalescing boundary tags, 824–826 coalescing free blocks, 824explicit free lists, 835fragmentation, 819–820heap memory requests, 823 implementation issues, 820 implicit free lists, 820–822 malloc andfree functions, 814–816 overview, 812–814purpose, 816–817segregated free lists, 836–838 splitting free blocks, 823 dynamic memory allocators, 813– 814 Dynamic RAM (DRAM), 9, 562 caches, 780,782, 782–783 conventional, 562–564 enhanced, 565–566historical popularity, 566modules, 564, 565 vs. SRAM, 562 trends, 584–585 dynamic Web content, 912 E-way set associative caches, 606 %eax [x86-64] low-order 32 bits register %rax , 274 %eax [IA32/Y86] register, 168, 337 %ebp [x86-64] low-order 32 bits register %rbp , 274 %ebp [IA32/Y86] frame pointer register, 168, 337 %ebx [x86-64] low-order 32 bits register %rbx , 274 %ebx [IA32/Y86] register, 168, 337 ECF. Seeexceptional control ﬂow (ECF) ECHILD return code, 725, 727 echo function, 257–258, 263 echo [CS:APP] read echo input lines, 911 echo_cnt [CS:APP] counting version ofecho ,971,973 echoclient.c [CS:APP] echo client, 908–909, 909 echoserveri.c [CS:APP] iterative echo server, 908, 910 echoservers.c [CS:APP]concurrent echo server based I/O multiplexing, 944 echoservert.c [CS:APP] concurrent echo server basedon threads, 953 echoservert_pre.c [CS:APP] prethreaded concurrent echoserver, 972 %ecx [x86-64] low-order 32 bits register %rcx , 274 %ecx [IA32/x86-64] register, 168, 274 %edi [x86-64] low-order 32 bits register %rdi , 274 %edi [IA32/x86-64] register, 168, 274 EDO DRAM (Extended Data DRAM), 566 %edx [x86-64] low-order 32 bits register %rdx , 274 %edx [IA32/Y86] register, 168, 337 EEPROMs (Electrically Erasable Programmable ROMs), 567 effective addresses, 170, 673 effective cycle time, 585 efﬁciency parallel programs, 977, 978 EINTR return code, 725 %eip [IA32] program counter, 161 Electrically Erasable Programmable ROMs (EEPROMs), 567 ELF. SeeExecutable Linkable Format (ELF) EM64T processor, 158 embedded processors, 344 encapsulation, 890 encodings machine-level programs, 159–160 code examples, 162–165 code overview, 160–161 Y86 instructions, 339–342 end-of-ﬁle (EOF) condition, 863, 909 entry points, 678, 679 environment variables lists, 731–732 EOF (end-of-ﬁle) condition, 863, 909 ephemeral ports, 899 epilogue blocks, 829 EPIPE error return code, 927 Erasable Programmable ROMs (EPROMs), 567 errno [Unix] Unix error variable, 1000 error-correcting codes memory, 5621020 Index error handling system calls, 717–718 Unix systems, 1000–1001wrappers, 718,999, 1001–1003 error-reporting functions, 718 errors child processes, 725–726link-time, 7off-by-one, 845race, 755, 755–759 reporting, 1001 synchronization, 957 %esi [x86-64] low-order 32 bits register %rsi , 274 %esi [IA32/Y86] register, 168, 337 %esp [x86-64] low-order 32 bits stack pointer register %rsp, 274 %esp [IA32/Y86] stack pointer register, 168, 337 establish connection server functions, 903–904 establish listening socket function, 905, 905–906 etest script, 443Ethernet segments, 888, 889 Ethernet technology, 888 EUs (execution units), 497, 499 eval [CS:APP] shell helper routine, 734, 735 event-driven programs, 942 based I/O multiplexing, 942–947based threads, 973 events, 703 scheduling, 743state machines, 942 evicting blocks, 594 exabytes, 270 exact-size integer types, 62–63 excepting instructions, 421exception handlers, 704, 705 exception handling instruction processing, 364–365 Y86, 344–345, 420–423, 435–436 exception numbers, 705 exception table base registers, 705 exception tables, 704, 705 exceptional control ﬂow (ECF), 702 exceptions, 703–711 importance, 702–703nonlocal jumps, 759–762process control. Seeprocesses signals. Seesignals summary, 763system call error handling, 717–718 exceptions, 703 anatomy, 703–704classes, 706–708 data alignment, 249 handling, 704–706Linux/IA32 systems, 708–711status code for, 384 synchronous, 707 Y86, 337 exclamation points ( !) operation, 54, 353 Exclusive-Or Boolean operation, 48 exclusive-or instruction ( xor) IA32, 178 Y86, 338 Executable Linkable Format (ELF), 658 executable object ﬁles, 678–679 headers, 658–659relocation, 673segment header tables, 678 symbol tables, 660–662 executable code, 160 executable object ﬁles, 4 creating, 656 description, 657 loading, 679–681 running, 7 segment header tables, 678–679 executable object programs, 4 execute access, 266execute disable bit, 801 execute stage instruction processing, 364, 366, 368–377 PIPE processor, 429–430SEQ, 387–389 execution concurrent, 713 parallel, 714 speculative, 498, 499, 527 tracing, 367, 369–370, 373–375, 382 executable code regions, 266–267 execution units (EUs), 497, 499 execve [Unix] load program, 730 arguments environment variables, 730–732 child processes, 681, 684loading programs, 679 running programs, 733–736 virtual memory, 810exit [C Stdlib] terminate process, 680, 719 exit status, 719, 725 expanding bit representation, 71–75expansion slots, 577 explicit allocator requirements goals, 817–819 explicit dynamic memory allocators, 813 explicit free lists, 835explicit thread termination, 950 explicitly reentrant functions, 981 exploit code, 260–261exponents ﬂoating-point representation, 103 extend_heap [CS:APP] allocator: extend heap, 830, 831 Extended Data DRAM (EDO DRAM), 566 extended precision ﬂoating-point representation, 128 IA32, 116machine-level data, 168x86-64 processors, 271 external exceptions pipelining, 420 external fragmentation, 819, 819–820 fall switch statements, 215 false fragmentation, 824 Fast Page Mode DRAM (FPM DRAM), 566 fault exception class, 706 faulting instructions, 707 faults, 708 Linux/IA32 systems, 709, 806–807Y86 pipelining caches, 448 FD_CLR [Unix] clear bit descriptor set,939, 940 FD_ISSET [Unix] bit turned descriptor set?, 939, 940, 942 FD_SET [Unix] set bit descriptor set,939, 940 FD_ZERO [Unix] clear descriptor set, 939, 940 feedback pipelining, 398–400, 403feedback paths, 375, 399fetch ﬁle metadata function, 873–874 fetch stage instruction processing, 364, 366, 368–377 PIPE processor, 424–425SEQ, 383–385Index 1021 fetches, locality, 588–589 fgets function, 258 Fibonacci (Pisano), 30ﬁeld-programmable gate arrays (FPGAs), 444 FIFOs, 937 ﬁle descriptors, 863 ﬁle position, 863 ﬁle tables, 716,875 ﬁle type, 879 ﬁles, 19 abstraction, 25 anonymous, 807 binary, 3 metadata, 873–875 object. Seeobject ﬁles register, 9, 161, 339–340, 362–363, 380, 499 regular, 807,874 sharing, 875–877 system-level I/O. Seesystem-level I/O Unix, 862, 862–863 fingerd daemon, 260 finish command GDB, 255 ﬁrmware, 567 ﬁrst ﬁt block placement policy, 822, 823 ﬁrst-level domain names, 896 ﬁrst readers-writers problem, 969 ﬁts, segregated, 836, 837 ﬁve-stage pipelines, 448–449ﬁxed-size arrays, 237–238ﬂash memory, 567 ﬂash translation layers, 582–583 ﬂat addressing, 159 float [C] single-precision ﬂoating point, 114, 270 ﬂoating-point representation programs, 99–100 architecture, 292 arithmetic, 31 C, 114–117 denormalized values, 105, 105–110 encodings, 30extended precision, 116, 128 fractional binary numbers, 100– 103 IEEE, 103–105machine-level representation, 292–293 normalized value, 103, 103–104 operations, 113–114overﬂow, 116–117 pi, 131rounding, 110–113special values, 105 SSE architecture, 292x86-64 processors, 270, 492 x87 architecture, 156–157, 292 ﬂows concurrent, 713, 713–714 control, 702 logical, 712, 712–713 parallel, 713–714 synchronizing, 755–759 ﬂushed instructions, 499 FNONE [Y86] default function code, 384 footers blocks, 825 [C] general loop statement, 203–206 forbidden regions, 964 foreground processes, 734 fork [Unix] create child process, 720 child processes, 684example, 721–723running programs, 733–736 virtual memory, 809–810 fork.c [CS:APP] fork example, 721 formal veriﬁcation, 443–444 format strings, 43formats machine-level data, 167–168 formatted disk capacity, 576 formatted printing, 43 formatting disks, 576machine-level code, 165–167 forwarding data hazards, 415–418 load, 456 forwarding priority, 427–428FPGAs (ﬁeld-programmable gate arrays), 444 FPM DRAM (Fast Page Mode DRAM), 566 fprintf [C Stdlib] function, 43 fractional binary numbers, 100–103fractional ﬂoating-point representa- tion, 103–110, 128 fragmentation, 819 dynamic memory allocation, 819–820 false, 824 frame pointer, 219frames Ethernet, 888 stack, 219, 219–221, 249, 284–287 free [C Stdlib] deallocate heap storage, 815, 815–816 free blocks, 813 coalescing, 824splitting, 823 free bounded buffer function, 968 free heap block function, 833 free heap blocks, referencing data in, 847 free lists creating, 830–832dynamic memory allocation, 820–822 explicit, 835implicit, 822 manipulating, 829–830 segregated, 836–838 free software, 6FreeBSD open source operating system, 78–79 freeing blocks, 832 Freescale processor family, 334RISC design, 342 front side bus (FSB), 568 fstat [Unix] fetch ﬁle metadata, 873–874 full duplex connections, 899 full duplex streams, 880 fully associative caches, 608, 608–609 fully linked executable object ﬁles, 678 fully pipelined functional units, 501 function calls performance strategies, 539PIC, 688–690 function codes Y86 instructions, 339–340 functional units, 499–502 functions parameter passing to, 226pointers to, 253reentrant, 980 static libraries, 667–670 system-level, 710 thread-safe thread-unsafe, 979, 979–981 -funroll-loops option, 512 gaps, disk sectors, 571, 5761022 Index garbage, 838 garbage collection, 814,838 garbage collectors, 813,838 basics, 839–840conservative, 839, 842 Mark&Sweep, 840–842 overview, 838–839 gates, logic, 353gcc (GNU Compiler Collection) compiler ATT format for, 294 code formatting, 165–166inline substitution, 479loop unrolling, 512optimizations, 254–256 options, 32–33, 476 support SIMD instructions, 524–525 working with, 159–160 gdb GNU debugger, 163, 254, 254–256 general protection faults, 709general-purpose registers IA32, 168–169x86-64, 273–275 Y86, 336–337 geometry disks, 570–571 get address shared library symbol function, 685 get DNS host entry functions, 896 “get from” operator (C++), 862GET method HTTP, 915 get parent process ID function, 719 get process group ID function, 739 get process ID function, 719 get thread ID function, 950 getenv [C Stdlib] read environment variable, 732 gethostbyaddr [Unix] get DNS host entry, 896, 982–983 gethostbyname [Unix] get DNS host entry, 896, 982–983 getpeername function, 78–79 getpgrp [Unix] get process group ID,739 getpid [Unix] get process ID, 719 getppid [Unix] get parent process ID,719 getrusage [Unix] function, 784 gets function, 256–259 GHz (gigahertz), 480 giga-instructions per second (GIPS), 392gigabytes, 572 gigaﬂops, 525 gigahertz (GHz), 480 GIPS (giga-instructions per second), 392 global IP Internet. SeeInternet Global Offset Table (GOT), 687, 688–690 global symbols, 660, 664–667 global variable mapping, 956GNU Compiler Collection. See gcc (GNU Compiler Collection) compiler GNU project, 6 GOT (Global Offset Table), 687, 688–690 goto [C] control transfer statement, 193, 216 goto code, 193–194 gprof Unix proﬁler, 540, 541–542 gradual underﬂow, 105granularity concurrency, 947 graphic user interfaces debuggers, 254 graphics adapters, 577 graphs data-ﬂow, 502–507 process, 721, 722 progress. Seeprogress graphs reachability, 839 greater signs ( >) “get from” operator, 862 right hoinkies, 878 groups abelian, 82 process, 739 guard values, 263 h_errno [Unix] DNS error variable, 1000 .hheader ﬁles, 669 halt [Y86] halt instruction execution, 339 exceptions, 344, 420–422instruction code for, 384 pipelining, 439 status code for, 384 handlers exception, 704, 705 interrupt, 706 signal, 738, 742, 744 handling signals, 744 issues, 745–751portable, 752–753 hardware caches. Seecaches cache memory Hardware Control Language (HCL), 352 Boolean expressions, 354–355integer expressions, 355–360logic gates, 353 hardware description languages (HDLs), 353, 444 hardware exceptions, 704 hardware interrupts, 706 hardware management, 14–15hardware organization, 7–8 buses, 8I/O devices, 8–9 main memory, 9 processors, 9–10 hardware registers, 361–362hardware structure Y86, 375–379hardware units, 375–377, 380 hash tables, 544–545 hazards pipelining, 336, 408 forwarding for, 415–418load/use, 418–420overview, 408–412 stalling for, 413–415 HCL (Hardware Control Language), 352 Boolean expressions, 354–355 integer expressions, 355–360 logic gates, 353 HDLs (hardware description languages), 353, 444 head crashes, 573 HEAD method HTTP, 915 header ﬁles static libraries, 669 system, 725 header tables ELF, 658,678, 678–679 headers blocks, 821 ELF, 658 Ethernet, 888 request, 914 response, 915 heap, 18,813 dynamic memory allocation, 813–814 Linux systems, 679 referencing data in, 847 requests, 823Index 1023 hello [CS:APP] C hello program, 2, 10–12 help command, 255 Hennessy, John, 342, 448heterogeneous data structures, 241 data alignment, 248–251 structures, 241–244unions, 244–248x86-64, 290–291 hexadecimal (hex) notation, 34, 34–37 hierarchies domain name, 895storage devices, 13, 13–14, 591, 591–595 high-level design performance strategies, 539 hit rates, 614 hit times, 614 hits cache, 593,614 write, 612 hlt [IA32/x86-64] halt instruction, 339 HLT[Y86] status code indicating halt instruction, 344 hoinkies, 878 holding mutexes, 964 Horner, William, 508 Horner’s method, 508 host bus adapters, 577 host bus interfaces, 577 host entry structures, 896 host information program command, 894 hostent [Unix] DNS host entry structure, 896 hostinfo [CS:APP] get DNS host entry, 897 hostname command, 894 hosts client-server model, 887 network, 889 number of, 898 htest script, 443HTML (Hypertext Markup Language), 911, 911–912 htonl [Unix] convert host-to- network long, 893 htons [Unix] convert host-to- network short, 893 HTTP . SeeHypertext Transfer Protocol (HTTP)hubs, 888 hyperlinks, 911 Hypertext Markup Language (HTML), 911, 911–912 Hypertext Transfer Protocol (HTTP), 911 dynamic content, 916–919 requests, 914, 914–915 responses, 915, 915–916 transactions, 914 hyperthreading, 22, 158 HyperTransport interconnect, 568 i-caches (instruction caches), 498, 612, 613 .iﬁles, 5, 655 i386 Intel microprocessors, 157, 269 i486 Intel microprocessors, 157 IA32 (Intel Architecture 32-bit) array access, 233condition codes, 185 conditional move instructions, 207–209 data alignment, 249 exceptions, 708–711extended-precision ﬂoating point, 116 machine language, 155–156 microprocessors, 44, 158registers, 168, 168–169 data movement, 171–177operand speciﬁers, 169–170 vs. Y86, 342, 345–346 IA32-EM64T microprocessors, 269IA64 Itanium instruction set, 269 iaddl [Y86] immediate add, 452 IBM out-of-order processing, 500processor family, 334RISC design, 342–343 ICALL [Y86] instruction code call instruction, 384 ICANN (Internet Corporation Assigned Names Numbers), 896 icode (Y86 instruction code), 364, 383 ICUs (instruction control units), 497–498 idivl [IA32/x86-64] signed divide, 182, 183 idivq [x86-64] signed divide, 279IDs (identiﬁers) processes, 719–720register, 339–340 IEEE. SeeInstitute Electrical Electronic Engineers (IEEE) description, 100 Posix standards, 15 IEEE ﬂoating-point representation denormalized, 105 normalized, 103–104 special values, 105Standard 754, 99standards, 99–100 if[C] conditional statement, 194– 196 ifun (Y86 instruction function), 364, 383 IHALT [Y86] instruction code halt instruction, 384 IIRMOVL [Y86] instruction code irmovl instruction, 384 ijk matrix multiplication, 626, 626– 628 IJXX [Y86] instruction code jump instructions, 384 ikj matrix multiplication, 626, 626– 628 illegal instruction exception, 384 imem_error signal, 384 immediate add instruction ( iaddl ), 452 immediate coalescing, 824 immediate offset, 170immediate operands, 169immediate register move instruction ( irmovl ),337 implicit dynamic memory allocators, 813–814 implicit free lists, 820–822, 822 implicit thread termination, 950 implicitly reentrant functions, 981 implied leading 1 representation, 104 IMRMOVL [Y86] instruction code mrmovl instruction, 384 imul [IA32/x86-64] multiply, 178 imull [IA32/x86-64] signed multiply, 182 imulq [x86-64] signed multiply, 279 in[HCL] set membership test, 360–361 in_addr [Unix] IP address structure, 893 inc[IA32/x86-64] increment, 1781024 Index incl [IA32/x86-64] increment, 179 include ﬁles, 669 #include preprocessor directive, 160 increment instruction ( inc), 178–179 indeﬁnite integer values, 116 index.html ﬁle, 912–913 index registers, 170 indexes direct-mapped caches, 605–606 indirect jumps, 190, 216inefﬁciencies loops, 486–490 inet_aton [Unix] convert application-to-network, 894 inet_ntoa [Unix] convert network- to-application, 894, 982–983 inﬁnite precision, 80inﬁnity constants, 115 representation, 104–105 info frame command, 255 info registers command, 255 information, 2–3information access IA32 registers, 168–169 data movement, 171–177 operand speciﬁers, 169–170 x86-64 registers, 273–277 information storage, 33 addressing byte ordering, 39–46 bit-level operations, 51–53Boolean algebra, 48–51code, 47data sizes, 38–39 disks. Seedisks ﬂoating-point representation. See ﬂoating-point representationand programs hexadecimal, 34–37 integers. Seeintegers locality. Seelocality memory. Seememory segregated, 836 shift operations, 54–56 strings, 46–47 summary, 629–630words, 38 init function, 723 init_pool [CS:APP] initialize client pool, 943, 945 initialize nonlocal handler jump function, 759initialize nonlocal jump functions, 759 initialize read buffer function, 868, 870 initialize semaphore function, 963 initialize thread function, 952 initializing threads, 952 inline assembly, 267inline substitution, 254, 479inlining, 254, 479 INOP [Y86] instruction code nop instruction, 384 input events, 942 input/output. SeeI/O (input/output) insert item bounded buffer function, 968 install portable handler function, 752 installing signal handlers, 744 Institute Electrical Electronic Engineers (IEEE) description, 100 ﬂoating-point representation denormalized, 105normalized, 103–104special values, 105 standards, 99–100 Posix standards, 15 instr_regids signal, 383 instr_valC signal, 383 instr_valid signal, 383–384 instruction caches (i-caches), 498, 612, 613 instruction code (icode), 364, 383instruction control units (ICUs), 497–498 instruction function (ifun), 364, 383 instruction-level parallelism, 23–24, 475, 496–497, 539 instruction memory SEQ timing, 380 instruction set architectures (ISAs), 9, 24, 160, 334 instruction set simulators, 348instructions classes, 171decoding, 498 excepting, 421 fetch locality, 588–589issuing, 406–407jump, 10, 189–193load, 10 low-level. Seemachine-level programmingmove, 206–213, 527, 529–530 pipelining, 446–447, 527privileged, 715 sequential Y86 implementation. Seesequential Y86 implemen- tation store, 10update, 10 Y86. SeeY86 instruction set architecture instructions per cycle (IPC), 449 intdata types integral, 58x86-64 processors, 270 int[HCL] integer signal, 356 INT_MAX constant, 62 INT_MIN constant, 62 integer arithmetic, 79, 178 division powers two, 95–98 multiplication constants, 92–95overview, 98–99two’s-complement addition, 83–87two’s-complement multiplication, 89–92 two’s-complement negation, 87–88unsigned addition, 79–83 integer bits ﬂoating-point representation, 128 integer expressions HCL, 355–360 integer indeﬁnite values, 116 integer operation instructions, 384 integer registers IA32, 168–169 x86-64, 273–275 Y86, 336–337 integers, 30, 56–57 arithmetic operations. Seeinteger arithmetic bit-level operations, 51–53 bit representation expansion, 71–75 byte order, 41data types, 57–58 shift operations, 54–56 signed unsigned conversions, 65–71 signed vs. unsigned guidelines, 76–79 truncating, 75–76 two’s-complement representation, 60–65 unsigned encoding, 58–60 integral data types, 57, 57–58Index 1025 integration caches VM, 791 Intel assembly-code format vs. ATT, 166–167 gcc, 294 Intel microprocessors 8086, 24, 157, 267 conditional move instructions, 207–209 coprocessors, 292Core i7. SeeCore i7 microproces- sors data alignment, 249 evolution, 157–158ﬂoating-point representation, 128i386, 157, 269 IA32. SeeIA32 (Intel Architecture 32-bit) northbridge southbridge chipsets, 568 out-of-order processing, 500x86-64. Seex86-64 microprocessors interconnected networks (internets), 888, 889–890 interfaces bus, 568host bus, 577 interlocks, load, 420 internal exceptions pipelining, 420internal fragmentation, 819 internal read function, 871 International Standards Organiza- tion (ISO), 4, 32 Internet, 889 connections, 899–900domain names, 895–899 IP addresses, 893–895 organization, 891–893origins, 900 Internet addresses, 890 Internet Corporation Assigned Names Numbers (ICANN), 896 Internet domain names, 892 Internet Domain Survey ,898 Internet hosts, number of, 898 Internet Protocol (IP), 892 Internet Software Consortium, 898 Internet worm, 260internets (interconnected networks), 888, 889–890 interpretation bit patterns, 30 interprocess communication (IPC), 937interrupt handlers, 706 interruptions, 745interrupts, 706, 706–707 interval counting schemes, 541–542 INTN_MAX [C] maximum value N-bit signed data type, 63 INTN_MIN [C] minimum value N-bit signed data type, 63 intN_t[C]N-bit signed integer data type, 63 invalid address status code, 344invalid memory reference exceptions, 435 invariants, semaphore, 963 I/O (input/output), 8,862 memory-mapped, 578 ports, 579 redirection, 877, 877–879 system-level. Seesystem-level I/O Unix, 19,862, 862–863 I/O bridges, 568 I/O buses, 576 I/O devices, 8–9 addressing, 579connecting, 576–578 I/O multiplexing, 935 concurrent programming with, 939–947 event-driven servers based on, 942–947 pros cons, 947–948 IOPL [Y86] instruction code integer operation instructions,384 IP (Internet Protocol), 892 IP address structure, 893, 894 IP addresses, 892, 893–895 IPC (instructions per cycle), 449IPC (interprocess communication), 937 IPOPL [Y86] instruction code popl instruction, 384 IPUSHL [Y86] instruction code pushl instruction, 384 IRET [Y86] instruction code ret instruction, 384 IRMMOVL [Y86] instruction code rmmovl instruction, 384 irmovl [Y86] immediate register move, 337 constant words for, 340 instruction code for, 384 processing steps, 367–368IRRMOVL [Y86] instruction code rrmovl instruction, 384 ISA (instruction set architecture), 9, 24, 160, 334 ISO (International Standards Organization), 4, 32 ISO C90 C standard, 32 ISO C99 C standard, 32, 39, 58 isPtr function, 842 issue time arithmetic operations, 501, 502 issuing instructions, 406–407 Itanium instruction set, 269 iteration, 256iterative servers, 908 iterative sorting routines, 544 ja[IA32/x86-64] jump unsigned greater, 190 jae [IA32/x86-64] jump unsigned greater equal, 190 Java language, 661 byte code, 293 linker symbols, 663–664numeric ranges, 63objects in, 241–242software exceptions, 703–704, 760 Java monitors, 970 Java Native Interface (JNI), 685 jb[IA32/x86-64] jump unsigned less, 190 jbe [IA32/x86-64] jump unsigned less equal, 190 je[IA32/x86-64/Y86] jump equal, 190, 338–339 , 373 jg[IA32/x86-64/Y86] jump greater, 190, 338–339 jge [IA32/x86-64/Y86] jump greater equal, 190, 338–339 jik matrix multiplication, 626, 626– 628 jki matrix multiplication, 626, 626– 628 jl[IA32/x86-64/Y86] jump less, 190, 338–339 jle [IA32/x86-64/Y86] jump less equal, 190, 338–339 jmp [IA32/x86-64/Y86] jump unconditionally, 190,338–339 jna [IA32/x86-64] jump unsigned greater, 190 jnae [IA32/x86-64] jump unsigned greater equal, 1901026 Index jnb [IA32/x86-64] jump unsigned less, 190 jnbe [IA32/x86-64] jump unsigned less equal, 190 jne [IA32/x86-64/Y86] jump equal, 190, 338–339 jng [IA32/x86-64] jump greater, 190 jnge [IA32/x86-64] jump greater equal, 190 JNI (Java Native Interface), 685 jnl [IA32/x86-64] jump less, 190 jnle [IA32/x86-64] jump less equal, 190 jns [IA32/x86-64] jump nonnegative, 190 jnz [IA32/x86-64] jump zero, 190 jobs, 740 joinable threads, 951 js[IA32/x86-64] jump negative, 190 jtest script, 443jump greater instruction ( jg), 190, 338–339 jump greater equal instruction (jge), 190, 338–339 jump less instruction ( jl), 190, 338–339 jump less equal instruction (jle), 190, 338–339 jump negative instruction ( js), 190 jump nonnegative instruction (jns), 190 jump equal instruction ( jne), 190, 338–339 jump greater instruction ( jng), 190 jump greater equal instruction ( jnge ), 190 jump less instruction ( jnl), 190 jump less equal instruction (jnle ), 190 jump unsigned greater instruction ( jna), 190 jump unsigned less instruction (jnb), 190 jump unsigned less equal instruction ( jnbe ), 190 jump zero instruction ( jnz), 190jump unsigned greater instruction (ja), 190 jump unsigned greater equal instruction ( jae), 190 jump unsigned less instruction ( jb), 190 jump unsigned less equal instruction ( jbe), 190 jump zero instruction ( jz), 190 jump instructions, 10, 189–193 direct, 190indirect, 190, 216 instruction code for, 384 nonlocal, 703, 759, 759–762 targets, 190 jump tables, 213, 216, 705 jump unconditionally instruction ( jmp),190, 190, 338–339 jump equal instruction ( je), 338 just-in-time compilation, 266, 294 jz[IA32/x86-64] jump zero, 190 K&R (C book), 4 Kahan, William, 99–100 Kahn, Robert, 900 kernel mode exception handlers, 706 processes, 714–716, 715 system calls, 708 kernels, 18, 680 exception numbers, 705 virtual memory, 803–804 Kernighan, Brian, 2, 4, 15, 32, 253, 849, 882 keyboard, signals from, 740–741 kij matrix multiplication, 626, 626– 628 kill.c [CS:APP] kill example, 741 kill command gdb debugger, 255 kill [Unix] send signal, 741 kji matrix multiplication, 626, 626– 628 Knuth, Donald, 823, 825 ksh[Unix] Unix shell program, 733 l sufﬁx, 168 L1 cache, 13,596 L2 cache, 13,596 L3 cache, 596 LANs (local area networks), 888, 889–891last-in ﬁrst-out (LIFO) free list order, 835 stack discipline, 172 latency arithmetic operations, 501, 502 disks, 574 instruction, 392load operations, 531–532pipelining, 391 latency bounds, 496, 502 lazy binding, 688, 689 ldUnix static linker, 657 ld-linux.so linker, 683 ldd tool, 690 LEA[IA32/x86-64] instruction, 93 leaf procedures, 284 leaks, memory, 847, 954 leal [IA32] load effective address, 177, 177–178, 252, 278 leaq [x86-64] load effective address, 277 least-frequently-used (LFU) replacement policies, 608 least-recently-used (LRU) replacement policies, 594, 608 least squares ﬁt, 480, 482 leave [IA32/x86-64/Y86] prepare stack return, 221–222, 228,453 left hoinkies ( <),878 length strings, 77 less signs ( <) left hoinkies, 878 “put to” operator, 862 levels optimization, 254, 256, 476storage, 591 LFU (least-frequently-used) replacement policies, 608 libc library, 879 libraries concurrent programming, 982–983 header ﬁles, 77 shared, 18, 681–686, 682 standard I/O, 879–880static, 667, 667–672 LIFO (last-in ﬁrst-out) free list order, 835 stack discipline, 172 limits.h ﬁle, 62, 71Index 1027 line matching direct-mapped caches, 599–600 fully associative caches, 608 set associative caches, 607–608 line replacement direct-mapped caches, 600–601 set associative caches, 608 .line section, 659 linear address spaces, 778 link-time errors, 7linkers linking, 5, 154, 160 compiler drivers, 655–657dynamic, 681–683, 682 object ﬁles, 657, 657–658 executable, 678–681loading, 679–681relocatable, 658–659tools for, 690 overview, 654–655 position-independent code, 687– 690 relocation, 672–678 shared libraries applications, 683–686 static, 657 summary, 691symbol resolution, 663–672 symbol tables, 660–662 virtual memory for, 785 linking phase, 5Linux operating system, 19–20, 44 code segments, 679–680 data alignment, 249 dynamic linker interfaces, 685and ELF, 658 exceptions, 708–711signals, 737 virtual memory, 803–807 Lisp language, 80 listen [Unix] convert active socket listening socket, 905 listening descriptors, 907–908listening sockets, 905 little endian byte ordering, 40 load effective address instruction ( leal ,leaq ), 177–178, 252 load forwarding, 456 load instructions, 10 load interlocks, 420load operations, 498–499load penalty CPI, 445load performance memory, 531–532load program function, 730 load/store architecture CISC vs. RISC, 343 load time code, 654 load/use data hazards, 418, 418–421 loaders, 657,679 loading concepts, 681executable object ﬁles, 679–681 programs, 730–732 shared libraries applications, 683–686 virtual memory for, 785–786 local area networks (LANs), 888, 889–891 local automatic variables, 956 local registers loop segments, 504–505 local static variables, 956 local symbols, 660 locality, 13, 560, 586, 586–587 blocking for, 629 caches, 625–629, 784 exploiting, 629 forms, 587, 595 instruction fetches, 588–589program data references, 587–588summary, 589–591 localtime function, 982–983 lock-and-copy technique, 980, 981 locking mutexes lock ordering rule, 987 semaphores, 964 logic design, 352 combinational circuits, 354–360, 392 logic gates, 353 memory clocking, 361–363set membership, 360–361 logic gates, 353 logic synthesis, 336, 353, 444 logical blocks disks, 575, 575–576 SSDs, 582 logical control ﬂow, 712–713logical operations, 54, 177 discussion, 180–182 shift, 55, 95, 178–180 unary binary, 178–179 long [C] integer data type, 39, 57–58, 270 long double [C] extended-precision ﬂoating point, 115, 168 270long integers x86-64 processors, 270 long long [C] integer data type, 39, 57–58, 270–271 long words machine-level data, 168 longjmp [C Stdlib] nonlocal jump, 703, 759, 760 loop registers, 505 loop unrolling, 480, 482, 509 Core i7, 551overview, 509–513with reassociation transforma- tions, 519–521 loopback addresses, 897 loops, 197 do-while , 197–200 for, 203–206 inefﬁciencies, 486–490reverse engineering, 199segments, 504–505for spatial locality, 625–629 , 200–203 low-level instructions. Seemachine- level programs low-level optimizations, 539 lowercase conversions, 487–489LRU (least-recently-used) replacement policies, 594, 608 lseek [Unix] function, 866–867 lvalues (C) pointers, 252 machine checks, 709 machine code, 154 machine-level programs arithmetic. Seearithmetic arrays. Seearrays buffer overﬂow. Seebuffer overﬂow control. Seecontrol structures data-ﬂow graphs from, 503–507data formats, 167–168data movement instructions, 171–177, 275–277 encodings, 159–167 ﬂoating-point programs, 292–293 gdb debugger, 254–256 heterogeneous data structures. See heterogeneous data structures historical perspective, 156–159 information access, 168–169 instructions, 41028 Index machine-level programs (continued) operand speciﬁers, 169–170 overview, 154–156pointer principles, 252–253procedures. Seeprocedures x86-64. Seex86-64 microprocessors macros free lists, 829–830main memory, 9 accessing, 567–570memory modules, 564 main threads, 948 malloc [C Stdlib] allocate heap storage, 32, 679, 813, 814 alignment with, 250dynamic memory allocation, 814–816 man ascii command, 46 mandatory alignment, 249 mangling process, 663, 663–664 many-core processors, 449map disk object memory function, 810 mapping memory. Seememory mapping variables, 956 maps, zone, 580–581mark phase Mark&Sweep, 840 Mark&Sweep algorithm, 839 Mark&Sweep garbage collectors, 840, 840–842 masking operations, 52matrices adjacency, 642 multiplying, 625–629 maximum two’s-complement number, 61 maximum unsigned number, 59maximum values, constants for, 63 McCarthy, John, 839 McIlroy, Doug, 15 mem_init [CS:APP] heap model, 828 mem_sbrk [CS:APP] sbrk emulator, 828 membership, set, 360–361 memcpy [Unix] copy bytes one region memory another,125 memory, 560 accessing, 567–570aliasing, 477, 478, 494 associative, 607 caches. Seecaches cache memorycopying bytes in, 125 data alignment in, 248–251data hazards, 413design, 363 dynamic. Seedynamic memory allocation hierarchy, 13, 13–14, 591, 591–595 interfacing processor, 447– 448 leaks, 847, 954 load performance, 531–532in logic design, 361–363machine-level programming, 160 main, 9,564, 567–570 mapping. Seememory mapping nonvolatile, 567 performance, 531–539protecting, 266, 786–787 RAM. Seerandom-access memories (RAM) ROM, 567 threads, 955–956trends, 583–586 virtual. Seevirtual memory (VM) Y86, 337 memory buses, 568 memory controllers, 563, 564 memory management units (MMUs), 778, 780 memory-mapped I/O, 578 memory mapping, 786 areas, 807, 807 execve function, 810 fork function, 809–810 loading, 681objects, 807–809user-level, 810–812 memory mountains, 621, 621–625 memory references operands, 170out-of-bounds. Seebuffer overﬂow performance, 491–496pipelining exceptions, 435 memory stage instruction processing, 364, 366, 368–377 PIPE processor, 430–431SEQ, 389–390Y86 pipelining, 403 memory system, 560 memory utilization, 818, 818–819 metadata, 873, 873–875 metastable states, 561methods HTTP, 915 objects, 242 micro-operations, 498microarchitecture, 10, 496 microprocessors. Seecentral processing units (CPUs) Microsoft Windows operating system, 44, 249 MIME (Multipurpose Internet Mail Extensions) types, 912 minimum block size, 822 minimum two’s-complement number, 61 minimum values constants, 63 two’s-complement representation, 61 mispredicted branches canceling, 434 performance penalties, 445, 499, 526–531 misses, caches, 448, 594 kinds, 594–595 penalties, 614, 780 rates, 614 mm_coalesce [CS:APP] allocator: boundary tag coalescing, 833 mm_free [CS:APP] allocator: free heap block, 832, 833 mm_ijk [CS:APP] matrix multiply ijk,626 mm_ikj [CS:APP] matrix multiply ikj,626 mm_init [CS:APP] allocator: initialize heap, 830, 831 mm_jik [CS:APP] matrix multiply jik,626 mm_jki [CS:APP] matrix multiply jki,626 mm_kij [CS:APP] matrix multiply kij,626 mm_kji [CS:APP] matrix multiply kj i,626 mm_malloc [CS:APP] allocator: allocate heap block, 832, 834 mmap [Unix] map disk object memory, 810, 810–812 MMUs (memory management units), 778, 780 Mockapetris, Paul, 900 mode bits, 715Index 1029 modern processor operation, 496– 509 modes kernel, 706,708 processes, 714–716, 715 user, 706 modular arithmetic, 80–81 modules DRAM, 564, 565 object, 657–658 monitors, Java, 970 monotonicity assumption, 819 monotonicity property, 114Moore, Gordon, 158–159Moore’s Law, 158, 158–159 mosaic browser, 912 motherboards, 8 Motorola 68020 processor, 268RISC processors, 343 mov [IA32/x86-64] move data, 171, 276 movabsq [x86-64] move absolute quad word, 276 movb [IA32/x86-64] move byte, 171–172 Move absolute quad word instruction (movabsq ), 276 move byte instruction ( movb ), 171 Move data instructions ( mov),171, 171–177, 276 move double word instruction (movl ), 171 move greater instruction ( cmovg ), 210, 339 move greater equal instruction (cmovge ), 210, 339 move less instruction ( cmovl ), 210, 339 move less equal instruction (cmovle ), 210, 339 move negative instruction ( cmovs ), 210 move nonnegative instruction (cmovns ), 210 move equal instruction (cmovne ), 210, 339 move greater instruction (cmovng ), 210 move greater equal instruction ( cmovnge ), 210 move less instruction ( cmovnl ), 210move less equal instruction (cmovnle ), 210 move unsigned greater instruction ( cmovna ), 210 move unsigned less instruction (cmovnb ), 210 move unsigned less equal instruction ( cmovnbe ), 210 move zero instruction (cmovnz ), 210 move unsigned greater instruction (cmova ), 210 move unsigned greater equal instruction ( cmovae ), 210 move unsigned less instruction (cmovb ), 210 move unsigned less equal instruction ( cmovbe ), 210 move zero instruction ( cmovz ), 210 move instructions, conditional, 206–213 move quad word instruction ( movq ), 276 move sign-extended byte double word instruction ( movsbl ), 171 move sign-extended byte quad word instruction ( movsbq ), 276 move sign-extended byte word instruction ( movsbw ), 171 move sign-extended double word quad word instruction (movslq ), 276 move sign-extended word double word instruction ( movswl ), 171 move sign-extended word quad word instruction ( movswq ), 276 move equal instruction ( move ), 339 move sign extension instructions (movs ), 171, 276 move zero extension instructions (movz ), 171, 276 move word instruction ( movw ), 171 move zero-extended byte double word instruction ( movzbl ), 171 move zero-extended byte quad word instruction ( movzbq ), 276 move zero-extended byte word instruction ( movzbw ), 171 move zero-extended word double word instruction ( movzwl ), 171 move zero-extended word quad word instruction ( movzwq ), 276moves, conditional, 527, 529–530 movl [IA32/x86-64] move double word, 171 movq [IA32/x86-64] move quad word, 272, 276 movs [IA32/x86-64] move sign extension, 171–172, 172, 276 movsbl [IA32/x86-64] move sign- extended byte double word, 171–172 movsbq [x86-64] move sign-extended byte quad word, 276 movsbw [IA32/x86-64] move sign- extended byte word, 171 movslq [x86-64] move sign-extended double word quad word, 276, 278 movss ﬂoating-point move instruction, 492 movswl [IA32/x86-64] move sign- extended word double word, 171 movswq [x86-64] move sign-extended word quad word, 276 movw [IA32/x86-64] move word, 171 movz [IA32/x86-64] move zero extension, 171, 172, 276 movzbl [IA32/x86-64] move zero- extended byte double word,171–172 movzbq [x86-64] move zero-extended byte quad word, 276 movzbw [IA32/x86-64] move zero- extended byte word, 171 movzwl [IA32/x86-64] move zero- extended word double word,171 movzwq [x86-64] move zero-extended word quad word, 276 mrmovl [Y86] memory register move instruction, 368 mull [IA32/x86-64] unsigned multiply, 182 mulq [x86-64] unsigned multiply, 279 mulss ﬂoating-point multiply instruction, 492 multi-core processors, 16, 22, 158, 586, 934 multi-level page tables, 792–794multi-threading, 17, 22Multics, 15multicycle instructions, 446–447 multidimensional arrays, 235–2361030 Index multimedia applications, 156–157 multiple accumulators parallelism, 514–518 multiple zone recording, 572 multiplexing, I/O, 935 concurrent programming with, 939–947 event-driven servers based on, 942–947 pros cons, 947–948 multiplexors, 354, 354–355 HCL case expression, 357 word-level, 357–358 multiplication constants, 92–95 ﬂoating-point, 113–114 instructions, 182matrices, 625–629two’s-complement, 89, 89–92 unsigned, 88,182, 182, 279 multiply deﬁned global symbols, 664–667 multiply instruction, 178, 182, 279, 492 multiported random-access memory, 362 multiprocessor systems, 22Multipurpose Internet Mail Extensions (MIME) types, 912 multitasking, 713 multiway branch statements, 213–219 munmap [Unix] unmap disk object, 812 mutexes lock ordering rule, 987 Pthreads, 970for semaphores, 964 mutual exclusion progress graphs, 962 semaphores for, 964–965 mutually exclusive access, 962 \n(newline character), 3 n-gram statistics, 542–543names data types, 43domain, 892, 895–899 mangling demangling processes, 663, 663–664 protocols, 890Y86 pipelines, 406naming conventions Y86 signals, 405–406 NaN (not-a-number) constants, 115representation, 104, 105 nanoseconds (ns), 480 National Science Foundation (NSF), 900 neg [IA32/x86-64] negate, 178 negate instruction, 178 negation, two’s-complement, 87, 87–88 negative overﬂow, 83,8 4 Nehalem microarchitecture, 497, 799 nested arrays, 235–236 nested structures, 244NetBurst microarchitecture, 157network adapters, 577 network byte order, 893 network clients, 20,886 Network File System (NFS), 591network programming, 886 client-server model, 886–887Internet. SeeInternet networks, 887–891 sockets interface. Seesockets interface summary, 927–928tiny Web server, 919–927 Web servers, 911–919 network servers, 21,886 networks, 20–21 acyclic, 354LANs, 888, 889–891 WANs, 889, 889–890 never taken (NT) branch prediction strategy, 407 newline character ( \n),3 next ﬁt block placement policy, 822, 823 nexti command GCB, 255 NFS (Network File System), 591nmtool, 690 no-execute (NX) memory protection, 266 operation nopinstruction instruction code for, 384 pipelining, 409–411 repas, 281 stack randomization, 262 no-write-allocate approach, 612 nodes, root, 839nondeterminism, 728 nondeterministic behavior, 728 nonexistent variables, referencing, 846 nonlocal jumps, 703, 759, 759–762 nonuniform partitioning, 395–397nonvolatile memory, 567 nopinstruction instruction code for, 384 pipelining, 409–411 repas, 281 nop sleds, 262 norace.c [CS:APP] Pthreads program without race, 985 normal operation status code, 344, 384 normalized values, ﬂoating-point, 103, 103–104 northbridge chipsets, 568not-a-number NaN constants, 115 representation, 104, 105 [IA32/x86-64] complement, 178 operation Boolean, 48–49 C operators, 54 logic gates, 353 ns (nanoseconds), 480 NSF (National Science Foundation), 900 NSFNET, 900 ntohl [Unix] convert network-to- host long, 893 ntohs [Unix] convert network-to- host short, 893 number systems conversions. See conversions numeric limit declarations, 71 numeric ranges integral types, 57–58Java standard, 63 NX (no-execute) memory protection, 266 .oﬁles, 5, 163, 655 objdump tool, 163, 254, 674, 690 object ﬁles, 160, 163 executable. Seeexecutable object ﬁles forms, 162, 657 relocatable, 5, 655,657, 658–659 tools, 690Index 1031 object modules, 657–658 objects memory-mapped, 807–809 private, 808, 809 program, 33shared, 682, 807–809, 808 struct , 241–242 oct words, 279 OF[IA32/x86-64/486] overﬂow ﬂag condition code, 185, 337 off-by-one errors, 845offsets GOTs, 687, 688–690 memory references, 170PPOs, 789 structures, 241–242unions, 245 VPOs, 788 one-operand multiply instructions, 182, 278–279 ones’-complement representation, 63 open [Unix] open ﬁle, 863, 863–865 open_clientfd [CS:APP] establish connection server, 903, 903–904 open_listenfd [CS:APP] establish listening socket, 905, 905–906 open operations ﬁles, 862–863 , 863–865 open shared library function, 684 open source operating systems, 78–79 operand speciﬁers, 169–170 operating systems (OS), 14 ﬁles, 19hardware management, 14–15kernels, 18 Linux, 19–20, 44 processes, 16–17threads, 17Unix, 32virtual memory, 17–19 Windows, 44, 249 operations bit-level, 51–53logical, 54shift, 54–56 optest script, 443 optimization address translation, 802compiler, 160levels, 254, 256, 476program performance. See performance optimization blockers, 475, 478 OPTIONS method, 915 or[IA32/x86-64] or, 178 Oroperation Boolean, 48–49C operators, 54HCL expressions, 354–355 logic gates, 353 order, bytes, 39–46 disassembled code, 193network, 893 unions, 247 origin servers, 915 OS. Seeoperating systems (OS) Ossanna, Joe, 15Ousterhout, John K., 474out-of-bounds memory references. Seebuffer overﬂow out-of-core algorithms, 268out-of-order execution, 497 ﬁve-stage pipelines, 449history, 500 overﬂow arithmetic, 81, 125 buffer. Seebuffer overﬂow ﬂoating-point values, 116– 117 identifying, 86 inﬁnity representation, 105multiplication, 93negative, 83,8 4 operations, 30 positive, 84 overﬂow ﬂag condition code (OF), 185, 337 overloaded functions, 663 P semaphore operation, 963, 964 P[CS:APP] wrapper function Posix sem_wait, 963, 964 P6 microarchitecture, 157PA (physical addresses), 777 vs. virtual, 777–778 packages, processor, 799 packet headers, 890 packets, 890 padding alignment, 250–251 blocks, 821 Y86, 341page faults Linux/IA32 systems, 709, 806–807 memory caches, 448 pipelining caches, 782, 782–783 page frames, 779 page hits caches, 782page table base registers (PTBRs), 788 page table entries (PTEs), 781, 782 Core i7, 800–802TLBs for, 791–794, 797 page table entry addresses (PTEAs), 791 page tables, 716, 797 caches, 780, 780–781 multi-level, 792–794 paged pages, 783 paged pages, 783 pages allocation, 783–784demand zero, 807 dirty, 801 physical, 779, 779–780 SSDs, 582virtual, 266, 779, 779–780 paging, 783 parallel execution, 714 parallel ﬂows, 713–714 parallel programs, 974 parallelism, 21–22, 513–514 instruction-level, 23–24, 475, 496–497, 539 multiple accumulators, 514–518reassociation transformations, 518–523 SIMD, 24–25, 523–524 threads for, 974–978 parent processes, 719–720 parse_uri [CS:APP] Tiny helper function, 923, 924 parseline [CS:APP] shell helper routine, 736 partitioning addresses, 598 nonuniform pipelining, 395–397 Pascal reference parameters, 226 passing arguments x86-64 processors, 283–284 parameters functions, 226 pointers structures, 242 Patterson, David, 342, 4481032 Index pause [Unix] suspend signal arrives, 730 payloads aggregate, 819 Ethernet, 888 protocol, 890 PC. Seeprogram counter (PC) PC-relative addressing jumps, 190–193, 191 operands, 275symbol references, 673, 674–675 Y86, 340 PC selection stage PIPE processor, 424–425 PC update stage instruction processing, 364, 366, 368–377 SEQ, 390 PCI (Peripheral Component Interconnect) bus, 576 PE (Portable Executable) format, 658 peak utilization metric, 818–819, 819 peer threads, 948 pending bit vectors, 739 pending signals, 738 Pentium II microprocessors, 157Pentium III microprocessors, 157Pentium 4 microprocessors, 157, 269 Pentium 4E microprocessors, 158, 273 PentiumPro microprocessors, 157 conditional move instructions, 207out-of-order processing, 500 performance, 6 Amdahl’s law, 545–547basic strategies, 539bottlenecks, 540–547 branch prediction mispredic- tion penalties, 526–531 caches, 531, 614–615, 620–629compiler capabilities limitations, 476–480 expressing, 480–482 limiting factors, 525–531 loop inefﬁciencies, 486–490loop unrolling, 509, 509–513 memory, 531–539memory references, 491–496 modern processors, 496–509 overview, 474–476parallelism. Seeparallelism procedure calls, 490–491program example, 482–486 program proﬁling, 540–545 register spilling, 525–526relative, 493–494results summary, 524–525 SEQ, 391 summary, 547–548Y86 pipelining, 444–446 periods (.) dotted-decimal notation, 893 Peripheral Component Interconnect (PCI) bus, 576 persistent connections HTTP, 915 physical address spaces, 778 physical addresses (PA), 777 vs. virtual, 777–778 Y86, 337 physical page numbers (PPNs), 788 physical page offset (PPO), 789 physical pages (PPs), 779, 779–780 pi ﬂoating-point representation, 131 PIC (position-independent code), 687 data references, 687–688 function calls, 688–690 picoseconds (ps), 392,480 PIDs (process IDs), 719 pins, DRAM, 562–563 PIPE– processor, 401, 403, 405–409 PIPE processor stages, 418–419, 423–424 decode write-back, 426–429execute, 429–430 memory, 430–431 PC selection fetch, 424–425 pipelining, 208, 391 computational, 392–393deep, 397–398 diagram, 392 ﬁve-stage, 448–449functional units, 501–502instruction, 527limitations, 394–395 nonuniform partitioning, 395–397 operation, 393–394registers, 393, 406store operation, 532–533systems feedback, 398–400 Y86. See Y86 pipelined implementations pipes, 937Pisano, Leonardo (Fibonacci), 30placement memory blocks, 820, 822–823 policies, 594,822 platters, disk, 570, 571 PLT (procedure linkage table), 688, 689–690 pmap tool, 762 point-to-point connections, 899 pointers, 33 arithmetic, 233–234, 846arrays, relationship to, 43, 252 block, 829 creating, 44, 175declaring, 39dereferencing, 44, 175–176, 234, 252, 843 examples, 174–176 frame, 219to functions, 253machine-level data, 167 principles, 252–253 role, 34stack, 219to structures, 242–243virtual memory, 843–846 void* ,4 4 pollution, cache, 717 polynomial evaluation, 507, 508, 551–552 pools peer threads, 948 pop double word instruction ( popl ), 171, 173, 339 pop instructions x86 models, 352pop operations stack, 172, 172–174 pop quad word instruction ( popq ), 276 popl instruction behavior of, 350–351 instruction code for, 384 processing steps, 369, 371Y86, 339, 340 popl [IA32/Y86] pop double word, 171, 173,339 popq [x86-64] pop quad word, 276 Portable Executable (PE) format, 658 portable signal handling, 752–753ports Ethernet, 888 Internet, 899 I/O, 579 register ﬁles, 362 .pos directive, 346Index 1033 position-independent code (PIC), 687 data references, 687–688 function calls, 688–690 positive overﬂow, 84 posix_error [CS:APP] reports Posix-style errors, 1001 Posix standards, 15Posix-style error handling, 1000 , 1001 Posix threads, 948, 948–949 POST method, 915–916, 918PowerPC processor family, 334RISC design, 342–343 powers two, division by, 95–98 PPNs (physical page numbers), 788 PPO (physical page offset), 789 PPs (physical pages), 779, 779–780 precedence shift operations, 56 precision ﬂoating-point, 103, 104, 116, 128 inﬁnite, 80 prediction branch, 208–209 misprediction penalties, 526–531Y86 pipelining, 403, 406–408 preempted processes, 713 prefetching mechanism, 623 preﬁx sum, 480, 481, 538, 552 prepare stack return instruction function ( leave ), 221–222 453 preprocessors, 5, 160 prethreading, 970, 970–973 principle locality, 586, 587 print command GDB, 255 printf [C Stdlib] formatted printing function formatted printing, 43 numeric values with, 70 priorities PIPE processor forwarding sources, 427–428 write ports, 387 private address space, 714 private areas, 808 private copy-on-write structures, 809 private declarations, 661private objects, 808, 809 privileged instructions, 715 /proc ﬁlesystem, 715, 762–763 procedure call instruction, 339 procedure linkage table (PLT), 688, 689–690procedure return instruction, 281, 339 procedures, 219 call performance, 490–491control transfer, 221–223example, 224–229 recursive, 229–232 register usage conventions, 223– 224 stack frame structure, 219–221x86-64 processors, 282 process contexts, 16,716 process graphs, 721, 722 process groups, 739 process IDs, 719 process tables, 716 processes, 16,712, 718 background, 733 concurrent ﬂow, 712–714, 713 concurrent programming with, 935–939 concurrent servers based on, 936–937 context switches, 716–717creating terminating, 719–723 default behavior, 724 error conditions, 725–726exit status, 725foreground, 734 IDs, 719–720 loading programs, 681, 730– 732 overview, 16–17private address space, 714vs. programs, 732–733 pros cons, 937 reaping, 723, 723–729 running programs, 730–736sleeping, 729–730tools, 762–763 user kernel modes, 714–715 waitpid function, 726–729 processor-memory gap, 12,586 processor packages, 799 processor states, 703 processors. Seecentral processing units (CPUs) procmask1.c [CS:APP] shell program race, 756 procmask2.c [CS:APP] shell program without race, 757 producer-consumer problem, 966, 966–968proﬁlers code, 475 proﬁling, program, 540–545 program counter (PC), 9 data hazards, 412 %eip ,161 fetch stage, 364 %rip ,275 SEQ timing, 380 Y86 instruction set architecture, 337 Y86 pipelining, 403, 406–408 program data references locality, 587–588 program registers data hazards, 412Y86, 336–337 programmable ROMs (PROMs), 567 programmer-visible state, 336, 336–337 programs code data, 18concurrent. Seeconcurrent programming forms, 4–5loading running, 730–732machine-level. Seemachine-level programming objects, 33 vs. processes, 732–733proﬁling, 540–545running, 10–12, 733–736Y86, 345–350 progress graphs, 959, 960–963 deadlock regions, 986, 987 forbidden regions, 964 limitations, 966 prologue blocks, 828 PROMs (programmable ROMs), 567 protection, memory, 786–787protocol software, 889–890 protocols, 890 proxy caches, 915 proxy chains, 915 ps (picoseconds), 392,480 pstool, 762 pseudo-random number generator functions, 980 psum.c [CS:APP] simple parallel sum program, 975 PTBRs (page table base registers), 7881034 Index PTEAs (page table entry addresses), 791 PTEs (page table entries), 781, 782 Core i7, 800–802TLBs for, 791–794, 797 pthread_cancel [Unix] terminate another thread, 951 pthread_create [Unix] create thread, 949, 950 pthread_detach [Unix] detach thread, 951, 952 pthread_exit [Unix] terminate current thread, 950 pthread_join [Unix] reap thread, 951 pthread_once [Unix] initialize thread, 952, 971 pthread_self [Unix] get thread ID, 950 Pthreads, 948, 948–949, 970 public declarations, 661Purify product, 692 push double word instruction ( pushl ), 171, 173, 339 push instructions x86 models, 352 push operations stack, 172, 172–174 push quad word instruction ( pushq ), 276 pushl [Y86] push, 338–339 instruction code for, 384 processing steps, 369–370 pushl [IA32] push double word, 171, 173 pushq [x86-64] push quad word, 276 PUT method HTTP, 915“put to” operator (C++), 862 qsort function, 544 quad words machine-level data, 167x86-64 processors, 270, 277 queued signals, 745 QuickPath interconnect, 568, 800 quit command GDB, 255 R_386_32 relocation type, 673 R_386_PC32 relocation type, 673 %r8[x86-64] program register, 274 %r8d [x86-64] low-order 32 bits register %r8, 274 %r8w [x86-64] low-order 16 bits register %r8, 274%r9[x86-64] program register, 274 %r9d [x86-64] low-order 32 bits register %r9, 274 %r9w [x86-64] low-order 16 bits register %r9, 274 %r10 [x86-64] program register, 274 %r10d [x86-64] low-order 32 bits register %r10, 274 %r10w [x86-64] low-order 16 bits register %r10, 274 %r11 [x86-64] program register, 274 %r11d [x86-64] low-order 32 bits register %r11, 274 %r11w [x86-64] low-order 16 bits register %r11, 274 %r12 [x86-64] program register, 274 %r12d [x86-64] low-order 32 bits register %r12, 274 %r12w [x86-64] low-order 16 bits register %r12, 274 %r13 [x86-64] program register, 274 %r13d [x86-64] low-order 32 bits register %r13, 274 %r13w [x86-64] low-order 16 bits register %r13, 274 %r14 [x86-64] program register, 274 %r14d [x86-64] low-order 32 bits register %r14, 274 %r14w [x86-64] low-order 16 bits register %r14, 274 %r15 [x86-64] program register, 274 %r15d [x86-64] low-order 32 bits register %r15, 274 %r15w [x86-64] low-order 16 bits register %r15, 274 race.c [CS:APP] program race, 984 race conditions, 954 races, 755 concurrent programming, 983–985exposing, 759signals, 755–759 RAM. Seerandom-access memories (RAM) Rambus DRAM (RDRAM), 566 rand [CS:APP] pseudo-random number generator, 980, 982– 983 rand_r function, 982 random-access memories (RAM), 361, 561 dynamic. SeeDynamic RAM (DRAM)multiported, 362 processors, 363 SEQ timing, 380 static. SeeStatic RAM (SRAM) random operations SSDs, 582–583random replacement policies, 594 ranges asymmetric, 61–62, 71 bytes, 34constants for, 62integral types, 57–58 Java standard, 63 RAS (Row Access Strobe) requests, 563 %rax [x86-64] program register, 274 %rbp [x86-64] program register, 274 %rbx [x86-64] program register, 274 %rcx [x86-64] program register, 274 %rdi [x86-64] program register, 274 RDRAM (Rambus DRAM), 566 %rdx [x86-64] program register, 274 reachability graphs, 839 reachable nodes, 839 read access, 266read echo input lines function, 911 read bandwidth, 621 read environment variable function, 732 read/evaluate steps, 733 read [Unix] read ﬁle, 865, 865–866 Read-Only Memory (ROM), 567 read operations buffered, 868, 870–871disk sectors, 578–579 ﬁle metadata, 873–875 ﬁles, 863, 865–866 SSDs, 582unbuffered, 867–868uninitialized memory, 843–844 read ports, 362 read_requesthdrs [CS:APP] Tiny helper function, 923 read sets, 940 read throughput, 621 read transactions, 567, 568–569 read/write heads, 573 readelf tool, 662, 690 readers-writers problem, 969, 969– 970 readline function, 873 readn function, 873 ready read descriptors, 940Index 1035 ready sets, 940 realloc function, 814–815 reap thread function, 951 reaping child processes, 723, 723–729 threads, 951 rearranging signals pipelines, 405–406 reassociation transformations, 511, 518, 518–523, 548 receiving signals, 738,742, 742–745 recording density, 571 recording zones, 572 recursive procedures, 229–232red zones stack, 289 redirection, I/O, 877, 877–879 reduced instruction set computers (RISC), 291, 342 vs. CISC, 342–344IA32 extensions, 267 SPARC processors, 448 reentrancy issues, 980–982reentrant functions, 980 reference, function parameters passed by, 226 reference bits, 801 reference counts, 875reference machines, 485 referencing data free heap blocks, 847 nonexistent variables, 846 refresh, DRAM, 562regions, deadlock, 986, 987 register ﬁles, 9, 161 contents, 362–363, 499 purpose, 339–340 SEQ timing, 380 register identiﬁers, 339–340, 384 register operands, 170 register speciﬁer bytes, 340 register memory move instruction ( rmmovl ),337 register register move instruction (rrmovl ),337 registers, 9 clocked, 361 data hazards, 412–413hardware, 361–362 IA32, 116, 168, 168–169 loop segments, 504–505 pipeline, 393, 406procedures, 223–224program, 336–337, 361–363, 412renaming, 500 saving, 287–290spilling, 240, 240–241, 525–526 x86-64, 270, 273–275, 287–290Y86, 340, 401–405 regular ﬁles, 807,874 .rel.data section, 659 .rel.text section, 659 relabeling signals, 405–406 relative performance, 493–494relative speedup parallel programs, 977 reliable connections, 899 relocatable object ﬁles, 5, 655,657, 658–659 relocation, 657, 672 algorithm, 673–674, 674 entries, 672–673, 673 PC-relative references, 674–675 practice problems, 676–677 remove item bounded buffer function, 968 renaming registers, 500 rep [IA32/x86-64] string repeat instruction, used no-op, 281 repeating string instruction, 281replacement policies, 594 replacing blocks, 594 report shared library error function, 685 reporting errors, 1001request headers HTTP, 914 request lines HTTP, 914 requests client-server model, 886 HTTP, 914, 914–915 Requests Comments (RFCs), 928 reset conﬁguration pipelining, 438 resident sets, 784 resources client-server model, 886 shared, 966–970 RESP [Y86] register ID %esp ,384 response bodies HTTP, 915 response headers HTTP, 915 response lines HTTP, 915 responses client-server model, 886 HTTP, 915, 915–916 restart.c [CS:APP] nonlocal jump example, 762 restrictions, alignment, 248–251retinstruction instruction code for, 384 processing steps, 372, 374–375 Y86 pipelining, 407–408, 432–436, 438–439 ret [IA32/x86-64/Y86] procedure return, 221–222, 281, 339 retiming circuits, 401 retirement units, 499 return addresses predicting, 408procedures, 220 return penalty CPI, 445reverse engineering loops, 199 machine code, 155 Revolutions per minute (RPM), 571 RFCs (Requests Comments), 928 rfork.c [CS:APP] wrapper exposes races, 758 ridges memory mountains, 621–624right hoinkies ( >),878 right shift operations, 55, 178rings, Boolean, 49 rio[CS:APP] robust I/O package, 867 buffered functions, 868–872origins, 873unbuffered functions, 867–868 rio_read [CS:APP] internal read function, 871 rio_readinitb [CS:APP] initialize read buffer, 868, 870 rio_readlineb [CS:APP] robust buffered read, 868, 872 rio_readn [CS:APP] robust unbuffered read, 867, 867–869 rio_readnb [CS:APP] robust buffered read, 868, 872 rio_t [CS:APP] read buffer, 870 rio_writen [CS:APP] robust unbuffered write, 867, 867–869 %rip [x86-64] program counter, 275 RISC (reduced instruction set computers), 291, 342 vs. CISC, 342–344IA32 extensions, 267SPARC processors, 448 Ritchie, Dennis, 4, 15, 32, 882 rmmovl [Y86] register memory move, 337 instruction code for, 384 processing steps, 368–3691036 Index RNONE [Y86] ID indicating register, 384 Roberts, Lawrence, 900 robust buffered read functions, 868, 872 Robust I/O ( rio) package, 867 buffered functions, 868–872 origins, 873unbuffered functions, 867–868 robust unbuffered read function, 867, 867–869 robust unbuffered write function, 867, 867–869 .rodata section, 658 ROM (Read-Only Memory), 567 root nodes, 839 rotating disks term, 571 rotational latency disks, 574 rotational rate disks, 570 round-down mode, 111 round-to-even mode, 110, 115 round-to-nearest mode, 110 round-toward-zero mode, 111 round-up mode, 111 rounding division, 96–97ﬂoating-point representation, 110–113 rounding modes, 110, 110–111 routers, Ethernet, 888 routines, thread, 949–950 Row Access Strobe (RAS) requests, 563 row-major array order, 235, 588 row-major sum function, 617, 617– 618 RPM (revolutions per minute), 571 rrmovl [Y86] register register move, 337,384 %rsi [x86-64] program register, 274 %rsp [x86-64] stack pointer register, 274, 285 runcommand GDB, 255 run concurrency, 713 run time linking, 654 shared libraries, 682 stack, 161 running parallel, 714 processes, 719 programs, 10–12, 730–736.sassembly-language ﬁles, 5, 162– 163, 655 SA[CS:APP] shorthand struct sockaddr, 902 SADR [Y86] status code address exception, 384 safe optimization, 477 safe trajectories progress graphs, 962 sal[IA32/x86-64] shift left, 178, 180 salq [IA32/x86-64] instruction, 277 SAOK [Y86] status code normal operation, 384 sar[IA32/x86-64] shift arithmetic right, 178, 180 SATA interfaces, 577 saturating arithmetic, 125 sbrk [C Stdlib] extend heap, 814, 815 emulator, 828 heap memory, 823 Sbuf [CS:APP] shared bounded buffer package, 967, 968 sbuf_deinit [CS:APP] free bounded buffer, 968 sbuf_init [CS:APP] allocate initialize bounded buffer, 968 sbuf_insert [CS:APP] insert item bounded buffer, 968 sbuf_remove [CS:APP] remove item bounded buffer, 968 sbuf_t [CS:APP] bounded buffer used Sbuf package, 967 scalar code performance summary, 524–525 scale factor memory references, 170 scaling parallel programs, 977–978 scanf function, 843 schedule alarm self function, 742 schedulers, 716 scheduling, 716 events, 743shared resources, 966–970 scripts, CGI, 917SCSI interfaces, 577 SDRAM (synchronous DRAM), 566 second-level domain names, 896 second readers-writers problem, 969 sectors, disks, 571, 575 reading, 578–579 spare, 581security holes, 7 security monoculture, 261security vulnerabilities getpeername function, 78–79 XDR library, 91–92 seeds pseudo-random number generators, 980 seek operations, 573,863 seek time disks, 573, 574 segment header tables, 678, 678– 679 segmentation faults, 709segmented addressing, 264segments code, 678, 679–680 data, 679 Ethernet, 888, 889 virtual memory, 804 segregated ﬁts, 836, 837 segregated free lists, 836–838 segregated storage, 836 select [Unix] wait I/O events, 939 self-loops, 942 self-modifying code, 413 sem_init [Unix] initialize semaphore, 963 sem_post [Unix] V operation, 963 sem_wait [Unix] P operation, 963 semaphores, 963, 963–964 concurrent server example, 970– 973 mutual exclusion, 964–965for scheduling shared resources, 966–970 sending signals, 738, 739–742 separate compilation, 654 SEQ+ Y86 processor design, 400, 400–401 SEQ Y86 processor design. See sequential Y86 implementation sequential circuits, 361 sequential execution, 185sequential operations SSDs, 582–583 sequential reference patterns, 588 sequential Y86 implementation, 364 decode write-back stage, 385–387 execute stage, 387–389fetch stage, 383–385hardware structure, 375–379Index 1037 instruction processing stages, 364–375 memory stage, 389–390 PC update stage, 390performance, 391timing, 379–383 serve_dynamic [CS:APP] Tiny helper function, 926, 926–927 serve_static [CS:APP] Tiny helper function, 924–926, 925 servers, 21 client-server model, 886 concurrent. Seeconcurrent servers network, 21 Web. SeeWeb servers services client-server model, 886 serving dynamic content, 916–919 Web content, 912 set associative caches, 606 line matching word selection, 607–608 line replacement, 608 set selection, 607 set index bits, 598 set equal instruction ( sete ), 187 set greater instruction ( setg ), 187 set greater equal instruction (setge ), 187 set less instruction ( setl ), 187 set less equal instruction (setle ), 187 set negative instruction ( sets ), 187 set nonnegative instruction (setns ), 187 set equal instruction ( setne ), 187 set greater instruction (setng ), 187 set greater equal instruction (setnge ), 187 set less instruction ( setnl ), 187 set less equal instruction (setnle ), 187 set zero instruction ( setnz ), 187 set unsigned greater instruction (seta ), 187 set unsigned greater equal instruction ( setae ), 187set unsigned less instruction (setb ), 187 set unsigned less equal instruction ( setge ), 187 set unsigned greater instruction ( setna ), 187 set unsigned less instruction (setnb ), 187 set unsigned less equal instruction ( setnbe ), 187 set zero instruction ( setz ), 187 set process group ID function, 739 set selection direct-mapped caches, 599fully associative caches, 608set associative caches, 607 seta [IA32/x86-64] set unsigned greater, 187 setae [IA32/x86-64] set unsigned greater equal, 187 setb [IA32/x86-64] set unsigned less, 187 setbe [IA32/x86-64] set unsigned less equal, 187 sete [IA32/x86-64] set equal, 187 setenv [Unix] create/change environment variable, 732 setg [IA32/x86-64] set greater, 187 setge [IA32/x86-64] set greater equal, 187 setjmp [C Stdlib] initialzie nonlocal jump, 703, 759, 760 setjmp.c [CS:APP] nonlocal jump example, 761 setl [IA32/x86-64] set less, 187 setle [IA32/x86-64] set less equal, 187 setna [IA32/x86-64] set unsigned greater, 187 setnae [IA32/x86-64] set unsigned less equal,187 setnb [IA32/x86-64] set unsigned less, 187 setnbe [IA32/x86-64] set unsigned less equal, 187 setne [IA32/x86-64] set equal, 187 setng [IA32/x86-64] set greater, 187setnge [IA32/x86-64] set greater equal, 187 setnl [IA32/x86-64] set less, 187 setnle [IA32/x86-64] set less equal, 187 setns [IA32/x86-64] set nonnegative, 187 setnz [IA32/x86-64] set zero, 187 setpgid [Unix] set process group ID,739 sets vs. cache lines, 615membership, 360–361 sets [IA32/x86-64] set negative, 187 setz [IA32/x86-64] set zero, 187 SF[IA32/x86-64/Y86] sign ﬂag condition code, 185, 337 sh[Unix] Unix shell program, 733 Shannon, Claude, 48shared areas, 808 shared libraries, 18,682 dynamic linking with, 681–683 loading linking applications, 683–686 shared object ﬁles, 657 shared objects, 682, 807–809, 808 shared resources, scheduling, 966– 970 shared variables, 954, 954–957 sharing ﬁles, 875–877 virtual memory for, 786 sharing.c [CS:APP] sharing Pthreads programs, 955 shellex.c [CS:APP] shell main routine, 734 shells, 7, 733 shift operations, 54–56 division, 95–98machine language, 179–180for multiplication, 92–95shift arithmetic right instruction, 178 shift left instruction, 178shift logical right instruction, 178 shl[IA32/x86-64] shift left, 178, 180 SHLT [Y86] status code halt ,384 short counts, 8661038 Index short [C] integer data types, 39 ranges, 57 x86-64 processors, 270 shr[IA32/x86-64] shift logical right, 178, 180 %si [x86-64] low-order 16 bits register %rsi , 274 side effects, 479 sigaction [Unix] install portable handler, 752 sigaddset [Unix] add signal signal set, 753 sigdelset [Unix] delete signal signal set, 753 sigemptyset [Unix] clear signal set,753 sigfillset [Unix] add every signal signal set, 753 SIGINT signal, 745 sigint1.c [CS:APP] catches SIGINT signal, 745 sigismember [Unix] test signal set membership, 753 siglongjmp [Unix] initialize nonlocal jump, 759, 760 sign bits ﬂoating-point representation, 128two’s-complement representation, 60 sign extension, 72, 72–73 sign ﬂag condition code (SF), 185, 337 sign-magnitude representation, 63 signal function, 743 Signal [CS:APP] portable version ofsignal ,752 signal handlers, 744 installing, 742 signal1.c [CS:APP] ﬂawed signal handler, 747–748 signal2.c [CS:APP] ﬂawed signal handler, 749–750 signal3.c [CS:APP] ﬂawed signal handler, 751 signal4.c [CS:APP] portable signal handling example, 754 signals, 702,736–737 , 736–738 blocking unblocking, 753–754 enabling disabling, 50ﬂow synchronizing, 755–759handling issues, 745–751portable handling, 752–753 processes, 719receiving, 742, 742–745 sending, 738, 739–742 terminology, 738–739Y86 pipelined implementations, 405–406 signed divide instruction, 182, 183, 279 signed integers, 30, 58 alternate representations, 63 shift operations, 55 two’s-complement encoding, 60–65 unsigned conversions, 65–71 signed multiply instruction, 182, 182, 279 signed representations programming advice, 76–79 signed size type, 866 signiﬁcands ﬂoating-point representation, 103 signs ﬂoating-point representa- tion, 103 SIGPIPE signal, 927 sigprocmask [Unix] block unblock signals, 753, 757 sigsetjmp [Unix] initialize nonlocal handler jump, 759, 760 %sil [x86-64] bits 0–7 register %rsi , 274 SimAquarium game, 619SIMD (single-instruction, multiple- data) parallelism, 24–25, 523–524 SIMM (Single Inline Memory Module), 564 simple segregated storage, 836, 836–837 simplicity instruction processing, 365 simultaneous multi-threading, 22single-bit data connections, 377 Single Inline Memory Module (SIMM), 564 single-instruction, multiple-data (SIMD) parallelism, 24–25,523–524 single-precision ﬂoating-point representation IEEE, 103, 104 machine-level data, 168support for, 39 SINS [Y86] status code illegal instruction exception, 384size blocks, 822 caches, 614data, 38–39word, 8,38 size classes, 836 size_t [Unix] unsigned size type, 77–78, 92, 866 size tool, 690 sizeof [C] compute size object, 44, 120–122, 125 sleep [Unix] suspend process, 729 slow system calls, 745 .soﬁles, 682 sockaddr [Unix] generic socket address structure, 902 sockaddr_in [Unix] Internet- style socket address structure, 901–902 socket addresses, 899 socket descriptors, 880, 902 socket function, 902–903 socket pairs, 899 sockets, 874, 899 sockets interface, 900, 900–901 accept function, 907–908 address structures, 901–902 bind function, 904–905 connect function, 903 example, 908–911 listen function, 905 open_clientfd function, 903–904 open_listenfd function, 905– 906 socket function, 902–903 Software Engineering Institute, 92software exceptions C++ Java, 760 ECF for, 703–704 vs. hardware, 704 Solaris, 15 ELF, 658 Sun Microsystems operating system, 44 solid-state disks (SSDs), 571, 581 beneﬁts, 567operation, 581–583 sorting performance, 544 source ﬁles, 3 source hosts, 889 source programs, 3 southbridge chipsets, 568Soviet Union, 900Index 1039 %sp [x86-64] low-order 16 bits stack pointer register %rsp , 274 SPARC 64-bit version, 268ﬁve-stage pipelines, 448–449RISC processors, 343 Sun Microsystems processor, 44 spare cylinders, 576, 581 spare sectors, 581spatial locality, 587 caches, 625–629 exploiting, 595 special arithmetic operations, 182– 185, 278–279 special control conditions Y86 pipelining detecting, 436–437handling, 432–436 speciﬁers, operand, 169–170speculative execution, 498, 499, 527 speedup parallel programs, 977, 978 spilling, register, 240, 240–241, 525–526 spindles, disks, 570 %spl [x86-64] bits 0–7 stack pointer register %rsp , 274 splitting free blocks, 823memory blocks, 820 sprintf [C Stdlib] function, 43, 259 Sputnik, 900 squashing mispredicted branch handling, 434 SRAM (Static RAM), 13,561, 561–562 cache. Seecaches cache memory vs. DRAM, 562trends, 584–585 SRAM cells, 561 srand [CS:APP] pseudo-random number generator seed, 980 SSDs (solid-state disks), 571, 581 beneﬁts, 567 operation, 581–583 SSE (Streaming SIMD Extensions) instructions, 156–157 data alignment exceptions, 249 parallelism, 523–524 SSE2 (Streaming SIMD Extensions, version 2), 292–293 ssize_t [Unix] signed size type, 866stack corruption detection, 263–265 stack frames, 219, 219–221 alignment on, 249x86-64 processors, 284–287 stack pointers, 219, 289 stack protectors, 263 stack randomization, 261–262stacks, 18,172, 172–174 buffer overﬂow, 844 byte alignment, 226 execve function, 731–732 machine-level programs, 161 overﬂow. Seebuffer overﬂow recursive procedures, 229–232Y86 pipelining, 408 stages, SEQ, 364–375 decode write-back, 385–387 execute, 387–389fetch, 383–385memory stage, 389–390PC update, 390 stalling, pipeline, 413–415, 437–438 Stallman, Richard, 6, 15standard C library, 4, 4–5 standard error ﬁles, 863 standard I/O library, 879, 879–880 standard input ﬁles, 863 standard output ﬁles, 863 startup code, 680 starvation readers-writers problem, 969 stat [Unix] fetch ﬁle metadata, 873 state machines, 942 states bistable memory, 561 deadlock, 986 processor, 703 programmer-visible, 336, 336–337 progress graphs, 961 state machines, 942 static libraries, 667, 667–672 static linkers, 657 static linking, 657 Static RAM (SRAM), 13,561, 561–562 cache. Seecaches cache memory vs. DRAM, 562trends, 584–585 static [C] variable function attribute, 660, 661, 956 static Web content, 912 status code registers, 413status codes HTTP, 916 Y86, 344–345, 345 status messages HTTP, 916 STDERR_FILENO [Unix] constant standard error descriptor, 863 stderr stream, 879 STDIN_FILENO [Unix] constant standard input descriptor, 863 stdin stream, 879 stdint.h ﬁle, 63 stdio.h [Unix] standard I/O library header ﬁle, 77–78 stdlib ,4, 4–5 STDOUT_FILENO [Unix] constant standard output descriptor, 863 stdout stream, 879 stepi command GDB, 255 Stevens, W. Richard, 873, 882, 928, 999 stopped processes, 719 storage. Seeinformation storage storage classes variables, 956 storage device hierarchy, 13–14store buffers, 534–535store instructions, 10store operations, 499 store performance memory, 532–537 strace tool, 762 straight-line code, 185 strcat function, 259 strcpy function, 259 Streaming SIMD Extensions (SSE) instructions, 156–157 data alignment exceptions, 249parallelism, 523–524 Streaming SIMD Extensions, version 2 (SSE2), 292–293 streams, 879 buffers, 879–880full duplex, 880 strerror function, 718 stride-1 reference patterns, 588 stride-k reference patterns, 588 string repeat instruction ( rep), 281 strings buffer overﬂow, 256–259 length, 77lowercase conversions, 487–489representing, 46–47 strings tool, 690 strip tool, 6901040 Index strlen function, 77, 487–489 strong scaling, 977 strong symbols, 664 .strtab section, 659 strtok function, 982–983 struct [C] structure data type, 241 structures address, 901–902heterogeneous. Seeheterogeneous data structures machine-level programs, 161x86-64 processors, 290–291 sub[IA32/x86-64] subtract, 178 subdomains, 896 subl [Y86] subtract, 338, 367 substitution, inline, 479 subtract instruction ( sub), 178, 338 subtract operation execute stage, 387 sumarraycols [CS:APP] column- major sum, 617 sumarrayrows [CS:APP] row-major sum, 617, 617–618 sumvec [CS:APP] vector sum, 616, 616–617 Sun Microsystems, 44 ﬁve-stage pipelines, 448–449RISC processors, 343security vulnerability, 91–92 SPARC architecture, 268 workstations, 268 supercells, 562, 563–564 superscalar processors, 24, 448–449, 497 supervisor mode, 715 surfaces, disks, 570, 575 suspend process function, 729 suspend signal arrives function, 730 suspended processes, 719 swap areas, 807 swap ﬁles, 807 swap space, 807 swapped pages, 783 swapped pages, 783 swapping pages, 783 sweep phase Mark&Sweep garbage collectors, 840 Swift, Jonathan, 40–41 switch [C] multiway branch statement, 213–219 switches, context, 716–717symbol resolution, 657, 663–664 multiply deﬁned global symbols, 664–667 static libraries, 667–672 symbol tables, 659, 660–662 symbolic methods, 443 symbols address translation, 788caches, 598relocation, 672–678strong weak, 664 .symtab section, 659 synchronization ﬂow, 755–759Java threads, 970progress graphs, 962 threads, 957–960 progress graphs, 960–963with semaphores. See semaphores synchronization errors, 957 synchronous DRAM (SDRAM), 566 /sys ﬁlesystem, 716 syscall function, 710 system bus, 568 system calls, 17,707, 707–708 error-handling, 717–718Linux/IA32 systems, 710–711slow, 745 system-level functions, 710 system-level I/O closing ﬁles, 865ﬁle metadata, 873–875I/O redirection, 877–879 opening ﬁles, 863–865 packages summary, 880–881reading ﬁles, 865–866riopackage, 867–873 sharing ﬁles, 875–877 standard, 879–880 summary, 881–882Unix I/O, 862–863writing ﬁles, 866–867 System V Unix, 15 ELF, 658 semaphores, 937shared memory, 937 T2B (two’s complement binary conversion), 66 T2U (two’s complement unsigned conversion), 66, 66–69tables descriptor, 875–876, 878 exception, 704, 705 GOTs, 687, 688–690 hash, 544–545header, 658,678, 678–679 jump, 213, 216, 705 page, 716, 780, 780–781, 792–794, 797 segment header, 678, 678–679 symbol, 659, 660–662 tag bits, 596–597 , 598 tags, boundary, 824–826, 825,833 targets, jump, 190, 190–193 TCP (Transmission Control Protocol), 892 TCP/IP (Transmission Control Protocol/Internet Protocol),892 tcsh [Unix] Unix shell program, 733 telnet remote login program, 914 temporal locality, 587 blocking for, 629 exploiting, 595 terabytes, 271terminate another thread function, 951 terminate current thread function, 950 terminate process function, 719 terminated processes, 719 terminating processes, 719–723threads, 950–951 test [IA32/x86-64] test, 186, 280 test byte instruction ( testb ), 186 test double word instruction ( testl ), 186 test instructions, 186, 280test quad word instruction ( testq ), 280 test signal set membership function, 753 test word instruction ( testw ), 186 testb [IA32/x86-64] test byte, 186 testing Y86 pipeline design, 442–443 testl [IA32/x86-64] test double word, 186 testq [IA32/x86-64] test quad word, 280 testw [IA32/x86-64] test word, 186 text ﬁles, 3, 870Index 1041 text lines, 868 text representation ASCII, 46 Unicode, 47 .text section, 658 Thompson, Ken, 15 thrashing direct-mapped caches, 604 pages, 784 thread contexts, 947,955 thread IDs (TIDs), 947 thread-level concurrency, 22–23thread-level parallelism, 23thread routines, 949–950 thread-safe functions, 979, 979–981 thread-unsafe functions, 979, 979– 980 threads, 17,935,947, 947–948 concurrent server based on, 952–954 creating, 950detaching, 951–952execution model, 948initializing, 952 library functions for, 982–983 mapping variables in, 956memory models, 955–956for parallelism, 974–978Posix, 948–949 races, 983–985 reaping, 951safety issues, 979–980shared variables with, 954, 954– 957 synchronizing, 957–960 progress graphs, 960–963with semaphores. See semaphores terminating, 950–951 throughput, 501 dynamic memory allocators, 818 pipelining for. Seepipelining read, 621 throughput bounds, 497, 502 TIDs (thread IDs), 947 time slicing, 713 timing, SEQ, 379–383tiny [CS:APP] Web server, 919, 919–927 TLB index (TLBI), 791 TLB tags (TLBT), 791, 797 TLBI (TLB index), 791TLBs (translation lookaside buffers), 448, 791, 791–797 TLBT (TLB tags), 791, 797 TMax (maximum two’s-complement number), 61,6 2 TMin (minimum two’s-complement number), 61, 62, 71 top stack, 172, 173 toptool, 762 Torvalds, Linus, 19 touching pages, 807 TRACE method, 915tracing execution, 367, 369–370, 373–375, 382 track density disks, 571 tracks, disks, 571, 575 trajectories progress graphs, 961, 962 transactions bus, 567, 568–570 client-server model, 886 client-server vs. database, 887 HTTP, 914–916 transfer time disks, 574 transfer units, 593 transferring control, 221–223 transformations, reassociation, 511, 518, 518–523, 548 transistors Moore’s Law, 158–159transitions progress graphs, 961 state machines, 942 translating programs, 4–5translation address. Seeaddress translation binary, 691–692 switch statements, 213 translation lookaside buffers (TLBs), 448, 791, 791–797 Transmission Control Protocol (TCP), 892 Transmission Control Proto- col/Internet Protocol (TCP/IP), 892 trap exception class, 706 traps, 707, 707–708 tree height reduction, 548 tree structure, 245–246 truncating numbers, 75–76two-operand multiply instructions, 182 two-way parallelism, 514–515two’s-complement representation addition, 83, 83–87 asymmetric range, 61–62, 71bit-level representation, 88 encodings, 30maximum value, 61 minimum value, 61multiplication, 89, 89–92 negation, 87, 87–88 signed unsigned conversions, 65–69 signed numbers, 60, 60–65 typedef [C] type deﬁnition, 42, 43 types conversions. Seeconversions ﬂoating point, 114–117 IA32, 167–168integral, 57, 57–58 machine-level, 161, 167–168MIME, 912 naming, 43 pointers, 33–34, 252x86-64 processors, 270–271 U2B (unsigned binary conversion), 66,6 8 U2T (unsigned two’s-complement conversion), 66, 69, 76 UDP (Unreliable Datagram Protocol), 892 UINTN_MAX [C] maximum value N-bit unsigned data type, 62 uintN_t[C]N-bit unsigned integer data type, 63 umask function, 864–865 UMax (maximum unsigned number), 59, 61–62 unallocated pages, 779 unary operations, 178–179 unblocking signals, 753–754unbuffered input output, 867–868uncached pages, 780underﬂow, gradual, 105 Unicode characters, 47 uniﬁed caches, 612 Uniform Resource Identiﬁers (URIs), 915 uninitialized memory, reading, 843–844 unions, 244–248uniprocessor systems, 16, 22United States, ARPA creation in, 9001042 Index Universal Resource Locators (URLs), 913 Universal Serial Bus (USB), 577 Unix 4.xBSD, 15, 901 unix_error [CS:APP] reports Unix-style errors, 718, 1001 Unix IPC, 937 Unix operating systems, 15,3 2 constants, 725 error-handling, 1000 , 1001 I/O, 19,862, 862–863 static libraries, 668 Unix signals, 736 unlocking mutexes, 964 unmap disk object function, 812 Unreliable Datagram Protocol (UDP), 892 unrolling loops, 480, 482, 509, 509–513, 551 unsafe regions progress graphs, 962 unsafe trajectories progress graphs, 962 unsetenv [Unix] delete environment variable, 732 unsigned data types, 57 unsigned representations, 76–79 addition, 79–83, 82 conversions, 65–71 divide instruction, 182, 184, 279 encodings, 30, 58–60, 59 multiplication, 88,182, 182, 279 unsigned size type, 866 update instructions, 10 URIs (Uniform Resource Identiﬁers), 915 URLs (Universal Resource Locators), 913 USB (Universal Serial Bus), 577 user-level memory mapping, 810– 812 user mode, 706 processes, 714–716, 715 regular functions in, 708 user stack, 18 UTF-8 characters, 47 v-node tables, 875 V semaphore operation, 963, 964 V[CS:APP] wrapper function Posix sem_post, 963, 964 VA. Seevirtual addresses (VA) valgrind program, 548valid bit cache lines, 596, 597 page tables, 781 values function parameters passed by, 226 pointers, 34, 252 variable-sized arrays, 238–241variables mapping, 956nonexistent, 846 shared, 954, 954–957 stack, 226–228storage classes, 956 VAX computer, 53vector data types, 24, 482–485 vector dot product function, 603 vector sum function, 616, 616–617 vectors, bit, 48, 49–50 veriﬁcation pipelining, 443–444 Verilog hardware description language logic design, 353Y86 pipelining implementation, 444 vertical bars ||for oroperation, 353 Large Instruction Word (VLIW) format, 269 VHDL hardware description language, 353 victim blocks, 594 Video RAM (VRAM), 566 virtual address spaces, 17, 33, 778 virtual addresses (VA) machine-level programming, 160–161 vs. physical, 777–778Y86, 337 virtual machines abstraction, 25Java byte code, 293 virtual memory (VM), 17, 33, 776 abstraction, 25 address spaces, 778–779 address translation. Seeaddress translation bugs, 843–847for caching, 779–784 characteristics, 776–777 Core i7, 799–803dynamic memory allocation. See dynamic memory allocation garbage collection, 838–842Linux, 803–807 loading, 681mapping. Seememory mapping memory management, 785–786 memory protection, 786–787 overview, 17–19physical vs. virtual addresses, 777–778 summary, 848 virtual page numbers (VPNs), 788 virtual page offset (VPO), 788 virtual pages (VPs), 266, 779, 779–780 viruses, 261–262VLIW (Very Large Instruction Word) format, 269 VM. Seevirtual memory (VM) void* [C] untyped pointers, 44 VP (virtual pages), 266, 779, 779–780 VPNs (virtual page numbers), 788 VPO (virtual page offset), 788 VRAM (Video RAM), 566 vtune program, 548, 692 vulnerabilities, security, 78–79 wait [Unix] wait child process, 726 wait child process functions, 724, 726, 726–729 wait client connection request function, 907, 907–908 wait I/O events function, 939 wait.h ﬁle, 725 wait sets, 724, 724 waitpid [Unix] wait child process, 724, 726–729 waitpid1 [CS:APP] waitpid example, 727 waitpid2 [CS:APP] waitpid example, 728 WANs (wide area networks), 889, 889–890 warming caches, 594 weak scaling, 978 weak symbols, 664 wear leveling logic, 583Web clients, 911, 912 Web servers, 684, 911 basics, 911–912dynamic content, 916–919HTTP transactions, 914–916tiny example, 919–927 Web content, 912–914 well-known ports, 899Index 1043 [C] loop statement, 200–203 wide area networks (WANs), 889, 889–890 WIFEXITED constant, 725WIFEXITSTATUS constant, 725WIFSIGNALED constant, 725 WIFSTOPPED constant, 725 Windows operating system, 44, 249wire names hardware diagrams, 377 WNOHANG constant, 724–725 word-level combinational circuits, 355–360 word selection direct-mapped caches, 600fully associative caches, 608 set associative caches, 607–608 word size, 8,38 words, 8 machine-level data, 167x86-64 processors, 270, 277 working sets, 595,784 world-wide data connections hardware diagrams, 377 World Wide Web, 912worm programs, 260–262 wrappers, error-handling, 718,999, 1001–1003 write [Unix] write ﬁle, 865, 866–867 write access, 266write-allocate approach, 612 write-back approach, 612 write-back stage instruction processing, 364, 366, 368–377 PIPE processor, 426–429 SEQ, 385–387 write hits, 612 write issues caches, 611–612write-only registers, 504 write operations ﬁles, 863, 866–867write ports priorities, 387register ﬁles, 362 write/read dependencies, 534–536 write strategies caches, 615 write-through approach, 612 write transactions, 567, 569–570 writen function, 873 writers readers-writers problem, 969–970 writing operations, SSDs, 582–583WSTOPSIG constant, 725WTERMSIG constant, 725 WUNTRACED constant, 724–725 x86 microprocessor line, 156 x86-64 microprocessors, 44, 156, 158, 267 argument passing, 283–284 arithmetic instructions, 277–279assembly-code example, 271–273control instructions, 279–282 data structures, 290–291 data types, 270–271ﬂoating-point code, 492history motivation, 268–269information access, 273–277 machine language, 155–156 overview, 267–268, 270procedures, 282register saving conventions, 287–290 registers, 273–275 stack frames, 284–287summary, 291 x87 ﬂoating-point architecture, 156–157, 292 XDR library, 91–92 Xeon microprocessors, 269XMM registers, 492Xor [IA32/x86-64] exclusive-or, 178 xorl [Y86] exclusive-or, 338Y86 instruction set architecture, 335–336 CISC vs. RISC, 342–344details, 350–352 exception handling, 344–345vs. IA32, 342instruction encoding, 339–342 instruction set, 337–339 programmer-visible state, 336–337programs, 345–350sequential implementation. See sequential Y86 implementation Y86 pipelined implementations, 400 computation stages, 400–401control logic. Seecontrol logic pipelining exception handling, 420–423 hazards. Seehazards pipelining memory system interfacing, 447–448 multicycle instructions, 446–447performance analysis, 444–446 predicted values, 406–408 signals, 405–406stages. SeePIPE processor stages testing, 442–443 veriﬁcation, 443–444 Verilog, 444 yasY86 assembler, 348–349 yisY86 instruction set simulator, 348 zero extension, 72 zero ﬂag condition code (ZF), 185, 337 ZF[IA32/x86-64/Y86] zero ﬂag condition code, 185, 337 zombie processes, 723, 723–724, 746 zones maps, 580–581 recording, 572