Computer organization arChite Cture Designing Performance tenth editionThis page intentionally left blank Computer organization arChite Cture Designing Performance tenth edition William Stallings Boston • Columbus • Hoboken • Indianapolis • New York • San Francisco Amsterdam • Cape Town • Dubai • London • Madrid • Milan • Munich • Paris • Montreal Toronto • Delhi • Mexico City • São Paulo • Sydney • Hong Kong • Seoul • Singapore • Taipei • TokyoWith contribution Peter Zeno University Bridgeport Foreword Chris Jesshope Professor (emeritus) University AmsterdamCopyright © 2016, 2013, 2010 Pearson Education, Inc., Hoboken, NJ 07030. rights reserved. Manufactured United States America. publication protected Copyright permissions obtained publisher prior prohibited reproduction, storage retrieval system, transmission form means, electronic, mechanical, photocopying, recording, likewise. obtain permission(s) use materials work, please submit written request Pearson Higher Education, Permissions Department, 221 River Street, Hoboken, NJ 07030. Many designations manufacturers seller distinguish products claimed trademarks. designations appear book, publisher aware trademark claim, designations printed initial caps caps. Credits acknowledgments borrowed sources reproduced, permission, textbook appears page 833. author publisher book used best efforts preparing book. efforts include development, research, testing theories programs determine effectiveness. author publisher make warranty kind, expressed implied, regard programs documentation contained book. author publisher shall liable event incidental consequential damages with, arising of, furnishing, performance, use programs. Pearson Education Ltd., London Pearson Education Australia Ply. Ltd., Sydney Pearson Education Singapore, Pte. Ltd. Pearson Education North Asia Ltd., Hong Kong Pearson Education Canada, Inc., Toronto Pearson Education de Mexico, S.A. de C.V . Pearson Education–Japan, Tokyo Pearson Education Malaysia, Pte. Ltd. Pearson Education, Inc., Hoboken, New Jersey Library Congress Cataloging- in- Publication Data Stallings, William. Computer organization architecture : designing performance / William Stallings. — Tenth edition. pages cm Includes bibliographical references index. ISBN 978-0-13-410161 -3 — ISBN 0-13-410161 -8 1. Computer organization. 2. Computer architecture. I. Title. QA76.9.C643S73 2016 004.2'2—dc23 2014044367Vice President Editorial Director, ECS: Marcia J. Horton Executive Editor: Tracy Johnson (Dunkelberger) Editorial Assistant: Kelsey Loanes Program Manager: Carole Snyder Director Product Management: Erin Gregg Team Lead Product Management: Scott Disanno Project Manager: Robert Engelhardt Media Team Lead: Steve Wright R&P Manager: Rachel Youdelman R&P Senior Project Manager: Timothy Nicholls Procurement Manager: Mary Fischer Senior Specialist, Program Planning Support: Maura Zaldivar-GarciaInventory Manager: Bruce Boundy VP Marketing: Christy Lesko Director Field Marketing: Demetrius Hall Product Marketing Manager: Bram van Kempen Marketing Assistant: Jon Bryant Cover Designer: Marta Samsel Cover Art: © anderm / Fotolia Full-Service Project Management: Mahalatchoumy Saravanan, Jouve India Printer/Binder: Edwards Brothers Malloy Cover Printer: Lehigh-Phoenix Color/Hagerstown Typeface: Times Ten LT Std 10/12 ISBN-10: 0-13-410161 -8 ISBN-13: 978-0-13-410161 -3 www.pearsonhighered.com10 9 8 7 6 5 4 3 2 1To Tricia loving wife, kindest gentlest personThis page intentionally left blank vii Foreword xiii Preface xv Author xxiii PART ONE INTRODUCTION 1 Chapter 1 Basic Concepts Computer Evolution 1 1.1 Organization Architecture 2 1.2 Structure Function 3 1.3 Brief History Computers 11 1.4 Evolution Intel x86 Architecture 27 1.5 Embedded Systems 29 1.6 Arm Architecture 33 1.7 Cloud Computing 39 1.8 Key erms, Review Questions, Problems 42 Chapter 2 Performance Issues 45 2.1 Designing Performance 46 2.2 Multicore, Mics, GPGPUs 52 2.3 wo Laws Provide Insight: Ahmdahl’s Law Little’s Law 53 2.4 Basic Measures Computer Performance 56 2.5 Calculating Mean 59 2.6 Benchmarks Spec 67 2.7 Key erms, Review Questions, Problems 74 PART TWO COMPUTER SYSTEM 80 Chapter 3 Top- Level View Computer Function Interconnection 80 3.1 Computer Components 81 3.2 Computer Function 83 3.3 Interconnection Structures 99 3.4 Bus Interconnection 100 3.5 Point- to- Point Interconnect 102 3.6 PCI Express 107 3.7 Key erms, Review Questions, Problems 116 Chapter 4 Cache Memory 120 4.1 Computer Memory System Overview 121 4.2 Cache Memory Principles 128 4.3 Elements Cache Design 131 4.4 Pentium 4 Cache Organization 149 4.5 Key erms, Review Questions, Problems 152 Appendix 4A Performance Characteristics wo- Level Memories 157Contentsviii Contents Chapter 5 Internal Memory 165 5.1 Semiconductor Main Memory 166 5.2 Error Correction 174 5.3 DDR DRAM 180 5.4 Flash Memory 185 5.5 Newer Nonvolatile Solid- State Memory echnologies 187 5.6 Key erms, Review Questions, Problems 190 Chapter 6 External Memory 194 6.1 Magnetic Disk 195 6.2 RAID 204 6.3 Solid State Drives 212 6.4 Optical Memory 217 6.5 Magnetic Tape 222 6.6 Key erms, Review Questions, Problems 224 Chapter 7 Input/Output 228 7.1 External Devices 230 7.2 I/O Modules 232 7.3 Programmed I/O 235 7.4 Interrupt- Driven I/O 239 7.5 Direct Memory Access 248 7.6 Direct Cache Access 254 7.7 I/O Channels Processors 261 7.8 External Interconnection Standards 263 7.9 IBM zEnterprise EC12 I/O Structure 266 7.10 Key erms, Review Questions, Problems 270 Chapter 8 Operating System Support 275 8.1 Operating System Overview 276 8.2 Scheduling 287 8.3 Memory Management 293 8.4 Intel x86 Memory Management 304 8.5 Arm Memory Management 309 8.6 Key erms, Review Questions, Problems 314 PART THREE ARITHMETIC LOGIC 318 Chapter 9 Number Systems 318 9.1 Decimal System 319 9.2 Positional Number Systems 320 9.3 Binary System 321 9.4 Converting Binary Decimal 321 9.5 Hexadecimal Notation 324 9.6 Key erms Problems 326 Chapter 10 Computer Arithmetic 328 10.1 Arithmetic Logic Unit 329 10.2 Integer Representation 330 10.3 Integer Arithmetic 335Contents ix 10.4 Floating- Point Representation 350 10.5 Floating- Point Arithmetic 358 10.6 Key erms, Review Questions, Problems 367 Chapter 11 Digital Logic 372 11.1 Boolean Algebra 373 11.2 Gates 376 11.3 Combinational Circuits 378 11.4 Sequential Circuits 396 11.5 Programmable Logic Devices 405 11.6 Key erms Problems 409 PART FOUR CENTRAL PROCESSING UNIT 412 Chapter 12 Instruction Sets: Characteristics Functions 412 12.1 Machine Instruction Characteristics 413 12.2 ypes Operands 420 12.3 Intel x86 ARM Data ypes 422 12.4 ypes Operations 425 12.5 Intel x86 ARM Operation ypes 438 12.6 Key erms, Review Questions, Problems 446 Appendix 12A Little-, Big-, Bi- Endian 452 Chapter 13 Instruction Sets: Addressing Modes Formats 456 13.1 Addressing Modes 457 13.2 x86 ARM Addressing Modes 463 13.3 Instruction Formats 469 13.4 x86 ARM Instruction Formats 477 13.5 Assembly Language 482 13.6 Key erms, Review Questions, Problems 484 Chapter 14 Processor Structure Function 488 14.1 Processor Organization 489 14.2 Register Organization 491 14.3 Instruction Cycle 496 14.4 Instruction Pipelining 500 14.5 x86 Processor Family 517 14.6 ARM Processor 524 14.7 Key erms, Review Questions, Problems 530 Chapter 15 Reduced Instruction Set Computers 535 15.1 Instruction Execution Characteristics 537 15.2 Use Large Register File 542 15.3 Compiler- Based Register Optimization 547 15.4 Reduced Instruction Set Architecture 549 15.5 RISC Pipelining 555 15.6 MIPS R4000 559 15.7 SPARC 565 15.8 RISC versus CISC Controversy 570 15.9 Key erms, Review Questions, Problems 571x Contents Chapter 16 Instruction- Level Parallelism Superscalar Processors 575 16.1 Overview 576 16.2 Design Issues 581 16.3 Intel Core Microarchitecture 591 16.4 ARM Cortex- A8 596 16.5 ARM Cortex- M3 604 16.6 Key erms, Review Questions, Problems 608 PART FIVE PARALLEL ORGANIZATION 613 Chapter 17 Parallel Processing 613 17.1 Multiple Processor Organizations 615 17.2 Symmetric Multiprocessors 617 17.3 Cache Coherence MESI Protocol 621 17.4 Multithreading Chip Multiprocessors 628 17.5 Clusters 633 17.6 Nonuniform Memory Access 640 17.7 Cloud Computing 643 17.8 Key erms, Review Questions, Problems 650 Chapter 18 Multicore Computers 656 18.1 Hardware Performance Issues 657 18.2 Software Performance Issues 660 18.3 Multicore Organization 665 18.4 Heterogeneous Multicore Organization 667 18.5 Intel Core i7-990X 676 18.6 ARM Cortex- A15 MPCore 677 18.7 IBM zEnterprise EC12 Mainframe 682 18.8 Key erms, Review Questions, Problems 685 Chapter 19 General- Purpose Graphic Processing Units 688 19.1 Cuda Basics 689 19.2 GPU versus CPU 691 19.3 GPU Architecture Overview 692 19.4 Intel’s Gen8 GPU 701 19.5 Use GPU Coprocessor 704 19.6 Key erms Review Questions 706 PART SIX CONTROL UNIT 707 Chapter 20 Control Unit Operation 707 20.1 Micro- Operations 708 20.2 Control Processor 714 20.3 Hardwired Implementation 724 20.4 Key erms, Review Questions, Problems 727 Chapter 21 Microprogrammed Control 729 21.1 Basic Concepts 730 21.2 Microinstruction Sequencing 739Contents xi 21.3 Microinstruction Execution 745 21.4 TI 8800 755 21.5 Key erms, Review Questions, Problems 766 Appendix Projects Teaching Computer Organization Architecture 768 A.1 Interactive Simulations 769 A.2 Research Projects 771 A.3 Simulation Projects 771 A.4 Assembly Language Projects 772 A.5 Reading/Report Assignments 773 A.6 Writing Assignments 773 A.7 est Bank 773 Appendix B Assembly Language Related Topics 774 B.1 Assembly Language 775 B.2 Assemblers 783 B.3 Loading Linking 787 B.4 Key erms, Review Questions, Problems 795 References 800 Index 809 Credits 833 1Online chapters, appendices, documents Premium Content, available via access card front book.ONLINE APPENDICES1 Appendix C System Buses Appendix Protocols Protocol Architectures Appendix E Scrambling Appendix F Victim Cache Strategies Appendix G Interleaved Memory Appendix H International Reference Alphabet Appendix Stacks Appendix J Thunderbolt Infiniband Appendix K Virtual Memory Page Replacement Algorithms Appendix L Hash Tables Appendix Recursive Procedures Appendix N Additional Instruction Pipeline Topics Appendix Timing Diagrams Glossary page intentionally left blank xiii Chris Jesshope Professor (emeritus) University Amsterdam Author Parallel Computers (with R W Hockney), 1981 & 1988 active computer organization architecture many years, pleas - ure write foreword new edition William Stallings’ comprehensive book subject. this, found reflecting trends changes subject time involved it. became interested computer archi - tecture time significant innovation disruption. disruption brought advances technology perhaps significantly access technology. VLSI VLSI design available students classroom. exciting times. ability integrate mainframe style computer single silicon chip milestone, accomplished academic research team made achievement quite unique. period characterized innovation diver - sity computer architecture one main trends area parallelism. 1970s, hands- experience Illiac IV, early example explicit parallelism computer architecture incidentally pioneered semicon - ductor memory. interaction, certainly that, kick- started interest computer architecture organization, particular emphasis explicit parallelism computer architecture. Throughout 1980s early 1990s research flourished field great deal innovation, much came market university start- ups. Iron - ically however, technology reversed trend. Diversity gradually replaced near monoculture computer systems advances instruc - tion set architectures. Moore’s law, self- fulfilling prediction became industry guide - line, meant basic device speeds integration densities grew exponentially, latter doubling every 18 months so. speed increase proverbial free lunch computer architects integration levels allowed complexity innovation micro- architecture level. free lunch course cost, expo - nential growth capital investment required fulfill Moore’s law, limited access state- of- the- art technologies. Moreover, users found easier wait next generation mainstream processor invest innovations parallel computers, pitfalls difficulties. exceptions large insti - tutions requiring ultimate performance; two topical examples large- scale scientific simulation climate modeling also security services code breaking. Forewordxiv Foreword everyone else, name game compatibility two instruction set architectures benefited x86 ARM, latter embedded systems former everything else. Parallelism still implementation ISAs, implicit, harnessed architecture instruction stream drives it. Throughout late 1990s early 2000s, approach implicitly exploiting con - currency single- core computer systems flourished. However, spite exponential growth logic density, cost techniques exploited brought era close. superscalar processors, logic costs grow linearly issue width (par - allelism), components grow square even cube issue width. Although exponential growth logic could sustain continued development, two major pitfalls: increasingly difficult expose concurrency implicitly imperative programs hence efficiencies use instruction issue slots decreased. Perhaps importantly, technology experiencing new barrier performance gains, namely power dissipation, several superscalar developments halted silicon would hot. constraints mandated exploitation explicit parallelism, despite compatibility challenges. seems innovation diversity opening area new research. Perhaps since 1980s interesting study field. diver - sity economic reality seen decrease issue width (implicit parallelism) increase number cores (explicit parallelism) mainstream processors. - ever, question exploit this, application system level. significant challenges still solved. Superscalar processors rely processor extract parallelism single instruction stream. shifted emphasis provided instruction stream maximum parallelism, exploit dif - ferent configurations and/or generations processors require different levels expli - cit parallelism? possible therefore micro- architecture sequentializes schedules maximum concurrency captured ISA match current configur - ation cores gain compatibility world explicit parallelism? require operating systems silicon efficiency? questions facing us today. answer questions requires sound foundation computer organization architecture, book William Stallings provides timely comprehensive foundation. gives com - plete introduction basics required, tackling quite complex topics apparent simplicity. Moreover, deals recent developments field, innovation past, is, currently taking place. Examples superscalar issue explicitly parallel multicores. more, latest edition includes two recent topics design use GPUs general- purpose use latest trends cloud computing, become mainstream recently. book makes good use examples throughout highlight theoretical issues covered, examples drawn developments two widely used ISAs, namely x86 ARM. reiterate, book complete pleasure read hopefully kick- start young researchers path enjoyed last 40 years!xvWHAT’S NEW TENTH EDITION Since ninth edition book published, field seen continued innovations improvements. new edition, try capture changes maintaining broad comprehensive coverage entire field. begin process revision, ninth edition book extensively reviewed number professors teach subject professionals working field. result that, many places, narrative clarified tightened, illustrations improved. Beyond refinements improve pedagogy user- friendliness, substantive changes throughout book. Roughly chapter organization retained, much material revised new material added. noteworthy changes follows: ■GPGPU [ General- Purpose Computing Graphics Processing Units (GPUs)]: One important new developments recent years broad adoption GPGPUs work coordination traditional CPUs handle wide range applications involving large arrays data. new chapter devoted topic GPGPUs. ■Heterogeneous multicore processors: latest development multicore architecture heterogeneous multicore processor. new section chapter multicore processors surveys various types heterogeneous multicore processors. ■Embedded systems: overview embedded systems Chapter 1 substan - tially revised expanded reflect current state embedded technology. ■Microcontrollers: terms numbers, almost computers use embedded microcontrollers. treatment embedded systems Chapter 1 includes cov - erage microcontrollers. ARM Cortex- M3 microcontroller used example system throughout text. ■Cloud computing: New edition discussion cloud computing, - view Chapter 1 detailed treatment Chapter 17 . ■System performance: coverage system performance issues revised, expanded, reorganized clearer thorough treatment. Chapter 2 devoted topic, issue system performance arises - book.preFaCe xvi PreFACe ■Flash memory: coverage flash memory updated expanded, includes discussion technology organization flash memory internal memory (Chapter 5) external memory (Chapter 6). ■Nonvolatile RAM: New edition treatment three important new nonvolatile solid- state RAM technologies occupy different positions memory hierarchy: STT- RAM, PCRAM, ReRAM. ■Direct cache access (DCA): meet protocol processing demands high speed network connections, Intel manufacturers developed DCA tech - nologies provide much greater throughput traditional direct memory access (DMA) approaches. New edition, Chapter 7 explores DCA detail. ■Intel Core Microarchitecture: previous edition, Intel x86 family used major example system throughout. treatment updated reflect newer Intel systems, especially Intel Core Microarchitecture, used PC server products. ■Homework problems: number supplemental homework problems, solu - tions, available student practice expanded. SUPPORT ACM/IEEE COMPUTER SCIENCE CURRICULA 2013 book intended academic professional audience. textbook, intended one- two- semester undergraduate course computer science, com - puter engineering, electrical engineering majors. edition designed support recommendations ACM/IEEE Computer Science Curricula 2013 (CS2013). CS2013 divides course work three categories: Core- Tier 1 (all topics included curriculum); Core- Tier- 2 (all almost topics included); Elective (desirable provide breadth depth). Architecture Organization (AR) area, CS2013 includes five Tier- 2 topics three Elective topics, number subtopics. text covers eight topics listed CS2013. Table P.1 shows support AR Knowledge Area provided textbook. Table P.1 Coverage CS2013 Architecture Organization (AR) Knowledge Area IAS Knowledge Units Topics Textbook Coverage Digital Logic Digital Systems (Tier 2) ●Overview history computer architecture ●Combinational vs. sequential logic/Field program- mable gate arrays fundamental combinational sequential logic building block ●Multiple representations/layers interpretation (hardware another layer) ●Physical constraints (gate delays, fan- in, fan- out, energy/power)—Chapter 1 —Chapter 11 Machine Level Represen- tation Data (Tier 2) ●Bits, bytes, words ●Numeric data representation number bases ● Fixed- floating- point systems ●Signed twos- complement representations ●Representation non- numeric data (character codes, graphical data)—Chapter 9 —Chapter 10PreFACe xvii IAS Knowledge Units Topics Textbook Coverage Assembly Level Machine Organization (Tier 2) ●Basic organization von Neumann machine ●Control unit; instruction fetch, decode, execution ●Instruction sets types (data manipulation, control, I/O) ●Assembly/machine language programming ●Instruction formats ●Addressing modes ●Subroutine call return mechanisms ( cross- reference PL/Language Translation Execution) ●I/O interrupts ●Shared memory multiprocessors/multicore organization ●Introduction SIMD vs. MIMD Flynn Taxonomy—Chapter 1 —Chapter 7 —Chapter 12 —Chapter 13 —Chapter 17 —Chapter 18 —Chapter 20 —Chapter 21 —Appendix Memory System Organi- zation Architecture (Tier 2) ●Storage systems technology ●Memory hierarchy: temporal spatial locality ●Main memory organization operations ●Latency, cycle time, bandwidth, interleaving ●Cache memories (address mapping, block size, replacement store policy) ●Multiprocessor cache consistency/Using memory system inter- core synchronization/atomic mem- ory operations ●Virtual memory (page table, TLB) ●Fault handling reliability—Chapter 4 —Chapter 5 —Chapter 6 —Chapter 8 —Chapter 17 Interfacing Commu- nication (Tier 2) ●I/O fundamentals: handshaking, buffering, pro- grammed I/O, interrupt- driven I/O ●Interrupt structures: vectored prioritized, inter - rupt acknowledgment ●External storage, physical organization, drives ●Buses: bus protocols, arbitration, direct- memory access (DMA) ●RAID architectures—Chapter 3 —Chapter 6 —Chapter 7 Functional Organization (Elective) ●Implementation simple datapaths, including instruction pipelining, hazard detection, resolution ●Control unit: hardwired realization vs. micropro- grammed realization ●Instruction pipelining ●Introduction instruction- level parallelism (ILP)—Chapter 14 —Chapter 16 —Chapter 20 —Chapter 21 Multiprocessing Alternative Architectures (Elective) ●Example SIMD MIMD instruction sets architectures ●Interconnection networks ●Shared multiprocessor memory systems memory consistency ●Multiprocessor cache coherence—Chapter 12 —Chapter 13 —Chapter 17 Performance Enhance- ments (Elective) ●Superscalar architecture ●Branch prediction, Speculative execution, Out- of- order execution ●Prefetching ●Vector processors GPUs ●Hardware support multithreading ●Scalability—Chapter 15 —Chapter 16 —Chapter 19xviii PreFACe OBJECTIVES book structure function computers. purpose present, clearly completely possible, nature characteristics modern- day computer systems. task challenging several reasons. First, tremendous variety prod - ucts rightly claim name computer, single- chip microprocessors costing dollars supercomputers costing tens millions dollars. Variety exhibited cost also size, performance, application. Second, rapid pace change always characterized computer technology continues letup. changes cover aspects computer technology, underlying integrated circuit technology used construct computer components increasing use parallel organization con - cepts combining components. spite variety pace change computer field, certain fundamental concepts apply consistently throughout. application concepts depends current state technology price/performance objectives designer. intent book provide thorough discussion fundamentals computer organization architecture relate contemporary design issues. subtitle suggests theme approach taken book. always important design computer systems achieve high performance, never requirement stronger difficult satisfy today. basic per - formance characteristics computer systems, including processor speed, memory speed, memory capacity, interconnection data rates, increasing rapidly. Moreover, increasing different rates. makes difficult design balanced system maxi - mizes performance utilization elements. Thus, computer design increasingly becomes game changing structure function one area compensate per - formance mismatch another area. see game played numerous design decisions throughout book. computer system, like system, consists interrelated set components. system best characterized terms structure— way components interconnected, function— operation individual components. Furthermore, computer’s organization hierarchical. major component described decomposing major subcomponents describing structure function. clarity ease understanding, hierarchical organization described book top down: ■Computer system: Major components processor, memory, I/O. ■Processor: Major components control unit, registers, ALU, instruction execu - tion unit. ■Control unit: Provides control signals operation coordination proces - sor components. Traditionally, microprogramming implementation used, major components control memory, microinstruction sequencing logic, registers. recently, microprogramming less prominent remains important implementation technique. objective present material fashion keeps new material clear context. minimize chance reader get lost provide better motivation bottom- approach.PreFACe xix Throughout discussion, aspects system viewed points view architecture (those attributes system visible machine language programmer) organization (the operational units interconnections realize architecture). EXAMPLE SYSTEMS text intended acquaint reader design principles implementation issues contemporary operating systems. Accordingly, purely conceptual theoretical treatment would inadequate. illustrate concepts tie real- world design choices must made, two processor families chosen running examples: ■Intel x86 architecture: x86 architecture widely used nonembedded com - puter systems. x86 essentially complex instruction set computer (CISC) RISC features. Recent members x86 family make use superscalar multicore design principles. evolution features x86 architecture provides unique case- study evolution design principles computer architecture. ■ARM: ARM architecture arguably widely used embedded processor, used cell phones, iPods, remote sensor equipment, many devices. ARM essentially reduced instruction set computer (RISC). Recent members ARM family make use superscalar multicore design principles. Many, means all, examples book drawn two computer families. Numerous systems, contemporary historical, provide examples important computer architecture design features. PLAN TEXT book organized six parts: ■Overview ■The computer system ■Arithmetic logic ■The central processing unit ■Parallel organization, including multicore ■The control unit book includes number pedagogic features, including use interactive sim - ulations numerous figures tables clarify discussion. chapter includes list key words, review questions, homework problems, suggestions reading. book also includes extensive glossary, list frequently used acronyms, bibliography. INSTRUCTOR SUPPORT MATERIALS Support materials instructors available Instructor Resource Center (IRC) textbook, reached publisher’s Web site www.pearsonhighered .com/stallings clicking link labeled “Pearson Resources Instructors” xx PreFACe book’s Companion Web site WilliamStallings.com/ComputerOrganization. gain access IRC, please contact local Pearson sales representative via pearsonhighered.com/ educator/replocator/requestSalesRep.page call Pearson Faculty Services 1-800-526- 0485. IRC provides following materials: ■Projects manual: Project resources including documents portable software, plus suggested project assignments project categories listed subsequently Preface. ■Solutions manual: Solutions end- of- chapter Review Questions Problems. ■PowerPoint slides: set slides covering chapters, suitable use lecturing. ■PDF files: Copies figures tables book. ■Test bank: chapter- by- chapter set questions. ■Sample syllabuses: text contains material conveniently covered one semester. Accordingly, instructors provided several sample syllabuses guide use text within limited time. samples based real- world experience professors first edition. Companion Web site , WilliamStallings.com/ComputerOrganization (click Instructor Resources link) includes following: ■Links Web sites courses taught using book. ■ Sign- information Internet mailing list instructors using book exchange information, suggestions, questions author. STUDENT RESOURCES new edition, tremendous amount original supporting material students made available online, two Web locations. Companion Web Site , WilliamStallings.com/ComputerOrganization (click Student Resources link), includes list relevant links organized chapter errata sheet book. Purchasing textbook new grants reader six months access Premium Content Site , includes following materials: ■Online chapters: limit size cost book, two chapters book provided PDF format. chapters listed book’s table contents. ■Online appendices: numerous interesting topics support material found text whose inclusion warranted printed text. total 13 appen - dices cover topics interested student. appendices listed book’s table contents. ■Homework problems solutions: aid student understanding material, separate set homework problems solutions available. Students enhance understanding material working solutions problems checking answers. PreFACe xxi access Premium Content site, click Premium Content link Companion Web site pearsonhighered.com/stallings enter stu - dent access code found card front book. Finally, maintain Computer Science Student Resource Site WilliamStallings.com/StudentSupport.html . PROJECTS STUDENT EXERCISES many instructors, important component computer organization architec - ture course project set projects student gets hands- experience reinforce concepts text. book provides unparalleled degree support including projects component course. instructor’s support materials available Prentice Hall includes guidance assign structure projects also includes set user’s manuals various project types plus specific assignments, written especially book. Instructors assign work following areas: ■Interactive simulation assignments: Described subsequently. ■Research projects: series research assignments instruct student research particular topic Internet write report. ■Simulation projects: IRC provides support use two simulation pack - ages: SimpleScalar used explore computer organization architecture design issues. SMPCache provides powerful educational tool examining cache design issues symmetric multiprocessors. ■Assembly language projects: simplified assembly language, CodeBlue, used assignments based popular Core Wars concept provided. ■Reading/report assignments: list papers literature, one chapter, assigned student read write short report. ■Writing assignments: list writing assignments facilitate learning material. ■Test bank: Includes T/F, multiple choice, fill- in- the- blank questions answers. diverse set projects student exercises enables instructor use book one component rich varied learning experience tailor course plan meet specific needs instructor students. See Appendix book details. INTERACTIVE SIMULATIONS important feature edition incorporation interactive simulations. simulations provide powerful tool understanding complex design features modern computer system. total 20 interactive simulations used illustrate key functions algorithms computer organization architecture design. relevant point book, icon indicates relevant interactive simulation available online student use. animations enable user set initial conditions, xxii PreFACe serve basis student assignments. instructor’s supplement includes set assignments, one animations. assignment includes several specific prob - lems assigned students. access animations, click rotating globe book’s Web site http://williamstallings.com/ComputerOrganization. ACKNOWLEDGMENTS new edition benefited review number people, gave generously time expertise. following professors instructors reviewed large part manuscript: Molisa Derk (Dickinson State University), Yaohang Li (Old Domin - ion University), Dwayne Ockel (Regis University), Nelson Luiz Passos (Midwestern State University), Mohammad Abdus Salam (Southern University), Vladimir Zwass (Fair - leigh Dickinson University). Thanks also many people provided detailed technical reviews one chapters: Rekai Gonzalez Alberquilla, Allen Baum, Jalil Boukhobza, Dmitry Bufistov, Humberto Calderón, Jesus Carretero, Ashkan Eghbal, Peter Glaskowsky, Ram Huggahalli, Chris Jesshope, Athanasios Kakarountas, Isil Oz, Mitchell Poplingher, Roger Shepherd, Jigar Savla, Karl Stevens, Siri Uppalapati, Dr. Sriram Vajapeyam, Kugan Vivekanandara - jah, Pooria M. Yaghini, Peter Zeno, Peter Zeno also contributed Chapter 19 GPGPUs. Professor Cindy Norris Appalachian State University, Professor Bin Mu Uni - versity New Brunswick, Professor Kenrick Mock University Alaska kindly supplied homework problems. Aswin Sreedhar University Massachusetts developed interactive simula - tion assignments also wrote test bank. Professor Miguel Angel Vega Rodriguez, Professor Dr. Juan Manuel Sánchez Pérez, Professor Dr. Juan Antonio Gómez Pulido, University Extremadura, Spain, prepared SMPCache problems instructor’s manual authored SMPCache User’s Guide. Todd Bezenek University Wisconsin James Stine Lehigh University prepared SimpleScalar problems instructor’s manual, Todd also authored SimpleScalar User’s Guide. Finally, would like thank many people responsible publication book, usual excellent job. includes staff Pearson, par - ticularly editor Tracy Johnson, assistant Kelsey Loanes, program manager Carole Snyder, production manager Bob Engelhardt. also thank Mahalatchoumy Saravanan production staff Jouve India another excellent rapid job. Thanks also marketing sales staffs Pearson, without whose efforts book would front you.xxiii Dr. William Stallings authored 17 textbooks, counting revised editions, 40 books computer security, computer networking, computer archi - tecture. 30 years field, technical contributor, technical manager, executive several high- technology firms. Currently, independent consultant whose clients included computer networking manufac - turers customers, software development firms, leading- edge government research institutions. 13 times received award best computer science textbook year Text Academic Authors Association. created maintains Computer Science Student Resource Site ComputerScienceStudent.com. site provides documents links variety sub - jects general interest computer science students (and professionals). articles appear regularly networking.answers.com, Networking Category Expert Writer. member editorial board Cryptologia , scholarly journal devoted aspects cryptology. Dr. Stallings holds PhD MIT computer science BS Notre Dame electrical engineering.about author page intentionally left blank 1 Chapter Basic concepts computer evolution 1.1 Organization Architecture 1.2 Structure Function Function Structure 1.3 Brief History Computers First Generation: Vacuum Tubes Second Generation: Transistors Third Generation: Integrated Circuits Later Generations 1.4 Evolution Intel x86 Architecture 1.5 Embedded Systems Internet Things Embedded Operating Systems Application Processors versus Dedicated Processors Microprocessors versus Microcontrollers Embedded versus Deeply Embedded Systems 1.6 ARM Architecture ARM Evolution Instruction Set Architecture ARM Products 1.7 Cloud Computing Basic Concepts Cloud Services 1.8 Key Terms, Review Questions, ProblemsPart One introduction2 Chapter 1 / Basi C Con Cepts Computer evolution 1.1 Organizati architecture describing computers, distinction often made computer architec - ture computer organization . Although difficult give precise definitions terms, consensus exists general areas covered each. example, see [VRAN80], [SIEW82], [BELL78a]; interesting alternative view presented [REDD76]. Computer architecture refers attributes system visible pro - grammer or, put another way, attributes direct impact logical execution program. term often used interchangeably com - puter architecture instruction set architecture (ISA) . ISA defines instruction formats, instruction opcodes, registers, instruction data memory; effect executed instructions registers memory; algorithm control - ling instruction execution. Computer organization refers operational units interconnections realize architectural specifications. Examples architectural attributes include instruction set, number bits used repre - sent various data types (e.g., numbers, characters), I/O mechanisms, techniques addressing memory. Organizational attributes include hardware details transparent programmer, control signals; interfaces com - puter peripherals; memory technology used. example, architectural design issue whether computer multiply instruction. organizational issue whether instruction implemented special multiply unit mechanism makes repeated use add unit system. organizational decision may based anticipated frequency use multiply instruction, relative speed two approaches, cost physical size special multiply unit. Historically, still today, distinction architecture organ - ization important one. Many computer manufacturers offer family computer models, architecture differences organization. Consequently, different models family different price perform - ance characteristics. Furthermore, particular architecture may span many years encompass number different computer models, organization changing changing technology. prominent example phenomena IBM System/370 architecture. architecture first introduced 1970 Learning Objectives studying chapter, able to: rExplain general functions structure digital computer. rPresent overview evolution computer technology early digital computers latest microprocessors. rPresent overview evolution x86 architecture. rDefine embedded systems list requirements constraints various embedded systems must meet.1.2 / struCture Fun Ction 3 included number models. customer modest requirements could buy cheaper, slower model and, demand increased, later upgrade expensive, faster model without abandon software already developed. years, IBM introduced many new models improved technology replace older models, offering customer greater speed, lower cost, both. newer models retained architecture customer’s soft - ware investment protected. Remarkably, System/370 architecture, enhancements, survived day architecture IBM’s mainframe product line. class computers called microcomputers, relationship archi - tecture organization close. Changes technology influence organization also result introduction powerful complex architectures. Generally, less requirement generation- to- generation compatibility smaller machines. Thus, interplay organizational architectural design decisions. intriguing example reduced instruction set computer (RISC), examine Chapter 15. book examines computer organization computer architecture. emphasis perhaps side organization. However, computer organization must designed implement particular architectural specification, thorough treatment organization requires detailed examination architecture well. 1.2 Structure Functi computer complex system; contemporary computers contain millions elementary electronic components. How, then, one clearly describe them? key recognize hierarchical nature complex systems, including computer [SIMO96]. hierarchical system set interrelated subsystems, latter, turn, hierarchical structure reach lowest level elementary subsystem. hierarchical nature complex systems essential design description. designer need deal particular level system time. level, system consists set components interrelationships. behavior level depends simplified, abstracted characterization system next lower level. level, designer concerned structure function: ■Structure: way components interrelated. ■Function: operation individual component part structure. terms description, two choices: starting bottom build - ing complete description, beginning top view decomposing system subparts. Evidence number fields suggests top- approach clearest effective [WEIN75]. approach taken book follows viewpoint. computer system described top down. begin major components computer, describing structure function, proceed successively 4 Chapter 1 / Basi C Con Cepts Computer evolution lower layers hierarchy. remainder section provides brief overview plan attack. Function structure functioning computer are, essence, simple. general terms, four basic functions computer perform: ■Data processing: Data may take wide variety forms, range pro - cessing requirements broad. However, shall see fundamental methods types data processing. ■Data storage: Even computer processing data fly (i.e., data come get processed, results go immediately), computer must temporarily store least pieces data worked given moment. Thus, least short- term data storage function. Equally important, computer performs long- term data storage function. Files data stored computer subsequent retrieval update. ■Data movement: computer’s operating environment consists devices serve either sources destinations data. data received delivered device directly connected computer, process known input– output (I/O), device referred peripheral . data moved longer distances, remote device, process known data communications . ■Control: Within computer, control unit manages computer’s resources orchestrates performance functional parts response instructions. preceding discussion may seem absurdly generalized. certainly possible, even top level computer structure, differentiate variety func - tions, quote [SIEW82]: remarkably little shaping computer structure fit function performed. root lies general- purpose nature computers, functional specialization occurs time programming time design. Structure look general way internal structure computer. begin traditional computer single processor employs microprogrammed control unit, examine typical multicore structure. simple single - processor computer Figure 1.1 provides hierarchical view internal structure traditional single- processor computer. four main structural components: ■Central processing unit (CPU): Controls operation computer performs data processing functions; often simply referred processor . ■Main memory: Stores data.1.2 / struCture Fun Ction 5 ■I/O: Moves data computer external environment. ■System interconnection: mechanism provides communication among CPU, main memory, I/O. common example system intercon - nection means system bus , consisting number conducting wires components attach. may one aforementioned components. Tra - ditionally, single processor. recent years, increasing use multiple processors single computer. design issues relat - ing multiple processors crop discussed text proceeds; Part Five focuses computers.Main memoryI/O CPUCOMPUTER System bus ALURegisters Contr ol unitCPU Inter nal bus Contr ol unit registers decodersCONT ROL UNIT Sequencing logic Contr ol memory Figure 1.1 Computer: Top- Level Structure6 Chapter 1 / Basi C Con Cepts Computer evolution components examined detail Part Two. - ever, purposes, interesting ways complex component CPU. major structural components follows: ■Control unit: Controls operation CPU hence computer. ■Arithmetic logic unit (ALU): Performs computer’s data processing functions. ■Registers: Provides storage internal CPU. ■CPU interconnection: mechanism provides communication among control unit, ALU, registers. Part Three covers components, see complexity added use parallel pipelined organizational techniques. Finally, sev - eral approaches implementation control unit; one common approach microprogrammed implementation. essence, microprogrammed control unit operates executing microinstructions define functionality control unit. approach, structure control unit depicted, Figure 1.1. structure examined Part Four. multicore computer structure mentioned, contemporary computers generally multiple processors. processors reside single chip, term multicore computer used, processing unit (consisting control unit, ALU, registers, perhaps cache) called core. clarify terminology, text use following definitions. ■Central processing unit (CPU): portion computer fetches executes instructions. consists ALU, control unit, registers. system single processing unit, often simply referred processor . ■Core: individual processing unit processor chip. core may equiv - alent functionality CPU single- CPU system. specialized pro - cessing units, one optimized vector matrix operations, also referred cores. ■Processor: physical piece silicon containing one cores. processor computer component interprets executes instruc - tions. processor contains multiple cores, referred multicore processor . decade discussion, broad industry consensus usage. Another prominent feature contemporary computers use multiple layers memory, called cache memory , processor main memory. Chapter 4 devoted topic cache memory. purposes section, simply note cache memory smaller faster main memory used speed memory access, placing cache data main memory, likely used near future. greater performance improvement may obtained using multiple levels cache, level 1 (L1) closest core additional levels (L2, L3, on) progressively farther core. scheme, level n smaller faster level n + 1.1.2 / struCture Fun Ction 7 Figure 1.2 simplified view principal components typical mul - ticore computer. computers, including embedded computers smartphones tablets, plus personal computers, laptops, workstations, housed motherboard. describing arrangement, need define terms. printed circuit board (PCB) rigid, flat board holds interconnects chips electronic components. board made layers, typically two ten, interconnect components via copper pathways etched board. main printed circuit board computer called system board motherboard , smaller ones plug slots main board called expansion boards. prominent elements motherboard chips. chip single piece semiconducting material, typically silicon, upon electronic circuits logic gates fabricated. resulting product referred integrated circuit . MOTHERBOARD PROCESSOR CHIP COREProcessor chipMain memory chips I/O chips Core L3 cache Instruction logic L1 I-cache L2 instruction cacheL2 data cacheL1 data cacheArithmetic logic unit (ALU)Load/ store logicL3 cacheCore Core Core Core Core Core Core Figure 1.2 Simplified View Major Elements Multicore Computer8 Chapter 1 / Basi C Con Cepts Computer evolution motherboard contains slot socket processor chip, typ - ically contains multiple individual cores, known multicore processor . also slots memory chips, I/O controller chips, key computer components. desktop computers, expansion slots enable inclusion components expansion boards. Thus, modern motherboard connects individual chip components, chip containing thousand hundreds millions transistors. Figure 1.2 shows processor chip contains eight cores L3 cache. shown logic required control operations cores cache cores external circuitry motherboard. figure indicates L3 cache occupies two distinct portions chip surface. However, typically, cores access entire L3 cache via aforemen - tioned control circuits. processor chip shown Figure 1.2 represent specific product, provides general idea chips laid out. Next, zoom structure single core, occupies portion processor chip. general terms, functional elements core are: ■Instruction logic: includes tasks involved fetching instructions, decoding instruction determine instruction operation memory locations operands. ■Arithmetic logic unit (ALU): Performs operation specified instruction. ■Load/store logic: Manages transfer data main memory via cache. core also contains L1 cache, split instruction cache ( I- cache) used transfer instructions main memory, L1 data cache, transfer operands results. Typically, today’s pro - cessor chips also include L2 cache part core. many cases, cache also split instruction data caches, although combined, single L2 cache also used. Keep mind representation layout core intended give general idea internal core structure. given product, functional elements may laid three distinct elements shown Figure 1.2, especially functions implemented part micropro - grammed control unit. examples instructive look real- world examples illustrate hierarchical structure computers. Figure 1.3 photograph motherboard computer built around two Intel Quad- Core Xeon processor chips. Many elements labeled photograph discussed subsequently book. Here, mention important, addition processor sockets: ■ PCI- Express slots high- end display adapter additional peripher - als (Section 3.6 describes PCIe). ■Ethernet controller Ethernet ports network connections. ■USB sockets peripheral devices.1.2 / struCture Fun Ction 9 2x Quad-Core Intel® Xeon® Processors Inte grated Memory ControllersSix Channel DDR3-1333 Memory Interfaces 48GBIntel® 3420 Chipset Serial ATA/300 (S ATA) Interface 2x USB 2.0 Internal 2x Ethernet Ports 10/100/1000Base-T Ethernet Controller ClockPCI Express® Connector APCI Express® Connector BPower & Backplane I/O Connector CVGA Video Output BIOS2x USB 2.0 External Figure 1.3 Motherboard Two Intel Quad- Core Xeon Processors Source: Chassis Plans, www.chassis-plans.com ■Serial ATA (SATA) sockets connection disk memory (Section 7.7 discusses Ethernet, USB, SATA). ■Interfaces DDR (double data rate) main memory chips (Section 5.3 discusses DDR). ■Intel 3420 chipset I/O controller direct memory access operations peripheral devices main memory (Section 7.5 discusses DDR). Following top- strategy, illustrated Figures 1.1 1.2, zoom look internal structure processor chip. variety, look IBM chip instead Intel processor chip. Figure 1.4 photograph processor chip IBM zEnterprise EC12 mainframe computer. chip 2.75 billion transistors. superimposed labels indicate silicon real estate chip allocated. see chip six cores, processors. addition, two large areas labeled L3 cache, shared six processors. L3 control logic controls traffic L3 cache cores L3 cache external environment. Additionally, stor - age control (SC) logic cores L3 cache. memory controller (MC) function controls access memory external chip. GX I/O bus controls interface channel adapters accessing I/O. Going one level deeper, examine internal structure single core, shown photograph Figure 1.5. Keep mind portion silicon surface area making single- processor chip. main sub- areas within core area following: ■ISU (instruction sequence unit): Determines sequence instructions executed referred superscalar architecture (Chapter 16). ■IFU (instruction fetch unit): Logic fetching instructions.10 Chapter 1 / Basi C Con Cepts Computer evolution ■IDU (instruction decode unit): IDU fed IFU buffers, responsible parsing decoding z/Architecture operation codes. ■LSU ( load- store unit): LSU contains 96-kB L1 data cache,1 man - ages data traffic L2 data cache functional execution units. responsible handling types operand accesses lengths, modes, formats defined z/Architecture. ■XU (translation unit): unit translates logical addresses instructions physical addresses main memory. XU also contains translation lookaside buffer (TLB) used speed memory access. TLBs discussed Chapter 8. ■FXU ( fixed- point unit): FXU executes fixed- point arithmetic operations. ■BFU (binary floating- point unit): BFU handles binary hexadeci - mal floating- point operations, well fixed- point multiplication operations. ■DFU (decimal floating- point unit): DFU handles fixed- point floating- point operations numbers stored decimal digits. ■RU (recovery unit): RU keeps copy complete state sys - tem includes registers, collects hardware fault signals, manages hardware recovery actions. Figure 1.4 zEnterprise EC12 Processor Unit (PU) chip diagram Source: IBM zEnterprise EC12 Technical Guide, December 2013, SG24-8049-01. IBM, Reprinted Permission Figure 1.5 zEnterprise EC12 Core layout Source: IBM zEnterprise EC12 Technical Guide, December 2013, SG24-8049-01. IBM, Reprinted Permission 1kB = kilobyte = 2048 bytes. Numerical prefixes explained document “Other Useful” tab ComputerScienceStudent.com.1.3 / Brie F history F Computers 11 ■COP (dedicated co- processor): COP responsible data compression encryption functions core. ■ I- cache: 64-kB L1 instruction cache, allowing IFU prefetch instructions needed. ■L2 control: control logic manages traffic two L2 caches. ■ Data- L2: 1-MB L2 data cache memory traffic instructions. ■ Instr- L2: 1-MB L2 instruction cache. progress book, concepts introduced section become clearer. 1.3 Brie F hiStOry cOmputer S2 section, provide brief overview history development computers. history interesting itself, importantly, provides basic introduction many important concepts deal throughout book. First Generation: Vacuum Tubes first generation computers used vacuum tubes digital logic elements memory. number research commercial computers built using vacuum tubes. purposes, instructive examine perhaps famous first- generation computer, known IAS computer. fundamental design approach first implemented IAS computer known stored- program concept . idea usually attributed mathem - atician John von Neumann. Alan Turing developed idea time. first publication idea 1945 proposal von Neumann new computer, EDVAC (Electronic Discrete Variable Computer).3 1946, von Neumann colleagues began design new stored- program computer, referred IAS computer, Princeton Institute Advanced Studies. IAS computer, although completed 1952, prototype subsequent general- purpose computers.4 Figure 1.6 shows structure IAS computer (compare Figure 1.1). consists ■A main memory , stores data instructions5 ■An arithmetic logic unit (ALU) capable operating binary data 2 book’s Companion Web site (WilliamStallings.com/ComputerOrganization) contains several links sites provide photographs many devices components discussed section. 4A 1954 report [GOLD54] describes implemented IAS machine lists final instruction set. available box.com/COA10e.3The 1945 report EDVAC available box.com/COA10e. 5In book, unless otherwise noted, term instruction refers machine instruction directly interpreted executed processor, contrast statement high- level language, Ada C ++, must first compiled series machine instructions executed.12 Chapter 1 / Basi C Con Cepts Computer evolution ■A control unit , interprets instructions memory causes executed ■ Input– output (I/O) equipment operated control unit structure outlined von Neumann’s earlier proposal, worth quoting part point [VONN45]: 2.2 First: Since device primarily computer, perform elementary operations arithmetic fre - quently. addition, subtraction, multiplication, divi - sion. therefore reasonable contain specialized organs operations.Cont rol circuits Addr essesContr ol signalsInstructions data AC: Accumulator register MQ: multiply-quotient register MBR: memory buf fer register IBR: instruction buf fer register PC: program counter MAR: memory address registe r IR: insruction registerInstructions data M(0) M(1) M(2) M(3) M(4) M(4095)M(4093)M(4092)MBRArithmetic-logic unit (CA)Central pr ocessing unit (CPU) Program contr ol unit (CC)Input- output equipment (I, O) Main memory (M)AC MQ Arithmetic-logic circuits IBR PC IR MAR Figure 1.6 IAS StructureIt must observed, however, principle probably sound, specific way realized requires close scrutiny. rate central arithmetical part device probably exist, constitutes first specific part: CA . 2.3 Second: logical control device, is, proper sequencing operations, efficiently car - ried central control organ. device elastic , is, nearly possible purpose , distinction must made specific instructions given defining particular problem, general control organs see instructions— matter are— carried out. former must stored way; latter represented definite operating parts device. central control mean latter function only, organs perform form second specific part: CC . 2.4 Third: device carry long compli - cated sequences operations (specifically calculations) must considerable memory . . . instructions govern complicated problem may constitute considerable material, particularly code cir - cumstantial (which arrangements). material must remembered. rate, total memory constitutes third specific part device: M. 2.6 three specific parts CA, CC (together C), cor - respond associative neurons human nervous system. remains discuss equivalents sensory afferent motor efferent neurons. input output organs device. device must endowed ability maintain input output (sensory motor) contact specific medium type. medium called outside record - ing medium device: R . 2.7 Fourth: device must organs transfer informa - tion R specific parts C M. organs form input , fourth specific part: . seen best make transfers R (by I) never directly C. 2.8 Fifth: device must organs transfer specific parts C R. organs form output , fifth specific part: . seen best make transfers (by O) R, never directly C. rare exceptions, today’s computers general structure function thus referred von Neumann machines . Thus, worth - point describe briefly operation IAS computer [BURK46, GOLD54]. Following [HAYE98], terminology notation von Neumann 1.3 / Brie F history F Computers 1314 Chapter 1 / Basi C Con Cepts Computer evolution changed following conform closely modern usage; exam - ples accompanying discussion based latter text. memory IAS consists 4,096 storage locations, called words , 40 binary digits (bits) each.6 data instructions stored there. Numbers represented binary form, instruction binary code. Figure 1.7 illustrates formats. number represented sign bit 39-bit value. word may alternatively contain two 20-bit instructions, instruction consisting 8-bit operation code (opcode) specifying operation performed 12-bit address designating one words memory (numbered 0 999). control unit operates IAS fetching instructions memory executing one time. explain operations reference Figure 1.6. figure reveals control unit ALU contain stor - age locations, called registers , defined follows: ■Memory buffer register (MBR): Contains word stored memory sent I/O unit, used receive word memory I/O unit. ■Memory address register (MAR): Specifies address memory word written read MBR. ■Instruction register (IR): Contains 8-bit opcode instruction executed. ■Instruction buffer register (IBR): Employed hold temporarily right- hand instruction word memory. ■Program counter (PC): Contains address next instruction pair fetched memory. ■Accumulator (AC) multiplier quotient (MQ): Employed hold tem - porarily operands results ALU operations. example, result 6There universal definition term word . general, word ordered set bytes bits normal unit information may stored, transmitted, operated within given computer. Typically, processor fixed- length instruction set, instruction length equals word length.(a) Numbe r wordsign bit0 39 (b) Instruction wordopcode (8 bits) addr ess (12 bits)left instruction (20 bits) 08 20 28 391 right instruction (20 bits) opcode (8 bits) addr ess (12 bits) Figure 1.7 IAS Memory Formatsof multiplying two 40-bit numbers 80-bit number; significant 40 bits stored AC least significant MQ. IAS operates repetitively performing instruction cycle , shown Figure 1.8. instruction cycle consists two subcycles. fetch cycle , opcode next instruction loaded IR address portion loaded MAR. instruction may taken IBR, obtained memory loading word MBR, IBR, IR, MAR. indirection? operations controlled electronic circuitry result use data paths. simplify electronics, one reg - ister used specify address memory read write one register used source destination.1.3 / Brie F history F Computers 15 Start next instruction IBR?MAR PC MBR M(MAR) IR IBR (0:7) MAR IBR (8:19)IR MBR (20:27) MAR MBR (28:39)Left instruction required?IBR MBR (20:39) IR MBR (0:7) MAR MBR (8:19) PC PC + 1Yes Yes YesNo M(X) = contents memory location whose address X (i:j) = bits jNo memory access required Decode instruction IR AC M(X) Go M(X, 0:19) AC > 0 go M(X, 0:19)AC AC + M(X) AC > 0? MBR M(MAR) MBR M(MAR) PC MAR AC MBR AC AC + MBRFetch cycle Execution cycle Figure 1.8 Partial Flowchart IAS Operation16 Chapter 1 / Basi C Con Cepts Computer evolution opcode IR, execute cycle performed. Control circuitry interprets opcode executes instruction sending appropri - ate control signals cause data moved operation performed ALU. IAS computer total 21 instructions, listed Table 1.1. grouped follows: ■Data transfer: Move data memory ALU registers two ALU registers. ■Unconditional branch: Normally, control unit executes instructions sequence memory. sequence changed branch instruc - tion, facilitates repetitive operations. Table 1.1 IAS Instruction Set Instruction Type OpcodeSymbolic Representation Description Data transfer00001010 LOAD MQ Transfer contents register MQ accumulator AC 00001001 LOAD MQ,M(X) Transfer contents memory location X MQ 00100001 STOR M(X) Transfer contents accumulator memory location X 00000001 LOAD M(X) Transfer M(X) accumulator 00000010 LOAD –M(X) Transfer –M(X) accumulator 00000011 LOAD |M(X)| Transfer absolute value M(X) accumulator 00000100 LOAD –|M(X)| Transfer –|M(X)| accumulator Unconditional branch00001101 JUMP M(X,0:19) Take next instruction left half M(X) 00001110 JUMP M(X,20:39) Take next instruction right half M(X) Conditional branch00001111 JUMP + M(X,0:19) number accumulator nonnegative, take next instruction left half M(X) 00010000 JUMP + M(X,20:39) number accumulator nonnegative, take next instruction right half M(X) Arithmetic00000101 ADD M(X) Add M(X) AC; put result AC 00000111 ADD |M(X)| Add |M(X)| AC; put result AC 00000110 SUB M(X) Subtract M(X) AC; put result AC 00001000 SUB |M(X)| Subtract |M(X)| AC; put remainder AC 00001011 MUL M(X) Multiply M(X) MQ; put significant bits result AC, put least significant bits MQ 00001100 DIV M(X) Divide AC M(X); put quotient MQ remainder AC 00010100 LSH Multiply accumulator 2; is, shift left one bit position 00010101 RSH Divide accumulator 2; is, shift right one position Address modify00010010 STOR M(X,8:19) Replace left address field M(X) 12 rightmost bits AC 00010011 STOR M(X,28:39) Replace right address field M(X) 12 rightmost bits AC ■Conditional branch: branch made dependent condition, thus allowing decision points. ■Arithmetic: Operations performed ALU. ■Address modify: Permits addresses computed ALU inserted instructions stored memory. allows program consider - able addressing flexibility. Table 1.1 presents instructions (excluding I/O instructions) symbolic, easy- to- read form. binary form, instruction must conform format Figure 1.7b. opcode portion (first 8 bits) specifies 21 instructions executed. address portion (remaining 12 bits) specifies 4,096 memory locations involved execution instruction. Figure 1.8 shows several examples instruction execution control unit. Note operation requires several steps, quite elaborate. multiplication operation requires 39 suboperations, one bit position except sign bit. Second Generation: Transistors first major change electronic computer came replacement vacuum tube transistor. transistor, smaller, cheaper, gener - ates less heat vacuum tube, used way vacuum tube construct computers. Unlike vacuum tube, requires wires, metal plates, glass capsule, vacuum, transistor solid- state device , made silicon. transistor invented Bell Labs 1947 1950s launched electronic revolution. late 1950s, however, fully transis - torized computers commercially available. use transistor defines second generation computers. become widely accepted classify com - puters generations based fundamental hardware technology employed (Table 1.2). new generation characterized greater processing perfor - mance, larger memory capacity, smaller size previous one. changes well. second generation saw intro - duction complex arithmetic logic units control units, use high- level programming languages, provision system software 1.3 / Brie F history F Computers 17 Table 1.2 Computer Generations GenerationApproximate Dates TechnologyTypical Speed (operations per second) 1 1946–1957 Vacuum tube 40,000 2 1957–1964 Transistor 200,000 3 1965–1971 Small- medium- scale integration1,000,000 4 1972–1977 Large scale integration 10,000,000 5 1978–1991 large scale integration 100,000,000 6 1991– Ultra large scale integration >1,000,000,00018 Chapter 1 / Basi C Con Cepts Computer evolution computer. broad terms, system software provided ability load programs, move data peripherals, libraries perform common computations, similar modern operating systems, Windows Linux, do. useful examine important member second generation: IBM 7094 [BELL71]. introduction 700 series 1952 introduc - tion last member 7000 series 1964, IBM product line underwent evolution typical computer products. Successive members product line showed increased performance, increased capacity, and/or lower cost. size main memory, multiples 210 36-bit words, grew 2k (1k = 210) 32k words,7 time access one word memory, mem- ory cycle time , fell 30 ms 1.4 ms. number opcodes grew modest 24 185. Also, lifetime series computers, relative speed CPU increased factor 50. Speed improvements achieved improved electronics (e.g., transistor implementation faster vacuum tube imple - mentation) complex circuitry. example, IBM 7094 includes Instruction Backup Register, used buffer next instruction. control unit fetches two adjacent words memory instruction fetch. Except occurrence branching instruction, relatively infrequent (perhaps 10 15%), means control unit access memory instruction half instruction cycles. prefetching significantly reduces average instruction cycle time. Figure 1.9 shows large (many peripherals) configuration IBM 7094, representative second- generation computers. Several differences IAS computer worth noting. important use data channels . data channel independent I/O module processor instruction set. computer system devices, CPU execute detailed I/O instructions. instructions stored main memory executed special- purpose processor data channel itself. CPU initi - ates I/O transfer sending control signal data channel, instructing execute sequence instructions memory. data channel performs task independently CPU signals CPU operation complete. arrangement relieves CPU considerable processing burden. Another new feature multiplexor , central termination point data channels, CPU, memory. multiplexor schedules access memory CPU data channels, allowing devices act independently. Third Generation: Integrated Circuits single, self- contained transistor called discrete component . Throughout 1950s early 1960s, electronic equipment composed largely discrete components— transistors, resistors, capacitors, on. Discrete components manufactured separately, packaged containers, soldered wired 7A discussion uses numerical prefixes, kilo giga, contained supporting docu - ment Computer Science Student Resource Site ComputerScienceStudent.com.together onto Masonite- like circuit boards, installed computers, oscilloscopes, electronic equipment. Whenever electronic device called transistor, little tube metal containing pinhead- sized piece silicon soldered circuit board. entire manufacturing process, transistor circuit board, expensive cumbersome. facts life beginning create problems computer indus - try. Early second- generation computers contained 10,000 transistors. figure grew hundreds thousands, making manufacture newer, powerful machines increasingly difficult. 1958 came achievement revolutionized electronics started era microelectronics: invention integrated circuit. integrated circuit defines third generation computers. section, provide brief introduction technology integrated circuits. look perhaps two important members third generation, intro- duced beginning era: IBM System/360 DEC PDP- 8. microelectronics Microelectronics means, literally, “small electronics.” Since beginnings digital electronics computer industry, persistent consistent trend toward reduction size digital electronic circuits. examining implications benefits trend, need say something nature digital electronics. detailed discussion found Chapter 11.CPU MemoryIBM 7094 computer Peripheral devices Data channelMag tape units Card punch Line printer Card reader Drum Disk Disk Hyper - tapes Telepr ocessing equipmentData channel Data channel Data channelMulti- plexor Figure 1.9 IBM 7094 Configuration1.3 / Brie F history F Computers 1920 Chapter 1 / Basi C Con Cepts Computer evolution basic elements digital computer, know, must perform data stor - age, movement, processing, control functions. two fundamental types components required (Figure 1.10): gates memory cells. gate device implements simple Boolean logical function. example, gate inputs B output C implements expression B TRUE C TRUE. devices called gates control data flow much way canal gates control flow water. memory cell device store 1 bit data; is, device one two stable states time. interconnecting large numbers fundamental devices, construct computer. relate four basic functions follows: ■Data storage: Provided memory cells. ■Data processing: Provided gates. ■Data movement: paths among components used move data memory memory memory gates memory. ■Control: paths among components carry control signals. example, gate one two data inputs plus control signal input activates gate. control signal ON, gate performs function data inputs produces data output. Conversely, control signal OFF, output line null, one produced high impedance state. Similarly, memory cell store bit input lead WRITE control signal place bit cell output lead READ control signal ON. Thus, computer consists gates, memory cells, interconnections among elements. gates memory cells are, turn, constructed simple elec - tronic components, transistors capacitors. integrated circuit exploits fact components transistors, resistors, conductors fabricated semiconductor silicon. merely extension solid- state art fabricate entire circuit tiny piece silicon rather assemble discrete components made separate pieces silicon circuit. Many transistors produced time single wafer silicon. Equally important, transistors con - nected process metallization form circuits. Boolean logic functionInput Activate signal (a) GateOutput• • •Binary storage cellInput Read Write (b) Memory cellOutput Figure 1.10 Fundamental Computer ElementsFigure 1.11 depicts key concepts integrated circuit. thin wafer silicon divided matrix small areas, millimeters square. identical circuit pattern fabricated area, wafer broken chips . chip consists many gates and/or memory cells plus number input output attachment points. chip packaged housing protects provides pins attachment devices beyond chip. number packages interconnected printed circuit board produce larger complex circuits. Initially, gates memory cells could reliably manufactured packaged together. early integrated circuits referred small- scale integration (SSI ). time went on, became possible pack com - ponents chip. growth density illustrated Figure 1.12; one remarkable technological trends ever recorded.8 figure reflects famous Moore’s law, propounded Gordon Moore, cofounder Intel, 1965 [MOOR65]. Moore observed number transistors could put single chip doubling every year, correctly predicted pace would continue near future. surprise many, including Moore, pace continued year year decade decade. pace slowed doubling every 18 months 1970s sustained rate ever since. consequences Moore’s law profound: 1. cost chip remained virtually unchanged period rapid growth density. means cost computer logic memory cir - cuitry fallen dramatic rate. Wafer Chip Gate Packaged chip Figure 1.11 Relationship among Wafer, Chip, Gate1.3 / Brie F history F Computers 21 8Note vertical axis uses log scale. basic review log scales math refresher document Computer Science Student Resource Site ComputerScienceStudent.com.22 Chapter 1 / Basi C Con Cepts Computer evolution 2. logic memory elements placed closer together densely packed chips, electrical path length shortened, increasing oper - ating speed. 3. computer becomes smaller, making convenient place vari - ety environments. 4. reduction power requirements. 5. interconnections integrated circuit much reliable solder connections. circuitry chip, fewer inter - chip connections. ibm system /360 1964, IBM firm grip computer market 7000 series machines. year, IBM announced System/360, new family computer products. Although announcement surprise, contained unpleasant news current IBM customers: 360 product line incompatible older IBM machines. Thus, transition 360 would difficult current customer base, IBM felt necessary break constraints 7000 architecture produce system capable evolving new integrated circuit technology [PADE81, GIFF87]. strategy paid financially technically. 360 success decade cemented IBM overwhelmingly dominant computer vendor, market share 70%. And, modifications extensions, architecture 360 remains day architecture IBM’s mainframe9 computers. Examples using architecture found throughout text. System/360 industry’s first planned family computers. family covered wide range performance cost. models compatible 1 1947First working transistorMoore’s law promulgated Invention integrated circuit 50 55 60 65 70 75 80 85 90 95 2000 05 11101001,00010,000100,00010 m100 m1 bn10 bn100 bn Figure 1.12 Growth Transistor Count Integrated Circuits 9The term mainframe used larger, powerful computers supercomputers. Typical characteristics mainframe supports large database, elaborate I/O hardware, used central data processing facility.sense program written one model capable executed another model series, difference time takes execute. concept family compatible computers novel extremely successful. customer modest requirements budget match could start relatively inexpensive Model 30. Later, customer’s needs grew, possible upgrade faster machine memory without sacrificing investment already- developed software. characteristics family follows: ■Similar identical instruction set: many cases, exact set machine instructions supported members family. Thus, pro - gram executes one machine also execute other. cases, lower end family instruction set subset top end family. means programs move down. ■Similar identical operating system: basic operating system available family members. cases, additional features added higher- end members. ■Increasing speed: rate instruction execution increases going lower higher family members. ■Increasing number I/O ports: number I/O ports increases going lower higher family members. ■Increasing memory size: size main memory increases going lower higher family members. ■Increasing cost: given point time, cost system increases going lower higher family members. could family concept implemented? Differences achieved based three factors: basic speed, size, degree simultaneity [STEV64]. example, greater speed execution given instruction could gained use complex circuitry ALU, allowing suboperations car - ried parallel. Another way increasing speed increase width data path main memory CPU. Model 30, 1 byte (8 bits) could fetched main memory time, whereas 8 bytes could fetched time Model 75. System/360 dictated future course IBM also pro - found impact entire industry. Many features become standard large computers. dec pdp- 8 year IBM shipped first System/360, another momentous first shipment occurred: PDP- 8 Digital Equipment Corporation (DEC). time average computer required air- conditioned room, PDP- 8 (dubbed minicomputer industry, miniskirt day) small enough could placed top lab bench built equipment. could everything mainframe could, $16,000, cheap enough lab technician one. contrast, System/360 series mainframe computers introduced months cost hundreds thousands dollars.1.3 / Brie F history F Computers 2324 Chapter 1 / Basi C Con Cepts Computer evolution low cost small size PDP- 8 enabled another manufacturer purchase PDP- 8 integrate total system resale. manu - facturers came known original equipment manufacturers (OEMs) , OEM market became remains major segment computer marketplace. contrast central- switched architecture (Figure 1.9) used IBM 700/7000 360 systems, later models PDP- 8 used structure became vir - tually universal microcomputers: bus structure. illustrated Figure 1.13. PDP- 8 bus, called Omnibus, consists 96 separate signal paths, used carry control, address, data signals. system components share common set signal paths, use controlled CPU. architecture highly flexible, allowing modules plugged bus create various configurations. recent years bus structure given way structure known point- to- point interconnect, described Chapter 3. Later Generations Beyond third generation less general agreement defining generations computers. Table 1.2 suggests number later generations, based advances integrated circuit technology. introduction large- scale integration (LSI) , 1,000 components placed single inte - grated circuit chip. Very- large- scale integration (VLSI) achieved 10,000 components per chip, current ultra- large- scale integration (ULSI) chips contain one billion components. rapid pace technology, high rate introduction new prod - ucts, importance software communications well hardware, classification generation becomes less clear less meaningful. section, mention two important developments later generations. semiconductor memory first application integrated circuit technology computers construction processor (the control unit arithmetic logic unit) integrated circuit chips. also found technology could used construct memories. 1950s 1960s, computer memory constructed tiny rings ferromagnetic material, sixteenth inch diameter. rings strung grids fine wires suspended small screens inside computer. Magnetized one way, ring (called core) represented one; mag - netized way, stood zero. Magnetic- core memory rather fast; took little millionth second read bit stored memory. Console contr ollerCPU Omnib usMain memoryI/O moduleI/O module• • • Figure 1.13 PDP- 8 Bus Structureexpensive bulky, used destructive readout: simple act reading core erased data stored it. therefore necessary install circuits restore data soon extracted. Then, 1970, Fairchild produced first relatively capacious semiconductor memory. chip, size single core, could hold 256 bits memory. nondestructive much faster core. took 70 billionths second read bit. However, cost per bit higher core. 1974, seminal event occurred: price per bit semiconductor memory dropped price per bit core memory. Following this, con - tinuing rapid decline memory cost accompanied corresponding increase physical memory density. led way smaller, faster machines mem - ory sizes larger expensive machines years earlier. Devel - opments memory technology, together developments processor technology discussed next, changed nature computers less decade. Although bulky, expensive computers remain part landscape, computer also brought “end user,” office machines personal computers. Since 1970, semiconductor memory 13 generations: 1k, 4k, 16k, 64k, 256k, 1M, 4M, 16M, 64M, 256M, 1G, 4G, and, writing, 8 Gb single chip ( 1 k=210, 1 M=220, 1 G=230). generation provided increased storage density, accompanied declining cost per bit declining access time. Densities projected reach 16 Gb 2018 32 Gb 2023 [ITRS14]. microprocessors density elements memory chips continued rise, density elements processor chips. time went on, elements placed chip, fewer fewer chips needed construct single computer processor. breakthrough achieved 1971, Intel developed 4004. 4004 first chip contain components CPU single chip: microprocessor born. 4004 add two 4-bit numbers multiply repeated addi - tion. today’s standards, 4004 hopelessly primitive, marked begin - ning continuing evolution microprocessor capability power. evolution seen easily number bits processor deals time. clear- cut measure this, perhaps best meas - ure data bus width: number bits data brought sent processor time. Another measure number bits accumu - lator set general- purpose registers. Often, measures coincide, always. example, number microprocessors developed operate 16-bit numbers registers read write 8 bits time. next major step evolution microprocessor introduc - tion 1972 Intel 8008. first 8-bit microprocessor almost twice complex 4004. Neither steps impact next major event: introduction 1974 Intel 8080. first general- purpose micropro - cessor. Whereas 4004 8008 designed specific applications, 8080 designed CPU general- purpose microcomputer. Like 1.3 / Brie F history F Computers 2526 Chapter 1 / Basi C Con Cepts Computer evolution Table 1.3 Evolution Intel Microprocessors (page 1 2) (a) 1970s Processors 4004 8008 8080 8086 8088 Introduced 1971 1972 1974 1978 1979 Clock speeds 108 kHz 108 kHz 2 MHz 5 MHz, 8 MHz, 10 MHz 5 MHz, 8 MHz Bus width 4 bits 8 bits 8 bits 16 bits 8 bits Number transistors 2,300 3,500 6,000 29,000 29,000 Feature size ( mm) 10 8 6 3 6 Addressable memory 640 bytes 16 KB 64 KB 1 MB 1 MB (b) 1980s Processors 80286 386TM DX 386TM SX 486TM DX CPU Introduced 1982 1985 1988 1989 Clock speeds 6–12.5 MHz 16–33 MHz 16–33 MHz 25–50 MHz Bus width 16 bits 32 bits 16 bits 32 bits Number transistors 134,000 275,000 275,000 1.2 million Feature size ( µm) 1.5 1 1 0.8–1 Addressable memory 16 MB 4 GB 16 MB 4 GB Virtual memory 1 GB 64 TB 64 TB 64 TB Cache — — — 8 kB (c) 1990s Processors 486TM SX Pentium Pentium Pro Pentium II Introduced 1991 1993 1995 1997 Clock speeds 16–33 MHz 60–166 MHz, 150–200 MHz 200–300 MHz Bus width 32 bits 32 bits 64 bits 64 bits Number transistors 1.185 million 3.1 million 5.5 million 7.5 million Feature size ( µm) 1 0.8 0.6 0.35 Addressable memory 4 GB 4 GB 64 GB 64 GB Virtual memory 64 TB 64 TB 64 TB 64 TB Cache 8 kB 8 kB 512 kB L1 1 MB L2512 kB L28008, 8080 8-bit microprocessor. 8080, however, faster, richer instruction set, large addressing capability. time, 16-bit microprocessors began developed. - ever, end 1970s powerful, general- purpose 16-bit microprocessors appeared. One 8086. next step trend occurred 1981, Bell Labs Hewlett- Packard developed 32-bit, single- chip microprocessors. Intel introduced 32-bit microprocessor, 80386, 1985 (Table 1.3).1.4 / evolution F intel x86 arChiteCture 27 (d) Recent Processors Pentium III Pentium 4 Core 2 Duo Core i7 EE 4960X Introduced 1999 2000 2006 2013 Clock speeds 450–660 MHz 1.3–1.8 GHz 1.06–1.2 GHz 4 GHz Bus width 64 bits 64 bits 64 bits 64 bits Number transistors 9.5 million 42 million 167 million 1.86 billion Feature size (nm) 250 180 65 22 Addressable memory 64 GB 64 GB 64 GB 64 GB Virtual memory 64 TB 64 TB 64 TB 64 TB Cache 512 kB L2 256 kB L2 2 MB L2 1.5 MB L2/15 MB L3 Number cores 1 1 2 6 1.4 evOlutiOn intel x86 architecture Throughout book, rely many concrete examples computer design implementation illustrate concepts illuminate trade- offs. Numerous sys - tems, contemporary historical, provide examples important computer architecture design features. book relies principally examples two processor families: Intel x86 ARM architectures. current x86 offer - ings represent results decades design effort complex instruction set com - puters (CISCs) . x86 incorporates sophisticated design principles found mainframes supercomputers serves excellent example CISC design. alternative approach processor design reduced instruction set computer (RISC) . ARM architecture used wide variety embedded sys - tems one powerful best- designed RISC- based systems market. section next, provide brief overview two systems. terms market share, Intel ranked number one maker micro - processors non- embedded systems decades, position seems unlikely yield. evolution flagship microprocessor product serves good indica - tor evolution computer technology general. Table 1.3 shows evolution. Interestingly, microprocessors grown faster much complex, Intel actually picked pace. Intel used develop microprocessors one another, every four years. Intel hopes keep rivals bay trimming year two development time, done recent x86 generations.10 10Intel refers tick- tock model . Using model, Intel successfully delivered next- generation silicon technology well new processor microarchitecture alternating years past several years. See http://www.intel.com/content/www/us/en/ silico n- innovations/inte l-tick-tock- model-general.html .28 Chapter 1 / Basi C Con Cepts Computer evolution worthwhile list highlights evolution Intel prod - uct line: ■8080: world’s first general- purpose microprocessor. 8-bit machine, 8-bit data path memory. 8080 used first personal computer, Altair. ■8086: far powerful, 16-bit machine. addition wider data path larger registers, 8086 sported instruction cache, queue, prefetches instructions executed. variant pro - cessor, 8088, used IBM’s first personal computer, securing suc - cess Intel. 8086 first appearance x86 architecture. ■80286: extension 8086 enabled addressing 16-MB memory instead 1 MB. ■80386: Intel’s first 32-bit machine, major overhaul product. 32-bit architecture, 80386 rivaled complexity power minicom - puters mainframes introduced years earlier. first Intel processor support multitasking, meaning could run multiple pro - grams time. ■80486: 80486 introduced use much sophisticated power - ful cache technology sophisticated instruction pipelining. 80486 also offered built- math coprocessor, offloading complex math operations main CPU. ■Pentium: Pentium, Intel introduced use superscalar tech - niques, allow multiple instructions execute parallel. ■Pentium Pro: Pentium Pro continued move superscalar organiza - tion begun Pentium, aggressive use register renaming, branch prediction, data flow analysis, speculative execution. ■Pentium II: Pentium II incorporated Intel MMX technology, designed specifically process video, audio, graphics data efficiently. ■Pentium III: Pentium III incorporates additional floating- point instruc - tions: Streaming SIMD Extensions (SSE) instruction set extension added 70 new instructions designed increase performance exactly operations performed multiple data objects. Typical applications digital signal processing graphics processing. ■Pentium 4: Pentium 4 includes additional floating- point enhancements multimedia.11 ■Core: first Intel x86 microprocessor dual core, referring implementation two cores single chip. ■Core 2: Core 2 extends Core architecture 64 bits. Core 2 Quad provides four cores single chip. recent Core offerings 10 cores per chip. important addition architecture Advanced Vector Extensions instruction set provided set 256-bit, 512- bit, instructions efficient processing vector data. 11With Pentium 4, Intel switched Roman numerals Arabic numerals model numbers.1.5 / emBedded systems 29 Almost 40 years introduction 1978, x86 architecture continues dominate processor market outside embedded systems. Although organiza - tion technology x86 machines changed dramatically decades, instruction set architecture evolved remain backward compatible ear - lier versions. Thus, program written older version x86 architecture execute newer versions. changes instruction set architecture involved additions instruction set, subtractions. rate change addition roughly one instruction per month added architecture [ANTH08], thousands instructions instruction set. x86 provides excellent illustration advances computer hard - ware past 35 years. 1978 8086 introduced clock speed 5 MHz 29,000 transistors. six- core Core i7 EE 4960X introduced 2013 operates 4 GHz, speedup factor 800, 1.86 billion transistors, 64,000 times many 8086. Yet Core i7 EE 4960X slightly larger package 8086 comparable cost. 1.5 emBedded Sy StemS term embedded system refers use electronics software within product, opposed general- purpose computer, laptop desktop sys - tem. Millions computers sold every year, including laptops, personal comput - ers, workstations, servers, mainframes, supercomputers. contrast, billions computer systems produced year embedded within larger devices. Today, many, perhaps most, devices use electric power embedded com - puting system. likely near future virtually devices embedded computing systems. Types devices embedded systems almost numerous list. Examples include cell phones, digital cameras, video cameras, calculators, micro - wave ovens, home security systems, washing machines, lighting systems, ther - mostats, printers, various automotive systems (e.g., transmission control, cruise control, fuel injection, anti- lock brakes, suspension systems), tennis rack - ets, toothbrushes, numerous types sensors actuators automated systems. Often, embedded systems tightly coupled environment. give rise real- time constraints imposed need interact environ - ment. Constraints, required speeds motion, required precision meas - urement, required time durations, dictate timing software operations. multiple activities must managed simultaneously, imposes complex real- time constraints. Figure 1.14 shows general terms embedded system organization. addi - tion processor memory, number elements differ typical desktop laptop computer: ■There may variety interfaces enable system measure, manip - ulate, otherwise interact external environment. Embedded sys - tems often interact (sense, manipulate, communicate) external world sensors actuators hence typically reactive systems; 30 Chapter 1 / Basi C Con Cepts Computer evolution reactive system continual interaction environment executes pace determined environment. ■The human interface may simple flashing light complicated real- time robotic vision. many cases, human interface. ■The diagnostic port may used diagnosing system controlled— diagnosing computer. ■ Special- purpose field programmable (FPGA), application- specific (ASIC), even nondigital hardware may used increase performance reliability. ■Software often fixed function specific application. ■Efficiency paramount importance embedded systems. opti - mized energy, code size, execution time, weight dimensions, cost. several noteworthy areas similarity general- purpose computer systems well: ■Even nominally fixed function software, ability field upgrade fix bugs, improve security, add functionality, become important embedded systems, consumer devices. ■One comparatively recent development embedded system plat - forms support wide variety apps. Good examples smart - phones audio/visual devices, smart TVs. Internet Things worthwhile separately callout one major drivers proliferation embedded systems. Internet things (IoT) term refers expanding MemoryCustom logic Human interfaceDiagnostic portProcessor D/A Conversion Actuators/ indicatorsA/D conversion Sensors Figure 1.14 Possible Organization Embedded System1.5 / emBedded systems 31 interconnection smart devices, ranging appliances tiny sensors. domi - nant theme embedding short- range mobile transceivers wide array gadgets everyday items, enabling new forms communication people things, things themselves. Internet supports intercon - nection billions industrial personal objects, usually cloud systems. objects deliver sensor information, act environment, and, cases, modify themselves, create overall management larger system, like factory city. IoT primarily driven deeply embedded devices (defined below). devices low- bandwidth, low- repetition data- capture, low- bandwidth data- usage appliances communicate provide data via user interfaces. Embedded appliances, high- resolution video security cameras, video VoIP phones, handful others, require high- bandwidth streaming capabilities. Yet countless products simply require packets data intermit - tently delivered. reference end systems supported, Internet gone roughly four generations deployment culminating IoT: 1. Information technology (IT): PCs, servers, routers, firewalls, on, bought devices enterprise people primarily using wired connectivity. 2. Operational technology (OT): Machines/appliances embedded built non- companies, medical machinery, SCADA (supervisory con - trol data acquisition), process control, kiosks, bought appliances enterprise OT people primarily using wired connectivity. 3. Personal technology: Smartphones, tablets, eBook readers bought devices consumers (employees) exclusively using wireless connectivity often multiple forms wireless connectivity. 4. Sensor/actuator technology: Single- purpose devices bought consumers, IT, OT people exclusively using wireless connectivity, generally single form, part larger systems. fourth generation usually thought IoT, marked use billions embedded devices. Embedded Operating Systems two general approaches developing embedded operating system (OS). first approach take existing OS adapt embedded application. example, embedded versions Linux, Windows, Mac, well commercial proprietary operating systems specialized embedded systems. approach design implement OS intended solely embedded use. example latter TinyOS, widely used wireless sensor networks. topic explored depth [STAL15]. Application Processors versus Dedicated Processors subsection, next two, briefly introduce terms commonly found literature embedded systems. Application processors defined 32 Chapter 1 / Basi C Con Cepts Computer evolution processor’s ability execute complex operating systems, Linux, Android, Chrome. Thus, application processor general- purpose nature. good example use embedded application processor smartphone. embedded system designed support numerous apps perform wide variety functions. embedded systems employ dedicated processor , which, name implies, dedicated one small number specific tasks required host device. embedded system dedicated specific task tasks, processor associated components engineered reduce size cost. Microprocessors versus Microcontrollers seen, early microprocessor chips included registers, ALU, sort control unit instruction processing logic. transistor density increased, became possible increase complexity instruction set architecture, ultimately add memory one processor. Contemporary micropro - cessor chips, shown Figure 1.2, include multiple cores substantial amount cache memory. microcontroller chip makes substantially different use logic space available. Figure 1.15 shows general terms elements typically found microcontroller chip. shown, microcontroller single chip contains processor, non- volatile memory program (ROM), volatile memory input output (RAM), clock, I/O control unit. processor portion microcontroller much lower silicon area microprocessors much higher energy efficiency. examine microcontroller organization detail Section 1.6. Also called “computer chip,” billions microcontroller units embedded year myriad products toys appliances automobiles. example, single vehicle use 70 microcontrollers. Typically, especially smaller, less expensive microcontrollers, used dedicated proces - sors specific tasks. example, microcontrollers heavily utilized automa - tion processes. providing simple reactions input, control machinery, turn fans off, open close valves, forth. integral parts modern industrial technology among inexpensive ways produce machinery handle extremely complex functionalities. Microcontrollers come range physical sizes processing power. Pro - cessors range 4-bit 32-bit architectures. Microcontrollers tend much slower microprocessors, typically operating MHz range rather GHz speeds microprocessors. Another typical feature microcontroller provide human interaction. microcontroller programmed specific task, embedded device, executes required. Embedded versus Deeply Embedded Systems have, section, defined concept embedded system. subset embedded systems, quite numerous subset, referred deeply embed - ded systems . Although term widely used technical commercial 1.6 / arm arChiteCture 33 literature, search Internet vain (or least did) straightfor - ward definition. Generally, say deeply embedded system proces- sor whose behavior difficult observe programmer user. deeply embedded system uses microcontroller rather microprocessor, programmable program logic device burned ROM ( read- memory), interaction user. Deeply embedded systems dedicated, single- purpose devices detect something environment, perform basic level processing, - thing results. Deeply embedded systems often wireless capability appear networked configurations, networks sensors deployed large area (e.g., factory, agricultural field). Internet things depends heavily deeply embedded systems. Typically, deeply embedded systems extreme resource con - straints terms memory, processor size, time, power consumption. 1.6 arm architecture ARM architecture refers processor architecture evolved RISC design principles used embedded systems. Chapter 15 examines RISC design principles detail. section, give brief overview ARM architecture.A/D converterAnalog data acquisitionTemporary dataProcessor System busRAM D/A converterROM Serial I/O portsEEPROM Parallel I/O portsTIMERProgram data Permanent data Timing functionsAnalog data transmission Send/r eceive data Peripheral interfaces Figure 1.15 Typical Microcontroller Chip Elements34 Chapter 1 / Basi C Con Cepts Computer evolution ARM Evolution ARM family RISC- based microprocessors microcontrollers designed ARM Holdings, Cambridge, England. company doesn’t make processors instead designs microprocessor multicore architectures licenses man - ufacturers. Specifically, ARM Holdings two types licensable products: proces - sors processor architectures. processors, customer buys rights use ARM- supplied design chips. processor architecture, customer buys rights design processor compliant ARM’s architecture. ARM chips high- speed processors known small die size low power requirements. widely used smartphones hand - held devices, including game systems, well large variety consumer prod - ucts. ARM chips processors Apple’s popular iPod iPhone devices, used virtually Android smartphones well. ARM probably widely used embedded processor architecture indeed widely used processor architecture kind world [VANC14]. origins ARM technology traced back British- based Acorn Computers company. early 1980s, Acorn awarded contract Brit - ish Broadcasting Corporation (BBC) develop new microcomputer architecture BBC Computer Literacy Project. success contract enabled Acorn go develop first commercial RISC processor, Acorn RISC Machine (ARM). first version, ARM1, became operational 1985 used internal research development well used coprocessor BBC machine. early stage, Acorn used company VLSI Technology actual fabrication processor chips. VLSI licensed market chip success getting companies use ARM products, particularly embedded processor. ARM design matched growing commercial need high- performance, low- power- consumption, small- size, low- cost processor embedded appli - cations. development beyond scope Acorn’s capabilities. Accordingly, new company organized, Acorn, VLSI, Apple Com - puter founding partners, known ARM Ltd. Acorn RISC Machine became Advanced RISC Machines.12 Instruction Set Architecture ARM instruction set highly regular, designed efficient implementation processor efficient execution. instructions 32 bits long follow regular format. makes ARM ISA suitable implementation wide range products. Augmenting basic ARM ISA Thumb instruction set, re- encoded subset ARM instruction set. Thumb designed increase per - formance ARM implementations use 16-bit narrower memory data bus, 12The company dropped designation Advanced RISC Machines late 1990s. simply known ARM architecture.1.6 / arm arChiteCture 35 allow better code density provided ARM instruction set. Thumb instruction set contains subset ARM 32-bit instruction set recoded 16-bit instructions. current defined version Thumb- 2. ARM Thumb- 2 ISAs discussed Chapters 12 13. ARM Products ARM Holdings licenses number specialized microprocessors related tech - nologies, bulk product line Cortex family microprocessor architectures. three Cortex architectures, conveniently labeled initials A, R, M. corte x- a/ corte x- a50 Cortex- Cortex- A50 application processors, intended mobile devices smartphones eBook readers, well consumer devices digital TV home gateways (e.g., DSL cable Internet modems). processors run higher clock frequency (over 1 GHz), support memory management unit (MMU), required full feature OSs Linux, Android, MS Windows, mobile OSs. MMU hardware module supports virtual memory paging translating virtual addresses physical addresses; topic explored Chapter 8. two architectures use ARM Thumb- 2 instruction sets; principal difference Cortex- 32-bit machine, Cortex- A50 64-bit machine. corte x- r Cortex- R designed support real- time applications, timing events needs controlled rapid response events. run fairly high clock frequency (e.g., 200MHz 800MHz) low response latency. Cortex- R includes enhancements instruction set processor organization support deeply embedded real- time devices. processors MMU; limited data requirements limited number simultaneous processes eliminates need elaborate hardware software support virtual memory. Cortex- R Memory Protection Unit (MPU), cache, memory features designed industrial applications. MPU hardware module prohibits one program memory accidentally accessing memory assigned another active program. Using various methods, protective boundary created around program, instructions within program prohibited referencing data outside boundary. Examples embedded systems would use Cortex- R automotive braking systems, mass storage controllers, networking printing devices. corte x- Cortex- series processors developed primarily microcontroller domain need fast, highly deterministic interrupt management coupled desire extremely low gate count lowest possible power consumption. Cortex- R series, Cortex- architecture MPU MMU. Cortex- uses Thumb- 2 instruction set. market Cortex- includes IoT devices, wireless sensor/actuator networks used factories enterprises, automotive body electronics, on.36 Chapter 1 / Basi C Con Cepts Computer evolution currently four versions Cortex- series: ■ Cortex- M0: Designed 8- 16-bit applications, model emphasizes low cost, ultra low power, simplicity. optimized small silicon die size (starting 12k gates) use lowest cost chips. ■ Cortex- M0+: enhanced version M0 energy efficient. ■ Cortex- M3: Designed 16- 32-bit applications, model emphasizes performance energy efficiency. also comprehensive debug trace features enable software developers develop applications quickly. ■ Cortex- M4: model provides features Cortex- M3, addi - tional instructions support digital signal processing tasks. text, primarily use ARM Cortex- M3 example embed - ded system processor. best suited ARM models general- purpose microcontroller use. Cortex- M3 used variety manufacturers micro - controller products. Initial microcontroller devices lead partners already combine Cortex- M3 processor flash, SRAM, multiple peripherals provide competitive offering price $1. Figure 1.16 provides block diagram EFM32 microcontroller Sil - icon Labs. figure also shows detail Cortex- M3 processor core com - ponents. examine level turn. Cortex- M3 core makes use separate buses instructions data. arrangement sometimes referred Harvard architecture, contrast von Neumann architecture, uses signal buses mem - ory instructions data. able read instruction data memory time, Cortex- M3 processor perform many operations parallel, speeding application execution. core contains decoder Thumb instructions, advanced ALU support hardware multiply divide, control logic, interfaces components processor. particular, interface nested vector interrupt controller (NVIC) embedded trace macrocell (ETM) module. core part module called Cortex- M3 processor . term somewhat misleading, typically literature, terms core pro - cessor viewed equivalent. addition core, processor includes following elements: ■NVIC: Provides configurable interrupt handling abilities processor. facilitates low- latency exception interrupt handling, controls power management. ■ETM: optional debug component enables reconstruction program execution. ETM designed high- speed, low- power debug tool supports instruction trace. ■Debug access port (DAP): provides interface external debug access processor. ■Debug logic: Basic debug functionality includes processor halt, single- step, processor core register access, unlimited software breakpoints, full system memory access.Cortex-M3 CoreMicrocontroller Chip Cortex-M3 Processor NVIC interfaceETM interface Hardware divider32-bit multiplier32-bit ALU Control logicThumb decode Instruction interfaceData interfaceICode interface Debug logic ARM coreDAP NVIC ETMMemory protection unitBus matrixSRAM & peripheral I/FSecurity Analog InterfacesTimers & Triggers Parallel I/O Ports Serial Interfaces Peripheral bus Core memory Clock management Ener gy managementCortex-M3 processorMemory protec- tion unitFlash memory 64 kBVoltage regula- tor Power - resetBrown- de- tectorVoltage compa r- atorHigh fre- quency RC oscillator Low fre- quency RC oscillatorHigh freq crystal oscillator Low freq crystal oscillatorSRAM memory 64 kBDebug inter- faceDMA control- lerPulse counterWatch- dog tmrLow energyReal time ctrPeriph bus intTimer/ counter General purpose I/OExternal Inter- ruptsUARTUSAR Low- energy UAR TUSBPin reset 32-bit busA/D con- verterHard- ware AESD/A con- verter Figure 1.16 Typical Microcontroller Chip Based Cortex- M3 3738 Chapter 1 / Basi C Con Cepts Computer evolution ■ICode interface: Fetches instructions code memory space. ■SRAM & peripheral interface: Read/write interface data memory peripheral devices. ■Bus matrix: Connects core debug interfaces external buses microcontroller. ■Memory protection unit: Protects critical data used operating system user applications, separating processing tasks disallowing access other’s data, disabling access memory regions, allowing memory regions defined read- only, detecting unexpected memory accesses could potentially break system. upper part Figure 1.16 shows block diagram typical micro - controller built Cortex- M3, case EFM32 microcontroller. microcontroller marketed use wide variety devices, including energy, gas, water metering; alarm security systems; industrial automation devices; home automation devices; smart accessories; health fitness devices. sil - icon chip consists 10 main areas:13 ■Core memory: region includes Cortex- M3 processor, static RAM (SRAM) data memory,14 flash memory15 storing program instructions nonvarying application data. Flash memory nonvolatile (data lost power shut off) ideal purpose. SRAM stores variable data. area also includes debug interface, makes easy reprogram update system field. ■Parallel I/O ports: Configurable variety parallel I/O schemes. ■Serial interfaces: Supports various serial I/O schemes. ■Analog interfaces: Analog- to- digital digital- to- analog logic support sensors actuators. ■Timers triggers: Keeps track timing counts events, generates - put waveforms, triggers timed actions peripherals. ■Clock management: Controls clocks oscillators chip. Multiple clocks oscillators used minimize power consumption provide short startup times. ■Energy management: Manages various low- energy modes operation processor peripherals provide real- time management energy needs minimize energy consumption. ■Security: chip includes hardware implementation Advanced Encryption Standard (AES). 13This discussion go details individual modules; interested reader, in- depth discussion provided document EFM32G200.pdf, available box.com/COA10e. 14Static RAM (SRAM) form random- access memory used cache memory; see Chapter 5. 15Flash memory versatile form memory used microcontrollers external memory; discussed Chapter 6.1.7 / Cloud Computing 39 ■32-bit bus: Connects components chip. ■Peripheral bus: network lets different peripheral module commu - nicate directly without involving processor. supports timing- critical operation reduces software overhead. Comparing Figure 1.16 Figure 1.2, see many similarities general hierarchical structure. Note, however, top level microcontroller computer system single chip, whereas multicore com - puter, top level motherboard containing number chips. Another note - worthy difference cache, neither Cortex- M3 processor microcontroller whole, plays important role code data resides external memory. Though number cycles read instruc - tion data varies depending cache hit miss, cache greatly improves performance external memory used. overhead needed microcontroller. 1.7 clOud cOmputing Although general concepts cloud computing go back 1950s, cloud computing services first became available early 2000s, particularly targeted large enterprises. Since then, cloud computing spread small medium size businesses, recently consumers. Apple’s iCloud launched 2012 20 million users within week launch. Evernote, cloud- based notetaking archiving service, launched 2008, approached 100 million users less 6 years. section, provide brief overview. Cloud computing examined detail Chapter 17 . Basic Concepts increasingly prominent trend many organizations move substantial portion even information technology (IT) operations Internet- connected infrastructure known enterprise cloud computing. time, individual users PCs mobile devices relying cloud computing services backup data, synch devices, share, using personal cloud computing. NIST defines cloud computing, NIST SP- 800-145 ( NIST Definition Cloud Computing ), follows: Cloud computing: model enabling ubiquitous, convenient, on- demand network access shared pool configurable computing resources (e.g., networks, servers, storage, applications, services) rapidly provisioned released minimal management effort service provider interaction. Basically, cloud computing, get economies scale, professional network management, professional security management. features attractive companies large small, government agencies, individual PC mobile users. individual company needs pay storage 40 Chapter 1 / Basi C Con Cepts Computer evolution capacity services need. user, company individual, doesn’t hassle setting database system, acquiring hardware need, maintenance, backing data— part cloud service. theory, another big advantage using cloud computing store data share others cloud provider takes care security. Alas, customer always protected. number security failures among cloud providers. Evernote made headlines early 2013 told users reset passwords intrusion discovered. Cloud networking refers networks network management function - ality must place enable cloud computing. cloud computing solu - tions rely Internet, piece networking infrastructure. One example cloud networking provisioning high- performance and/or high- reliability networking provider subscriber. case, traffic enterprise cloud bypasses Internet uses dedicated private network facilities owned leased cloud service pro - vider. generally, cloud networking refers collection network capa - bilities required access cloud, including making use specialized services Internet, linking enterprise data centers cloud, using firewalls network security devices critical points enforce access security policies. think cloud storage subset cloud computing. essence, cloud storage consists database storage database applications hosted remotely cloud servers. Cloud storage enables small businesses individual users take advantage data storage scales needs take advantage variety database applications without buy, maintain, manage storage assets. Cloud Services essential purpose cloud computing provide convenient rental computing resources. cloud service provider (CSP) maintains computing data storage resources available Internet private networks. Customers rent portion resources needed. Virtually cloud ser - vice provided using one three models (Figure 1.17): SaaS, PaaS, IaaS, examine section. software service (saas) name implies, SaaS cloud provides service customers form software, specifically application software, running accessible cloud. SaaS follows familiar model Web services, case applied cloud resources. SaaS enables customer use cloud provider’s applications running provider’s cloud infrastructure. applications accessible various client devices simple interface Web browser. Instead obtaining desktop server licenses software products uses, enterprise obtains functions cloud service. SaaS saves complexity software installation, maintenance, upgrades, patches. Examples services level Gmail, Google’s e- mail service, Salesforce.com, help firms keep track customers. Common subscribers SaaS organizations want provide employees access typical office productivity software, document 1.7 / Cloud Computing 41 management email. Individuals also commonly use SaaS model acquire cloud resources. Typically, subscribers use specific applications demand. cloud provider also usually offers data- related features automatic backup data sharing subscribers. platform service (paas) PaaS cloud provides service customers form platform customer’s applications run. PaaS enables customer deploy onto cloud infrastructure containing customer- created acquired applications. PaaS cloud provides useful software building blocks, plus number development tools, programming languages, run- time environments, tools assist deploying new applications. effect, PaaS operating system cloud. PaaS useful organization wants develop new tailored applications paying needed computing resources needed long needed. Google App Engine Salesforce1 Platform Salesforce.com examples PaaS.ApplicationsInfrastructure service (IaaS)Traditional architecturePlatform service (PaaS)Software service (SaaS)Managed clientApplication Framework Compilers Run-time environment Databases Operating system Virtual machine Server hardware Storage NetworkingApplications Application Framework Compilers Run-time environment Databases Operating system Virtual machine Server hardware Storage Networking complex upfront cost Less scalable customizableLess complex Lower upfront cost scalable Less customizable = information technology CSP = cloud service provider Managed CSPApplicationsManaged clientApplication Framework Compilers Run-time environment Databases Operating system Virtual machine Server hardware Storage NetworkingManaged CSPApplications Application Framework Compilers Run-time environment Databases Operating system Virtual machine Server hardware Storage NetworkingManaged CSP Figure 1.17 Alternative Information Technology Architectures42 Chapter 1 / Basi C Con Cepts Computer evolution infrastructure service (iaas) IaaS, customer access underlying cloud infrastructure. IaaS provides virtual machines abstracted hardware operating systems, may controlled service application programming interface (API). IaaS offers customer processing, storage, networks, fundamental computing resources customer able deploy run arbitrary software, include operating systems applications. IaaS enables customers combine basic computing services, number crunching data storage, build highly adaptable computer systems. Examples IaaS Amazon Elastic Compute Cloud (Amazon EC2) Windows Azure. 1.8 Key termS, review Que StiOnS, prOBlemS Key Terms application processor arithmetic logic unit (ALU) ARM central processing unit (CPU) chip cloud computing cloud networking cloud storage computer architecture computer organization control unit core dedicated processor deeply embedded system embedded systemgate infrastructure service (IaaS) input– output (I/O) instruction set architecture (ISA) integrated circuit Intel x86 Internet things (IoT) main memory memory cell memory management unit (MMU) memory protection unit (MPU) microcontroller microelectronicsmicroprocessor motherboard multicore multicore processor original equipment manufacturer (OEM) platform service (PaaS) printed circuit board processor registers semiconductor semiconductor memory software service (SaaS) system bus system interconnection vacuum tubes Review Questions 1.1 What, general terms, distinction computer organization com - puter architecture? 1.2 What, general terms, distinction computer structure computer function? 1.3 four main functions computer? 1.4 List briefly define main structural components computer. 1.5 List briefly define main structural components processor. 1.6 stored program computer? 1.7 Explain Moore’s law. 1.8 List explain key characteristics computer family. 1.9 key distinguishing feature microprocessor?1.8 / Key terms, review Questions, proBlems 43 Problems 1.1 write IAS program compute results following equation. Y=aN X=1X Assume computation result arithmetic overflow X, Y, N positive integers N ≥ 1. Note : IAS assembly language, machine language. a. Use equation Sum(Y)=N(N+1) 2 writing IAS program. b. “hard way,” without using equation part (a). 1.2 a. IAS, would machine code instruction look like load con - tents memory address 2 accumulator? b. many trips memory CPU need make complete instruc - tion instruction cycle? 1.3 IAS, describe English process CPU must undertake read value memory write value memory terms put MAR, MBR, address bus, data bus, control bus. 1.4 Given memory contents IAS computer shown below, Address Contents 08A 010FA210FB 08B 010FA0F08D 08C 020FA210FB show assembly language code program, starting address 08A. Explain program does. 1.5 Figure 1.6, indicate width, bits, data path (e.g., AC ALU). 1.6 IBM 360 Models 65 75, addresses staggered two separate main mem - ory units (e.g., even- numbered words one unit odd- numbered words another). might purpose technique? 1.7 relative performance IBM 360 Model 75 50 times 360 Model 30, yet instruction cycle time 5 times fast. account discrepancy? 1.8 browsing Billy Bob’s computer store, overhear customer asking Billy Bob fastest computer store buy. Billy Bob replies, “You’re looking Macintoshes. fastest Mac runs clock speed 1.2 GHz. really want fastest machine, buy 2.4-GHz Intel Pentium IV instead.” Billy Bob correct? would say help customer? 1.9 ENIAC, precursor ISA machine, decimal machine, register represented ring 10 vacuum tubes. time, one vacuum tube state, representing one 10 decimal digits. Assuming ENIAC capability multiple vacuum tubes state simultaneously, representation “wasteful” range integer values could represent using 10 vacuum tubes? 1.10 following examples, determine whether embedded system, explaining not. a. programs understand physics and/or hardware embedded? example, one uses finite- element methods predict fluid flow airplane wings? b. internal microprocessor controlling disk drive example embedded system?44 Chapter 1 / Basi C Con Cepts Computer evolution c. I/O drivers control hardware, presence I/O driver imply computer executing driver embedded? d. PDA (Personal Digital Assistant) embedded system? e. microprocessor controlling cell phone embedded system? f. computers big phased- array radar considered embedded? radars 10-story buildings one three 100-foot diameter radiating patches sloped sides building. g. traditional flight management system (FMS) built airplane cockpit considered embedded? h. computers hardware- in- the- loop (HIL) simulator embedded? i. computer controlling pacemaker person’s chest embedded computer? j. computer controlling fuel injection automobile engine embedded?45Chapter Performance Issues 2.1 Designing Performance Microprocessor Speed Performance Balance Improvements Chip Organization Architecture 2.2 Multicore, MICs, GPGPUs 2.3 Two Laws Provide Insight: Amdahl’s Law Little’s Law Amdahl’s Law Little’s Law 2.4 Basic Measures Computer Performance Clock Speed Instruction Execution Rate 2.5 Calculating Mean Arithmetic Mean Harmonic Mean Geometric Mean 2.6 Benchmarks SPEC Benchmark Principles SPEC Benchmarks 2.7 Key Terms, Review Questions, Problems 46 Chapter 2 / performan Ce Issues chapter addresses issue computer system performance. begin consideration need balanced utilization computer resources, pro - vides perspective useful throughout book. Next look contemporary computer organization designs intended provide performance meet current projected demand. Finally, look tools models devel - oped provide means assessing comparative computer system performance. 2.1 Designing Performance Year year, cost computer systems continues drop dramatically, performance capacity systems continue rise equally dramatically. Today’s laptops computing power IBM mainframe 10 15 years ago. Thus, virtually “free” computer power. Processors inexpen - sive microprocessors throw away. digital pregnancy test example (used thrown away). continuing technological revolution enabled development applications astounding complex - ity power. example, desktop applications require great power today’s microprocessor-based systems include ■Image processing ■Three-dimensional rendering ■Speech recognition ■Videoconferencing ■Multimedia authoring ■Voice video annotation files ■Simulation modeling Workstation systems support highly sophisticated engineering scientific applications capacity support image video applications. addi - tion, businesses relying increasingly powerful servers handle transaction database processing support massive client/server networks replaced huge mainframe computer centers yesteryear. well, cloud service Learning Objectives studying chapter, able to: rUnderstand key performance issues relate computer design. rExplain reasons move multicore organization, understand trade-off cache processor resources single chip. rDistinguish among multicore, MIC, GPGPU organizations. rSummarize issues computer performance assessment. rDiscuss SPEC benchmarks. rExplain differences among arithmetic, harmonic, geometric means.2.1 / Des IgnIng performan Ce 47 providers use massive high-performance banks servers satisfy high-volume, high-transaction-rate applications broad spectrum clients. fascinating perspective computer organiza - tion architecture that, one hand, basic building blocks today’s computer miracles virtually IAS computer 50 years ago, hand, techniques squeezing maximum performance materials hand become increasingly sophisticated. observation serves guiding principle presentation book. progress various elements components computer, two objectives pursued. First, book explains fundamental functionality area consideration, second, book explores techniques required achieve maximum performance. remainder section, highlight driving factors behind need design performance. Microprocessor Speed gives Intel x86 processors IBM mainframe computers mind-boggling power relentless pursuit speed processor chip manufacturers. evolu - tion machines continues bear Moore’s law, described Chapter 1. long law holds, chipmakers unleash new generation chips every three years—with four times many transistors. memory chips, quadrupled capacity dynamic random-access memory (DRAM) , still basic technology computer main memory, every three years. microprocessors, addition new circuits, speed boost comes reducing distances them, improved performance four- fivefold every three years since Intel launched x86 family 1978. raw speed microprocessor achieve potential unless fed constant stream work form computer instructions. - thing gets way smooth flow undermines power proces - sor. Accordingly, chipmakers busy learning fabricate chips greater greater density, processor designers must come ever elaborate techniques feeding monster. Among techniques built contemporary processors following: ■Pipelining: execution instruction involves multiple stages oper - ation, including fetching instruction, decoding opcode, fetching oper - ands, performing calculation, on. Pipelining enables processor work simultaneously multiple instructions performing different phase multiple instructions time. processor - laps operations moving data instructions conceptual pipe stages pipe processing simultaneously. example, one instruc - tion executed, computer decoding next instruction. principle seen assembly line. ■Branch prediction: processor looks ahead instruction code fetched memory predicts branches, groups instructions, likely processed next. processor guesses right time, prefetch correct instructions buffer processor kept busy. sophisticated examples strategy predict 48 Chapter 2 / performan Ce Issues next branch multiple branches ahead. Thus, branch prediction poten - tially increases amount work available processor execute. ■Superscalar execution: ability issue one instruction every processor clock cycle. effect, multiple parallel pipelines used. ■Data flow analysis: processor analyzes instructions dependent other’s results, data, create optimized schedule instruc - tions. fact, instructions scheduled executed ready, independ - ent original program order. prevents unnecessary delay. ■Speculative execution: Using branch prediction data flow analysis, processors speculatively execute instructions ahead actual appearance program execution, holding results temporary locations. ena - bles processor keep execution engines busy possible execut - ing instructions likely needed. sophisticated techniques made necessary sheer power processor. Collectively make possible execute many instruc - tions per processor cycle, rather take many cycles per instruction. Performance Balance processor power raced ahead breakneck speed, critical compo - nents computer kept up. result need look performance balance: adjustment/tuning organization architecture compensate mismatch among capabilities various components. problem created mismatches particularly critical inter - face processor main memory. processor speed grown rap - idly, speed data transferred main memory processor lagged badly. interface processor main memory crucial pathway entire computer responsible carry - ing constant flow program instructions data memory chips processor. memory pathway fails keep pace processor’s insist - ent demands, processor stalls wait state, valuable processing time lost. system architect attack problem number ways, reflected contemporary computer designs. Consider following examples: ■Increase number bits retrieved one time making DRAMs “wider” rather “deeper” using wide bus data paths. ■Change DRAM interface make efficient including cache1 buffering scheme DRAM chip. ■Reduce frequency memory access incorporating increasingly com - plex efficient cache structures processor main memory. includes incorporation one caches processor chip well off-chip cache close processor chip. 1A cache relatively small fast memory interposed larger, slower memory logic accesses larger memory. cache holds recently accessed data designed speed subse - quent access data. Caches discussed Chapter 4.2.1 / Des IgnIng performan Ce 49 ■Increase interconnect bandwidth processors memory using higher-speed buses hierarchy buses buffer structure data flow. Another area design focus handling I/O devices. computers become faster capable, sophisticated applications developed support use peripherals intensive I/O demands. Figure 2.1 gives examples typical peripheral devices use personal computers workstations. devices create tremendous data throughput demands. current generation processors handle data pumped devices, remains problem getting data moved processor peripheral. Strategies include caching buffering schemes plus use higher-speed interconnection buses elaborate interconnection struc - tures. addition, use multiple-processor configurations aid satisfying I/O demands. key balance. Designers constantly strive balance throughput processing demands processor components, main memory, I/O devices, interconnection structures. design must constantly rethought cope two constantly evolving factors: ■The rate performance changing various technology areas (processor, buses, memory, peripherals) differs greatly one type ele - ment another. ■New applications new peripheral devices constantly change nature demand system terms typical instruction profile data access patterns. 10110210310410510610710810910101011 Data Rate (bps)Graphics displayEthernet modem (max speed) Wi-Fi modem (max speed) Hard disk Optical disc Laser printer Scanner Mouse Keyboard Figure 2.1 Typical I/O Device Data Rates50 Chapter 2 / performan Ce Issues Thus, computer design constantly evolving art form. book attempts present fundamentals art form based present survey current state art. Improvements Chip Organization Architecture designers wrestle challenge balancing processor performance main memory computer components, need increase pro - cessor speed remains. three approaches achieving increased processor speed: ■Increase hardware speed processor. increase fundamentally due shrinking size logic gates processor chip, gates packed together tightly increasing clock rate. gates closer together, propagation time signals significantly reduced, enabling speeding processor. increase clock rate means individual operations executed rapidly. ■Increase size speed caches interposed proces - sor main memory. particular, dedicating portion processor chip cache, cache access times drop significantly. ■Make changes processor organization architecture increase effective speed instruction execution. Typically, involves using parallel - ism one form another. Traditionally, dominant factor performance gains increases clock speed due logic density. However, clock speed logic density increase, number obstacles become significant [INTE04]: ■Power: density logic clock speed chip increase, power density (Watts/cm2). difficulty dissipating heat generated high-density, high-speed chips becoming serious design issue [GIBB04, BORK03]. ■RC delay: speed electrons flow chip transis - tors limited resistance capacitance metal wires connecting them; specifically, delay increases RC product increases. components chip decrease size, wire interconnects become thinner, increasing resistance. Also, wires closer together, increasing capacitance. ■Memory latency throughput: Memory access speed (latency) transfer speed (throughput) lag processor speeds, previously discussed. Thus, emphasis organization architectural approaches improving performance. techniques discussed later chapters text. Beginning late 1980s, continuing 15 years, two main strat - egies used increase performance beyond achieved simply increasing clock speed. First, increase cache capacity. typically two three levels cache processor main mem - ory. chip density increased, cache memory incorpor - ated chip, enabling faster cache access. example, original Pentium 2.1 / Des IgnIng performan Ce 51 chip devoted 10% on-chip area cache. Contemporary chips devote half chip area caches. And, typically, three-quarters half pipeline-related control buffering. Second, instruction execution logic within processor become increas - ingly complex enable parallel execution instructions within processor. Two noteworthy design approaches pipelining superscalar. pipeline works much assembly line manufacturing plant enabling different stages execution different instructions occur time along pipeline. superscalar approach essence allows multiple pipelines within single processor, instructions depend one another executed parallel. mid late 90s, approaches reaching point diminishing returns. internal organization contemporary processors exceedingly complex able squeeze great deal parallelism instruction stream. seems likely significant increases direction relatively modest [GIBB04]. three levels cache processor chip, level providing substantial capacity, also seems benefits cache reaching limit. However, simply relying increasing clock rate increased performance runs power dissipation problem already referred to. faster clock rate, greater amount power dissipated, fundamental phys - ical limits reached. Figure 2.2 illustrates concepts discussing.2 top line shows that, per Moore’s Law, number transistors single chip continues 2I grateful Professor Kathy Yelick UC Berkeley, provided graph.0.1110 1970 1975 1980 1985 1990 1995 2000 2005 2010Transistors (Thousands) Frequency (MHz) Power (W) Cores 102103104105106107 Figure 2.2 Processor Trends52 Chapter 2 / performan Ce Issues grow exponentially.3 Meanwhile, clock speed leveled off, order prevent rise power. continue increasing performance, designers find ways exploiting growing number transistors simply building complex processor. response recent years development multicore computer chip. 2.2 multicore, mics, gPgPus difficulties cited preceding section mind, designers turned fundamentally new approach improving performance: placing multiple processors chip, large shared cache. use multiple proces - sors chip, also referred multiple cores, multicore , provides potential increase performance without increasing clock rate. Studies indicate that, within processor, increase performance roughly proportional square root increase complexity [BORK03]. software support effective use multiple processors, doubling number processors almost doubles performance. Thus, strategy use two simpler processors chip rather one complex processor. addition, two processors, larger caches justified. important power consumption memory logic chip much less processing logic. logic density chips continues rise, trend cores cache single chip continues. Two-core chips quickly followed four-core chips, 8, 16, on. caches became larger, made performance sense create two three levels cache chip, ini - tially, first-level cache dedicated individual processor levels two three shared processors. common second-level cache also private core. Chip manufacturers process making huge leap forward number cores per chip, 50 cores per chip. leap perform - ance well challenges developing software exploit large number cores led introduction new term: many integrated core (MIC) . multicore MIC strategy involves homogeneous collection general- purpose processors single chip. time, chip manufacturers pursuing another design option: chip multiple general-purpose processors plus graphics processing units (GPUs) specialized cores video processing tasks. broad terms, GPU core designed perform parallel oper - ations graphics data. Traditionally found plug-in graphics card (display adapter), used encode render 2D 3D graphics well process video. Since GPUs perform parallel operations multiple sets data, increasingly used vector processors variety applications require repetitive computations. blurs line GPU CPU 3The observant reader note transistor count values figure significantly less Figure 1.12. latter figure shows transistor count form main memory known DRAM (discussed Chapter 5), supports higher transistor density processor chips.2.3 / two Laws provIDe Ins Ight: ahmDahL’s Law LIttLe’s Law 53 [AROR12, FATA08, PROP11]. broad range applications supported processor, term general-purpose computing GPUs (GPGPU) used. explore design characteristics multicore computers Chapter 18 GPGPUs Chapter 19. 2.3 two laws Provi De insight: ahmDahl’s law little’s law section, look two equations, called “laws.” two laws unrelated provide insight performance parallel systems multicore systems. Amdahl’s Law Computer system designers look ways improve system performance advances technology change design. Examples include use parallel processors, use memory cache hierarchy, speedup memory access time I/O transfer rate due technology improvements. cases, important note speedup one aspect technology design result corresponding improvement performance. limitation succinctly expressed Amdahl’s law. Amdahl’s law first proposed Gene Amdahl 1967 ([AMDA67], [AMDA13]) deals potential speedup program using multiple pro - cessors compared single processor. Consider program running single processor fraction (1-f) execution time involves code inherently sequential, fraction f involves code infinitely paralleliz - able scheduling overhead. Let total execution time program using single processor. speedup using parallel processor N pro- cessors fully exploits parallel portion program follows: Speedup=Time execute program single processor Time execute program N parallel processors =T(1-f)+Tf T(1-f)+Tf N=1 (1-f)+f N equation illustrated Figures 2.3 2.4. Two important conclusions drawn: 1. f small, use parallel processors little effect. 2. N approaches infinity, speedup bound 1/(1-f), diminishing returns using processors. conclusions pessimistic, assertion first put forward [GUST88]. example, server maintain multiple threads multiple tasks handle multiple clients execute threads tasks parallel limit number processors. Many database applications involve computa - tions massive amounts data split multiple parallel tasks. 54 Chapter 2 / performan Ce Issues Nevertheless, Amdahl’s law illustrates problems facing industry develop - ment multicore machines ever-growing number cores: software runs machines must adapted highly parallel execution environ - ment exploit power parallel processing. Amdahl’s law generalized evaluate design technical improve - ment computer system. Consider enhancement feature system results speedup. speedup expressed Speedup=Performance enhancement Performance enhancement=Execution time enhancement Execution time enhancement (2.1)T (1 – f)T (1 – f)T fT fT N 1f11 NT Figure 2.3 Illustration Amdahl’s Law Number Pr ocessorsSpeedupf = 0.95 f = 0.90 f = 0.75 f = 0.5 10 1 100 10005101520 Figure 2.4 Amdahl’s Law Multiprocessors2.3 / two Laws provIDe Ins Ight: ahmDahL’s Law LIttLe’s Law 55 Suppose feature system used execution fraction time f, enhancement, speedup feature enhancement SUf. overall speedup system Speedup=1 (1-f)+f SUf ExAMPLE 2.1 Suppose task makes extensive use floating-point operations, 40% time consumed floating-point operations. new hardware de - sign, floating-point module sped factor K. overall speedup follows: Speedup=1 0.6+0.4 K Thus, independent K, maximum speedup 1.67 . Little’s Law fundamental simple relation broad applications Little’s Law [LITT61, LITT11].4 apply almost system statistically steady state, leakage. Specifically, steady state system items arrive average rate l items per unit time. items stay system average W units time. Finally, average L units system one time. Little’s Law relates three variables L=lW. Using queuing theory terminology, Little’s Law applies queuing system. central element system server, provides service items. Items population items arrive system served. server idle, item served immediately. Otherwise, arriving item joins waiting line, queue. single queue single server, single queue multiple servers, multiples queues, one multiple servers. ser - ver completed serving item, item departs. items waiting queue, one immediately dispatched server. server model represent anything performs function service collection items. Examples: processor provides service processes; transmission line provides transmission service packets frames data; I/O device provides read write service I/O requests. understand Little’s formula, consider following argument, focuses experience single item. item arrives, find 4The second reference retrospective article law Little wrote 50 years original paper. must unique history technical literature, although Amdahl comes close, 46-year gap [AMDA67] [AMDA13].56 Chapter 2 / performan Ce Issues average L items ahead it, one serviced rest queue. item leaves system serviced, leave behind average number items system, namely L, L defined average number items waiting. Further, average time item system W. Since items arrive rate l, reason time W, total lW items must arrived. Thus w=lW. summarize, steady state conditions, average number items queuing system equals average rate items arrive multiplied average time item spends system. relationship requires assumptions. need know service time distribution is, distribution arrival times is, order priority items served. simplicity generality, Little’s Law extremely useful experienced somewhat revival due interest performance problems related multicore computers. simple example, [LITT11], illustrates Little’s Law might applied. Consider multicore system, core supporting multiple threads execution. level, cores share common memory. cores share common main memory typically share common cache memory well. case, thread executing, may arrive point must retrieve piece data common memory. thread stops sends request data. stopped threads queue. system used server, analyst determine demand system terms rate user requests, translate rate requests data threads generated respond individual user request. purpose, user request broken subtasks implemented threads. l=the average rate total thread processing required mem - bers’ requests broken whatever detailed subtasks required. Define L average number stopped threads waiting relevant time. W=average response time. simple model serve guide designers whether user requirements met and, not, provide quan - titative measure amount improvement needed. 2.4 Basic measures comPuter Performance evaluating processor hardware setting requirements new systems, per - formance one key parameters consider, along cost, size, security, reliability, and, cases, power consumption. difficult make meaningful performance comparisons among different processors, even among processors family. Raw speed far less import - ant processor performs executing given application. Unfortu - nately, application performance depends raw speed processor also instruction set, choice implementation language, efficiency compiler, skill programming done implement application. section, look traditional measures processor speed. next section, examine benchmarking, common approach assessing processor computer system performance. following section discusses average results multiple tests.2.4 / Bas IC measures Computer performan Ce 57 Clock Speed Operations performed processor, fetching instruction, decoding instruction, performing arithmetic operation, on, governed system clock. Typically, operations begin pulse clock. Thus, fundamental level, speed processor dictated pulse frequency pro - duced clock, measured cycles per second, Hertz (Hz). Typically, clock signals generated quartz crystal, generates constant sine wave power applied. wave converted digital voltage pulse stream provided constant flow processor circuitry (Figure 2.5). example, 1-GHz processor receives 1 billion pulses per second. rate pulses known clock rate , clock speed . One increment, pulse, clock referred clock cycle , clock tick . time pulses cycle time . clock rate arbitrary, must appropriate physical layout processor. Actions processor require signals sent one pro - cessor element another. signal placed line inside processor, takes finite amount time voltage levels settle accurate value (logical 1 0) available. Furthermore, depending physical layout processor circuits, signals may change rapidly others. Thus, operations must synchronized paced proper electrical sig - nal (voltage) values available operation. execution instruction involves number discrete steps, fetching instruction memory, decoding various portions instruc - tion, loading storing data, performing arithmetic logical operations. Thus, instructions processors require multiple clock cycles com - plete. instructions may take cycles, others require dozens. addition, pipelining used, multiple instructions executed simulta - neously. Thus, straight comparison clock speeds different processors tell whole story performance. quartzcrystal Computer Desktop Enc yclopedia 1998, Computer Language Co.analog digital conv ersion Figure 2.5 System Clock58 Chapter 2 / performan Ce Issues Instruction Execution Rate processor driven clock constant frequency f or, equivalently, con - stant cycle time t, t=1/f. Define instruction count, Ic, program number machine instructions executed program runs com - pletion defined time interval. Note number instruction executions, number instructions object code program. important parameter average cycles per instruction ( CPI) program. instructions required number clock cycles, CPI would constant value processor. However, given processor, number clock cycles required varies different types instructions, load, store, branch, on. Let CPIi number cycles required instruction type i, Ii number executed instructions type given program. calculate overall CPI follows: CPI=an i=1(CPIi*Ii) Ic (2.2) processor time needed execute given program expressed T=Ic*CPI*t refine formulation recognizing execution instruction, part work done processor, part time word transferred memory. latter case, time transfer depends memory cycle time, may greater processor cycle time. rewrite preceding equation T=Ic*[p+(m*k)]*t p number processor cycles needed decode execute instruc - tion, number memory references needed, k ratio memory cycle time processor cycle time. five performance factors preceding equation (Ic, p, m, k, t) influenced four system attributes: design instruction set (known instruction set architecture ); compiler tech - nology (how effective compiler producing efficient machine language program high-level language program); processor implementation; cache memory hierarchy. Table 2.1 matrix one dimension shows five performance factors dimension shows four system attri - butes. X cell indicates system attribute affects performance factor. Table 2.1 Performance Factors System Attributes Ic p k Instruction set architecture X X Compiler technology X X X Processor implementation X X Cache memory hierarchy X X2.5 / Ca LCuLatIng mean 59 common measure performance processor rate instructions executed, expressed millions instructions per second (MIPS), referred MIPS rate . express MIPS rate terms clock rate CPI follows: MIPS rate =Ic T*106=f CPI*106 (2.3) ExAMPLE 2.2 Consider execution program results execution 2 million instructions 400-MHz processor. program consists four major types instructions. instruction mix CPI instruction type given below, based result program trace experiment: Instruction Type CPI Instruction Mix (%) Arithmetic logic 1 60 Load/store cache hit 2 18 Branch 4 12 Memory reference cache miss 8 10 average CPI program executed uniprocessor trace results CPI=0.6+(2*0.18)+(4*0.12)+(8*0.1)=2.24. corres - ponding MIPS rate (400*106)/(2.24*106)≈178. Another common performance measure deals floating-point instruc - tions. common many scientific game applications. Floating-point performance expressed millions floating-point operations per second (MFLOPS), defined follows: MFLOPS rate=Number executed floating-point operations program Execution time *106 2.5 calculating mean evaluating aspect computer system performance, often case single number, execution time memory consumed, used characterize performance compare systems. Clearly, single number provide simplified view system’s capability. Nevertheless, especially field benchmarking, single numbers typically used performance comparison [SMIT88]. discussed Section 2.6, use benchmarks compare systems involves calculating mean value set data points related execution time. turns multiple alternative algorithms used calculating mean value, source controversy 60 Chapter 2 / performan Ce Issues benchmarking field. section, define alternative algorithms comment properties. prepares us discussion next section mean calculation benchmarking. three common formulas used calculating mean arithmetic, geo - metric, harmonic. Given set n real numbers ( x1, x2, …, xn), three means defined follows: Arithmetic mean AM=x1+g +xn n=1 nan i=1xi (2.4) Geometric mean GM=n2x1*g *xn=aqn i=1xib1/n =ea1 nan i=1ln(xi)b (2.5) Harmonic mean HM=n a1 x1b+g +a1 xnb=n i=1a1 xib xi70 (2.6) shown following inequality holds: AM…GM…HM values equal x1=x2=c xn. get useful insight alternative calculations defining functional mean. Let f(x) continuous monotonic function defined inter - val 0…y6∞. functional mean respect function f(x) n positive real numbers ( x1, x2, …, xn) defined Functional mean FM=f-1af(x1)+g +f(xn) nb=f-1a1 nan i=1f(xi)b f-1(x) inverse f(x). mean values defined Equations (2.1) (2.3) special cases functional mean, follows: ■AM FM respect f(x)=x ■GM FM respect f(x)=ln x ■HM FM respect f(x)=1/x ExAMPLE 2.3 Figure 2.6 illustrates three means applied various data sets, eleven data points maximum data point value 11. median value also included chart. Perhaps stands figure HM tendency produce misleading result data skewed larger values small-value outlier.2.5 / Ca LCuLatIng mean 61 Let us consider means appropriate given per - formance measure. preface remarks, noted num - ber papers ([CITR06], [FLEM86], [GILA95], [JACO95], [JOHN04], [MASH04], [SMIT88]) books ([HENN12], [HWAN93], [JAIN91], [LILJ00]) years argued pros cons three means performance analysis come conflicting conclusions. simplify complex controversy, note conclusions reached depend much examples chosen way objectives stated.0 246 89 10 1357 11MD GM HM(a) MD GM HM(b) MD GM HM(c) MD GM HM(d) MD GM HM(e) MD GM HM(f) MD GM HM MD = median = arithmetic mean GM = geometric mean HM = harmonic mean(a) Constant (1 1, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11) (b) Clustered around central value (3, 5, 6, 6, 7, 7, 7, 8, 8, 9, 11) (c) Uniform distribution (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11) (d) Lar ge-number bias (1, 4, 4, 7, 7, 9, 9, 10, 10, 1 1, 11) (e) Small-number bias(1, 1, 2, 2, 3, 3, 5, 5, 8, 8, 11) (f) Upper outlier (1 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) (g) Lower outlier (1, 1 1, 11, 11, 11, 11, 11, 11, 11, 11, 11)(g) Figure 2.6 Comparison Means Various Data Sets (each set maximum data point value 11)62 Chapter 2 / performan Ce Issues Arithmetic Mean appropriate measure sum measurements meaningful interesting value. good candidate comparing execution time per - formance several systems. example, suppose interested using system large-scale simulation studies wanted evaluate several alternative products. system could run simulation multiple times different input val - ues run, take average execution time across runs. use multiple runs different inputs ensure results heavily biased unusual feature given input set. runs good measure system’s performance simulations, good number use system comparison. used time-based variable (e.g., seconds), program exe - cution time, important property directly proportional total time. So, total time doubles, mean value doubles. Harmonic Mean situations, system’s execution rate may viewed useful mea - sure value system. could either instruction execution rate, measured MIPS MFLOPS, program execution rate, measures rate given type program executed. Consider wish calculated mean behave. makes sense say would like mean rate proportional total rate, total rate defined sum individual rates. sum rates would meaningless statistic. Rather, would like mean inversely proportional total execution time. example, total time execute benchmark programs suite pro - grams twice much system C system D, would want mean value execution rate half much system C system D. Let us look basic example first examine performs. Sup - pose set n benchmark programs record execution times program given system t1, t2, …, tn. simplicity, let us assume program executes number operations Z; could weight individual programs calculate accordingly would change conclusion argument. execution rate individual program Ri=Z/ti. use calculate average execution rate. AM=1 nan i=1Ri=1 nan i=1Z ti=Z nan i=11 ti see execution rate proportional sum inverse execution times, inversely proportional sum execution times. Thus, desired property. HM yields following result. HM=n i=1a1 Rib=n i=1a1 Z/tib=nZ i=1ti HM inversely proportional total execution time, desired property.2.5 / Ca LCuLatIng mean 63 reader may wonder go effort. want compare execution times, could simply compare total execution times three systems. want compare rates, could simply take inverse total execution time, shown table. two reasons individ - ual calculations rather looking aggregate numbers: Table 2.2 Comparison Arithmetic Harmonic Means Rates Computer time (secs)Computer B time (secs)Computer C time (secs)Computer rate (MFLOPS)Computer B rate (MFLOPS)Computer C rate (MFLOPS) Program 1 (108 FP ops)2.0 1.0 0.75 50 100 133.33 Program 2 (108 FP ops)0.75 2.0 4.0 133.33 50 25 Total execution time2.75 3.0 4.75 — — — Arithmetic mean times1.38 1.5 2.38 — — — Inverse total execution time (1/sec)0.36 0.33 0.21 — — — Arithmetic mean rates— — — 91.67 75.00 79.17 Harmonic mean rates— — — 72.72 66.67 42.11 ExAMPLE 2.4 simple numerical example illustrate difference two means calculating mean value rates, shown Table 2.2. table compares performance three computers execution two programs. simplicity, assume execution program results execution 108 floating-point operations. left half table shows execution times computer running program, total execution time, execution times. Computer executes less total time B, executes less total time C, reflected accurately AM. right half table provides comparison terms rates, expressed MFLOPS. rate calculation straightforward. example, program 1 executes 100 million floating-point operations. Computer takes 2 seconds execute program MFLOPS rate 100/2=50. Next, consider rates. greatest value computer A, suggests fastest computer. terms total execu - tion time, minimum time, fastest computer three. rates shows B slower C, whereas fact B faster C. Looking HM values, see correctly reflect speed ordering computers. confirms HM preferred calculating rates.64 Chapter 2 / performan Ce Issues 1. customer researcher may interested overall average performance also performance different types benchmark pro - grams, business applications, scientific modeling, multimedia appli - cations, systems programs. Thus, breakdown type benchmark needed well total. 2. Usually, different programs used evaluation weighted differently. Table 2.2, assumed two test programs execute num - ber operations. case, may want weight accordingly. different programs could weighted differently reflect importance priority. Let us see result test programs weighted proportional number operations. Following preceding notation, program executes Zi instructions time ti. rate weighted instructions count. weighted HM therefore: WHM=1 i=1£°Zi j=1Zj ¢a1 Rib≥=n i=1£°Zi j=1Zj ¢ati Zib≥=an j=1Zj i=1ti (2.7) see weighted HM quotient sum operation count divided sum execution times. Geometric Mean Looking equations three types means, easier get intuitive sense behavior HM GM. Several observa - tions, [FEIT15], may helpful regard. First, note respect changes values, GM gives equal weight values data set. example, suppose set data values averaged includes large values small values. Here, dominated large values. change 10% largest value noticeable effect, change smallest value factor negligible effect. contrast, change value 10% data values results change GM: 2n1.1. ExAMPLE 2.5 point illustrated data set (e) Figure 2.6. effects increasing either maximum minimum value data set 10%: Geometric Mean Arithmetic Mean Original value 3.37 4.45 Increase max value 11 12.1 ( +10%)3.40 ( + 0.87,) 4.55 ( + 2.24,) Increase min value 1 1.1 ( +10%)3.40 ( + 0.87,) 4.46 ( + 0.20,)2.5 / Ca LCuLatIng mean 65 second observation GM ratio, GM ratios equals ratio GMs: GM=aqn i=1Zi tib1/n =aqn i=1Zib1/n aqn i=1tib1/n (2.8) Compare Equation 2.4. use execution times, opposed rates, one drawback GM may non-monotonic relative intuitive AM. words may cases one data set larger another set, GM smaller. ExAMPLE 2.6 Figure 2.6, data set larger data set c, opposite true GM. Data set c Data set Arithmetic mean 7.00 7.55 Geometric mean 6.68 6.42 One property GM made appealing benchmark analy - sis provides consistent results measuring relative performance machines. fact benchmarks primarily used for: compare one machine another terms performance metrics. results, seen, expressed terms values normalized reference machine. ExAMPLE 2.7 simple example illustrate way GM exhibits con - sistency normalized results. Table 2.3, use performance results used Table 2.2. Table 2.3a, results normalized Computer A, means calculated normalized values. Based total execution time, faster B, faster C. AMs GMs normalized times reflect this. Table 2.3b, systems normalized B. GMs correctly reflect rela - tive speeds three computers, produces different ordering. Sadly, consistency always produce correct results. Table 2.4, execution times altered. again, reports conflicting results two normalizations. GM reports consistent results, result B faster C, equal. examples like fueled “benchmark means wars” citations listed earlier. safe say single number provide information one needs comparing performance across systems. However, 66 Chapter 2 / performan Ce Issues Table 2.4 Another Comparison Arithmetic Geometric Means Normalized Results (a) Results normalized Computer Computer time Computer B time Computer C time Program 1 2.0 (1.0) 1.0 (0.5) 0.20 (0.1) Program 2 0.4 (1.0) 2.0 (5.0) 4.0 (10.0) Total execution time 2.4 3.00 4.2 Arithmetic mean normalized times1.00 2.75 5.05 Geometric mean normalized times1.00 1.58 1.00 (b) Results normalized Computer B Computer time Computer B time Computer C time Program 1 2.0 (2.0) 1.0 (1.0) 0.20 (0.2) Program 2 0.4 (0.2) 2.0 (1.0) 4.0 (2.0) Total execution time 2.4 3.00 4.2 Arithmetic mean normalized times1.10 1.00 1.10 Geometric mean normalized times0.63 1.00 0.63Table 2.3 Comparison Arithmetic Geometric Means Normalized Results (a) Results normalized Computer Computer time Computer B time Computer C time Program 1 2.0 (1.0) 1.0 (0.5) 0.75 (0.38) Program 2 0.75 (1.0) 2.0 (2.67) 4.0 (5.33) Total execution time 2.75 3.0 4.75 Arithmetic mean normalized times1.00 1.58 2.85 Geometric mean normalized times1.00 1.15 1.41 (b) Results normalized Computer B Computer time Computer B time Computer C time Program 1 2.0 (2.0) 1.0 (1.0) 0.75 (0.75) Program 2 0.75 (0.38) 2.0 (1.0) 4.0 (2.0) Total execution time 2.75 3.0 4.75 Arithmetic mean normalized times1.19 1.00 1.38 Geometric mean normalized times0.87 1.00 1.222.6 / Ben Chmarks speC 67 despite conflicting opinions literature, SPEC chosen use GM, several reasons: 1. mentioned, GM gives consistent results regardless system used reference. benchmarking primarily comparison analysis, important feature. 2. documented [MCMA93], confirmed subsequent analyses SPEC analysts [MASH04], GM less biased outliers HM AM. 3. [MASH04] demonstrates distributions performance ratios better modeled lognormal distributions normal ones, gen - erally skewed distribution normalized numbers. confirmed [CITR06]. And, shown Equation (2.5), GM described back-transformed average lognormal distribution. 2.6 Benchmarks sPec Benchmark Principles Measures MIPS MFLOPS proven inadequate evaluating per - formance processors. differences instruction sets, instruction execu - tion rate valid means comparing performance different architectures. ExAMPLE 2.8 Consider high-level language statement: = B + C /* assume quantities main memory */ traditional instruction set architecture, referred complex instruction set computer (CISC), instruction compiled one processor instruction: add mem(B), mem(C), mem (A) typical RISC machine, compilation would look something like this: load mem(B), reg(1); load mem(C), reg(2); add reg(1), reg(2), reg(3); store reg(3), mem (A) nature RISC architecture (discussed Chapter 15), - chines may execute original high-level language instruction time. example representative two machines, CISC machine rated 1 MIPS, RISC machine would rated 4 MIPS. amount high-level language work amount time. Another consideration performance given processor given program may useful determining processor perform different type application. Accordingly, beginning late 1980s early 1990s, industry academic interest shifted measuring performance 68 Chapter 2 / performan Ce Issues systems using set benchmark programs. set programs run different machines execution times compared. Benchmarks provide guid - ance customers trying decide system buy, useful ven - dors designers determining design systems meet benchmark goals. [WEIC90] lists following desirable characteristics benchmark program: 1. written high-level language, making portable across different machines. 2. representative particular kind programming domain paradigm, systems programming, numerical programming, commercial programming. 3. measured easily. 4. wide distribution. SPEC Benchmarks common need industry academic research communities generally accepted computer performance measurements led development stan - dardized benchmark suites. benchmark suite collection programs, defined high-level language, together attempt provide representative test computer particular application system programming area. best known collection benchmark suites defined maintained Standard Performance Evaluation Corporation (SPEC), industry consortium. orga - nization defines several benchmark suites aimed evaluating computer systems. SPEC performance measurements widely used comparison research purposes. best known SPEC benchmark suites SPEC CPU2006. industry standard suite processor-intensive applications. is, SPEC CPU2006 appropriate measuring performance applications spend time computation rather I/O. SPEC suites include following: ■SPECviewperf: Standard measuring 3D graphics performance based professional applications. ■SPECwpc: benchmark measure key aspects workstation performance based diverse professional applications, including media entertain - ment, product development, life sciences, financial services, energy. ■SPECjvm2008: Intended evaluate performance combined hardware software aspects Java Virtual Machine (JVM) client platform. ■SPECjbb2013 (Java Business Benchmark): benchmark evaluating serv - er-side Java-based electronic commerce applications. ■SPECsfs2008: Designed evaluate speed request-handling capabili - ties file servers. ■SPECvirt_sc2013: Performance evaluation datacenter servers used vir - tualized server consolidation. Measures end-to-end performance system components including hardware, virtualization platform, virtualized guest operating system application software. benchmark supports hardware virtualization, operating system virtualization, hard - ware partitioning schemes.2.6 / Ben Chmarks speC 69 CPU2006 suite based existing applications already ported wide variety platforms SPEC industry members. order make benchmark results reliable realistic, CPU2006 benchmarks drawn real-life applications, rather using artificial loop programs synthetic benchmarks. suite consists 12 integer benchmarks written C C++, 17 floating-point benchmarks written C, C++, Fortran (Tables 2.5 2.6). suite contains 3 million lines code. fifth generation Table 2.5 SPEC CPU2006 Integer Benchmarks BenchmarkReference time (hours)Instr count (billion) LanguageApplication Area Brief Description 400.perlbench 2.71 2378 C Programming LanguagePERL programming lan - guage interpreter, applied set three programs. 401.bzip2 2.68 2472 C Compression General-purpose data compression work done memory, rather I/O. 403.gcc 2.24 1064 C C Compiler Based gcc Version 3.2, generates code Opteron. 429.mcf 2.53 327 C Combinatorial OptimizationVehicle scheduling algorithm. 445.gobmk 2.91 1603 C Artificial IntelligencePlays game Go, simply described deeply complex game. 456.hmmer 2.59 3363 C Search Gene SequenceProtein sequence analysis using profile-hidden Markov models. 458.sjeng 3.36 2383 C Artificial IntelligenceA highly ranked chess program also plays several chess variants. 462.libquantum 5.76 3555 C Physics / Quantum ComputingSimulates quantum computer, running Shor’s polynomial-time factor- ization algorithm. 464.h264ref 6.15 3731 C Video CompressionH.264/AVC (Advanced Video Coding) video compression. 471.omnetpp 1.74 687 C++ Discrete Event SimulationUses OMNet++ discrete event simulator model large Ethernet campus network. 473.astar 1.95 1200 C++ Path-finding AlgorithmsPathfinding library 2D maps. 483.xalancbmk 1.92 1184 C++ XML ProcessingA modified version Xalan-C++, trans- forms XML documents document types.70 Chapter 2 / performan Ce Issues Table 2.6 SPEC CPU2006 Floating-Point Benchmarks BenchmarkReference time (hours)Instr count (billion) LanguageApplication Area Brief Description 410.bwaves 3.78 1176 Fortran Fluid DynamicsComputes 3D transonic transient laminar viscous flow. 416.gamess 5.44 5189 Fortran Quantum ChemistryQuantum chemical computations. 433.milc 2.55 937 C Physics / Quantum Chromody- namicsSimulates behavior quarks gluons. 434.zeusmp 2.53 1566 Fortran Physics / CFDComputational fluid dynamics simulation astrophysical phenomena. 435.gromacs 1.98 1958 C, Fortran Biochemistry / Molecular DynamicsSimulates Newtonian equations motion hundreds millions particles. 436. cactusADM3.32 1376 C, Fortran Physics / General RelativitySolves Einstein evolu- tion equations. 437.leslie3d 2.61 1273 Fortran Fluid DynamicsModels fuel injection flows. 444.namd 2.23 2483 C++ Biology / Molecular DynamicsSimulates large biomolecu- lar systems. 447.dealII 3.18 2323 C++ Finite Element AnalysisProgram library targeted adaptive finite elements error estimation. 450.soplex 2.32 703 C++ Linear Pro- gramming, OptimizationTest cases include railroad planning military airlift models. 453.povray 1.48 940 C++ Image Ray-Tracing3D image rendering. 454.calculix 2.29 3,04 C, Fortran Structural MechanicsFinite element code linear nonlinear 3D structural applications. 459. GemsFDTD2.95 1320 Fortran Computa- tional Elec- tromagneticsSolves Maxwell equa- tions 3D. 465.tonto 2.73 2392 Fortran Quantum ChemistryQuantum chemistry pack- age, adapted crystallo- graphic tasks. 470.lbm 3.82 1500 C Fluid DynamicsSimulates incompressible fluids 3D. 481.wrf 3.10 1684 C, Fortran Weather Weather forecasting model. 482.sphinx3 5.41 2472 C Speech RecognitionSpeech recognition software.2.6 / Ben Chmarks speC 71 processor-intensive suites SPEC, replacing SPEC CPU2000, SPEC CPU95, SPEC CPU92, SPEC CPU89 [HENN07]. better understand published results system using CPU2006, define following terms used SPEC documentation: ■Benchmark: program written high-level language compiled executed computer implements compiler. ■System test: system evaluated. ■Reference machine: system used SPEC establish baseline per - formance benchmarks. benchmark run measured machine establish reference time benchmark. system test evaluated running CPU2006 benchmarks comparing results running programs reference machine. ■Base metric: required reported results strict guide - lines compilation. essence, standard compiler less default settings used system test achieve compar - able results. ■Peak metric: enables users attempt optimize system performance optimizing compiler output. example, different compiler options may used benchmark, feedback-directed optimization allowed. ■Speed metric: simply measurement time takes execute compiled benchmark. speed metric used comparing ability computer complete single tasks. ■Rate metric: measurement many tasks computer accom - plish certain amount time; called throughput , capacity, rate measure. rate metric allows system test execute simultaneous tasks take advantage multiple processors. SPEC uses historical Sun system, “Ultra Enterprise 2,” intro - duced 1997, reference machine. reference machine uses 296-MHz UltraSPARC II processor. takes 12 days rule-conforming run base metrics CINT2006 CFP2006 CPU2006 reference machine. Tables 2.5 2.6 show amount time run benchmark using refer - ence machine. tables also show dynamic instruction counts reference machine, reported [PHAN07]. values actual number instruc - tions executed run program. consider specific calculations done assess system. consider integer benchmarks; procedures used create floating- point benchmark value. integer benchmarks, 12 programs test suite. Calculation three-step process (Figure 2.7): 1. first step evaluating system test compile run pro - gram system three times. program, runtime measured median value selected. reason use three runs take median value account variations execution time intrin - sic program, disk access time variations, OS kernel execu - tion variations one run another.72 Chapter 2 / performan Ce Issues 2. Next, 12 results normalized calculating runtime ratio reference run time system run time. ratio calculated follows: ri=Trefi Tsuti (2.9) Tref execution time benchmark program reference system Tsut execution time benchmark program system test. Thus, ratios higher faster machines. 3. Finally, geometric mean 12 runtime ratios calculated yield overall metric: rG=aq12 i=1rib1/12 integer benchmarks, four separate metrics calculated: ■SPECint2006: geometric mean 12 normalized ratios bench - marks compiled peak tuning. ■SPECint_base2006: geometric mean 12 normalized ratios benchmarks compiled base tuning. ■SPECint_rate2006: geometric mean 12 normalized throughput ratios benchmarks compiled peak tuning. ■SPECint_rate_base2006: geometric mean 12 normalized throughput ratios benchmarks compiled base tuning.Start Get next program Run program three times Select median value Ratio(prog) = Tref(prog)/TSUT(prog) programs? Compute geometric mean ratios EndYesN Figure 2.7 SPEC Evaluation Flowchart2.6 / Ben Chmarks speC 73 ExAMPLE 2.9 results Sun Blade 1000 shown Table 2.7a. One SPEC CPU2006 integer benchmark 464.h264ref. reference implementation H.264/ VC (Advanced Video Coding), latest state-of-the-art video compression standard. Sun Blade 1000 executes program median time 5,259 seconds. reference implementation requires 22,130 seconds. ratio calculated as: 22,130/5,259=4.21. speed metric calculated taking twelfth root product ratios: (3.18*2.96*2.98*3.91*3.17*3.61*3.51*2.01* 4.21*2.43*2.75*3.42)1/12=3.12 rate metrics take account system multiple processors. test machine, number copies N selected—usually equal number processors number simultaneous threads execution test system. individual test program’s rate determined taking median three runs. run consists N copies program running simultaneously test system. execution time time takes copies finish (i.e., time first copy starts last copy finishes). rate metric program calculated following formula: ratei=N*Trefi Tsuti rate score system test determined geometric mean rates program test suite. ExAMPLE 2.10 results Sun Blade X6250 shown Table 2.7b. sys - tem two processor chips, two cores per chip, total four cores. get rate metric, benchmark program executed simultaneously four cores, execution time time start four copies end slowest run. speed ratio calculated before, rate value simply four times speed ratio. final rate metric found taking geometric mean rate values: (78.63*62.97*60.87*77.29*65.87*83.68*76.70*134.98* 106.65*40.39*48.41*65.40)1/12=71.59 Table 2.7 SPEC CINT2006 Results (a) Sun Blade 1000 BenchmarkExecution time (secs)Execution time (secs)Execution time (secs)Reference time (secs) Ratio 400.perlbench 3077 3076 3080 9770 3.18 401.bzip2 3260 3263 3260 9650 2.96 403.gcc 2711 2701 2702 8050 2.98 429.mcf 2356 2331 2301 9120 3.91 445.gobmk 3319 3310 3308 10,490 3.17 456.hmmer 2586 2587 2601 9330 3.61 (Continued )74 Chapter 2 / performan Ce Issues Table 2.7 (Continued ) (a) Sun Blade 1000 BenchmarkExecution time (secs)Execution time (secs)Execution time (secs)Reference time (secs) Ratio 458.sjeng 3452 3449 3449 12,100 3.51 462.libquantum 10,318 10,319 10,273 20,720 2.01 464.h264ref 5246 5290 5259 22,130 4.21 471.omnetpp 2565 2572 2582 6250 2.43 473.astar 2522 2554 2565 7020 2.75 483.xalancbmk 2014 2018 2018 6900 3.42 (b) Sun Blade x6250 BenchmarkExecution time (secs)Execution time (secs)Execution time (secs)Reference time (secs) Ratio Rate 400.perlbench 497 497 497 9770 19.66 78.63 401.bzip2 613 614 613 9650 15.74 62.97 403.gcc 529 529 529 8050 15.22 60.87 429.mcf 472 472 473 9120 19.32 77.29 445.gobmk 637 637 637 10,490 16.47 65.87 456.hmmer 446 446 446 9330 20.92 83.68 458.sjeng 631 632 630 12,100 19.18 76.70 462.libquantum 614 614 614 20,720 33.75 134.98 464.h264ref 830 830 830 22,130 26.66 106.65 471.omnetpp 619 620 619 6250 10.10 40.39 473.astar 580 580 580 7020 12.10 48.41 483.xalancbmk 422 422 422 6900 16.35 65.40 2.7 key terms, review Questions, Pro Blems Key Terms Amdahl’s law arithmetic mean (AM) base metric benchmark clock cycle clock cycle time clock rate clock speed clock tick cycles per instruction ( CPI)functional mean (FM) general-purpose computing GPU (GPGPU) geometric mean (GM) graphics processing unit (GPU) harmonic mean (HM) instruction execution rate Little’s law many integrated core (MIC)microprocessor MIPS rate multicore peak metric rate metric reference machine speed metric SPEC system test throughput2.7 / key terms, revIew Quest Ions, proBLems 75 Review Questions 2.1 List briefly define techniques used contemporary processors increase speed. 2.2 Explain concept performance balance. 2.3 Explain differences among multicore systems, MICs, GPGPUs. 2.4 Briefly characterize Amdahl’s law. 2.5 Briefly characterize Little’s law. 2.6 Define MIPS FLOPS. 2.7 List define three methods calculating mean value set data values. 2.8 List desirable characteristics benchmark program. 2.9 SPEC benchmarks? 2.10 differences among base metric, peak metric, speed metric, rate metric? Problems 2.1 benchmark program run 40 MHz processor. executed program consists 100,000 instruction executions, following instruction mix clock cycle count: Instruction Type Instruction Count Cycles per Instruction Integer arithmetic 45,000 1 Data transfer 32,000 2 Floating point 15,000 2 Control transfer 8000 2 Determine effective CPI, MIPS rate, execution time program. 2.2 Consider two different machines, two different instruction sets, clock rate 200 MHz. following measurements recorded two machines running given set benchmark programs: Instruction TypeInstruction Count (millions)Cycles per Instruction Machine Arithmetic logic 8 1 Load store 4 3 Branch 2 4 Others 4 3 Machine Arithmetic logic 10 1 Load store 8 2 Branch 2 4 Others 4 3 a. Determine effective CPI, MIPS rate, execution time machine. b. Comment results.76 Chapter 2 / performan Ce Issues 2.3 Early examples CISC RISC design VAX 11/780 IBM RS/6000, respectively. Using typical benchmark program, following machine characteris - tics result: ProcessorClock Frequency (MHz)Performance (MIPS)CPU Time (secs) VAX 11/780 5 1 12 x IBM RS/6000 25 18 x final column shows VAX required 12 times longer IBM mea - sured CPU time. a. relative size instruction count machine code benchmark program running two machines? b. CPI values two machines? 2.4 Four benchmark programs executed three computers following results: Computer Computer B Computer C Program 1 1 10 20 Program 2 1000 100 20 Program 3 500 1000 50 Program 4 100 800 100 table shows execution time seconds, 100,000,000 instructions exe - cuted four programs. Calculate MIPS values computer program. calculate arithmetic harmonic means assuming equal weights four programs, rank computers based arithmetic mean harmonic mean. 2.5 following table, based data reported literature [HEAT84], shows execution times, seconds, five different benchmark programs three machines. BenchmarkProcessor R Z E 417 244 134 F 83 70 70 H 66 153 135 39,449 35,527 66,000 K 772 368 369 a. Compute speed metric processor benchmark, normalized machine R. is, ratio values R 1.0. ratios calculated using Equation (2.5) R treated reference system. compute arithmetic mean value system using Equation (2.3). approach taken [HEAT84]. b. Repeat part (a) using reference machine. calculation tried [HEAT84]. c. machine slowest based preceding two calculations? d. Repeat calculations parts (a) (b) using geometric mean, defined Equation (2.6). machine slowest based two calculations?2.7 / key terms, revIew Quest Ions, proBLems 77 2.6 clarify results preceding problem, look simpler example. BenchmarkProcessor x Z 1 20 10 40 2 40 80 20 a. Compute arithmetic mean value system using X reference machine using reference machine. Argue intuitively three machines roughly equivalent performance arithmetic mean gives misleading results. b. Compute geometric mean value system using X reference machine using reference machine. Argue results realistic arithmetic mean. 2.7 Consider example Section 2.5 calculation average CPI MIPS rate, yielded result CPI=2.24 MIPS rate=178. assume program executed eight parallel tasks threads roughly equal num - ber instructions executed task. Execution 8-core system core (processor) performance single processor originally used. Coordination synchronization parts adds extra 25,000 instruction executions task. Assume instruction mix example task, increase CPI memory reference cache miss 12 cycles due contention memory. a. Determine average CPI. b. Determine corresponding MIPS rate. c. Calculate speedup factor. d. Compare actual speedup factor theoretical speedup factor deter - mined Amdhal’s law. 2.8 processor accesses main memory average access time T2. smaller cache memory interposed processor main memory. cache sig - nificantly faster access time T16T2. cache holds, time, copies main memory words designed words likely accessed near future cache. Assume probability next word accessed processor cache H, known hit ratio. a. single memory access, theoretical speedup accessing word cache rather main memory? b. Let average access time. Express function T1, T2, H. overall speedup function H? c. practice, system may designed processor must first access cache determine word cache and, not, access main memory, miss (opposite hit), memory access time T1+T2. Express function T1, T2, H. calculate speedup compare result produced part (b). 2.9 owner shop observes average 18 customers per hour arrive typically 8 customers shop. average length time cus - tomer spends shop? 2.10 gain insight Little’s law considering Figure 2.8a. period time T, total C items arrive system, wait service, complete service. upper solid line shows time sequence arrivals, lower solid line shows time sequence departures. shaded area bounded two lines represents total “work” done system units job-seconds; let total work. wish derive relationship among L, W, λ.78 Chapter 2 / performan Ce Issues a. Figure 2.8b divides total area horizontal rectangles, height one job. Picture sliding rectangles left left edges line t=0. Develop equation relates A, C, W. b. Figure 2.8c divides total area vertical rectangles, defined vertical transition boundaries indicated dashed lines. Picture sliding rect - angles lower edges line N(t)=0. Develop equation relates A, T, L. c. Finally, derive L=lW results (a) (b). 2.11 Figure 2.8a, jobs arrive times t=0, 1, 1.5, 3.25, 5.25, 7 .75. corresponding completion times t=2, 3, 3.5, 4.25, 8.25, 8.75. a. Determine area six rectangles Figure 2.8b sum get total area A. Show work. b. Determine area 10 rectangles Figure 2.8c sum get total area A. Show work. 2.12 Section 2.6, specified base ratio used comparing system test reference system is: ri=Trefi Tsuti N(t) tC T0 0 (c) Viewed vertical r ectanglesN(t) tC T0 0Total completions (a) Arrival completion jobsN(t) tC T0 0 (b) Viewed horizontal r ectanglesTotal arrivals Figure 2.8 Illustration Little’s Law2.7 / key terms, revIew Quest Ions, proBLems 79 a. preceding equation provides measure speedup system test compared reference system. Assume number floating-point operations executed test program Ii. show speedup function instruction execution rate FLOPS i. b. Another technique normalizing performance express performance system percent change relative performance another system. Express relative change first function instruction execution rate, function execution times. 2.13 Assume benchmark program executes 480 seconds reference machine A. program executes systems B, C, 360, 540, 210 seconds, respectively. a. Show speedup three systems test relative A. b. show relative speedup three systems. Comment three ways comparing machines (execution time, speedup, relative speedup). 2.14 Repeat preceding problem using machine reference machine. affect relative rankings four systems? 2.15 Recalculate results Table 2.2 using computer time data Table 2.4 comment results. 2.16 Equation 2.5 shows two different formulations geometric mean, one using product operator one using summation operator. a. Show two formulas equivalent. b. would summation formulation preferred calculating geometric mean? 2.17 Project. Section 2.5 lists number references document “benchmark means wars.” referenced papers available box.com/COA10e. Read papers summarize case use geometric mean SPEC calculations.80ChapterPart two Compu Ter SySTem 3.1 Computer Components 3.2 Computer Function Instruction Fetch Execute Interrupts I/O Function 3.3 Interconnection Structures 3.4 Bus Interconnection 3.5 Point-to-Point Interconnect QPI Physical Layer QPI Link Layer QPI Routing Layer QPI Protocol Layer 3.6 PCI Express PCI Physical Logical Architecture PCIe Physical Layer PCIe Transaction Layer PCIe Data Link Layer 3.7 Key Terms, Review Questions, Problems Top-LeveL view Compu Ter funCTion inTerConne CTion3.1 / Computer Components 81 top level, computer consists CPU (central processing unit), memory, I/O components, one modules type. components interconnected fashion achieve basic function computer, execute programs. Thus, top level, characterize computer system describing (1) external behavior component, is, data control signals exchanges components, (2) intercon - nection structure controls required manage use interconnec - tion structure. top-level view structure function important explanatory power understanding nature computer. Equally important use understand increasingly complex issues performance evaluation. grasp top-level structure function offers insight system bottlenecks, alternate pathways, magnitude system failures component fails, ease adding performance enhancements. many cases, requirements greater system power fail-safe capabilities met changing design rather merely increasing speed reliability individual components. chapter focuses basic structures used computer component interconnection. background, chapter begins brief examination basic components interface requirements. functional overview provided. prepared examine use buses interconnect system components. 3.1 Computer Components discussed Chapter 1, virtually contemporary computer designs based concepts developed John von Neumann Institute Advanced Studies, Princeton. design referred von Neumann architecture based three key concepts: ■Data instructions stored single read–write memory. ■The contents memory addressable location, without regard type data contained there.Learning Objectives studying chapter, able to: rUnderstand basic elements instruction cycle role interrupts. rDescribe concept interconnection within computer system. rAssess relative advantages point-to-point interconnection compared bus interconnection. rPresent overview QPI. rPresent overview PCIe.82 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction ■Execution occurs sequential fashion (unless explicitly modified) one instruction next. reasoning behind concepts discussed Chapter 2 worth summarizing here. small set basic logic components com - bined various ways store binary data perform arithmetic logical operations data. particular computation performed, con - figuration logic components designed specifically computation could constructed. think process connecting various components desired configuration form programming. resulting “program” form hardware termed hardwired program . consider alternative. Suppose construct general-purpose con - figuration arithmetic logic functions. set hardware perform vari - ous functions data depending control signals applied hardware. original case customized hardware, system accepts data produces results (Figure 3.1a). general-purpose hardware, system accepts data control signals produces results. Thus, instead rewiring hardware new program, programmer merely needs supply new set control signals. shall control signals supplied? answer simple subtle. entire program actually sequence steps. step, arithmetic logical operation performed data. step, new set control sig - nals needed. Let us provide unique code possible set control signals, Sequence arithmetic logic functionsData Results (a) Programming hardware Data ResultsInstruction codes General-purpose arithmetic logic functionsContr ol signals (b) Programming softwareInstruction interpr eter Figure 3.1 Hardware Software Approaches3.2 / Computer funCtion 83 let us add general-purpose hardware segment accept code generate control signals (Figure 3.1b). Programming much easier. Instead rewiring hardware new program, need provide new sequence codes. code is, effect, instruction, part hardware interprets instruction gen - erates control signals. distinguish new method programming, sequence codes instructions called software . Figure 3.1b indicates two major components system: instruction interpreter module general-purpose arithmetic logic functions. two constitute CPU. Several components needed yield function - ing computer. Data instructions must put system. need sort input module. module contains basic components accepting data instructions form converting internal form signals usable system. means reporting results needed, form output module. Taken together, referred I/O components . One component needed. input device bring instructions data sequentially. program invariably executed sequentially; may jump around (e.g., IAS jump instruction). Similarly, operations data may require access one element time predetermined sequence. Thus, must place temporarily store instructions data. module called memory , main memory , distinguish external storage peripheral devices. Von Neumann pointed memory could used store instructions data. Figure 3.2 illustrates top-level components suggests interac - tions among them. CPU exchanges data memory. purpose, typ - ically makes use two internal (to CPU) registers: memory address register (MAR) , specifies address memory next read write, memory buffer register (MBR) , contains data written memory receives data read memory. Similarly, I/O address register (I/OAR) specifies particular I/O device. I/O buffer register (I/OBR) used exchange data I/O module CPU. memory module consists set locations, defined sequentially num - bered addresses. location contains binary number interpreted either instruction data. I/O module transfers data external devices CPU memory, vice versa. contains internal buffers temporarily hold - ing data sent on. looked briefly major components, turn overview components function together execute programs. 3.2 Computer Fun Ction basic function performed computer execution program, con - sists set instructions stored memory. processor actual work executing instructions specified program. section provides overview 84 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction key elements program execution. simplest form, instruction processing consists two steps: processor reads ( fetches ) instructions memory one time executes instruction. Program execution consists repeating process instruction fetch instruction execution. instruction execution may involve several operations depends nature instruction (see, example, lower portion Figure 2.4). processing required single instruction called instruction cycle . Using simplified two-step description given previously, instruction cycle depicted Figure 3.3. two steps referred fetch cycle execute cycle . Program execution halts machine turned off, sort unrecov - erable error occurs, program instruction halts computer encountered. Instruction Fetch Execute beginning instruction cycle, processor fetches instruction memory. typical processor, register called program counter (PC) holds address instruction fetched next. Unless told otherwise, processor PC MAR IR MBR I/O AR I/O BRCPU Main memory System bus I/O Module BuffersInstruction0 1 2 n – 2 n – 1Data Data Data DataInstruction Instruction PC = Program counter IR = Instruction register MAR = Memory address register MBR = Memory buffer register I/O AR = Input/output address register I/O BR = Input/output buffer registerExecution unit Figure 3.2 Computer Components: Top-Level View3.2 / Computer funCtion 85 always increments PC instruction fetch fetch next instruction sequence (i.e., instruction located next higher memory address). So, example, consider computer instruction occupies one 16-bit word memory. Assume program counter set memory loca - tion 300, location address refers 16-bit word. processor next fetch instruction location 300. succeeding instruction cycles, fetch instructions locations 301, 302, 303, on. sequence may altered, explained presently. fetched instruction loaded register processor known instruction register (IR). instruction contains bits specify action processor take. processor interprets instruction performs required action. general, actions fall four categories: ■Processor-memory: Data may transferred processor memory memory processor. ■Processor-I/O: Data may transferred peripheral device transferring processor I/O module. ■Data processing: processor may perform arithmetic logic oper - ation data. ■Control: instruction may specify sequence execution altered. example, processor may fetch instruction location 149, specifies next instruction location 182. processor remember fact setting program counter 182. Thus, next fetch cycle, instruction fetched location 182 rather 150. instruction’s execution may involve combination actions. Consider simple example using hypothetical machine includes characteristics listed Figure 3.4. processor contains single data register, called accumulator (AC). instructions data 16 bits long. Thus, convenient organize memory using 16-bit words. instruction format provides 4 bits opcode, many 24=16 different opcodes, 212=4096 (4K) words memory directly addressed. Figure 3.5 illustrates partial program execution, showing relevant por - tions memory processor registers.1 program fragment shown adds contents memory word address 940 contents memory word START HAL TFetch next instructionFetch cycle Execute cycle Execute instruction Figure 3.3 Basic Instruction Cycle 1Hexadecimal notation used, digit represents 4 bits. convenient nota - tion representing contents memory registers word length multiple 4. See Chapter 9 basic refresher number systems (decimal, binary, hexadecimal).86 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction Program counter (PC) = Address instruction Instruction gister (IR) = Instruction executed Accumulator (A C) = Temporary storage 0001 = Load AC memory 0010 = Store AC memory 0101 = Add AC memory(a) Instruction formatOpcode Addr ess (b) Inte ger format (c) Internal CPU gistersMagnitude0 15 43 1 0 15 (d) P artial list opcodes Figure 3.4 Characteristics Hypothetical Machine 2PC 300CPU r egisters Memory 300 1940 301 5941 302 2941 940 0003 941 0002AC IR 1940 Step 1•• •• •••• •• ••PC 300CPU r egisters Memory 301 1940 301 5941 302 2941 940 0003 941 0002AC IR 19400003 Step 2 PC 300CPU r egisters Memory 301 0005 00050003 00051940 301 5941 302 2941 940 0003 941 0002AC IR 5941 Step 3PC 300CPU r egisters Memory 302 1940 301 594 1 302 29411 940 0003 941 0002AC IR 5941 Step 4 PC 300CPU r egisters Memory 30 1940 301 5941 302 2941 940 0003 941 0002AC IR 2941 Step 5PC 300CPU r egisters Memory 303 1940 301 5941 302 2941 940 0003 941 0005AC IR 2941 Step 63 + 2 = 5 Figure 3.5 Example Program Execution (contents memory registers hexadecimal)3.2 / Computer funCtion 87 address 941 stores result latter location. Three instructions, described three fetch three execute cycles, required: 1. PC contains 300, address first instruction. instruction (the value 1940 hexadecimal) loaded instruction register IR, PC incremented. Note process involves use memory address register memory buffer register. simplicity, intermedi - ate registers ignored. 2. first 4 bits (first hexadecimal digit) IR indicate AC loaded. remaining 12 bits (three hexadecimal digits) specify address (940) data loaded. 3. next instruction (5941) fetched location 301, PC incremented. 4. old contents AC contents location 941 added, result stored AC. 5. next instruction (2941) fetched location 302, PC incremented. 6. contents AC stored location 941. example, three instruction cycles, consisting fetch cycle execute cycle, needed add contents location 940 contents 941. complex set instructions, fewer cycles would needed. older processors, example, included instructions contain one memory address. Thus, execution cycle particular instruction processors could involve one reference memory. Also, instead memory refer - ences, instruction may specify I/O operation. example, PDP-11 processor includes instruction, expressed symboli - cally ADD B,A, stores sum contents memory locations B memory location A. single instruction cycle following steps occurs: ■Fetch ADD instruction. ■Read contents memory location processor. ■Read contents memory location B processor. order contents lost, processor must least two registers storing memory values, rather single accumulator. ■Add two values. ■Write result processor memory location A. Thus, execution cycle particular instruction may involve one reference memory. Also, instead memory references, instruction may specify I/O operation. additional considerations mind, Figure 3.6 provides detailed look basic instruction cycle Figure 3.3. figure form state diagram. given instruction cycle, states may null others may visited once. states described follows: ■Instruction address calculation (iac): Determine address next instruction executed. Usually, involves adding fixed number 88 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction address previous instruction. example, instruction 16 bits long memory organized 16-bit words, add 1 previ - ous address. If, instead, memory organized individually addressable 8-bit bytes, add 2 previous address. ■Instruction fetch (if): Read instruction memory location processor. ■Instruction operation decoding (iod): Analyze instruction determine type operation performed operand(s) used. ■Operand address calculation (oac): operation involves reference operand memory available via I/O, determine address operand. ■Operand fetch (of): Fetch operand memory read I/O. ■Data operation (do): Perform operation indicated instruction. ■Operand store (os): Write result memory I/O. States upper part Figure 3.6 involve exchange pro - cessor either memory I/O module. States lower part diagram involve internal processor operations. oac state appears twice, instruction may involve read, write, both. However, action performed state fundamentally cases, single state identifier needed. Also note diagram allows multiple operands multiple results, instructions machines require this. example, PDP-11 instruction ADD A,B results following sequence states: iac, if, iod, oac, of, oac, of, do, oac, os. Finally, machines, single instruction specify operation per - formed vector (one-dimensional array) numbers string (one-dimensional Instruction address calculationInstruction operation decodingOperand address calculationData operationOperand address calculationInstruction fetch Instruction complete, fetch next instructionMultiple operands Return string vector dataOperand fetchOperand store Multiple results Figure 3.6 Instruction Cycle State Diagram3.2 / Computer funCtion 89 array) characters. Figure 3.6 indicates, would involve repetitive operand fetch and/or store operations. Interrupts Virtually computers provide mechanism modules (I/O, memory) may interrupt normal processing processor. Table 3.1 lists com - mon classes interrupts. specific nature interrupts examined later book, especially Chapters 7 14. However, need introduce concept understand clearly nature instruction cycle impli - cations interrupts interconnection structure. reader need con - cerned stage details generation processing interrupts, focus communication modules results interrupts. Interrupts provided primarily way improve processing efficiency. example, external devices much slower processor. Suppose processor transferring data printer using instruction cycle scheme Figure 3.3. write operation, processor must pause remain idle printer catches up. length pause may order many hundreds even thousands instruction cycles involve memory. Clearly, wasteful use processor. Figure 3.7a illustrates state affairs. user program performs ser - ies WRITE calls interleaved processing. Code segments 1, 2, 3 refer sequences instructions involve I/O. WRITE calls I/O program system utility perform actual I/O operation. I/O program consists three sections: ■A sequence instructions, labeled 4 figure, prepare actual I/O operation. may include copying data output special buffer preparing parameters device command. ■The actual I/O command. Without use interrupts, command issued, program must wait I/O device perform requested function (or periodically poll device). program might wait simply repeatedly performing test operation determine I/O operation done. ■A sequence instructions, labeled 5 figure, complete operation. may include setting flag indicating success failure operation. Table 3.1 Classes Interrupts Program Generated condition occurs result instruction execution, arithmetic overflow, division zero, attempt exe- cute illegal machine instruction, reference outside user’s allowed memory space. Timer Generated timer within processor. allows operating system perform certain functions regular basis. I/O Generated I/O controller, signal normal completion operation, request service processor, signal variety error conditions. Hardware Failure Generated failure power failure memory parity error.90 User Program WRITE WRITE WRITEI/O Program I/O Command END1 2 32 34 5 (a) interrupts = interrupt occurs course execution user programUser Program WRITE WRITE WRITEI/O Program I/O Command Interrupt Handler END1 2a 2b 3a 3b4 5 (b) Interrupts; short I/O waitUser Program WRITE WRITE WRITEI/O Program I/O Command Interrupt Handler END1 4 5 (c) Interrupts; long I/O wait Figure 3.7 Program Flow Control without Interrupts3.2 / Computer funCtion 91 I/O operation may take relatively long time complete, I/O program hung waiting operation complete; hence, user program stopped point WRITE call considerable period time. interrupts instruction cycle interrupts, processor engaged executing instructions I/O operation progress. Consider flow control Figure 3.7b. before, user program reaches point makes system call form WRITE call. I/O program invoked case consists preparation code actual I/O command. instructions executed, control returns user program. Meanwhile, external device busy accepting data computer memory printing it. I/O operation conducted concurrently execution instructions user program. external device becomes ready serviced—that is, ready accept data processor—the I/O module external device sends interrupt request signal processor. processor responds suspending operation current program, branching program service particular I/O device, known interrupt handler , resuming original execution device serviced. points interrupts occur indicated asterisk Figure 3.7b. Let us try clarify happening Figure 3.7. user program contains two WRITE commands. segment code beginning, one WRITE command, second segment code, second WRITE command, third final segment code. WRITE command invokes I/O program provided OS. Similarly, I/O program consists seg - ment code, followed I/O command, followed another segment code. I/O command invokes hardware I/O operation. 92 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction point view user program, interrupt that: interrup - tion normal sequence execution. interrupt processing completed, execution resumes (Figure 3.8). Thus, user program contain special code accommodate interrupts; processor operating system responsible suspending user program resuming point. accommodate interrupts, interrupt cycle added instruction cycle, shown Figure 3.9. interrupt cycle, processor checks see interrupts occurred, indicated presence interrupt signal. interrupts pending, processor proceeds fetch cycle fetches next instruction current program. interrupt pending, processor following: ■It suspends execution current program executed saves context. means saving address next instruction executed 1 2 + 1 M• • •• • • • • •Interrupt occurs eUser pr ogram Interrupt handler Figure 3.8 Transfer Control via Interrupts Fetch cycle Execute cycle Interrupt cycle Interrupts disabled Interrupts enabledSTART HAL TFetch next instructionExecute instructionCheck interrupt; process interrupt Figure 3.9 Instruction Cycle Interrupts3.2 / Computer funCtion 93 (current contents program counter) data relevant processor’s current activity. ■It sets program counter starting address interrupt handler routine. processor proceeds fetch cycle fetches first instruction interrupt handler program, service interrupt. interrupt handler program generally part operating system. Typically, program determines nature interrupt performs whatever actions needed. example using, handler determines I/O module gen - erated interrupt may branch program write data I/O module. interrupt handler routine completed, processor resume execution user program point interruption. clear overhead involved process. Extra instruc - tions must executed (in interrupt handler) determine nature inter - rupt decide appropriate action. Nevertheless, relatively large amount time would wasted simply waiting I/O operation, processor employed much efficiently use interrupts. appreciate gain efficiency, consider Figure 3.10, timing diagram based flow control Figures 3.7a 3.7b. figure, user program code segments shaded green, I/O program code segments 41 55 2 5 34Time I/O operation; processor waitsI/O operation concurrent processor executing I/O operation concurrent processor executing I/O operation; processor waits4 2a1 2b 4 3a 5 3b (a) Without interrupts(b) interrupts Figure 3.10 Program Timing: Short I/O Wait94 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction shaded gray. Figure 3.10a shows case interrupts used. pro - cessor must wait I/O operation performed. Figures 3.7b 3.10b assume time required I/O operation rela - tively short: less time complete execution instructions write operations user program. case, segment code labeled code segment 2 interrupted. portion code (2a) executes (while I/O operation performed) interrupt occurs (upon completion I/O operation). inter - rupt serviced, execution resumes remainder code segment 2 (2b). typical case, especially slow device printer, I/O operation take much time executing sequence user instruc - tions. Figure 3.7c indicates state affairs. case, user program reaches second WRITE call I/O operation spawned first call com - plete. result user program hung point. preced - ing I/O operation completed, new WRITE call may processed, new I/O operation may started. Figure 3.11 shows timing situation 41 5 2 5 34Time 4 21 5 4 (a) Without interrupts(b) interrupts3 5I/O operation; processor waits I/O operation; processor waitsI/O operation concurrent processor executing; processor waits I/O operation concurrent processor executing; processor waits Figure 3.11 Program Timing: Long I/O Wait3.2 / Computer funCtion 95 without use interrupts. see still gain efficiency part time I/O operation way overlaps execution user instructions. Figure 3.12 shows revised instruction cycle state diagram includes inter - rupt cycle processing. multiple interrupts discussion far focused occurrence single interrupt. Suppose, however, multiple interrupts occur. example, program may receiving data communications line printing results. printer generate interrupt every time completes print operation. communication line controller generate interrupt every time unit data arrives. unit could either single character block, depending nature communications discipline. case, possible communications interrupt occur printer interrupt processed. Two approaches taken dealing multiple interrupts. first disable interrupts interrupt processed. disabled interrupt simply means processor ignore interrupt request signal. interrupt occurs time, generally remains pending checked processor processor enabled interrupts. Thus, user program executing interrupt occurs, interrupts disabled immedi - ately. interrupt handler routine completes, interrupts enabled resuming user program, processor checks see additional interrupts occurred. approach nice simple, interrupts handled strict sequential order (Figure 3.13a). drawback preceding approach take account relative priority time-critical needs. example, input arrives communications line, may need absorbed rapidly make room input. first batch input processed second batch arrives, data may lost. second approach define priorities interrupts allow interrupt higher priority cause lower-priority interrupt handler interrupted (Figure 3.13b). example second approach, consider system three I/O devices: printer, disk, communications line, increasing priori - ties 2, 4, 5, respectively. Figure 3.14 illustrates possible sequence. user program begins t=0. t=10, printer interrupt occurs; user information placed system stack execution continues printer interrupt service routine (ISR) . routine still executing, t=15, communications inter - rupt occurs. communications line higher priority printer, interrupt honored. printer ISR interrupted, state pushed onto stack, execution continues communications ISR. routine exe - cuting, disk interrupt occurs (t=20). interrupt lower priority, simply held, communications ISR runs completion. communications ISR complete (t=25), previous proces - sor state restored, execution printer ISR. However, even single instruction routine executed, processor honors higher-priority disk interrupt control transfers disk ISR. interruptInterrupt checkInterruptInstruction address calculationInstruction operation decodingOperand address calculationData operationOperand address calculationInstruction fetch Instruction complete, fetch next instructionMultiple operands Return string vector dataOperand fetchOperand store Multiple results Figure 3.12 Instruction Cycle State Diagram, Interrupts 96User pr ogramInterrupt handler X Interrupt handler (a) Sequential interrupt processing (b) Nested interrupt processingUser pr ogramInterrupt handler X Interrupt handler Figure 3.13 Transfer Control Multiple Interrupts 9798 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction routine complete (t=35) printer ISR resumed. routine com - pletes (t=40), control finally returns user program. I/O Function Thus far, discussed operation computer controlled pro - cessor, looked primarily interaction processor memory. discussion alluded role I/O component. role dis - cussed detail Chapter 7 , brief summary order here. I/O module (e.g., disk controller) exchange data directly processor. processor initiate read write memory, desig - nating address specific location, processor also read data write data I/O module. latter case, processor identifies specific device controlled particular I/O module. Thus, instruction sequence similar form Figure 3.5 could occur, I/O instructions rather memory-referencing instructions. cases, desirable allow I/O exchanges occur directly memory. case, processor grants I/O module authority read write memory, I/O-memory transfer occur without tying processor. transfer, I/O module issues read write com - mands memory, relieving processor responsibility exchange. operation known direct memory access (DMA) examined Chapter 7.User programPrinter interrupt service routineCommunication interrupt service routine Disk interrupt service routinet = 0 = 10 = 40t = 15 = 25 = 25 = 35 Figure 3.14 Example Time Sequence Multiple Interrupts3.3 / inter Conne Ction struCtures 99 3.3 inter Conne Ction struCtures computer consists set components modules three basic types (pro - cessor, memory, I/O) communicate other. effect, computer network basic modules. Thus, must paths connecting modules. collection paths connecting various modules called intercon- nection structure . design structure depend exchanges must made among modules. Figure 3.15 suggests types exchanges needed indicating major forms input output module type2: ■Memory: Typically, memory module consist N words equal length. word assigned unique numerical address (0, 1, c, N-1). word data read written memory. nature operation 2The wide arrows represent multiple signal lines carrying multiple bits information parallel. narrow arrow represents single signal line.Memory N words 0 • • •Data I/O module ports CPUExter nal data Interrupt signalsInter nal data DataAddr ess Contr ol signalsDataAddr essWriteRead Exter nal dataAddr ess Inter nal dataWriteRead DataInstructions Interrupt signalsN  1 Figure 3.15 Computer Modules100 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction indicated read write control signals. location operation specified address. ■I/O module: internal (to computer system) point view, I/O functionally similar memory. two operations; read write. Fur - ther, I/O module may control one external device. refer interfaces external device port give unique address (e.g., 0, 1, c, M-1). addition, external data paths input output data external device. Finally, I/O module may able send interrupt signals processor. ■Processor: processor reads instructions data, writes data processing, uses control signals control overall operation sys - tem. also receives interrupt signals. preceding list defines data exchanged. interconnection structure must support following types transfers: ■Memory processor: processor reads instruction unit data memory. ■Processor memory: processor writes unit data memory. ■I/O processor: processor reads data I/O device via I/O module. ■Processor I/O: processor sends data I/O device. ■I/O memory: two cases, I/O module allowed exchange data directly memory, without going processor, using direct memory access. years, number interconnection structures tried. far common (1) bus various multiple-bus structures, (2) point- to-point interconnection structures packetized data transfer. devote remainder chapter discussion structures. 3.4 Bus inter Conne Ction bus dominant means computer system component interconnection decades. general-purpose computers, gradually given way various point-to-point interconnection structures, dominate computer system design. However, bus structures still commonly used embedded systems, par - ticularly microcontrollers. section, give brief overview bus structure. Appendix C provides detail. bus communication pathway connecting two devices. key characteristic bus shared transmission medium. Multiple devices connect bus, signal transmitted one device available recep - tion devices attached bus. two devices transmit time period, signals overlap become garbled. Thus, one device time successfully transmit.3.4 / Bus inter Conne Ction 101 Typically, bus consists multiple communication pathways, lines. line capable transmitting signals representing binary 1 binary 0. time, sequence binary digits transmitted across single line. Taken together, several lines bus used transmit binary digits simultaneously (in paral - lel). example, 8-bit unit data transmitted eight bus lines. Computer systems contain number different buses provide pathways components various levels computer system hierarchy. bus connects major computer components (processor, memory, I/O) called system bus. common computer interconnection structures based use one system buses. system bus consists, typically, fifty hundreds separate lines. line assigned particular meaning function. Although many different bus designs, bus lines classified three func - tional groups (Figure 3.16): data, address, control lines. addition, may power distribution lines supply power attached modules. data lines provide path moving data among system modules. lines, collectively, called data bus . data bus may consist 32, 64, 128, even separate lines, number lines referred width data bus. line carry one bit time, number lines determines many bits transferred time. width data bus key factor determining overall system performance. example, data bus 32 bits wide instruction 64 bits long, processor must access memory module twice instruction cycle. address lines used designate source destination data data bus. example, processor wishes read word (8, 16, 32 bits) data memory, puts address desired word address lines. Clearly, width address bus determines maximum possible memory capac - ity system. Furthermore, address lines generally also used address I/O ports. Typically, higher-order bits used select particular module bus, lower-order bits select memory location I/O port within module. example, 8-bit address bus, address 01111111 might reference locations memory module (module 0) 128 words memory, address 10000000 refer devices attached I/O module (module 1). control lines used control access use data address lines. data address lines shared components, CPU Memory Memory • • • I/O BusI/O Contr ol lines Addr ess lines Data lines• • • Figure 3.16 Bus Interconnection Scheme102 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction must means controlling use. Control signals transmit com - mand timing information among system modules. Timing signals indicate validity data address information. Command signals specify operations performed. Typical control lines include: ■Memory write: causes data bus written addressed location. ■Memory read: causes data addressed location placed bus. ■I/O write: causes data bus output addressed I/O port. ■I/O read: causes data addressed I/O port placed bus. ■Transfer ACK: indicates data accepted placed bus. ■Bus request: indicates module needs gain control bus. ■Bus grant: indicates requesting module granted control bus. ■Interrupt request: indicates interrupt pending. ■Interrupt ACK: acknowledges pending interrupt recognized. ■Clock: used synchronize operations. ■Reset: initializes modules. operation bus follows. one module wishes send data another, must two things: (1) obtain use bus, (2) transfer data via bus. one module wishes request data another module, must (1) obtain use bus, (2) transfer request module appropriate control address lines. must wait second module send data. 3.5 point-to- point inter Conne Ct shared bus architecture standard approach interconnection processor components (memory, I/O, on) decades. con - temporary systems increasingly rely point-to-point interconnection rather shared buses. principal reason driving change bus point-to-point intercon - nect electrical constraints encountered increasing frequency wide synchronous buses. higher higher data rates, becomes increasingly diffi - cult perform synchronization arbitration functions timely fashion. Further, advent multicore chips, multiple processors significant memory single chip, found use conventional shared bus chip magnified difficulties increasing bus data rate reducing bus latency keep processors. Compared shared bus, point-to- point interconnect lower latency, higher data rate, better scalability. section, look important representative example point-to-point interconnect approach: Intel’s QuickPath Interconnect (QPI) , introduced 2008.3.5 / point-to- point inter Conne Ct 103 following significant characteristics QPI point-to-point interconnect schemes: ■Multiple direct connections: Multiple components within system enjoy direct pairwise connections components. eliminates need arbitration found shared transmission systems. ■Layered protocol architecture: found network environments, TCP/IP-based data networks, processor-level interconnects use lay - ered protocol architecture, rather simple use control signals found shared bus arrangements. ■Packetized data transfer: Data sent raw bit stream. Rather, data sent sequence packets, includes control headers error control codes. Figure 3.17 illustrates typical use QPI multicore computer. QPI links (indicated green arrow pairs figure) form switching fabric enables data move throughout network. Direct QPI connections estab - lished pair core processors. core Figure 3.17 needs access memory controller core D, sends request either cores B C, must turn forward request memory controller core D. Similarly, larger systems eight processors built using processors three links routing traffic intermediate processors. addition, QPI used connect I/O module, called I/O hub (IOH). IOH acts switch directing traffic I/O devices. Typically newer Core AI/O Hub I/O HubCore B Core CCore DDRAM I/O de vice I/O de vice DRAMDRAM DRAMI/O de vice I/O de vice QPI PCI Express Memory bus Figure 3.17 Multicore Configuration Using QPI104 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction systems, link IOH I/O device controller uses interconnect technology called PCI Express (PCIe), described later chapter. IOH translates QPI protocols formats PCIe protocols - mats. core also links main memory module (typically memory uses dynamic access random memory (DRAM) technology) using dedicated memory bus. QPI defined four-layer protocol architecture,3 encompassing fol - lowing layers (Figure 3.18): ■Physical: Consists actual wires carrying signals, well circuitry logic support ancillary features required transmission receipt 1s 0s. unit transfer Physical layer 20 bits, called Phit (physical unit). ■Link: Responsible reliable transmission flow control. Link layer’s unit transfer 80-bit Flit (flow control unit). ■Routing: Provides framework directing packets fabric. ■Protocol: high-level set rules exchanging packets data devices. packet comprised integral number Flits. QPI Physical Layer Figure 3.19 shows physical architecture QPI port. QPI port consists 84 individual links grouped follows. data path consists pair wires transmits data one bit time; pair referred lane. 20 data lanes direction (transmit receive), plus clock lane direction. Thus, QPI capable transmitting 20 bits parallel direction. 20-bit unit referred phit. Typical signaling speeds link current products calls operation 6.4 GT/s (transfers per second). 20 bits per transfer, adds 16 GB/s, since QPI links involve dedicated bidirectional pairs, total capacity 32 GB/s. 3 reader unfamiliar concept protocol architecture find brief overview Appendix D.Link PhysicalProtocolPackets Flits PhitsRouting Link PhysicalProtocol Routing Figure 3.18 QPI Layers3.5 / point-to- point inter Conne Ct 105 lanes direction grouped four quadrants 5 lanes each. applications, link also operate half quarter widths order reduce power consumption work around failures. form transmission lane known differential signaling , balanced transmission . balanced transmission, signals transmitted cur - rent travels one conductor returns other. binary value depends voltage difference. Typically, one line positive voltage value line zero voltage, one line associated binary 1 one line associated binary 0. Specifically, technique used QPI known low-voltage differential signaling (LVDS). typical implementation, trans - mitter injects small current one wire other, depending logic level sent. current passes resistor receiving end, returns opposite direction along wire. receiver senses polar - ity voltage across resistor determine logic level. Another function performed physical layer manages trans - lation 80-bit flits 20-bit phits using technique known multilane distribution . flits considered bit stream distributed across data lanes round-robin fashion (first bit first lane, second bit second lane, etc.), illustrated Figure 3.20. approach enables QPI achieve high data rates implementing physical link two ports multiple parallel channels. QPI Link Layer QPI link layer performs two key functions: flow control error control. functions performed part QPI link layer protocol, operate level flit (flow control unit). flit consists 72-bit message payload Transmission LanesIntel QuickPath Inter connect P ortCOMPONENT COMPONENT BFwd ClkReception Lanes Rcv Clk Reception LanesRcv ClkTransmission Lanes Fwd Clk Intel QuickPath Inter connect P ort Figure 3.19 Physical Interface Intel QPI Interconnect106 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction 8-bit error control code called cyclic redundancy check (CRC). discuss error control codes Chapter 5. flit payload may consist data message information. data flits transfer actual bits data cores core IOH. message flits used functions flow control, error control, cache coherence. discuss cache coherence Chapters 5 17. flow control function needed ensure sending QPI entity overwhelm receiving QPI entity sending data faster receiver process data clear buffers incoming data. control flow data, QPI makes use credit scheme. initialization, sender given set number credits send flits receiver. Whenever flit sent receiver, sender decrements credit counters one credit. Whenever buffer freed receiver, credit returned sender buffer. Thus, receiver controls pace data transmitted QPI link. Occasionally, bit transmitted physical layer changed trans - mission, due noise phenomenon. error control function link layer detects recovers bit errors, isolates higher layers experiencing bit errors. procedure works follows flow data system system B: 1. mentioned, 80-bit flit includes 8-bit CRC field. CRC func - tion value remaining 72 bits. transmission, calculates CRC value flit inserts value flit. 2. flit received, B calculates CRC value 72-bit payload compares value value incoming CRC value flit. two CRC values match, error detected. 3. B detects error, sends request retransmit flit error. However, may sufficient credit send stream flits, additional flits transmitted flit error #2n+1 #2n #n+2 #n+1 #n #2 #1bit str eam /f_lits#2n+1 #n+1 #1QPI lane 0 #2n+2 #n+2 #2QPI lane 1 #3n #2n #nQPI lane 19 Figure 3.20 QPI Multilane Distribution3.6 / pCi express 107 receives request retransmit. Therefore, request back retransmit damaged flit plus subsequent flits. QPI Routing Layer routing layer used determine course packet traverse across available system interconnects. Routing tables defined firmware describe possible paths packet follow. small configurations, two-socket platform, routing options limited routing tables quite simple. larger systems, routing table options complex, giving flexibility routing rerouting traffic depending (1) devices popu - lated platform, (2) system resources partitioned, (3) reliability events result mapping around failing resource. QPI Protocol Layer layer, packet defined unit transfer. packet contents definition standardized flexibility allowed meet differing market segment require - ments. One key function performed level cache coherency protocol, deals making sure main memory values held multiple caches consistent. typical data packet payload block data sent cache. 3.6 pCi express peripheral component interconnect (PCI) popular high-bandwidth, processor-independent bus function mezzanine peripheral bus. Compared common bus specifications, PCI delivers better system perfor - mance high-speed I/O subsystems (e.g., graphic display adapters, network inter - face controllers, disk controllers). Intel began work PCI 1990 Pentium-based systems. Intel soon released patents public domain promoted creation industry association, PCI Special Interest Group (SIG), develop maintain compatibility PCI specifications. result PCI widely adopted finding increasing use personal computer, workstation, server systems. specification public domain supported broad cross-section microprocessor peripheral industry, PCI prod - ucts built different vendors compatible. system bus discussed preceding sections, bus-based PCI scheme able keep pace data rate demands attached devices. Accordingly, new version, known PCI Express (PCIe) devel - oped. PCIe, QPI, point-to-point interconnect scheme intended replace bus-based schemes PCI. key requirement PCIe high capacity support needs higher data rate I/O devices, Gigabit Ethernet. Another requirement deals need support time-dependent data streams. Applications video-on- demand audio redistribution putting real-time constraints servers too. Many communications applications embedded PC control systems also pro - cess data real-time. Today’s platforms must also deal multiple concurrent 108 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction transfers ever-increasing data rates. longer acceptable treat data equal—it important, example, process streaming data first since late real-time data useless data. Data needs tagged I/O system prioritize flow throughout platform. PCI Physical Logical Architecture Figure 3.21 shows typical configuration supports use PCIe. root complex device, also referred chipset host bridge , connects processor memory subsystem PCI Express switch fabric comprising one PCIe PCIe switch devices. root complex acts buffering device, deal difference data rates I/O controllers memory processor components. root complex also translates PCIe transaction formats processor memory signal control requirements. chipset typically support multiple PCIe ports, attach directly PCIe device, one attach switch manages multiple PCIe streams. PCIe links chipset may attach following kinds devices implement PCIe: ■Switch: switch manages multiple PCIe streams. ■PCIe endpoint: I/O device controller implements PCIe, Gigabit ethernet switch, graphics video controller, disk interface, communications controller. ChipsetCore Core Gigabit ether netPCIe PCIe PCIe PCIe PCIe PCIePCIePCIe–PCI bridgeMemory Memory Legacy endpointPCIe endpointPCIe endpointPCIe endpointSwitch Figure 3.21 Typical Configuration Using PCIe3.6 / pCi express 109 ■Legacy endpoint: Legacy endpoint category intended existing designs migrated PCI Express, allows legacy behaviors use I/O space locked transactions. PCI Express endpoints permitted require use I/O space runtime must use locked transactions. distinguishing categories, possible system designer restrict eliminate legacy behaviors negative impacts system performance robustness. ■PCIe/PCI bridge: Allows older PCI devices connected PCIe-based systems. QPI, PCIe interactions defined using protocol architecture. PCIe protocol architecture encompasses following layers (Figure 3.22): ■Physical: Consists actual wires carrying signals, well circuitry logic support ancillary features required transmission receipt 1s 0s. ■Data link: responsible reliable transmission flow control. Data pack - ets generated consumed DLL called Data Link Layer Packets (DLLPs). ■Transaction: Generates consumes data packets used implement load/ store data transfer mechanisms also manages flow control packets two components link. Data packets generated consumed TL called Transaction Layer Packets (TLPs). TL software layers generate read write requests transported transaction layer I/O devices using packet-based transaction protocol. PCIe Physical Layer Similar QPI, PCIe point-to-point architecture. PCIe port consists number bidirectional lanes (note QPI, lane refers transfer one direction only). Transfer direction lane means differential signal - ing pair wires. PCI port provide 1, 4, 6, 16, 32 lanes. follows, refer PCIe 3.0 specification, introduced late 2010. QPI, PCIe uses multilane distribution technique. Figure 3.23 shows example PCIe port consisting four lanes. Data distributed four Data link PhysicalTransaction layer packets (TLPs) Data link layer packets (DLLPs)Transaction Data link PhysicalTransaction Figure 3.22 PCIe Protocol LayersB1 B2 B3 B4 B5 B6 B7 B0byte str eamPCIe lane 0B4 B0 B5 B1 B6 B2 B7 B3128b/ 130b PCIe lane 1128b/ 130b PCIe lane 2128b/ 130b PCIe lane 3128b/ 130b Figure 3.23 PCIe Multilane Distribution 1103.6 / pCi express 111 lanes 1 byte time using simple round-robin scheme. physical lane, data buffered processed 16 bytes (128 bits) time. block 128 bits encoded unique 130-bit codeword transmission; referred 128b/130b encoding. Thus, effective data rate individual lane reduced factor 128/130. understand rationale 128b/130b encoding, note unlike QPI, PCIe use clock line synchronize bit stream. is, clock line used determine start end point incoming bit; used signaling purposes only. However, necessary receiver syn - chronized transmitter, receiver knows bit begins ends. drift clocks used bit transmission reception transmitter receiver, errors may occur. compensate possibil - ity drift, PCIe relies receiver synchronizing transmitter based transmitted signal. QPI, PCIe uses differential signaling pair wires. Synchronization achieved receiver looking transitions data synchronizing clock transition. However, consider long string 1s 0s using differential signaling, output constant voltage long period time. circumstances, drift clocks transmitter receiver result loss synchronization two. common approach, one used PCIe 3.0, overcoming prob - lem long string bits one value scrambling. Scrambling, increase number bits transmitted, mapping technique tends make data appear random. scrambling tends spread num - ber transitions appear receiver uniformly spaced, good synchronization. Also, transmission properties, spectral properties, enhanced data nearly random nature rather constant repetitive. discussion scrambling, see Appendix E. Another technique aid synchronization encoding, add - itional bits inserted bit stream force transitions. PCIe 3.0, group 128 bits input mapped 130-bit block adding 2-bit block sync header. value header 10 data block 01 called ordered set block , refers link-level information block. Figure 3.24 illustrates use scrambling encoding. Data trans - mitted fed scrambler. scrambled output fed 128b/130b encoder, buffers 128 bits maps 128-bit block 130-bit block. block passes parallel-to-serial converter transmitted one bit time using differential signaling. receiver, clock synchronized incoming data recover bit stream. passes serial-to-parallel converter produce stream 130-bit blocks. block passed 128b/130b decoder recover original scrambled bit pattern, descrambled produce original bit stream. Using techniques, data rate 16 GB/s achieved. One final detail mention; transmission block data PCI link begins ends 8-bit framing sequence intended give receiver time synchro - nize incoming physical layer bit stream.112 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction PCIe Transaction Layer transaction layer (TL) receives read write requests software TL creates request packets transmission destination via link layer. transactions use split transaction technique, works follow - ing fashion. request packet sent source PCIe device, waits response, called completion packet. completion following request initiated completer data and/or status ready delivery. packet unique identifier enables completion packets directed correct originator. split transaction technique, completion sep - arated time request, contrast typical bus operation sides transaction must available seize use bus. request completion, PCIe traffic may use link. TL messages write transactions posted transactions , meaning response expected. TL packet format supports 32-bit memory addressing extended 64-bit memory addressing. Packets also attributes “no-snoop,” ScramblerDiffer ential receive r Data r ecovery circuitClock r ecovery circuit8b 130b 128b130b 1b1b 1b128b/130b Encoding Parallel serial (a) TransmitterSerial parallel Transmitter differ ential drive r128b/130b decoding Descrambler (b) Recei ver8b 8bD+ D– D+ D– Figure 3.24 PCIe Transmit Receive Block Diagrams3.6 / pCi express 113 “relaxedordering,” “priority,” may used optimally route packets I/O subsystem. address spaces transaction types TL supports four address spaces: ■Memory: memory space includes system main memory. also includes PCIe I/O devices. Certain ranges memory addresses map I/O devices. ■I/O: address space used legacy PCI devices, reserved memory address ranges used address legacy I/O devices. ■Configuration: address space enables TL read/write configuration registers associated I/O devices. ■Message: address space control signals related interrupts, error handling, power management. Table 3.2 shows transaction types provided TL. memory, I/O, configuration address spaces, read write transactions. case memory transactions, also read lock request function. Locked operations occur result device drivers requesting atomic access registers PCIe device. device driver, example, atomically read, modify, write device register. accomplish this, device driver causes processor execute instruction set instructions. root complex converts pro - cessor instructions sequence PCIe transactions, perform individual read write requests device driver. transactions must executed atomically, root complex locks PCIe link executing transactions. locking prevents transactions part sequence occur - ring. sequence transactions called locked operation. particular set Table 3.2 PCIe TLP Transaction Types Address Space TLP Type Purpose MemoryMemory Read Request Transfer data location system memory map.Memory Read Lock Request Memory Write Request I/OI/O Read Request Transfer data location system memory map legacy devices. I/O Write Request ConfigurationConfig Type 0 Read Request Transfer data location configura- tion space PCIe device.Config Type 0 Write Request Config Type 1 Read Request Config Type 1 Write Request MessageMessage Request Provides in-band messaging event reporting. Message Request Data Memory, I/O, ConfigurationCompletion Returned certain requests.Completion Data Completion Locked Completion Locked Data114 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction processor instructions cause locked operation occur depends system chip set processor architecture. maintain compatibility PCI, PCIe supports Type 0 Type 1 con - figuration cycles. Type 1 cycle propagates downstream reaches bridge interface hosting bus (link) target device resides on. configuration transaction converted destination link Type 1 Type 0 bridge. Finally, completion messages used split transactions memory, I/O, configuration transactions. tlp packet assembly PCIe transactions conveyed using transaction layer packets, illustrated Figure 3.25a. TLP originates transaction layer sending device terminates transaction layer receiving device. STP framing Sequence number ECRC LCRC (a) Transaction Layer P acket (b) Data Link Layer PacketSTP framingAppended Physical LayerAppended Data Link LayerCreated Transaction Layer Created DLL1 2 12 16 0 4096 0 4 4 1Number octets DataHeaderStart DLLP End1 4 1CRC 2 Appended PL Figure 3.25 PCIe Protocol Data Unit Format3.6 / pCi express 115 Upper layer software sends TL information needed TL create core TLP, consists following fields: ■Header: header describes type packet includes information needed receiver process packet, including needed routing information. internal header format discussed subsequently. ■Data: data field 4096 bytes may included TLP. TLPs contain data field. ■ECRC: optional end-to-end CRC field enables destination TL layer check errors header data portions TLP. PCIe Data Link Layer purpose PCIe data link layer ensure reliable delivery packets across PCIe link. DLL participates formation TLPs also trans - mits DLLPs. data link layer packets Data link layer packets originate data link layer transmitting device terminate DLL device end link. Figure 3.25b shows format DLLP. three important groups DLLPs used managing link: flow control packets, power management packets, TLP ACK NAK packets. Power management packets used managing power platform budgeting. Flow control packets regulate rate TLPs DLLPs transmitted across link. ACK NAK packets used TLP processing, discussed following paragraphs. transaction layer packet processing DLL adds two fields core TLP created TL (Figure 3.25a): 16-bit sequence number 32-bit link-layer CRC (LCRC). Whereas core fields created TL used destination TL, two fields added DLL processed intermediate node way source destination. TLP arrives device, DLL strips sequence number LCRC fields checks LCRC. two possibilities: 1. errors detected, core portion TLP handed local transaction layer. receiving device intended destination, TL processes TLP. Otherwise, TL determines route TLP passes back DLL transmission next link way destination. 2. error detected, DLL schedules NAK DLL packet return back remote transmitter. TLP eliminated. DLL transmits TLP, retains copy TLP. receives NAK TLP sequence number, retransmits TLP. receives ACK, discards buffered TLP.116 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction 3.7 Key terms, review Questions, proBlems Key Terms address bus address lines arbitration balanced transmission bus control lines data bus data lines differential signaling disabled interrupt distributed arbitration error control functionexecute cycle fetch cycle flit flow control function instruction cycle interrupt interrupt handler interrupt service routine (ISR) lane memory address register (MAR) memory buffer register (MBR)multilane distribution packets PCI Express (PCIe) peripheral component interconnect (PCI) phit QuickPath Interconnect (QPI) root complex system bus Review Questions 3.1 general categories functions specified computer instructions? 3.2 List briefly define possible states define instruction execution. 3.3 List briefly define two approaches dealing multiple interrupts. 3.4 types transfers must computer’s interconnection structure (e.g., bus) support? 3.5 List briefly define QPI protocol layers. 3.6 List briefly define PCIe protocol layers. Problems 3.1 hypothetical machine Figure 3.4 also two I/O instructions: 0011=Load AC I/O 0111=Store AC I/O cases, 12-bit address identifies particular I/O device. Show program execution (using format Figure 3.5) following program: 1. Load AC device 5. 2. Add contents memory location 940. 3. Store AC device 6. Assume next value retrieved device 5 3 location 940 contains value 2. 3.2 program execution Figure 3.5 described text using six steps. Expand description show use MAR MBR.3.7 / Key terms, review Questions, proBLems 117 3.3 Consider hypothetical 32-bit microprocessor 32-bit instructions composed two fields: first byte contains opcode remainder immediate oper - operand address. a. maximum directly addressable memory capacity (in bytes)? b. Discuss impact system speed microprocessor bus has: 1. 32-bit local address bus 16-bit local data bus, 2. 16-bit local address bus 16-bit local data bus. c. many bits needed program counter instruction register? 3.4 Consider hypothetical microprocessor generating 16-bit address (for example, assume program counter address registers 16 bits wide) hav - ing 16-bit data bus. a. maximum memory address space processor access directly connected “16-bit memory”? b. maximum memory address space processor access directly connected “8-bit memory”? c. architectural features allow microprocessor access separate “I/O space”? d. input output instruction specify 8-bit I/O port number, many 8-bit I/O ports microprocessor support? many 16-bit I/O ports? Explain. 3.5 Consider 32-bit microprocessor, 16-bit external data bus, driven 8-MHz input clock. Assume microprocessor bus cycle whose minimum dura - tion equals four input clock cycles. maximum data transfer rate across bus microprocessor sustain, bytes/sec? increase performance, would better make external data bus 32 bits double external clock frequency supplied microprocessor? State assumptions make, explain. Hint: Determine number bytes transferred per bus cycle. 3.6 Consider computer system contains I/O module controlling simple key - board/printer teletype. following registers contained processor con - nected directly system bus: INPR: Input Register, 8 bits OUTR: Output Register, 8 bits FGI: Input Flag, 1 bit FGO: Output Flag, 1 bit IEN: Interrupt Enable, 1 bit Keystroke input teletype printer output teletype controlled I/O module. teletype able encode alphanumeric symbol 8-bit word decode 8-bit word alphanumeric symbol. a. Describe processor, using first four registers listed problem, achieve I/O teletype. b. Describe function performed efficiently also employing IEN. 3.7 Consider two microprocessors 8- 16-bit-wide external data buses, respec - tively. two processors identical otherwise bus cycles take long. a. Suppose instructions operands two bytes long. factor maximum data transfer rates differ? b. Repeat assuming half operands instructions one byte long. 3.8 Figure 3.26 indicates distributed arbitration scheme used obso - lete bus scheme known Multibus I. Agents daisy-chained physically priority order. left-most agent diagram receives constant bus priority (BPRN) signal indicating higher-priority agent desires bus. agent require bus, asserts bus priority (BPRO) line. beginning clock 118 Chapter 3 / top-Leve L view Computer funCtion inter Conne Ction cycle, agent request control bus lowering BPRO line. lowers BPRN line next agent chain, turn required lower BPRO line. Thus, signal propagated length chain. end chain reaction, one agent whose BPRN asserted whose BPRO not. agent priority. If, beginning bus cycle, bus busy (BUSY inactive), agent priority may seize control bus asserting BUSY line. takes certain amount time BPR signal propagate highest-priority agent lowest. Must time less clock cycle? Explain. 3.9 VAX SBI bus uses distributed, synchronous arbitration scheme. SBI device (i.e., processor, memory, I/O module) unique priority assigned unique transfer request (TR) line. SBI 16 lines (TR0, TR1, . . ., TR15), TR0 highest priority. device wants use bus, places reservation future time slot asserting TR line current time slot. end current time slot, device pending reservation examines TR lines; highest-priority device reservation uses next time slot. maximum 17 devices attached bus. device priority 16 TR line. not? 3.10 VAX SBI, lowest-priority device usually lowest average wait time. reason, processor usually given lowest priority SBI. priority 16 device usually lowest average wait time? circumstances would true? 3.11 synchronous read operation (Figure 3.18), memory module must place data bus sufficiently ahead falling edge Read signal allow signal settling. Assume microprocessor bus clocked 10 MHz Read signal begins fall middle second half T3. a. Determine length memory read instruction cycle. b. When, latest, memory data placed bus? Allow 20 ns settling data lines. 3.12 Consider microprocessor memory read timing shown Figure 3.18. analysis, designer determines memory falls short providing read data time 180 ns. a. many wait states (clock cycles) need inserted proper system opera - tion bus clocking rate 8 MHz? b. enforce wait states, Ready status line employed. processor issued Read command, must wait Ready line asserted attempting read data. time interval must keep Ready line low order force processor insert required number wait states?Bus terminatorBus terminator BPRN BPR BPRN BPR BPRN BPR (highest priority) Master 1M aster 2M aster 3(lowest priority) Figure 3.26 Multibus Distributed Arbitration3.7 / Key terms, review Questions, proBLems 119 3.13 microprocessor memory write timing shown Figure 3.18. manufac - turer specifies width Write signal determined T-50, clock period ns. a. width expect Write signal bus clocking rate 5 MHz? b. data sheet microprocessor specifies data remain valid 20 ns falling edge Write signal. total duration valid data presentation memory? c. many wait states insert memory requires valid data presentation least 190 ns? 3.14 microprocessor increment memory direct instruction, adds 1 value memory location. instruction five stages: fetch opcode (four bus clock cycles), fetch operand address (three cycles), fetch operand (three cycles), add 1 operand (three cycles), store operand (three cycles). a. amount (in percent) duration instruction increase insert two bus wait states memory read memory write operation? b. Repeat assuming increment operation takes 13 cycles instead 3 cycles. 3.15 Intel 8088 microprocessor read bus timing similar Figure 3.18, requires four processor clock cycles. valid data bus amount time extends fourth processor clock cycle. Assume processor clock rate 8 MHz. a. maximum data transfer rate? b. Repeat, assume need insert one wait state per byte transferred. 3.16 Intel 8086 16-bit processor similar many ways 8-bit 8088. 8086 uses 16-bit bus transfer 2 bytes time, provided lower-order byte even address. However, 8086 allows even- odd-aligned word operands. odd-aligned word referenced, two memory cycles, consisting four bus cycles, required transfer word. Consider instruction 8086 involves two 16-bit operands. long take fetch operands? Give range possible answers. Assume clocking rate 4 MHz wait states. 3.17 Consider 32-bit microprocessor whose bus cycle duration 16-bit microprocessor. Assume that, average, 20% operands instruc - tions 32 bits long, 40% 16 bits long, 40% 8 bits long. Calculate improvement achieved fetching instructions operands 32-bit microprocessor. 3.18 microprocessor Problem 3.14 initiates fetch operand stage incre - ment memory direct instruction time keyboard actives interrupt request line. long processor enter interrupt processing cycle? Assume bus clocking rate 10 MHz.120 CaChe MeMory 4.1 Computer Memory System Overview Characteristics Memory Systems Memory Hierarchy 4.2 Cache Memory Principles 4.3 Elements Cache Design Cache Addresses Cache Size Mapping Function Replacement Algorithms Write Policy Line Size Number Caches 4.4 Pentium 4 Cache Organization 4.5 Key Terms, Review Questions, Problems Appendix 4A Performance Characteristics Two- Level Memories Locality Operation Two- Level Memory PerformanceCHAPTER4.1 / Computer memory Sy Stem overview 121 Although seemingly simple concept, computer memory exhibits perhaps wid - est range type, technology, organization, performance, cost feature computer system. single technology optimal satisfying memory requirements computer system. consequence, typical computer system equipped hierarchy memory subsystems, internal system (directly accessible processor) external (accessible processor via I/O module). chapter next focus internal memory elements, Chapter 6 devoted external memory. begin, first section examines key character - istics computer memories. remainder chapter examines essential element modern computer systems: cache memory. 4.1 COMPUTER MEMORY SYSTEM OVERVIEW Characteristics Memory Systems complex subject computer memory made manageable classify memory systems according key characteristics. important listed Table 4.1. term location Table 4.1 refers whether memory internal exter - nal computer. Internal memory often equated main memory, forms internal memory. processor requires local memory, form registers (e.g., see Figure 2.3). Further, see, control unit portion processor may also require internal memory. defer discussion latter two types internal memory later chapters. Cache another form internal memory. External memory consists peripheral storage devices, disk tape, accessible processor via I/O controllers. obvious characteristic memory capacity . internal memory, typically expressed terms bytes (1 byte=8 bits) words. Common word lengths 8, 16, 32 bits. External memory capacity typically expressed terms bytes.Learning Objectives studying chapter, able to: rPresent overview main characteristics computer memory systems use memory hierarchy. rDescribe basic concepts intent cache memory. rDiscuss key elements cache design. rDistinguish among direct mapping, associative mapping, set- associative mapping. rExplain reasons using multiple levels cache. rUnderstand performance implications multiple levels memory.122 CHApter 4 / C ACHe memory related concept unit transfer . internal memory, unit transfer equal number electrical lines memory module. may equal word length, often larger, 64, 128, 256 bits. clarify point, consider three related concepts internal memory: ■Word: “natural” unit organization memory. size word typically equal number bits used represent integer instruction length. Unfortunately, many exceptions. example, CRA C90 (an older model CRA supercomputer) 64-bit word length uses 46-bit integer representation. Intel x86 architecture wide variety instruction lengths, expressed multiples bytes, word size 32 bits. ■Addressable units: systems, addressable unit word. - ever, many systems allow addressing byte level. case, rela - tionship length bits address number N addressable units 2A=N. ■Unit transfer: main memory, number bits read written memory time. unit transfer need equal word addressable unit. external memory, data often transferred much larger units word, referred blocks. Another distinction among memory types method accessing units data. include following: ■Sequential access: Memory organized units data, called records. Access must made specific linear sequence. Stored addressing infor - mation used separate records assist retrieval process. shared read– write mechanism used, must moved current loca - tion desired location, passing rejecting intermediate record. Thus, time access arbitrary record highly variable. Tape units, dis - cussed Chapter 6, sequential access. ■Direct access: sequential access, direct access involves shared read– write mechanism. However, individual blocks records unique Table 4.1 Key Characteristics Computer Memory Systems Location Internal (e.g., processor registers, cache, main memory) External (e.g., optical disks, magnetic disks, tapes) Capacity Number words Number bytes Unit Transfer Word Block Access Method Sequential Direct Random AssociativePerformance Access time Cycle time Transfer rate Physical Type Semiconductor Magnetic Optical Magneto- optical Physical Characteristics Volatile/nonvolatile Erasable/nonerasable Organization Memory modules4.1 / Computer memory Sy Stem overview 123 address based physical location. Access accomplished direct access reach general vicinity plus sequential searching, counting, waiting reach final location. Again, access time variable. Disk units, discussed Chapter 6, direct access. ■Random access: addressable location memory unique, physically wired- addressing mechanism. time access given location inde - pendent sequence prior accesses constant. Thus, location selected random directly addressed accessed. Main memory cache systems random access. ■Associative: random access type memory enables one make comparison desired bit locations within word specified match, words simultaneously. Thus, word retrieved based portion contents rather address. ordinary random- access memory, location addressing mechanism, retrieval time constant independent location prior access patterns. Cache memories may employ associative access. user’s point view, two important characteristics memory capacity performance . Three performance parameters used: ■Access time (latency): random- access memory, time takes perform read write operation, is, time instant address presented memory instant data stored made available use. non- random- access memory, access time time takes position read– write mechanism desired location. ■Memory cycle time: concept primarily applied random- access memory consists access time plus additional time required second access commence. additional time may required transients die signal lines regenerate data read destructively. Note memory cycle time concerned system bus, processor. ■Transfer rate: rate data transferred memory unit. random- access memory, equal 1/(cycle time). non- random- access memory, following relationship holds: Tn=TA+n R (4.1) Tn=Average time read write n bits TA=Average access time n=Number bits R=Transfer rate, bits per second (bps) variety physical types memory employed. com - mon today semiconductor memory, magnetic surface memory, used disk tape, optical magneto- optical.124 CHApter 4 / C ACHe memory Several physical characteristics data storage important. volatile memory, information decays naturally lost electrical power switched off. nonvolatile memory, information recorded remains without deterio - ration deliberately changed; electrical power needed retain informa - tion. Magnetic- surface memories nonvolatile. Semiconductor memory (memory integrated circuits) may either volatile nonvolatile. Nonerasable memory cannot altered, except destroying storage unit. Semiconductor memory type known read- memory (ROM). necessity, practical nonerasa- ble memory must also nonvolatile. random- access memory, organization key design issue. con - text, organization refers physical arrangement bits form words. obvious arrangement always used, explained Chapter 5. Memory Hierarchy design constraints computer’s memory summed three ques - tions: much? fast? expensive? question much somewhat open ended. capacity there, applications likely developed use it. question fast is, sense, easier answer. achieve greatest performance, memory must able keep processor. is, processor executing instructions, would want pause waiting instructions operands. final question must also considered. practical system, cost memory must reasonable relationship components. might expected, trade- among three key characteristics memory: capacity, access time, cost. variety technologies used implement memory systems, across spectrum technologies, following relationships hold: ■Faster access time, greater cost per bit; ■Greater capacity, smaller cost per bit; ■Greater capacity, slower access time. dilemma facing designer clear. designer would like use mem - ory technologies provide large- capacity memory, cap - acity needed cost per bit low. However, meet performance requirements, designer needs use expensive, relatively lower- capacity mem - ories short access times. way dilemma rely single memory component technology, employ memory hierarchy . typical hierarchy illustrated Figure 4.1. one goes hierarchy, following occur: a. Decreasing cost per bit; b. Increasing capacity; c. Increasing access time; d. Decreasing frequency access memory processor. Thus, smaller, expensive, faster memories supplemented larger, cheaper, slower memories. key success organization 4.1 / Computer memory Sy Stem overview 125 item (d): decreasing frequency access. examine concept greater detail discuss cache, later chapter, virtual memory Chapter 8. brief explanation provided point. use two levels memory reduce average access time works prin - ciple, conditions (a) (d) apply. employing variety tech - nologies, spectrum memory systems exists satisfies conditions (a) (c). Fortunately, condition (d) also generally valid. basis validity condition (d) principle known locality reference [DENN68]. course execution program, memory ref - erences processor, instructions data, tend cluster. Programs typically contain number iterative loops subroutines. loop sub - routine entered, repeated references small set instructions. Simi - larly, operations tables arrays involve access clustered set data words. long period time, clusters use change, short period time, processor primarily working fixed clusters memory references.Inboard memory Outboard storage Off-line storageMain memory Magnetic diskCD-ROM CD-RW DVD-RW DVD-RAM Blu-Ray Magnetic tapeCacheReg- isters Figure 4.1 Memory Hierarchy126 CHApter 4 / C ACHe memory Accordingly, possible organize data across hierarchy percentage accesses successively lower level substantially less level above. Consider two- level example already presented. Let level 2 EXAMPLE 4.1 Suppose processor access two levels memory. Level 1 contains 1000 words access time 0.01 ms; level 2 contains 100,000 words access time 0.1 ms. Assume word accessed level 1, processor accesses directly. level 2, word first transferred level 1 accessed processor. simplicity, ignore time required pro - cessor determine whether word level 1 level 2. Figure 4.2 shows general shape curve covers situation. figure shows average access time two- level memory function hit ratio H, H defined fraction memory accesses found faster memory (e.g., cache), T1 access time level 1, T2 access time level 2.1 seen, high percentages level 1 access, average total access time much closer level 1 level 2. example, suppose 95% memory accesses found level 1. average time access word expressed (0.95)(0.01 ms)+(0.05)(0.01 ms+0.1 ms)=0.0095+0.0055=0.015 ms average access time much closer 0.01 ms 0.1 ms, desired. 1If accessed word found faster memory, defined hit. miss occurs accessed word found faster memory.0T1T1 + T2 T2 1 Fraction accesses volving le vel 1 (hit ratio)Average access time Figure 4.2 Performance Accesses Involving Level 1 (hit ratio)4.1 / Computer memory Sy Stem overview 127 memory contain program instructions data. current clusters tem - porarily placed level 1. time time, one clusters level 1 swapped back level 2 make room new cluster coming level 1. average, however, references instructions data contained level 1. principle applied across two levels memory, sug - gested hierarchy shown Figure 4.1. fastest, smallest, expen - sive type memory consists registers internal processor. Typically, processor contain dozen registers, although machines contain hundreds registers. Main memory principal internal memory system computer. location main memory unique address. Main memory usu - ally extended higher- speed, smaller cache. cache usually visible programmer or, indeed, processor. device staging movement data main memory processor registers improve performance. three forms memory described are, typically, volatile employ semiconductor technology. use three levels exploits fact semicon - ductor memory comes variety types, differ speed cost. Data stored permanently external mass storage devices, com - mon hard disk removable media, removable magnetic disk, tape, optical storage. External, nonvolatile memory also referred secondary memory auxiliary memory . used store program data files usually visible programmer terms files records, opposed individual bytes words. Disk also used provide extension main mem - ory known virtual memory, discussed Chapter 8. forms memory may included hierarchy. example, large IBM mainframes include form internal memory known expanded storage. uses semiconductor technology slower less expensive main memory. Strictly speaking, memory fit hierarchy side branch: Data moved main memory expanded storage expanded storage external memory. forms secondary memory include optical magneto- optical disks. Finally, additional levels effectively added hierarchy software. portion main memory used buffer hold data temporarily read disk. tech - nique, sometimes referred disk cache,2 improves performance two ways: ■Disk writes clustered. Instead many small transfers data, large transfers data. improves disk performance minimizes processor involvement. ■Some data destined write- may referenced program next dump disk. case, data retrieved rapidly soft - ware cache rather slowly disk. Appendix 4A examines performance implications multilevel memory structures. 2 Disk cache generally purely software technique examined book. See [STAL15] discussion.128 CHApter 4 / C ACHe memory 4.2 CACHE MEMORY PRINCIPLES Cache memory designed combine memory access time expensive, high- speed memory combined large memory size less expensive, lower- speed memory. concept illustrated Figure 4.3a. relatively large slow main memory together smaller, faster cache memory. cache contains copy portions main memory. processor attempts read word memory, check made determine word cache. so, word delivered processor. not, block main memory, consisting fixed number words, read cache word delivered pro - cessor. phenomenon locality reference, block data fetched cache satisfy single memory reference, likely future references memory location words block. Figure 4.3b depicts use multiple levels cache. L2 cache slower typically larger L1 cache, L3 cache slower typically larger L2 cache. Figure 4.4 depicts structure cache/ main- memory system. Main mem - ory consists 2n addressable words, word unique n- bit address. mapping purposes, memory considered consist number fixed- length blocks K words each. is, M=2n/K blocks main memory. cache consists blocks, called lines .3 line contains K words, CPUWord transfer Fast Fastest FastLess fastSlowBlock transfer Cache Main memory (a) Single cache (b) Three-level cache ganizationCPULevel 1 (L1) cacheLevel 2 (L2) cacheLevel 3 (L3) cacheMain memorySlow Figure 4.3 Cache Main Memory 3In referring basic unit cache, term line used, rather term block , two rea - sons: (1) avoid confusion main memory block, contains number data words cache line; (2) cache line includes K words data, main memory block, also includes tag control bits.4.2 / C ACHe memory prinCipleS 129 plus tag bits. line also includes control bits (not shown), bit indicate whether line modified since loaded cache. length line, including tag control bits, line size . line size may small 32 bits, “word” single byte; case line size 4 bytes. number lines considerably less number main memory blocks (mVM). time, subset blocks mem - ory resides lines cache. word block memory read, block transferred one lines cache. blocks lines, individual line cannot uniquely permanently dedicated par - ticular block. Thus, line includes tag identifies particular block currently stored. tag usually portion main memory address, described later section. Figure 4.5 illustrates read operation. processor generates read address (RA) word read. word contained cache, deliv - ered processor. Otherwise, block containing word loaded cache, word delivered processor. Figure 4.5 shows last two operations occurring parallel reflects organization shown Figure 4.6, typical contemporary cache organizations. organization, cache connects processor via data, control, address lines. data address lines also attach data address buffers, attach system bus Memory addr ess 0 1 20 1 2 C – 13 2n – 1 Word lengthBlock length (K words)Block 0 (K words) Block M–1Line number Tag Block (b) Main memory(a) Cache      Figure 4.4 Cache/Main Memory Structure130 CHApter 4 / C ACHe memory main memory reached. cache hit occurs, data address buff - ers disabled communication processor cache, system bus traffic. cache miss occurs, desired address loaded onto system bus data returned data buffer cache processor. organizations, cache physically interposed processor main memory data, address, control lines. latter case, cache miss, desired word first read cache transferred cache processor. discussion performance parameters related cache use contained Appendix 4A.Receive address RA CPU block containing RA cache? Fetch RA word deliver CPU DONEAccess main memory block containing RA Allocate cache line main memory block Deliver RA word CPULoad main memory block cache lineSTART Yes Figure 4.5 Cache Read Operation4.3 / element C ACHe DeSign 131 4.3 ELEMENTS CACHE DESIGN section provides overview cache design parameters reports typi - cal results. occasionally refer use caches high- performance computing (HPC) . HPC deals supercomputers software, especially scientific applications involve large amounts data, vector matrix computation, use parallel algorithms. Cache design HPC quite different hard - ware platforms applications. Indeed, many researchers found HPC appli - cations perform poorly computer architectures employ caches [BAIL93]. researchers since shown cache hierarchy useful improving perfor - mance application software tuned exploit cache [WANG99, PRES01].4 Although large number cache implementations, basic design elements serve classify differentiate cache architectures. Table 4.2 lists key elements. Cache Addresses Almost nonembedded processors, many embedded processors, support vir - tual memory, concept discussed Chapter 8. essence, virtual memory facil - ity allows programs address memory logical point view, without regard amount main memory physically available. virtual memory used, address fields machine instructions contain virtual addresses. reads Processor CacheAddr ess Addr ess buffer Data bufferContr ol DataContr ol System bus Figure 4.6 Typical Cache Organization 4For general discussion HPC, see [DOWD98].132 CHApter 4 / C ACHe memory writes main memory, hardware memory management unit (MMU) translates virtual address physical address main memory. virtual addresses used, system designer may choose place cache processor MMU MMU main mem - ory (Figure 4.7). logical cache , also known virtual cache , stores data using Table 4.2 Elements Cache Design Cache Addresses Logical Physical Cache Size Mapping Function Direct Associative Set associative Replacement Algorithm Least recently used (LRU) First first (FIFO) Least frequently used (LFU) RandomWrite Policy Write Write back Line Size Number Caches Single two level Unified split ProcessorMain memoryCacheLogical addr ess Physical addr ess DataMMU (a) Logical cache ProcessorMain memoryCacheLogical addr ess Physical addr ess DataMMU (b) Ph ysical cache Figure 4.7 Logical Physical Caches4.3 / element C ACHe DeSign 133 virtual addresses . processor accesses cache directly, without going MMU. physical cache stores data using main memory physical addresses . One obvious advantage logical cache cache access speed faster physical cache, cache respond MMU performs address translation. disadvantage fact virtual memory systems supply application virtual memory address space. is, application sees virtual memory starts address 0. Thus, virtual address two different applications refers two different phys - ical addresses. cache memory must therefore completely flushed application context switch, extra bits must added line cache identify virtual address space address refers to. subject logical versus physical cache complex one, beyond scope book. in- depth discussion, see [CEKL97] [JACO08]. Cache Size second item Table 4.2, cache size, already discussed. would like size cache small enough overall average cost per bit close main memory alone large enough overall average access time close cache alone. several motivations minimizing cache size. larger cache, larger num - ber gates involved addressing cache. result large caches tend slightly slower small ones— even built integrated circuit technology put place chip circuit board. avail - able chip board area also limits cache size. performance cache sensitive nature workload, impossible arrive single “optimum” cache size. Table 4.3 lists cache sizes current past processors. Mapping Function fewer cache lines main memory blocks, algorithm needed mapping main memory blocks cache lines. Further, means needed determining main memory block currently occupies cache line. choice mapping function dictates cache organized. Three techniques used: direct, associative, set-associative. examine turn. case, look general structure specific example. EXAMPLE 4.2 three cases, example includes following elements: ■The cache hold 64 kB. ■Data transferred main memory cache blocks 4 bytes each. means cache organized 16K=214 lines 4 bytes each. ■The main memory consists 16 MB, byte directly addressable 24-bit address (224=16M). Thus, mapping purposes, consider main memory consist 4M blocks 4 bytes each.134 CHApter 4 / C ACHe memory direct mapping simplest technique, known direct mapping, maps block main memory one possible cache line. mapping expressed i=j modulo i=cache line number j=main memory block number m=number lines cache Figure 4.8a shows mapping first blocks main memory. block main memory maps one unique line cache. next blocks Table 4.3 Cache Sizes Processors Processor TypeYear Introduction L1 Cachea L2 Cache L3 Cache IBM 360/85 Mainframe 1968 16–32 kB — — PDP- 11/70 Minicomputer 1975 1 kB — — VAX 11/780 Minicomputer 1978 16 kB — — IBM 3033 Mainframe 1978 64 kB — — IBM 3090 Mainframe 1985 128–256 kB — — Intel 80486 PC 1989 8 kB — — Pentium PC 1993 8 kB/8 kB 256–512 kB — PowerPC 601 PC 1993 32 kB — — PowerPC 620 PC 1996 32 kB/32 kB — — PowerPC G4 PC/server 1999 32 kB/32 kB 256 kB 1 MB 2 MB IBM S/390 G6 Mainframe 1999 256 kB 8 MB — Pentium 4 PC/server 2000 8 kB/8 kB 256 kB — IBM SP High- end server/ supercomputer2000 64 kB/32 kB 8 MB — CRAY MTAbSupercomputer 2000 8 kB 2 MB — Itanium PC/server 2001 16 kB/16 kB 96 kB 4 MB Itanium 2 PC/server 2002 32 kB 256 kB 6 MB IBM POWER5 High- end server 2003 64 kB 1.9 MB 36 MB CRAY XD- 1 Supercomputer 2004 64 kB/64 kB 1 MB — IBM POWER6 PC/server 2007 64 kB/64 kB 4 MB 32 MB IBM z10 Mainframe 2008 64 kB/128 kB 3 MB 24–48 MB Intel Core i7 EE 990Workstation/ server20116*32 kB/ 32 kB1.5 MB 12 MB IBM zEnterprise 196Mainframe/ server201124*64 kB/ 128 kB24*1.5 MB24 MB L3 192 MB L4 Notes: Two values separated slash refer instruction data caches. b caches instruction only; data caches.4.3 / element C ACHe DeSign 135 main memory map cache fashion; is, block Bm main memory maps line L0 cache, block Bm+1 maps line L1, on. mapping function easily implemented using main memory address. Figure 4.9 illustrates general mechanism. purposes cache access, main memory address viewed consisting three fields. least signifi - cant w bits identify unique word byte within block main memory; contemporary machines, address byte level. remaining bits specify one 2s blocks main memory. cache logic interprets bits tag s-r bits (most significant portion) line field r bits. latter field iden - tifies one m=2r lines cache. summarize, ■Address length =(s+w) bits ■Number addressable units =2s+w words bytes ■Block size=line size=2w words bytes ■Number blocks main memory =2s+w 2w=2s ■Number lines cache =m=2r ■Size cache =2r+w words bytes ■Size tag =(s-r) bits(a) Direct mappingFirst blocks main memory (equal size cache)b L0 Lm–1 L0 Lm–1Bm–1B0 b = length block bits = length tag bitsCache memory lines bb b (b) Associati mappingOne block main memory Cache memory Figure 4.8 Mapping Main Memory Cache: Direct Associative136 CHApter 4 / C ACHe memory EXAMPLE 4.2a Figure 4.10 shows example system using direct mapping.5 example, m=16K=214 i=j modulo 214. mapping becomes Cache Line Starting Memory Address Block 0 000000, 010000, …, FF0000 1 000004, 010004, …, FF0004 f f 214-1 00FFFC, 01FFFC, …, FFFFFC Note two blocks map line number tag number. Thus, blocks starting addresses 000000, 010000, …, FF0000 tag numbers 00, 01, …, FF, respectively. Referring back Figure 4.5, read operation works follows. cache system presented 24-bit address. 14-bit line number used index cache access particular line. 8-bit tag number matches tag number currently stored line, 2-bit word number used select one 4 bytes line. Otherwise, 22-bit tag- plus- line field used fetch block main memory. actual address used fetch 22-bit tag- plus- line concatenated two 0 bits, 4 bytes fetched starting block boundary.Word Line TagW0 W1 W2 W3 Compare 1 match 0 match 0 match 1 matchW4j W(4j+1) W(4j+2) W(4j+3)Tag DataCache L0 LiMemory address (Miss cache)(Hit cache)ws – rw rs + w Main memory BjB0 w Lm–1s – r Figure 4.9 Direct- Mapping Cache Organization 5In subsequent figures, memory values represented hexadecimal notation. See Chapter 9 basic refresher number systems (decimal, binary, hexadecimal).4.3 / element C ACHe DeSign 137 effect mapping blocks main memory assigned lines cache follows: Cache line Main memory blocks assigned 0 0, m, 2m, c, 2s-m 1 1, m+1, 2m+1, c, 2s-m+1 f f m-1 m-1, 2m-1, 3m-1, c, 2s-1 Thus, use portion address line number provides unique mapping block main memory cache. block actually 111111111111111111111100111111111111111111111000111111110000000000000000000101101111111111111100000101100011001110011100 111111110000000000000100000101100000000000000100000101100000000000000000000000001111111111111100000000000000000000000000 000000000000000000000100 00000000111111111111100000 00 FF FF FF FF16 16161600 0013579246TagTag (hex)Main memory addr ess (binary) Tag Data 32 bits 16K line cache8 bits 8 bits 2 bitsTag Main memory addr ess =Line WordLine numbe rLine + Word Data 77777777 11235813 12345678FEDCBA98 FEDCBA98 24682468112233441357924600 16 FF 16160000 0001 0CE7 3FFE 3FFF11235813 FEDCBA98 11223344 12345678 14 bits32 bits 16-Mb main memoryNote : Memory address v alues binary representation; v alues xadecimal. Figure 4.10 Direct Mapping Example138 CHApter 4 / C ACHe memory read assigned line, necessary tag data distinguish blocks fit line. significant s-r bits serve purpose. direct mapping technique simple inexpensive implement. main disadvantage fixed cache location given block. Thus, program happens reference words repeatedly two different blocks map line, blocks continually swapped cache, hit ratio low (a phenomenon known thrashing ). Selective Victim Cache Simulator One approach lower miss penalty remember discarded case needed again. Since discarded data already fetched, used small cost. recycling possible using victim cache. Victim cache originally proposed approach reduce conflict misses direct mapped caches without affecting fast access time. Victim cache fully associative cache, whose size typically 4 16 cache lines, residing direct mapped L1 cache next level memory. concept explored Appendix F. associative mapping Associative mapping overcomes disadvantage direct mapping permitting main memory block loaded line cache (Figure 4.8b). case, cache control logic interprets memory address simply Tag Word field. Tag field uniquely identifies block main memory. determine whether block cache, cache control logic must simultaneously examine every line’s tag match. Figure 4.11 illustrates logic. Tag WordW0 W1 W2 W3 CompareW4j W(4 j+1) W(4 j+2) W(4 j+3)Tag DataCache Memory address (Miss cache)(Hit cache)wwss+w Main memory w s1 match 0 match 0 match 1 matchL0 LjB0 Bj Lm–1 Figure 4.11 Fully Associative Cache Organization4.3 / element C ACHe DeSign 139 111111111111111111111100111111111111111111111000111111111111111111110100000101100011001110011000 000101100011001110011100 000101100011001110100000000000000000000000000100000000000000000000000000 13579246 FEDCBA98Tag Data 32 bits 16K line cache22 bits Tag Main memory addr ess =WordLine numberData 246824681122334433333333112233443FFFFE 058CE7 000000 3FFFFF0000 0001 3FFE 3FFFFEDCBA98 135792463FFFFD 3FFD 33333333 24682468 32 bits 16-Mb main memory 2 bits 22 bits000000 000001Tag (hex) 058CE7 058CE8058CE6 3FFFFE3FFFFD 3FFFFFTagMain memory addr ess (binary) Word Note : Memory address values binary representation; v alues xadecimal. Figure 4.12 Associative Mapping Example EXAMPLE 4.2b Figure 4.12 shows example using associative mapping. main memory address consists 22-bit tag 2-bit byte number. 22-bit tag must stored 32-bit block data line cache. Note leftmost (most significant) 22 bits address form tag. Thus, 24-bit hexadecimal address 16339C 22-bit tag 058CE7 . easily seen binary notation: Memory address 0001 0110 0011 0011 1001 1100 (binary) 1 6 3 3 9 C (hex) Tag (leftmost 22 bits) 00 0101 1000 1100 1110 0111 (binary) 0 5 8 C E 7 (hex)140 CHApter 4 / C ACHe memory Note field address corresponds line number, number lines cache determined address format. summarize, ■Address length =(s+w) bits ■Number addressable units =2s+w words bytes ■Block size=line size=2w words bytes ■Number blocks main memory =2s+w 2w=2s ■Number lines cache=undetermined ■Size tag =s bits associative mapping, flexibility block replace new block read cache. Replacement algorithms, discussed later section, designed maximize hit ratio. principal disadvantage asso - ciative mapping complex circuitry required examine tags cache lines parallel. Cache Time Analysis Simulator set- associative mapping Set- associative mapping compromise exhibits strengths direct associative approaches reducing disadvantages. case, cache consists number sets, consists num - ber lines. relationships m=v*k i=j modulo v i=cache set number j=main memory block number m=number lines cache v=number sets k=number lines set referred k- way set- associative mapping. set- associative map - ping, block Bj mapped lines set j. Figure 4.13a illustrates mapping first v blocks main memory. associative mapping, word maps multiple cache lines. set- associative mapping, word maps cache lines specific set, main memory block B0 maps set 0, on. Thus, set- associative cache physically implemented v associative caches. also possible implement set- associative cache k direct mapping caches, shown Figure 4.13b. direct- mapped cache referred way, consisting v lines. first v lines main memory direct mapped v lines way; next group v lines main memory similarly mapped, on. direct- mapped implementation typically used 4.3 / element C ACHe DeSign 141 small degrees associativity (small values k) associative- mapped implementation typically used higher degrees associativity [JACO08]. set- associative mapping, cache control logic interprets memory address three fields: Tag, Set, Word. set bits specify one v=2d sets. bits Tag Set fields specify one 2s blocks main memory. Figure 4.14 illustrates cache control logic. fully associative mapping, tag memory address quite large must compared tag every line cache. k- way set- associative mapping, tag memory address much smaller compared k tags within single set. summarize, ■Address length =(s+w) bits ■Number addressable units =2s+w words bytesFirst v blocks main memory (equal number sets)Cache memory—way 1 Cache memory—way kOne set (b) k direct–mapped caches v lines Bv–1B0 L0 Lv–1(a) v associati ve–mapped cachesFirst v blocks main memory (equal number sets)Cache memory–set 0 Cache memory–set v–1 k lines Bv–1B0 L0 Lk–1 Figure 4.13 Mapping Main Memory Cache: k- Way Set Associative142 CHApter 4 / C ACHe memory ■Block size=line size=2w words bytes ■Number blocks main memory =2s+w 2w=2s ■Number lines set =k ■Number sets =v=2d ■Number lines cache =m=kv=k*2d ■Size cache =k*2d+w words bytes ■Size tag =(s-d) bitsWord Set Tag CompareTag DataCache F0Memory address (Hit cache)s – dw – ds + w Main memory + wF1 Fk–1 Fk Fk+i F2k–1Set 0 Set 1B1B0 Bj 1 match 0 match 0 match 1 match(Miss cache) Figure 4.14 k- Way Set-Associative Cache Organization EXAMPLE 4.2 c Figure 4.15 shows example using set- associative mapping two lines set, referred two- way set- associative. 13-bit set number iden - tifies unique set two lines within cache. also gives number block main memory, modulo 213. determines mapping blocks lines. Thus, blocks 000000, 008000, …, FF8000 main memory map cache set 0. blocks loaded either two lines set. Note two blocks map cache set tag number. read operation, 13-bit set number used determine set two lines examined. lines set exam - ined match tag number address accessed.000101100111111111111100 111111111111111111111000111111111000000000000000000101100011001110011100000101100000000000000000000000001111111111111000000000000000000000000000 13579246 000 000 000 000Tag (hex) Tag Data 32 bits 16K line cache9 bitsTagMain memory addr ess = SetW ord Tag DataSet numberData 77777777 11235813 12345678FEDCBA98 FEDCBA98 246824681122334402C 02C 02C 02C 1FF 1FF 1FF 1FF77777777 13579246000 02C 1FF 02C02C0000 0001 0CE7 1FFE 1FFF02C 246824681FF11235813 11223344 12345678 32 bits 16–Mb main memory32 bits 9 bitsFEDCBA982 bits 13 bits 9 bits 111111111111111111111100111111111000000000000100000101100000000000000100000000001111111111111100000000000000000000000100TagMain memory addr ess (binary) Set + Word Note : Memory address values binary representation; values xadecimal. Figure 4.15 Two- Way Set- Associative Mapping Example 143144 CHApter 4 / C ACHe memory extreme case v=m, k=1, set- associative technique reduces direct mapping, v=1, k=m, reduces associative mapping. use two lines per set (v=m/2, k=2) common set- associative organization. significantly improves hit ratio direct mapping. Four- way set associative (v=m/4, k=4) makes modest additional improvement relatively small additional cost [MAYB84, HILL89]. increases number lines per set little effect. Figure 4.16 shows results one simulation study set- associative cache performance function cache size [GENU04]. difference performance direct two- way set associative significant least cache size 64 kB. Note also difference two- way four- way 4 kB much less difference going 4 kB 8 kB cache size. complexity cache increases proportion associativity, case would justifiable increasing cache size 8 even 16 kB. final point note beyond 32 kB, increase cache size brings significant increase performance. results Figure 4.16 based simulating execution GCC compiler. Different applications may yield different results. example, [CANT01] reports results cache performance using many CPU2000 SPEC benchmarks. results [CANT01] comparing hit ratio cache size follow pattern Figure 4.16, specific values somewhat different. Cache Simulator Multitask Cache Simulator0.0 1kHit ratio 2k 4k 8k 16k Cache size (bytes) Direct Two-way Four-way Eight-way Sixteen-w ay32k6 4k 128k 256k 512k 1M0.10.20.30.40.50.60.70.80.91.0 Figure 4.16 Varying Associativity Cache Size4.3 / element C ACHe DeSign 145 Replacement Algorithms cache filled, new block brought cache, one existing blocks must replaced. direct mapping, one possible line particular block, choice possible. associative set- associative techniques, replacement algorithm needed. achieve high speed, algorithm must implemented hardware. number algorithms tried. mention four common. Probably effective least recently used (LRU) : Replace block set cache longest reference it. two- way set associative, easily implemented. line includes USE bit. line referenced, USE bit set 1 USE bit line set set 0. block read set, line whose USE bit 0 used. assuming recently used memory locations likely referenced, LRU give best hit ratio. LRU also relatively easy implement fully associative cache. cache mechanism maintains separate list indexes lines cache. line referenced, moves front list. replacement, line back list used. simplicity implementation, LRU popular replacement algorithm. Another possibility first- in- first- (FIFO): Replace block set cache longest. FIFO easily implemented round- robin circu - lar buffer technique. Still another possibility least frequently used (LFU): Replace block set experienced fewest references. LFU could imple - mented associating counter line. technique based usage (i.e., LRU, LFU, FIFO, variant) pick line random among candidate lines. Simulation studies shown random replacement provides slightly inferior performance algorithm based usage [SMIT82]. Write Policy block resident cache replaced, two cases consider. old block cache altered, may - written new block without first writing old block. least one write operation performed word line cache, main mem - ory must updated writing line cache block memory bringing new block. variety write policies, performance eco - nomic trade- offs, possible. two problems contend with. First, one device may access main memory. example, I/O module may able read- write directly memory. word altered cache, corresponding memory word invalid. Further, I/O device altered main memory, cache word invalid. complex problem occurs multiple processors attached bus processor local cache. Then, word altered one cache, could conceivably invalidate word caches. simplest technique called write . Using technique, write operations made main memory well cache, ensuring main memory always valid. processor– cache module monitor traffic main memory maintain consistency within cache. main disadvantage 146 CHApter 4 / C ACHe memory technique generates substantial memory traffic may create bot - tleneck. alternative technique, known write back , minimizes memory writes. write back, updates made cache. update occurs, dirty bit , use bit , associated line set. Then, block replaced, written back main memory dirty bit set. problem write back portions main memory invalid, hence accesses I/O modules allowed cache. makes complex circuitry potential bottleneck. Experience shown percentage memory references writes order 15% [SMIT82]. However, HPC applications, number may approach 33% ( vector- vector multiplication) go high 50% (matrix transposition). EXAMPLE 4.3 Consider cache line size 32 bytes main memory requires 30 ns transfer 4-byte word. line written least swapped cache, average number times line must written swapped write- back cache efficient write- cache? write- back case, dirty line written back once, swap- time, taking 8*30=240 ns. write- case, update line requires one word written main memory, taking 30 ns. Therefore, average line gets written least gets written 8 times swap out, write back efficient. bus organization one device (typically processor) cache main memory shared, new problem introduced. data one cache altered, invalidates corresponding word main memory, also word caches (if cache happens word). Even write- policy used, caches may contain invalid data. system prevents problem said maintain cache coher - ency. Possible approaches cache coherency include following: ■Bus watching write through: cache controller monitors address lines detect write operations memory bus masters. another master writes location shared memory also resides cache memory, cache controller invalidates cache entry. strategy depends use write- policy cache controllers. ■Hardware transparency: Additional hardware used ensure updates main memory via cache reflected caches. Thus, one pro - cessor modifies word cache, update written main memory. addition, matching words caches similarly updated. ■Noncacheable memory: portion main memory shared one processor, designated noncacheable. system, accesses shared memory cache misses, shared memory never copied cache. noncacheable memory identified using chip- select logic high- address bits.4.3 / element C ACHe DeSign 147 Cache coherency active field research. topic explored Part Five. Line Size Another design element line size. block data retrieved placed cache, desired word also number adjacent words retrieved. block size increases small larger sizes, hit ratio first increase principle locality, states data vicinity referenced word likely referenced near future. block size increases, useful data brought cache. hit ratio begin decrease, however, block becomes even bigger probability using newly fetched information becomes less probability reusing information replaced. Two specific effects come play: ■Larger blocks reduce number blocks fit cache. block fetch overwrites older cache contents, small number blocks results data overwritten shortly fetched. ■As block becomes larger, additional word farther requested word therefore less likely needed near future. relationship block size hit ratio complex, depending locality characteristics particular program, definitive optimum value found. size 8 64 bytes seems reasonably close optimum [SMIT87, PRZY88, PRZY90, HAND98]. HPC systems, 64- 128-byte cache line sizes frequently used. Number Caches caches originally introduced, typical system single cache. recently, use multiple caches become norm. Two aspects design issue concern number levels caches use unified versus split caches. multilevel caches logic density increased, become possible cache chip processor: on- chip cache. Compared cache reachable via external bus, on- chip cache reduces processor’s external bus activity therefore speeds execution times increases overall system performance. requested instruction data found on- chip cache, bus access eliminated. short data paths internal processor, compared bus lengths, on- chip cache accesses complete appreciably faster would even zero- wait state bus cycles. Furthermore, period bus free support transfers. inclusion on- chip cache leaves open question whether off- chip, external, cache still desirable. Typically, answer yes, contemporary designs include on- chip external caches. simplest organization known two- level cache, internal level 1 (L1) external cache designated level 2 (L2). reason including L2 cache following: L2 cache processor makes access request memory location L1 cache, processor must access DRAM 148 CHApter 4 / C ACHe memory ROM memory across bus. Due typically slow bus speed slow memory access time, results poor performance. hand, L2 SRAM (static RAM) cache used, frequently missing information quickly retrieved. SRAM fast enough match bus speed, data accessed using zero- wait state transaction, fastest type bus transfer. Two features contemporary cache design multilevel caches note - worthy. First, off- chip L2 cache, many designs use system bus path transfer L2 cache processor, use separate data path, reduce burden system bus. Second, continued shrinkage processor components, number processors incorporate L2 cache processor chip, improving performance. potential savings due use L2 cache depends hit rates L1 L2 caches. Several studies shown that, general, use second- level cache improve performance (e.g., see [AZIM92], [NOVI93], [HAND98]). However, use multilevel caches complicate design issues related caches, including size, replacement algorithm, write policy; see [HAND98] [PEIR99] discussions. Figure 4.17 shows results one simulation study two- level cache perfor - mance function cache size [GENU04]. figure assumes caches line size shows total hit ratio. is, hit counted desired data appears either L1 L2 cache. figure shows impact L2 total hits respect L1 size. L2 little effect total number cache hits least double L1 cache size. Note steepest part slope L1 cache 8 kB L2 cache 16 kB. L1 cache 16 kB, steepest part curve L2 cache size 32 kB. Prior point, L2 cache little, any, impact total cache performance. need L2 cache larger 0.780.800.820.840.860.880.900.920.940.960.98 1k 2k 4k 8k 16k 32kL1 = 16k 64k1 28k256k512k1 M2 MHit ratio L2 cache size (bytes)L1 = 8k Figure 4.17 Total Hit Ratio (L1 L2) 8-kB 16-kB L14.4 / pentium 4 C ACHe orgAnizAtion 149 L1 cache affect performance makes sense. L2 cache line size capacity L1 cache, contents less mirror L1 cache. increasing availability on- chip area available cache, con - temporary microprocessors moved L2 cache onto processor chip added L3 cache. Originally, L3 cache accessible external bus. recently, microprocessors incorporated on- chip L3 cache. either case, appears performance advantage adding third level (e.g., see [GHAI98]). Further, large systems, IBM mainframe zEnter - prise systems, incorporate 3 on- chip cache levels fourth level cache shared across multiple chips [CURR11]. unified versus split caches on- chip cache first made appearance, many designs consisted single cache used store references data instructions. recently, become common split cache two: one dedicated instructions one dedicated data. two caches exist level, typically two L1 caches. processor attempts fetch instruction main memory, first consults instruction L1 cache, processor attempts fetch data main memory, first consults data L1 cache. two potential advantages unified cache: ■For given cache size, unified cache higher hit rate split caches balances load instruction data fetches automatically. is, execution pattern involves many instruction fetches data fetches, cache tend fill instructions, execution pattern involves relatively data fetches, opposite occur. ■Only one cache needs designed implemented. trend toward split caches L1 unified caches higher levels, particularly superscalar machines, emphasize parallel instruction execu - tion prefetching predicted future instructions. key advantage split cache design eliminates contention cache instruction fetch/decode unit execution unit. important design relies pipelining instructions. Typically, processor fetch instructions ahead time fill buffer, pipeline, instructions executed. Suppose unified instruction/data cache. execution unit performs memory access load store data, request submitted unified cache. If, time, instruction prefetcher issues read request cache instruc - tion, request temporarily blocked cache service execu - tion unit first, enabling complete currently executing instruction. cache contention degrade performance interfering efficient use instruction pipeline. split cache structure overcomes difficulty. 4.4 PENTIUM 4 CACHE ORGANIZATION evolution cache organization seen clearly evolution Intel micro - processors (Table 4.4). 80386 include on- chip cache. 80486 includes single on- chip cache 8 kB, using line size 16 bytes four- way 150 CHApter 4 / C ACHe memory set- associative organization. Pentium processors include two on- chip L1 caches, one data one instructions. Pentium 4, L1 data cache 16 kB, using line size 64 bytes four- way set- associative organi - zation. Pentium 4 instruction cache described subsequently. Pentium II also includes L2 cache feeds L1 caches. L2 cache eight- way set associative size 512 kB line size 128 bytes. L3 cache added Pentium III became on- chip high- end versions Pentium 4. Figure 4.18 provides simplified view Pentium 4 organization, high - lighting placement three caches. processor core consists four major components: ■Fetch/decode unit: Fetches program instructions order L2 cache, decodes series micro- operations, stores results L1 instruction cache. ■ Out- of- order execution logic: Schedules execution micro- operations subject data dependencies resource availability; thus, micro- operations may scheduled execution different order fetched instruction stream. time permits, unit schedules speculative execution micro- operations may required future.Table 4.4 Intel Cache Evolution Problem SolutionProcessor Feature First Appears External memory slower system bus.Add external cache using faster memory technology.386 Increased processor speed results external bus becoming bottleneck cache access.Move external cache on- chip, operating speed processor.486 Internal cache rather small, due limited space chip.Add external L2 cache using faster technology main memory.486 Contention occurs Instruction Prefetcher Execution Unit simultaneously require access cache. case, Prefetcher stalled Execution Unit’s data access takes place.Create separate data instruc- tion caches.Pentium Increased processor speed results external bus becoming bottleneck L2 cache access.Create separate back- side bus runs higher speed main ( front- side) external bus. BSB dedicated L2 cache.Pentium Pro Move L2 cache processor chip.Pentium II applications deal massive databases must rapid access large amounts data. on- chip caches small.Add external L3 cache. Pentium III Move L3 cache on- chip. Pentium 4Load addr ess unitInteger r egister /f_ile L1 data cache (16 kB)FP register /f_ile Store addr ess unitSimple integer ALUInstruction fetch/decode unitOut-of-order execution logic L2 cache (512 kB)L3 cache (1 MB)L1 instruction cache (12K mops) Simple integer ALUComplex integer ALUFP/ MMX unitFP move unitSystem b us 64 bits 256 bits Figure 4.18 Pentium 4 Block Diagram 151152 CHApter 4 / C ACHe memory ■Execution units: units execute micro- operations, fetching required data L1 data cache temporarily storing results registers. ■Memory subsystem: unit includes L2 L3 caches system bus, used access main memory L1 L2 caches cache miss access system I/O resources. Unlike organization used previous Pentium models, processors, Pentium 4 instruction cache sits instruction decode logic execution core. reasoning behind design decision follows: discussed fully Chapter 16, Pentium process decodes, translates, Pentium machine instructions simple RISC- like instructions called micro- operations. use simple, fixed- length micro- operations enables use superscalar pipelining scheduling techniques enhance performance. However, Pentium machine instructions cumbersome decode; variable number bytes many different options. turns perform - ance enhanced decoding done independently scheduling pipe - lining logic. return topic Chapter 16. data cache employs write- back policy: Data written main memory removed cache update. Pen - tium 4 processor dynamically configured support write- caching. L1 data cache controlled two bits one control registers, labe - led CD (cache disable) NW (not write- through) bits (Table 4.5). also two Pentium 4 instructions used control data cache: INVD invalidates (flushes) internal cache memory signals external cache (if any) invalidate. WBINVD writes back invalidates internal cache writes back invalidates external cache. L2 L3 caches eight- way set- associative line size 128 bytes. 4.5 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key TermsTable 4.5 Pentium 4 Cache Operating Modes Control Bits Operating Mode CD NW Cache Fills Write Throughs Invalidates 0 0 Enabled Enabled Enabled 1 0 Disabled Enabled Enabled 1 1 Disabled Disabled Disabled Note : CD=0; NW=1 invalid combination. access time associative mapping cache hitcache line cache memory cache misscache set data cache direct access4.5 / Key termS, review Que Stion S, problem 153 Review Questions 4.1 differences among sequential access, direct access, random access? 4.2 general relationship among access time, memory cost, capacity? 4.3 principle locality relate use multiple memory levels? 4.4 differences among direct mapping, associative mapping, set- associative mapping? 4.5 direct- mapped cache, main memory address viewed consisting three fields. List define three fields. 4.6 associative cache, main memory address viewed consisting two fields. List define two fields. 4.7 set- associative cache, main memory address viewed consisting three fields. List define three fields. 4.8 distinction spatial locality temporal locality? 4.9 general, strategies exploiting spatial locality temporal locality? Problems 4.1 set- associative cache consists 64 lines, slots, divided four- line sets. Main memory contains 4K blocks 128 words each. Show format main memory addresses. 4.2 two- way set- associative cache lines 16 bytes total size 8 kB. 64-MB main memory byte addressable. Show format main memory addresses. 4.3 hexadecimal main memory addresses 111111, 666666, BBBBBB, show following information, hexadecimal format: a. Tag, Line, Word values direct- mapped cache, using format Figure 4.10 b. Tag Word values associative cache, using format Figure 4.12 c. Tag, Set, Word values two- way set- associative cache, using format Figure 4.15 4.4 List following values: a. direct cache example Figure 4.10: address length, number addressable units, block size, number blocks main memory, number lines cache, size tag b. associative cache example Figure 4.12: address length, number addressable units, block size, number blocks main memory, number lines cache, size tagdirect mapping high- performance computing (HPC) hit hit ratio instruction cache L1 cache L2 cache L3 cache line localitylogical cache memory hierarchy miss multilevel cache physical address physical cache random access replacement algorithm secondary memory sequential access set- associative mappingspatial locality split cache tag temporal locality unified cache virtual address virtual cache write back write through154 CHApter 4 / C ACHe memory c. two- way set- associative cache example Figure 4.15: address length, num - ber addressable units, block size, number blocks main memory, number lines set, number sets, number lines cache, size tag 4.5 Consider 32-bit microprocessor on- chip 16-kB four- way set- associative cache. Assume cache line size four 32-bit words. Draw block dia - gram cache showing organization different address fields used determine cache hit/miss. cache word memory location ABCDE8F8 mapped? 4.6 Given following specifications external cache memory: four- way set asso - ciative; line size two 16-bit words; able accommodate total 4K 32-bit words main memory; used 16-bit processor issues 24-bit addresses. Design cache structure pertinent information show interprets pro - cessor’s addresses. 4.7 Intel 80486 on- chip, unified cache. contains 8 kB four- way set- associative organization block length four 32-bit words. cache orga - nized 128 sets. single “line valid bit” three bits, B0, B1, B2 (the “LRU” bits), per line. cache miss, 80486 reads 16-byte line main mem - ory bus memory read burst. Draw simplified diagram cache show different fields address interpreted. 4.8 Consider machine byte addressable main memory 216 bytes block size 8 bytes. Assume direct mapped cache consisting 32 lines used machine. a. 16-bit memory address divided tag, line number, byte number? b. line would bytes following addresses stored? 0001000100011011 1100001100110100 1101000000011101 1010101010101010 c. Suppose byte address 0001 1010 0001 1010 stored cache. addresses bytes stored along it? d. many total bytes memory stored cache? e. tag also stored cache? 4.9 on- chip cache, Intel 80486 uses replacement algorithm referred pseudo least recently used . Associated 128 sets four lines (labeled L0, L1, L2, L3) three bits B0, B1, B2. replacement algorithm works follows: line must replaced, cache first determine whether recent use L0 L1 L2 L3. cache determine pair blocks least recently used mark replacement. Figure 4.19 illustrates logic. a. Specify bits B0, B1, B2 set describe words used replacement algorithm depicted Figure 4.19. b. Show 80486 algorithm approximates true LRU algorithm. Hint: Con - sider case recent order usage L0, L2, L3, L1. c. Demonstrate true LRU algorithm would require 6 bits per set. 4.10 set- associative cache block size four 16-bit words set size 2. cache accommodate total 4096 words. main memory size cacheable 64K*32 bits. Design cache structure show processor’s addresses interpreted. 4.11 Consider memory system uses 32-bit address address byte level, plus cache uses 64-byte line size. a. Assume direct mapped cache tag field address 20 bits. Show address format determine following parameters: number addressable units, number blocks main memory, number lines cache, size tag.4.5 / Key termS, review Que Stion S, problem 155 b. Assume associative cache. Show address format determine follow - ing parameters: number addressable units, number blocks main memory, number lines cache, size tag. c. Assume four- way set- associative cache tag field address 9 bits. Show address format determine following parameters: number addressable units, number blocks main memory, number lines set, num - ber sets cache, number lines cache, size tag. 4.12 Consider computer following characteristics: total 1 MB main mem - ory; word size 1 byte; block size 16 bytes; cache size 64 kB. a. main memory addresses F0010, 01234, CABBE, give corre - sponding tag, cache line address, word offsets direct- mapped cache. b. Give two main memory addresses different tags map cache slot direct- mapped cache. c. main memory addresses F0010 CABBE, give corresponding tag offset values fully- associative cache. d. main memory addresses F0010 CABBE, give corresponding tag, cache set, offset values two- way set- associative cache. 4.13 Describe simple technique implementing LRU replacement algorithm four- way set- associative cache. 4.14 Consider Example 4.3. answer change main memory uses block transfer capability first- word access time 30 ns access time 5 ns word thereafter? 4.15 Consider following code: (i=0; i620; i++) (j=0; j610; j++) a[i]=a[i]*j a. Give one example spatial locality code. b. Give one example temporal locality code. 4.16 Generalize Equations (4.2) (4.3), Appendix 4A, N- level memory hierarchies. 4.17 computer system contains main memory 32K 16-bit words. also 4K word cache divided four- line sets 64 words per line. Assume cache initially empty. processor fetches words locations 0, 1, 2, . . . , 4351 four lines set valid? B0 = 0?Yes YesN oY es NoYes, L0 L1 least r ecently usedNo, L2 L3 least r ecently usedNo B1 = 0? Replace L0Replace L1Replace L2Replace L3B2 = 0?Replace nonvalid line Figure 4.19 Intel 80486 On- Chip Cache Replacement Strategy156 CHApter 4 / C ACHe memory order. repeats fetch sequence nine times. cache 10 times faster main memory. Estimate improvement resulting use cache. Assume LRU policy block replacement. 4.18 Consider cache 4 lines 16 bytes each. Main memory divided blocks 16 bytes each. is, block 0 bytes addresses 0 15, on. consider program accesses memory following sequence addresses: Once: 63 70. Loop ten times: 15 32; 80 95. a. Suppose cache organized direct mapped. Memory blocks 0, 4, assigned line 1; blocks 1, 5, line 2; on. Compute hit ratio. b. Suppose cache organized two- way set associative, two sets two lines each. Even- numbered blocks assigned set 0 odd- numbered blocks assigned set 1. Compute hit ratio two- way set- associative cache using least recently used replacement scheme. 4.19 Consider memory system following parameters: Tc=100 ns Cc=10-4 $/bit Tm=1200 ns Cm=10-5 $/bit a. cost 1 MB main memory? b. cost 1 MB main memory using cache memory technology? c. effective access time 10% greater cache access time, hit ratio H? 4.20 a. Consider L1 cache access time 1 ns hit ratio H=0.95. Sup - pose change cache design (size cache, cache organization) increase H 0.97 , increase access time 1.5 ns. conditions must met change result improved performance? d. Explain result makes intuitive sense. 4.21 Consider single- level cache access time 2.5 ns, line size 64 bytes, hit ratio H=0.95. Main memory uses block transfer capability first- word (4 bytes) access time 50 ns access time 5 ns word thereafter. a. access time cache miss? Assume cache waits line fetched main memory re- executes hit. b. Suppose increasing line size 128 bytes increases H 0.97 . reduce average memory access time? 4.22 computer cache, main memory, disk used virtual memory. ref - erenced word cache, 20 ns required access it. main memory cache, 60 ns needed load cache, refer - ence started again. word main memory, 12 ms required fetch word disk, followed 60 ns copy cache, reference started again. cache hit ratio 0.9 main memory hit ratio 0.6. average time nanoseconds required access referenced word system? 4.23 Consider cache line size 64 bytes. Assume average 30% lines cache dirty. word consists 8 bytes. a. Assume 3% miss rate (0.97 hit ratio). Compute amount main memory traffic, terms bytes per instruction write- write- back policies. Memory read cache one line time. However, write back, single word written cache main memory. b. Repeat part 5% rate. c. Repeat part 7% rate. d. conclusion draw results? 4.24 Motorola 68020 microprocessor, cache access takes two clock cycles. Data access main memory bus processor takes three clock cycles Appen Dix 4A 157 case wait state insertion; data delivered processor parallel delivery cache. a. Calculate effective length memory cycle given hit ratio 0.9 clocking rate 16.67 MHz. b. Repeat calculations assuming insertion two wait states one cycle per memory cycle. conclusion draw results? 4.25 Assume processor memory cycle time 300 ns instruction process - ing rate 1 MIPS. average, instruction requires one bus memory cycle instruction fetch one operand involves. a. Calculate utilization bus processor. b. Suppose processor equipped instruction cache associated hit ratio 0.5. Determine impact bus utilization. 4.26 performance single- level cache system read operation character - ized following equation: Ta=Tc+(1 -H)Tm Ta average access time, Tc cache access time, Tm memory access time (memory processor register), H hit ratio. simplicity, assume word question loaded cache parallel load processor register. form Equation (4.2). a. Define Tb=time transfer line cache main memory, W=fraction write references. Revise preceding equation account writes well reads, using write- policy. b. Define Wb probability line cache altered. Provide equation Ta write- back policy. 4.27 system two levels cache, define Tc1=first-level cache access time; Tc2=second-level cache access time; Tm=memory access time; H1=first-level cache hit ratio; H2=combined first/second level cache hit ratio. Provide equation Ta read operation. 4.28 Assume following performance characteristics cache read miss: one clock cycle send address main memory four clock cycles access 32-bit word main memory transfer processor cache. a. cache line size one word, miss penalty (i.e., additional time required read event read miss)? b. miss penalty cache line size four words multiple, non - burst transfer executed? c. miss penalty cache line size four words transfer exe - cuted, one clock cycle per word transfer? 4.29 cache design preceding problem, suppose increasing line size one word four words results decrease read miss rate 3.2% 1.1%. nonburst transfer burst transfer case, average miss penalty, averaged reads, two different line sizes? APPENDIX 4A PERFORMANCE CHARACTERISTICS TWO- LEVEL MEMORIES chapter, reference made cache acts buffer main mem - ory processor, creating two- level internal memory. two- level architecture exploits property known locality provide improved performance com - parable one- level memory.158 CHApter 4 / C ACHe memory main memory cache mechanism part computer architecture, implemented hardware typically invisible operating system. two instances two- level memory approach also exploit locality are, least partially, implemented operating system: virtual memory disk cache (Table 4.6). Virtual memory explored Chapter 8; disk cache beyond scope book examined [STAL15]. appendix, look performance characteristics two- level memories com - mon three approaches. Locality basis performance advantage two- level memory principle known locality reference [DENN68]. principle states memory references tend cluster. long period time, clusters use change, short period time, processor primarily working fixed clusters mem - ory references. Intuitively, principle locality makes sense. Consider following line reasoning: 1. Except branch call instructions, constitute small fraction program instructions, program execution sequential. Hence, cases, next instruction fetched immediately follows last instruction fetched. 2. rare long uninterrupted sequence procedure calls followed corresponding sequence returns. Rather, program remains con - fined rather narrow window procedure- invocation depth. Thus, short period time references instructions tend localized procedures. 3. iterative constructs consist relatively small number instructions repeated many times. duration iteration, computation - fore confined small contiguous portion program. 4. many programs, much computation involves processing data struc - tures, arrays sequences records. many cases, successive refer - ences data structures closely located data items. Table 4.6 Characteristics Two- Level Memories Main Memory CacheVirtual Memory (paging) Disk Cache Typical access time ratios5:1 (main memory vs. cache)106:1 (main memory vs. disk)106:1 (main memory vs. disk) Memory management systemImplemented special hardwareCombination hardware system softwareSystem software Typical block page size4 128 bytes (cache block)64 4096 bytes (virtual memory page)64 4096 bytes (disk block pages) Access processor second levelDirect access Indirect access Indirect accessAppen Dix 4A 159 line reasoning confirmed many studies. reference point 1, variety studies analyzed behavior high- level language pro - grams. Table 4.7 includes key results, measuring appearance various statement types execution, following studies. earliest study program - ming language behavior, performed Knuth [KNUT71], examined collection FORTRAN programs used student exercises. Tanenbaum [TANE78] published measurements collected 300 procedures used operating- system pro - grams written language supports structured programming (SAL). Pat - terson Sequein [PATT82a] analyzed set measurements taken compilers programs typesetting, computer- aided design (CAD), sorting, file com - parison. programming languages C Pascal studied. Huck [HUCK83] analyzed four programs intended represent mix general- purpose scientific computing, including fast Fourier transform integration systems differ - ential equations. good agreement results mixture languages applications branching call instructions represent fraction statements executed lifetime program. Thus, studies confirm assertion 1. respect assertion 2, studies reported [PATT85a] provide confirma - tion. illustrated Figure 4.20, shows call- return behavior. call represented line moving right, return line moving right. figure, window depth equal 5 defined. sequence calls returns net movement 6 either direction causes window move. seen, executing program remain within stationary window long periods time. study analysts C Pascal programs showed window depth 8 need shift less 1% calls returns [TAMI83]. distinction made literature spatial locality temporal locality. Spatial locality refers tendency execution involve number memory locations clustered. reflects tendency processor access instructions sequentially. Spatial location also reflects tendency pro - gram access data locations sequentially, processing table data. Temporal locality refers tendency processor access memory locations used recently. example, iteration loop executed, processor executes set instructions repeatedly.Table 4.7 Relative Dynamic Frequency High- Level Language Operations Study Language Workload[HUCK83] Pascal Scientific[KNUT71] FORTRAN Student[PATT82a] Pascal C System System[TANE78] SAL System Assign 74 67 45 38 42 Loop 4 3 5 3 4 Call 1 3 15 12 12 20 11 29 43 36 GOTO 2 9 — 3 — — 7 6 1 6160 CHApter 4 / C ACHe memory Traditionally, temporal locality exploited keeping recently used instruction data values cache memory exploiting cache hierarchy. Spatial locality generally exploited using larger cache blocks incor - porating prefetching mechanisms (fetching items anticipated use) cache control logic. Recently, considerable research refining techniques achieve greater performance, basic strategies remain same. Operation Two- Level Memory locality property exploited formation two- level memory. upper- level memory (M1) smaller, faster, expensive (per bit) lower- level memory (M2). M1 used temporary store part contents larger M2. memory reference made, attempt made access item M1. succeeds, quick access made. not, block memory locations copied M2 M1 access takes place via M1. locality, block brought M1, number accesses locations block, resulting fast overall service. express average time access item, must consider speeds two levels memory, also probability given reference found M1. Ts=H*T1+(1 -H)*(T1+T2) =T1+(1 -H)*T2 (4.2) Ts=average (system) access time T1=access time M1 (e.g., cache, disk cache) T2=access time M2 (e.g., main memory, disk) H=hit ratio (fraction time reference found M1)w = 5t = 33Time (in units calls/r eturns) Nesting depthRetur n Call Figure 4.20 Example Call- Return Behavior ProgramAppen Dix 4A 161 Figure 4.2 shows average access time function hit ratio. seen, high percentage hits, average total access time much closer M1 M2. Performance Let us look parameters relevant assessment two- level mem - ory mechanism. First consider cost. Cs=C1S1+C2S2 S1+S2 (4.3) Cs=average cost per bit combined two@level memory C1=average cost per bit upper@level memory M1 C2=average cost per bit lower@level memory M2 S1=size M1 S2=size M2 would like Cs≈C2. Given C1WC2, requires S16S2. Figure 4.21 shows relationship. 23 45 67 89100 Relative size two le vels (S2/S1)Relative combined cost (Cs/C2)(C1/C2) = 1000 (C1/C2) = 100 (C1/C2) = 10 23 45 67 89100056 78 9101000 100 10 187 6 5 4 3 2 87 6 5 4 3 2 87 6 5 4 3 2 Figure 4.21 Relationship Average Memory Cost Relative Memory Size Two- Level Memory162 CHApter 4 / C ACHe memory Next, consider access time. two- level memory provide significant performance improvement, need Ts approximately equal T1(Ts≈T1). Given T1 much less T2(T166T2), hit ratio close 1 needed. would like M1 small hold cost, large improve hit ratio therefore performance. size M1 satisfies requirements reasonable extent? answer question series subquestions: ■What value hit ratio needed Ts≈T1? ■What size M1 assure needed hit ratio? ■Does size satisfy cost requirement? get this, consider quantity T1/Ts, referred access effi - ciency. measure close average access time (Ts) M1 access time (T1). Equation (4.2), T1 Ts=1 1+(1-H) T2 T1 (4.4) Figure 4.22 plots T1/Ts function hit ratio H, quantity T2/T1 parameter. Typically, on- chip cache access time 25 50 times faster main memory access time (i.e., T2/T1 25 50), off- chip cache access time Access ef/f_iciency = T1/Ts 0.0 0.2 0.4 0.6 0.8 1.0 Hit ratio = H1 0.1 0.01 0.001r = 10r = 1 r = 100 r = 1000 Figure 4.22 Access Efficiency Function Hit Ratio (r=T2/T1)Appen Dix 4A 163 5 15 times faster main memory access time (i.e., T2/T1 5 15), main memory access time 1000 times faster disk access time (T2/T1=1000). Thus, hit ratio range near 0.9 would seem needed satisfy performance requirement. phrase question relative memory size exactly. hit ratio of, say, 0.8 better reasonable S166S2? depend number factors, including nature software executed details design two- level memory. main determinant is, course, degree locality. Figure 4.23 suggests effect locality hit ratio. Clearly, M1 size M2, hit ratio 1.0: items M2 always also stored M1. suppose locality; is, references completely random. case hit ratio strictly linear function relative memory size. example, M1 half size M2, time half items M2 also M1 hit ratio 0.5. practice, however, degree locality references. effects moderate strong locality indicated figure. Note Figure 4.23 derived specific data model; figure suggests type performance seen various degrees locality. strong locality, possible achieve high values hit ratio even relatively small upper- level memory size. example, numerous studies shown rather small cache sizes yield hit ratio 0.75 regardless size main memory (e.g., [AGAR89], [PRZY88], [STRE83], [SMIT82]). cache range 1K 128K words generally adequate, whereas main localityModerate localityStrong localityHit ratio Relative memory size (S1/S2)0.00.00.20.40.60.81.0 0.2 0.4 0.6 0.8 1.0 Figure 4.23 Hit Ratio Function Relative Memory Size164 CHApter 4 / C ACHe memory memory typically gigabyte range. consider virtual memory disk cache, cite studies confirm phenomenon, namely relatively small M1 yields high value hit ratio locality. brings us last question listed earlier: relative size two memories satisfy cost requirement? answer clearly yes. need relatively small upper- level memory achieve good performance, average cost per bit two levels memory approach cheaper lower- level memory. Please note L2 cache, even L2 L3 caches, involved, analysis much complex. See [PEIR99] [HAND98] discussions.165 Chapter Internal MeMory 5.1 Semiconductor Main Memory Organization DRAM SRAM Types ROM Chip Logic Chip Packaging Module Organization Interleaved Memory 5.2 Error Correction 5.3 DDR DRAM Synchronous DRAM DDR SDRAM 5.4 Flash Memory Operation NAND Flash Memory 5.5 Newer Nonvolatile Solid-State Memory Technologies STT-RAM PCRAM ReRAM 5.6 Key Terms, Review Questions, Problems 166 Chapter 5 / Internal Mory begin chapter survey semiconductor main memory subsystems, including ROM, DRAM, SRAM memories. look error control tech - niques used enhance memory reliability. Following this, look advanced DRAM architectures. 5.1 Semiconductor main memory earlier computers, common form random-access storage computer main memory employed array doughnut-shaped ferromagnetic loops referred cores . Hence, main memory often referred core, term persists day. advent of, advantages of, microelectronics long since vanquished magnetic core memory. Today, use semiconductor chips main memory almost universal. Key aspects technology explored section. Organization basic element semiconductor memory memory cell. Although vari - ety electronic technologies used, semiconductor memory cells share certain properties: ■They exhibit two stable (or semistable) states, used represent binary 1 0. ■They capable written (at least once), set state. ■They capable read sense state. Figure 5.1 depicts operation memory cell. commonly, cell three functional terminals capable carrying electrical signal. select ter - minal, name suggests, selects memory cell read write operation. control terminal indicates read write. writing, terminal provides electrical signal sets state cell 1 0. reading, terminal used output cell’s state. details internal organization, function - ing, timing memory cell depend specific integrated circuit tech - nology used beyond scope book, except brief summary. purposes, take given individual cells selected reading writing operations.Learning Objectives studying chapter, able to: rPresent overview principle types semiconductor main memory. rUnderstand operation basic code detect correct single-bit errors 8-bit words. rSummarize properties contemporary DDR DRAM organizations. rUnderstand difference NAND flash memory. rPresent overview newer nonvolatile solid-state memory technologies.5.1 / Se MICondu Ctor Mory 167 DRAM SRAM memory types explore chapter random access. is, individual words memory directly accessed wired-in addressing logic. Table 5.1 lists major types semiconductor memory. common referred random-access memory (RAM) . is, fact, misuse term, types listed table random access. One distinguishing characteristic memory designated RAM possible read data memory write new data memory easily rapidly. reading writing accomplished use electrical signals. distinguishing characteristic traditional RAM volatile. RAM must provided constant power supply. power interrupted, data lost. Thus, RAM used temporary storage. two traditional forms RAM used computers DRAM SRAM. Newer forms RAM, discussed Section 5.5, nonvolatile. dynamic ram RAM technology divided two technologies: dynamic static. dynamic RAM (DRAM) made cells store data charge capacitors. presence absence charge capacitor interpreted binary 1 0. capacitors natural tendency discharge, dynamic RAMs require periodic charge refreshing maintain data storage. term CellSelect Data inContr ol (a) WriteCellSelect SenseContr ol (b) Read Figure 5.1 Memory Cell Operation Table 5.1 Semiconductor Memory Types Memory Type Category ErasureWrite Mechanism Volatility Random-access memory (RAM)Read-write memoryElectrically, byte-levelElectrically Volatile Read-only memory (ROM) Read-only memoryNot possibleMasks NonvolatileProgrammable ROM (PROM) ElectricallyErasable PROM (EPROM)UV light, chip-level Electrically Erasable PROM (EEPROM)Read-mostly memoryElectrically, byte-level Flash memoryElectrically, block-level168 Chapter 5 / Internal Mory dynamic refers tendency stored charge leak away, even power continuously applied. Figure 5.2a typical DRAM structure individual cell stores one bit. address line activated bit value cell read written. transistor acts switch closed (allowing current flow) voltage applied address line open (no current flows) voltage present address line. write operation, voltage signal applied bit line; high volt - age represents 1, low voltage represents 0. signal applied address line, allowing charge transferred capacitor. read operation, address line selected, transistor turns charge stored capacitor fed onto bit line sense amplifier. sense amplifier compares capacitor voltage reference value determines cell contains logic 1 logic 0. readout cell discharges capacitor, must restored complete operation. Although DRAM cell used store single bit (0 1), essentially analog device. capacitor store charge value within range; thresh - old value determines whether charge interpreted 1 0. static ram contrast, static RAM (SRAM) digital device uses logic elements used processor. SRAM, binary values stored using traditional flip-flop logic-gate configurations (see Chapter 11 description flip-flops). static RAM hold data long power supplied it. Figure 5.2b typical SRAM structure individual cell. Four transistors (T1, T2, T3, T4) cross connected arrangement produces stable logic Bit line BAddr ess line Grounddc voltage Addr ess line (b) Static RAM (SRAM) cell (a) ynamic RAM (DRAM) cellBit line BT5 T6T3 T4 T1 T2C1 C2 Bit line BTransistor GroundStorage capacitor Figure 5.2 Typical Memory Cell Structures5.1 / Se MICondu Ctor Mory 169 state. logic state 1, point C1 high point C2 low; state, T1 T4 T2 T3 on.1 logic state 0, point C1 low point C2 high; state, T1 T4 T2 T3 off. states stable long direct current (dc) voltage applied. Unlike DRAM, refresh needed retain data. DRAM, SRAM address line used open close switch. address line controls two transistors ( T5 T6). signal applied line, two transistors switched on, allowing read write operation. write operation, desired bit value applied line B, complement applied line B. forces four transistors (T1, T2, T3, T4) proper state. read operation, bit value read line B. sram versus dram static dynamic RAMs volatile; is, power must continuously supplied memory preserve bit values. dynamic memory cell simpler smaller static memory cell. Thus, DRAM dense (smaller cells = cells per unit area) less expensive corresponding SRAM. hand, DRAM requires supporting refresh circuitry. larger memories, fixed cost refresh circuitry compensated smaller variable cost DRAM cells. Thus, DRAMs tend favored large memory requirements. final point SRAMs somewhat faster DRAMs. relative characteristics, SRAM used cache memory (both chip), DRAM used main memory. Types ROM name suggests, read-only memory (ROM) contains permanent pattern data cannot changed. ROM nonvolatile; is, power source required maintain bit values memory. possible read ROM, possible write new data it. important application ROMs micro - programming, discussed Part Four. potential applications include ■Library subroutines frequently wanted functions ■System programs ■Function tables modest-sized requirement, advantage ROM data program permanently main memory need never loaded secondary storage device. ROM created like integrated circuit chip, data actually wired chip part fabrication process. presents two problems: ■The data insertion step includes relatively large fixed cost, whether one thousands copies particular ROM fabricated. ■There room error. one bit wrong, whole batch ROMs must thrown out. small number ROMs particular memory content needed, less expensive alternative programmable ROM (PROM) . Like 1The circles associated T3 T4 Figure 5.2b indicate signal negation.170 Chapter 5 / Internal Mory ROM, PROM nonvolatile may written once. PROM, writing process performed electrically may performed supplier customer time later original chip fabrication. Special equipment required writing “programming” process. PROMs provide flexibility convenience. ROM remains attractive high-volume production runs. Another variation read-only memory read-mostly memory , useful applications read operations far frequent write operations nonvolatile storage required. three common forms read-mostly memory: EPROM, EEPROM, flash memory. optically erasable programmable read-only memory (EPROM) read written electrically, PROM. However, write operation, stor - age cells must erased initial state exposure packaged chip ultraviolet radiation. Erasure performed shining intense ultraviolet light window designed memory chip. erasure process performed repeatedly; erasure take much 20 minutes perform. Thus, EPROM altered multiple times and, like ROM PROM, holds data virtually indefinitely. comparable amounts storage, EPROM expensive PROM, advantage multiple update capability. attractive form read-mostly memory electrically erasable programmable read-only memory (EEPROM) . read-mostly memory written time without erasing prior contents; byte bytes addressed updated. write operation takes considerably longer read operation, order several hundred microseconds per byte. EEPROM combines advantage nonvolatility flexibility updatable place, using ordinary bus control, address, data lines. EEPROM expen - sive EPROM also less dense, supporting fewer bits per chip. Another form semiconductor memory flash memory (so named speed reprogrammed). First introduced mid-1980s, flash memory intermediate EPROM EEPROM cost functional - ity. Like EEPROM, flash memory uses electrical erasing technology. entire flash memory erased one seconds, much faster EPROM. addition, possible erase blocks memory rather entire chip. Flash memory gets name microchip organized section memory cells erased single action “flash.” However, flash memory provide byte-level erasure. Like EPROM, flash memory uses one transistor per bit, achieves high density (compared EEPROM) EPROM. Chip Logic integrated circuit products, semiconductor memory comes pack - aged chips (Figure 1.11). chip contains array memory cells. memory hierarchy whole, saw trade-offs among speed, density, cost. trade-offs also exist consider organiza - tion memory cells functional logic chip. semiconductor memories, one key design issues number bits data may read/written time. one extreme organization physical arrangement cells array logical arrangement (as perceived pro - cessor) words memory. array organized W words B bits each. 5.1 / Se MICondu Ctor Mory 171 example, 16-Mbit chip could organized 1M 16-bit words. extreme so-called 1-bit-per-chip organization, data read/written one bit time. illustrate memory chip organization DRAM; ROM organization similar, though simpler. Figure 5.3 shows typical organization 16-Mbit DRAM. case, 4 bits read written time. Logically, memory array organized four square arrays 2048 2048 elements. Various physical arrangements possible. case, elements array connected horizontal (row) vertical (column) lines. horizontal line connects Select terminal cell row; vertical line connects Data-In/Sense terminal cell column. Address lines supply address word selected. total log2 W lines needed. example, 11 address lines needed select one 2048 rows. 11 lines fed row decoder, 11 lines input 2048 lines output. logic decoder activates single one 2048 outputs depending bit pattern 11 input lines (211=2048). additional 11 address lines select one 2048 columns 4 bits per column. Four data lines used input output 4 bits data buffer. input (write), bit driver bit line activated 1 0 according value corresponding data line. output (read), value bit line passed sense amplifier presented data lines. row line selects row cells used reading writing. Column decoderRefresh circuitryMemory array (2048 * 2048 * 4)Row de- coderA0 A1 A10Row address buffer Column address bufferTiming controlRASCASWE OE MUXRefresh counter Data input buffer Data output bufferD1D2D3D4 Figure 5.3 Typical 16-Mbit DRAM (4M*4)172 Chapter 5 / Internal Mory 4 bits read/written DRAM, must multiple DRAMs connected memory controller read/write word data bus. Note 11 address lines (A0–A10), half number would expect 2048*2048 array. done save number pins. 22 required address lines passed select logic external chip multiplexed onto 11 address lines. First, 11 address signals passed chip define row address array, 11 address signals presented column address. signals accompanied row address select (RAS) column address select (CAS) signals provide timing chip. write enable (WE) output enable (OE) pins determine whether write read operation performed. Two pins, shown Figure 5.3, ground (Vss) voltage source (Vcc). aside, multiplexed addressing plus use square arrays result quadrupling memory size new generation memory chips. One pin devoted addressing doubles number rows columns, size chip memory grows factor 4. Figure 5.3 also indicates inclusion refresh circuitry. DRAMs require refresh operation. simple technique refreshing is, effect, disable DRAM chip data cells refreshed. refresh counter steps row values. row, output lines refresh counter sup - plied row decoder RAS line activated. data read written back location. causes cell row refreshed. Chip Packaging mentioned Chapter 2, integrated circuit mounted package contains pins connection outside world. Figure 5.4a shows example EPROM package, 8-Mbit chip organized 1M*8. case, organization treated one-word-per- chip package. package includes 32 pins, one standard chip pack - age sizes. pins support following signal lines: ■The address word accessed. 1M words, total 20 (220=1M) pins needed (A0–A19). ■The data read out, consisting 8 lines (D0–D7). ■The power supply chip (Vcc). ■A ground pin (Vss). ■A chip enable (CE) pin. may one memory chip, connected address bus, CE pin used indi - cate whether address valid chip. CE pin activated logic connected higher-order bits address bus (i.e., address bits A19). use signal illustrated presently. ■A program voltage (Vpp) supplied programming (write operations). typical DRAM pin configuration shown Figure 5.4b, 16-Mbit chip organized 4M*4. several differences ROM chip. RAM updated, data pins input/output. write enable (WE) output enable (OE) pins indicate whether write read operation. 5.1 / Se MICondu Ctor Mory 173 DRAM accessed row column, address multi - plexed, 11 address pins needed specify 4M row/column combinations (211*211=222=4M). functions row address select (RAS) col - umn address select (CAS) pins discussed previously. Finally, connect (NC) pin provided even number pins. Module Organization RAM chip contains one bit per word, clearly need least number chips equal number bits per word. example, Figure 5.5 shows memory module consisting 256K 8-bit words could organized. 256K words, 18-bit address needed supplied module external source (e.g., address lines bus module attached). address presented 8 256K*1@bit chips, provides input/output one bit. organization works long size memory equals number bits per chip. case larger memory required, array chips needed. Figure 5.6 shows possible organization memory consisting 1M word 8 bits per word. case, four columns chips, column containing 256K words arranged Figure 5.5. 1M word, 20 address lines needed. 18 least significant bits routed 32 modules. high-order 2 bits input group select logic module sends chip enable signal one four columns modules. Interleaved Memory Main memory composed collection DRAM memory chips. number chips grouped together form memory bank . possible organize memory 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 171 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16A19 A16 A15 A12 A7 A6 A5 A4 A3 A2 A1 A0 D0 D1 D2 VssVcc A18 A17 A14 A13 A8 A9 A11 Vpp A10 CE D7 D6 D5 D4 D332-Pin Dip 0.6" Top View24 23 22 21 20 19 18 17 16 15 14 131 2 3 4 5 6 7 8 9 10 11 12Vcc D0 D1 RAS NC A10 A0 A1 A2 A3 VccVss D3 D2 CAS OE A9 A8 A7 A6 A5 A4 Vss (a) 8-Mbit EPR OM (b) 16-Mbit DRAM24-Pin Dip 0.6" Top View Figure 5.4 Typical Memory Package Pins Signals174 Chapter 5 / Internal Mory banks way known interleaved memory. bank independently able ser - vice memory read write request, system K banks service K requests simultaneously, increasing memory read write rates factor K. con - secutive words memory stored different banks, transfer block memory speeded up. Appendix G explores topic interleaved memory. 5.2 error correction semiconductor memory system subject errors. categorized hard failures soft errors. hard failure permanent physical defect memory cell cells affected cannot reliably store data become stuck 0 1 512 words 512 bits Chip #1 Memory b uffer register (MBR)Memory addr ess register (MAR) Decode 1 512 bit-senseDecode 1 512 512 words 512 bits Chip #8 Decode 1 512 bit-senseDecode 1 51219 92 3 4 5 6 7 8• • •• • • • • • Figure 5.5 256-KByte Memory Organization Interleaved Memory Simulator5.2 / error Corre CtIon 175 switch erratically 0 1. Hard errors caused harsh environmen - tal abuse, manufacturing defects, wear. soft error random, nondestructive event alters contents one memory cells without damaging memory. Soft errors caused power supply problems alpha particles. particles result radioactive decay distressingly common radioactive nuclei found small quantities nearly materials. hard soft errors clearly undesirable, modern main memory systems include logic detecting correcting errors. Figure 5.7 illustrates general terms process carried out. data written memory, calculation, depicted function f, per - formed data produce code. code data stored. Thus, M-bit word data stored code length K bits, actual size stored word M+K bits. previously stored word read out, code used detect possibly correct errors. new set K code bits generated data bits compared fetched code bits. comparison yields one three results: ■No errors detected. fetched data bits sent out. ■An error detected, possible correct error. data bits plus error correction bits fed corrector, produces corrected set bits sent out. ■An error detected, possible correct it. condition reported. Codes operate fashion referred error-correcting codes . code characterized number bit errors word correct detect. 1/512 1/512A1 1/512 1/512B1 C1 D11/512 1/512A81/512 1/512B8 C8 D81 2 7 8E EBit 1 chips 512 words 512 bits. 2-terminal cellsEE E A2 A7 E Bit 8EE E29 9 B7B2 C7 D7Memory buffer register (MBR)Memory addr ess register (MAR) Chip group enable Select 1 4 groupsAGroup B C Figure 5.6 1 -MB Memory Organization176 Chapter 5 / Internal Mory simplest error-correcting codes Hamming code devised Richard Hamming Bell Laboratories. Figure 5.8 uses Venn diagrams illus - trate use code 4-bit words (M=4). three intersecting circles, seven compartments. assign 4 data bits inner compartments ( Figure 5.8a). remaining compartments filled called parity bits. parity bit chosen total number 1s circle even ( Figure 5.8b). Thus, circle includes three data 1s, parity bit circle set 1. Now, error changes one data bits (Figure 5.8c), eas - ily found. checking parity bits, discrepancies found circle circle C circle B. one seven compartments C B (Figure 5.8d). error therefore corrected changing bit. clarify concepts involved, develop code detect correct single-bit errors 8-bit words. start, let us determine long code must be. Referring Figure 5.7, comparison logic receives input two K-bit values. bit-by-bit comparison done taking exclusive-OR two inputs. result called syn- drome word. Thus, bit syndrome 0 1 according match bit position two inputs. syndrome word therefore K bits wide range 0 2K-1. value 0 indicates error detected, leaving 2K-1 values indi - cate, error, bit error. Now, error could occur data bits K check bits, must 2K-1ÚM+K inequality gives number bits needed correct single bit error word containing data bits. example, word 8 data bits (M=8), ■K=3: 23-168+3 ■K=4: 24-178+4ff CompareCorrector MemoryData inData outError signal KM KK Figure 5.7 Error-Correcting Code Function5.2 / error Corre CtIon 177 Thus, eight data bits require four check bits. first three columns Table 5.2 lists number check bits required various data word lengths. convenience, would like generate 4-bit syndrome 8-bit data word following characteristics: ■If syndrome contains 0s, error detected. ■If syndrome contains one one bit set 1, error occurred one 4 check bits. correction needed. ■If syndrome contains one bit set 1, numerical value syndrome indicates position data bit error. data bit inverted correction. achieve characteristics, data check bits arranged 12-bit word depicted Figure 5.9. bit positions numbered 1 12. bit positions whose position numbers powers 2 designated check 1 1 0 1A (a) 1 1 000 1 1 1 1 000 1 0(b) 1 1 000 1 0(d) (c)B C Figure 5.8 Hamming Error-Correcting Code178 Chapter 5 / Internal Mory bits. check bits calculated follows, symbol ⊕ designates exclusive-OR operation: C1=D1⊕D2⊕ D4⊕D5⊕ D7 C2=D1⊕ D3⊕D4⊕ D6⊕D7 C4= D2⊕D3⊕D4 ⊕ D8 C8= ⊕D5⊕D6⊕D7⊕D8 check bit operates every data bit whose position number contains 1 bit position position number check bit. Thus, data bit pos - itions 3, 5, 7, 9, 11 (D1, D2, D4, D5, D7) contain 1 least significant bit position number C1; bit positions 3, 6, 7, 10, 11 contain 1 second bit position, C2; on. Looked another way, bit position n checked bits Ci ai=n. example, position 7 checked bits position 4, 2, 1; 7=4+2+1. Let us verify scheme works example. Assume 8-bit input word 00111001, data bit D1 rightmost position. calculations follows: C1=1⊕0⊕1⊕1⊕0=1 C2=1⊕0⊕1⊕1⊕0=1 C4=0⊕0⊕1⊕0=1 C8=1⊕1⊕0⊕0=0 Bit position12 1100 D8Position number Data bit Check bit11 1011 D710 1010 D69 1001 D5 C88 10007 0111 D46 0110 D35 0101 D24 01003 0011 D12 00101 0001 C4 C2 C1 Figure 5.9 Layout Data Bits Check BitsTable 5.2 Increase Word Length Error Correction Single-Error CorrectionSingle-Error Correction/ Double-Error Detection Data Bits Check Bits % Increase Check Bits % Increase 8 4 50.0 5 62.5 16 5 31.25 6 37.5 32 6 18.75 7 21.875 64 7 10.94 8 12.5 128 8 6.25 9 7.03 256 9 3.52 10 3.915.2 / error Corre CtIon 179 Suppose data bit 3 sustains error changed 0 1. check bits recalculated, C1=1⊕0⊕1⊕1⊕0=1 C2=1⊕1⊕1⊕1⊕0=0 C4=0⊕1⊕1⊕0=0 C8=1⊕1⊕0⊕0=0 new check bits compared old check bits, syndrome word formed: C8 C4 C2 C1 0 1 1 1 ⊕0 0 0 1 0 1 1 0 result 0110, indicating bit position 6, contains data bit 3, error. Figure 5.10 illustrates preceding calculation. data check bits positioned properly 12-bit word. Four data bits value 1 (shaded table), bit position values XORed produce Hamming code 0111, forms four check digits. entire block stored 001101001111. Suppose data bit 3, bit position 6, sustains error changed 0 1. resulting block 001101101111, Hamming code 0001. XOR Hamming code bit position values nonzero data bits results 0110. nonzero result detects error indicates error bit position 6. code described known single-error-correcting (SEC) code . commonly, semiconductor memory equipped single-error-correcting, double-error-detecting (SEC-DED) code . Table 5.2 shows, codes require one additional bit compared SEC codes. Figure 5.11 illustrates code works, 4-bit data word. sequence shows two errors occur (Figure 5.11c), checking procedure goes astray (d) worsens problem creating third error (e). overcome Bit position12 1100 D8Position number Data bit Check bit11 1011 D710 1010 D69 1001 D5 C88 10007 0111 D46 0110 D35 0101 D24 01003 0011 D12 00101 0001 C4 C2 C1 Word stored as0 0 1100Word fetched Position number Check bit0 0 10111 1 10101 1 1001 00 0 10001 1 01110 1 01100 0 01011 1 01001 1 00111 1 00101 1 0001 00 1 Figure 5.10 Check Bit Calculation180 Chapter 5 / Internal Mory problem, eighth bit added set total number 1s diagram even. extra parity bit catches error (f). error-correcting code enhances reliability memory cost added complexity. 1-bit-per-chip organization, SEC-DED code gen - erally considered adequate. example, IBM 30xx implementations used 8-bit SEC-DED code 64 bits data main memory. Thus, size main memory actually 12% larger apparent user. VAX computers used 7-bit SEC-DED 32 bits memory, 22% overhead. Contemporary DRAM systems may anywhere 7% 20% overhead [SHAR03]. 5.3 ddr dram discussed Chapter 1, one critical system bottlenecks using high-performance processors interface internal main memory. inter - face important pathway entire computer system. basic building block main memory remains DRAM chip, decades; recently, significant changes DRAM architecture since early 1970s. traditional DRAM chip constrained internal architecture interface processor’s memory bus. seen one attack performance problem DRAM main memory insert one levels high-speed SRAM cache DRAM main memory processor. SRAM much costlier DRAM, expanding cache size beyond certain point yields diminishing returns. recent years, number enhancements basic DRAM architecture explored. schemes currently dominate market SDRAM DDR-DRAM. examine turn.0 1 0 1(a) 0 0 001 1 1(c) 1 0 0 001 1 1(d) 10 0 011 1 1(e) 10 0 011 1 1(f) 10 1 001 0 1(b) 1 Figure 5.11 Hamming SEC-DEC Code5.3 / ddr draM 181 Synchronous DRAM One widely used forms DRAM synchronous DRAM (SDRAM) . Unlike traditional DRAM, asynchronous, SDRAM exchanges data processor synchronized external clock signal running full speed processor/memory bus without imposing wait states. typical DRAM, processor presents addresses control levels memory, indicating set data particular location memory either read written DRAM. delay, access time, DRAM either writes reads data. access-time delay, DRAM performs various internal functions, activating high capacitance row column lines, sensing data, routing data output buff - ers. processor must simply wait delay, slowing system performance. synchronous access, DRAM moves data control system clock. processor master issues instruction address information, latched DRAM. DRAM responds set number clock cycles. Meanwhile, master safely tasks SDRAM processing request. Figure 5.12 shows internal logic typical 256-Mb SDRAM typical SDRAM organization, Table 5.3 defines various pin assignments. Column address latc h Column decoderMod e register Multiple xer Row decoderRefresh controllerData buffe r Data ou buffe rSelf- refresh controller Refresh counte r Row address buffe r Bank contro l logic Column address bufferCommand decoder & clock generator Burst counte r8192 512 (x 16)819281928192A10 A12 A11 A9 A8 A7CLK CKE CS RAS CAS A6 A5 A4 A3 A2 A1 A0 BA0 BA11313 13 91616 1616DQML DQMH DQ 0-15 13Memor cell array (4 Mb x 16) DRAM BANK 0 Sense ampsRow address latch Figure 5.12 256-Mb Synchronous Dynamic RAM (SDRAM)182 Chapter 5 / Internal Mory SDRAM employs burst mode eliminate address setup time row column line precharge time first access. burst mode, series data bits clocked rapidly first bit accessed. mode useful bits accessed sequence row array initial access. addition, SDRAM multiple-bank internal architecture improves opportunities on-chip parallelism. mode register associated control logic another key feature differen - tiating SDRAMs conventional DRAMs. provides mechanism custom - ize SDRAM suit specific system needs. mode register specifies burst length, number separate units data synchronously fed onto bus. register also allows programmer adjust latency receipt read request beginning data transfer. SDRAM performs best transferring large blocks data sequen - tially, applications like word processing, spreadsheets, multimedia. Figure 5.13 shows example SDRAM operation. case, burst length 4 latency 2. burst read command initiated CS CAS low holding RAS high rising edge clock. address inputs determine starting column address burst, mode register sets type burst (sequential interleave) burst length (1, 2, 4, 8, full page). delay start command data first cell appears outputs equal value CAS latency set mode register.Table 5.3 SDRAM Pin Assignments A0 A13 Address inputs BA0, BA1 Bank address lines CLK Clock input CKE Clock enable CS Chip select RAS Row address strobe CAS Column address strobe Write enable DQ0 DQ7 Data input/output DQM Data mask T0 CLK COMMAND DQsT1 T2 T3 T4 T5 T6 T7 T8 DOUT A0NOP NOP NOP NOP NOP NOP NOP NOP DOUT A1DOUT A2DOUT A3READ Figure 5.13 SDRAM Read Timing (burst length=4, CAS latency=2)5.3 / ddr draM 183 DDR SDRAM Although SDRAM significant improvement asynchronous RAM, still shortcomings unnecessarily limit I/O data rate achieved. address shortcomings newer version SDRAM, referred double- data-rate DRAM (DDR DRAM) provides several features dramatically increase data rate. DDR DRAM developed JEDEC Solid State Tech - nology Association, Electronic Industries Alliance’s semiconductor-engineering- standardization body. Numerous companies make DDR chips, widely used desktop computers servers. DDR achieves higher data rates three ways. First, data transfer syn - chronized rising falling edge clock, rather rising edge. doubles data rate; hence term double data rate . Second, DDR uses higher clock rate bus increase transfer rate. Third, buffering scheme used, explained subsequently. JEDEC thus far defined four generations DDR technology (Table 5.4). initial DDR version makes use 2-bit prefetch buffer. prefetch buffer memory cache located SDRAM chip. enables SDRAM chip pre - position bits placed data bus rapidly possible. DDR I/O bus uses clock rate memory chip, handle two bits per cycle, achieves data rate double clock rate. 2-bit prefetch buffer enables SDRAM chip keep I/O bus. understand operation prefetch buffer, need look point view word transfer. prefetch buffer size determines many words data fetched (across multiple SDRAM chips) every time column com - mand performed DDR memories. core DRAM much slower interface, difference bridged accessing information par - allel serializing interface multiplexor (MUX). Thus, DDR prefetches two words, means every time read write operation performed, performed two words data, bursts of, into, SDRAM one clock cycle clock edges total two consecutive operations. result, DDR I/O interface twice fast SDRAM core. Although new generation SDRAM results much greater capacity, core speed SDRAM changed significantly generation generation. achieve greater data rates afforded rather modest increases SDRAM clock rate, JEDEC increased buffer size. DDR2, 4-bit buffer used, allowing words transferred parallel, increasing effective data rate factor 4. DDR3, 8-bit buffer used factor 8 speedup achieved (Figure 5.14). Table 5.4 DDR Characteristics DDR1 DDR2 DDR3 DDR4 Prefetch buffer (bits) 2 4 8 8 Voltage level (V) 2.5 1.8 1.5 1.2 Front side bus data rates (Mbps) 200—400 400—1066 800—2133 2133—4266184 Chapter 5 / Internal Mory downside prefetch effectively determines minimum burst length SDRAMs. example, difficult efficient burst length four words DDR3’s prefetch eight. Accordingly, JEDEC designers chose increase buffer size 16 bits DDR4, rather introduce concept bank group [ALLA13]. Bank groups separate enti - ties allow column cycle complete within bank group, column cycle impact happening another bank group. Thus, two prefetches eight operating parallel two bank groups. arrangement keeps prefetch buffer size DDR3, increasing performance prefetch larger. Figure 5.14 shows configuration two bank groups. DDR4, 4 bank groups used.Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz)Memory array (100–150 MHz) I/O (100–150 MHz) 100–150 MbpsSDRAM 1N Memory array (100–200 MHz) Memory array (100–200 MHz)I/O (100–200 MHz) 200–400 MbpsDDR 2N MUX Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz)I/O (200–533 MHz) 400–1066 MbpsDDR2 4N MUX Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz)I/O (400–1066 MHz) 800–2133 MbpsDDR3 8N MUX Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz)Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz) I/O (667–1600 MHz) 1333–3200 MbpsDDR4 8N MUX MUX Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz) Memory array (100-266 MHz)Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz) Memory array (100–266 MHz)8N MUX Figure 5.14 DDR Generations5.4 / Fla Sh Mory 185 5.4 FlaSh memory Another form semiconductor memory flash memory. Flash memory used internal memory external memory applications. Here, provide technical overview look use internal memory. First introduced mid-1980s, flash memory intermediate EPROM EEPROM cost functionality. Like EEPROM, flash mem - ory uses electrical erasing technology. entire flash memory erased one seconds, much faster EPROM. addition, possible erase blocks memory rather entire chip. Flash memory gets name microchip organized section memory cells erased single action “flash.” However, flash memory provide byte- level erasure. Like EPROM, flash memory uses one transistor per bit, achieves high density (compared EEPROM) EPROM. Operation Figure 5.15 illustrates basic operation flash memory. comparison, Fig - ure 5.15a depicts operation transistor. Transistors exploit properties semiconductors small voltage applied gate used control flow large current source drain. flash memory cell, second gate—called floating gate, insu - lated thin oxide layer—is added transistor. Initially, floating gate interfere operation transistor (Figure 5.15b). state, cell deemed represent binary 1. Applying large voltage across oxide layer causes electrons tunnel become trapped floating gate, remain even power disconnected (Figure 5.15c). state, cell deemed represent binary 0. state cell read using external circuitry test whether transistor working not. Applying large voltage opposite direction removes electrons floating gate, returning state binary 1. (a) Transistor structure (b) Flash memor cell one state (c) Flash memor cell zero stateContr ol gate N+ DrainN+ Source P-substrate Contr ol gate N+ DrainN+ Sour ceFloating gate P-substrateContr ol gate N+ DrainN+ Sour ce P-substrate–+ –– –– –++ ++ + Figure 5.15 Flash Memory Operation186 Chapter 5 / Internal Mory important characteristic flash memory persistent memory, means retains data power applied memory. Thus, useful secondary (external) storage, alternative random access memory computers. NAND Flash Memory two distinctive types flash memory, designated NAND (Figure 5.16). flash memory , basic unit access bit, referred memory cell . Cells flash connected parallel bit lines cell read/write/erased individually. memory cell device turned corresponding word line, bit line goes low. similar function logic gate.2 NAND flash memory organized transistor arrays 16 32 transistors series. bit line goes low transistors corresponding word lines turned on. similar function NAND logic gate. Although specific quantitative values various characteristics NAND changing year year, relative differences two types remained stable. differences usefully illustrated Kiviat graphs3 shown Figure 5.17. (a) /f_lash structur e (b) NAND /f_lash structu reGround selec transistorBit-line selec transisto rWord line 0Word line 1Word line 2Word line 3Word line 4Word line 5Word line 6Word line 7Word line 0Word line 1 Memo ry cell Memo ry cellWord line 2Word line 3Word line 4Word line 5Bit line Bit line Figure 5.16 Flash Memory Structures 2The circles associated Figure 5.2b indicate signal negation. 3A Kiviat graph provides pictorial means comparing systems along multiple variables [MORR74]. variables laid lines equal angular intervals within circle, line going center circle circumference. given system defined one point line; closer circumference, better value. points connected yield shape characteristic system. area enclosed shape, “better” system.5.5 / newer nonvolat Ile Sol Id-State Mory teChnolog IeS 187 flash memory provides high-speed random access. read write data specific locations, reference retrieve single byte. NAND reads writes small blocks. NAND provides higher bit density greater write speed. NAND flash provide random-access external address bus data must read blockwise basis (also known page access), block holds hundreds thousands bits. internal memory embedded systems, flash memory tradition - ally preferred. NAND memory made inroads, remains dominant technology internal memory. ideally suited microcontrollers amount program code relatively small certain amount appli - cation data vary. example, flash memory Figure 1.16 memory. NAND memory better suited external memory, USB flash drives, memory cards (in digital cameras, MP3 players, etc.), known solid-state disks (SSDs). discuss SSDs Chapter 6. 5.5 newer nonvolatile Solid-State memory technologie traditional memory hierarchy consisted three levels (Figure 5.18): ■Static RAM (SRAM): SRAM provides rapid access time, expen - sive least dense (bit density). SRAM suitable cache memory. ■Dynamic RAM (DRAM): Cheaper, denser, slower SRAM, DRAM traditionally choice off-chip main memory. ■Hard disk: magnetic disk provides high bit density low cost per bit, relatively slow access times. traditional choice exter - nal storage part memory hierarchy.(a) NORCost per bit File storage use Code execution Capacity Write speedRead speedActive powerLowLowLow Easy EasyStandby power High HighHigh HighHighHigh Hard Hard Low LowLow (b) NANDCost per bit File storage use Code execution Capacity Write speedRead speedActive powerLowLowLow Easy EasyStandby power High HighHigh HighHighHigh Hard Hard Low LowLow Figure 5.17 Kiviat Graphs Flash Memory188 Chapter 5 / Internal Mory mix, seen, added flash memory. Flash memory advantage traditional memory nonvolatile. flash best suited storing programs static application data embedded systems, NAND flash characteristics intermediate DRAM hard disks. time, technologies seen improvements scaling: higher bit density, higher speed, lower power consumption, lower cost. However, semiconductor memory, becoming increasingly difficult continue pace improvement [ITRS14]. Recently, breakthroughs developing new forms non - volatile semiconductor memory continue scaling beyond flash memory. promising technologies spin-transfer torque RAM (STT-RAM), phase- change RAM (PCRAM), resistive RAM (ReRAM) ([ITRS14], [GOER12]). volume production. However, NAND Flash extent Flash still dominating applications, emerging memories used specialty applications yet fulfilled original promise become dominating mainstream high-density nonvolatile memory. likely change next years. Figure 5.18 shows three technologies likely fit mem - ory hierarchy.SRAM STT-RAM PCRAM ReRAMIncreasing performance endurance Decreasing cost per bit, increasing capacity densityDRAM NAND FLASH HARD DISK Figure 5.18 Nonvolatile RAM within Memory Hierarchy5.5 / newer nonvolat Ile Sol Id-State Mory teChnolog IeS 189 STT-RAM STT-RAM new type magnetic RAM (MRAM) , features non- volatility, fast writing/reading speed (6 10 ns), high programming endurance (7 1015 cycles) zero standby power [KULT13]. storage capability programmability MRAM arises magnetic tunneling junction (MTJ), thin tunneling dielectric sandwiched two ferromagnetic layers. One ferromagnetic layer (pinned reference layer) designed magnetization pinned, magnetization layer (free layer) flipped write event. MTJ low (high) resistance magnetizations free layer pinned layer parallel (anti-parallel). first-generation MRAM design, magnetization free layer changed current-induced magnetic field. STT-RAM, new write mechanism, called polarization-current-induced magnetization switching , intro - duced. STT-RAM, magnetization free layer flipped electrical current directly. current required switch MTJ resistance state pro - portional MTJ cell area, STT-RAM believed better scaling property first-generation MRAM. Figure 5.19a illustrates general configuration. STT-RAM good candidate either cache main memory. PCRAM Phase-change RAM ( pcram ) mature new technologies, extensive technical literature ([RAOU09], [ZHOU09], [LEE10]). PCRAM technology based chalcogenide alloy material, similar commonly used optical storage media (compact discs digital versa - tile discs). data storage capability achieved resistance differences amorphous (high-resistance) crystalline (low-resistance) phase chalcogenide-based material. SET operation, phase change material crystallized applying electrical pulse heats significant portion cell crystallization temperature. RESET operation, larger electrical current applied abruptly cut order melt quench material, leaving amorphous state. Figure 5.19b illustrates general configuration. PCRAM good candidate replace supplement DRAM main memory. ReRAM ReRAM (also known RRAM) works creating resistance rather directly storing charge. electric current applied material, changing resistance material. resistance state measured 1 0 read result. Much work done ReRAM date focused finding appro - priate materials measuring resistance state cells. ReRAM designs low voltage, endurance far superior flash memory, cells much smaller—at least theory. Figure 5.19c shows one ReRam configuration. ReRAM good candidate replace supplement secondary storage main memory.190 Chapter 5 / Internal Mory 5.6 Key termS, review Que Stion S, Problem Key Terms(a) STT-RAM (b) PCRAMBit line Free layer Refer ence layer Base electr odeInterface layerDirection magnetization Electric currentbinary 0 Interface layerInsulating layerPerpendicular magnetic layer Perpendicular magnetic layerBit line Free layer Refer ence layer Base electr odeInterface layerDirection magnetization Electric currentbinary 1 Interface layerInsulating layerPerpendicular magnetic layer Perpendicular magnetic layer Top electr ode Bottom electr odePolycrystaline chalcogenide Heater Insulator Filament Metal oxideInsulator Metal oxideInsulator (c) ReRAMTop electr ode Bottom electr odeFilamentOxidation: high r esistanceReduction: low r esistanceTop electr ode Bottom electr odeTop electr ode Bottom electr odePolycrystaline chalcogenideAmorphous chalcogenide Heater Insulator Figure 5.19 Nonvolatile RAM Technologies bank group double data rate DRAM (DDR DRAM) dynamic RAM (DRAM)electrically erasable programmable ROM (EEPROM) erasable programmable ROM (EPROM)error correcting code (ECC) error correction flash memory Hamming code hard failure5.6 / Key terMS, revIew Que StIonS, proble MS 191 Review Questions 5.1 key properties semiconductor memory? 5.2 two interpretations term random-access memory ? 5.3 difference DRAM SRAM terms application? 5.4 difference DRAM SRAM terms characteristics speed, size, cost? 5.5 Explain one type RAM considered analog digital. 5.6 applications ROM? 5.7 differences among EPROM, EEPROM, flash memory? 5.8 Explain function pin Figure 5.4b. 5.9 parity bit? 5.10 syndrome Hamming code interpreted? 5.11 SDRAM differ ordinary DRAM? 5.12 DDR RAM? 5.13 difference NAND flash memory? 5.14 List briefly define three newer nonvolatile solid-state memory technologies. Problems 5.1 Suggest reasons RAMs traditionally organized one bit per chip whereas ROMs usually organized multiple bits per chip. 5.2 Consider dynamic RAM must given refresh cycle 64 times per ms. refresh operation requires 150 ns; memory cycle requires 250 ns. percentage memory’s total operating time must given refreshes? 5.3 Figure 5.20 shows simplified timing diagram DRAM read operation bus. access time considered last t1 t2. recharge time, lasting t2 t3, DRAM chips recharge processor access again. a. Assume access time 60 ns recharge time 40 ns. memory cycle time? maximum data rate DRAM sustain, assuming 1 -bit output? b. Constructing 32-bit wide memory system using chips yields data transfer rate? 5.4 Figure 5.6 indicates construct module chips store 1 MB based group four 256-Kbyte chips. Let’s say module chips packaged single 1 -MB chip, word size 1 byte. Give high-level chip diagram construct 8-MB computer memory using eight 1 -MB chips. sure show address lines diagram address lines used for.magnetic RAM (MRAM) NAND flash memory nonvolatile memory flash memory phase-change RAM (PCRAM) programmable ROM (PROM) random access memory (RAM)read-mostly memory read-only memory (ROM) resistive RAM (ReRAM) semiconductor memory single-error-correcting (SEC) code single-error-correcting, double-error-detecting (SEC-DED) codesoft error spin-transfer torque RAM (STT-RAM) static RAM (SRAM) synchronous DRAM (SDRAM) syndrome volatile memory192 Chapter 5 / Internal Mory 5.5 typical Intel 8086-based system, connected via system bus DRAM memory, read operation, RAS activated trailing edge Address Enable signal (Figure C.1 Appendix C). However, due propagation delays, RAS go active 50 ns Address Enable returns low. Assume latter occurs middle second half state T1 (somewhat earlier Figure C.1). Data read processor end T3. timely presentation processor, however, data must provided 60 ns earlier memory. interval accounts propagation delays along data paths (from memory processor) processor data hold time requirements. Assume clocking rate 10 MHz. a. fast (access time) DRAMs wait states inserted? b. many wait states insert per memory read operation access time DRAMs 150 ns? 5.6 memory particular microcomputer built 64K*1 DRAMs. Accord - ing data sheet, cell array DRAM organized 256 rows. row must refreshed least every 4 ms. Suppose refresh memory strictly periodic basis. a. time period successive refresh requests? b. long refresh address counter need? 5.7 Figure 5.21 shows one early SRAMs, 16*4 Signetics 7489 chip, stores 16 4-bit words. a. List mode operation chip CS input pulse shown Figure 5.21c. b. List memory contents word locations 0 6 pulse n. c. state output data leads input pulses h m? 5.8 Design 16-bit memory total capacity 8192 bits using SRAM chips size 64*1 bit. Give array configuration chips memory board showing required input output signals assigning memory lowest address space. design allow byte 16-bit word accesses. 5.9 common unit measure failure rates electronic components Failure unIT (FIT), expressed rate failures per billion device hours. Another well known less used measure mean time failures (MTBF), average time operation particular component fails. Consider 1 MB memory 16-bit microprocessor 256K*1 DRAMs. Calculate MTBF assuming 2000 FITS DRAM.Addr ess lines t1 t2 t3Data linesR/WCASRASRow addr ess Data validColumn addr ess Figure 5.20 Simplified DRAM Read Timing5.6 / Key terMS, revIew Que StIonS, proble MS 193 5.10 Hamming code shown Figure 5.10, show happens check bit rather data bit error? 5.11 Suppose 8-bit data word stored memory 11000010. Using Hamming algo - rithm, determine check bits would stored memory data word. Show got answer. 5.12 8-bit word 00111001, check bits stored would 0111. Suppose word read memory, check bits calculated 1101. data word read memory? 5.13 many check bits needed Hamming error correction code used detect single bit errors 1024-bit data word? 5.14 Develop SEC code 16-bit data word. Generate code data word 0101000000111001. Show code correctly identify error data bit 5.(b) Truth table (c) Pulse trainOperating ModeInputs Outputs Write H = high v oltage le vel L = low voltage le vel X = don’ careRead Inhibit writing Store - disable outputsDn CS R/W L H X LH L HL H HL XOn L H Data H L H HH16 15 14 13 12 11 10 91 2 3 4 5 6 7 8D3 O3 O2D2 GNDVcc A2 A1 A0 D0 O0 D1 O1Signetics 7489 16 × 4 SRAMCS R/W 01010101010101a b c e f g h j k l nA0 A1 A2 A3 CS R/W D3 D2 D1 D0A3 Figure 5.21 Signetics 7489 SRAM194CHAPTER ExtErnal MEMory 6.1 Magnetic Disk Magnetic Read Write Mechanisms Data Organization Formatting Physical Characteristics Disk Performance Parameters 6.2 RAID RAID Level 0 RAID Level 1 RAID Level 2 RAID Level 3 RAID Level 4 RAID Level 5 RAID Level 6 6.3 Solid State Drives SSD Compared HDD SSD Organization Practical Issues 6.4 Optical Memory Compact Disk Digital Versatile Disk High- Definition Optical Disks 6.5 Magnetic Tape 6.6 Key Terms, Review Questions, Problems 6.1 / Magnetic Disk 195 chapter examines range external memory devices systems. begin important device, magnetic disk. Magnetic disks founda - tion external memory virtually computer systems. next section exam - ines use disk arrays achieve greater performance, looking specifically family systems known RAID (Redundant Array Independent Disks). increasingly important component many computer systems solid state disk, discussed next. Then, external optical memory examined. Finally, magnetic tape described. 6.1 MAGNETIC DISK disk circular platter constructed nonmagnetic material, called substrate , coated magnetizable material. Traditionally, substrate alumi - num aluminum alloy material. recently, glass substrates intro - duced. glass substrate number benefits, including following: ■Improvement uniformity magnetic film surface increase disk reliability. ■A significant reduction overall surface defects help reduce read- write errors. ■Ability support lower fly heights (described subsequently). ■Better stiffness reduce disk dynamics. ■Greater ability withstand shock damage. Magnetic Read Write Mechanisms Data recorded later retrieved disk via conducting coil named head ; many systems, two heads, read head write head. read write operation, head stationary platter rotates beneath it. write mechanism exploits fact electricity flowing coil produces magnetic field. Electric pulses sent write head, result - ing magnetic patterns recorded surface below, different patterns positive negative currents. write head made easily magnetizable Learning Objectives studying chapter, able to: rUnderstand key properties magnetic disks. rUnderstand performance issues involved magnetic disk access. rExplain concept RAID describe various levels. rCompare contrast hard disk drives solid disk drives. rDescribe general terms operation flash memory . rUnderstand differences among different optical disk storage media. rPresent overview magnetic tape storage technology.196 cHaPteR 6 / exteRnal MoRy material shape rectangular doughnut gap along one side turns conducting wire along opposite side (Figure 6.1). electric cur - rent wire induces magnetic field across gap, turn magnetizes small area recording medium. Reversing direction current reverses direction magnetization recording medium. traditional read mechanism exploits fact magnetic field moving relative coil produces electrical current coil. surface disk rotates head, generates current polarity one already recorded. structure head reading case essentially writing therefore head used both. single heads used floppy disk systems older rigid disk systems. Contemporary rigid disk systems use different read mechanism, requiring separate read head, positioned convenience close write head. read head consists partially shielded magnetoresistive (MR) sensor. MR mate - rial electrical resistance depends direction magnetization medium moving it. passing current MR sensor, resistance changes detected voltage signals. MR design allows higher- frequency operation, equates greater storage densities operating speeds. Data Organization Formatting head relatively small device capable reading writing portion platter rotating beneath it. gives rise organization data platter concentric set rings, called tracks . track width head. thousands tracks per surface.N N N SS NN N N STrack width Recording mediumInductive write elementShield MagnetizationMR sensorRead current Write curr ent Figure 6.1 Inductive Write/Magnetoresistive Read Head6.1 / Magnetic Disk 197 Figure 6.2 depicts data layout. Adjacent tracks separated intertrack gaps . prevents, least minimizes, errors due misalignment head simply interference magnetic fields. Data transferred disk sectors . typically hundreds sectors per track, may either fixed variable length. contemporary systems, fixed- length sectors used, 512 bytes nearly universal sector size. avoid imposing unreasonable precision requirements system, adjacent sectors separated intersector gaps. bit near center rotating disk travels past fixed point (such read– write head) slower bit outside. Therefore, way must found com - pensate variation speed head read bits rate. done defining variable spacing bits information recorded Inter -sector gapInter -track gap Sector PlatterRead-write head (1 per surface)TrackRotation CylinderSpindle BoomDirection arm motionTrack sectorS4 S4 S4S3 S3 S3S2 S2 S2 S1 S1 S1        S5 S5 S5S6 S6 S6SN SN SN Figure 6.2 Disk Data Layout198 cHaPteR 6 / exteRnal MoRy locations disk, way outermost tracks sectors bigger spacing. information scanned rate rotating disk fixed speed, known constant angular velocity (CAV) . Figure 6.3a shows layout disk using CAV. disk divided number pie- shaped sectors series concentric tracks. advantage using CAV individual blocks data directly addressed track sector. move head current loca - tion specific address, takes short movement head specific track short wait proper sector spin head. disadvantage CAV amount data stored long outer tracks stored short inner tracks. density , bits per linear inch, increases moving outer - track innermost track, disk storage capacity straightforward CAV system limited maximum recording density achieved innermost track. maximize storage capacity, would preferable linear bit density track. would require unacceptably complex cir - cuitry. Modern hard disk systems use simpler technique, approximates equal bit density per track, known multiple zone recording (MZR), surface divided number concentric zones (16 typical). zone contains number contiguous tracks, typically thousands. Within zone, number bits per track constant. Zones farther center contain bits (more sectors) zones closer center. Zones defined way lin - ear bit density approximately tracks disk. MZR allows greater overall storage capacity expense somewhat complex circuitry. disk head moves one zone another, length (along track) individual bits changes, causing change timing reads writes. Figure 6.3b simplified MZR layout, 15 tracks organized 5 zones. innermost two zones two tracks each, track nine sectors; next zone 3 tracks, 12 sectors; outermost 2 zones 4 tracks each, track 16 sectors. (a) Constant angular velocity (b) Multiple zone r ecordingTrack SectorZone Figure 6.3 Comparison Disk Layout Methods6.1 / Magnetic Disk 199 means needed locate sector positions within track. Clearly, must starting point track way identifying start end sector. requirements handled means control data recorded disk. Thus, disk formatted extra data used disk drive accessible user. example disk formatting shown Figure 6.4. case, track contains 30 fixed- length sectors 600 bytes each. sector holds 512 bytes data plus control information useful disk controller. ID field unique identifier address used locate particular sector. SYNCH byte spe - cial bit pattern delimits beginning field. track number identi - fies track surface. head number identifies head, disk multiple surfaces (explained presently). ID data fields contain error- detecting code. Physical Characteristics Table 6.1 lists major characteristics differentiate among various types magnetic disks. First, head may either fixed movable respect radial direction platter. fixed- head disk , one read- write head per track. heads mounted rigid arm extends across tracks; systems rare today. movable- head disk , one read- write head. Again, head mounted arm. head must able positioned track, arm extended retracted purpose. disk mounted disk drive, consists arm, spindle rotates disk, electronics needed input output binary data. nonremovable disk permanently mounted disk drive; hard disk personal computer nonremovable disk. removable disk removed replaced another disk. advantage latter type unlimited amounts data available limited number disk systems. Furthermore, disk may moved one computer system another. Floppy disks ZIP cartridge disks examples removable disks. Gap 1 17 74 1 515 20 1774 1 515 20 1211 21 512 217 74 1 515 600 bytes/sector20Physical sector 0Sector Bytes BytesIndex Physical sector 1P hysical sector 29 ID /f_ield 0Gap 2Data /f_ield 0Gap 3 Synch byteTrack #Head #Sector #CRCSynch byteData CRCGap 1ID /f_ield 1Gap 2Data /f_ield 1Gap 3Gap 1ID /f_ield 29Gap 2Data /f_ield 29Gap 3 Figure 6.4 Winchester Disk Format (Seagate ST506)200 cHaPteR 6 / exteRnal MoRy disks, magnetizable coating applied sides plat - ter, referred double sided . less expensive disk systems use single- sided disks. disk drives accommodate multiple platters stacked vertically fraction inch apart. Multiple arms provided (Figure 6.2). Multiple– platter disks employ movable head, one read- write head per platter surface. heads mechanically fixed distance center disk move together. Thus, time, heads positioned tracks equal distance center disk. set tracks relative position platter referred cylinder . illus - trated Figure 6.2. Finally, head mechanism provides classification disks three types. Traditionally, read- write head positioned fixed distance platter, allowing air gap. extreme head mechanism actually comes physical contact medium read write operation. mechanism used floppy disk , small, flexible platter least expensive type disk. understand third type disk, need comment relation - ship data density size air gap. head must generate sense electromagnetic field sufficient magnitude write read properly. narrower head is, closer must platter surface function. narrower head means narrower tracks therefore greater data density, desirable. However, closer head disk, greater risk error impurities imperfections. push technology further, Winchester disk developed. Winchester heads used sealed drive assemblies almost free contaminants. designed operate closer disk’s sur - face conventional rigid disk heads, thus allowing greater data density. head actually aerodynamic foil rests lightly platter’s surface disk motionless. air pressure generated spinning disk enough make foil rise surface. resulting noncontact system engineered use narrower heads operate closer platter’s surface conventional rigid disk heads. Table 6.2 gives disk parameters typical contemporary high- performance disks.Table 6.1 Physical Characteristics Disk Systems Head Motion Fixed head (one per track) Movable head (one per surface)Platters Single platter Multiple platter Disk Portability Nonremovable disk Removable diskHead Mechanism Contact (floppy) Fixed gap Sides Single sided Double sidedAerodynamic gap (Winchester)6.1 / Magnetic Disk 201 Disk Performance Parameters actual details disk I/O operation depend computer system, oper - ating system, nature I/O channel disk controller hardware. general timing diagram disk I/O transfer shown Figure 6.5. disk drive operating, disk rotating constant speed. read write, head must positioned desired track beginning desired sector track. Track selection involves moving head movable- head system electronically selecting one head fixed- head system. movable- head system, time takes position head track known seek time . either case, track selected, disk controller waits appropriate sector rotates line head. time takes beginning sector reach head known rotational delay , rotational latency . sum seek time, any, rotational delay equals access time , time takes get position read write. head position, read write operation performed sector moves head; data transfer portion operation; time required transfer transfer time . addition access time transfer time, several queuing delays normally associated disk I/O operation. process issues I/O Table 6.2 Typical Hard Disk Drive Parameters CharacteristicsSeagate EnterpriseSeagate Barracuda XTSeagate Cheetah NSSeagate Laptop HDD Application Enterprise Desktop Network- attached storage, application serversLaptop Capacity 6 TB 3 TB 600 GB 2 TB Average seek time 4.16 ms N/A 3.9 ms read 4.2 ms write13 ms Spindle speed 7200 rpm 7200 rpm 10,075 rpm 5400 rpm Average latency 4.16 ms 4.16 ms 2.98 5.6 ms Maximum sustained transfer rate216 MB/sec 149 MB/sec 97 MB/sec 300 MB/sec Bytes per sector 512/4096 512 512 4096 Tracks per cylinder (number platter surfaces)8 10 8 4 Cache 128 MB 64 MB 16 MB 8 MB Wait deviceWait channelSeek Rotational delayData transfer Device b usy Figure 6.5 Timing Disk I/O Transfer202 cHaPteR 6 / exteRnal MoRy request, must first wait queue device available. time, device assigned process. device shares single I/O channel set I/O channels disk drives, may additional wait channel available. point, seek performed begin disk access. high- end systems servers, technique known rotational pos - itional sensing (RPS) used. works follows: seek command issued, channel released handle I/O operations. seek completed, device determines data rotate head. sector approaches head, device tries reestablish communication path back host. either control unit channel busy another I/O, reconnection attempt fails device must rotate one whole revolution attempt reconnect, called RPS miss. extra delay element must added timeline Figure 6.5. seek time Seek time time required move disk arm required track. turns difficult quantity pin down. seek time consists two key components: initial startup time, time taken traverse tracks crossed access arm speed. Unfortunately, traversal time linear function number tracks, includes settling time (time positioning head target track track identification confirmed). Much improvement comes smaller lighter disk components. years ago, typical disk 14 inches (36 cm) diameter, whereas com - mon size today 3.5 inches (8.9 cm), reducing distance arm travel. typical average seek time contemporary hard disks 10 ms. rotational delay Disks, floppy disks, rotate speeds ranging 3600 rpm (for handheld devices digital cameras) to, writing, 20,000 rpm; latter speed, one revolution per 3 ms. Thus, average, rotational delay 1.5 ms. transfer time transfer time disk depends rotation speed disk following fashion: T=b rN T=transfer time b=number bytes transferred N=number bytes track r=rotation speed, revolutions per second Thus total average read write time Ttotal expressed Ttotal=Ts+1 2r+b rN (6.1) Ts average seek time. Note zoned drive, number bytes per track variable, complicating calculation.1 1Compare two preceding equations Equation (4.1).6.1 / Magnetic Disk 203 timing comparison foregoing parameters defined, let us look two different I/O operations illustrate danger relying average values. Consider disk advertised average seek time 4 ms, rotation speed 15,000 rpm, 512-byte sectors 500 sectors per track. Suppose wish read file consisting 2500 sectors total 1.28 Mbytes. would like estimate total time transfer. First, let us assume file stored compactly possible disk. is, file occupies sectors 5 adjacent tracks (5 tracks*500 sectors/track=2500 sectors). known sequential organ - ization . Now, time read first track follows: Average seek 4 ms Average rotational delay 2 ms Read 500 sectors 4 ms 10 ms Suppose remaining tracks read essentially seek time. is, I/O operation keep flow disk. Then, most, need deal rotational delay four remaining tracks. Thus successive track read 2+4=6 ms. read entire file, Total time=10+(4*6)=34 ms=0.034 seconds let us calculate time required read data using random access rather sequential access; is, accesses sectors distributed randomly disk. sector, Average seek 4 ms Rotational delay 2 ms Read 1 sectors 0.008 ms 6.008 ms Total time=2500*6.008=15,020 ms=15.02 seconds clear order sectors read disk tre - mendous effect I/O performance. case file access multiple sectors read written, control way sectors data deployed. However, even case file access, multipro - gramming environment, I/O requests competing disk. Thus, worthwhile examine ways performance disk I/O improved achieved purely random access disk. leads consideration disk scheduling algorithms, province operating system beyond scope book (see [STAL15] discussion). RAID Simulator204 cHaPteR 6 / exteRnal MoRy 6.2 RAID discussed earlier, rate improvement secondary storage performance considerably less rate processors main memory. mismatch made disk storage system perhaps main focus concern improving overall computer system performance. areas computer performance, disk storage designers recognize one component pushed far, additional gains performance using multiple parallel components. case disk storage, leads development arrays disks operate independently par - allel. multiple disks, separate I/O requests handled parallel, long data required reside separate disks. Further, single I/O request executed parallel block data accessed distributed across multiple disks. use multiple disks, wide variety ways data organized redundancy added improve reliability. could make difficult develop database schemes usable number platforms operating systems. Fortunately, industry agreed standard - ized scheme multiple- disk database design, known RAID (Redundant Array Independent Disks). RAID scheme consists seven levels,2 zero six. levels imply hierarchical relationship designate different design architectures share three common characteristics: 1. RAID set physical disk drives viewed operating system single logical drive. 2. Data distributed across physical drives array scheme known striping, described subsequently. 3. Redundant disk capacity used store parity information, guarantees data recoverability case disk failure. details second third characteristics differ different RAID levels. RAID 0 RAID 1 support third characteristic. term RAID originally coined paper group researchers University California Berkeley [PATT88].3 paper outlined vari - ous RAID configurations applications introduced definitions RAID levels still used. RAID strategy employs multiple disk drives distributes data way enable simultaneous access data multiple drives, thereby improving I/O performance allowing easier incremen - tal increases capacity. 2Additional levels defined researchers companies, seven levels described section ones universally agreed on. 3In paper, acronym RAID stood Redundant Array Inexpensive Disks. term inexpen- sive used contrast small relatively inexpensive disks RAID array alternative, single large expensive disk (SLED). SLED essentially thing past, similar disk technol - ogy used RAID non- RAID configurations. Accordingly, industry adopted term independent emphasize RAID array creates significant performance reliability gains.6.2 / R aiD 205 unique contribution RAID proposal address effectively need redundancy. Although allowing multiple heads actuators operate simultaneously achieves higher I/O transfer rates, use multiple devices increases probability failure. compensate decreased reliability, RAID makes use stored parity information enables recovery data lost due disk failure. examine RAID levels. Table 6.3 provides rough guide seven levels. table, I/O performance shown terms data transfer capacity, ability move data, I/O request rate, ability satisfy I/O requests, since RAID levels inherently perform differently relative two metrics. RAID level’s strong point highlighted darker shad - ing. Figure 6.6 illustrates use seven RAID schemes support data capacity requiring four disks redundancy. figures highlight layout user data redundant data indicates relative storage requirements various levels. refer figures throughout following discussion. seven RAID levels described, four commonly used: RAID levels 0, 1, 5, 6. RAID Level 0 RAID level 0 true member RAID family include redundancy improve performance. However, applications, supercomputers performance capacity primary concerns low cost important improved reliability. RAID 0, user system data distributed across disks array. notable advantage use single large disk: two- different I/O requests pending two different blocks data, good chance requested blocks different disks. Thus, two requests issued parallel, reducing I/O queuing time. RAID 0, RAID levels, goes simply distribut - ing data across disk array: data striped across available disks. best understood considering Figure 6.7. user system data viewed stored logical disk. logical disk divided strips; strips may physical blocks, sectors, unit. strips mapped round robin consecutive physical disks RAID array. set logically con - secutive strips maps exactly one strip array member referred stripe. n- disk array, first n logical strips physically stored first strip n disks, forming first stripe; second n strips distributed second strips disk; on. advantage layout single I/O request consists multiple logically contiguous strips, n strips request handled parallel, greatly reducing I/O transfer time. Figure 6.7 indicates use array management software map logical physical disk space. software may execute either disk subsys - tem host computer. raid 0 high data transfer capacity performance RAID levels depends critically request patterns host system layout data. issues clearly addressed RAID 0, Table 6.3 RAID Levels Category Level DescriptionDisks Required Data AvailabilityLarge I/O Data Transfer CapacitySmall I/O Request Rate Striping 0 Nonredundant N Lower single disk highVery high read write Mirroring 1 Mirrored 2NHigher RAID 2, 3, 4, 5; lower RAID 6Higher single disk read; similar single disk writeUp twice single disk read; similar single disk write Parallel access2Redundant via Hamming codeN+mMuch higher single disk; comparable RAID 3, 4, 5Highest listed alternativesApproximately twice single disk 3 Bit- interleaved parityN+1Much higher single disk; comparable RAID 2, 4, 5Highest listed alternativesApproximately twice single disk Independent access4 Block- interleaved parityN+1Much higher single disk; comparable RAID 2, 3, 5Similar RAID 0 read; significantly lower single disk writeSimilar RAID 0 read; significantly lower single disk write 5 Block- interleaved distributed parityN+1Much higher single disk; comparable RAID 2, 3, 4Similar RAID 0 read; lower single disk writeSimilar RAID 0 read; generally lower single disk write 6 Block- interleaved dual distributed parityN+2Highest listed alternativesSimilar RAID 0 read; lower RAID 5 writeSimilar RAID 0 read; significantly lower RAID 5 write Note: N=number data disks; proportional log N 2066.2 / R aiD 207 impact redundancy interfere analysis. First, let us consider use RAID 0 achieve high data transfer rate. applications experience high transfer rate, two requirements must met. First, high transfer capacity must exist along entire path host memory individual disk drives. includes internal controller buses, host system I/O buses, I/O adapters, host memory buses. second requirement application must make I/O requests drive disk array efficiently. requirement met typical request large amounts logically contiguous data, compared size strip. case, single I/O request involves parallel transfer data multiple disks, increasing effective transfer rate compared single- disk transfer. raid 0 high i/o request rate transaction- oriented environment, user typically concerned response time transfer rate. individual I/O request small amount data, I/O time dominated motion disk heads (seek time) movement disk (rotational latency). transaction environment, may hundreds I/O requests per sec - ond. disk array provide high I/O execution rates balancing I/O load across multiple disks. Effective load balancing achieved typically strip 12 (a) RAID 0 (Nonredundant)strip 8strip 4strip 0 strip 13strip 9strip 5strip 1 strip 14strip 10strip 6strip 2 strip 15strip 11strip 7strip 3 strip 12 (b) RAID 1 (Mirrored)strip 8strip 4strip 0 strip 13strip 9strip 5strip 1 strip 14strip 10strip 6strip 2 strip 15strip 11strip 7strip 3 strip 12strip 8strip 4strip 0 strip 13strip 9strip 5strip 1 strip 14strip 10strip 6strip 2 (c) RAID 2 (Redundanc throu gh Hammin g code)b0 b1 b2 b3 f0(b) f1(b) f2(b)strip 15strip 11strip 7strip 3 Figure 6.6 RAID Levels ( Continued )208 cHaPteR 6 / exteRnal MoRy multiple I/O requests outstanding. This, turn, implies multiple inde - pendent applications single transaction- oriented application capable multiple asynchronous I/O requests. performance also influenced strip size. strip size relatively large, single I/O request involves single disk access, multiple waiting I/O requests handled parallel, reducing queuing time request.block 12 (e) RAID 4 (Block-le vel parity)block 8block 4block 0 block 13block 9block 5block 1 block 14block 10block 6block 2 block 15block 7block 3 P(12–15)P(8–11)P(4–7)P(0–3) block 12block 8block 4block 0 block 9block 5block 1 block 13block 6block 2 block 14block 10block 3 block 15 P(16-19)P(12–15)P(8–11)P(4–7) block 16 block 17 block 18 block 19block 11block 7 (f) RAID 5 (Block-le vel distrib uted parity)(d) RAID 3 (Bit-interlea ved parity)b0 b1 b2 b3 P(b) P(0–3)block 11 block 12 (g) RAID 6 (Dual redundanc y) block 8block 4block 0 P(12–15)block 9block 5block 1 Q(12–15)P(8–11)block 6block 2 block 13P(4–7)block 3 block 14block 10Q(4–7)P(0–3) Q(8–11) block 15block 7Q(0–3) block 11 Figure 6.6 RAID Levels ( Continued )6.2 / R aiD 209 strip 4strip 0 strip 3 strip 4 strip 5 strip 6 strip 7 strip 8 strip 9 strip 10 strip 11 strip 15strip 2strip 1strip 0Logical Disk Physical disk 1Physical disk 3Physical disk 0Physical disk 2 strip 5strip 1 strip 6strip 2 strip 11 strip 10 strip 9 strip 8 strip 15 strip 14 strip 13 strip 12strip 7strip 3 strip 13strip 12 strip 14Array Management Softwa Figure 6.7 Data Mapping RAID Level 0 Array RAID Level 1 RAID 1 differs RAID levels 2 6 way redundancy achieved. RAID schemes, form parity calculation used introduce redundancy, whereas RAID 1, redundancy achieved simple expedient duplicating data. Figure 6.6b shows, data striping used, RAID 0. case, logical strip mapped two separate physical disks every disk array mirror disk contains data. RAID 1 also implemented without data striping, though less common. number positive aspects RAID 1 organization: 1. read request serviced either two disks contains requested data, whichever one involves minimum seek time plus rota - tional latency. 2. write request requires corresponding strips updated, done parallel. Thus, write performance dictated slower two writes (i.e., one involves larger seek time plus rotational latency). However, “write penalty” RAID 1. RAID levels 2 6 involve use parity bits. Therefore, single strip updated, array management software must first compute update parity bits well updating actual strip question. 3. Recovery failure simple. drive fails, data may still accessed second drive.210 cHaPteR 6 / exteRnal MoRy principal disadvantage RAID 1 cost; requires twice disk space logical disk supports. that, RAID 1 configuration likely limited drives store system software data highly critical files. cases, RAID 1 provides real- time copy data event disk failure, critical data still immediately available. transaction- oriented environment, RAID 1 achieve high I/O request rates bulk requests reads. situation, performance RAID 1 approach double RAID 0. However, substantial fraction I/O requests write requests, may significant performance gain RAID 0. RAID 1 may also provide improved performance RAID 0 data transfer intensive applications high percentage reads. Improve - ment occurs application split read request disk members participate. RAID Level 2 RAID levels 2 3 make use parallel access technique. parallel access array, member disks participate execution every I/O request. Typically, spindles individual drives synchronized disk head position disk given time. RAID schemes, data striping used. case RAID 2 3, strips small, often small single byte word. RAID 2, error- correcting code calculated across corresponding bits data disk, bits code stored corresponding bit positions multiple par - ity disks. Typically, Hamming code used, able correct single- bit errors detect double- bit errors. Although RAID 2 requires fewer disks RAID 1, still rather costly. number redundant disks proportional log number data disks. single read, disks simultaneously accessed. requested data associated error- correcting code delivered array controller. single- bit error, controller recognize correct error instantly, read access time slowed. single write, data disks parity disks must accessed write operation. RAID 2 would effective choice environment many disk errors occur. Given high reliability individual disks disk drives, RAID 2 overkill implemented. RAID Level 3 RAID 3 organized similar fashion RAID 2. difference RAID 3 requires single redundant disk, matter large disk array. RAID 3 employs parallel access, data distributed small strips. Instead error- correcting code, simple parity bit computed set individual bits position data disks. redundancy event drive failure, parity drive accessed data reconstructed remaining devices. failed drive replaced, missing data restored new drive operation resumed.6.2 / R aiD 211 Data reconstruction simple. Consider array five drives X0 X3 contain data X4 parity disk. parity ith bit calculated follows: X4(i)=X3(i) ⊕ X2(i) ⊕ X1(i) ⊕ X0(i) ⊕ exclusive- function. Suppose drive X1 failed. add X4(i) ⊕ X1(i) sides preceding equation, get X1(i)=X4(i) ⊕ X3(i) ⊕ X2(i) ⊕ X0(i) Thus, contents strip data X1 regenerated contents corresponding strips remaining disks array. principle true RAID levels 3 6. event disk failure, data still available referred reduced mode. mode, reads, missing data regenerated fly using exclusive- calculation. data written reduced RAID 3 array, consistency parity must maintained later regeneration. Return full operation requires failed disk replaced entire contents failed disk regenerated new disk. performance data striped small strips, RAID 3 achieve high data transfer rates. I/O request involve parallel transfer data data disks. large transfers, performance improvement especially noticeable. hand, one I/O request executed time. Thus, transaction- oriented environment, performance suffers. RAID Level 4 RAID levels 4 6 make use independent access technique. inde - pendent access array, member disk operates independently, separate I/O requests satisfied parallel. this, independent access arrays suitable applications require high I/O request rates rela - tively less suited applications require high data transfer rates. RAID schemes, data striping used. case RAID 4 6, strips relatively large. RAID 4, bit- by- bit parity strip calculated across corresponding strips data disk, parity bits stored corresponding strip parity disk. RAID 4 involves write penalty I/O write request small size per - formed. time write occurs, array management software must update user data also corresponding parity bits. Consider array five drives X0 X3 contain data X4 parity disk. Suppose write performed involves strip disk X1. Initially, bit i, following relationship: X4(i)=X3(i) ⊕ X2(i) ⊕ X1(i) ⊕ X0(i) (6.2) update, potentially altered bits indicated prime symbol: X4′(i)=X3(i) ⊕ X2(i) ⊕ X1′(i)X0(i) =X3(i) ⊕ X2(i) ⊕ X1′(i) ⊕ X0(i) ⊕ X1(i) ⊕ X1(i) =X3(i) ⊕ X2(i) ⊕ X1(i) ⊕ X0(i) ⊕ X1(i) ⊕ X1′(i) =X4(i) ⊕ X1(i) ⊕ X1′(i)212 cHaPteR 6 / exteRnal MoRy preceding set equations derived follows. first line shows change X1 also affect parity disk X4. second line, add terms ⊕ X1(i) ⊕ X1(i)]. exclusive- quantity 0, affect equation. However, convenience used create third line, reordering. Finally, Equation (6.2) used replace first four terms X4( i). calculate new parity, array management software must read old user strip old parity strip. update two strips new data newly calculated parity. Thus, strip write involves two reads two writes. case larger size I/O write involves strips disk drives, parity easily computed calculation using new data bits. Thus, parity drive updated parallel data drives extra reads writes. case, every write operation must involve parity disk, - fore become bottleneck. RAID Level 5 RAID 5 organized similar fashion RAID 4. difference RAID 5 distributes parity strips across disks. typical allocation round- robin scheme, illustrated Figure 6.6f. n- disk array, parity strip differ - ent disk first n stripes, pattern repeats. distribution parity strips across drives avoids potential I/O bottle- neck found RAID 4. RAID Level 6 RAID 6 introduced subsequent paper Berkeley researchers [KATZ89]. RAID 6 scheme, two different parity calculations carried stored separate blocks different disks. Thus, RAID 6 array whose user data require N disks consists N+2 disks. Figure 6.6g illustrates scheme. P Q two different data check algo - rithms. One two exclusive- calculation used RAID 4 5. independent data check algorithm. makes possible regener - ate data even two disks containing user data fail. advantage RAID 6 provides extremely high data availability. Three disks would fail within MTTR (mean time repair) interval cause data lost. hand, RAID 6 incurs substantial write penalty, write affects two parity blocks. Performance benchmarks [EISC07] show RAID 6 controller suffer 30% drop overall write per - formance compared RAID 5 implementation. RAID 5 RAID 6 read performance comparable. Table 6.4 comparative summary seven levels. 6.3 SOLID STATE DRIVES One significant developments computer architecture recent years increasing use solid state drives (SSDs) complement even replace hard disk drives (HDDs) , internal external secondary memory. term solid Table 6.4 RAID Comparison Level Advantages Disadvantages Applications 0I/O performance greatly improved spreading I/O load across many channels drives parity calculation overhead involved simple design Easy implementThe failure one drive result data array lostVideo production editing Image Editing Pre- press applications application requiring high bandwidth 1100% redundancy data means rebuild necessary case disk fail- ure, copy replacement disk certain circumstances, RAID 1 sustain multiple simultaneous drive failures Simplest RAID storage subsystem designHighest disk overhead RAID types (100%)—inefficientAccounting Payroll Financial application requiring high availability 2Extremely high data transfer rates possible higher data transfer rate required, better ratio data disks ECC disks Relatively simple controller design com- pared RAID levels 3, 4, & 5Very high ratio ECC disks data disks smaller word sizes— inefficient Entry level cost high— requires high transfer rate requirement justifyNo commercial imple- mentations exist/not commercially viable 3Very high read data transfer rate high write data transfer rate Disk failure insignificant impact throughput Low ratio ECC (parity) disks data disks means high efficiencyTransaction rate equal single disk drive best (if spindles synchronized) Controller design fairly complexVideo production live streaming Image editing Video editing Prepress applications application requiring high throughput 4Very high Read data transaction rate Low ratio ECC (parity) disks data disks means high efficiencyQuite complex controller design Worst write transaction rate Write aggregate transfer rate Difficult inefficient data rebuild event disk failureNo commercial imple- mentations exist/not commercially viable 5Highest Read data transaction rate Low ratio ECC (parity) disks data disks means high efficiency Good aggregate transfer rateMost complex controller design Difficult rebuild event disk failure (as compared RAID level 1)File application servers Database servers Web, e- mail, news servers Intranet servers versatile RAID level 6Provides extremely high data fault tolerance sustain multiple simultaneous drive failuresMore complex controller design Controller overhead compute parity addresses extremely highPerfect solution mis- sion critical applications6.3 / soliD state Rives 213214 cHaPteR 6 / exteRnal MoRy state refers electronic circuitry built semiconductors. SSD memory device made solid state components used replacement hard disk drive. SSDs market coming line use NAND flash memory, described Chapter 5. SSD Compared HDD cost flash- based SSDs dropped performance bit density increased, SSDs become increasingly competitive HDDs. Table 6.5 shows typical measures comparison time writing. SSDs following advantages HDDs: ■ High- performance input/output operations per second (IOPS): Significantly increases performance I/O subsystems. ■Durability: Less susceptible physical shock vibration. ■Longer lifespan: SSDs susceptible mechanical wear. ■Lower power consumption: SSDs use considerably less power comparable- size HDDs. ■Quieter cooler running capabilities: Less space required, lower energy costs, greener enterprise. ■Lower access times latency rates: 10 times faster spinning disks HDD. Currently, HDDs enjoy cost per bit advantage capacity advantage, differences shrinking. SSD Organization Figure 6.8 illustrates general view common architectural system component associated SSD system. host system, operating system invokes file system software access data disk. file system, turn, invokes I/O driver software. I/O driver software provides host access particular SSD product. interface component Figure 6.8 refers physical electrical interface host processor SSD peripheral device. device internal hard drive, common interface PCIe. external devices, one com - mon interface USB. Table 6.5 Comparison Solid State Drives Disk Drives NAND Flash Drives Seagate Laptop Internal HDD File copy/write speed 200–550 Mbps 50–120 Mbps Power draw/battery life Less power draw, averages 2–3 watts, resulting 30+ minute battery boostMore power draw, averages 6–7 watts therefore uses battery Storage capacity Typically larger 512 GB notebook size drives; 1 TB max desktopsTypically around 500 GB 2 TB max notebook size drives; 4 TB max desktops Cost Approx. $0.50 per GB 1-TB drive Approx. $0.15 per GB 4-TB drive6.3 / soliD state Rives 215 I/O driver softwa reFile system softwa reOperating system softwar eHost system SSDInterfaceInterface Contr oller Flash memory components Flash memory components Flash memory components Flash memory componentsAddr essing Data buffer/ cacheError correction Figure 6.8 Solid State Drive Architecture addition interface host system, SSD contains following components: ■Controller: Provides SSD device level interfacing firmware execution. ■Addressing: Logic performs selection function across flash memory components. ■Data buffer/cache: High speed RAM memory components used speed matching increased data throughput.216 cHaPteR 6 / exteRnal MoRy ■Error correction: Logic error detection correction. ■Flash memory components: Individual NAND flash chips. Practical Issues two practical issues peculiar SSDs faced HDDs. First, SSD performance tendency slow device used. - stand reason this, need know files stored disk set pages, typically 4 KB length. pages necessarily, indeed typ - ically, stored contiguous set pages disk. reason arrange - ment explained discussion virtual memory Chapter 8. However, flash memory accessed blocks, typical block size 512 KB, typically 128 pages per block. consider must done write page onto flash memory. 1. entire block must read flash memory placed RAM buffer. appropriate page RAM buffer updated. 2. block written back flash memory, entire block flash memory must erased— possible erase one page flash memory. 3. entire block buffer written back flash memory. Now, flash drive relatively empty new file created, pages file written drive contiguously, one blocks affected. However, time, way virtual memory works, files become fragmented, pages scattered multiple blocks. drive become occupied, fragmentation, writing new file affect multiple blocks. Thus, writing multiple pages one block becomes slower, fully occupied disk is. Manufacturers developed variety techniques compensate property flash memory, setting aside substantial portion SSD extra space write operations (called - provisioning), erase inactive pages idle time used defragment disk. Another technique TRIM command, allows operating system inform SSD blocks data longer considered use wiped internally.4 second practical issue flash memory drives flash memory becomes unusable certain number writes. flash cells stressed, lose ability record retain values. typical limit 100,000 writes [GSOE08]. Techniques prolonging life SSD drive include front- ending flash cache delay group write operations, using wear- leveling algorithms evenly distribute writes across block cells, sophisticated bad- block management techniques. addition, vendors deploying SSDs RAID configurations reduce probability data loss. flash devices also capable estimating remaining lifetimes systems anticipate failure take preemptive action. 4While TRIM frequently spelled capital letters, acronym; merely command name.6.4 / oPtical MoRy 217 Table 6.6 Optical Disk Products CD Compact Disk. nonerasable disk stores digitized audio information. standard system uses 12-cm disks record 60 minutes uninterrupted playing time. CD- ROM Compact Disk Read- Memory. nonerasable disk used storing computer data. standard system uses 12-cm disks hold 650 Mbytes. CD- R CD Recordable. Similar CD- ROM. user write disk once. CD- RW CD Rewritable. Similar CD- ROM. user erase rewrite disk multiple times. DVD Digital Versatile Disk. technology producing digitized, compressed representation video information, well large volumes digital data. 8 12 cm diameters used, double- sided capacity 17 Gbytes. basic DVD read- ( DVD- ROM). DVD- R DVD Recordable. Similar DVD- ROM. user write disk once. one- sided disks used. DVD- RW DVD Rewritable. Similar DVD- ROM. user erase rewrite disk multiple times. one- sided disks used. Blu- ray DVD High- definition video disk. Provides considerably greater data storage density DVD, using 405-nm ( blue- violet) laser. single layer single side store 25 Gbytes. 6.4 OPTICAL MEMORY 1983, one successful consumer products time introduced: compact disk (CD) digital audio system. CD nonerasable disk store 60 minutes audio information one side. huge commercial success CD enabled development low- cost optical- disk storage technol - ogy revolutionized computer data storage. variety optical- disk systems introduced (Table 6.6). briefly review these. Compact Disk cd-rom audio CD CD- ROM (compact disk read- memory) share similar technology. main difference CD- ROM players rugged error correction devices ensure data properly transferred disk computer. types disk made way. disk formed resin, polycarbonate. Digitally recorded information (either music computer data) imprinted series microscopic pits surface polycarbonate. done, first all, finely focused, high- intensity laser create master disk. master used, turn, make die stamp copies onto polycarbonate. pitted surface coated highly reflective surface, usually aluminum gold. shiny surface protected dust scratches top coat clear acrylic. Finally, label silkscreened onto acrylic.218 cHaPteR 6 / exteRnal MoRy Information retrieved CD CD- ROM low- powered laser housed optical- disk player, drive unit. laser shines clear polycarbonate motor spins disk past (Figure 6.9). intensity reflected light laser changes encounters pit. Specifically, laser beam falls pit, somewhat rough surface, light scatters low intensity reflected back source. areas pits called lands . land smooth surface, reflects back higher intensity. change pits lands detected photosensor converted digital signal. sensor tests surface regular intervals. beginning end pit represents 1; change elevation occurs intervals, 0 recorded. Recall magnetic disk, information recorded concentric tracks. simplest constant angular velocity (CAV) system, number bits per track constant. increase density achieved multiple zone recording , surface divided number zones, zones farther center containing bits zones closer center. Although technique increases capacity, still optimal. achieve greater capacity, CDs CD- ROMs organize information concentric tracks. Instead, disk contains single spiral track, beginning near center spiraling outer edge disk. Sectors near outside disk length near inside. Thus, information packed evenly across disk segments size scanned rate rotating disk variable speed. pits read laser constant linear velocity (CLV) . disk rotates slowly accesses near outer edge near center. Thus, capacity track rotational delay increase positions nearer outer edge disk. data capacity CD- ROM 680 MB. Data CD- ROM organized sequence blocks. typical block format shown Figure 6.10. consists following fields: ■Sync: sync field identifies beginning block. consists byte 0s, 10 bytes 1s, byte 0s. ■Header: header contains block address mode byte. Mode 0 specifies blank data field; mode 1 specifies use error- correcting Polycarbonate plasticProtective acrylic Aluminum Laser transmit/ receivePitLandLabel Figure 6.9 CD Operation6.4 / oPtical MoRy 219 00 00 Data 12 bytes SYNC4 bytes ID2048 bytes Data288 bytes L-ECCLayer ed ECCMIN SEC Sector ModeFF ... FF 2352 bytes Figure 6.10 CD- ROM Block Format code 2048 bytes data; mode 2 specifies 2336 bytes user data error- correcting code. ■Data: User data. ■Auxiliary: Additional user data mode 2. mode 1, 288-byte error- correcting code. use CLV, random access becomes difficult. Locating spe - cific address involves moving head general area, adjusting rotation speed reading address, making minor adjustments find access specific sector. CD- ROM appropriate distribution large amounts data large number users. expense initial writing process, appropriate individualized applications. Compared traditional magnetic disks, CD- ROM two advantages: ■The optical disk together information stored mass repli - cated inexpensively— unlike magnetic disk. database magnetic disk reproduced copying one disk time using two disk drives. ■The optical disk removable, allowing disk used archi - val storage. magnetic disks nonremovable. information non - removable magnetic disks must first copied another storage medium disk drive/disk used store new information. disadvantages CD- ROM follows: ■It read- cannot updated. ■It access time much longer magnetic disk drive, much half second. cd recordable accommodate applications one small number copies set data needed, write- read- many CD, known CD recordable ( CD- R), developed. CD- R, disk prepared way subsequently written laser beam modest-intensity. Thus, somewhat expensive disk controller CD- ROM, customer write well read disk. CD- R medium similar identical CD CD- ROM. CDs CD- ROMs, information recorded pitting surface 220 cHaPteR 6 / exteRnal MoRy medium, changes reflectivity. CD- R, medium includes dye layer. dye used change reflectivity activated high- intensity laser. resulting disk read CD- R drive CD- ROM drive. CD- R optical disk attractive archival storage documents files. provides permanent record large volumes user data. cd rewritable CD- RW optical disk repeatedly written overwritten, magnetic disk. Although number approaches tried, pure optical approach proved attractive called phase change . phase change disk uses material two significantly different reflectivities two different phase states. amorphous state, molecules exhibit random orientation reflects light poorly; crystalline state, smooth surface reflects light well. beam laser light change material one phase other. primary disadvantage phase change optical disks material eventually permanently loses desirable properties. Current materials used 500,000 1,000,000 erase cycles. CD- RW obvious advantage CD- ROM CD- R rewritten thus used true secondary storage. such, competes magnetic disk. key advantage optical disk engineering tolerances optical disks much less severe high- capacity magnetic disks. Thus, exhibit higher reliability longer life. Digital Versatile Disk capacious digital versatile disk (DVD), electronics industry last found acceptable replacement analog VHS video tape. DVD replaced videotape used video cassette recorders (VCRs) and, import - ant discussion, replaced CD- ROM personal computers servers. DVD takes video digital age. delivers movies impressive picture quality, randomly accessed like audio CDs, DVD machines also play. Vast volumes data crammed onto disk, currently seven times much CD- ROM. DVD’s huge storage capacity vivid quality, PC games become realistic educational software incorporates video. Following wake developments new crest traffic Internet corporate intranets, material incorporated Web sites. DVD’s greater capacity due three differences CDs (Figure 6.11): 1. Bits packed closely DVD. spacing loops spiral CD 1.6 mm minimum distance pits along spiral 0.834 mm. DVD uses laser shorter wavelength achieves loop spacing 0.74 mm minimum distance pits 0.4 mm. result two improvements seven- fold increase capacity, 4.7 GB. 2. DVD employs second layer pits lands top first layer. dual- layer DVD semireflective layer top reflective layer, adjusting focus, lasers DVD drives read layer separately. technique almost doubles capacity disk, 8.5 GB. lower reflectivity second layer limits storage capacity full doubling achieved.6.4 / oPtical MoRy 221 1.2 mm thick 1.2 mm thickLabel Protective layer (acrylic) Re/f_lective layer (aluminum) Polycarbonate substrate (plastic) Polycarbonate substrate, side 2 Semir e/f_lective layer , side 2 Polycarbonate layer , side 2 Fully r e/f_lective layer , side 2 Fully r e/f_lective layer , side 1 Polycarbonate layer , side 1 Semir e/f_lective layer , side 1 Polycarbonate substrate, side 1Laser f ocuses polycarbonate pits fr ont r e/f_lective layer (a) CD-R OM–Capacity 682 MB (b) VD-R OM, double-sided, dual-la yer–Capacit 17 GBLaser f ocuses pits one layer one side time. Disk must /f_lipped r ead side Figure 6.11 CD- ROM DVD- ROM 3. DVD- ROM two sided, whereas data recorded one side CD. brings total capacity 17 GB. CD, DVDs come writeable well read- versions (Table 6.6). High- Definition Optical Disks High- definition optical disks designed store high- definition videos pro - vide significantly greater storage capacity compared DVDs. higher bit density achieved using laser shorter wavelength, blue- violet range. data pits, constitute digital 1s 0s, smaller high- definition optical disks compared DVD shorter laser wavelength. Two competing disk formats technologies initially competed market acceptance: HD DVD Blu- ray DVD. Blu- ray scheme ultimately achieved market dominance. HD DVD scheme store 15 GB single layer single side. Blu- ray positions data layer disk closer laser (shown right- hand side diagram Figure 6.12). enables tighter focus less distortion thus smaller pits tracks. Blu- ray store 25 GB single layer. Three versions available: read ( BD- ROM), recordable ( BD- R), rerecordable ( BD- RE).222 cHaPteR 6 / exteRnal MoRy 6.5 MAGNETIC TAPE Tape systems use reading recording techniques disk systems. medium flexible polyester (similar used clothing) tape coated magnetizable material. coating may consist particles pure metal special binders vapor- plated metal films. tape tape drive analogous home tape recorder system. Tape widths vary 0.38 cm (0.15 inch) 1.27 cm (0.5 inch). Tapes used packaged open reels threaded second spindle use. Today, virtually tapes housed cartridges. Data tape structured number parallel tracks running length - wise. Earlier tape systems typically used nine tracks. made possible store data one byte time, additional parity bit ninth track. followed tape systems using 18 36 tracks, corresponding digital word double word. recording data form referred parallel recording . modern systems instead use serial recording , data laid sequence bits along track, done magnetic disks. disk, data read written contiguous blocks, called physical records , tape. Blocks tape separated gaps referred interrecord gaps. disk, tape formatted assist locating physical records. typical recording technique used serial tapes referred serpen- tine recording . technique, data recorded, first set bits recorded along whole length tape. end tape reached, Beam spotLandData layer Laser wa velength = 780 nm 650 nm405 nmCD2.11 µm DVD Blu-ray1.2 µm Pit Track 0.6 µm0.1 µm1.32 µm0.58 µm Figure 6.12 Optical Memory Characteristics6.5 / Magnetic taPe 223 Bottom edge tapeDirection read–write (a) Serpentine reading writingTrack 0 Direction tape motion (b) Block layout system reads–writes four tracks simultaneouslyTrack 0Track 1Track 2Track 3Track 1Track 2 4 8 12 16 20 3 7 11 15 19 2 6 10 14 18 1 5 9 13 17 Figure 6.13 Typical Magnetic Tape Featuresthe heads repositioned record new track, tape recorded whole length, time opposite direction. process continues, back forth, tape full (Figure 6.13a). increase speed, read- write head capable reading writing number adjacent tracks simultaneously (typ - ically two eight tracks). Data still recorded serially along individual tracks, blocks sequence stored adjacent tracks, suggested Figure 6.13b. tape drive sequential- access device. tape head positioned record 1, read record N, necessary read physical records 1 N-1, one time. head currently positioned beyond desired record, necessary rewind tape certain distance begin reading forward. Unlike disk, tape motion read write operation. contrast tape, disk drive referred direct- access device. disk drive need read sectors disk sequentially get desired one. must wait intervening sectors within one track make successive accesses track. Magnetic tape first kind secondary memory. still widely used lowest- cost, slowest- speed member memory hierarchy.224 cHaPteR 6 / exteRnal MoRy dominant tape technology today cartridge system known linear tape- open (LTO). LTO developed late 1990s open- source alterna - tive various proprietary systems market. Table 6.7 shows parameters various LTO generations. See Appendix J details. 6.6 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key TermsTable 6.7 LTO Tape Drives LTO- 1 LTO- 2 LTO- 3 LTO- 4 LTO- 5 LTO- 6 LTO- 7 LTO- 8 Release date 2000 2003 2005 2007 2010 2012 TBA TBA Compressed capacity200 GB 400 GB 800 GB 1600 GB 3.2 TB 8 TB 16 TB 32 TB Compressed transfer rate40 MB/s80 MB/s160 MB/s240 MB/s280 MB/s400 MB/s788 MB/s1.18 GB/s Linear density (bits/mm)4880 7398 9638 13,250 15,142 15,143 Tape tracks 384 512 704 896 1280 2176 Tape length (m) 609 609 680 820 846 846 Tape width (cm)1.27 1.27 1.27 1.27 1.27 1.27 Write elements 8 8 16 16 16 16 WORM? Yes Yes Yes Yes Yes Yes Encryption Capable?No Yes Yes Yes Yes Yes Partitioning? Yes Yes Yes Yes access time Blu- ray CD CD- R CD- ROM CD- RW constant angular velocity (CA V) constant linear velocity (CL V) cylinder DVD DVD- R DVD- ROM DVD- RW fixed- head disk flash memory floppy disk gap hard disk drive (HDD) head land magnetic disk magnetic tape magnetoresistive movable- head disk multiple zone recording nonremovable diskoptical memory pit platter RAID removable disk rotational delay sector seek time serpentine recording solid state drive (SSD) striped data substrate track transfer time6.6 / key teRMs, Review Questions, PRoble Ms 225 Review Questions 6.1 advantages using glass substrate magnetic disk? 6.2 data written onto magnetic disk? 6.3 data read magnetic disk? 6.4 Explain difference simple CA V system multiple zone recording system. 6.5 Define terms track, cylinder, sector . 6.6 typical disk sector size? 6.7 Define terms seek time, rotational delay, access time, transfer time . 6.8 common characteristics shared RAID levels? 6.9 Briefly define seven RAID levels. 6.10 Explain term striped data . 6.11 redundancy achieved RAID system? 6.12 context RAID, distinction parallel access indepen - dent access? 6.13 difference CA V CL V? 6.14 differences CD DVD account larger capacity latter? 6.15 Explain serpentine recording. Problems 6.1 Justify Equation 6.1. is, explain three terms right- hand side equation contributes value left- hand side. 6.2 Consider disk N tracks numbered 0 (N-1) assume requested sectors distributed randomly evenly disk. want calculate average number tracks traversed seek. a. First, calculate probability seek length j head currently positioned track t. Hint : matter determining total number combinations, recognizing track positions destination seek equally likely. b. Next, calculate probability seek length K. Hint : involves sum - ming possible combinations movements K tracks. c. Calculate average number tracks traversed seek, using formula expected value E[x]=aN-1 i=0i*Pr[x=i] Hint : Use equalities: i=1i=n(n+1) 2; i=1i2=n(n+1)(2n+1) 6. d. Show large values N, average number tracks traversed seek approaches N/3. 6.3 Define following disk system: ts=seek time; average time position head track r=rotation speed disk, revolutions per second n=number bits per sector N=capacity track, bits tsector=time access sector Develop formula tsector function parameters.226 cHaPteR 6 / exteRnal MoRy 6.4 Consider magnetic disk drive 8 surfaces, 512 tracks per surface, 64 sectors per track. Sector size 1 kB. average seek time 8 ms, track- to- track access time 1.5 ms, drive rotates 3600 rpm. Successive tracks cylinder read without head movement. a. disk capacity? b. average access time? Assume file stored successive sectors tracks successive cylinders, starting sector 0, track 0, cylinder i. c. Estimate time required transfer 5-MB file. d. burst transfer rate? 6.5 Consider single- platter disk following parameters: rotation speed: 7200 rpm; number tracks one side platter: 30,000; number sectors per track: 600; seek time: one ms every hundred tracks traversed. Let disk receive request access random sector random track assume disk head starts track 0. a. average seek time? b. average rotational latency? c. transfer time sector? d. total average time satisfy request? 6.6 distinction made physical records logical records. logical record collection related data elements treated conceptual unit, independent information stored. physical record contiguous area storage space defined characteristics storage device operating system. Assume disk system physical record contains thirty 120-byte logical records. Calculate much disk space (in sectors, tracks, surfaces) required store 300,000 logical records disk fixed- sector 512 bytes/sec - tor, 96 sectors/track, 110 tracks per surface, 8 usable surfaces. Ignore file header record(s) track indexes, assume records cannot span two sectors. 6.7 Consider disk rotates 3600 rpm. seek time move head adjacent tracks 2 ms. 32 sectors per track, stored linear order sector 0 sector 31. head sees sectors ascending order. Assume read/write head positioned start sector 1 track 8. main memory buffer large enough hold entire track. Data transferred disk locations reading source track main memory buffer writing data buffer target track. a. long take transfer sector 1 track 8 sector 1 track 9? b. long take transfer sectors track 8 corresponding sectors track 9? 6.8 clear disk striping improve data transfer rate strip size small compared I/O request size. also clear RAID 0 provides improved performance relative single large disk, multiple I/O requests handled parallel. However, latter case, disk striping necessary? is, disk striping improve I/O request rate performance compared comparable disk array without striping? 6.9 Consider 4-drive, 200 GB- per- drive RAID array. available data storage capacity RAID levels 0, 1, 3, 4, 5, 6? 6.10 compact disk, audio converted digital 16-bit samples, treated stream 8-bit bytes storage. One simple scheme storing data, called direct recording, would represent 1 land 0 pit. Instead, byte expanded 14-bit binary number. turns exactly 256 (28) total 16,134 (214) 14-bit numbers least two 0s every pair 1s, numbers selected expansion 8 14 bits. optical system detects presence 1s detecting transition pit land land pit. detects 0s measuring distances intensity changes. scheme requires 1s succession; hence use 8- to- 14 code.6.6 / key teRMs, Review Questions, PRoble Ms 227 advantage scheme follows. given laser beam diameter, minimum- pit size, regardless bits represented. scheme, minimum- pit size stores 3 bits, least two 0s follow every 1. direct recording, pit would able store one bit. Considering number bits stored per pit 8- to- 14 bit expansion, scheme stores bits factor? 6.11 Design backup strategy computer system. One option use plug- external disks, cost $150 500 GB drive. Another option buy tape drive $2500, 400 GB tapes $50 apiece. (These realistic prices 2008.) typical backup strategy two sets backup media onsite, backups alternately written case system fails making backup, previous ver - sion still intact. There’s also third set kept offsite, offsite set periodically swapped on- site set. a. Assume 1 TB (1000 GB) data back up. much would disk backup system cost? b. much would tape backup system cost 1 TB? c. large would backup order tape strategy less expensive? d. kind backup strategy favors tapes?Input/Output 7.1 External Devices 7.2 I/O Modules 7.3 Programmed I/O 7.4 Interrupt- Driven I/O 7.5 Direct Memory Access 7.6 Direct Cache Access 7.7 I/O Channels Processors 7.8 External Interconnection Standards 7.9 IBM zEnterprise EC12 I/O Structure 7.10 Key Terms, Review Questions, Problems Chapter 228Input/Output 229 I/O System Design Tool addition processor set memory modules, third key element computer system set I/O modules. module interfaces system bus central switch controls one peripheral devices. I/O module simply set mechanical connectors wire device system bus. Rather, I/O module contains logic performing communication function peripheral bus. reader may wonder one connect peripherals directly system bus. reasons follows: ■There wide variety peripherals various methods operation. would impractical incorporate necessary logic within processor control range devices. ■The data transfer rate peripherals often much slower memory processor. Thus, impractical use high- speed system bus communicate directly peripheral. ■On hand, data transfer rate peripherals faster memory processor. Again, mismatch would lead ineffi - ciencies managed properly. ■Peripherals often use different data formats word lengths com - puter attached. ■Thus, I/O module required. module two major functions (Figure 7.1): ■Interface processor memory via system bus central switch. ■Interface one peripheral devices tailored data links. begin chapter brief discussion external devices, followed overview structure function I/O module. look various ways I/O function performed cooperation processor memory: internal I/O interface. Next, examine Learning Objectives studying chapter, able to: rExplain use I/O modules part computer organization. rUnderstand difference programmed I/O interrupt- driven I/O discuss relative merits. rPresent overview operation direct memory access. rPresent overview direct cache access. rExplain function use I/O channels.230 Chapter 7 / Input/Output detail direct memory access recent innovation direct cache access. Finally, examine external I/O interface, I/O module outside world. 7.1 ExtErnal EvicEs I/O operations accomplished wide assortment external devices provide means exchanging data external environment computer. external device attaches computer link I/O module (Figure 7 .1). link used exchange control, status, data I/O module external device. external device connected I/O module often referred peripheral device or, simply, peripheral. broadly classify external devices three categories: ■Human readable: Suitable communicating computer user; ■Machine readable: Suitable communicating equipment; ■Communication: Suitable communicating remote devices. Examples human- readable devices video display terminals (VDTs) printers. Examples machine- readable devices magnetic disk tape sys - tems, sensors actuators, used robotics application. Note viewing disk tape systems I/O devices chapter, whereas Chapter 6 viewed memory devices. functional point view, devices part memory hierarchy, use appropriately dis - cussed Chapter 6. structural point view, devices controlled I/O modules hence considered chapter.I/O module Links peripheral devicesContr ol linesData linesAddr ess lines System bus Figure 7.1 Generic Model I/O Module7.1 / external Dev ICes 231 Communication devices allow computer exchange data remote device, may human- readable device, terminal, machine- readable device, even another computer. general terms, nature external device indicated Figure 7.2. interface I/O module form control, data, status signals. Con- trol signals determine function device perform, send data I/O module (INPUT READ), accept data I/O module (OUTPUT WRITE), report status, perform control function particular device (e.g., position disk head). Data form set bits sent received I/O module. Status signals indicate state device. Examples READY/ NOT- READY show whether device ready data transfer. Control logic associated device controls device’s operation response direction I/O module. transducer converts data elec - trical forms energy output forms electrical input. Typically, buffer associated transducer temporarily hold data transferred I/O module external environment. buffer size 8 16 bits common serial devices, whereas block- oriented devices disk drive controllers may much larger buffers. interface I/O module external device exam - ined Section 7.7. interface external device environment beyond scope book, several brief examples given here. Keyboard/Monitor common means computer/user interaction keyboard/monitor arrangement. user provides input keyboard, input trans - mitted computer may also displayed monitor. addition, monitor displays data provided computer. Buffer TransducerContr ol logicContr ol signals fr om I/O moduleStatus signals I/O moduleData bits fr om I/O module Data (de vice-unique) fr om environment Figure 7.2 Block Diagram External Device232 Chapter 7 / Input/Output basic unit exchange character. Associated charac - ter code, typically 7 8 bits length. commonly used text code International Reference Alphabet (IRA).1 character code represented unique 7-bit binary code; thus, 128 different characters represented. Characters two types: printable control. Printable char - acters alphabetic, numeric, special characters printed paper displayed screen. control characters controlling printing displaying characters; example carriage return. control characters concerned communications procedures. See Appendix H details. keyboard input, user depresses key, generates elec - tronic signal interpreted transducer keyboard translated bit pattern corresponding IRA code. bit pattern trans - mitted I/O module computer. computer, text stored IRA code. output, IRA code characters transmitted exter - nal device I/O module. transducer device interprets code sends required electronic signals output device either display indicated character perform requested control function. Disk Drive disk drive contains electronics exchanging data, control, status signals I/O module plus electronics controlling disk read/write mechanism. fixed- head disk, transducer capable converting magnetic patterns moving disk surface bits device’s buffer (Figure 7 .2). moving- head disk must also able cause disk arm move radially across disk’s surface. 7.2 i/O MODulEs Module Function major functions requirements I/O module fall following categories: ■Control timing ■Processor communication ■Device communication ■Data buffering ■Error detection period time, processor may communicate one external devices unpredictable patterns, depending program’s need 1IRA defined ITU- Recommendation T.50 formerly known International Alphabet Number 5 (IA5). U.S. national version IRA referred American Standard Code Information Interchange (ASCII).7.2 / I/O ODules 233 I/O. internal resources, main memory system bus, must shared among number activities, including data I/O. Thus, I/O function includes control timing requirement, coordinate flow traffic internal resources external devices. example, control transfer data external device processor might involve following sequence steps: 1. processor interrogates I/O module check status attached device. 2. I/O module returns device status. 3. device operational ready transmit, processor requests transfer data, means command I/O module. 4. I/O module obtains unit data (e.g., 8 16 bits) external device. 5. data transferred I/O module processor. system employs bus, interactions proces - sor I/O module involves one bus arbitrations. preceding simplified scenario also illustrates I/O module must communicate processor external device. Processor communi - cation involves following: ■Command decoding: I/O module accepts commands processor, typically sent signals control bus. example, I/O module disk drive might accept following commands: READ SECTOR, WRITE SECTOR, SEEK track number, SCAN record ID. latter two com - mands include parameter sent data bus. ■Data: Data exchanged processor I/O module data bus. ■Status reporting: peripherals slow, important know status I/O module. example, I/O module asked send data processor (read), may ready still working previous I/O command. fact reported status signal. Common status signals BUSY READY. may also signals report various error conditions. ■Address recognition: word memory address, I/O device. Thus, I/O module must recognize one unique address peripheral controls. side, I/O module must able perform device communication . communication involves commands, status information, data (Figure 7.2). essential task I/O module data buffering . need func - tion apparent Figure 2.1. Whereas transfer rate main memory processor quite high, rate orders magnitude lower many peripheral devices covers wide range. Data coming main memory sent I/O module rapid burst. data buffered I/O module sent peripheral device data rate. opposite direction, data buffered tie memory slow transfer operation. Thus, 234 Chapter 7 / Input/Output I/O module must able operate device memory speeds. Similarly, I/O device operates rate higher memory access rate, I/O module performs needed buffering operation. Finally, I/O module often responsible error detection subse - quently reporting errors processor. One class errors includes mechanical electrical malfunctions reported device (e.g., paper jam, bad disk track). Another class consists unintentional changes bit pattern transmit - ted device I/O module. form error- detecting code often used detect transmission errors. simple example use parity bit character data. example, IRA character code occupies 7 bits byte. eighth bit set total number 1s byte even (even parity) odd (odd parity). byte received, I/O module checks parity determine whether error occurred. I/O Module Structure I/O modules vary considerably complexity number external devices control. attempt general description here. (One specific device, Intel 8255A, described Section 7 .4.) Figure 7 .3 provides general block diagram I/O module. module connects rest computer set signal lines (e.g., system bus lines). Data transferred module buffered one data registers. may also one status registers provide current status information. status register may also function control register, accept detailed control informa - tion processor. logic within module interacts processor via set control lines. processor uses control lines issue commands Status/Contr ol registersData r egistersInterface system bus I/O logic Contr ol linesAddr ess linesData lines Exter nal device interface logicData Status Contr olExter nal device interface logicData Status Contr olInterface exter nal de vice Figure 7.3 Block Diagram I/O Module7.3 / prOgraMMeD I/O 235 I/O module. control lines may used I/O module (e.g., arbitration status signals). module must also able recognize generate addresses associated devices controls. I/O module unique address or, controls one external device, unique set addresses. Finally, I/O module contains logic specific interface device controls. I/O module functions allow processor view wide range devices simple- minded way. spectrum capabilities may provided. I/O module may hide details timing, formats, electromechanics external device processor function terms simple read write commands, possibly open close file commands. simplest form, I/O module may still leave much work controlling device (e.g., rewind tape) visible processor. I/O module takes detailed processing burden, present - ing high- level interface processor, usually referred I/O channel I/O processor . I/O module quite primitive requires detailed control usually referred I/O controller device controller . I/O controllers commonly seen microcomputers, whereas I/O channels used mainframes. follows, use generic term I/O module confusion results use specific terms necessary. 7.3 PrOgraMMED i/O Three techniques possible I/O operations. programmed I/O , data exchanged processor I/O module. processor executes program gives direct control I/O operation, including sensing device status, sending read write command, transferring data. pro - cessor issues command I/O module, must wait I/O operation complete. processor faster I/O module, waste processor time. interrupt- driven I/O, processor issues I/O command , continues execute instructions, interrupted I/O module latter completed work. programmed interrupt I/O, processor responsible extracting data main memory output storing data main memory input. alternative known direct memory access (DMA) . mode, I/O module main memory exchange data directly, without processor involvement. Table 7.1 indicates relationship among three techniques. sec - tion, explore programmed I/O. Interrupt I/O DMA explored fol - lowing two sections, respectively. Table 7.1 I/O Techniques Interrupts Use Interrupts I/ O- to- memory transfer processor Programmed I/O Interrupt- driven I/O Direct I/ O- to- memory transfer Direct memory access (DMA)236 Chapter 7 / Input/Output Overview Programmed I/O processor executing program encounters instruction relating I/O, executes instruction issuing command appropriate I/O module. programmed I/O, I/O module perform requested action set appropriate bits I/O status register (Figure 7 .3). I/O module takes action alert processor. particular, interrupt pro - cessor. Thus, responsibility processor periodically check status I/O module finds operation complete. explain programmed I/O technique, view first point view I/O commands issued processor I/O module, point view I/O instructions executed processor. I/O Commands execute I/ O- related instruction, processor issues address, specifying particular I/O module external device, I/O command. four types I/O commands I/O module may receive addressed processor: ■Control: Used activate peripheral tell do. example, magnetic- tape unit may instructed rewind move forward one record. commands tailored particular type peripheral device. ■Test: Used test various status conditions associated I/O module peripherals. processor want know peripheral inter - est powered available use. also want know recent I/O operation completed errors occurred. ■Read: Causes I/O module obtain item data peripheral place internal buffer (depicted data register Figure 7.3). processor obtain data item requesting I/O module place data bus. ■Write: Causes I/O module take item data (byte word) data bus subsequently transmit data item peripheral. Figure 7.4a gives example use programmed I/O read block data peripheral device (e.g., record tape) memory. Data read one word (e.g., 16 bits) time. word read in, processor must remain status- checking cycle determines word available I/O module’s data register. flowchart highlights main disadvantage technique: time- consuming process keeps processor busy needlessly. I/O Instructions programmed I/O, close correspondence I/ O- related instructions processor fetches memory I/O commands processor issues I/O module execute instructions. is, instructions easily mapped I/O commands, often simple one- to- one rela - tionship. form instruction depends way external devices addressed.7.3 / prOgraMMeD I/O 237 Typically, many I/O devices connected I/O modules system. device given unique identifier address. processor issues I/O command, command contains address desired device. Thus, I/O module must interpret address lines determine com - mand itself. processor, main memory, I/O share common bus, two modes addressing possible: memory mapped isolated. memory- mapped I/O, single address space memory locations I/O devices. pro - cessor treats status data registers I/O modules memory locations uses machine instructions access memory I/O devices. So, example, 10 address lines, combined total 210=1024 memory locations I/O addresses supported, combination. memory- mapped I/O, single read line single write line needed bus. Alternatively, bus may equipped memory read write plus input output command lines. command line specifies whether address refers memory location I/O device. full range addresses may available both. Again, 10 address lines, system may support 1024 memory locations 1024 I/O addresses. address space I/O isolated memory, referred isolated I/O .Issue Read command I/O module Read status I/O module Check status Read word I/O module Write word memory Done? Next instruction (a) Programmed I/OCPU I/O CPU memoryI/O CPU I/O CPUError condition Ready Ready Yes YesNoNot readyIssue Read command I/O moduleDo something else InterruptRead status I/O module Check status Read word I/O Module Write word memory Done? Next instruction (b) Interrupt-driven I/OCPU memoryDo something else InterruptCPU DMA DMA CPU I/O CPUError condition NoIssue Read block command I/O module Read status DMA module Next instruction (c) Direct memory accessCPU I/O I/O CPU Figure 7.4 Three Techniques Input Block Data238 Chapter 7 / Input/Output Figure 7.5 contrasts two programmed I/O techniques. Figure 7.5a shows interface simple input device terminal keyboard might appear programmer using memory- mapped I/O. Assume 10-bit address, 512-bit memory (locations 0–511) 512 I/O addresses (locations 512–1023). Two addresses dedicated keyboard input particular terminal. Address 516 refers data register address 517 refers status register, also func - tions control register receiving processor commands. program shown read 1 byte data keyboard accumulator register processor. Note processor loops data byte available. isolated I/O (Figure 7.5b), I/O ports accessible special I/O commands, activate I/O command lines bus. types processors, relatively large set different instruc - tions referencing memory. isolated I/O used, I/O instructions. Thus, advantage memory- mapped I/O large repertoire instructions used, allowing efficient programming. disadvantage valuable memory address space used up. memory- mapped isolated I/O common use. 76 5 516 Keyboard input data r egister4321 0 76 5 517 (a) Memory-mapped I/OKeyboard input status contr ol register 1 = r eady 0 = busy4321 0 Set 1 start r ead ADDRESS INSTR UCTION OPERAND COMMENT 200 Load AC “1” Load accumulator Store AC 517 Initiate keyboard r ead 202 Load AC 517 Get status byte Branch Sign = 0 202 Loop r eady Load AC 516 Load data byte (b) Isolated I/O ADDRESS INSTR UCTION OPERAND COMMENT 200 Load I/O 5 Initiate keyboard r ead 201 Test I/O 5 Check f completion Branch Ready 201 Loop complete 5 Load data byte Figure 7.5 Memory- Mapped Isolated I/O7.4 / Inter ruptt-DrIven I/O 239 7.4 intErruPt- Driv En i/O problem programmed I/O processor wait long time I/O module concern ready either reception transmission data. processor, waiting, must repeatedly interrogate status I/O module. result, level performance entire system severely degraded. alternative processor issue I/O command module go useful work. I/O module interrupt processor request service ready exchange data processor. processor executes data transfer, before, resumes - mer processing. Let us consider works, first point view I/O module. input, I/O module receives READ command processor. I/O module proceeds read data associated peripheral. data module’s data register, module signals interrupt processor control line. module waits data requested pro - cessor. request made, module places data data bus ready another I/O operation. processor’s point view, action input follows. pro - cessor issues READ command. goes something else (e.g., processor may working several different programs time). end instruction cycle, processor checks interrupts (Figure 3.9). interrupt I/O module occurs, processor saves context (e.g., pro - gram counter processor registers) current program processes interrupt. case, processor reads word data I/O module stores memory. restores context program working (or program) resumes execution. Figure 7.4b shows use interrupt I/O reading block data. Compare Figure 7.4a. Interrupt I/O efficient programmed I/O eliminates needless waiting. However, interrupt I/O still consumes lot processor time, every word data goes memory I/O module I/O module memory must pass processor. Interrupt Processing Let us consider role processor interrupt- driven I/O detail. occurrence interrupt triggers number events, processor hard - ware software. Figure 7 .6 shows typical sequence. I/O device com - pletes I/O operation, following sequence hardware events occurs: 1. device issues interrupt signal processor. 2. processor finishes execution current instruction responding interrupt, indicated Figure 3.9. 3. processor tests interrupt, determines one, sends acknowledgment signal device issued interrupt. acknowl - edgment allows device remove interrupt signal.240 Chapter 7 / Input/Output 4. processor needs prepare transfer control interrupt rou - tine. begin, needs save information needed resume current pro - gram point interrupt. minimum information required (a) status processor, contained register called program status word (PSW) ; (b) location next instruction executed, contained program counter. pushed onto sys - tem control stack.2 5. processor loads program counter entry location interrupt- handling program respond interrupt. Depending computer architecture operating system design, may single program; one program type interrupt; one program device type interrupt. one interrupt- handling routine, processor must determine one invoke. information may included original interrupt signal, processor may issue request device issued interrupt get response contains needed information.Device controller system hardware issues interrupt Processor /f_inishes execution current instruction Processor signals acknowledgment interrupt Processor pushes PSW PC onto control stack Processor loads new PC value based interruptSave remainder process state information Process interrupt Restore process state information Restore old PSW PCHardware Software Figure 7.6 Simple Interrupt Processing 2See Appendix discussion stack operation.7.4 / Inter ruptt-DrIven I/O 241 program counter loaded, processor proceeds next instruction cycle, begins instruction fetch. instruc - tion fetch determined contents program counter, result control transferred interrupt- handler program. execution pro - gram results following operations: 6. point, program counter PSW relating interrupted pro - gram saved system stack. However, infor - mation considered part “state” executing program. particular, contents processor registers need saved, registers may used interrupt handler. So, values, plus state information, need saved. Typically, interrupt handler begin saving contents registers stack. Fig - ure 7.7a shows simple example. case, user program interrupted instruction location N. contents registers plus address next instruction (N+1) pushed onto stack. stack pointer updated point new top stack, program counter updated point beginning interrupt service routine. 7. interrupt handler next processes interrupt. includes exam - ination status information relating I/O operation event caused interrupt. may also involve sending additional commands acknowledgments I/O device. 8. interrupt processing complete, saved register values retrieved stack restored registers (e.g., see Figure 7.7b). 9. final act restore PSW program counter values stack. result, next instruction executed previously interrupted program. Note important save state information interrupted program later resumption. interrupt routine called program. Rather, interrupt occur time therefore point execution user program. occurrence unpredictable. Indeed, see next chapter, two programs may anything common may belong two different users. Design Issues Two design issues arise implementing interrupt I/O. First, almost invariably multiple I/O modules, processor determine device issued interrupt? second, multiple interrupts occurred, processor decide one process? Let us consider device identification first. Four general categories tech - niques common use: ■Multiple interrupt lines ■Software poll ■Daisy chain (hardware poll, vectored) ■Bus arbitration (vectored)242 Chapter 7 / Input/Output straightforward approach problem provide multiple inter - rupt lines processor I/O modules. However, impractical dedicate bus lines processor pins interrupt lines. Consequently, even multiple lines used, likely line multiple I/O mod - ules attached it. Thus, one three techniques must used line. One alternative software poll . processor detects interrupt, branches interrupt- service routine polls I/O module determine module caused interrupt. poll could form separate com - mand line (e.g., TESTI/O). case, processor raises TESTI/O places address particular I/O module address lines. I/O module responds positively set interrupt. Alternatively, I/O module could contain addressable status register. processor reads status register I/O module identify interrupting module. correct module identified, processor branches device- service routine specific device.Start N + 1Y + L NYY Return User’s program Main MemoryProcessorGeneral registersProgram counter Stack pointerN + 1T – – MTControl stack Interrupt service routine User’s programInterrupt service routine (a) Interrupt occurs instruction location N(b) Return interruptStart N + 1Y + L NYT Return Main MemoryProcessorGeneral registersProgram counter Stack pointerY + LT – – TControl stackN + 1 Figure 7.7 Changes Memory Registers Interrupt7.4 / Inter ruptt-DrIven I/O 243 disadvantage software poll time consuming. efficient technique use daisy chain , provides, effect, hardware poll. example daisy- chain configuration shown Figure 3.26. interrupts, I/O modules share common interrupt request line. interrupt acknowledge line daisy chained modules. processor senses interrupt, sends interrupt acknowledge. signal propagates series I/O modules gets requesting module. requesting module typically responds placing word data lines. word referred vector either address I/O module unique identifier. either case, processor uses vector pointer appropriate device- service routine. avoids need execute general interrupt- service routine first. technique called vectored interrupt. another technique makes use vectored interrupts, bus arbitration . bus arbitration, I/O module must first gain control bus raise interrupt request line. Thus, one module raise line time. processor detects interrupt, responds interrupt acknowledge line. requesting module places vector data lines. aforementioned techniques serve identify requesting I/O module. also provide way assigning priorities one device request - ing interrupt service. multiple lines, processor picks interrupt line highest priority. software polling, order modules polled determines priority. Similarly, order modules daisy chain determines priority. Finally, bus arbitration employ priority scheme, discussed Section 3.4. turn two examples interrupt structures. Intel 82C59A Interrupt Controller Intel 80386 provides single Interrupt Request (INTR) single Interrupt Acknowledge (INTA) line. allow 80386 handle variety devices priority structures, usually configured external interrupt arbiter, 82C59A. External devices connected 82C59A, turn connects 80386. Figure 7.8 shows use 82C59A connect multiple I/O modules 80386. single 82C59A handle eight modules. control eight modules required, cascade arrangement used handle 64 modules. 82C59A’s sole responsibility management interrupts. accepts interrupt requests attached modules, determines interrupt highest priority, signals processor raising INTR line. pro - cessor acknowledges via INTA line. prompts 82C59A place appropriate vector information data bus. processor proceed process interrupt communicate directly I/O module read write data. 82C59A programmable. 80386 determines priority scheme used setting control word 82C59A. following interrupt modes possible: ■Fully nested: interrupt requests ordered priority 0 (IR0) 7 (IR7).244 Chapter 7 / Input/Output ■Rotating: applications number interrupting devices equal priority. mode device, serviced, receives lowest prior - ity group. ■Special mask: allows processor inhibit interrupts certain devices.External device 00Slave 82C59A interrupt controller External device 07IR0 IR1 INT IR2 IR3 IR4 IR5 IR6 IR7External device 01 External device 08Slave 82C59A interrupt controller External device 15IR0 IR1 INT IR2 IR3 IR4 IR5 IR6 IR7Master 82C59A interrupt controller IR0 IR1 INT IR2 IR3 IR4 IR5 IR6 IR7External device 0980386 processor INTR External device 56Slave 82C59A interrupt controller External device 63IR0 IR1 INT IR2 IR3 IR4 IR5 IR6 IR7External device 57 Figure 7.8 Use 82C59A Interrupt Controller7.4 / Inter ruptt-DrIven I/O 245 Intel 8255A Programmable Peripheral Interface example I/O module used programmed I/O interrupt- driven I/O, consider Intel 8255A Programmable Peripheral Interface. 8255A single- chip, general- purpose I/O module originally designed use Intel 80386 processor. since cloned manufacturers widely used peripheral controller chip. uses include controller simple I/O devices microprocessors embedded systems, including microcontroller systems. architecture operation Figure 7.9 shows general block diagram plus pin assignment 40-pin package housed. shown pin layout, 8255A includes following lines: ■D0–D7: data I/O lines device. information read written 8255A occurs via eight data lines. ■CS (Chip Select Input): line logical 0, microprocessor read write 8255A. ■RD (Read Input): line logical 0 CS input logical 0, 8255A data outputs enabled onto system data bus. ■WR (Write Input): input line logical 0 CS input logical 0, data written 8255A system data bus. ■RESET: 8255A placed reset state input line logical 1. peripheral ports set input mode. PA4 1 PA34 0 (b) Pin layoutPA5 2 PA23 9 PA6 3 PA13 8 PA7 4 PA03 7 WR 5 RD 36 Reset 6 CS 35 D0 7 GND3 4 D1 8 A1 33 D2 9 A0 32 D3 10 PC73 1 D4 11 PC68255A 30 D5 12 PC52 9 D6 13 PC42 8 D7 14 PC32 7 V 15 PC22 6 PB7 16 PC12 5 PB6 17 PC02 4 PB5 18 PB0 23 PB4 19 PB1 22 PB3 20 PB2 21Data bus bufferPower supplies Bi-directional data bus 8-bit internal data busD7–D0I/O PA7–PA0 I/O PC7–PC4 I/O PC3–PC0 I/O PB7–PB0RD WR A1 A0 Reset CSGroup controlGroup port (8) Group B port B (8)Group port C upper (4) Group B port C lower (4) Group B controlRead/ write control logic (a) Block diagram+5 V GND Figure 7.9 Intel 8255A Programmable Peripheral Interface246 Chapter 7 / Input/Output ■PA0–PA7, PB0–PB7, PC0–PC7: signal lines used 8-bit I/O ports. connected peripheral devices. ■A0, A1: logical combination two input lines determine internal register 8255A data written read from. right side block diagram Figure 7.9a external interface 8255A. 24 I/O lines divided three 8-bit groups (A, B, C). group function 8-bit I/O port, thus providing connection three periph - eral devices. addition, group C subdivided 4-bit groups ( CA CB), may used conjunction B I/O ports. Configured manner, group C lines carry control status signals. left side block diagram internal interface microproces - sor system bus. includes 8-bit bidirectional data bus (D0 D7), used transfer data microprocessor I/O ports transfer control information. processor controls 8255A means 8-bit control register processor. processor set value control register specify variety operating modes configurations. processor point view, control port, control register bits set processor sent control port lines D0–D7. two address lines specify one three I/O ports control register, follows: A1 A2 Selects 0 0 Port 0 1 Port B 1 0 Port C 1 1 Control register Thus, processor sets A1 A2 1, 8255A interprets 8-bit value data bus control word. processor transfers 8-bit control word line D7 set 1 (Figure 7.10a), control word used config - ure operating mode 24 I/O lines. three modes are: ■Mode 0: basic I/O mode. three groups eight external lines function three 8-bit I/O ports. port designated input - put. Data may sent port port defined output, data may read port port set input. ■Mode 1: mode, ports B configured either input output, lines port C serve control lines B. control signals serve two principal purposes: “handshaking” interrupt request. Handshaking simple timing mechanism. One control line used sender DATA READY line, indicate data present I/O data lines. Another line used receiver ACKNOWLEDGE, indicating data read data lines may cleared. Another line may designated INTERRUPT REQUEST line tied back system bus.7.4 / Inter ruptt-DrIven I/O 247 ■Mode 2: bidirectional mode. mode, port configured either input output lines bidirectional traffic port B, port B lines providing opposite direction. Again, port C lines used control signaling. processor sets D7 0 (Figure 7.10b), control word used program bit values port C individually. feature rarely used. keyboard /display example 8255A programmable via control register, used control variety simple peripheral devices. Figure 7.11 illustrates use control keyboard/display terminal. keyboard provides 8 bits input. Two bits, SHIFT CONTROL, special meaning keyboard- handling program executing processor. However, interpretation transparent 8255A, simply accepts 8 bits data presents system data bus. Two handshaking control lines provided use keyboard. display also linked 8-bit data port. Again, two bits special meanings transparent 8255A. addition two handshaking lines, two lines provide additional control functions.D7 D6 D5 D4 D3 D2 D1 D0 D7 D6 D5 D4 D3 D2 D1 D0 Bit set/r eset 1 = set 0 = r esetBit set/r eset /f_lag 0 = Active Mode set /f_lag 1 = ActivePort C (upper) 1 = Input 0 = Output Port 1= Input 0 = Output Mode selection 00 = Mode 0 01 = Mode 1 1X = Mode 2Port C (lower) 1 = Input 0 = Output Port B 1= Input 0 = Output Mode selection 0 = Mode 0 1 = Mode 1Don’t car e Group B Group (a) Mode de/f_inition 8255 control register con/f_igure 8255(b) Bit de/f_initions 8255 control register modify single bits port CD3 0 0 0 0 1 1 1 1D2 0 0 1 1 0 0 1 1D1 0 1 0 1 0 1 0 1bit 0 port C bit 1 port C bit 2 port C bit 3 port C bit 4 port C bit 5 port C bit 6 port C bit 7 port C Figure 7.10 Intel 8255A Control Word248 Chapter 7 / Input/Output 7.5 DirEct EMOry accEss Drawbacks Programmed Interrupt- Driven I/O Interrupt- driven I/O, though efficient simple programmed I/O, still requires active intervention processor transfer data memory I/O module, data transfer must traverse path proces - sor. Thus, forms I/O suffer two inherent drawbacks: 1. I/O transfer rate limited speed processor test service device.A0 A1 A2 A3 A4 A5 A6 A7C3Interrupt request Interrupt requestC0INPUT POR TKEYBO ARD OUTPUT POR T82C55A B0 B1 B2 B3 B4 B5 B6 B7 C1 C2 C6 C7C4 C5R0 R1 R2 R3 R4 R5 Shift Contr ol Data r eady Acknowledge DISPLA YS0 S1 S2 S3 S4 S5 Backspace Clear Data r eady Acknowledge Blanking Clear line Figure 7.11 Keyboard/Display Interface 8255A7.5 / IreCt MOry aCCess 249 2. processor tied managing I/O transfer; number instructions must executed I/O transfer (e.g., Figure 7.5). somewhat trade- two drawbacks. Consider transfer block data. Using simple programmed I/O, processor dedi - cated task I/O move data rather high rate, cost nothing else. Interrupt I/O frees processor extent expense I/O transfer rate. Nevertheless, methods adverse impact processor activity I/O transfer rate. large volumes data moved, efficient technique required: direct memory access (DMA). DMA Function DMA involves additional module system bus. DMA module (Figure 7 .12) capable mimicking processor and, indeed, taking con - trol system processor. needs transfer data memory system bus. purpose, DMA module must use bus processor need it, must force processor suspend operation temporarily. latter technique common referred cycle stealing , DMA module effect steals bus cycle. processor wishes read write block data, issues command DMA module, sending DMA module following information: ■Whether read write requested, using read write control line processor DMA module. ■The address I/O device involved, communicated data lines. Addr ess register Contr ol logicData registerData count Data lines Addr ess lines Request DMA Acknowledge fr om DMA Interrupt Read Write Figure 7.12 Typical DMA Block Diagram250 Chapter 7 / Input/Output ■The starting location memory read write to, communicated data lines stored DMA module address register. ■The number words read written, communicated via data lines stored data count register. processor continues work. delegated I/O oper - ation DMA module. DMA module transfers entire block data, one word time, directly memory, without going proces - sor. transfer complete, DMA module sends interrupt signal processor. Thus, processor involved beginning end transfer (Figure 7.4c). Figure 7.13 shows instruction cycle processor may sus - pended. case, processor suspended needs use bus. DMA module transfers one word returns control processor. Note interrupt; processor save context something else. Rather, processor pauses one bus cycle. overall effect cause processor execute slowly. Nevertheless, multiple- word I/O transfer, DMA far efficient interrupt- driven programmed I/O. DMA mechanism configured variety ways. possibili - ties shown Figure 7.14. first example, modules share system bus. DMA module, acting surrogate processor, uses programmed I/O exchange data memory I/O module DMA module. configuration, may inexpensive, clearly inefficient. processor- controlled programmed I/O, transfer word consumes two bus cycles. number required bus cycles cut substantially integrating DMA I/O functions. Figure 7.14b indicates, means path DMA module one I/O modules include Processor cycle Fetch instruction Processor cycle Decode instruction Processor cycleInstruction cycleTime DMA breakpointsInterrupt breakpointFetch operandProcessor cycle Execute instruction Processor cycle Store resultProcessor cycle Process interrupt Figure 7.13 DMA Interrupt Breakpoints Instruction Cycle7.5 / IreCt MOry aCCess 251 system bus. DMA logic may actually part I/O module, may separate module controls one I/O modules. concept taken one step connecting I/O modules DMA module using I/O bus (Figure 7.14c). reduces number I/O interfaces DMA module one provides easily expandable configuration. cases (Figures 7.14b c), system bus DMA module shares processor memory used DMA module exchange data memory. exchange data DMA I/O modules takes place system bus. Intel 8237A DMA Controller Intel 8237A DMA controller interfaces 80 * 86 family processors DRAM memory provide DMA capability. Figure 7 .15 indicates location DMA module. DMA module needs use system buses (data, address, control) transfer data, sends signal called HOLD processor. processor responds HLDA (hold acknowledge) signal, indicating Processor DMA (a) Single-b us, detached DMA (b) Single-b us, inte grated DMA-I/O (c) I/O busI/O busSystem busI/O I/O Memory Processor DMA Memory I/O I/O I/OProcessor DMA DMA I/O I/O I/OMemory Figure 7.14 Alternative DMA Configurations252 Chapter 7 / Input/Output DMA module use buses. example, DMA module transfer block data memory disk, following: 1. peripheral device (such disk controller) request service DMA pulling DREQ (DMA request) high. 2. DMA put high HRQ (hold request), signaling CPU HOLD pin needs use buses. 3. CPU finish present bus cycle (not necessarily present instruc - tion) respond DMA request putting high HDLA (hold acknowledge), thus telling 8237 DMA go ahead use buses perform task. HOLD must remain active high long DMA performing task. 4. DMA activate DACK (DMA acknowledge), tells peripheral device start transfer data. 5. DMA starts transfer data memory peripheral putting address first byte block address bus activating MEMR, thereby reading byte memory data bus; activates IOW write peripheral. DMA decrements counter incre - ments address pointer repeats process count reaches zero task finished. 6. DMA finished job deactivate HRQ, signaling CPU regain control buses.CPU DACK = DMA acknowledge DREQ = DMA r equest HLD = HOLD acknowledge HRQ = HOLD r equestData bus DACKDREQ Addr ess bus Contr ol bus (IOR, IO W, MEMR, MEMW)8237 DMA chipMain memoryDisk contr ollerHRQ HLD Figure 7.15 8237 DMA Usage System Bus7.5 / IreCt MOry aCCess 253 DMA using buses transfer data, processor idle. Simi - larly, processor using bus, DMA idle. 8237 DMA known fly- DMA controller. means data moved one location another pass DMA chip stored DMA chip. Therefore, DMA transfer data I/O port memory address, two I/O ports two memory locations. However, explained subse - quently, DMA chip perform memory- to- memory transfer via register. 8237 contains four DMA channels programmed inde - pendently, one channels may active moment. chan - nels numbered 0, 1, 2, 3. 8237 set five control/command registers program control DMA operation one channels (Table 7.2): ■Command: processor loads register control operation DMA. D0 enables memory- to- memory transfer, channel 0 used transfer byte 8237 temporary register channel 1 used transfer byte register memory. memory- to- memory enabled, D1 used disable increment/decrement channel 0 fixed value written block memory. D2 enables disables DMA. ■Status: processor reads register determine DMA status. Bits D0–D3 used indicate channels 0–3 reached TC (terminal count). Bits D4–D7 used processor determine channel DMA request pending. ■Mode: processor sets register determine mode operation DMA. Bits D0 D1 used select channel. bits select various operation modes selected channel. Bits D2 D3 determine transfer I/O device memory (write) memory I/O (read), verify operation. D4 set, memory address regis - ter count register reloaded original values end DMA data transfer. Bits D6 D7 determine way 8237 used. single mode, single byte data transferred. Block demand modes used block transfer, demand mode allowing premature ending transfer. Cascade mode allows multiple 8237s cascaded expand number channels 4. ■Single Mask: processor sets register. Bits D0 D1 select chan - nel. Bit D2 clears sets mask bit channel. reg - ister DREQ input specific channel masked (disabled) unmasked (enabled). command register used disable whole DMA chip, single mask register allows programmer disable enable specific channel. ■All Mask: register similar single mask register except four channels masked unmasked one write operation. addition, 8237A eight data registers: one memory address register one count register channel. processor sets registers indi - cate location size main memory affected transfers.254 Chapter 7 / Input/Output Table 7.2 Intel 8237A Registers Bit Command Status Mode Single Mask Mask D0 Memory- to- memory E/DChannel 0 reached TC Channel selectSelect channel mask bitClear/set chan- nel 0 mask bit D1 Channel 0 address hold E/DChannel 1 reached TCClear/set chan- nel 1 mask bit D2 Controller E/D Channel 2 reached TCVerify/write/read transferClear/set mask bitClear/set chan- nel 2 mask bit D3 Normal/com- pressed timingChannel 3 reached TC usedClear/set chan- nel 3 mask bit D4 Fixed/rotating priorityChannel 0 request Auto- initialization E/D usedD5 Late/extended write selectionChannel 0 request Address increment/ decrement select D6 DREQ sense active high/lowChannel 0 request D7 DACK sense active high/lowChannel 0 request Demand/single/ block/cascade mode select E/D=enable/disable TC=terminal count 7.6 DirEct cachE accEss DMA proved effective means enhancing performance I/O periph - eral devices network I/O traffic. However, dramatic increases data rates network I/O, DMA able scale meet increased demand. demand coming primarily widespread deployment 10-Gbps 100-Gbps Ethernet switches handle massive amounts data transfer database servers high- performance systems [STAL14a]. secondary increasingly important source traffic comes Wi- Fi gigabit range. Network Wi- Fi devices handle 3.2 Gbps 6.76 Gbps becoming widely available producing demand enterprise systems [STAL14b]. section, show enabling I/O function direct access cache enhance performance, technique known direct cache access (DCA) . Throughout section, concerned cache closest main memory, referred last- level cache . systems, L2 cache, others L3 cache. begin, describe way contemporary multicore systems use on- chip shared cache enhance DMA performance. approach involves ena - bling DMA function direct access last- level cache. Next exam - ine cache- related performance issues manifest high- speed network traffic processed. there, look several different strategies DCA designed enhance network protocol processing performance. Finally, section describes DCA approach implemented Intel, referred Direct Data I/O.7.6 / IreCt CaChe aCCess 255 DMA Using Shared Last- Level Cache discussed Chapter 1 (see Figure 1.2), contemporary multicore systems include cache dedicated core additional level shared cache, either L2 L3. increasing size available last- level cache, system design - ers enhanced DMA function DMA controller access shared cache manner similar cores. clarify interaction DMA cache, useful first describe specific system architecture. pur - pose, following overview Intel Xeon system. xeon multicore processor Intel Xeon Intel’s high- end, high- performance processor family, used servers, high- performance workstations, supercomputers. Many members Xeon family use ring interconnect system, illustrated Xeon E5-2600/4600 Figure 7.16. E5-2600/4600 configured eight cores single chip. core dedicated L1 L2 caches. shared L3 cache 20 MB. L3 cache divided slices, one associated core although core address entire cache. Further, slice cache pipe - line, requests sent parallel slices. bidirectional high- speed ring interconnect links cores, last- level cache, PCIe, integrated memory controller (IMC). essence, ring operates follows: 1. component attaches bidirectional ring (QPI, PCIe, L3 cache, L2 cache) considered ring agent, implements ring agent logic. 2. ring agents cooperate via distributed protocol request allocate access ring, form time slots. 3. agent data send, chooses ring direction results shortest path destination transmits scheduling slot available. ring architecture provides good performance scales well multiple cores, point. systems greater number cores, multiple rings used, ring supporting cores. dma use cache traditional DMA operation, data exchanged main memory I/O device means system interconnection structure, bus, ring, QPI point- to- point matrix. So, example, Xeon E5-2600/4600 used traditional DMA technique, output would proceed follows. I/O driver running core would send I/O command I/O controller (labeled PCIe Figure 7.16) location size buffer main memory containing data transferred. I/O controller issues read request routed memory controller hub (MCH), accesses data DDR3 memory puts system ring delivery I/O controller. L3 cache involved transaction one off- chip memory reads required. Similarly, input, data arrive I/O controller delivered system ring MCH written main memory. MCH must also invalidate L3 cache lines corresponding updated memory locations. case, one off- chip memory writes required. Further, application wants access new data, main memory read required.256 Chapter 7 / Input/Output availability large amounts last- level cache, efficient technique possible, used Xeon E5-2600/4600. output, I/O controller issues read request, MCH first checks see data L3 cache. likely case, application recently written data memory block output. case, MCH directs data L3 cache I/O controller; main memory accesses needed. However, also causes data evicted cache, is, act reading I/O device L3 Cache (2.5 MB) L2 (256 KB) L1 (64 KB) L3 Cache (2.5 MB) L3 Cache (2.5 MB)L3 Cache (2.5 MB) L3 Cache (2.5 MB)L3 Cache (2.5 MB) L3 Cache (2.5 MB)L3 Cache (2.5 MB)Core 0Core 7 L2 (256 KB) L1 (64 KB) Core 1L2 (256 KB) L1 (64 KB) Core 2L2 (256 KB) L1 (64 KB) Core 3 L1 (64 KB)L2 (256 KB) Core 6L1 (64 KB)L2 (256 KB) Core 5L1 (64 KB)L2 (256 KB) Core 4L1 (64 KB)L2 (256 KB)QPI PCIe Memory Contr oller Hub Chip boundaryTo processor chipsTo I/O devices DDR3 memory Figure 7.16 Xeon E5-2600/4600 Chip Architecture7.6 / IreCt CaChe aCCess 257 causes data evicted. Thus, I/O operation proceeds efficiently require main memory access. But, application need data future, must read back L3 cache main memory. input operation Xeon E5-2600/4600 operates described previous para - graph; L3 cache involved. Thus, performance improvement involves output operations. final point. Although output transfer directly cache I/O controller, term direct cache access used feature. Rather, term reserved I/O protocol application, described remainder section. Cache- Related Performance Issues Network traffic transmitted form sequence protocol blocks, called packets protocol data units. lowest, link, level protocol typically Ethernet, arriving departing block data consists Ethernet packet containing payload higher- level protocol packet. higher- level pro - tocols usually Internet Protocol (IP), operating top Ethernet, Transmission Control Protocol (TCP), operating top IP . Accordingly, Ethernet payload consists block data TCP header IP header. outgoing data, Ethernet packets formed peripheral component, I/O controller network interface controller (NIC). Similarly, incoming traffic, I/O controller strips Ethernet information delivers TCP/ IP packet host CPU. outgoing incoming traffic, core, main memory, cache involved. DMA scheme, application wishes transmit data, places data application- assigned buffer main memory. core trans - fers system buffer main memory creates necessary TCP IP headers, also buffered system memory. packet picked via DMA transfer via NIC. activity engages main memory also cache. incoming traffic, similar transfers system applica - tion buffers required. large volumes protocol traffic processed, two factors sce - nario degrade performance. First, core consumes valuable clock cycles copy - ing data system application buffers. Second, memory speeds kept CPU speeds, core loses time waiting memory reads writes. traditional way processing protocol traffic, cache help data protocol headers constantly changing thus cache must constantly updated. clarify performance issue explain benefit DCA way improving performance, let us look processing protocol traffic detail incoming traffic. general terms, following steps occur: 1. Packet arrives: NIC receives incoming Ethernet packet. NIC pro - cesses strips Ethernet control information. includes error detection calculation. remaining TCP/IP packet transferred system’s DMA module, generally part NIC. NIC also creates packet descriptor information packet, buffer location memory.258 Chapter 7 / Input/Output 2. DMA: DMA module transfers data, including packet descriptor, main memory. must also invalidate corresponding cache lines, any. 3. NIC interrupts host: number packets transferred, NIC issues interrupt host processor. 4. Retrieve descriptors headers: core processes interrupt, invoking interrupt handling procedure, reads descriptor header received packets. 5. Cache miss occurs: new data coming in, cache lines corre - sponding system buffer containing new data invalidated. Thus, core must stall read data main memory cache, core registers. 6. Header processed: protocol software executes core analyze contents TCP IP headers. likely include accessing transport control block (TCB), contains context information related TCP. TCB access may may trigger cache miss, necessitating main memory access. 7. Payload transferred: data portion packet transferred system buffer appropriate application buffer. similar sequence steps occurs outgoing packet traffic, differences affect cache managed. outgoing traffic, following steps occur: 1. Packet transfer requested: application block data transfer remote system, places data application buffer alerts OS type system call. 2. Packet created: OS invokes TCP/IP process create TCP/IP packet transmission. TCP/IP process accesses TCB (which may involve cache miss) creates appropriate headers. also reads data application buffer, places completed packet (headers plus data) system buffer. Note data written system buf - fer also exists cache. TCP/IP process also creates packet descrip - tor placed memory shared DMA module. 3. Output operation invoked: uses device driver program signal DMA module output ready NIC. 4. DMA transfer: DMA module reads packet descriptor, DMA transfer performed main memory last- level cache NIC. Note DMA transfers invalidate cache line cache even case read (by DMA module). line modified, causes write back. core invalidates. invalidates happen DMA module reads data. 5. NIC signals completion: transfer complete, NIC signals driver core originated send signal. 6. Driver frees buffer: driver receives completion notice, frees buffer space reuse. core must also invalidate cache lines containing buffer data.7.6 / IreCt CaChe aCCess 259 seen, network I/O involves number accesses cache main memory movement data application buffer system buffer. heavy involvement main memory becomes bottleneck, core network performance outstrip gains memory access times. Direct Cache Access Strategies Several strategies proposed making efficient use caches network I/O, general term direct cache access applied strategies. simplest strategy one implemented prototype number Intel Xeon processors 2006 2010 [KUMA07, INTE08]. form DCA applies incoming network traffic. DCA function mem - ory controller sends prefetch hint core soon data available system memory. enables core prefetch data packet system buffer, thus avoiding cache misses associated waste core cycles. simple form DCA provide improvement, much substantial gains realized avoiding system buffer main memory altogether. specific function protocol processing, note packet packet descriptor information accessed system buffer core. incoming packets, core reads data buffer trans - fers packet payload application buffer. need access data system buffer again. Similarly, outgoing packets, core placed data system buffer, need access data again. Suppose, therefore, I/O system equipped capability directly accessing main memory, also accessing cache, input output operations. would possible use last- level cache instead main memory buffer packets descriptors incoming outgoing packets. last approach, true DCA, proposed [HUGG05]. also described cache injection [LEON06]. version complete form DCA implemented Intel’s Xeon processor line, referred Direct Data I/O [INTE12]. Direct Data I/O Intel Direct Data I/O (DDIO) implemented Xeon E5 family pro - cessors. operation best explained side- by- side comparison transfers without DDIO. packet input First, look case packet arriving NIC network. Figure 7.17a shows steps involved DMA operation. NIC initiates memory write (1). NIC invalidates cache lines corresponding system buffer (2). Next, DMA operation performed, depositing packet directly main memory (3). Finally, appropriate core receives DMA interrupt signal, core read packet data memory cache (4). discussing processing incoming packet using DDIO, need summarize discussion cache write policy Chapter 4, introduce new technique. following discussion, issues relating cache coher - ency arise multiprocessor multicore environment. discussed 260 Chapter 7 / Input/Output Chapter 17 details need concern us here. Recall two techniques dealing update cache line: ■Write through: write operations made main memory well cache, ensuring main memory always valid. core– cache module monitor traffic main memory maintain consistency within local cache. ■Write back: Updates made cache. update occurs, dirty bit associated line set. Then, block replaced, written back main memory dirty bit set. DDIO uses write- back strategy L3 cache. cache write operation may encounter cache miss, dealt one two strategies: ■Write allocate: required line loaded cache main memory. Then, line cache updated write operation. scheme typically used write- back method. ■ Non- write allocate: block modified directly main memory. change made cache. scheme typically used write- method. mind, describe DDIO strategy inbound transfers initiated NIC. 1. cache hit, cache line updated, main memory; simply write- back strategy cache hit. Intel literature refers write update .(a) Normal DMA transfer memoryI/O contr ollerMain memoryCore 1Core N Last–le vel cacheCore 2 12 34 (b) DDIO transfer cacheI/O contr ollerMain memoryCore 1Core N Last–le vel cacheCore 2 123 (c) Normal DMA transfer I/OI/O contr ollerMain memoryCore 1Core N Last–le vel cacheCore 2 2 31 (d) DDIO transfer I/OI/O contr ollerMain memoryCore 1Core N Last–le vel cacheCore 21 2 Figure 7.17 Comparison DMA DDIO7.7 / I/O Channels prOCessOrs 261 2. cache miss, write operation occurs line cache written back main memory. Subsequent writes update cache line, reference main memory future action writes data main memory. Intel documentation [INTE12] refers write allocate , unfortunately meaning term general cache literature. DDIO strategy effective network protocol application incoming data need retained future use. protocol application going write data application buffer, need temporarily store system buffer. Figure 7.17b shows operation DDIO input. NIC initiates memory write (1). NIC invalidates cache lines corresponding system buffer deposits incoming data cache (2). Finally, appropriate core receives DCA interrupt signal, core read packet data cache (3). packet output Figure 7.17c shows steps involved DMA operation outbound packet transmission. TCP/IP protocol handler executing core reads data application buffer writes system buffer. data access operations result cache misses cause data read memory L3 cache (1). NIC receives notification starting transmit operation, reads data L3 cache transmits (2). cache access NIC causes data evicted cache written back main memory (3). Figure 7.17d shows steps involved DDIO operation packet trans - mission. TCP/IP protocol handler creates packet transmitted stores allocated space L3 cache (1), main memory (2). read operation initiated NIC satisfied data cache, without causing evictions main memory. clear side- by- side comparisons DDIO efficient DMA incoming outgoing packets therefore better able keep high packet traffic rate. 7.7 i/O chann Els PrOcEssOrs Evolution I/O Function computer systems evolved, pattern increasing complex - ity sophistication individual components. Nowhere evident I/O function. already seen part evolution. evolutionary steps summarized follows: 1. CPU directly controls peripheral device. seen simple microprocessor- controlled devices. 2. controller I/O module added. CPU uses programmed I/O without interrupts. step, CPU becomes somewhat divorced spe - cific details external device interfaces. 3. configuration step 2 used, interrupts employed. CPU need spend time waiting I/O operation performed, thus increasing efficiency.262 Chapter 7 / Input/Output 4. I/O module given direct access memory via DMA. move block data memory without involving CPU, except beginning end transfer. 5. I/O module enhanced become processor right, specialized instruction set tailored I/O. CPU directs I/O processor execute I/O program memory. I/O processor fetches executes instructions without CPU intervention. allows CPU specify sequence I/O activities interrupted entire sequence performed. 6. I/O module local memory is, fact, computer right. architecture, large set I/O devices controlled, minimal CPU involvement. common use architecture control communication interactive terminals. I/O processor takes care tasks involved controlling terminals. one proceeds along evolutionary path, I/O func - tion performed without CPU involvement. CPU increasingly relieved I/ O- related tasks, improving performance. last two steps (5–6), major change occurs introduction concept I/O module capable executing program. step 5, I/O module often referred I/O channel . step 6, term I/O processor often used. However, terms occasion applied situations. follows, use term I/O channel . Characteristics I/O Channels I/O channel represents extension DMA concept. I/O channel ability execute I/O instructions, gives complete control I/O operations. computer system devices, CPU execute I/O instructions. instructions stored main memory executed special- purpose processor I/O channel itself. Thus, CPU initiates I/O transfer instructing I/O channel execute program memory. pro - gram specify device devices, area areas memory storage, priority, actions taken certain error conditions. I/O channel follows instructions controls data transfer. Two types I/O channels common, illustrated Figure 7.18. selector channel controls multiple high- speed devices and, one time, dedicated transfer data one devices. Thus, I/O chan - nel selects one device effects data transfer. device, small set devices, handled controller, I/O module, much like I/O mod - ules discussing. Thus, I/O channel serves place CPU controlling I/O controllers. multiplexor channel handle I/O multiple devices time. low- speed devices, byte multiplexor accepts transmits characters fast possible multiple devices. example, resultant character stream three devices different rates indi - vidual streams A1A2A3A4 c, B1B2B3B4 c, C1C2C3C4 c might A1B1C1A2C2A3B2C3A4, on. high- speed devices, block multiplexor interleaves blocks data several devices.7.8 / external Inter COnneCtIOn stanDarDs 263 7.8 ExtErnal intErcOnnEctiOn stanDarDs section, provide brief overview widely used external inter - face standards support I/O. Two these, Thunderbolt InfiniBand, exam - ined detail Appendix J. Universal Serial Bus (USB) USB widely used peripheral connections. default interface slower- speed devices, keyboard pointing devices, also commonly used high- speed I/O, including printers, disk drives, network adapters. USB gone multiple generations. first version, USB 1.0, defined Low Speed data rate 1.5 Mbps Full Speed rate 12 Mbps. USB 2.0 provides data rate 480 Mbps. USB 3.0 includes new, higher speed bus Selector channel Contr ol signal path CPUData addr ess channel main memory I/O contr oller I/O contr ollerI/O contr oller(a) Selector (b) Multiple xorI/O contr oller Multiplexor channel Contr ol signal path CPUData addr ess channel main memory I/O contr ollerI/O contr oller Figure 7.18 I/O Channel Architecture264 Chapter 7 / Input/Output called SuperSpeed parallel USB 2.0 bus. signaling speed Super - Speed 5 Gbps, due signaling overhead, usable data rate 4 Gbps. recent specification USB 3.1, includes faster transfer mode called SuperSpeed+ . transfer mode achieves signaling rate 10 Gbps theoretical usable data rate 9.7 Gbps. USB system controlled root host controller, attaches devices create local network hierarchical tree topology. FireWire Serial Bus FireWire developed alternative small computer system interface (SCSI) used smaller systems, personal computers, workstations, servers. objective meet increasing demands high I/O rates systems, avoiding bulky expensive I/O channel technologies developed mainframe supercomputer systems. result IEEE stan - dard 1394, High Performance Serial Bus, commonly known FireWire. FireWire uses daisy- chain configuration, 63 devices connected single port. Moreover, 1022 FireWire buses interconnected using bridges, enabling system support many peripherals required. FireWire provides known hot plugging, makes possible connect disconnect peripherals without power computer system reconfigure system. Also, FireWire provides automatic configur - ation; necessary manually set device IDs concerned rela - tive position devices. FireWire, terminations, system automatically performs configuration function assign addresses. FireWire bus need strict daisy chain. Rather, tree- structured configuration possible. important feature FireWire standard specifies set three layers protocols standardize way host system interacts peripheral devices serial bus. physical layer defines transmission media permissible FireWire electrical signaling characteristics each. Data rates 25 Mbps 3.2 Gbps defined. link layer describes transmission data packets. transaction layer defines request– response protocol hides lower- layer details FireWire applications. Small Computer System Interface (SCSI) SCSI common standard connecting peripheral devices (disks, modems, printers, etc.) small medium- sized computers. Although SCSI evolved higher data rates, lost popularity competitors USB FireWire smaller systems. However, high- speed versions SCSI remain popular mass memory support enterprise systems. example, IBM zEnterprise EC12 IBM mainframes offer support SCSI, number Seagate hard drive systems use SCSI. physical organization SCSI shared bus, support 16 32 devices, depending generation standard. bus provides parallel transmission rather serial, bus width 16 bits earlier gener - ations 32 bits later generations. Speeds range 5 Mbps original SCSI- 1 specification 160 Mbps SCSI- 3 U3.Thunderbolt recent, one fastest, peripheral connection technology become available general- purpose use Thunderbolt, developed Intel collabora - tion Apple. One Thunderbolt cable manage work previously required multiple cables. technology combines data, video, audio, power single high- speed connection peripherals hard drives, RAID (Redundant Array Independent Disks) arrays, video- capture boxes, network interfaces. provides 10 Gbps throughput direction 10 watts power connected peripherals. Thunderbolt described detail Appendix J. InfiniBand InfiniBand I/O specification aimed high- end server market. first version specification released early 2001 attracted numerous vendors. example, IBM zEnterprise series mainframes relied heavily InfiniBand number years. standard describes architecture speci - fications data flow among processors intelligent I/O devices. InfiniBand become popular interface storage area networking large storage con - figurations. essence, InfiniBand enables servers, remote storage, network devices attached central fabric switches links. switch- based archi - tecture connect 64,000 servers, storage systems, networking devices. Infiniband described detail Appendix J. PCI Express PCI Express high- speed bus system connecting peripherals wide variety types speeds. Chapter 3 discusses PCI Express detail. SATA Serial ATA (Serial Advanced Technology Attachment) interface disk stor - age systems. provides data rates 6 Gbps, maximum per device 300 Mbps. SATA widely used desktop computers, industrial embed - ded applications. Ethernet Ethernet predominant wired networking technology, used homes, offices, data centers, enterprises, wide- area networks. Ethernet evolved sup - port data rates 100 Gbps distances meters tens km, become essential supporting personal computers, workstations, servers, massive data storage devices organizations large small. Ethernet began experimental bus- based 3-Mbps system. bus sys - tem, attached devices, PCs, connect common coaxial cable, much like residential cable TV systems. first commercially- available Ether - net, first version IEEE 802.3, bus- based systems operating 10 Mbps. technology advanced, Ethernet moved bus- based switch- based, data rate periodically increased order magnitude. 7.8 / external Inter COnneCtIOn stanDarDs 265266 Chapter 7 / Input/Output switch- based systems, central switch, devices connected directly switch. Currently, Ethernet systems available speeds 100 Gbps. brief chronology. ■1983: 10 Mbps (megabit per second, million bits per second) ■1995: 100 Mbps ■1998: 1 Gbps (gigabit per second, billion bits per second) ■2003: 10 Gbps ■2010: 40 Gbps 100 Gbps Wi- Fi Wi- Fi predominant wireless Internet access technology, used homes, offices, public spaces. Wi- Fi home connects computers, tablets, smart phones, host electronic devices, video cameras, TVs, thermostats. Wi- Fi enterprise become essential means enhancing worker productivity network effectiveness. public Wi- Fi hotspots expanded dramatically provide free Internet access public places. technology antennas, wireless transmission techniques, wireless protocol design evolved, IEEE 802.11 committee able introduce standards new versions Wi- Fi ever- higher speeds. standard issued, industry quickly develops products. brief chronology, starting original standard, simply called IEEE 802.11, showing maximum data rate version: ■802.11 (1997): 2 Mbps (megabit per second, million bits per second) ■802.11a (1999): 54 Mbps ■802.11b (1999): 11 Mbps ■802.11n (1999): 600 Mbps ■802.11g (2003): 54 Mbps ■802.11ad (2012): 6.76 Gbps (billion bits per second) ■802.11ac (2014): 3.2 Gbps 7.9 iBM zEnt ErPrisE Ec12 i/O structur E zEnterprise EC12 IBM’s latest mainframe computer offering (at time writing). system based use zEC12 processor chip, 5.5-GHz multicore chip six cores. zEC12 architecture maximum 101 processor chips total 606 cores. section, look I/O structure zEnterprise EC12. Channel Structure zEnterprise EC12 dedicated I/O subsystem manages I/O oper - ations, completely off- loading processing memory burden main processors. Figure 7 . 21 shows logical structure I/O subsystem. 96 core processors, 4 dedicated I/O use, creating 4 channel subsystems (CSS) . CSS made following elements: ■System assist processor (SAP): SAP core processor configured I/O operation. role offload I/O operations manage channels I/O operations queues. relieves processors I/O tasks, allowing dedicated application logic. ■Hardware system area (HSA): HSA reserved part system mem - ory containing I/O configuration. used SAPs. fixed amount 32 GB reserved, part customer- purchased memory. provides greater configuration flexibility higher availability elimi - nating planned preplanned outages. ■Logical partitions: logical partition form virtual machine, essence, logical processor defined operating system level.3 CSS supports 16 logical partitions.Partition≤ 15 partitions per channel subsystem ≤ 256 channels per channel subsystemsubchannels Channel ChannelChannel SubsystemChannel SubsystemChannel subsystemChannel SubsystemChannel subsystem4 channel subsystemsChannel subsystemChannel subsystemPartition subchannelsPartition subchannelsPartition subchannels≤ 60 partitions per system ≤ 1024 partitions per systemChannel Channel Figure 7.19 IBM zEC12 I/O Channel Subsystem Structure 3A virtual machine instance operating system along one applications running isolated memory partition within computer. enables different operating systems run computer time well prevents applications interfering other. See [STAL12] discussion virtual machines.7.9 / IBM z enterpr Ise eC12 I/O struCture 267268 Chapter 7 / Input/Output ■Subchannels: subchannel appears program logical device con - tains information required perform I/O operation. One subchannel exists I/O device addressable CSS. subchannel used channel subsystem code running partition pass I/O request channel subsystem. subchannel assigned device defined logical partition. 196k subchannels supported per CSS. ■Channel path: channel path single interface channel subsys - tem one control units, via channel. Commands data sent across channel path perform I/O requests. CSS 256 channel paths. ■Channel: Channels small processors communicate I/O con - trol units (CUs). manage data transfer memory external devices. elaborate structure enables mainframe manage massive num - ber I/O devices communication links. I/O processing offloaded application server processors, enhancing performance. channel subsys - tem processors somewhat general configuration, enabling manage wide variety I/O duties keep evolving requirements. chan - nel processors specifically programmed I/O control units interface. I/O System Organization explain I/O system organization, need first briefly explain physical layout zEnterprise EC12. Figure 7 . 20 front view water- cooled version machine (there also air- cooled version). system following characteristics: ■Weight: 2430 kg (5358 lbs) ■Width: 1.568 (5.14 ft) ■Depth: 1.69 (6.13 ft) ■Height: 2.015 (6.6 ft) exactly laptop. system consists two large bays, called frames, house various components zEnterprise EC12. right-hand frame includes two large cages, plus room cabling components. upper cage processor cage, four slots house four processor books fully intercon - nected. book contains multichip module (MCM), memory cards, I/O cage connections. MCM board houses six multicore chips two storage control chips. lower cage frame I/O cage, contains I/O hardware, including multiplexors channels. I/O cage fixed unit installed IBM customer specifications factory. left-hand Z frame contains internal batteries power supplies room one support elements, used system manager platform management. Z frame also contains slots two I/O drawers. I/O drawer contains similar components I/O cage. differences drawer smaller easily swapped customer site meet changing requirements. background, show typical configuration zEnterprise EC12 I/O system structure (Figure 7.21). zEC12 processor book supports two internal (i.e., internal Z frames) I/O infrastructures: InfiniBand I/O cages I/O drawers, PCI Express (PCIe) I/O drawers. channel controllers referred fanouts . InfiniBand connections processor book I/O cages I/O drawers via Host Channel Adapter (HCA) fanout, InfiniBand links InfiniBand multiplexors I/O cage drawer. InfiniBand multi - plexors used interconnect servers, communications infrastructure equipment, storage, embedded systems. addition using InfiniBand interconnect systems, use InfiniBand, InfiniBand multiplexor supports I/O technologies. ESCON (Enterprise Systems Connection) supports connectivity disks, tapes, printer devices using proprietary fiber- based technology. Eth - ernet connections provide 1-Gbps 10-Gbps connections variety devices support popular local area network technology. One noteworthy use Ethernet construct large server farms, particularly interconnect blade serv - ers mainframes.4 Internal batteries (optional) Power supplies Suppor elements PCIe I/O draw erFlexible ser vice processor (FSP) controller c ards Processor books memor HCA - PCIe-fanout card In/f_iniBand PCIe I/O interconne cts I/O cage carried forward N+1 water cooling units Figure 7.20 IBM zEC12 I/O Frames– Front View 4A blade server server architecture houses multiple server modules (blades) single chassis. widely used data centers save space improve system management. Either self- standing rack mounted, chassis provides power supply, blade CPU, memory, hard disk.7.9 / IBM z enterpr Ise eC12 I/O struCture 269270 Chapter 7 / Input/Output PCIe connections processor book I/O drawers via PCIe fanout PCIe switches. PCIe switches connect number I/O device controllers. Typical examples zEnterprise EC12 1-Gbps 10-Gbps Ethernet Fiber Channel. book contains combination 8 InfiniBand HCA PCIe fanouts. fanout supports 32 connections, total maximum 256 connections per processor book, connection controlled channel processor. 7.10 KEy tErMs, rEviEw Qu EstiOns, PrOBlEMs Key TermsBook 1 Book 2 Book 3 Book 4 PCIe I/O Drawer I/O Cage & I/O DrawerPCIe switchPCIe switchPCIe switchPCIe switchIn/f_iniB multiplexorIn/f_iniB multiplexor Channels Ports 1-Gbps Ether net contr ollerFibre Channel contr ollerESCON 10-Gbps Ether net contr ollerMemory PU PU PU SC1, SCO PCIe (8 ×)PU PU PUMemory PU PU PU SC1, SCO PCIe (8 ×)PU PU PUMemory PU PU PU SC1, SCO HCA2 (8 ×)PU PU PUMemory PU PU PU SC1, SCO HCA2 (8 ×)PU PU PU Figure 7.21 IBM zEC12 I/O System Structure cache injection cycle stealing direct cache access (DCA) Direct Data I/O direct memory access (DMA) InfiniBand interrupt interrupt- driven I/O I/O channelI/O command I/O module I/O processor isolated I/O last- level cache memory- mapped I/O multiplexor channel non- write allocate parallel I/Operipheral device programmed I/O selector channel serial I/O Thunderbolt write allocate write back write write update7.10 / Key terMs, revIew Quest IOns, prOBleMs 271 Review Questions 7.1 List three broad classifications external, peripheral, devices. 7.2 International Reference Alphabet? 7.3 major functions I/O module? 7.4 List briefly define three techniques performing I/O. 7.5 difference memory- mapped I/O isolated I/O? 7.6 device interrupt occurs, processor determine device issued interrupt? 7.7 DMA module takes control bus, retains control bus, processor do? Problems 7.1 typical microprocessor, distinct I/O address used refer I/O data registers distinct address control status registers I/O controller given device. registers referred ports . Intel 8088, two I/O instruction formats used. one format, 8-bit opcode specifies I/O opera - tion; followed 8-bit port address. I/O opcodes imply port address 16-bit DX register. many ports 8088 address I/O addressing mode? 7.2 similar instruction format used Zilog Z8000 microprocessor family. case, direct port addressing capability, 16-bit port address part instruction, indirect port addressing capability, instruction references one 16-bit general purpose registers, contains port address. many ports Z8000 address I/O addressing mode? 7.3 Z8000 also includes block I/O transfer capability that, unlike DMA, direct control processor. block transfer instructions specify port address register (Rp), count register (Rc), destination register (Rd). Rd contains main memory address first byte read input port stored. Rc 16-bit general purpose registers. large data block transferred? 7.4 Consider microprocessor block I/O transfer instruction found Z8000. Following first execution, instruction takes five clock cycles re- execute. However, employ nonblocking I/O instruction, takes total 20 clock cycles fetching execution. Calculate increase speed block I/O instruction transferring blocks 128 bytes. 7.5 system based 8-bit microprocessor two I/O devices. I/O con - trollers system use separate control status registers. devices handle data 1 - byte- at- a- time basis. first device two status lines three control lines. second device three status lines four control lines. a. many 8-bit I/O control module registers need status reading control device? b. total number needed control module registers given first device output- device? c. many distinct addresses needed control two devices? 7.6 programmed I/O, Figure 7 .5 indicates processor stuck wait loop status checking I/O device. increase efficiency, I/O software could written processor periodically checks status device. device ready, processor jump tasks. timed interval, processor comes back check status again. a. Consider scheme outputting data one character time printer operates 10 characters per second (cps). happen status scanned every 200 ms?272 Chapter 7 / Input/Output b. Next consider keyboard single character buffer. average, characters entered rate 10 cps. However, time interval two consecu - tive key depressions short 60 ms. frequency key - board scanned I/O program? 7.7 microprocessor scans status output I/O device every 20 ms. accom - plished means timer alerting processor every 20 ms. interface device includes two ports: one status one data output. long take scan service device, given clocking rate 8 MHz? Assume sim - plicity pertinent instruction cycles take 12 clock cycles. 7.8 Section 7 .3, one advantage one disadvantage memory- mapped I/O, compared isolated I/O, listed. List two advantages two disadvantages. 7.9 particular system controlled operator commands entered keyboard. average number commands entered 8-hour interval 60. a. Suppose processor scans keyboard every 100 ms. many times keyboard checked 8-hour period? b. fraction would number processor visits keyboard reduced interrupt- driven I/O used? 7.10 Suppose 8255A shown Figure 7 .9 configured follows: port input, port B output, bits port C output. Show bits control reg - ister define configuration. 7.11 Consider system employing interrupt- driven I/O particular device trans - fers data average 8 KB/s continuous basis. a. Assume interrupt processing takes 100 µs (i.e., time jump interrupt service routine (ISR), execute it, return main program). Determine fraction processor time consumed I/O device interrupts every byte. b. assume device two 16-byte buffers interrupts proces - sor one buffers full. Naturally, interrupt processing takes longer, ISR must transfer 16 bytes. executing ISR, processor takes 8 µs transfer byte. Determine fraction proces - sor time consumed I/O device case. c. assume processor equipped block transfer I/O instruction found Z8000. permits associated ISR transfer byte block 2 µs. Determine fraction processor time con - sumed I/O device case. 7.12 virtually systems include DMA modules, DMA main memory given higher priority CPU access main memory. Why? 7.13 DMA module transferring characters memory using cycle stealing , device transmitting 9600 bps. processor fetching instructions rate 1 million instructions per second (1 MIPS). much processor slowed due DMA activity? 7.14 Consider system bus cycles takes 500 ns. Transfer bus control either direction, processor I/O device vice versa, takes 250 ns. One I/O devices data transfer rate 50 KB/s employs DMA. Data transferred 1 byte time. a. Suppose employ DMA burst mode. is, DMA interface gains bus mastership prior start block transfer maintains control bus whole block transferred. long would device tie bus transferring block 128 bytes? b. Repeat calculation cycle- stealing mode. 7.15 Examination timing diagram 8237A indicates block transfer begins, takes three bus clock cycles per DMA cycle. DMA cycle, 8237A transfers one byte information memory I/O device. a. Suppose clock 8237A rate 5 MHz. long take transfer one byte?7.10 / Key terMs, revIew Quest IOns, prOBleMs 273 b. would maximum attainable data transfer rate? c. Assume memory fast enough insert two wait states per DMA cycle. actual data transfer rate? 7.16 Assume system preceding problem, memory cycle takes 750 ns. value could reduce clocking rate bus without effect attain - able data transfer rate? 7.17 DMA controller serves four receive- telecommunication links (one per DMA channel) speed 64 Kbps each. a. Would operate controller burst mode cycle- stealing mode? b. priority scheme would employ service DMA channels? 7.18 32-bit computer two selector channels one multiplexor channel. selec - tor channel supports two magnetic disk two magnetic tape units. multiplexor channel two line printers, two card readers, 10 VDT terminals connected it. Assume following transfer rates: Disk drive 800 Kbytes/s Magnetic tape drive 200 Kbytes/s Line printer 6.6 Kbytes/s Card reader 1.2 Kbytes/s VDT 1 Kbyte/s Estimate maximum aggregate I/O transfer rate system. 7.19 computer consists processor I/O device connected main mem - ory via shared bus data bus width one word. processor exe - cute maximum 106 instructions per second. average instruction requires five machine cycles, three use memory bus. memory read write operation uses one machine cycle. Suppose processor continuously executing “back - ground” programs require 95% instruction execution rate I/O instructions. Assume one processor cycle equals one bus cycle. suppose I/O device used transfer large blocks data D. a. programmed I/O used one- word I/O transfer requires processor execute two instructions, estimate maximum I/O data- transfer rate, words per second, possible D. b. Estimate rate DMA used. 7.20 data source produces 7-bit IRA characters, appended parity bit. Derive expression maximum effective data rate (rate IRA data bits) R- bps line following: a. Asynchronous transmission, 1.5-unit stop bit; b. Bit- synchronous transmission, frame consisting 48 control bits 128 information bits; c. (b), 1024-bit information field; d. Character- synchronous, nine control characters per frame 16 information characters; e. (d), 128 information characters. 7.21 Two women either side high fence. One women, named Apple- server, beautiful apple tree loaded delicious apples growing side fence; happy supply apples woman whenever needed. woman, named Apple- eater, loves eat apples none. fact, must eat apples fixed rate (an apple day keeps doctor away). eats faster rate, get sick. eats slower, suffer malnutri - tion. Neither woman talk, problem get apples Apple- server Apple- eater correct rate. a. Assume alarm clock sitting top fence clock multiple alarm settings. clock used solve problem? Draw timing diagram illustrate solution.274 Chapter 7 / Input/Output b. assume alarm clock. Instead Apple- eater flag wave whenever needs apple. Suggest new solution. Would help - ful Apple- server also flag? so, incorporate solution. Discuss drawbacks approach. c. take away flag assume existence long piece string. Suggest solution superior (b) using string. 7.22 Assume one 16-bit two 8-bit microprocessors interfaced system bus. following details given: 1. microprocessors hardware features necessary type data transfer: programmed I/O, interrupt- driven I/O, DMA. 2. microprocessors 16-bit address bus. 3. Two memory boards, 64-Kbytes capacity, interfaced bus. designer wishes use shared memory large possible. 4. system bus supports maximum four interrupt lines one DMA line. Make assumptions necessary, and: a. Give system bus specifications terms number types lines. b. Describe possible protocol communicating bus (i.e., read- write, interrupt, DMA sequences). c. Explain aforementioned devices interfaced system bus.275 Operating SyStem SuppOrt 8.1 Operating System Overview Operating System Objectives Functions Types Operating Systems 8.2 Scheduling Long- Term Scheduling Medium- Term Scheduling Short- Term Scheduling 8.3 Memory Management Swapping Partitioning Paging Virtual Memory Translation Lookaside Buffer Segmentation 8.4 Intel x86 Memory Management Address Spaces Segmentation Paging 8.5 ARM Memory Management Memory System Organization Virtual Memory Address Translation Memory- Management Formats Access Control 8.6 Key Terms, Review Questions, Problems Chapter276 Chapter 8 / Operating Sy Stem Supp Ort Although focus text computer hardware, one area software needs addressed: computer’s OS. OS program manages computer’s resources, provides services programmers, schedules exe - cution programs. understanding operating systems essential appreciate mechanisms CPU controls computer system. par - ticular, explanations effect interrupts management mem - ory hierarchy best explained context. chapter begins overview brief history operating systems. bulk chapter looks two OS functions relevant study computer organization architecture: scheduling memory management. 8.1 Operating Sy Stem Overview Operating System Objectives Functions OS program controls execution application programs acts interface applications computer hardware. thought two objectives: ■Convenience: OS makes computer convenient use. ■Efficiency: OS allows computer system resources used efficient manner. Let us examine two aspects OS turn. operating system user/computer interface hardware software used providing applications user viewed layered hierarchical fashion, depicted Figure 8.1. user applications, end user, generally concerned computer’s architecture. Thus end user views computer system terms application. application expressed programming language developed application programmer. develop application program set processor instructions Learning Objectives studying chapter, able to: rSummarize, top level, key functions operating system (OS) . rDiscuss evolution operating systems early simple batch systems modern complex systems. rExplain differences among long-, medium-, short- term scheduling. rUnderstand reason memory partitioning explain various tech- niques used. rAssess relative advantages paging segmentation. rDefine virtual memory.8.1 / Operating Sy Stem Overview 277 completely responsible controlling computer hardware would overwhelmingly complex task. ease task, set system programs provided. programs referred utilities . implement frequently used functions assist program creation, management files, control I/O devices. programmer makes use facilities developing application, application, running, invokes utilities perform certain functions. important system program OS. OS masks details hardware programmer provides programmer convenient interface using system. acts mediator, making easier programmer application programs access use facilities services. Briefly, OS typically provides services following areas: ■Program creation: OS provides variety facilities services, editors debuggers, assist programmer creating programs. Typi - cally, services form utility programs actually part OS accessible OS. ■Program execution: number steps need performed execute program. Instructions data must loaded main memory, I/O devices files must initialized, resources must prepared. OS handles user. ■Access I/O devices: I/O device requires specific set instruc - tions control signals operation. OS takes care details programmer think terms simple reads writes. ■Controlled access files: case files, control must include - standing nature I/O device (disk drive, tape drive) also file format storage medium. Again, OS worries details. Further, case system multiple simultaneous users, OS provide protection mechanisms control access files.I/O de vices networkingSystem inter connect (bus)Softwar eApplication programming interface Instruction set architectur e Hard ware Main memoryMemory translationExecution hard wareApplication pr ograms Application binary interface Operating systemLibraries/utilities Figure 8.1 Computer Hardware Software Structure278 Chapter 8 / Operating Sy Stem Supp Ort ■System access: case shared public system, OS controls access system whole specific system resources. access function must provide protection resources data unauthorized users must resolve conflicts resource contention. ■Error detection response: variety errors occur computer system running. include internal external hardware errors, memory error, device failure malfunction; various software errors, arithmetic overflow, attempt access forbidden memory loca - tion, inability OS grant request application. case, OS must make response clears error condition least impact running applications. response may range ending program caused error, retrying operation, simply reporting error application. ■Accounting: good OS collects usage statistics various resources monitors performance parameters response time. system, information useful anticipating need future enhancements tuning system improve performance. multiuser system, infor - mation used billing purposes. Figure 8.1 also indicates three key interfaces typical computer system: ■Instruction set architecture (ISA): ISA defines repertoire machine language instructions computer follow. interface boundary hardware software. Note appli - cation programs utilities may access ISA directly. pro - grams, subset instruction repertoire available (user ISA). OS access additional machine language instructions deal managing system resources (system ISA). ■Application binary interface (ABI): ABI defines standard bin - ary portability across programs. ABI defines system call inter - face operating system hardware resources services available system user ISA. ■Application programming interface (API): API gives program access hardware resources services available system user ISA supplemented high- level language (HLL) library calls. system calls usually performed libraries. Using API enables application software ported easily, recompilation, systems support API. operating system resource manager computer set resources movement, storage, processing data control functions. OS responsible managing resources. say OS controls movement, storage, processing data? one point view, answer yes: managing computer’s resources, OS control computer’s basic functions. control exercised curious way. Normally, think control mechanism something external controlled, least something distinct separate part controlled. (For example, residential heating system 8.1 / Operating Sy Stem Overview 279 controlled thermostat, completely distinct heat- generation heat- distribution apparatus.) case OS, control mechanism unusual two respects: ■The OS functions way ordinary computer software; is, program executed processor. ■The OS frequently relinquishes control must depend processor allow regain control. Like computer programs, OS provides instructions proces - sor. key difference intent program. OS directs processor use system resources timing execution programs. order processor things, must cease executing OS program execute programs. Thus, OS relinquishes control processor “useful” work resumes control long enough prepare processor next piece work. mechanisms involved become clear chapter proceeds. Figure 8.2 suggests main resources managed OS. portion OS main memory. includes kernel , nucleus , contains frequently used functions OS and, given time, portions OS currently use. remainder main memory contains user programs data. allocation resource (main memory) controlled jointly OS memory- management hardware processor, see. OS decides I/O device used program execution, controls access • • •• • • • • •MemoryComputer system I/O devices Operating system software Programs data Processor Processor OS Programs DataStoragePrinters, keyboards, digital camera, etc.I/O controller I/O controller I/O controller Figure 8.2 Operating System Resource Manager280 Chapter 8 / Operating Sy Stem Supp Ort use files. processor resource, OS must determine much processor time devoted execution particular user program. case multiple- processor system, decision must span processors. Types Operating Systems Certain key characteristics serve differentiate various types operating systems. characteristics fall along two independent dimensions. first dimension spec - ifies whether system batch interactive. interactive system, user/pro - grammer interacts directly computer, usually keyboard/display terminal, request execution job perform transaction. Furthermore, user may, depending nature application, communicate computer execution job. batch system opposite interac - tive. user’s program batched together programs users sub - mitted computer operator. program completed, results printed user. Pure batch systems rare today, however, useful description contemporary operating systems briefly examine batch systems. independent dimension specifies whether system employs multipro - gramming not. multiprogramming, attempt made keep pro - cessor busy possible, work one program time. Several programs loaded memory, processor switches rapidly among them. alternative uniprogramming system works one pro - gram time. early systems earliest computers, late 1940s mid- 1950s, programmer interacted directly computer hardware; OS. processors run console, consisting display lights, toggle switches, form input device, printer. Programs processor code loaded via input device (e.g., card reader). error halted program, error condition indicated lights. programmer could proceed examine registers main memory determine cause error. program proceeded normal completion, output appeared printer. early systems presented two main problems: ■Scheduling: installations used sign- sheet reserve processor time. Typically, user could sign block time multiples half hour so. user might sign hour finish 45 minutes; would result wasted computer idle time. hand, user might run problems, finish allotted time, forced stop resolving problem. ■Setup time: single program, called job, could involve loading com - piler plus high- level language program (source program) memory, saving compiled program (object program), loading linking together object program common functions. steps could involve mounting dismounting tapes, setting card decks. error occurred, hapless user typically go back beginning setup sequence. Thus considerable amount time spent setting program run.8.1 / Operating Sy Stem Overview 281 mode operation could termed serial processing, reflecting fact users access computer series. time, various system software tools developed attempt make serial processing efficient. include libraries common functions, linkers, loaders, debuggers, I/O driver routines available common software users. simple batch systems Early processors expensive, therefore important maximize processor utilization. wasted time due scheduling setup time unacceptable. improve utilization, simple batch operating systems developed. system, also called monitor , user longer direct access pro- cessor. Rather, user submits job cards tape computer operator, batches jobs together sequentially places entire batch input device, use monitor. understand scheme works, let us look two points view: monitor processor. point view monitor, monitor controls sequence events. so, much monitor must always main memory available execution (Figure 8.3). portion referred resident monitor . rest monitor consists utilities common functions loaded subroutines user pro - gram beginning job requires them. monitor reads jobs one time input device (typically card reader magnetic tape drive). read in, current job placed user program area, control passed job. job completed, returns control monitor, imme - diately reads next job. results job printed delivery user. Interrupt processing Device drivers Job sequencing Control language interpreter User program areaMonitor Boundary Figure 8.3 Memory Layout Resident Monitor282 Chapter 8 / Operating Sy Stem Supp Ort consider sequence point view processor. certain point time, processor executing instructions portion main mem - ory containing monitor. instructions cause next job read another portion main memory. job read in, processor encounter monitor branch instruction instructs processor con - tinue execution start user program. processor execute instruction user’s program encounters ending error condi - tion. Either event causes processor fetch next instruction monitor program. Thus phrase “control passed job” simply means pro - cessor fetching executing instructions user program, “control returned monitor” means processor fetching executing instructions monitor program. clear monitor handles scheduling problem. batch jobs queued up, jobs executed rapidly possible, intervening idle time. job setup time? monitor handles well. job, instructions included job control language (JCL) . special type programming language used provide instructions monitor. simple example user submitting program written FORTRAN plus data used program. FORTRAN instruction item data separate punched card separate record tape. addition - TRAN data lines, job includes job control instructions, denoted beginning “$”. overall format job looks like this: $JOB $FTN f 6 FORTRAN instructions $LOAD $RUN f 6 Data $END execute job, monitor reads $FTN line loads appropri - ate compiler mass storage (usually tape). compiler translates user’s program object code, stored memory mass storage. stored memory, operation referred “compile, load, go.” stored tape, $LOAD instruction required. instruction read monitor, regains control compile operation. monitor invokes loader, loads object program memory place compiler transfers control it. manner, large segment main memory shared among different subsystems, although one subsystem could resident executing time. see monitor, batch OS, simply computer program. relies ability processor fetch instructions various portions main 8.1 / Operating Sy Stem Overview 283 memory order seize relinquish control alternately. Certain hardware features also desirable: ■Memory protection: user program executing, must alter memory area containing monitor. attempt made, proces - sor hardware detect error transfer control monitor. monitor would abort job, print error message, load next job. ■Timer: timer used prevent single job monopolizing system. timer set beginning job. timer expires, interrupt occurs, control returns monitor. ■Privileged instructions: Certain instructions designated privileged executed monitor. processor encounters instruc - tion executing user program, error interrupt occurs. Among privileged instructions I/O instructions, monitor retains con - trol I/O devices. prevents, example, user program acci - dentally reading job control instructions next job. user program wishes perform I/O, must request monitor perform operation it. privileged instruction encountered processor executing user program, processor hardware considers error transfers control monitor. ■Interrupts: Early computer models capability. feature gives OS flexibility relinquishing control regaining control user programs. Processor time alternates execution user programs execution monitor. two sacrifices: main memory given monitor processor time consumed monitor. forms overhead. Even overhead, simple batch system improves utilization computer. multiprogrammed batch systems Even automatic job sequencing provided simple batch OS, processor often idle. problem I/O devices slow compared processor. Figure 8.4 details representative calculation. calculation concerns program processes file records performs, average, 100 processor instructions per record. example computer spends 96% time waiting I/O devices finish transferring data! Figure 8.5a illustrates situation. processor spends certain amount Read one record /f_ile 15 Execute 100 instructions 1 Write one record /f_ile 15 TOTAL 31 Percent CPU utilization =1 31= 0.032 = 3.2% Figure 8.4 System Utilization Example284 Chapter 8 / Operating Sy Stem Supp Ort time executing, reaches I/O instruction. must wait I/O instruction concludes proceeding. inefficiency necessary. know must enough memory hold OS (resident monitor) one user program. Suppose room OS two user programs. Now, one job needs wait I/O, pro - cessor switch job, likely waiting I/O (Figure 8.5b). Furthermore, might expand memory hold three, four, programs switch among (Figure 8.5c). technique known multiprogram - ming , multitasking .1 central theme modern operating systems. 1The term multitasking sometimes reserved mean multiple tasks within program may handled concurrently OS, contrast multiprogramming, would refer multiple processes multiple programs. However, common equate terms multitasking multiprogramming, done standards dictionaries (e.g., IEEE Std 100-1992, New IEEE Standard Dictionary Electrical Electronics Terms ).Run WaitW ait Run Time Run WaitW ait Run Run ARun ARun Wait WaitW ait Run Run BWaitW aitRun B Run ARun ARun BRun BRun CRun C(a) Uniprogramming Time (b) Multiprogramming two programs Time (c) Multiprogramming three programsProgram AProgram Program B Run WaitW ait Run Run Wait WaitW ait RunProgram Program B WaitW ait Combine dRun Wait WaitW ait Run Program CCombine Figure 8.5 Multiprogramming Example8.1 / Operating Sy Stem Overview 285 simple batch system, multiprogramming batch system must rely certain computer hardware features. notable additional feature useful multiprogramming hardware supports I/O interrupts ExAMPLE 8.1 example illustrates benefit multiprogramming. Consider computer 250 Mbytes available memory (not used OS), disk, terminal, printer. Three programs, JOB1, JOB2, JOB3, submitted execution time, attributes listed Table 8.1. assume minimal processor require - ments JOB1 JOB2 continuous disk printer use JOB3. simple batch environment, jobs executed sequence. Thus, JOB1 completes 5 minutes. JOB2 must wait 5 minutes completes 15 minutes that. JOB3 begins 20 minutes completes 30 minutes time initially submitted. average resource utilization, throughput, response times shown uniprogramming column Table 8.2. Device- by- device utilization illus - trated Figure 8.6a. evident gross underutilization resources averaged required 30-minute time period. suppose jobs run concurrently multiprogramming OS. - cause little resource contention jobs, three run nearly min - imum time coexisting others computer (assuming JOB2 JOB3 allotted enough processor time keep input output operations ac - tive). JOB1 still require 5 minutes complete end time, JOB2 one- third finished, JOB3 half finished. three jobs finished within 15 minutes. improvement evident examining multiprogramming column Table 8.2, obtained histogram shown Figure 8.6b. Table 8.1 Sample Program Execution Attributes JOB1 JOB2 JOB3 Type job Heavy compute Heavy I/O Heavy I/O Duration (min) 5 15 10 Memory required (M) 50 100 80 Need disk? Yes Need terminal? Yes Need printer? Yes Table 8.2 Effects Multiprogramming Resource Utilization Uniprogramming Multiprogramming Processor use (%) 20 40 Memory use (%) 33 67 Disk use (%) 33 67 Printer use (%) 33 67 Elapsed time (min) 30 15 Throughput rate (jobs/hr) 6 12 Mean response time (min) 18 10286 Chapter 8 / Operating Sy Stem Supp Ort DMA. interrupt- driven I/O DMA, processor issue I/O com - mand one job proceed execution another job I/O car - ried device controller. I/O operation complete, processor interrupted control passed interrupt- handling program OS. OS pass control another job. Multiprogramming operating systems fairly sophisticated compared single- program, uniprogramming , systems. several jobs ready run, jobs must kept main memory, requiring form memory management . addition, several jobs ready run, processor must decide one run, requires algorithm scheduling. concepts discussed later chapter. time- sharing systems use multiprogramming, batch processing quite efficient. However, many jobs, desirable provide mode user interacts directly computer. Indeed, jobs, transaction processing, interactive mode essential. Today, requirement interactive computing facility be, often is, met use dedicated microcomputer. option available 1960s, computers big costly. Instead, time sharing developed. multiprogramming allows processor handle multiple batch jobs time, multiprogramming used handle multiple interactive jobs. latter case, technique referred time sharing, proces - sor’s time shared among multiple users. time- sharing system , multiple users 0% 05 10 15 20 25 30 Minutes Time (a) UniprogrammingJOB1 JOB2 JOB3Job historyPrinterTerminalDiskMemoryCPU 100%0%100%0%100%0%100%0%100% 0% 05 10 15 Minutes (b) MultiprogrammingJOB1 JOB2 JOB3Job historyPrinterTerminalDiskMemoryCPU 100%0%100%0%100%0%100%0%100% Time Figure 8.6 Utilization Histograms8.2 / Cheduling 287 simultaneously access system terminals, OS interleaving execution user program short burst quantum computation. Thus, n users actively requesting service one time, user see average 1/ n effective computer speed, counting OS overhead. - ever, given relatively slow human reaction time, response time properly designed system comparable dedicated computer. batch multiprogramming time sharing use multiprogramming. key differences listed Table 8.3. 8.2 Scheduling key multiprogramming scheduling. fact, four types scheduling typically involved (Table 8.4). explore presently. first, introduce concept process . term first used designers Multics OS 1960s. somewhat general term job. Many definitions given term process , including ■A program execution ■The “animated spirit” program ■That entity processor assigned concept become clearer proceed. Long- Term Scheduling long- term scheduler determines programs admitted system processing. Thus, controls degree multiprogramming (number processes memory). admitted, job user program becomes process added queue short- term scheduler. systems, newly created pro - cess begins swapped- condition, case added queue medium- term scheduler.Table 8.3 Batch Multiprogramming versus Time Sharing Batch Multiprogramming Time Sharing Principal objective Maximize processor use Minimize response time Source directives operating systemJob control language commands provided jobCommands entered terminal Table 8.4 Types Scheduling Long- term scheduling decision add pool processes executed. Medium- term scheduling decision add number processes partially fully main memory. Short- term scheduling decision available process executed processor. I/O scheduling decision process’s pending I/O request shall han- dled available I/O device.288 Chapter 8 / Operating Sy Stem Supp Ort batch system, batch portion general- purpose OS, newly submit - ted jobs routed disk held batch queue. long- term scheduler creates processes queue can. two decisions involved here. First, scheduler must decide OS take one additional processes. Second, scheduler must decide job jobs accept turn processes. criteria used may include priority, expected execution time, I/O requirements. interactive programs time- sharing system, process request gen - erated user attempts connect system. Time- sharing users simply queued kept waiting system accept them. Rather, OS accept authorized comers system saturated, using pre - defined measure saturation. point, connection request met message indicating system full user try later. Medium- Term Scheduling Medium- term scheduling part swapping function, described Section 8.3. Typically, swapping- decision based need manage degree multiprogramming. system use virtual memory, memory man - agement also issue. Thus, swapping- decision consider memory requirements swapped- processes. Short- Term Scheduling long- term scheduler executes relatively infrequently makes coarse- grained decision whether take new process, one take. short- term scheduler, also known dispatcher , executes frequently makes fine- grained decision job execute next. process states understand operation short- term scheduler, need consider concept process state . lifetime process, status change number times. status point time referred state. term state used connotes certain information exists defines status point. minimum, five defined states process (Figure 8.7): ■New: program admitted high- level scheduler yet ready execute. OS initialize process, moving ready state. New Ready BlockedRunning ExitAdmitDispatch TimeoutRelease Event waitEvent occurs Figure 8.7 Five- State Process Model8.2 / Cheduling 289 ■Ready: process ready execute awaiting access processor. ■Running: process executed processor. ■Waiting: process suspended execution waiting system resource, I/O. ■Halted: process terminated destroyed OS. process system, OS must maintain information indicat - ing state process information necessary process execution. purpose, process represented OS process control block (Figure 8.8), typically contains: ■Identifier: current process unique identifier. ■State: current state process (new, ready, on). ■Priority: Relative priority level. ■Program counter: address next instruction program executed. ■Memory pointers: starting ending locations process memory. ■Context data: data present registers processor process executing, discussed Part Three. now, enough say data represent “context” process. context data plus program counter saved process leaves running state. retrieved processor resumes execu - tion process. Identi/f_ier State Priority Program counter Memory pointers Context data I/O status information Accounting information • • • Figure 8.8 Process Control Block290 Chapter 8 / Operating Sy Stem Supp Ort ■I/O status information: Includes outstanding I/O requests, I/O devices (e.g., tape drives) assigned process, list files assigned process, on. ■Accounting information: May include amount processor time clock time used, time limits, account numbers, on. scheduler accepts new job user request execution, creates blank process control block places associated process new state. system properly filled process control block, process transferred ready state. scheduling techniques understand OS manages scheduling various jobs memory, let us begin considering simple example Figure 8.9. figure shows main memory partitioned given point time. kernel OS is, course, always resident. addition, number active processes, including B, allocated portion memory. Operating system Service handler Scheduler Interrupt handler "Running" B "Ready" partitions (a) (b) (c)Operating system Service handler Scheduler Interrupt handler "Waiting" B "Ready" partitionsOperating system Service handler Scheduler Interrupt handler "Waiting" B "Running" partitionsIn controlIn control control Figure 8.9 Scheduling Example8.2 / Cheduling 291 begin point time process running. processor exe - cuting instructions program contained A’s memory partition. later point time, processor ceases execute instructions begins exe - cuting instructions OS area. happen one three reasons: 1. Process issues service call (e.g., I/O request) OS. Execution suspended call satisfied OS. 2. Process causes interrupt. interrupt hardware- generated signal processor. signal detected, processor ceases execute transfers interrupt handler OS. variety events related cause interrupt. One example error, attempting execute privileged instruction. Another example timeout; prevent one process monopolizing processor, process granted processor short period time. 3. event unrelated process requires attention causes interrupt. example completion I/O operation. case, result following. processor saves current context data program counter A’s process control block begins executing OS. OS may perform work, initiating I/O operation. short- term- scheduler portion OS decides process executed next. example, B chosen. OS instructs proces - sor restore B’s context data proceed execution B left off. simple example highlights basic functioning short- term sched - uler. Figure 8.10 shows major elements OS involved multiprogram - ming scheduling processes. OS receives control processor Service call handler (code)Service call process Interrupt process Pass control processInterrupt I/OInterrupt handler (code) Short-term scheduler (code)Long- term queueShort- term queueI/O queuesOperating system Figure 8.10 Key Elements Operating System Multiprogramming292 Chapter 8 / Operating Sy Stem Supp Ort interrupt handler interrupt occurs service- call handler service call occurs. interrupt service call handled, short- term scheduler invoked select process execution. job, OS maintains number queues. queue simply waiting list processes waiting resource. long- term queue list jobs waiting use system. conditions permit, high- level scheduler allocate memory create process one waiting items. short- term queue consists processes ready state. one processes could use processor next. short- term scheduler pick one. Generally, done round- robin algorithm, giving process time turn. Priority levels may also used. Finally, I/O queue I/O device. one process may request use I/O device. processes waiting use device lined device’s queue. Figure 8.11 suggests processes progress computer control OS. process request (batch job, user- defined interactive job) placed long- term queue. resources become available, process request becomes process placed ready state put short- term queue. processor alternates executing OS instructions executing user processes. OS control, decides process short- term queue executed next. OS finished immediate tasks, turns processor chosen process. mentioned earlier, process executed may suspended variety reasons. suspended process requests I/O, EndLong-term queueShort-term queue Admit Processor I/O 1 queueI/O 1 occurs I/O 2 occurs I/O n occursI/O 2 queue I/O n queue Figure 8.11 Queuing Diagram Representation Processor Scheduling8.3 / memOry management 293 placed appropriate I/O queue. suspended timeout OS must attend pressing business, placed ready state put short- term queue. Finally, mention OS also manages I/O queues. I/O operation completed, OS removes satisfied process I/O queue places short- term queue. selects another waiting process (if any) signals I/O device satisfy process’s request. 8.3 memOry management uniprogramming system, main memory divided two parts: one part OS (resident monitor) one part program currently executed. multiprogramming system, “user” part memory subdivided accom - modate multiple processes. task subdivision carried dynamically OS known memory management . Effective memory management vital multiprogramming system. processes memory, much time processes waiting I/O processor idle. Thus, memory needs allocated efficiently pack many processes memory possible. Swapping Referring back Figure 8.11, discussed three types queues: long- term queue requests new processes, short- term queue processes ready use processor, various I/O queues processes ready use processor. Recall reason elaborate machinery I/O activities much slower computation therefore processor unipro - gramming system idle time. arrangement Figure 8.11 entirely solve problem. true that, case, memory holds multiple processes processor move another process one process waiting. processor much faster I/O common processes memory waiting I/O. Thus, even multiprogramming, processor could idle time. do? Main memory could expanded, able accommo - date processes. two flaws approach. First, main memory expensive, even today. Second, appetite programs memory grown fast cost memory dropped. larger memory results larger pro - cesses, processes. Another solution swapping , depicted Figure 8.12. long- term queue process requests, typically stored disk. brought in, one time, space becomes available. processes completed, moved main memory. situation arise none processes mem - ory ready state (e.g., waiting I/O operation). Rather remain idle, processor swaps one processes back disk intermediate queue . queue existing processes temporarily 294 Chapter 8 / Operating Sy Stem Supp Ort kicked memory. OS brings another process intermedi - ate queue, honors new process request long- term queue. Execution continues newly arrived process. Swapping, however, I/O operation, therefore potential making problem worse, better. disk I/O generally fastest I/O system (e.g., compared tape printer I/O), swapping usu - ally enhance performance. sophisticated scheme, involving virtual memory, improves performance simple swapping. discussed shortly. first, must prepare ground explaining partitioning paging. Partitioning simplest scheme partitioning available memory use fixed- size partitions , shown Figure 8.13. Note that, although partitions fixed size, need equal size. process brought memory, placed smallest available partition hold it. Even use unequal fixed- size partitions, wasted mem - ory. cases, process require exactly much memory provided Operating system Operating systemDisk storage Long-term queue Long-term queueIntermediate queueCompleted jobs user sessions Completed jobs user sessions(a) Simple job scheduling (b) Swappin gMain memory Disk storage Main memory Figure 8.12 Use Swapping8.3 / memOry management 295 partition. example, process requires 3M bytes memory would placed 4M partition Figure 8.13b, wasting 1M could used another process. efficient approach use variable- size partitions . process brought memory, allocated exactly much memory requires more.Operating system 8MOperating system 8M 8M2M 4M 6M 8M 8M 12M 16M8M 8M 8M 8M 8M 8M (a) Equal-size partitions (b) Unequal-size partitions Figure 8.13 Example Fixed Partitioning 64-Mbyte Memory ExAMPLE 8.2 example, using 64 Mbytes main memory, shown Figure 8.14. Initially, main memory empty, except OS (a). first three processes loaded in, starting OS ends occupying enough space process (b, c, d). leaves “hole” end memory small fourth process. point, none processes memory ready. OS swaps process 2 (e), leaves sufficient room load new process, process 4 (f). process 4 smaller process 2, another small hole created. Later, point reached none processes main memory ready, process 2, ready- suspend state, available. insufficient room memory process 2, OS swaps process 1 (g) swaps process 2 back (h).296 Chapter 8 / Operating Sy Stem Supp Ort example shows, method starts well, eventually leads situation lot small holes memory. time goes on, mem - ory becomes fragmented, memory utilization declines. One technique overcoming problem compaction : time time, OS shifts processes memory place free memory together one block. time- consuming procedure, wasteful processor time. consider ways dealing shortcomings partitioning, must clear one loose end. Consider Figure 8.14; obvious pro - cess likely loaded place main memory time swapped in. Furthermore, compaction used, process may shifted main memory. process memory consists instructions plus data. instruc - tions contain addresses memory locations two types: ■Addresses data items ■Addresses instructions, used branching instructions (a)Operating system8M 20M 36M56M (b)Operating system Process 1 20M 14M 22M (c)Operating system Process 1 Process 220M 14M 18M 4M (d)Operating system Process 1 Process 2 14MProcess 3 20M 14M 18M 4M (e)Operating system Process 1 Process 320M 8M 6M 18M 4M (f)Operating system Process 1 Process 4 Process 320M 8M 6M 18M 4M (g)Operating system Process 4 Process 38M 6M6M 18M 4M (h)Operating system Process 4 Process 3Process 2 Figure 8.14 Effect Dynamic Partitioning8.3 / memOry management 297 addresses fixed. change time process swapped in. solve problem, distinction made logical addresses physical addresses. logical address expressed location relative beginning program. Instructions program contain logical addresses. physical address actual location main memory. processor exe - cutes process, automatically converts logical physical address adding current starting location process, called base address , logical address. another example processor hardware feature designed meet OS requirement. exact nature hardware feature depends mem - ory management strategy use. see several examples later chapter. Paging unequal fixed- size variable- size partitions inefficient use mem - ory. Suppose, however, memory partitioned equal fixed- size chunks relatively small, process also divided small fixed- size chunks size. chunks program, known pages , could assigned available chunks memory, known frames , page frames. most, then, wasted space memory process fraction last page. Figure 8.15 shows example use pages frames. given point time, frames memory use free. list free frames maintained OS. Process A, stored disk, consists four pages. 1413 15 16In useMain memory (a) (b) AfterProcess Free frame list 13 14 15 18 20Free frame list 20 Process page table 18 13 14 15Page 0 Page 1 Page 2 Page 3 use use17 18 19 201413 15 16In use useMain memory Page 0 APage 3 APage 2 APage 1 use17 18 19 20Process Page 0 Page 1 Page 2 Page 3 Figure 8.15 Allocation Free Frames298 Chapter 8 / Operating Sy Stem Supp Ort comes time load process, OS finds four free frames loads four pages process four frames. suppose, example, sufficient unused con - tiguous frames hold process. prevent OS loading A? answer no, use concept logical address. simple base address longer suffice. Rather, OS maintains page table process. page table shows frame location page process. Within program, logical address consists page number relative address within page. Recall case simple partitioning, logical address location word relative beginning program; processor translates physical address. paging, logical- to- physical address translation still done processor hardware. processor must know access page table current process. Presented logical address (page number, relative address), processor uses page table produce physical address (frame number, relative address). example shown Figure 8.16. approach solves problems raised earlier. Main memory divided many small equal- size frames. process divided frame- size pages: smaller processes require fewer pages, larger processes require more. process brought in, pages loaded available frames, page table set up. 30 18 13 14 151Page numberRelative addr ess within page Logical addr essPhysical addr essMain memory Process page table30Page 3 Page 0 APage 2 APage 1 A13 14 15 16 17 1813Frame numberRelative addr ess within frame Figure 8.16 Logical Physical Addresses8.3 / memOry management 299 Virtual Memory demand paging use paging, truly effective multiprogramming systems came being. Furthermore, simple tactic breaking process pages led development another important concept: virtual memory. understand virtual memory, must add refinement paging scheme discussed. refinement demand paging , simply means page process brought needed, is, demand. Consider large process, consisting long program plus number arrays data. short period time, execution may confined small section program (e.g., subroutine), perhaps one two arrays data used. principle locality, introduced Appendix 4A. would clearly wasteful load dozens pages process pages used program suspended. make better use memory loading pages. Then, program branches instruc - tion page main memory, program references data page memory, page fault triggered. tells OS bring desired page. Thus, one time, pages given process memory, therefore processes maintained memory. Furthermore, time saved unused pages swapped memory. However, OS must clever manages scheme. brings one page in, must throw another page out; known page replacement . throws page used, go get page almost immediately. much leads condition known thrashing : processor spends time swapping pages rather executing instructions. avoidance thrashing major research area 1970s led var - iety complex effective algorithms. essence, OS tries guess, based recent history, pages least likely used near future. Page Replacement Algorithm Simulators discussion page replacement algorithms beyond scope chap - ter. potentially effective technique least recently used (LRU), algo - rithm discussed Chapter 4 cache replacement. practice, LRU difficult implement virtual memory paging scheme. Several alternative approaches seek approximate performance LRU use; see Appendix K details. demand paging, necessary load entire process main memory. fact remarkable consequence: possible process larger main memory . One fundamental restrictions pro - gramming lifted. Without demand paging, programmer must acutely aware much memory available. program written large, programmer must devise ways structure program pieces 300 Chapter 8 / Operating Sy Stem Supp Ort loaded one time. demand paging, job left OS hard - ware. far programmer concerned, dealing huge mem - ory, size associated disk storage. process executes main memory, memory referred real memory . programmer user perceives much larger memory— allocated disk. latter therefore referred virtual memory . Virtual memory allows effective multiprogramming relieves user unnecessarily tight constraints main memory. page table structure basic mechanism reading word memory involves translation virtual, logical, address, consisting page number offset, physical address, consisting frame number offset, using page table. page table variable length, depending size process, cannot expect hold registers. Instead, must main memory accessed. Figure 8.16 suggests hardware implementation scheme. particular process running, register holds starting address page table process. page number virtual address used index table look corresponding frame number. combined offset portion virtual address produce desired real address. systems, one page table per process. process occupy huge amounts virtual memory. example, VAX architecture, pro - cess 231=2 Gbytes virtual memory. Using 29=512-byte pages, means many 222 page table entries required per process . Clearly, amount memory devoted page tables alone could unacceptably high. overcome problem, virtual memory schemes store page tables virtual memory rather real memory. means page tables subject paging pages are. process running, least part page table must main memory, including page table entry currently executing page. processors make use two- level scheme organize large page tables. scheme, page directory, entry points page table. Thus, length page directory X, maximum length page table Y, process consist X*Y pages. Typically, maximum length page table restricted equal one page. see example two- level approach consider Intel x86 later chapter. alternative approach use one- two- level page tables use inverted page table structure (Figure 8.17). Variations approach used PowerPC, UltraSPARC, IA- 64 architecture. implementa - tion Mach OS RT- PC also uses technique. approach, page number portion virtual address mapped hash value using simple hashing function.2 hash value pointer inverted page table, contains page table entries. one entry 2A hash function maps numbers range 0 numbers range 0 N, M7N. output hash function used index hash table. Since one input maps output, possible input item map hash table entry already occupied. case, new item must overflow another hash table location. Typically, new item placed first succeeding empty space, pointer original location provided chain entries together. See Appendix L information hash functions.8.3 / memOry management 301 inverted page table real memory page frame rather one per virtual page. Thus fixed proportion real memory required tables regardless number processes virtual pages supported. one virtual address may map hash table entry, chaining technique used managing overflow. hashing technique results chains typically short— one two entries. page table’s structure called inverted indexes page table entries frame number rather virtual page number. Translation Lookaside Buffer principle, then, every virtual memory reference cause two physical mem - ory accesses: one fetch appropriate page table entry, one fetch desired data. Thus, straightforward virtual memory scheme would effect doubling memory access time. overcome problem, virtual mem - ory schemes make use special cache page table entries, usually called translation lookaside buffer (TLB) . cache functions way memory cache contains page table entries recently used. Figure 8.18 flowchart shows use TLB. principle locality, virtual memory references locations recently used pages. Therefore, references involve page table entries cache. Studies VAX TLB shown scheme significantly improve performance [CLAR85, SATY81].Page # Offset Frame # bitsm bitsn bitsn bitsVirtual address Hash functionPage #Process IDControl bits Chain Inverted page table (one entry physical memory frame)Real addressOffseti0 j 2m – 1 Figure 8.17 Inverted Page Table Structure302 Chapter 8 / Operating Sy Stem Supp Ort Note virtual memory mechanism must interact cache system (not TLB cache, main memory cache). illustrated Figure 8.19. virtual address generally form page number, offset. First, memory system consults TLB see matching page table entry present. is, real (physical) address generated combining frame number offset. not, entry accessed page table. real address generated, form tag remainder, cache consulted see block containing word present (see Figure 4.5). so, returned processor. not, word retrieved main memory. reader able appreciate complexity processor hard - ware involved single memory reference. virtual address translated real address. involves reference page table, may TLB, Start CPU checks TLB Page table entry TLB? Access page table Update TLB YesYes YesNo NoNo CPU generates physical addr essOS instructs CPU read page disk CPU activates I/O hard warePage fault handling r outineRetur n faulted instruction Page tables updatedPerform page replacementPage transferr ed disk main memoryPage main memory? Memory full? Figure 8.18 Operation Paging Translation Lookaside Buffer (TLB)main memory, disk. referenced word may cache, main memory, disk. latter case, page containing word must loaded main memory block loaded cache. addition, page table entry page must updated. Segmentation another way addressable memory subdivided, known segmentation. Whereas paging invisible programmer serves purpose providing programmer larger address space, segmentation usually visible programmer provided convenience organizing programs data means associating privilege protection attributes instructions data. Segmentation allows programmer view memory consisting multiple address spaces segments. Segments variable, indeed dynamic, size. Typi - cally, programmer OS assign programs data different segments. may number program segments various types programs well number data segments. segment may assigned access usage rights. Memory references consist (segment number, offset) form address. organization number advantages programmer non- segmented address space:Page # OffsetVirtual addressTLB operation Page tableMain memoryTLB miss MissHit ValueTLB hitTLB Tag RemainderReal addressCache operation Cache+ Value Figure 8.19 Translation Lookaside Buffer Cache Operation8.3 / memOry management 303304 Chapter 8 / Operating Sy Stem Supp Ort 1. simplifies handling growing data structures. programmer know ahead time large particular data structure become, necessary guess. data structure assigned segment, OS expand shrink segment needed. 2. allows programs altered recompiled independently without requiring entire set programs relinked reloaded. Again, accomplished using multiple segments. 3. lends sharing among processes. programmer place utility program useful table data segment addressed processes. 4. lends protection. segment constructed contain well- defined set programs data, programmer system administra - tor assign access privileges convenient fashion. advantages available paging, invisible pro - grammer. hand, seen paging provides efficient form memory management. combine advantages both, systems equipped hardware OS software provide both. 8.4 intel x86 memOry management Since introduction 32-bit architecture, microprocessors evolved sophisticated memory management schemes build lessons learned medium- large- scale systems. many cases, microprocessor versions superior larger- system antecedents. schemes developed microprocessor hardware vendor may employed variety operat - ing systems, tend quite general purpose. representative example scheme used Intel x86 architecture. Address Spaces x86 includes hardware segmentation paging. mechanisms disabled, allowing user choose four distinct views memory: ■Unsegmented unpaged memory: case, virtual address physical address. useful, example, low- complexity, high- performance controller applications. ■Unsegmented paged memory: memory viewed paged linear address space. Protection management memory done via paging. favored operating systems (e.g., Berkeley UNIX). ■Segmented unpaged memory: memory viewed collection logical address spaces. advantage view paged approach affords protection level single byte, necessary. Fur - thermore, unlike paging, guarantees translation table needed (the segment table) on- chip segment memory. Hence, segmented unpaged memory results predictable access times. ■Segmented paged memory: Segmentation used define logical memory partitions subject access control, paging used manage alloca - tion memory within partitions. Operating systems UNIX System V favor view. Segmentation segmentation used, virtual address (called logical address x86 documentation) consists 16-bit segment reference 32-bit offset. Two bits segment reference deal protection mechanism, leaving 14 bits specifying particular segment. Thus, unsegmented memory, user’s virtual memory 232=4 Gbytes. segmented memory, total virtual memory space seen user 246=64 terabytes (Tbytes). physical address space employs 32-bit address maximum 4 Gbytes. amount virtual memory actually larger 64 Tbytes. processor’s interpretation virtual address depends pro - cess currently active. Virtual address space divided two parts. One- half virtual address space ( 8K segments* 4 Gbytes) global, shared pro - cesses; remainder local distinct process. Associated segment two forms protection: privilege level access attribute. four privilege levels, protected (level 0) least protected (level 3). privilege level associated data segment “classifica - tion”; privilege level associated program segment “clearance.” exe - cuting program may access data segments clearance level lower (more privileged) equal (same privilege) privilege level data segment. hardware dictate privilege levels used; depends OS design implementation. intended privilege level 1 would used OS, level 0 would used small portion OS devoted memory management, protection, access control. leaves two levels applications. many systems, applications reside level 3, level 2 unused. Specialized application subsystems must pro - tected implement security mechanisms good candidates level 2. examples database management systems, office automation systems, software engineering environments. addition regulating access data segments, privilege mechanism limits use certain instructions. instructions, dealing memory- management registers, executed level 0. I/O instructions executed certain level designated OS; typically, level 1. access attribute data segment specifies whether read/write read- accesses permitted. program segments, access attribute specifies read/execute read- access. address translation mechanism segmentation involves mapping vir - tual address referred linear address (Figure 8.20b). virtual address consists 32-bit offset 16-bit segment selector (Figure 8.20a). instruction fetching storing operand specifies offset register contain - ing segment selector. segment selector consists following fields: ■Table Indicator (TI): Indicates whether global segment table local segment table used translation.8.4 / intel x86 memOry management 305306 Chapter 8 / Operating Sy Stem Supp Ort ■Segment Number: number segment. serves index segment table. ■Requested Privilege Level (RPL): privilege level requested access. entry segment table consists 64 bits, shown Figure 8.20c. fields defined Table 8.5.(b) Linear addressDirectory Table Offset31 2221 1211 0(a) Segment selectorT IIndex RPL15 32 10 TI = Table indicator RPL = Requestor privilege level (e) Page table entryPage frame address 31...12 AVLD APP W TP C DU SR W31 12 76 54 32 1 11 90 = Dirty(d) Page directory entryPage frame address 31...12 AVL0 APP W TP C DP SU SR W31 12 76 54 32 1 11 90 PWT = Write US = User/supervisor RW = Read-write P = PresentAVL = Available systems programmer use P = Page size = Accessed PCD = Cache disable= Reserved(c) Segment descriptor (segment table entry)Base 31...24 Base 23...16 Segment limit 15...0 Base 15...0GP Type DPLSegment limit 19...16D / BA V L31 2223 1920 1213 78 24 141516 11 0 AVL = Available use system software Base = Segment base address D/B = Default operation size DPL = Descriptor privilege size G = GranularityL = 64-bit code segment (64-bit mode only) P = Segment present Type = Segment type = Descriptor typeL Figure 8.20 Intel x86 Memory Management FormatsTable 8.5 x86 Memory Management Parameters Segment Descriptor (Segment Table Entry) Base Defines starting address segment within 4-Gbyte linear address space. D/B bit code segment, bit indicates whether operands addressing modes 16 32 bits. Descriptor Privilege Level (DPL) Specifies privilege level segment referred segment descriptor. Granularity bit (G) Indicates whether Limit field interpreted units one byte 4 Kbytes. Limit Defines size segment. processor interprets limit field one two ways, depending granularity bit: units one byte, segment size limit 1 Mbyte, units 4 Kbytes, segment size limit 4 Gbytes. bit Determines whether given segment system segment code data segment. Segment Present bit (P) Used nonpaged systems. indicates whether segment present main memory. paged systems, bit always set 1. Type Distinguishes various kinds segments indicates access attributes. Page Directory Entry Page Table Entry Accessed bit (A) bit set 1 processor levels page tables read write operation corresponding page occurs. Dirty bit (D) bit set 1 processor write operation corresponding page occurs. Page Frame Address Provides physical address page memory present bit set. Since page frames aligned 4K boundaries, bottom 12 bits 0, top 20 bits included entry. page direc- tory, address page table. Page Cache Disable bit (PCD) Indicates whether data page may cached. Page Size bit (PS) Indicates whether page size 4 Kbyte 4 Mbyte. Page Write bit (PWT) Indicates whether write- write- back caching policy used data corresponding page. Present bit (P) Indicates whether page table page main memory. Read/Write bit (RW) user- level pages, indicates whether page read- access read/write access user- level programs. User/Supervisor bit (US) Indicates whether page available operating system (supervisor level) available operating system applications (user level).8.4 / intel x86 memOry management 307308 Chapter 8 / Operating Sy Stem Supp Ort Paging Segmentation optional feature may disabled. segmentation use, addresses used programs virtual addresses converted linear addresses, described. segmentation use, linear addresses used programs. either case, following step convert linear address real 32-bit address. understand structure linear address, need know x86 paging mechanism actually two- level table lookup operation. first level page directory, contains 1024 entries. splits 4-Gbyte linear memory space 1024 page groups, page table, 4 Mbytes length. page table contains 1024 entries; entry corresponds single 4-Kbyte page. Memory management option using one page directory processes, one page directory process, combination two. page directory current task always main memory. Page tables may virtual memory. Figure 8.20 shows formats entries page directories page tables, fields defined Table 8.5. Note access control mechanisms provided page page group basis. x86 also makes use translation lookaside buffer. buffer hold 32 page table entries. time page directory changed, buffer cleared. Figure 8.21 illustrates combination segmentation paging mechanisms. clarity, translation lookaside buffer memory cache mechanisms shown. Segmen descriptorLogical address OffsetSegmen selec tor Global descriptor table (GDT )Linear address space PageSegmen base addressSegmen Page direc tory Segmentation PagingLin. Addr.Linear address DirT ableO ffset Entr yPage tablePhysical address spac e Entr yPhy. Addr.Page Figure 8.21 Intel x86 Memory Address Translation Mechanisms8.5 / arm memOry management 309 Finally, x86 includes new extension found earlier 80386 80486, provision two page sizes. PSE (page size extension) bit con - trol register 4 set 1, paging unit permits OS programmer define page either 4 Kbyte 4 Mbyte size. 4-Mbyte pages used, one level table lookup pages. hardware accesses page directory, page directory entry (Figure 8.20d) PS bit set 1. case, bits 9 21 ignored bits 22 31 define base address 4-Mbyte page memory. Thus, single page table. use 4-Mbyte pages reduces memory- management storage require - ments large main memories. 4-Kbyte pages, full 4-Gbyte main memory requires 4 Mbytes memory page tables. 4-Mbyte pages, single table, 4 Kbytes length, sufficient page memory management. 8.5 arm memOry management ARM provides versatile virtual memory system architecture tailored needs embedded system designer. Memory System Organization Figure 8.22 provides overview memory management hardware ARM virtual memory. virtual memory translation hardware uses one two levels tables translation virtual physical addresses, explained subsequently. translation lookaside buffer (TLB) cache recent page table entries. entry available TLB, TLB directly sends physical address main memory read write operation. explained Chapter 4, data exchanged Access control hard wareAccess bits, domain Access bits, domain Abort Contr ol bitsPhysical addr essPhysical addr ess Physical addr ess Virtual addr essVirtual addr ess ARM coreTLBMemory-management unit (MMU) Cache line fetch hard wareVirtual memory translation hard ware Main memory Cache write buffer Figure 8.22 ARM Memory System Overview310 Chapter 8 / Operating Sy Stem Supp Ort processor main memory via cache. logical cache organization used (Figure 4.7a), ARM supplies address directly cache well supplying TLB cache miss occurs. physical cache organization used (Figure 4.7b), TLB must supply physical address cache. Entries translation tables also include access control bits, deter - mine whether given process may access given portion memory. access denied, access control hardware supplies abort signal ARM processor. Virtual Memory Address Translation ARM supports memory access based either sections pages: ■Supersections (optional): Consist 16-MB blocks main memory. ■Sections: Consist 1-MB blocks main memory. ■Large pages: Consist 64-kB blocks main memory. ■Small pages: Consist 4-kB blocks main memory. Sections supersections supported allow mapping large region memory using single entry TLB. Additional access control mechanisms extended within small pages 1kB subpages, within large pages 16kB subpages. translation table held main memory two levels: ■Level 1 table: Holds level 1 descriptors contain base address translation properties Section Supersection; translation proper - ties pointers level 2 table large page small page. ■Level 2 table: Holds level 2 descriptors contain base address trans - lation properties Small page Large page. level 2 table requires 1 kB memory. memory- management unit (MMU) translates virtual addresses generated processor physical addresses access main memory, also derives checks access permission. Translations occur result TLB miss, start first- level fetch. section- mapped access requires first- level fetch, whereas page- mapped access also requires second- level fetch. Figure 8.23 shows two- level address translation process small pages. single level 1 (L1) page table 4K 32-bit entries. L1 entry points level 2 (L2) page table 256 32-bit entries. L2 entry points 4-kB page main memory. 32-bit virtual address interpreted follows: significant 12 bits index L1 page table. next 8 bits index relevant L2 page table. least significant 12 bits index byte relevant page main memory. similar two- page lookup procedure used large pages. sections supersection, L1 page table lookup required. Memory- Management Formats get better understanding ARM memory management scheme, con - sider key formats, shown Figure 8.24. control bits shown figure defined Table 8.6.8.5 / arm memOry management 311 L1 table, entry descriptor associated 1-MB virtual address range mapped. entry one four alternative formats: ■Bits [1:0]=00: associated virtual addresses unmapped, attempts access generate translation fault. ■Bits [1:0]=01: entry gives physical address L2 page table, specifies associated virtual address range mapped. ■Bits [1:0]=01: bit 19=0: entry section descriptor asso - ciated virtual addresses. ■Bits [1:0]=01: bit 19=1: entry supersection descriptor associated virtual addresses. Entries bits [1:0]=11 reserved. memory structured pages, two- level page table access required. Bits [31:10] L1 page entry contain pointer L2 page table. small pages, L2 entry contains 20-bit pointer base address 4-kB page main memory. large pages, structure complex. virtual addresses small pages, virtual address large page structure includes 12-bit index Small page (4 kB)Main memoryVirtual address Level 1 (L1) page table Level 2 (L2) page tableL1 index L2 PT base addrPage index0 04095 0255 01 page base add r1 011 19 31 L2 index Figure 8.23 ARM Virtual Memory Address Translation Small Pages312 Chapter 8 / Operating Sy Stem Supp Ort level one table 8-bit index L2 table. 64-kB large pages, page index portion virtual address must 16 bits. accommodate bits 32-bit format, 4-bit overlap page index field L2 table index field. ARM accommodates overlap requiring page table entry L2 page table supports large pages replicated 16 times. effect, size L2 page table reduced 256 entries 16 entries, entries refer large pages. However, given L2 page service mixture large small pages, hence need replication large page entries.00 IGN Fault 10 P Coarse page table base addr ess (a) Alternati /f_irst-le vel descriptor formats (b) Alternati second-le vel descriptor formatsSBZ Domain 01 0S P APAP X AP Xn GX NTEX Section base addr ess CBS B ZDomain 01 1S P AP AP XAP Xn G n GX NBase addr ess [39:36]Base addr ess [35:32]TEXSupersection base addr essCBS B ZPage table Section Supersection 000123456789101112 1415 31 16012345 89101112 14 2019 2423 31 IGN Fault 0 1920 31 Level 1 table index Section index Section 0 1920 1112 31 Level 1 table index Level 2 table index Page indexSmall pageLarge page 10 Large page base addr ess (c) Virtual memor address formatsSBZ TEX1 n GSX N X NSmall page base addr ess CB CAP AP BTEX Small page 0 1920 1112 1516 31 Level 1 table indexLevel 2 table indexPage inde xLarge page0 1920 2324 31 Level 1 table index Supersection index Supersection Figure 8.24 ARM Memory- Management Formats8.5 / arm memOry management 313 memory structured sections supersections, one- level page table access required. sections, bits [31:20] L1 entry contain 12-bit pointer base 1-MB section main memory. supersections, bits [31:24] L1 entry contain 8-bit pointer base 16-MB section main memory. large pages, page table entry replication required. case supersections, L1 table index portion virtual address overlaps 4 bits supersection index portion vir - tual address Therefore, 16 identical L1 page table entries required. range physical address space expanded eight additional address bits (bits [23:20] [8:5]). number additional bits implementation dependent. additional bits interpreted extending size phys - ical memory much factor 28=256. Thus, physical memory may fact much 256 times large memory space available individual process. Access Control AP access control bits table entry control access region memory given process. region memory designated access, read only, read- write. Further, region designated privileged access only, reserved use OS applications. ARM also employs concept domain, collection sec - tions and/or pages particular access permissions. ARM architecture Table 8.6 ARM Memory- Management Parameters Access Permission (AP), Access Permission Extension (AP x) bits control access corresponding memory region. access made area memory without required permissions, Permission Fault raised. Bufferable (B) bit Determines, TEX bits, write buffer used cacheable memory. Cacheable (C) bit Determines whether memory region mapped cache. Domain Collection memory regions. Access control applied basis domain. Global (nG) Determines whether translation marked global (0), process specific (1). Shared (S) Determines whether translation not- shared (0), shared (1) memory. SBZ zero. Type Extension (TE x) bits, together B C bits, control accesses caches, write buffer used, memory region shareable therefore must kept coherent. Execute Never ( xN) Determines whether region executable (0) executable (1).314 Chapter 8 / Operating Sy Stem Supp Ort Review Questions 8.1 operating system? 8.2 List briefly define key services provided OS. 8.3 List briefly define major types OS scheduling. 8.4 difference process program? 8.5 purpose swapping? 8.6 process may dynamically assigned different locations main memory, implication addressing mechanism? 8.7 necessary pages process main memory process executing?supports 16 domains. domain feature allows multiple processes use translation tables maintaining protection other. page table entry TLB entry contains field specifies domain entry in. 2-bit field Domain Access Control Register controls access domain. field allows access entire domain ena - bled disabled quickly, whole memory areas swapped virtual memory efficiently. Two kinds domain access supported: ■Clients: Users domains (execute programs access data) must observe access permissions individual sections and/or pages make domain. ■Managers: Control behavior domain (the current sections pages domain, domain access), bypass access permissions table entries domain. One program client domains, manager domains, access remaining domains. allows flexible memory protection programs access different memory resources. 8.6 Key termS, review Que StiOnS, prOblem Key Terms batch system demand paging interactive operating system interrupt job control language (JCL) kernel logical address long- term scheduling medium- term scheduling memory management memory protection multiprogrammingmultitasking nucleus operating system (OS) page table paging partitioning physical address privileged instruction process process control block process state real memoryresident monitor segmentation short- term scheduling swapping thrashing time- sharing system translation lookaside buffer (TLB) utility virtual memory8.6 / Key termS, review Que StiOnS, prOblem 315 8.8 Must pages process main memory contiguous? 8.9 necessary pages process main memory sequential order? 8.10 purpose translation lookaside buffer? Problems 8.1 Suppose multiprogrammed computer job identical characteristics. one computation period, T, job, half time spent I/O half processor activity. job runs total N periods. Assume simple round- robin priority used, I/O operations overlap processor operation. Define following quantities: ■Turnaround time = actual complete job . ■Throughput = average number jobs completed per time period T. ■Processor utilization = percentage time processor active (not waiting) . Compute quantities one, two, four simultaneous jobs, assuming period distributed following ways: a. I/O first half, processor second half; b. I/O first fourth quarters, processor second third quarters. 8.2 I/ O- bound program one that, run alone, would spend time waiting I/O using processor. processor- bound program opposite. Suppose short- term scheduling algorithm favors programs used little processor time recent past. Explain algorithm favors I/ O- bound programs yet permanently deny processor time processor- bound programs. 8.3 program computes row sums Ci=an j=1aij array 100 100. Assume computer uses demand paging page size 1000 words, amount main memory allotted data five page frames. difference page fault rate stored virtual memory rows columns? Explain. 8.4 Consider fixed partitioning scheme equal- size partitions 216 bytes total main memory size 224 bytes. process table maintained includes pointer partition resident process. many bits required pointer? 8.5 Consider dynamic partitioning scheme. Show that, average, memory contains half many holes segments. 8.6 Suppose page table process currently executing processor looks like following. numbers decimal, everything numbered starting zero, addresses memory byte addresses. page size 1024 bytes. Virtual page number Valid bit Reference bit Modify bitPage frame number 0 1 1 0 4 1 1 1 1 7 2 0 0 0 — 3 1 0 0 2 4 0 0 0 — 5 1 0 1 0316 Chapter 8 / Operating Sy Stem Supp Ort a. Describe exactly how, general, virtual address generated CPU trans - lated physical main memory address. b. physical address, any, would following virtual addresses corre - spond to? (Do try handle page faults, any.) i. 1052 ii. 2221 iii. 5499 8.7 Give reasons page size virtual memory system neither small large. 8.8 process references five pages, A, B, C, D, E, following order: A; B; C; D; A; B; E; A; B; C; D; E Assume replacement algorithm first- in- first- find number page transfers sequence references starting empty main mem - ory three page frames. Repeat four page frames. 8.9 following sequence virtual page numbers encountered course exe - cution computer virtual memory: 3 4 2 6 4 7 1 3 2 6 3 5 1 2 3 Assume least recently used page replacement policy adopted. Plot graph page hit ratio (fraction page references page main memory) function main- memory page capacity n 1…n…8. Assume main memory initially empty. 8.10 VAX computer, user page tables located virtual addresses system space. advantage user page tables virtual rather main memory? disadvantage? 8.11 Suppose program statement (i=1; 6=n; i+) a[i]=b[i]+c[i]; executed memory page size 1000 words. Let n=1000. Using machine full range register- to- register instructions employs index registers, write hypothetical program implement foregoing statement. show sequence page references execution. 8.12 IBM System/370 architecture uses two- level memory structure refers two levels segments pages, although segmentation approach lacks many features described earlier chapter. basic 370 architecture, page size may either 2 Kbytes 4 Kbytes, segment size fixed either 64 Kbytes 1 Mbyte. 370/XA 370/ESA architectures, page size 4 Kbytes segment size 1 Mbyte. advantages segmentation scheme lack? benefit segmentation 370? 8.13 Consider computer system segmentation paging. segment memory, words wasted last page. addition, segment size page size p, s/p page table entries. smaller page size, less waste last page segment, larger page table. page size minimizes total overhead? 8.14 computer cache, main memory, disk used virtual memory. refer - enced word cache, 20 ns required access it. main memory cache, 60 ns needed load cache, reference started again. word main memory, 12 ms required fetch word disk, followed 60 ns copy cache, reference started again. cache hit ratio 0.9 main- memory hit ratio 0.6. aver - age time ns required access referenced word system? 8.15 Assume task divided four equal- sized segments system builds eight- entry page descriptor table segment. Thus, system combina - tion segmentation paging. Assume also page size 2 Kbytes.8.6 / Key termS, review Que StiOnS, prOblem 317 a. maximum size segment? b. maximum logical address space task? c. Assume element physical location 00021ABC accessed task. format logical address task generates it? maximum physical address space system? 8.16 Assume microprocessor capable accessing 232 bytes physical main mem- ory. implements one segmented logical address space maximum size 231 bytes. instruction contains whole two- part address. External memory management units (MMUs) used, whose management scheme assigns contiguous blocks physical memory fixed size 222 bytes segments. starting physical address segment always divisible 1024. Show detailed interconnection external mapping mechanism converts logical addresses physical addresses using appropriate number MMUs, show detailed internal structure MMU (assuming MMU contains 128-entry directly mapped segment descriptor cache) MMU selected. 8.17 Consider paged logical address space (composed 32 pages 2 Kbytes each) mapped 1 -Mbyte physical memory space. a. format processor’s logical address? b. length width page table (disregarding “access rights” bits)? c. effect page table physical memory space reduced half? 8.18 IBM’s mainframe operating system, OS/390, one major modules ker - nel System Resource Manager (SRM). module responsible alloca - tion resources among address spaces (processes). SRM gives OS/390 degree sophistication unique among operating systems. mainframe OS, cer - tainly type OS, match functions performed SRM. concept resource includes processor, real memory, I/O channels. SRM accumulates sta - tistics pertaining utilization processor, channel, various key data structures. purpose provide optimum performance based performance monitoring analysis. installation sets forth various performance objectives, serve guidance SRM, dynamically modifies installation job perfor - mance characteristics based system utilization. turn, SRM provides reports enable trained operator refine configuration parameter settings improve user service. problem concerns one example SRM activity. Real memory divided equal- sized blocks called frames, may many thousands. frame hold block virtual memory referred page. SRM receives control approximately 20 times per second inspects every page frame. page referenced changed, counter incremented 1. time, SRM averages numbers determine average number seconds page frame system goes untouched. might purpose action might SRM take? 8.19 ARM virtual address formats shown Figure 8.24, show physical address format. 8.20 Draw figure similar Figure 8.23 ARM virtual memory translation main memory divided sections.318Part three Arithmetic Logic Number SyStemS 9.1 Decimal System 9.2 Positional Number Systems 9.3 Binary System 9.4 Converting Binary Decimal Integers Fractions 9.5 Hexadecimal Notation 9.6 Key Terms Problems CHAPTER9.1 / Decimal Sy STem 319 9.1 DECIMAL SYSTEM everyday life use system based decimal digits (0, 1, 2, 3, 4, 5, 6, 7 , 8, 9) represent numbers, refer system decimal system. Consider number 83 means. means eight tens plus three: 83=(8*10)+3 number 4728 means four thousands, seven hundreds, two tens, plus eight: 4728=(4*1000)+(7*100)+(2*10)+8 decimal system said base , radix , 10. means digit number multiplied 10 raised power corresponding digit’s position: 83=(8*101)+(3*100) 4728=(4*103)+(7*102)+(2*101)+(8*100) principle holds decimal fractions, negative powers 10 used. Thus, decimal fraction 0.256 stands 2 tenths plus 5 hundredths plus 6 thousandths: 0.256=(2*10-1)+(5*10-2)+(6*10-3) number integer fractional part digits raised positive negative powers 10: 442.256=(4*102)+(4+101)+(2*100)+(2*10-1)+(5*10-2) +(6*10-3) number, leftmost digit referred significant digit , carries highest value. rightmost digit called least significant digit . preceding decimal number, 4 left significant digit 6 right least significant digit. Table 9.1 shows relationship digit position value assigned position. position weighted 10 times value position right one-tenth value position left. Thus, positions rep - resent successive powers 10. number positions indicated Table 9.1, position weighted value 10i.Learning Objectives studying chapter, able to: rUnderstand basic concepts terminology positional number systems . rExplain techniques converting decimal binary integers fractions. rExplain rationale using hexadecimal notation .320 cha PTeR 9 / Numbe R SySTemS general, decimal representation X=5c d2d1d0.d-1d-2d-3 c6, value X X=a i(di*10i) (9.1) One observation worth making. Consider number 509 ask many tens number. 0 tens position, might tempted say tens. fact 50 tens. 0 tens position means tens left cannot lumped hundreds, thousands, on. Therefore, position holds leftover numbers cannot lumped higher positions, digit position needs value greater nine. Nine maximum value position hold flips next higher position. 9.2 POSITIONAL NUMBER SYSTEMS positional number system, number represented string digits digit position associated weight ri, r radix, base, number system. general form number system radix r (c a3a2a1a0.a-1a-2a-3c)r value digit ai integer range 0…ai6r. dot a0 a-1 called radix point . number defined value c+a3r3+a2r2+a1r1+a0r0+a-1r-1+a-2r-2+a-3r-3+c =a i(ai*bi) (9.2) decimal system, then, special case positional number system radix 10 digits range 0 9. example another positional system, consider system base 7. Table 9.2 shows weighting value positions -1 4. position, digit value ranges 0 6.Table 9.1 Positional Interpretation Decimal Number 4 7 2 2 5 6 100s 10s 1s tenths hundredths thousandths 10210110010-110-210-3 position 2 position 1 position 0 position –1 position –2 position –3 Table 9.2 Positional Interpretation Number Base 7 Position 4 3 2 1 0 -1 Value Exponential Form 74737271707-1 Decimal Value 2401 343 49 7 1 1/79.4 / coNveRTiNg biNaRy Decimal 321 9.3 BINARY SYSTEM decimal system, 10 different digits used represent numbers base 10. binary system, two digits, 1 0. Thus, numbers binary system represented base 2. avoid confusion, sometimes put subscript number indicate base. example, 8310 472810 numbers represented decimal notation or, briefly, decimal numbers. digits 1 0 binary notation meaning decimal notation: 02=010 12=110 represent larger numbers, decimal notation, digit binary num - ber value depending position: 102=(1*21)+(0*20)=210 112=(1*21)+(1*20)=310 1002=(1*22)+(0*21)+(0*20)=410 on. Again, fractional values represented negative powers radix: 1001.101=23+20+2-1+2-3=9.62510 general, binary representation Y=5c b2b1b0.b-1b-2b-3c6, value Y=a i(bi*2i) (9.3) 9.4 CONVERTING BINARY DECIMAL simple matter convert number binary notation decimal notation. fact, showed several examples previous subsection. required multiply binary digit appropriate power 2 add results. convert decimal binary, integer fractional parts han - dled separately. Integers integer part, recall binary notation, integer represented bm-1bm-2 cb2b1b0 bi=0 1 value (bm-1*2m-1)+(bm-2*2m-2)+c+(b1*21)+b0322 cha PTeR 9 / Numbe R SySTemS Suppose required convert decimal integer N binary form. divide N 2, decimal system, obtain quotient N1 remainder R0, may write N=2*N1+R0 R0=0 1 Next, divide quotient N1 2. Assume new quotient N2 new remainder R1. N1=2*N2+R1 R1=0 1 N=2(2N2+R1)+R0=(N2*22)+(R1*21)+R0 next N2=2N3+R2 N=(N3*23)+(R2*22)+(R1*21)+R0 N7N17N2c, continuing sequence eventually produce quotient Nm-1=1 (except decimal integers 0 1, whose binary equivalents 0 1, respectively) remainder Rm-2, 0 1. N=(1*2m-1)+(Rm-2*2m-2)+c+(R2*22)+(R1*21)+R0 binary form N. Hence, convert base 10 base 2 repeated divisions 2. remainders final quotient, 1, give us, order increas - ing significance, binary digits N. Figure 9.1 shows two examples. Fractions fractional part, recall binary notation, number value 0 1 represented 0.b-1b-2b-3 c bi=0 1 value (b-1*2-1)+(b-2*2-2)+(b-3*2-3)c rewritten 2-1*(b-1+2-1*(b-2+2-1*(b-3+ c) c)) expression suggests technique conversion. Suppose want con - vert number F(06F61) decimal binary notation. know F expressed form F=2-1*(b-1+2-1*(b-2+2-1*(b-3+ c) c)) multiply F 2, obtain, 2*F=b-1+2-1*(b-2+2-1*(b-3+c)c)9.4 / coNveRTiNg biNaRy Decimal 323 equation, see integer part (2*F), must either 0 1 06F61, simply b-1. say (2*F)=b-1+F1, 06F161 F1=2-1*(b-2+2-1*(b-3+2-1*(b-4+c)c)) find b-2, repeat process. Therefore, conversion algorithm involves repeated multiplication 2. step, fractional part number previous step multiplied 2. digit left decimal point product 0 1 contributes binary representation, starting significant digit. fractional part product used multiplicand next step. Figure 9.2 shows two examples. process necessarily exact; is, decimal fraction finite number digits may require binary fraction infinite number digits. cases, conversion algorithm usually halted prespecified number steps, depending desired accuracy.(a) 1110Quotient 5=1Remainder 11 2 2=15 2 1=02 2 0=1 10112 = 11101 2 (b) 2110Quotient 5=0Remainder 10 2 2=15 2 1=02 2 0=1 101012 = 21101 210=121 2 Figure 9.1 Examples Converting Decimal Notation Binary Notation Integers324 cha PTeR 9 / Numbe R SySTemS 9.5 HEXADECIMAL NOTATION inherent binary nature digital computer components, forms data within computers represented various binary codes. However, matter convenient binary system computers, exceedingly cumbersome human beings. Consequently, computer professionals must spend time working actual raw data computer prefer compact notation. notation use? One possibility decimal notation. certainly compact binary notation, awkward tediousness converting base 2 base 10. Instead, notation known hexadecimal adopted. Binary digits grouped sets four bits, called nibble . possible combination four binary digits given symbol, follows: 0000=0 0100=4 1000=8 1100=C 0001=1 0101=5 1001=9 1101=D 0010=2 0110=6 1010=A 1110=E 0011=3 0111=7 1011=B 1111=FProduct 0.81 2 = 1.62 1Integer Part 0.62 2 = 1.24 1 0.24  2 = 0.48 0 0.48 2 = 0.96 0.96  2 = 1.92 0.92  2 = 1.840 1 10.1100112 (a) 0.8110 = 0.1100112 (approximately) Product 0.25  2 = 0.5 0Integer Part 0.5  2 = 1.0 10.012 (b) 0.2510 = 0.01 2 (exactly)* * * * * * * * Figure 9.2 Examples Converting Decimal Notation Binary Notation Fractions9.5 / hexaDecimal TaTioN 325 16 symbols used, notation called hexadecimal , 16 symbols hexadecimal digits . sequence hexadecimal digits thought representing integer base 16 (Table 9.3). Thus, 2C16=(216*161)+(C16*160) =(210*161)+(1210*160)=44 Thus, viewing hexadecimal numbers numbers positional number sys - tem base 16, Z=a i(hi*16i) (9.4) 16 base hexadecimal digit hi decimal range 0…hi615, equivalent hexadecimal range 0…hi…F. Table 9.3 Decimal, Binary, Hexadecimal Decimal (base 10) Binary (base 2) Hexadecimal (base 16) 0 0000 0 1 0001 1 2 0010 2 3 0011 3 4 0100 4 5 0101 5 6 0110 6 7 0111 7 8 1000 8 9 1001 9 10 1010 11 1011 B 12 1100 C 13 1101 14 1110 E 15 1111 F 16 0001 0000 10 17 0001 0001 11 18 0001 0010 12 31 0001 1111 1F 100 0110 0100 64 255 1111 1111 FF 256 0001 0000 0000 100326 cha PTeR 9 / Numbe R SySTemS Hexadecimal notation used representing integers also used concise notation representing sequence binary digits, whether represent text, numbers, type data. reasons using hexadec - imal notation follows: 1. compact binary notation. 2. computers, binary data occupy multiple 4 bits, hence multiple single hexadecimal digit. 3. extremely easy convert binary hexadecimal notation. example last point, consider binary string 110111100001. equivalent 1101 1110 0001 = DE1 16 E 1 process performed naturally experienced programmer mentally convert visual representations binary data hexadecimal equiva - lent without written effort. 9.6 KEY TERMS PROBLEMS Key Terms base binary decimal fractionhexadecimal integer least significant digit significant digitnibble positional number system radix radix point Problems 9.1 Count 1 2010 following bases: a. 8 b. 6 c. 5 d. 3 9.2 Order numbers (1.1)2, (1.4)10, (1.5)16 smallest largest. 9.3 Perform indicated base conversions: a. 548 base 5 b. 3124 base 7 c. 5206 base 7 d. 122123 base 9 9.4 generalizations draw converting number one base power base; e.g., base 3 base 9 (32) base 2 base 4 (22) base 8 (23)? 9.5 Convert following binary numbers decimal equivalents: a. 001100 b. 000011 c. 011100 d. 111100 e. 101010 9.6 Convert following binary numbers decimal equivalents: a. 11100.011 b. 110011.10011 c. 1010101010.1 9.7 Convert following decimal numbers binary equivalents: a. 64 b. 100 c. 111 d. 145 e. 255 9.8 Convert following decimal numbers binary equivalents: a. 34.75 b. 25.25 c. 27 .18759.6 / Key Te RmS PRoblem 327 9.9 Prove every real number terminating binary representation (finite number digits right binary point) also terminating decimal representation (finite number digits right decimal point). 9.10 Express following octal numbers (number radix 8) hexadecimal notation: a. 12 b. 5655 c. 2550276 d. 76545336 e. 3726755 9.11 Convert following hexadecimal numbers decimal equivalents: a. C b. 9F c. D52 d. 67E e. ABCD 9.12 Convert following hexadecimal numbers decimal equivalents: a. F.4 b. D3.E c. 1111.1 d. 888.8 e. EBA.C 9.13 Convert following decimal numbers hexadecimal equivalents: a. 16 b. 80 c. 2560 d. 3000 e. 62,500 9.14 Convert following decimal numbers hexadecimal equivalents: a. 204.125 b. 255.875 c. 631.25 d. 10000.00390625 9.15 Convert following hexadecimal numbers binary equivalents: a. E b. 1C c. A64 d. 1F.C e. 239.4 9.16 Convert following binary numbers hexadecimal equivalents: a. 1001.1111 b. 110101.011001 c. 10100111.111011328 Chapter Computer Arithmeti C 10.1 Arithmetic Logic Unit 10.2 Integer Representation Sign-Magnitude Representation Twos Complement Representation Range Extension Fixed-Point Representation 10.3 Integer Arithmetic Negation Addition Subtraction Multiplication Division 10.4 Floating-Point Representation Principles IEEE Standard Binary Floating-Point Representation 10.5 Floating-Point Arithmetic Addition Subtraction Multiplication Division Precision Considerations IEEE Standard Binary Floating-Point Arithmetic 10.6 Key Terms, Review Questions, Problems 10.1 / Ari ThmeTic Logic Uni 329 begin examination processor overview arithmetic logic unit (ALU). chapter focuses complex aspect ALU, computer arithmetic. implementations simple logic arithmetic functions digital logic described Chapter 11, logic functions part ALU described Chapter 12. Computer arithmetic commonly performed two different types numbers: integer floating point. cases, representation chosen cru - cial design issue treated first, followed discussion arithmetic operations. chapter includes number examples, highlighted shaded box. 10.1 Ari ThmeTic Logic Uni ALU part computer actually performs arithmetic logical operations data. elements computer system—control unit, registers, memory, I/O—are mainly bring data ALU process take results back out. have, sense, reached core essence computer consider ALU. ALU indeed, electronic components computer, based use simple digital logic devices store binary digits perform simple Boolean logic operations. Figure 10.1 indicates, general terms, ALU interconnected rest processor. Operands arithmetic logic operations presented ALU registers, results operation stored registers. registers temporary storage locations within processor connected signal paths ALU (e.g., see Figure 2.3). ALU may also set flags result operation. example, overflow flag set 1 result com - putation exceeds length register stored.Learning Objectives studying chapter, able to: rUnderstand distinction way numbers represented (the binary format) algorithms used basic arithmetic operations. rExplain twos complement representation . rPresent overview techniques basic arithmetic operation two complement notation. rUnderstand use significand, base, exponent representation floating-point numbers . rPresent overview IEEE 754 standard floating-point representation. rUnderstand key concepts related floating-point arithmetic, including guard bits, rounding, subnormal numbers, underflow overflow.330 chApTer 10 / compUTer Ari ThmeTic flag values also stored registers within processor. processor pro - vides signals control operation ALU movement data ALU. 10.2 inTeger represen TATion binary number system,1 arbitrary numbers represented digits zero one, minus sign (for negative numbers), period, radix point (for numbers fractional component). -1101.01012=-13.312510 purposes computer storage processing, however, ben - efit special symbols minus sign radix point. binary digits (0 1) may used represent numbers. limited nonnegative integers, representation straightforward.ALUContr ol signals Operand registersFlags Result registers Figure 10.1 ALU Inputs Outputs 1See Chapter 9 basic refresher number systems (decimal, binary, hexadecimal).An 8-bit word represent numbers 0 255, 00000000= 0 00000001= 1 00101001= 41 10000000=128 11111111=255 general, n-bit sequence binary digits an-1an-2 c a1a0 inter - preted unsigned integer A, value A=an-1 i=02iai10.2 / inTeger represen TATion 331 Sign-Magnitude Representation several alternative conventions used represent negative well pos - itive integers, involve treating significant (leftmost) bit word sign bit. sign bit 0, number positive; sign bit 1, number negative. simplest form representation employs sign bit sign-magni - tude representation. n-bit word, rightmost n-1 bits hold magnitude integer. +18 =00010010 -18 =10010010 (sign magnitude) general case expressed follows: Sign Magnitude A=µan-2 i=0 2iai an-1=0 -an-2 i=02iai an-1=1 (10.1) several drawbacks sign-magnitude representation. One addition subtraction require consideration signs numbers relative magnitudes carry required operation. become clear discussion Section 10.3. Another drawback two representations 0: + 010 =00000000 - 010 =10000000 (sign magnitude) inconvenient slightly difficult test 0 (an operation performed frequently computers) single representation. drawbacks, sign-magnitude representation rarely used implementing integer portion ALU. Instead, common scheme twos complement representation.2 Twos Complement Representation Like sign magnitude, twos complement representation uses significant bit sign bit, making easy test whether integer positive negative. dif - fers use sign-magnitude representation way bits interpreted. Table 10.1 highlights key characteristics twos complement repre - sentation arithmetic, elaborated section next. treatments twos complement representation focus rules producing negative numbers, formal proof scheme valid. Instead, 2In literature, terms two’s complement 2’s complement often used. follow practice used standards documents omit apostrophe (e.g., IEEE Std 100-1992, New IEEE Standard Dictionary Electrical Electronics Terms ).332 chApTer 10 / compUTer Ari ThmeTic presentation twos complement integers section Section 10.3 based [DATT93], suggests twos complement representation best understood defining terms weighted sum bits, previously unsigned sign-magnitude representations. advantage treatment leave lingering doubt rules arithmetic operations twos complement notation may work special cases. Consider n-bit integer, A, twos complement representation. pos - itive, sign bit, an-1, zero. remaining bits represent magnitude number fashion sign magnitude: A=an-2 i=02iai AÚ0 number zero identified positive therefore 0 sign bit magni - tude 0s. see range positive integers may represented 0 (all magnitude bits 0) 2n-1-1 (all magnitude bits 1). larger number would require bits. Now, negative number A(A60), sign bit, an-1, one. remain - ing n-1 bits take one 2n-1 values. Therefore, range negative integers represented -1 -2n-1. would like assign bit values negative integers way arithmetic handled straight - forward fashion, similar unsigned integer arithmetic. unsigned integer represen - tation, compute value integer bit representation, weight significant bit +2n-1. representation sign bit, turns desired arithmetic properties achieved, see Section 10.3, weight significant bit -2n-1. convention used twos complement representation, yielding following expression negative numbers: Twos Complement A=-2n-1an-1+an-2 i=02iai (10.2) Equation (10.2) defines twos complement representation positive negative numbers. an-1=0, term -2n-1an-1=0 equation defines Table 10.1 Characteristics Twos Complement Representation Arithmetic Range -2n-1 2n-1-1 Number Representations ZeroOne Negation Take Boolean complement bit corresponding positive number, add 1 resulting bit pattern viewed unsigned integer. Expansion Bit Length Add additional bit positions left fill value original sign bit. Overflow Rule two numbers sign (both positive nega- tive) added, overflow occurs result opposite sign. Subtraction Rule subtract B A, take twos complement B add A.10.2 / inTeger represen TATion 333 nonnegative integer. an-1=1, term 2n-1 subtracted summa - tion term, yielding negative integer. Table 10.2 compares sign-magnitude twos complement representa - tions 4-bit integers. Although twos complement awkward representation human point view, see facilitates important arith - metic operations, addition subtraction. reason, almost universally used processor representation integers. useful illustration nature twos complement representation value box, value far right box 1 (20) succeeding position left double value, leftmost position, negated. see Figure 10.2a, negative twos complement number represented -2n-1; bits sign bit one, adds positive amount number. Also, clear negative number must 1 leftmost position positive number must 0 position. Thus, largest positive number 0 followed 1s, equals 2n-1-1. rest Figure 10.2 illustrates use value box convert twos complement decimal decimal twos complement. Range Extension sometimes desirable take n-bit integer store bits, m7n. expansion bit length referred range extension , range numbers expressed extended increasing bit length.Table 10.2 Alternative Representations 4-Bit Integers Decimal RepresentationSign-Magnitude RepresentationTwos Complement RepresentationBiased Representation +8 — — 1111 +7 0111 0111 1110 +6 0110 0110 1101 +5 0101 0101 1100 +4 0100 0100 1011 +3 0011 0011 1010 +2 0010 0010 1001 +1 0001 0001 1000 +0 0000 0000 0111 -0 1000 — — -1 1001 1111 0110 -2 1010 1110 0101 -3 1011 1101 0100 -4 1100 1100 0011 -5 1101 1011 0010 -6 1110 1010 0001 -7 1111 1001 0000 -8 — 1000 —334 chApTer 10 / compUTer Ari ThmeTic sign-magnitude notation, easily accomplished: simply move sign bit new leftmost position fill zeros. +18 = 00010010 (sign magnitude, 8 bits) +18 = 0000000000010010 (sign magnitude, 16 bits) -18 = 10010010 (sign magnitude, 8 bits) -18 = 1000000000010010 (sign magnitude, 16 bits) procedure work twos complement negative integers. Using example,−128 64 32 16 8 4 2 1 (a) eight-position twos complement v alue box −128 64 32 16 8 4 2 1 −128 +2 +1 = −125 (b) Con vert binary 10000011 decimal −128 64 32 16 8 4 2 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 −120 = −128 +8 (c) Con vert decimal −120 binary Figure 10.2 Use Value Box Conversion Twos Complement Binary Decimal +18 = 00010010 (twos complement, 8 bits) +18 = 0000000000010010 (twos complement, 16 bits) -18 = 11101110 (twos complement, 8 bits) - 32,658 = 1000000001101110 (twos complement, 16 bits) next last line easily seen using value box Figure 10.2. last line verified using Equation (10.2) 16-bit value box. Instead, rule twos complement integers move sign bit new leftmost position fill copies sign bit. positive numbers, fill zeros, negative numbers, fill ones. called sign extension. -18 = 11101110 (twos complement, 8 bits) -18 = 1111111111101110 (twos complement, 16 bits)10.3 / inTeger Ari ThmeTic 335 see rule works, let us consider n-bit sequence bin - ary digits an-1 an-2 c a1a0 interpreted twos complement integer A, value A=-2n-1an-1+an-2 i=02iai positive number, rule clearly works. Now, negative want construct m-bit representation, m7n. A=-2m-1am-1+am-2 i=02iai two values must equal: -2m-1+am-2 i=02iai=-2n-1+an-2 i=02iai -2m-1+am-2 i=n-12iai=-2n-1 -2n-1+am-2 i=n-12iai=2m-1 1+an-2 i=02i+am-2 i=n-12iai=1+am-2 i=02i am-2 i=n-12iai=am-2 i=n-12i 1 am-2=c =an-2=an-2=1 going first second equation, require least signifi - cant n-1 bits change two representations. get next last equation, true bits positions n-1 m-2 1. Therefore, sign-extension rule works. reader may find rule easier grasp studying discussion twos complement negation beginning Section 10.3. Fixed-Point Representation Finally, mention representations discussed section sometimes referred fixed point. radix point (binary point) fixed assumed right rightmost digit. programmer use representation binary fractions scaling numbers binary point implicitly positioned location. 10.3 inTeger Ari ThmeTic section examines common arithmetic functions numbers twos comple - ment representation.336 chApTer 10 / compUTer Ari ThmeTic Negation sign-magnitude representation, rule forming negation integer simple: invert sign bit. twos complement notation, negation integer formed following rules: 1. Take Boolean complement bit integer (including sign bit). is, set 1 0 0 1. 2. Treating result unsigned binary integer, add 1. two-step process referred twos complement operation , taking twos complement integer. +18 = 00010010 (twos complement) bitwise complement = 11101101 + 1 11101110 = -18 expected, negative negative number itself: -18 = 11101110 (twos complement) bitwise complement = 00010001 + 1 00010010 = +18 demonstrate validity operation described using defi - nition twos complement representation Equation (10.2). Again, interpret n-bit sequence binary digits an-1an-2 c a1a0 twos complement integer A, value A=-2n-1an-1+an-2 i=02iai form bitwise complement, an-1an-2 c a0, and, treating unsigned integer, add 1. Finally, interpret resulting n-bit sequence binary dig - twos complement integer B, value B=-2n-1an-1+1+an-2 i=02iai Now, want A=-B, means A+B=0. easily shown true: A+B=-(an-1+an-1)2n-1+1+aan-2 i=02i(ai+ai)b =-2n-1+1+aan-2 i=02ib =-2n-1+1+(2n-1-1) =-2n-1+2n-1=010.3 / inTeger Ari ThmeTic 337 preceding derivation assumes first treat bitwise complement unsigned integer purpose adding 1, treat result twos complement integer. two special cases consider. First, consider A=0. case, 8-bit representation: 0 = 00000000 (twos complement) bitwise complement = 11111111 + 1 100000000 = 0 carry significant bit position, ignored. result negation 0 0, be. second special case problem. take negation bit pattern 1 followed n-1 zeros, get back number. example, 8-bit words, +128 = 10000000 (twos complement) bitwise complement = 01111111 + 1 10000000 = -128 anomaly unavoidable. number different bit patterns n-bit word 2 n, even number. wish represent positive neg - ative integers 0. equal number positive negative integers rep - resented (sign magnitude), two representations 0. one representation 0 (twos complement), must unequal number negative positive numbers represented. case twos complement, n-bit length, representation -2n-1 +2n-1. Addition Subtraction Addition twos complement illustrated Figure 10.3. Addition proceeds two numbers unsigned integers. first four examples illustrate successful operations. result operation positive, get positive number twos complement form, unsigned-integer form. result operation negative, get negative number twos complement form. Note that, instances, carry bit beyond end word (indicated shading), ignored. addition, result may larger held word size used. condition called overflow . overflow occurs, ALU must signal fact attempt made use result. detect overflow, following rule observed: OvERFLO w RULE : two numbers added, positive negative, overflow occurs result opposite sign.338 chApTer 10 / compUTer Ari ThmeTic Figures 10.3e f show examples overflow. Note overflow occur whether carry. Subtraction easily handled following rule:Figure 10.3 Addition Numbers Twos Complement Representation SUBTRACTION RULE : subtract one number (subtrahend) another (minuend), take twos complement (negation) subtrahend add minuend. Thus, subtraction achieved using addition, illustrated Figure 10.4. last two examples demonstrate overflow rule still applies. Figure 10.4 Subtraction Numbers Twos Complement Representation (M-S)10.3 / inTeger Ari ThmeTic 339 insight twos complement addition subtraction gained looking geometric depiction [BENH92], shown Figure 10.5. circle upper half part figure formed selecting appropriate seg - ment number line joining endpoints. Note numbers laid circle, twos complement number horizontally opposite number (indicated dashed horizontal lines). Starting number circle, add positive k (or subtract negative k) number moving k positions clockwise, subtract positive k (or add negative k) number moving k positions counterclockwise. arithmetic operation results traversal point endpoints joined, incorrect answer given (overflow).0000 0+1 +2 +3 +4 +5 +6 +7 –8–7–6–5–4–3–2–10001Addition positive numbersSubtraction positive numbers 0010 0011 0100 0101 0110 01111000 (a) 4-bit numbers (b) n-bit numbers1001101010111100110111101111 0–1–2–3–4–5–6–7–8–9 123456789000…0 0 2n–2 –2n–1–2n–2–1Addition positive numbersSubtraction positive numbers 010…0 011…1100…0110…0111…1 –2n–1 –2n–1–1 2n–12n–1–12n–1–1 Figure 10.5 Geometric Depiction Twos Complement Integers examples Figures 10.3 10.4 easily traced circle Figure 10.5. Figure 10.6 suggests data paths hardware elements needed accom - plish addition subtraction. central element binary adder, pre - sented two numbers addition produces sum overflow indication. binary adder treats two numbers unsigned integers. (A logic implemen - tation adder given Chapter 11.) addition, two numbers pre - sented adder two registers, designated case B registers. result may stored one registers third. overflow indi - cation stored 1-bit overflow flag (0=no overflow; 1=overflow). sub - traction, subtrahend ( B register) passed twos complementer twos complement presented adder. Note Figure 10.6 shows 340 chApTer 10 / compUTer Ari ThmeTic data paths. Control signals needed control whether complementer used, depending whether operation addition subtraction. Multiplication Compared addition subtraction, multiplication complex operation, whether performed hardware software. wide variety algorithms used various computers. purpose subsection give reader feel type approach typically taken. begin simpler problem multiplying two unsigned (nonnegative) integers, look one common techniques multiplication numbers twos complement representation. unsigned integers Figure 10.7 illustrates multiplication unsigned binary integers, might carried using paper pencil. Several important observations made: 1. Multiplication involves generation partial products, one digit multiplier. partial products summed produce final product.Adder = Over/f_low bit SW = Switch (select addition subtraction)ComplementerA Register B Register SW Figure 10.6 Block Diagram Hardware Addition Subtraction 1011 ×1101 1011 0000 1011 1011 10001111Multiplicand (11) Multiplier (13) Product (143)Partial pr oducts Figure 10.7 Multiplication Unsigned Binary Integers10.3 / inTeger Ari ThmeTic 341 2. partial products easily defined. multiplier bit 0, partial product 0. multiplier 1, partial product multiplicand. 3. total product produced summing partial products. oper - ation, successive partial product shifted one position left relative preceding partial product. 4. multiplication two n-bit binary integers results product 2 n bits length (e.g., 11*11=1001). Compared pencil-and-paper approach, several things make computerized multiplication efficient. First, perform run - ning addition partial products rather waiting end. eliminates need storage partial products; fewer registers needed. Second, save time generation partial products. 1 multiplier, add shift operation required; 0, shift required. Figure 10.8a shows possible implementation employing measures. multiplier multiplicand loaded two registers (Q M). third Mn–1Multiplicand (a) Block diagramAdd Shift right Multipliern-bit adderShift add contr ol logicM0 An–1 A0 Qn–1 Q0 C (b) Example Fi gure 10.7 (product A, Q)C 0 0 0 0 0 0 1 0A 0000 1011 0101 0010 1101 0110 0001 1000Q 1101 1101 1110 1111 1111 1111 1111 1111M 1011 1011 1011 1011 1011 1011 1011 1011Initial values Add Shift Shift Add Shift Add ShiftFirst cycle Second cycle Third cycle Fourth cycle Figure 10.8 Hardware Implementation Unsigned Binary Multiplication342 chApTer 10 / compUTer Ari ThmeTic register, register, also needed initially set 0. also 1-bit C register, initialized 0, holds potential carry bit resulting addition. operation multiplier follows. Control logic reads bits multiplier one time. Q0 1, multiplicand added register result stored register, C bit used overflow. bits C, A, Q registers shifted right one bit, C bit goes An-1, A0 goes Qn-1, Q0 lost. Q0 0, addition performed, shift. process repeated bit original multi - plier. resulting 2 n-bit product contained Q registers. flowchart operation shown Figure 10.9, example given Figure 10.8b. Note second cycle, multiplier bit 0, add operation. twos complement multiplication seen addition subtraction performed numbers twos complement notation treating unsigned integers. Consider 1001 + 0011 1100 numbers considered unsigned integers, adding 9 (1001) plus 3 (0011) get 12 (1100). twos complement integers, adding -7(1001) 3 (0011) get -4(1100). START ENDYes NoNo YesC, 0 Multiplicand Q Multiplier Count n Shift right C, A, Q Count Count – 1C, + MQ0 = 1? Count = 0? Product A, Q Figure 10.9 Flowchart Unsigned Binary Multiplication10.3 / inTeger Ari ThmeTic 343 Unfortunately, simple scheme work multiplication. see this, consider Figure 10.7. multiplied 11 (1011) 13 (1101) get 143 (10001111). interpret twos complement numbers, -5(1011) times -3 (1101) equals -113 (10001111). example demonstrates straight - forward multiplication work multiplicand multiplier negative. fact, work either multiplicand multiplier nega - tive. justify statement, need go back Figure 10.7 explain done terms operations powers 2. Recall unsigned binary number expressed sum powers 2. Thus, 1101=1*23+1*22+0*21+1*20 =23+22+20 Further, multiplication binary number 2n accomplished shift - ing number left n bits. mind, Figure 10.10 recasts Figure 10.7 make generation partial products multiplication explicit. difference Figure 10.10 recognizes partial products viewed 2 n-bit numbers generated n-bit multiplicand. Thus, unsigned integer, 4-bit multiplicand 1011 stored 8-bit word 00001011. partial product (other 20) consists num - ber shifted left, unoccupied positions right filled zeros (e.g., shift left two places yields 00101100). demonstrate straightforward multiplication work multiplicand negative. problem contribution negative multiplicand partial product must negative number 2 n-bit field; sign bits partial products must line up. demonstrated Figure 10.11, shows multiplication 1001 0011. treated unsigned integers, multiplication 9*3=27 proceeds simply. However, 1001 interpreted 1011 × 1101 00001011 1011 × 1 × 20 00000000 1011 × 0 × 21 00101100 1011 × 1 × 22 01011000 1011 × 1 × 23 10001111 Figure 10.10 Multiplication Two Unsigned 4-Bit Integers Yielding 8-Bit Result 1001 (9) × 0011(3) 00001001 1001 × 20 00010010 1001 × 21 00011011 (27) 1001 (–7) × 0011(3) 11111001 (–7) × 20 = (–7) 11110010 (–7) × 21 = (–14) 11101011 (–21) (a) Unsigned inte gers (b) Twos complement inte gers Figure 10.11 Comparison Multiplication Unsigned Twos Complement Integers344 chApTer 10 / compUTer Ari ThmeTic twos complement value -7, partial product must negative twos complement number 2 n (8) bits, shown Figure 10.11b. Note accomplished padding partial product left binary 1s. multiplier negative, straightforward multiplication also work. reason bits multiplier longer correspond shifts multiplications must take place. example, 4-bit decimal number -3 written 1101 twos complement. simply took partial products based bit position, would following correspondence: 11014-(1*23+1*22+0*21+1*20)=-(23+22+20) fact, desired -(21+20). multiplier cannot used directly manner describing. number ways dilemma. One would convert multiplier multiplicand positive numbers, perform multiplication, take twos complement result sign two original numbers differed. Implementers preferred use techniques require final transformation step. One common Booth’s algorithm [BOOT51]. algorithm also benefit speeding multiplication process, relative straightforward approach. Booth’s algorithm depicted Figure 10.12 described follows. before, multiplier multiplicand placed Q registers, START ENDYes No/H11549 10 /H11549 01 /H11549 11 /H11549 00A 0, Q /H115461 0 Multiplicand Q Multiplier Count n Arithmetic shift Right: A, Q, Q /H115461 Count Count /H11546 1A /H11545 /H11546 MQ0, Q/H115461 Count /H11549 0? Figure 10.12 Booth’s Algorithm Twos Complement Multiplication10.3 / inTeger Ari ThmeTic 345 respectively. also 1-bit register placed logically right least significant bit (Q0) Q register designated Q-1; use explained shortly. results multiplication appear Q registers. Q-1 initialized 0. before, control logic scans bits multiplier one time. Now, bit examined, bit right also examined. two bits (1–1 0–0), bits A, Q, Q-1 registers shifted right 1 bit. two bits differ, multiplicand added subtracted register, depending whether two bits 0–1 1–0. Following addition subtraction, right shift occurs. either case, right shift leftmost bit A, namely An-1, shifted An-2, also remains An-1. required preserve sign number Q. known arithmetic shift , preserves sign bit. Figure 10.13 shows sequence events Booth’s algorithm multi - plication 7 3. compactly, operation depicted Figure 10.14a. rest Figure 10.14 gives examples algorithm. seen, works combination positive negative numbers. Note also effi - ciency algorithm. Blocks 1s 0s skipped over, average one addition subtraction per block.Q–1 0 0 1 1 1 0 0A 0000 1001 1100 1110 0101 0010 0001Q 0011 0011 1001 0100 0100 1010 0101M 0111 0111 0111 0111 0111 0111 0111Initial values – Shift Shift + Shift ShiftFirst cycle Second cycle Third cycle Fourth cycle Figure 10.13 Example Booth’s Algorithm (7*3) 0111 × 0011 (0) 11111001 1–0 0000000 1–1 000111 0–1 00010101 (21) 0111 × 1101 (0) 11111001 1–0 0000111 0–1 111001 1–0 11101011 (–21) (a) (7) × (3) = (21) (b) (7) × (−3) = (−21) 1001 × 0011 (0) 00000111 1–0 0000000 1–1 111001 0–1 11101011 (–21) 1001 × 1101 (0) 00000111 1–0 1111001 0–1 000111 1–0 00010101 (21) (c) (−7) × (3) = (−21) (d) (−7) × (−3) = (21) Figure 10.14 Examples Using Booth’s Algorithm346 chApTer 10 / compUTer Ari ThmeTic Booth’s algorithm work? Consider first case positive multi - plier. particular, consider positive multiplier consisting one block 1s sur - rounded 0s (e.g., 00011110). know, multiplication achieved adding appropriately shifted copies multiplicand: M*(00011110)=M*(24+23+22+21) =M*(16+8+4+2) =M*30 number operations reduced two observe 2n+2n-1+c +2n-K=2n+1-2n-K (10.3) M*(00011110)=M*(25-21) =M*(32-2) =M*30 product generated one addition one subtraction multi - plicand. scheme extends number blocks 1s multiplier, including case single 1 treated block. M*(01111010)=M*(26+25+24+23+21) =M*(27-23+22-21) Booth’s algorithm conforms scheme performing subtraction first 1 block encountered (1–0) addition end block encountered (0–1). show scheme works negative multiplier, need observe following. Let X negative number twos complement notation: Representation X=51xn-2xn-3cx1x06 value X expressed follows: X=-2n-1+(xn-2*2n-2)+(xn-3*2n-3)+c(x1*21)+(x0*20) (10.4) reader verify applying algorithm numbers Table 10.2. leftmost bit X 1, X negative. Assume leftmost 0 kth position. Thus, X form Representation X=5111 c 10xk-1xk-2cx1x06 (10.5) value X X=-2n-1+2n-2+c +2k+1+(xk-1*2k-1)+c +(x0*20) (10.6) Equation (10.3), say 2n-2+2n-3+c +2k-1=2n-1-2k-110.3 / inTeger Ari ThmeTic 347 Rearranging -2n-1+2n-2+2n-3+c +2k+1=-2k+1 (10.7) Substituting Equation (10.7) Equation (10.6), X=-2k+1+(xk-1*2k-1)+c +(x0*20) (10.8) last return Booth’s algorithm. Remembering representation X [Equation (10.5)], clear bits x0 leftmost 0 handled properly produce terms Equation (10.8) (-2k+1) thus proper form. algorithm scans leftmost 0 encounters next 1 (2k+1), 1–0 transition occurs subtraction takes place (-2k+1). remaining term Equation (10.8). example, consider multiplication multiplicand (-6). twos complement representation, using 8-bit word, (-6) represented 11111010. Equation (10.4), know -6=-27+26+25+24+23+21 reader easily verify. Thus, M*(11111010)=M*(-27+26+25+24+23+21) Using Equation (10.7), M*(11111010)=M*(-23+21) reader verify still M*(-6). Finally, following earlier line reasoning, M*(11111010)=M*(-23+22-21) see Booth’s algorithm conforms scheme. performs sub - traction first 1 encountered (10), addition (01) encountered, finally another subtraction first 1 next block 1s encoun - tered. Thus, Booth’s algorithm performs fewer additions subtractions straightforward algorithm. Division Division somewhat complex multiplication based general principles. before, basis algorithm paper-and-pencil approach, operation involves repetitive shifting addition subtraction. Figure 10.15 shows example long division unsigned binary inte - gers. instructive describe process detail. First, bits dividend examined left right, set bits examined represents number greater equal divisor; referred divisor able divide number. event occurs, 0s placed quotient left right. event occurs, 1 placed quotient divisor sub - tracted partial dividend. result referred partial remainder.348 chApTer 10 / compUTer Ari ThmeTic point on, division follows cyclic pattern. cycle, additional bits dividend appended partial remainder result greater equal divisor. before, divisor subtracted number produce new partial remainder. process continues bits dividend exhausted. Figure 10.16 shows machine algorithm corresponds long division process. divisor placed register, dividend Q register. 00001101 1011 10010011 1011 001110 1011 001111 1011 100Quotient Dividend Divisor RemainderPartial remainders Figure 10.15 Example Division Unsigned Binary Integers START ENDYes NoNo Yes Quotient Q Remainder AA 0 Divisor Q Dividend Count n Shift left A, Q /H11546 Count Count /H11546 1Q0 1Q0 0 /H11545 /H11021 0? Count /H11549 0? Figure 10.16 Flowchart Unsigned Binary Division10.3 / inTeger Ari ThmeTic 349 step, Q registers together shifted left 1 bit. subtracted determine whether divides partial remainder.3 does, Q0 gets 1 bit. Otherwise, Q0 gets 0 bit must added back restore previous value. count decremented, process continues n steps. end, quotient Q register remainder register. process can, difficulty, extended negative numbers. give one approach twos complement numbers. example approach shown Figure 10.17. algorithm assumes divisor V dividend positive ∙V∙6∙D∙. ∙V∙=∙D∙, quotient Q=1 remainder R=0. ∙V∙7∙D∙, Q=0 R=D. algorithm summarized follows: 1. Load twos complement divisor register; is, register contains negative divisor. Load dividend A, Q registers. dividend must expressed 2 n-bit positive number. Thus, example, 4-bit 0111 becomes 00000111. 2. Shift A, Q left 1 bit position. 3. Perform AdA-M. operation subtracts divisor contents A. 4. a. result nonnegative (most significant bit A=0), set Q0d1. b. result negative (most significant bit A=1), set Q0d0. restore previous value A. 5. Repeat steps 2 4 many times bit positions Q. 6. remainder quotient Q. 3This subtraction unsigned integers. result requires borrow significant bit negative result.AQ Initial value Shift Use twos complement 0011 f subtraction Subtract Restor e, set Q0 = 0 Subtract, set Q0 = 1Shift Subtract Restor e, set Q0 = 0 ShiftShift Subtract Restor e, set Q0 = 0 Figure 10.17 Example Restoring Twos Complement Division (7/3)350 chApTer 10 / compUTer Ari ThmeTic deal negative numbers, recognize remainder defined D=Q*V+R is, remainder value R needed preceding equation valid. Consider following examples integer division possible com - binations signs V: D=7 V=3 1 Q=2 R=1 D=7 V=-3 1 Q=-2R=1 D=-7V=3 1 Q=-2R=-1 D=-7V=-3 1 Q=2 R=-1 reader note Figure 10.17 (-7)/(3) (7)/(-3) produce different remainders. see magnitudes Q R unaffected input signs signs Q R easily derivable signs V. Specifically, sign(R)=sign(D) sign(Q)=sign(D)*sign(V). Hence, one way twos complement division convert operands unsigned values and, end, account signs complementation needed. method choice restoring division algorithm [PARH10]. 10.4 FLoATing-poinT represen TATion Principles fixed-point notation (e.g., twos complement) possible represent range positive negative integers centered near 0. assuming fixed binary radix point, format allows representation numbers frac - tional component well. approach limitations. large numbers cannot represented, small fractions. Furthermore, fractional part quotient div - ision two large numbers could lost. decimal numbers, get around limitation using scientific notation. Thus, 976,000,000,000,000 represented 9.76*1014, 0.0000000000000976 represented 9.76*10-14, done, effect, dynamically slide decimal point convenient location use exponent 10 keep track decimal point. allows range large small numbers represented digits. approach taken binary numbers. represent number form {S*B{E number stored binary word three fields: ■Sign: plus minus ■Significand ■Exponent E10.4 / F LoATing-poinT represen TATion 351 base B implicit need stored numbers. Typically, assumed radix point right leftmost, significant, bit significand. is, one bit left radix point. principles used representing binary floating-point numbers best explained example. Figure 10.18a shows typical 32-bit floating-point - mat. leftmost bit stores sign number (0=positive, 1=negative). exponent value stored next 8 bits. representation used known biased representation . fixed value, called bias, subtracted field get true exponent value. Typically, bias equals (2k-1-1), k number bits binary exponent. case, 8-bit field yields numbers 0 255. bias 127 (27-1), true exponent values range -127 to+128. example, base assumed 2. Table 10.2 shows biased representation 4-bit integers. Note bits biased representation treated unsigned integers, relative mag - nitudes numbers change. example, biased unsigned representations, largest number 1111 smallest number 0000. true sign-magnitude twos complement representation. advantage biased representation nonnegative floating-point numbers treated integers comparison purposes. final portion word (23 bits case) significand .4 floating-point number expressed many ways.8 bitsSign signi/f_icand Signi/f_icand23 bits (a) F ormat (b) Examples 1.1010001 × 210100 = 0 10010011 10100010000000000000000 = 1.6328125 × 220 –1.1010001 × 210100 = 1 10010011 10100010000000000000000 = –1.6328125 × 220 1.1010001 × 2–10100 = 0 01101011 10100010000000000000000 = 1.6328125 × 2–20 –1.1010001 × 2–10100 = 1 01101011 10100010000000000000000 = –1.6328125 × 2–20Biased exponent Figure 10.18 Typical 32-Bit Floating-Point Format 4The term mantissa , sometimes used instead significand, considered obsolete. Mantissa also means “the fractional part logarithm,” best avoided context.The following equivalent, significand expressed binary form: 0.110*25 110*22 0.0110*26 simplify operations floating-point numbers, typically required normalized. normal number one significant digit 352 chApTer 10 / compUTer Ari ThmeTic significand nonzero. base 2 representation, normal number therefore one significant bit significand one. mentioned, typical convention one bit left radix point. Thus, - mal nonzero number one form {1.bbbcb*2{E b either binary digit (0 1). significant bit always one, unnecessary store bit; rather, implicit. Thus, 23-bit field used store 24-bit significand value half open interval [1, 2). Given num - ber normal, number may normalized shifting radix point right leftmost 1 bit adjusting exponent accordingly. Figure 10.18b gives examples numbers stored format. example, left binary number; center corresponding bit pat - tern; right decimal value. Note following features: ■The sign stored first bit word. ■The first bit true significand always 1 need stored significand field. ■The value 127 added true exponent stored exponent field. ■The base 2. comparison, Figure 10.19 indicates range numbers rep - resented 32-bit word. Using twos complement integer representation, integers -231 231-1 represented, total 232 different num - bers. example floating-point format Figure 10.18, following ranges numbers possible: ■Negative numbers -(2-2-23)*2128 -2-127 ■Positive numbers 2-127 (2-2-23)*2128 Expr essible integers Expr essible negative numbersNegative over/f_l owPositive over/f_l owNegativ e under/f_l ow ZeroPositive under/f_l ow Expr essible positiv e numbers(a) Twos complement inte gers (b) Floating-point numbersNumber line Number line0 0 Figure 10.19 Expressible Numbers Typical 32-Bit Formats10.4 / F LoATing-poinT represen TATion 353 Five regions number line included ranges: ■Negative numbers less -(2-2-23)*2128, called negative overflow ■Negative numbers greater 2-127, called negative underflow ■Zero ■Positive numbers less 2-127, called positive underflow ■Positive numbers greater (2-2-23)*2128, called positive overflow representation presented accommodate value 0. - ever, shall see, actual floating-point representations include special bit pattern designate zero. Overflow occurs arithmetic operation results absolute value greater expressed exponent 128 (e.g., 2120*2100=2220). Underflow occurs fractional magnitude small (e.g., 2-120*2-100=2-220). Underflow less serious problem result generally satisfactorily approximated 0. important note representing individual values floating-point notation. maximum number different values represented 32 bits still 232. done spread numbers two ranges, one positive one negative. practice, floating-point numbers one would wish represent represented approximately. However, moderate sized integers, representation exact. Also, note numbers represented floating-point notation spaced evenly along number line, fixed-point numbers. possible val - ues get closer together near origin farther apart move away, shown Figure 10.20. one trade-offs floating-point math: Many calcula - tions produce results exact rounded nearest value notation represent. type format depicted Figure 10.18, trade-off range precision. example shows 8 bits devoted exponent 23 significand. increase number bits exponent, expand range expressible numbers. fixed number different values expressed, reduced density numbers therefore precision. way increase range precision use bits. Thus, computers offer, least, single-precision numbers doublepreci - sion numbers. example, processor could support single-precision format 64 bits, double-precision format 128 bits. trade-off number bits exponent number bits significand. even complicated that. implied base exponent need 2. IBM S/390 architecture, example, uses base 16 [ANDE67b]. format consists 7-bit exponent 24-bit significand. 0 /H11546nn 2n 4n Figure 10.20 Density Floating-Point Numbers354 chApTer 10 / compUTer Ari ThmeTic advantage using larger exponent greater range achieved number exponent bits. remember, increased number different values represented. Thus, fixed format, larger exponent base gives greater range expense less precision. IEEE Standard Binary Floating-Point Representation important floating-point representation defined IEEE Standard 754, adopted 1985 revised 2008. standard developed facilitate portability programs one processor another encourage devel - opment sophisticated, numerically oriented programs. standard widely adopted used virtually contemporary processors arithmetic coprocessors. IEEE 754-2008 covers binary decimal floating-point repre - sentations. chapter, deal binary representations. IEEE 754-2008 defines following different types floating-point formats: ■Arithmetic format: mandatory operations defined standard supported format. format may used represent floating-point operands results operations described standard. ■Basic format: format covers five floating-point representations, three binary two decimal, whose encodings specified standard, used arithmetic. least one basic formats imple - mented conforming implementation. ■Interchange format: fully specified, fixed-length binary encoding allows data interchange different platforms used storage. three basic binary formats bit lengths 32, 64, 128 bits, exponents 8, 11, 15 bits, respectively (Figure 10.21). Table 10.3 summarizes characteristics three formats. two basic decimal formats bit lengths 64 128 bits. basic formats also arithmetic format types (can used arithmetic operations) interchange format types (platform independent). Several formats specified standard. binary16 format interchange format intended storage values higher pre - cision required. binary{ k} format decimal{ k} format inter - change formats total length k bits defined lengths significand exponent. format must multiple 32 bits; thus formats defined k=160, 192, on. two families formats also arithmetic formats. addition, standard defines extended precision formats , extend supported basic format providing additional bits exponent (extended range) significand (extended precision). exact format IBM base-16 format, 0.11010001*210100=0.11010001*16101 exponent stored represent 5 rather 20.10.4 / F LoATing-poinT represen TATion 355 implementation dependent, standard places certain constraints length exponent significand. formats arithmetic format types interchange format types. extended formats used inter - mediate calculations. greater precision, extended formats lessen Trailing signi/f_icand /f_ield (c) Binary128 formatBiased exponentTrailing signi/f_icand /f_ield (b) Binary64 format8 bitsSign bit Trailing signi/f_icand /f_ield (a) Binary32 formatBiased exponent 23 bits 11 bits 52 bits 15 bits 112 bitsSign bitBiased exponent Sign bit Figure 10.21 IEEE 754 Formats Table 10.3 IEEE 754 Format Parameters ParameterFormat Binary32 Binary64 Binary128 Storage width (bits) 32 64 128 Exponent width (bits) 8 11 15 Exponent bias 127 1023 16383 Maximum exponent 127 1023 16383 Minimum exponent -126 -1022 -16382 Approx normal number range (base 10)10-38, 10+3810-308, 10+30810-4932, 10+4932 Trailing significand width (bits)* 23 52 112 Number exponents 254 2046 32766 Number fractions 2232522112 Number values 1.98*2311.99*2631.99*2128 Smallest positive normal number 2-1262-10222-16362 Largest positive normal number 2128-210421024-2971216384-216271 Smallest subnormal magnitude 2-1492-10742-16494 Note : * including implied bit including sign bit.356 chApTer 10 / compUTer Ari ThmeTic chance final result contaminated excessive roundoff error; greater range, also lessen chance intermediate overflow aborting computation whose final result would representable basic format. additional motivation extended format affords benefits larger basic format without incurring time penalty usually associated higher precision. Finally, IEEE 754-2008 defines extendable precision format format precision range defined user control. Again, formats may used intermediate calculations, standard places constraint format length. Table 10.4 shows relationship defined formats format types. bit patterns IEEE formats interpreted usual way; instead, bit patterns used represent special values. Table 10.5 indicates values assigned various bit patterns. exponent values zeros (0 bits) ones (1 bits) define special values. following classes numbers represented: ■For exponent values range 1 254 32-bit format, 1 2046 64-bit format, 1 16382, normal nonzero floating-point numbers represented. exponent biased, range expo - nents -126 +127 32-bit format, on. normal number requires 1 bit left binary point; bit implied, giving effec - tive 24-bit, 53-bit, 113-bit significand. one bits implied, corresponding field binary format referred trailing signifi - cand field . ■An exponent zero together fraction zero represents positive negative zero, depending sign bit. mentioned, useful exact value 0 represented. Table 10.4 IEEE Formats FormatFormat Type Arithmetic Format Basic Format Interchange Format binary16 X binary32 X X X binary64 X X X binary128 X X X binary{ k} (k = n * 32 n 7 4)X X decimal64 X X X decimal128 X X X decimal{ k} (k = n * 32 n 7 4)X X extended precision X extendable precision X10.4 / F LoATing-poinT represen TATion 357 Table 10.5 Interpretation IEEE 754 Floating-Point Numbers (a) binary32 format Sign Biased Exponent Fraction value positive zero 0 0 0 0 negative zero 1 0 0 -0 plus infinity 0 1s 0 ∞ minus infinity 1 1s 0 -∞ quiet NaN 0 1 1s ≠0; first bit=1 qNaN signaling NaN 0 1 1s ≠0; first bit=0 sNaN positive normal nonzero 0 06e6225 f 2e-127(1.f) negative normal nonzero 1 06e6225 f -2e-127(1.f) positive subnormal 0 0 f≠0 2e-126(0.f) negative subnormal 1 0 f≠0 -2e-126(0.f) (b) binary64 format Sign Biased Exponent Fraction value positive zero 0 0 0 0 negative zero 1 0 0 -0 plus infinity 0 1s 0 ∞ minus infinity 1 1s 0 -∞ quiet NaN 0 1 1s ≠0; first bit=1 qNaN signaling NaN 0 1 1s ≠0; first bit=0 sNaN positive normal nonzero 0 06e62047 f 2e-1023(1.f) negative normal nonzero 1 06e62047 f -2e-1023(1.f) positive subnormal 0 0 f≠0 2e-1022(0.f) negative subnormal 1 0 f≠0 -2e-1022(0.f) (c) binary128 format Sign Biased Exponent Fraction value positive zero 0 0 0 0 negative zero 1 0 0 -0 plus infinity 0 1s 0 ∞ minus infinity 1 1s 0 -∞ quiet NaN 0 1 1s ≠0; first bit=1 qNaN signaling NaN 0 1 1s ≠0; first bit=0 sNaN positive normal nonzero 0 1s f 2e-16383(1.f) negative normal nonzero 1 1s f -2e-16383(1.f) positive subnormal 0 0 f≠0 2e-16383(0.f) negative subnormal 1 0 f≠0 -2e-16383(0.f)358 chApTer 10 / compUTer Ari ThmeTic ■An exponent ones together fraction zero represents positive negative infinity, depending sign bit. also useful represen - tation infinity. leaves user decide whether treat - flow error condition carry value ∞ proceed whatever program executed. ■An exponent zero together nonzero fraction represents subnormal number. case, bit left binary point zero true exponent -126 or-1022. number positive negative depending sign bit. ■An exponent ones together nonzero fraction given value NaN, means Number , used signal various exception conditions. significance subnormal numbers NaNs discussed Section 10.5. 10.5 FLoATing-poinT AriThmeTic Table 10.6 summarizes basic operations floating-point arithmetic. addi - tion subtraction, necessary ensure operands exponent value. may require shifting radix point one operands achieve alignment. Multiplication division straightforward. floating-point operation may produce one conditions: ■Exponent overflow: positive exponent exceeds maximum possible expo - nent value. systems, may designated + ∞ or-∞. ■Exponent underflow: negative exponent less minimum possible exponent value (e.g., -200 less -127). means number small represented, may reported 0. Examples: X=0.3*102=30 Y=0.2*103=200 X+Y=(0.3*102-3+0.2)*103=0.23*103=230 X-Y=(0.3*102-3-0.2)*103=(-0.17)*103=-170 X*Y=(0.3*0.2)*102+3=0.06*105=6000 X,Y=(0.3,0.2)*102-3=1.5*10-1=0.15Table 10.6 Floating-Point Numbers Arithmetic Operations Floating-Point Numbers Arithmetic Operations X=XS*BXE Y=YS*BYEX+Y=(XS*BXE-YE+YS)*BYE X-Y=(XS*BXE-YE-YS)*BYEfXE…YE X*Y=(XS*YS)*BXE+YE X Y=aXS YSb*BXE-YE10.5 / F LoATing-poinT AriThmeTic 359 ■Significand underflow: process aligning significands, digits may flow right end significand. discuss, form rounding required. ■Significand overflow: addition two significands sign may result carry significant bit. fixed realign - ment, explain. Addition Subtraction floating-point arithmetic, addition subtraction complex multi - plication division. need alignment. four basic phases algorithm addition subtraction: 1. Check zeros. 2. Align significands. 3. Add subtract significands. 4. Normalize result. typical flowchart shown Figure 10.22. step-by-step narrative high - lights main functions required floating-point addition subtraction. assume format similar Figure 10.21. addition subtraction operation, two operands must transferred registers used ALU. floating-point format includes implicit significand bit, bit must made explicit operation. Phase 1. Zero check: addition subtraction identical except sign change, process begins changing sign subtrahend subtract operation. Next, either operand 0, reported result. Phase 2. Significand alignment: next phase manipulate numbers two exponents equal. see need aligning exponents, consider following decimal addition: (123*100)+(456*10-2) Clearly, cannot add significands. digits must first set equivalent positions, is, 4 second number must aligned 3 first. conditions, two exponents equal, mathematical condition two numbers form added. Thus, (123*100)+(456*10-2)=(123*100)+(4.56*100)=127.56*100 Alignment may achieved shifting either smaller number right (increasing exponent) shifting larger number left. either operation may result loss digits, smaller number shifted; digits lost therefore relatively small significance. alignment 360 SUBTRA CT RETURNADD RETURNYesNo NoNo NoNo YesZ YZ 0 X /H11549 0? YesYes YesYes YesY /H11549 0?Increment smaller exponent Shift signi/f_icand rightAdd signed signi/f_icands Shift signi/f_icand right Put number ZRound result Increment exponentChange sign Report under/f_lo w Report over/f_lo wRETURNRETURN RETURN RETURNNoNo YesYesExponents equal? Signi/f_icand /H11549 0? Exponent over/f_low?Shift signi/f_icand left Decr ement exponent Exponent under/f_low?Results normalized? Signi/f_icand /H11549 0? Signi/f_icand over/f_low?Z X Figure 10.22 Floating-Point Addition Subtraction (ZdX{Y)10.5 / F LoATing-poinT AriThmeTic 361 achieved repeatedly shifting magnitude portion significand right 1 digit incrementing exponent two exponents equal. (Note implied base 16, shift 1 digit shift 4 bits.) process results 0 value significand, number reported result. Thus, two numbers exponents differ significantly, lesser number lost. Phase 3. Addition: Next, two significands added together, taking account signs. signs may differ, result may 0. also possibility significand overflow 1 digit. so, significand result shifted right exponent incremented. exponent overflow could occur result; would reported operation halted. Phase 4. Normalization: final phase normalizes result. Normalization consists shifting significand digits left significant digit (bit, 4 bits base-16 exponent) nonzero. shift causes decrement exponent thus could cause exponent underflow. Finally, result must rounded reported. defer discussion rounding discussion multiplication division. Multiplication Division Floating-point multiplication division much simpler processes addition subtraction, following discussion indicates. first consider multiplication, illustrated Figure 10.23. First, either operand 0, 0 reported result. next step add exponents. exponents stored biased form, exponent sum would doubled bias. Thus, bias value must subtracted sum. result could either exponent overflow underflow, would reported, ending algorithm. exponent product within proper range, next step multiply significands, taking account signs. multiplication per - formed way integers. case, dealing sign - magnitude representation, details similar twos complement representation. product double length multiplier multipli - cand. extra bits lost rounding. product calculated, result normalized rounded, done addition subtraction. Note normalization could result exponent underflow. Finally, let us consider flowchart division depicted Figure 10.24. Again, first step testing 0. divisor 0, error report issued, result set infinity, depending implementation. dividend 0 results 0. Next, divisor exponent subtracted dividend exponent. removes bias, must added back in. Tests made expo - nent underflow overflow. next step divide significands. followed usual - malization rounding.362 chApTer 10 / compUTer Ari ThmeTic Precision Considerations guard bits mentioned that, prior floating-point operation, exponent significand operand loaded ALU registers. case significand, length register almost always greater length significand plus implied bit. register contains additional bits, called guard bits, used pad right end significand 0s.MUL TIPL RETURN RETURNYesNo Z 0X /H11549 0? Yes Yes YesSubtract biasAdd exponents Report over/f_lo w Multiply signi/f_icandsY /H11549 0? Exponent over/f_low? Normalize RoundExponent under/f_low?No NoReport under/f_lo w Figure 10.23 Floating-Point Multiplication (ZdX{Y) reason use guard bits illustrated Figure 10.25. Consider numbers IEEE format, 24-bit significand, including implied 1 bit left binary point. Two numbers close value x=1.00 g 00*21 y=1.11 g 11*20. smaller number subtracted larger, must shifted right 1 bit align exponents. shown Figure 10.25a. process, loses 1 bit significance; result 2-22. operation repeated 10.5 / F LoATing-poinT AriThmeTic 363 (a) Binary e xample, without guard bits (c) xadecimal e xample, without guard bits (b) Binar example, guard bits (d) xadecimal e xample, guard bitsx = 1.000.....00 × 21 –y = 0.111.....11 × 21 z = 0.000.....01 × 21 = 1.000.....00 × 2–22x = .100000 × 161 –y = .0FFFFF × 161 z = .000001 × 161 = .100000 × 16–4 x = .100000 00 × 161 –y = .0FFFFF F0 × 161 z = .000000 10 × 161 = .100000 00 × 16–5x = 1.000.....00 0000 × 21 –y = 0.111.....11 1000 × 21 z = 0.000.....00 1000 × 21 = 1.000.....00 0000 × 2–23 Figure 10.25 Use Guard BitsDIVIDE RETURN RETURNYesNo Z 0X /H11549 0? Yes Yes YesAdd biasSubtract exponents Report over/f_lo w Divide signi/f_icandsY /H11549 0? Exponent over/f_low? Normalize RoundExponent under/f_low?No NoReport under/f_lo wZ /H11009 Figure 10.24 Floating-Point Division (ZdX/Y)364 chApTer 10 / compUTer Ari ThmeTic rounding Another detail affects precision result rounding policy. result operation significands generally stored longer register. result put back floating-point format, extra bits must eliminated way produce result close exact result. process called rounding . number techniques explored performing rounding. fact, IEEE standard lists four alternative approaches: ■Round nearest: result rounded nearest representable number. ■Round toward +H: result rounded toward plus infinity. ■Round toward −H: result rounded toward negative infinity. ■Round toward 0: result rounded toward zero. Let us consider policies turn. Round nearest default rounding mode listed standard defined follows: representable value nearest infinitely precise result shall delivered.part (b) addition guard bits. least significant bit lost due align - ment, result 2-23, difference factor 2 previous answer. radix 16, loss precision greater. Figures 10.25c (d) show, difference factor 16. extra bits, beyond 23 bits stored, 10010, extra bits amount one-half last representable bit position. case, cor - rect answer add binary 1 last representable bit, rounding next rep - resentable number. consider extra bits 01111. case, extra bits amount less one-half last representable bit position. correct answer simply drop extra bits (truncate), effect rounding next representable number. standard also addresses special case extra bits form 10000.… result exactly halfway two possible representable values. One possible technique would always truncate, would sim - plest operation. However, difficulty simple approach intro - duces small cumulative bias sequence computations. required unbiased method rounding. One possible approach would round basis random number that, average, result would unbiased. argument approach produce predict - able, deterministic results. approach taken IEEE standard force result even: result computation exactly midway two rep - resentable numbers, value rounded last representable bit currently 1 rounded currently 0.10.5 / F LoATing-poinT AriThmeTic 365 next two options, rounding plus minus infinity , useful imple - menting technique known interval arithmetic. Interval arithmetic provides efficient method monitoring controlling errors floating-point computa - tions producing two values result. two values correspond lower upper endpoints interval contains true result. width interval, difference upper lower endpoints, indi - cates accuracy result. endpoints interval representa - ble, interval endpoints rounded up, respectively. Although width interval may vary according implementation, many algorithms designed produce narrow intervals. range upper lower bounds sufficiently narrow, sufficiently accurate result obtained. not, least know perform additional analysis. final technique specified standard round toward zero . is, fact, simple truncation: extra bits ignored. certainly simplest technique. However, result magnitude truncated value always less equal precise original value, introducing consistent bias toward zero operation. serious bias affects every operation nonzero extra bits. IEEE Standard Binary Floating-Point Arithmetic IEEE 754 goes beyond simple definition format lay specific prac - tices procedures floating-point arithmetic produces uniform, predictable results independent hardware platform. One aspect already discussed, namely rounding. subsection looks three topics: infinity, NaNs, subnormal numbers. infinity Infinity arithmetic treated limiting case real arithmetic, infinity values given following interpretation: -∞ 6(every finite number)6+∞ exception special cases discussed subsequently, arithmetic operation involving infinity yields obvious result. example: 5+(+∞)=+∞ 5,(+∞) =+0 5-(+∞)=-∞ (+∞)+(+∞)=+∞ 5+(-∞)=-∞ (-∞)+(-∞)=-∞ 5-(-∞)=+∞ (-∞)-(+∞)=-∞ 5*(+∞)=+∞ (+∞)-(-∞)=+∞ quiet signaling nans NaN symbolic entity encoded floating- point format, two types: signaling quiet. signaling NaN signals invalid operation exception whenever appears operand. Signaling366 chApTer 10 / compUTer Ari ThmeTic NaNs afford values uninitialized variables arithmetic-like enhancements subject standard. quiet NaN propagates almost every arithmetic operation without signaling exception. Table 10.7 indicates operations produce quiet NaN. Note types NaNs general format (Table 10.4): exponent ones nonzero fraction. actual bit pattern nonzero fraction implementation dependent; fraction values used distinguish quiet NaNs signaling NaNs specify particular exception conditions. subnormal numbers Subnormal numbers included IEEE 754 handle cases exponent underflow. exponent result becomes small (a negative exponent large magnitude), result subnormalized right shifting fraction incrementing exponent shift exponent within representable range. Figure 10.26 illustrates effect including subnormal numbers. rep - resentable numbers grouped intervals form [2n, 2n+1]. Within Table 10.7 Operations Produce Quiet NaN Operation Quiet NaN Produced operation signaling NaN Add subtractMagnitude subtraction infinities: (+∞)+(-∞) (-∞)+(+∞) (+∞)-(+∞) (-∞)-(-∞) Multiply 0*∞ Division 0 0 ∞ ∞ Remainder x REM 0 ∞ REM Square root2x, x60 2−1262−1252−1242−123 2−1262−1252−1242−123Gap (a) 32-bit format without subnormal numbers Uniform spacing (b) 32-bit format subnormal numbers0 0 Figure 10.26 Effect IEEE 754 Subnormal Numbers10.6 / Key Terms, review Q UesTions, probLems 367 interval, exponent portion number remains constant fraction varies, producing uniform spacing representable numbers within interval. get closer zero, successive interval half width preceding interval contains number representable numbers. Hence density representable numbers increases approach zero. However, normal numbers used, gap smallest normal number 0. case 32-bit IEEE 754 format, 223 representable num - bers interval, smallest representable positive number 2-126. addition subnormal numbers, additional 223-1 numbers uniformly added 0 2-126. use subnormal numbers referred gradual underflow [COON81]. Without subnormal numbers, gap smallest representable nonzero number zero much wider gap smallest representable nonzero number next larger number. Gradual underflow fills gap reduces impact exponent underflow level comparable roundoff among normal numbers. 10.6 Key Terms, review Q UesTions, probLems Key Terms arithmetic logic unit (ALU) arithmetic shift base biased representation dividend divisor exponent exponent overflow exponent underflow fixed-point representation floating-point representation guard bits mantissaminuend multiplicand multiplier negative overflow negative underflow normal number ones complement represen- tation overflow partial product positive overflow positive underflow product quotientradix point range extension remainder rounding sign bit sign-magnitude representation significand significand overflow significand underflow subnormal number subtrahend twos complement representation Review Questions 10.1 Briefly explain following representations: sign magnitude, twos complement, biased. 10.2 Explain determine number negative following representations: sign magnitude, twos complement, biased. 10.3 sign-extension rule twos complement numbers? 10.4 form negation integer twos complement representation? 10.5 general terms, twos complement operation n-bit integer produce integer?368 chApTer 10 / compUTer Ari ThmeTic 10.6 difference twos complement representation number twos complement number? 10.7 treat two twos complement numbers unsigned integers purposes addi - tion, result correct interpreted twos complement number. true multiplication. Why? 10.8 four essential elements number floating-point notation? 10.9 benefit using biased representation exponent portion float - ing-point number? 10.10 differences among positive overflow, exponent overflow, significand overflow? 10.11 basic elements floating-point addition subtraction? 10.12 Give reason use guard bits. 10.13 List four alternative methods rounding result floating-point operation. Problems 10.1 Represent following decimal numbers binary sign/magnitude twos complement using 16 bits: +512; -29. 10.2 Represent following twos complement values decimal: 1101011; 0101101. 10.3 Another representation binary integers sometimes encountered ones complement . Positive integers represented way sign magnitude. negative integer represented taking Boolean complement bit corresponding positive number. a. Provide definition ones complement numbers using weighted sum bits, similar Equations (10.1) (10.2). b. range numbers represented ones complement? c. Define algorithm performing addition ones complement arithmetic. Note: Ones complement arithmetic disappeared hardware 1960s, still survives checksum calculations Internet Protocol (IP) Transmission Control Protocol (TCP). 10.4 Add columns Table 10.1 sign magnitude ones complement. 10.5 Consider following operation binary word. Start least significant bit. Copy bits 0 first bit reached copy bit, too. take complement bit thereafter. result? 10.6 Section 10.3, twos complement operation defined follows. find twos complement X, take Boolean complement bit X, add 1. a. Show following equivalent definition. n-bit integer X, twos complement X formed treating X unsigned integer calculating (2n-X). b. Demonstrate Figure 10.5 used support graphically claim part (a), showing clockwise movement used achieve subtraction. 10.7 r’s complement n-digit number N base r defined rn-N N≠0 0 N=0. Find tens complement decimal number 13,250. 10.8 Calculate (72, 530-13, 250) using tens complement arithmetic. Assume rules similar twos complement arithmetic. 10.9 Consider twos complement addition two n-bit numbers: zn-1zn-2cz0=xn-1xn-2cx0+yn-1yn-2cy0 Assume bitwise addition performed carry bit ci generated addi - tion xi, yi, ci-1. Let n binary variable indicating overflow n=1. Fill values table.10.6 / Key Terms, review Q UesTions, probLems 369 Inputxn-1 0 0 0 0 1 1 1 1 yn-1 0 0 1 1 0 0 1 1 cn-2 0 1 0 1 0 1 0 1 Outputzn-1 n 10.10 Assume numbers represented 8-bit twos complement representation. Show calculation following: a. 6+13 b. -6+13 c. 6-13 d. -6-13 a. 111000 -110011b. 11001100 -101110c. 111100001111 -110011110011d. 11000011 -11101000 10.11 Find following differences using twos complement arithmetic: 10.12 following valid alternative definition overflow twos complement arithmetic? exclusive-OR carry bits leftmost column 1, overflow condition. Otherwise, not. 10.13 Compare Figures 10.9 10.12. C bit used latter? 10.14 Given x=0101 y=1010 twos complement notation (i.e., x=5, y=-6), compute product p=x*y Booth’s algorithm. 10.15 Use Booth algorithm multiply 23 (multiplicand) 29 (multiplier), number represented using 6 bits. 10.16 Prove multiplication two n-digit numbers base B gives product 2 n digits. 10.17 Verify validity unsigned binary division algorithm Figure 10.16 show - ing steps involved calculating division depicted Figure 10.15. Use pre - sentation similar Figure 10.17 . 10.18 twos complement integer division algorithm described Section 10.3 known restoring method value register must restored following unsuccessful subtraction. slightly complex approach, known nonrestoring, avoids unnecessary subtraction addition. Propose algorithm latter approach. 10.19 computer integer arithmetic, quotient J/K two integers J K less equal usual quotient. True false? 10.20 Divide -145 13 binary twos complement notation, using 12-bit words. Use algorithm described Section 10.3. 10.21 a. Consider fixed-point representation using decimal digits, implied radix point position (to right least significant digit, right significant digit, on). many decimal digits needed represent approximations Planck’s constant (6.63*10-27) Avogadro’s number (6.02*1023)? implied radix point must position numbers. b. consider decimal floating-point format exponent stored biased representation bias 50. normalized representation assumed. many decimal digits needed represent constants floating-point format? 10.22 Assume exponent e constrained lie range 0…e…X, bias q, base b, significand p digits length. a. largest smallest positive values written? b. largest smallest positive values written normalized floating-point numbers?370 chApTer 10 / compUTer Ari ThmeTic 10.23 Express following numbers IEEE 32-bit floating-point format: a. -5 b. -6 c. -1.5 d. 384 e. 1/16 f. -1/32 10.24 following numbers use IEEE 32-bit floating-point format. equiv - alent decimal value? a. 1 10000011 11000000000000000000000 b. 0 01111110 10100000000000000000000 c. 0 10000000 00000000000000000000000 10.25 Consider reduced 7-bit IEEE floating-point format, 3 bits exponent 3 bits significand. List 127 values. 10.26 Express following numbers IBM’s 32-bit floating-point format, uses 7-bit exponent implied base 16 exponent bias 64 (40 hexadec - imal). normalized floating-point number requires leftmost hexadecimal digit nonzero; implied radix point left digit. a. 1.0 b. 0.5c. 1/64 d. 0.0e. -15.0 f. 5.4*10-79g. 7.2*1075 h. 65,535 10.27 Let 5BCA0000 floating-point number IBM format, expressed hexadecimal. decimal value number? 10.28 would bias value a. base-2 exponent (B=2) 6-bit field? b. base-8 exponent (B=8) 7-bit field? 10.29 Draw number line similar Figure 10.19b floating-point format Figure 10.21b. 10.30 Consider floating-point format 8 bits biased exponent 23 bits significand. Show bit pattern following numbers format: a. -720 b. 0.645 10.31 text mentions 32-bit format represent maximum 232 different num - bers. many different numbers represented IEEE 32-bit format? Explain. 10.32 floating-point representation used computer represent certain real numbers exactly; others must approximated. A′ stored value approxi - mating real value A, relative error, r, expressed r=A-A′ Represent decimal quantity +0.4 following floating-point format: base=2; exponent: biased, 4 bits; significand, 7 bits. relative error? 10.33 A=1.427, find relative error truncated 1.42 rounded 1.43. 10.34 people speak inaccuracy floating-point arithmetic, often ascribe errors cancellation occurs subtraction nearly equal quantities. X approximately equal, difference X-Y obtained exactly, error. people really mean? 10.35 Numerical values B stored computer approximations A′ B′ Neglecting truncation roundoff errors, show relative error product approximately sum relative errors factors. 10.36 One serious errors computer calculations occurs two nearly equal numbers subtracted. Consider A=0.22288 B=0.22211. computer trun - cates values four decimal digits. Thus A′=0.2228 B′=0.2221. a. relative errors A′ B′? b. relative error C′=A′-B′?10.6 / Key Terms, review Q UesTions, probLems 371 10.37 get feel effects denormalization gradual underflow, consider decimal system provides 6 decimal digits significand smallest normalized number 10-99. normalized number one nonzero decimal digit left decimal point. Perform following calculations denormal - ize results. Comment results. a. (2.50000*10-60)*(3.50000*10-43) b. (2.50000*10-60)*(3.50000*10-60) c. (5.67834*10-97)-(5.67812*10-97) 10.38 Show following floating-point additions performed (where significands truncated 4 decimal digits). Show results normalized form. a. 5.566*102+7.777*102 b. 3.344*101+8.877*10-2 10.39 Show following floating-point subtractions performed (where signifi - cands truncated 4 decimal digits). Show results normalized form. a. 7.744*10-3-6.666*10-3b. 8.844*10-3-2.233*10-1 10.40 Show following floating-point calculations performed (where significands truncated 4 decimal digits). Show results normalized form. a. (2.255*101)*(1.234*100) b. (8.833*102),(5.555*104)372CHAPTER Digital logic 11.1 Boolean Algebra 11.2 Gates 11.3 Combinational Circuits Implementation Boolean Functions Multiplexers Decoders Read- Memory Adders 11.4 Sequential Circuits Flip- Flops Registers Counters 11.5 Programmable Logic Devices Programmable Logic Array Field- Programmable Gate Array 11.6 Key Terms Problems 11.1 / Boolean algeBra 373 operation digital computer based storage processing binary data. Throughout book, assumed existence storage ele - ments exist one two stable states, circuits operate binary data control control signals implement various computer functions. chapter, suggest storage elements circuits implemented digital logic, specifically combinational sequential circuits. chapter begins brief review Boolean algebra, mathemati - cal foundation digital logic. Next, concept gate introduced. Finally, com - binational sequential circuits, constructed gates , described. 11.1 BOOLEAN ALGEBRA digital circuitry digital computers digital systems designed, behavior analyzed, use mathematical discipline known Boolean algebra . name honor English mathematician George Boole, pro - posed basic principles algebra 1854 treatise, Investigation Laws Thought Found Mathematical Theories Logic Probabilities. 1938, Claude Shannon, research assistant Electrical Engineering Department M.I.T., suggested Boolean algebra could used solve problems relay- switching circuit design [SHAN38].1 Shannon’s techniques subsequently used analysis design electronic digital circuits. Boolean algebra turns convenient tool two areas: ■Analysis: economical way describing function digital circuitry. ■Design: Given desired function, Boolean algebra applied develop simplified implementation function. algebra, Boolean algebra makes use variables operations. case, variables operations logical variables operations. Thus, variable may take value 1 (TRUE) 0 (FALSE). basic logical Learning Objectives studying chapter, able to: rUnderstand basic operations Boolean algebra . rDistinguish among different types flip- flops . rUse Karnaugh map simplify Boolean expression. rPresent overview programmable logic devices . 1The paper available box.com/COA10e.374 CHaPTer 11 / Digi Tal logiC operations AND, OR, NOT, symbolically represented dot, plus sign, overbar:2 B=A # B B=A+B A=A operation yields true (binary value 1) operands true. operation yields true either operands true. unary operation inverts value operand. example, consider equation D=A+(B # C) equal 1 1 B=0 C=1. Otherwise equal 0. Several points concerning notation needed. absence paren - theses, operation takes precedence operation. Also, ambiguity occur, operation represented simple concatenation instead dot operator. Thus, A+B # C=A+(B # C)=A+BC mean: Take B C; take result A. Table 11.1a defines basic logical operations form known truth table , lists value operation every possible combination val - ues operands. table also lists three useful operators: XOR, NAND , . exclusive- (XOR) two logical operands 1 exactly one operands value 1. NAND function complement (NOT) function, complement OR: NAND B=NOT (A B)=AB B=NOT (A B)=A+B shall see, three new operations useful implementing certain digital circuits. logical operations, exception NOT, generalized two variables, shown Table 11.1b. Table 11.2 summarizes key identities Boolean algebra. equations arranged two columns show complementary, dual, nature operations. two classes identities: basic rules (or postu- lates ), stated without proof, identities derived basic postulates. postulates define way Boolean expressions interpreted. One two distributive laws worth noting differs would find ordinary algebra: A+(B # C)=(A+B) # (A+C) 2Logical often indicated apostrophe: A=A′. 11.1 / Boolean algeBra 375 two bottommost expressions referred DeMorgan’s theorem. restate follows: B=A B NAND B=A B reader invited verify expressions Table 11.2 substituting actual values (1s 0s) variables A, B, C.Table 11.1 Boolean Operators (a) Boolean Operators Two Input Variables P QNOT P (P)P Q (P # Q)P Q (P + Q)P NAND Q (P # Q)P Q (P + Q)P XOR Q (P ⊕ Q) 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 0 (b) Boolean Operators Extended Two Inputs (A, B, . . .) Operation Expression Output=1 # B # c set {A, B, …} 1. A+B+c set {A, B, …} 1. NAND # B # c set {A, B, …} 0. A+B+c set {A, B, …} 0. XOR ⊕ B ⊕ c set {A, B, …} contains odd number ones. Table 11.2 Basic Identities Boolean Algebra Basic Postulates # B=B # A+B=B+A Commutative Laws # (B+C)=(A # B)+(A # C) A+(B # C)=(A+B) # (A+C) Distributive Laws 1 # A=A 0+A=A Identity Elements # A=0 A+A=1 Inverse Elements Identities 0 # A=0 1+A=1 # A=A A+A=A # (B # C)=(A # B) # C A+(B+C)=(A+B)+C Associative Laws # B=A+B A+B=A # B DeMorgan’s Theorem376 CHaPTer 11 / Digi Tal logiC 11.2 GATES fundamental building block digital logic circuits gate. Logical func - tions implemented interconnection gates. gate electronic circuit produces output signal simple Boolean operation input signals. basic gates used digital logic AND, OR, NOT, NAND, NOR, XOR. Figure 11.1 depicts six gates. gate defined three ways: graphic symbol, algebraic notation, truth table. symbology used chapter IEEE standard, IEEE Std 91. Note inversion (NOT) operation indicated circle. gate shown Figure 11.1 one two inputs one output. - ever, indicated Table 11.1b, gates except two inputs. Thus, (X+Y+Z) implemented single gate three inputs. one values input changed, correct output signal appears almost instantaneously, delayed propagation time signals gate (known gate delay ). significance delay discussed Section 11.3. cases, gate implemented two outputs, one output negation output. B F 0 0 1 0 1 0 1 0 0 1 1 0 B F 0 0 0 0 1 1 1 0 1 1 1 0Graphical SymbolAlgebraic FunctionTruth Table Name NAND XORF =  B F = AB F = + BABF 0 0 1 10 0 0 10 1 0 1 ABF 0 0 1 10 1 1 10 1 0 1 ABF 0 0 1 11 1 1 00 1 0 1AF 0 11 0A AB F = F = A/uni2032.bold F = AB F = + B F = ⊕ BFA BF BFF BFA BF Figure 11.1 Basic Logic Gates11.2 / gaTes 377 introduce common term: say assert signal cause signal line make transition logically false (0) state logically true (1) state. true (1) state either high low voltage state, depending type electronic circuitry. Typically, gate types used implementation. Design fabrica - tion simpler one two types gates used. Thus, important identify functionally complete sets gates. means Boolean function implemented using gates set. following functionally complete sets: ■AND, OR, ■AND, ■OR, ■NAND ■NOR clear AND, OR, gates constitute functionally complete set, represent three operations Boolean algebra. gates form functionally complete set, must way synthesize operation operations. done applying DeMorgan’s theorem: A+B=A # B B=NOT((NOT A)AND (NOT B)) Similarly, operations functionally complete used synthesize operation. Figure 11.2 shows AND, OR, functions implemented solely NAND gates, Figure 11.3 shows thing gates. reason, digital circuits be, frequently are, implemented solely NAND gates solely gates. AA BA BA B A+BA B B Figure 11.2 Uses NAND Gates378 CHaPTer 11 / Digi Tal logiC gates, reached primitive circuit level computer hardware. examination transistor combinations used construct gates departs realm enters realm electrical engineering. pur - poses, however, content describe gates used building blocks implement essential logical circuits digital computer. 11.3 COMBINATIONAL CIRCUITS combinational circuit interconnected set gates whose output time function input time. single gate, appearance input followed almost immediately appearance output, gate delays. general terms, combinational circuit consists n binary inputs binary outputs. gate, combinational circuit defined three ways: ■Truth table: 2n possible combinations input signals, binary value output signals listed. ■Graphical symbols: interconnected layout gates depicted. ■Boolean equations: output signal expressed Boolean function input signals. Implementation Boolean Functions Boolean function implemented electronic form network gates. given function, number alternative realizations. Consider Boolean function represented truth table Table 11.3. express function simply itemizing combinations values A, B, C cause F 1: F+ABC+ABC+ABC (11.1)A BA BA (A+B) BA+B B Figure 11.3 Uses Gates11.3 / Com BinaTional Cir CuiTs 379 three combinations input values cause F 1, one combinations occurs, result 1. form expression, self- evident reasons, known sum products (SOP) form. Figure 11.4 shows straightfor - ward implementation AND, OR, gates. Another form also derived truth table. SOP form expresses output 1 input combinations produce 1 true. also say output 1 none input combinations produce 0 true. Thus, F=(A B C) # (A B C) # (A B C) # (A B C) # (A B C) rewritten using generalization DeMorgan’s theorem: (X#Y#Z)=X+Y+ZTable 11.3 Boolean Function Three Variables B C F 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0 AB C F Figure 11.4 Sum- of- Products Implementation Table 11.3380 CHaPTer 11 / Digi Tal logiC Thus, F=(A+B+C) # (A+B+C) # (A+B+C) # (A+B+C) # (A+B+C) (11.2) =(A+B+C) # (A+B+C) # (A+B+C) # (A+B+C) # (A+B+C) product sums (POS) form, illustrated Figure 11.5. clarity, gates shown. Rather, assumed input signal complement available. simplifies logic diagram makes inputs gates readily apparent. Thus, Boolean function realized either SOP POS form. point, would seem choice would depend whether truth table con - tains 1s 0s output function: SOP one term 1, POS one term 0. However, considerations: ■It often possible derive simpler Boolean expression truth table either SOP POS. ■It may preferable implement function single gate type (NAND NOR). significance first point that, simpler Boolean expression, fewer gates needed implement function. Three methods used achieve simplification ■Algebraic simplification ■Karnaugh maps ■ Quine– McCluskey tablesFA B C B CA B CA B C B C Figure 11.5 Product- of- Sums Implementation Table 11.311.3 / Com BinaTional Cir CuiTs 381 algebraic simplification Algebraic simplification involves application identities Table 11.2 reduce Boolean expression one fewer elements. example, consider Equation (11.1). thought convince reader equivalent expression F=AB+BC (11.3) Or, even simpler, F=B(A+C) expression implemented shown Figure 11.6. simplification Equation (11.1) done essentially observation. complex expres - sions, systematic approach needed. karnaugh maps purposes simplification, Karnaugh map convenient way representing Boolean function small number (up four) variables. map array 2n squares, representing possible combinations values n binary variables. Figure 11.7a shows map four squares function two variables. essential later purposes list combinations order 00, 01, 11, 10. squares corresponding combinations used recording information, combinations customarily written squares. case three variables, representation arrangement eight squares (Figure 11.7b), values one variables left two variables squares. four variables, 16 squares needed, arrangement indicated Figure 11.7c. map used represent Boolean function following way. square corresponds unique product sum- of- products form, 1 value corresponding variable 0 value corresponding variable. Thus, product AB corresponds fourth square Figure 11.7a. product function, 1 placed corres - ponding square. Thus, two- variable example, map corresponds AB +AB. Given truth table Boolean function, easy matter construct map: combination values variables produce result 1 truth table, fill corresponding square map 1. Figure 11.7b shows result truth table Table 11.3. convert Boolean expression map, first necessary put expression referred canonical form: term expression must contain variable. So, example, Equation (11.3), must first expand full form Equation (11.1) convert map. FBA C Figure 11.6 Simplified Implementation Table A.3382 CHaPTer 11 / Digi Tal logiC labeling used Figure 11.7d emphasizes relationship var - iables rows columns map. two rows embraced symbol variable value 1; rows embraced symbol 0; similarly B, C, D. map function created, often write simple algebraic expression noting arrangement 1s map. principle follows. two squares adjacent differ one variables. two adjacent squares entry one, corresponding product terms differ one variable. case, two terms merged eliminat - ing variable. example, Figure 11.8a, two adjacent squares correspond two terms ABCD ABCD. Thus, function expressed ABCD+ABCD=ABD process extended several ways. First, concept adjacency extended include wrapping around edge map. Thus, top square column adjacent bottom square, leftmost square row adjacent rightmost square. conditions illustrated Figures 11.8b c. Second, group 2 squares 2n adjacent squares (i.e., 2, 4, 8, etc.). next three examples Figure 11.8 show groupings 4 squares. Note case, two variables eliminated. last three examples show groupings 8 squares, allow three variables eliminated. summarize rules simplification follows: 1. Among marked squares (squares 1), find belong unique largest block 1, 2, 4, 8 circle blocks.AB 100 01 11 10 00 00 01 11 1001 11 1000 0 1 01 11 10 1 (a) F = AB + ABBC 11 1 (b) F = ABC + ABC + ABC CD AB1 (c) F = ABCD + ABCD + ABCD1 1C B DA (d) Simpli/f_ied labeling mapA Figure 11.7 Use Karnaugh Maps Represent Boolean Functions11.3 / Com BinaTional Cir CuiTs 383 2. Select additional blocks marked squares large possible number possible, include every marked square least once. results may unique cases. example, marked square combines exactly two squares, fourth marked square complete larger group, choice made two groupings choose. circling groups, allowed use 1 value once. 3. Continue draw loops around single marked squares, pairs adjacent marked squares, groups four, eight, way every marked square belongs least one loop; use blocks possible include marked squares. Figure 11.9a, based Table 11.3, illustrates simplification process. isolated 1s remain groupings, circled group 1s. (a) ABD (b) BCD (b) ABD (d) AB (e) BC (f) BD (g) (h) D1100 0001 0111 1110 10ABCD 1 100 0001 0111 1110 10ABCD 1 100 0001 0111 1110 10ABCD 111 100 0001 0111 1110 10ABCD 11 1100 0001 0111 1110 10ABCD 11 1100 0001 0111 1110 10ABCD 111 1 111 100 0001 0111 1110 10ABCD 11 1 111 1 100 0001 0111 1110 10ABCD 1 111 1 11100 0001 0111 1110 10AB (i) CCD Figure 11.8 Use Karnaugh Maps384 CHaPTer 11 / Digi Tal logiC Finally, going map simplified Boolean expression, group 1s completely overlapped groups eliminated. shown Figure 11.9b. case, horizontal group redundant may ignored creating Boolean expression. One additional feature Karnaugh maps needs mentioned. cases, certain combinations values variables never occur, therefore cor - responding output never occurs. referred “don’t care” conditions. condition, letter “d” entered corresponding square map. grouping simplification, “d” treated 1 0, whichever leads simplest expression. example, presented [HAYE98], illustrates points dis - cussing. would like develop Boolean expressions circuit adds 1 packed decimal digit. packed decimal, decimal digit represented 4-bit code, obvious way. Thus, 0=0000, 1=0001,c, 8=1000, 9=1001. remaining 4-bit values, 1010 1111, used. code also referred Binary Coded Decimal (BCD) . Table 11.4 shows truth table producing 4-bit result one 4-bit BCD input. addition modulo 10. Thus, 9+1=0. Also, note six input codes produce “don’t care” results, valid BCD inputs. Figure 11.10 shows resulting Karnaugh maps output variables. squares used achieve best possible groupings. quine – mccluskey method four variables, Karnaugh map method becomes increasingly cumbersome. five variables, two 16*16 maps needed, one map considered top three dimensions achieve adjacency. Six variables require use four 16*16 (b) F = BCD + ACD(a) F = AB + BC 1 1 1 100 0001 0111 1110 10ABA CD1 1 100 0 101 11 10BC Figure 11.9 Overlapping Groups11.3 / Com BinaTional Cir CuiTs 385 00 00 01 11 10011110CD AB1 1dddd dd (a) W = AD + ABCD00 00 01 11 1001 11 10CD AB1 11 1 dddd dd (b) X = BD + BC + BCD 00 00 01 11 1001 11 10CD AB11 1 ddd dd (c) = ACD + ACD00 01 11 10CD AB (d) Z = Dd ddd dd00 01 11 101 11 1 1 Figure 11.10 Karnaugh Maps Incrementertables four dimensions! alternative approach tabular technique, referred Quine– McCluskey method. method suitable programming computer give automatic tool producing minimized Boolean expressions.Table 11.4 Truth Table One- Digit Packed Decimal Incrementer Input Output Number B C Number W X Z 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 2 0 0 1 0 2 0 0 1 0 3 0 0 1 1 3 0 0 1 1 4 0 1 0 0 4 0 1 0 0 5 0 1 0 1 5 0 1 0 1 6 0 1 1 0 6 0 1 1 0 7 0 1 1 1 7 0 1 1 1 8 1 0 0 0 8 1 0 0 0 9 1 0 0 1 9 1 0 0 1 0 0 0 0 0 Don’t care condition 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 Dµ386 CHaPTer 11 / Digi Tal logiC method best explained means example. Consider following expression: ABCD+ABCD+ABC D+ABCD+ABCD+ABCD+ABCD+A B CD Let us assume expression derived truth table. would like produce minimal expression suitable implementation gates. first step construct table row corresponds one product terms expression. terms grouped according number complemented variables. is, start term comple - ments, exists, terms one complement, on. Table 11.5 shows list example expression, horizontal lines used indicate group - ing. clarity, term represented 1 uncomplemented variable 0 complemented variable. Thus, group terms according number 1s contain. index column simply decimal equivalent useful follows. next step find pairs terms differ one variable, is, pairs terms except one variable 0 one terms 1 other. way grouped terms, starting first group comparing term first group every term second group. compare term second group terms third group, on. Whenever match found, place check next term, combine pair eliminating variable differs two terms, add new list. Thus, example, terms ABCD ABCD combined produce ABC. process continues entire ori - ginal table examined. result new table following entries: CD ABC ABDU BCDU ACD ABC BCDU ABDU Table 11.5 First Stage Quine– McCluskey Method (for F=ABCD+ABCD+ABC D+ABCD+ABCD+ABCD+ABCD+A B CD) Product Term Index B C B CD 1 0 0 0 1 ✓ ABCD 5 0 1 0 1 ✓ ABCD 6 0 1 1 0 ✓ ABC 12 1 1 0 0 ✓ ABCD 7 0 1 1 1 ✓ ABCD 11 1 0 1 1 ✓ ABCD 13 1 1 0 1 ✓ ABCD 15 1 1 1 1 ✓11.3 / Com BinaTional Cir CuiTs 387 new table organized groups, indicated, fashion first table. second table processed manner first. is, terms differ one variable checked new term produced third table. example, third table produced contains one term: BD. general, process would proceed successive tables table matches produced. case, involved three tables. process described completed, eliminated many possible terms expression. terms eliminated used construct matrix, illustrated Table 11.6. row matrix corresponds one terms eliminated (has check) tables used far. column corresponds one terms original expression. X placed intersection row column row element “compatible” column element. is, varia - bles present row element value variables present column element. Next, circle X alone column. place square around X row circled X. every column either squared circled X, done, row elements whose Xs marked constitute minimal expression. Thus, example, final expression ABC+ACD+ABC+A CD cases columns neither circle square, additional processing required. Essentially, keep adding row elements columns covered. Let us summarize Quine– McCluskey method try justify intuitively works. first phase operation reasonably straightforward. process eliminates unneeded variables product terms. Thus, expression ABC+ABC equivalent AB, ABC+ABC=AB(C+C)=AB elimination variables, left expression clearly equivalent original expression. However, may redundant terms expression, found redundant groupings Karnaugh maps. mat - rix layout assures term original expression covered way minimizes number terms final expression. Table 11.6 Last Stage Quine– McCluskey Method (for F=ABCD+ABCD+ABC D+ABCD+ABCD+ABCD+ABCD+A B CD) ABCD ABCD ABC ABCD ABCD ABCD ABCD B CD BD X X X X CD X ⊗ ABC X ⊗ ABC X ⊗ ACD X ⊗388 CHaPTer 11 / Digi Tal logiC nand implementations Another consideration implemen - tation Boolean functions concerns types gates used. sometimes desirable implement Boolean function solely NAND gates solely gates. Although may minimum- gate implementation, advantage regularity, simplify manufacturing process. Consider Equation (11.3): F=B(A+C) complement complement value original value, F=B(A+C)=(AB+(BC) Applying DeMorgan’s theorem, F=(AB)•(BC) three NAND forms, illustrated Figure 11.11. Multiplexers multiplexer connects multiple inputs single output. time, one inputs selected passed output. general block diagram representation shown Figure 11.12. represents 4- to- 1 multiplexer. four input lines, labeled D0, D1, D2, D3. One lines selected provide output B B CF Figure 11.11 NAND Implementation Table 11.3 D0 D1 D2 S2 S1D3F4-to-1 MUX Figure 11.12 4- to- 1 Multiplexer Representation11.3 / Com BinaTional Cir CuiTs 389 signal F. select one four possible inputs, 2-bit selection code needed, implemented two select lines labeled S1 S2. example 4- to- 1 multiplexer defined truth table Table 11.7. simplified form truth table. Instead showing possible combina - tions input variables, shows output data line D0, D1, D2, D3. Figure 11.13 shows implementation using AND, OR, gates. S1 S2 connected gates way that, combination S1 S2, three gates output 0. fourth gate output value selected line, either 0 1. Thus, three inputs gate always 0, output gate equal value selected input gate. Using regular organization, easy construct multiplexers size 8- to- 1, 16- to- 1, on. Multiplexers used digital circuits control signal data routing. example loading program counter (PC). value loaded program counter may come one several different sources: D0 D1 D2 D3S1 S2 F Figure 11.13 Multiplexer ImplementationTable 11.7 4- to- 1 Multiplexer Truth Table S2 S1 F 0 0 D0 0 1 D1 1 0 D2 1 1 D3390 CHaPTer 11 / Digi Tal logiC ■A binary counter, PC incremented next instruction. ■The instruction register , branch instruction using direct address executed. ■The output ALU, branch instruction specifies address using displacement mode. various inputs could connected input lines multiplexer, PC connected output line. select lines determine value loaded PC. PC contains multiple bits, multiple multiplexers used, one per bit. Figure 11.14 illustrates 16-bit addresses. Decoders decoder combinational circuit number output lines, one asserted time. output line asserted depends pattern input lines. general, decoder n inputs 2n outputs. Figure 11.15 shows decoder three inputs eight outputs. Decoders find many uses digital computers. One example address decod - ing. Suppose wish construct 1 K- byte memory using four 256*8@bit RAM chips. want single unified address space, broken follows: Address Chip 0000–00FF 0 0100–01FF 1 0200–02FF 2 0300–03FF 3 chip requires 8 address lines, supplied lower- order 8 bits address. higher- order 2 bits 10-bit address used select one four RAM chips. purpose, 2- to- 4 decoder used whose output enables one four chips, shown Figure 11.16. additional input line, decoder used demultiplexer. demultiplexer performs inverse function multiplexer; connects single input one several outputs. shown Figure 11.17. before, n inputs decoded produce single one 2n outputs. 2n output lines ANDed S1S2C0IR0 PC0ALU 0 C1IR1ALU 1 C15IR15ALU 15 4-to-1 MUXS1S2 PC14-to-1 MUXS1S2 PC154-to-1 MUX Figure 11.14 Multiplexer Input Program CounterAD0000 D1001 D2010 D3011 D4100 D5101 D6110 D7111B C Figure 11.15 Decoder 3 Inputs 23=8 Outputs 256 × 8 RAM256 × 8 RAM256 × 8 RAM256 × 8 RAM Enable Enable Enable EnableA0 A7 A8 A92-to-4 Decoder Figure 11.16 Address Decoding 391392 CHaPTer 11 / Digi Tal logiC data input line. Thus, n inputs act address select particular - put line, value data input line (0 1) routed output line. configuration Figure 11.17 viewed another way. Change label new line Data Input Enable. allows control timing decoder. decoded output appears encoded input present enable line value 1. Read- Memory Combinational circuits often referred “memoryless” circuits, output depends current input history prior inputs retained. However, one sort memory implemented combinational cir - cuits, namely read- memory (ROM) . Recall ROM memory unit performs read operation. implies binary information stored ROM permanent cre - ated fabrication process. Thus, given input ROM (address lines) always produces output (data lines). outputs function present inputs, ROM fact combinational circuit. ROM implemented decoder set gates. example, consider Table 11.8. viewed truth table four inputs four outputs. 16 possible input values, corresponding set values outputs shown. also viewed defining contents 64-bit ROM consisting 16 words 4 bits each. four inputs specify address, four outputs specify contents location specified address. Figure 11.18 shows memory could implemented using 4- to- 16 decoder four gates. PLA, regular organization used, interconnections made reflect desired result. Adders far, seen interconnected gates used implement functions routing signals, decoding, ROM. One essential area yet addressed arithmetic. brief overview, content looking addition function. Binary addition differs Boolean algebra result includes carry term. Thus, Data inputn-bit destination addr ess2n outputsn-to-2n decoder Figure 11.17 Implementation Demultiplexer Using DecoderX1 X2 X3 X4Four-input sixteen- output decoder0000 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111 Z1 Z2 Z3 Z4 Figure 11.18 64-Bit ROMTable 11.8 Truth Table ROM Input Output X1 X2 X3 X4 Z1 Z2 Z3 Z4 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 393394 CHaPTer 11 / Digi Tal logiC However, addition still dealt Boolean terms. Table 11.9a, show logic adding two input bits produce 1-bit sum carry bit. truth table could easily implemented digital logic. However, interested performing addition single pair bits. Rather, wish add two n- bit numbers. done putting together set adders carry one adder provided input next. 4-bit adder depicted Figure 11.19. multiple- bit adder work, single- bit adders must three inputs, including carry next- lower- order adder. revised truth table appears Table 11.9b. two outputs expressed: Sum=A BC+ABC+ABC+ABC Carry=AB +AC +BC Figure 11.20 implementation using AND, OR, gates.Table 11.9 Binary Addition Truth Tables A3 C3 S3CinB3 A2 C2 S2CinB2 A1 C1 S1CinB1 A0 C0 S0Cin 0B0 Over/f_lo w signal Figure 11.19 4-Bit Adder(a) Single- Bit Addition B Sum Carry 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1(b) Addition Carry Input Cin B Sum Cout 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 +0 0+1 1+0 1+1 1011.3 / Com BinaTional Cir CuiTs 395 Thus necessary logic implement multiple- bit adder shown Figure 11.21. Note output adder depends carry previous adder, increasing delay least signifi - cant significant bit. single- bit adder experiences certain amount gate delay, gate delay accumulates. larger adders, accumulated delay become unacceptably high. carry values could determined without ripple previous stages, single- bit adder could function independently, delay would accumulate. achieved approach known carry lookahead. Let us look 4-bit adder explain approach. would like come expression specifies carry input stage adder without reference previous carry values. haveCA B CA B CA B CA B BA CA CBSum Carry Figure 11.20 Implementation Adder A31 C23CoutB31 S31 S24A24B24 8-bit adderA23 C15B23 S23 S16A16B16 8-bit adderA15 C7B15 S15 S8A8B8 8-bit adderA7 CinB7 S7 S0A0B0 8-bit adder Figure 11.21 Construction 32-Bit Adder Using 8-Bit Adders396 CHaPTer 11 / Digi Tal logiC C0=A0B0 (11.4) C1=A1B1+A1A0B0+B1A0B0 (11.5) Following procedure, get C2=A2B2+A2A1B1+A2A1A0B0+A2B1A0B0+B2A1B1 + B2A1A0B0+B2B1A0B0 process repeated arbitrarily long adders. carry term expressed SOP form function original inputs, dependence carries. Thus, two levels gate delay occur regardless length adder. long numbers, approach becomes excessively complicated. Evaluating expression significant bit n- bit adder requires gate 2n - 1 inputs 2n - 1 gates 2 n+1 inputs. Accordingly, full carry lookahead typically done 4 8 bits time. Figure 11.21 shows 32-bit adder constructed four 8-bit adders. case, carry must ripple four 8-bit adders, substantially quicker ripple thirty- two 1-bit adders. 11.4 SEQUENTIAL CIRCUITS Combinational circuits implement essential functions digital computer. However, except special case ROM, provide memory state information, elements also essential operation digital computer. latter purposes, complex form digital logic circuit used: sequential circuit . current output sequential circuit depends current input, also past history inputs. Another generally useful way view current output sequential circuit depends current input current state circuit. section, examine simple useful examples sequential circuits. seen, sequential circuit makes use combinational circuits. Flip- Flops simplest form sequential circuit flip- flop. variety flip- flops, share two properties: ■The flip- flop bistable device. exists one two states and, absence input, remains state. Thus, flip- flop function 1 -bit memory. ■The flip- flop two outputs, always complements other. generally labeled Q Q. s– r latch Figure 11.22 shows common configuration known S– R flip- flop S– R latch . circuit two inputs, (Set) R (Reset), two outputs, Q Q, consists two gates connected feedback arrangement.11.4 / sequen Tial Cir CuiTs 397 First, let us show circuit bistable. Assume R 0 Q 0. inputs lower gate Q=0 S=0. Thus, output Q=1 means inputs upper gate Q=1 R=0, output Q=0. Thus, state circuit internally consistent remains stable long S=R=0. similar line reasoning shows state Q=1, Q=0 also stable R=S=0. Thus, circuit function 1-bit memory. view output Q “value” bit. inputs R serve write values 1 0, respect - ively, memory. see this, consider state Q=0, Q=1, S=0, R=0. Suppose changes value 1. inputs lower gate S=1, Q=0. time delay ∆t, output lower gate Q=0 (see Figure 11.23). So, point time, inputs upper gate become R=0, Q=0. another gate delay ∆t output Q becomes 1. stable state. inputs lower gate S=1, Q=1, maintain output Q=0. long S=1 R=0, outputs remain Q=1, Q=0. Furthermore, returns 0, outputs remain unchanged. R output performs opposite function. R goes 1, forces Q=0, Q=1 regardless previous state Q Q. Again, time delay 2∆t occurs final state established (Figure 11.23). S– R latch defined table similar truth table, called characteristic table , shows next state states sequential circuit function current states inputs. case S– R latch, state defined value Q. Table 11.10a shows resulting characteristic table. Observe inputs S=1, R=1 allowed, would pro - duce inconsistent output (both Q Q equal 0). table expressed compactly, Table 11.10b. illustration behavior S– R latch shown Table 11.10c. clocked s– r flip- flop output S– R latch changes, brief time delay, response change input. referred asynchronous operation. typically, events digital computer synchronized clock pulse, changes occur clock pulse occurs. Figure 11.24 shows SQ QR Figure 11.22 S– R Latch Implemented Gates1 0S R Q Q1 0 1 0 1 02∆t ∆t 2∆t ∆tt Figure 11.23 S– R Latch Timing Diagram Table 11.10 S– R Latch (a) Characteristic Table Current InputsCurrent StateNext State SR Qn Qn+1 00 0 0 00 1 1 01 0 0 01 1 0 10 0 1 10 1 1 11 0 — 11 1 —(b) Simplified Characteristic Table R Qn+1 0 0 Qn 0 1 0 1 0 1 1 1 — (c) Response Series Inputs 0 1 2 3 4 5 6 7 8 9 1 0 0 0 0 0 0 0 1 0 R 0 0 0 1 0 0 1 0 0 0 Qn+1 1 1 1 0 0 0 0 0 1 1 39811.4 / sequen Tial Cir CuiTs 399 arrangement. device referred clocked S– R flip- flop. Note R inputs passed gates clock pulse. flip- flop One problem S– R flip- flop condition R=1, S=1 must avoided. One way allow single input. flip- flop accomplishes this. Figure 11.25 shows gate implementation flip- flop. using inverter, nonclock inputs two gates guaranteed opposite other. flip- flop sometimes referred data flip- flop is, effect, storage one bit data. output flip- flop always equal recent value applied input. Hence, remembers produces last input. also referred delay flip- flop, delays 0 1 applied input single clock pulse. capture logic flip- flop following truth table: Qn+1 0 0 1 1 j– k flip- flop Another useful flip- flop J– K flip- flop. Like S– R flip- flop, two inputs. However, case possible combinations input values valid. Figure 11.26 shows gate implementation J– K flip- flop, Figure 11.27 shows characteristic table (along S– R flip- flops). Note first three combinations S– R flip- flop. input asserted, output stable. J input asserted, result set SR QQ Clock Figure 11.24 Clocked S– R Flip- Flop DQQ Clock Figure 11.25 Flip- Flop400 CHaPTer 11 / Digi Tal logiC function, causing output 1; K input asserted, result reset function, causing output 0. J K 1, function performed referred toggle function: output reversed. Thus, Q 1 1 applied J K, Q becomes 0. reader verify implementation Figure 11.26 produces characteristic function.JK QQ Clock Figure 11.26 J– K Flip- Flop Name Graphical Symbol Truth Table S–RSQ RQS R 00 01 1QnQn+1 10 –0 1 1 J–KJQ KQJ K 00 01 1Qn QnQn+1 10 0 1 1 DDQ QD 0 0 1Qn+1 1Ck Ck Ck Figure 11.27 Basic Flip- Flops11.4 / sequen Tial Cir CuiTs 401 Registers example use flip- flops, let us first examine one essential ele - ments CPU: register. know, register digital circuit used within CPU store one bits data. Two basic types registers commonly used: parallel registers shift registers. parallel registers parallel register consists set 1-bit memories read written simultaneously. used store data. registers discussed throughout book parallel registers. 8-bit register Figure 11.28 illustrates operation parallel register using flip- flops. control signal, labeled load , controls writing register signal lines, D11 D18. lines might output multiplexers, data variety sources loaded register. shift register shift register accepts and/or transfers information serially. Consider, example, Figure 11.29, shows 5-bit shift register constructed clocked flip- flops. Data input leftmost flip- flop. clock pulse, data shifted right one position, rightmost bit transferred out. Shift registers used interface serial I/O devices. addition, used within ALU perform logical shift rotate functions. D08D18 ClkQ ClkQ ClkQ ClkQ ClkQ ClkQ ClkQ ClkQ Clock LoadD17 D16 D15 D14 D13 D12 D11 D07 D06 D05 Output linesData lines D04 D03 D02 D01 Figure 11.28 8-Bit Parallel Register ClkQ ClkQ ClkQ ClkQ ClkQ ClockSerial Serial Figure 11.29 5-Bit Shift Register402 CHaPTer 11 / Digi Tal logiC latter capacity, need equipped parallel read/write circuitry well serial. Counters Another useful category sequential circuit counter . counter register whose value easily incremented 1 modulo capacity register; is, maximum value achieved next increment sets counter value 0. Thus, register made n flip- flops count 2n - 1. example counter CPU program counter. Counters designated asynchronous synchronous, depending way operate. Asynchronous counters relatively slow output one flip- flop triggers change status next flip- flop. synchronous counter , flip- flops change state time. latter type much faster, kind used CPUs. However, useful begin discussion description asynchronous counter. ripple counter asynchronous counter also referred ripple counter , change occurs increment counter starts one end “ripples” end. Figure 11.30 shows implementation 4-bit counter using J– K flip- flops, together timing diagram illustrates behavior. timing diagram idealized show propagation delay occurs signals move series flip- flops. output leftmost flip- flop (Q0) least significant bit. design could clearly extended arbitrary number bits cascading flip- flops. JQ Q0 Q0 Q1 Q2 Q3K QCkJQ Q1K QCkJQ Q2K QCkJQ Q3K QCk Clock ClockHigh (a) Sequential cir cuit (b) Timing diagram Figure 11.30 Ripple Counter11.4 / sequen Tial Cir CuiTs 403 illustrated implementation, counter incremented clock pulse. J K inputs flip- flop held constant 1. means that, clock pulse, output Q inverted (1 0; 0 1). Note change state shown occurring falling edge clock pulse; known edge- triggered flip- flop. Using flip- flops respond tran - sition clock pulse rather pulse provides better timing control complex circuits. one looks patterns output counter, seen cycles 0000, 0001, …, 1110, 1111, 0000, on. synchronous counters ripple counter disadvantage delay involved changing value, proportional length counter. overcome disadvantage, CPUs make use synchronous counters, flip- flops counter change time. subsection, present design 3-bit synchronous counter. so, illustrate basic concepts design synchronous circuit. 3-bit counter, three flip- flops needed. Let us use J– K flip- flops. Label uncomplemented output three flip- flops C, B, A, respectively, C representing significant bit. first step construct truth table relates J– K inputs outputs, allow us design overall cir - cuit. truth table shown Figure 11.31a. first three columns show possible combinations outputs C, B, A. listed order appear counter incremented. row lists current value C, B, inputs three flip- flops required reach next value C, B, A. understand way truth table Figure 11.31a constructed, may helpful recast characteristic table J– K flip- flop. Recall table presented follows: J K Qn+1 0 0 Qn 0 1 0 1 0 1 1 1 Qn+1 form, table shows effect J K inputs output. consider following organization information: Qn J K Qn+1 0 0 0 0 1 1 1 1 0 1 0 1 form, table provides value next output inputs present output known. exactly information needed design counter or, indeed, sequential circuit. form, table referred excitation table .404 CHaPTer 11 / Digi Tal logiC Let us return Figure 11.31a. Consider first row. want value C remain 0, value B remain 0, value go 0 1 next application clock pulse. excitation table shows maintain output 0, must inputs J=0 don’t care K. effect transition 0 1, inputs must J=1 K=d. values shown first row table. similar reasoning, remainder table filled in.(c) Logic diagram High ClockJa KaJb B B KbCB binary outputA Jc C C KcCB AJcJ b Kc JaKa Kb 00 00 0d1 00 10 1dd 1 01 00 dd1 0 01 11 ddd 1 1 10 0d 001 10 1d 10d 1 11 0d d01 0 11 1d d1d 1 1(a) Truth table (b) Kar naugh maps Jc = BA CBA dd dd1 0 100 01 11 10 Kc = BA CBA dd dd 10 100 01 11 10 Jb = CBA 11 dd0 100 01 11 10 Kb = CBA dd dd1 10 100 01 11 10 Ja = 1 CBA 1 d1 d10 1100 01 11 10 Ka = 1 CBA 1 1 1d 1d0 1d00 01 11 10 Ck Ck Ck Figure 11.31 Design Synchronous Counter11.5 / Programma Ble logiC Devi Ces 405 constructed truth table Figure 11.31a, see table shows required values J K inputs functions current val - ues C, B, A. aid Karnaugh maps, develop Boolean expres - sions six functions. shown part b figure. example, Karnaugh map variable Ja (the J input flip- flop produces output) yields expression Ja=BC. six expressions derived, straightforward matter design actual circuit, shown part c figure. 11.5 PROGRAMMABLE LOGIC DEVICES Thus far, treated individual gates building blocks, arbitrary functions realized. designer could pursue strategy minimizing number gates used manipulating corresponding Boolean expressions. level integration provided integrated circuits increases, considerations apply. Early integrated circuits, using small- scale integration (SSI), provided one ten gates chip. gate treated independently, building- block approach described far. construct logic function, number chips laid printed circuit board appropriate pin intercon - nections made. Increasing levels integration made possible put gates chip make gate interconnections chip well. yields advantages decreased cost, decreased size, increased speed (because on- chip delays shorter duration off- chip delays). design problem arises, however. particular logic function set functions, layout gates interconnec - tions chip must designed. cost time involved custom chip design high. Thus, becomes attractive develop general- purpose chip readily adapted specific purposes. intent programmable logic device (PLD). number different types PLDs commercial use. Table 11.11 lists key terms defines important types. section, first look one simplest devices, programmable logic array (PLA) introduce perhaps important widely used type PLD, field- programmable gate array (FPGA). Programmable Logic Array PLA based fact Boolean function (truth table) expressed sum- of- products (SOP) form, seen. PLA consists regular arrangement NOT, AND, gates chip. chip input passed gate input complement available gate. output gate available gate, output gate chip output. making appropriate connections, arbitrary SOP expressions implemented. Figure 11.32a shows PLA three inputs, eight gates, two outputs. left programmable array. array programmed estab - lishing connection PLA input negation gate input connecting corresponding lines point intersection. 406 CHaPTer 11 / Digi Tal logiC right programmable array, involves connecting gate outputs gate inputs. larger PLAs contain several hundred gates, 15 25 inputs, 5 15 outputs. connections inputs gates, gates gates, specified programming time. PLAs manufactured two different ways allow easy programming (mak - ing connections). first, every possible connection made fuse every intersection point. undesired connections later removed blowing fuses. type PLA referred field- programmable logic array (FPLA). Alternatively, proper connections made chip fab - rication using appropriate mask supplied particular interconnection pat - tern. either case, PLA provides flexible, inexpensive way implementing digital logic functions. Figure 11.32b shows programmed PLA realizes two Boolean expressions. Field- Programmable Gate Array PLA example simple PLD (SPLD). difficulty increasing capacity strict SPLD architecture structure programmable logic- planes grows quickly size number inputs increased. feasible way provide large capacity devices based SPLD architectures integrate multiple SPLDs onto single chip provide interconnect pro - grammably connect SPLD blocks together. Many commercial PLD products Table 11.11 PLD Terminology Programmable Logic Device (PLD) general term refers type integrated circuit used implementing digital hard- ware, chip configured end user realize different designs. Programming device often involves placing chip special programming unit, chips also configured “ in- system.” Also referred field- programmable device (FPD). Programmable Logic Array (PLA) relatively small PLD contains two levels logic, AND- plane OR- plane, levels programmable. Programmable Array Logic (PAL) relatively small PLD programmable AND- plane followed fixed OR- plane. Simple PLD (SPLD) PLA PAL. Complex PLD (CPLD) complex PLD consists arrangement multiple SPLD- like blocks single chip. Field- Programmable Gate Array (FPGA) PLD featuring general structure allows high logic capacity. Whereas CPLDs feature logic resources wide number inputs (AND planes), FPGAs offer narrow logic resources. FPGAs also offer higher ratio flip- flops logic resources CPLDs. Logic Block relatively small circuit block replicated array FPD. circuit implemented FPD, first decomposed smaller subcircuits mapped logic block. term logic block mostly used context FPGAs, could also refer block circuitry CPLD.I1 O1O2I2I3 “AND” array“OR” array (a) Layout 3-input 2-output PLA B C (b) Programmed PLAABC ABC + AB AB + ACACAB Figure 11.32 Example Programmable Logic Array (PLA) 407408 CHaPTer 11 / Digi Tal logiC exist market today basic structure, collectively referred Complex PLDs (CPLDs). important type CPLD FPGA. FPGA consists array uncommitted circuit elements, called logic blocks , interconnect resources. illustration typical FPGA architecture shown Figure 11.33. key components FPGA are; ■Logic block: configurable logic blocks computation user’s circuit takes place. ■I/O block: I/O blocks connect I/O pins circuitry chip. ■Interconnect: signal paths available establishing connections among I/O blocks logic blocks. logic block either combinational circuit sequential circuit. essence, programming logic block done downloading contents truth table logic function. Figure 11.34 shows example simple logic block consisting flip- flop, 2- to- 1 multiplexer, 16-bit lookup table . lookup table memory consisting 16 1-bit elements, 4 input lines required select one 16 bits. Larger logic blocks larger lookup tables multiple interconnected lookup tables. combinational logic realized lookup table output directly stored flip- flop output synchro - nously. separate one- bit memory controls multiplexer determine whether output comes directly lookup table flip- flop. interconnecting numerous logic blocks, complex logic functions easily implemented. Logic block I/O block Figure 11.33 Structure FPGA11.6 / Key Terms Pro Blems 409 11.6 KEY TERMS PROBLEMS Key TermsDA0 A1 A2 A3 Clock2-to-1 MUX Q16×1 lookup table Ck Figure 11.34 Simple FPGA Logic Block adder gate assert Boolean algebra clocked S– R flip- flop flip- flop gates graphical symbol J– K flip- flop Karnaugh map logic block lookup table multiplexer NAND gate NOROR gate parallel register combinational circuit complex PLD (CPLD) counter decoder product sums (POS) programmable array logic (PAL) programmable logic array (PLA) programmable logic device (PLD) Quine– McCluskey method read- memory (ROM)register excitation table field- programmable gate array (FPGA) flip- flop ripple counter sequential circuit shift register simple PLD (SPLD) sum products (SOP) synchronous counter S– R Latch truth table XOR gate Problems 11.1 Construct truth table following Boolean expressions: a. ABC+A B C b. ABC+A B C+A B C c. A(BC+BC) d. (A+B)(A+C)(A+B) 11.2 Simplify following expressions according commutative law: a. # B+B # A+C # # E+C # # E+E # C # b. # B+A # C+B # c. (L # # N)(A # B)(C # # E)(M # N # L) d. F # (K+R)+S # V+W # X+V # S+X # W+(R+K) # F410 CHaPTer 11 / Digi Tal logiC 11.3 Apply DeMorgan’s theorem following equations: a. F=V+A+L b. F=A+B+C+D 11.4 Simplify following expressions: a. A=S # T+V # W+R # # b. A=T # U # V+X # Y+Y c. A=F # (E+F+G) d. A=(P # Q+R+S # T)T # e. A=D # # E f. A=Y # (W+X+Y+Z) # Z g. A=(B # E+C+F) # C 11.5 Construct operation XOR basic Boolean operations AND, OR, NOT. 11.6 Given gate gates, draw logic diagram perform three- input function. 11.7 Write Boolean expression four- input NAND gate . 11.8 combinational circuit used control seven- segment display decimal digits, shown Figure 11.35. circuit four inputs, provide four- bit code used packed decimal representation (010=0000,c, 910=1001). seven outputs define segments activated display given decimal digit. Note combinations inputs outputs needed. a. Develop truth table circuit. b. Express truth table SOP form. c. Express truth table POS form. d. Provide simplified expression. 11.9 Design 8- to- 1 multiplexer. 11.10 Add additional line Figure 11.15 functions demultiplexer. 11.11 Gray code binary code integers. differs ordinary binary rep - resentation single bit change representations two numbers. useful applications counters analog- to- digital converters sequence numbers generated. one bit changes time, never ambiguity due slight timing differences. first eight elements code Combinational circuitx1Z1Z1 Z2 Z2Z3Z3 Z4Z4 Z5 Z5 Z6Z6 Z7 Z7x2 x3 x4BCD digit (a) (b) Figure 11.35 Seven- Segment LED Display Example11.6 / Key Terms Pro Blems 411 Binary Code Gray Code 000 000 001 001 010 011 011 010 100 110 101 111 110 101 111 100 Design circuit converts binary Gray code. 11.12 Design 5*32 decoder using four 3*8 decoders (with enable inputs) one 2*4 decoder. 11.13 Implement full adder Figure 11.20 five gates. ( Hint: gates XOR gates .) 11.14 Consider Figure 11.20. Assume gate produces delay 10 ns. Thus, sum output valid 20 ns carry output 20 ns. total add time 32-bit adder a. Implemented without carry lookahead, Figure 11.19? b. Implemented carry lookahead using 8-bit adders, Figure 11.21? 11.15 alternative form S– R latch structure Figure 11.22 uses NAND gates instead gates. a. Redo Table 11.10a 11.10b S– R latch implemented NAND gates. b. Complete following table, similar Table 11.10c. 0 1 2 3 4 5 6 7 8 9 0 1 1 1 1 1 0 1 0 1 R 1 1 0 1 0 1 1 1 0 0 11.16 Consider graphic symbol S– R flip- flop Figure 11.27 . Add additional lines depict flip- flop wired S– R flip- flop. 11.17 Show structure PLA three inputs (C, B, A) four outputs (O0, O1, O2, O3) outputs defined follows: O0=A BC+AB +ABC O1=A BC+ABC O2=C O3=AB +ABC 11.18 interesting application PLA conversion old, obsolete punched card character codes ASCII codes. standard punched cards popular computers past 12 rows 80 columns holes could punched. column corresponded one character, character 12-bit code. However, 96 characters actually used. Consider application reads punched cards converts character codes ASCII. a. Describe PLA implementation application. b. problem solved ROM? Explain.412 Part Four CenTral ProCessing UniT CHAPTER insTrUCTion seTs: Chara CTerisTiCs FUnCTions 12.1 Machine Instruction Characteristics Elements Machine Instruction Instruction Representation Instruction Types Number Addresses Instruction Set Design 12.2 Types Operands Numbers Characters Logical Data 12.3 Intel x86 ARM Data Types x86 Data Types ARM Data Types 12.4 Types Operations Data Transfer Arithmetic Logical Conversion Input/Output System Control Transfer Control 12.5 Intel x86 ARM Operation Types x86 Operation Types ARM Operation Types 12.6 Key Terms, Review Questions, Problems Appendix 12A Little-, Big-, Bi- Endian12.1 / Machine instruction characteristics 413 Much discussed book readily apparent user pro - grammer computer. programmer using high- level language, Pascal Ada, little architecture underlying machine visible. One boundary computer designer computer programmer view machine machine instruction set. designer’s point view, machine instruction set provides functional requirements processor: implementing processor task large part involves imple - menting machine instruction set. user chooses program machine language (actually, assembly language; see Appendix B) becomes aware register memory structure, types data directly supported machine, functioning ALU. description computer’s machine instruction set goes long way toward explaining computer’s processor. Accordingly, focus machine instructions chapter next. 12.1 MACHINE INSTRUCTION CHARACTERISTICS operation processor determined instructions executes, referred machine instructions computer instructions . collection different instructions processor execute referred processor’s instruc- tion set. Elements Machine Instruction instruction must contain information required processor execu - tion. Figure 12.1, repeats Figure 3.6, shows steps involved instruction execution and, implication, defines elements machine instruction. elements follows: ■Operation code: Specifies operation performed (e.g., ADD, I/O). operation specified binary code, known operation code, opcode . ■Source operand reference: operation may involve one source operands, is, operands inputs operation.Learning Objectives studying chapter, able to: rPresent overview essential characteristics machine instructions . rDescribe types operands used typical machine instruction sets. rPresent overview x86 ARM data types. rDescribe types operands supported typical machine instruction sets. rPresent overview x86 ARM operation types. rUnderstand differences among big endian , little endian , bi- endian .414 cha Pter 12 / instruction sets: characteristics Functions ■Result operand reference: operation may produce result. ■Next instruction reference: tells processor fetch next instruction execution instruction complete. address next instruction fetched could either real address virtual address, depending architecture. Generally, distinction transparent instruction set architecture. cases, next instruction fetched immediately follows current instruction. cases, explicit reference next instruction. explicit reference needed, main memory virtual memory address must supplied. form address supplied discussed Chapter 13. Source result operands one four areas: ■Main virtual memory: next instruction references, main vir - tual memory address must supplied. ■Processor register: rare exceptions, processor contains one registers may referenced machine instructions. one register exists, reference may implicit. one register exists, register assigned unique name number, instruction must contain number desired register. ■Immediate: value operand contained field instruction executed. ■I/O device: instruction must specify I/O module device operation. memory- mapped I/O used, another main virtual memory address. Instruction Representation Within computer, instruction represented sequence bits. instruction divided fields, corresponding constituent elements Instruction addr ess calculationInstruction operation decodingOperand addr ess calculationData operationOperand addr ess calculationInstruction fetch Instruction complete, fetch next instructionMultiple operands Retur n string vector dataOperand fetchOperand store Multiple results Figure 12.1 Instruction Cycle State Diagram12.1 / Machine instruction characteristics 415 instruction. simple example instruction format shown Figure 12.2. another example, IAS instruction format shown Figure 2.2. instruction sets, one format used. instruction execution, instruction read instruction register (IR) processor. processor must able extract data various instruction fields perform required operation. difficult programmer reader textbooks deal binary representations machine instructions. Thus, become common prac - tice use symbolic representation machine instructions. example used IAS instruction set, Table 1.1. Opcodes represented abbreviations, called mnemonics, indicate operation. Common examples include ADD Add SUB Subtract MUL Multiply DIV Divide LOAD Load data memory STOR Store data memory Operands also represented symbolically. example, instruction ADD R, may mean add value contained data location contents regis - ter R. example, refers address location memory, R refers particular register. Note operation performed contents location, address. Thus, possible write machine- language program symbolic form. symbolic opcode fixed binary representation, programmer spec - ifies location symbolic operand. example, programmer might begin list definitions: X=513 Y=514 on. simple program would accept symbolic input, convert opcodes operand references binary form, construct binary machine instructions. Machine- language programmers rare point nonexistence. programs today written high- level language or, failing that, assembly lan - guage, discussed Appendix B. However, symbolic machine language remains useful tool describing machine instructions, use purpose.Opcode4 Bits 6 Bits 6 Bits 16 BitsOperand reference Operand reference Figure 12.2 Simple Instruction Format416 cha Pter 12 / instruction sets: characteristics Functions Instruction Types Consider high- level language instruction could expressed language BASIC FORTRAN. example, X=X+Y statement instructs computer add value stored value stored X put result X. might accomplished machine instructions? Let us assume variables X correspond locations 513 514. assume simple set machine instructions, operation could accomplished three instructions: 1. Load register contents memory location 513. 2. Add contents memory location 514 register. 3. Store contents register memory location 513. seen, single BASIC instruction may require three machine instructions. typical relationship high- level language machine language. high- level language expresses operations concise alge - braic form, using variables. machine language expresses operations basic form involving movement data registers. simple example guide us, let us consider types instructions must included practical computer. computer set instructions allows user formulate data processing task. Another way view consider capabilities high- level programming language. program written high- level language must translated machine language executed. Thus, set machine instructions must sufficient express instructions high- level language. mind categor - ize instruction types follows: ■Data processing: Arithmetic logic instructions. ■Data storage: Movement data register memory locations. ■Data movement: I/O instructions. ■Control: Test branch instructions. Arithmetic instructions provide computational capabilities processing numeric data. Logic (Boolean) instructions operate bits word bits rather numbers; thus, provide capabilities processing type data user may wish employ. operations performed primarily data processor registers. Therefore, must memory instructions mov - ing data memory registers. I/O instructions needed transfer programs data memory results computations back user. Test instructions used test value data word status computation. Branch instructions used branch different set instructions depending decision made. examine various types instructions greater detail later chapter.12.1 / Machine instruction characteristics 417 Number Addresses One traditional ways describing processor architecture terms number addresses contained instruction. dimension become less significant increasing complexity processor design. Nevertheless, use - ful point draw analyze distinction. maximum number addresses one might need instruc - tion? Evidently, arithmetic logic instructions require oper - ands. Virtually arithmetic logic operations either unary (one source operand) binary (two source operands). Thus, would need maximum two addresses reference source operands. result operation must stored, suggesting third address, defines destination operand. Finally, completion instruction, next instruction must fetched, address needed. line reasoning suggests instruction could plausibly required contain four address references: two source operands, one destination operand, address next instruction. architectures, many instructions one, two, three operand addresses, address next instruction implicit (obtained program counter). architectures also special- purpose instructions operands. example, load store multiple instructions ARM architecture, described Chapter 13, desig - nate 17 register operands single instruction. Figure 12.3 compares typical one-, two-, three- address instructions could used compute Y=(A-B)/[C+(D*E)]. three addresses, instruction specifies two source operand locations destination operand location. choose alter value operand locations, Instruction Comment SUB Y, A, − B MPY T, D, ET × E ADD T, T, CT + C DIV Y, Y, TY ÷ (a) Three- address instructions Instruction Comment MOVE Y, AY SUB Y, − B MOVE T, DT MPY T, ET × E ADD T, CT + C DIV Y, TY ÷ TInstruction Comment LOAD AC MPY E AC AC × E ADD C AC AC + C STOR YY AC LOAD AC SUB B AC AC − B DIV AC AC ÷ STOR YY AC (b) Two- address instructions (c) One- address instructions Figure 12.3 Programs Execute Y=A-B C+(D*E)418 cha Pter 12 / instruction sets: characteristics Functions temporary location, T, used store intermediate results. Note four instructions original expression five operands. Three- address instruction formats common require relatively long instruction format hold three address references. two- address instructions, binary operations, one address must double duty operand result. Thus, instruction SUB Y, B carries calcu - lation Y-B stores result Y. two- address format reduces space requirement also introduces awkwardness. avoid altering value operand, MOVE instruction used move one values result temporary location performing operation. sample program expands six instructions. Simpler yet one- address instruction. work, second address must implicit. common earlier machines, implied address processor register known accumulator (AC). accumulator con - tains one operands used store result. example, eight instructions needed accomplish task. is, fact, possible make zero addresses instructions. Zero- address instructions applicable special memory organization called stack. stack last- in- first- set locations. stack known loca - tion and, often, least top two elements processor registers. Thus, zero- address instructions would reference top two stack elements. Stacks described Appendix I. use explored later chapter Chapter 13. Table 12.1 summarizes interpretations placed instructions zero, one, two, three addresses. case table, assumed address next instruction implicit, one operation two source operands one result operand performed. number addresses per instruction basic design decision. Fewer addresses per instruction result instructions primitive, requiring less complex processor. also results instructions shorter length. hand, programs contain total instructions, general results longer execution times longer, complex programs. Also, important threshold one- address multiple- address instructions. one- address instructions, programmer generally available one general- purpose Table 12.1 Utilization Instruction Addresses (Nonbranching Instructions) Number Addresses Symbolic Representation Interpretation 3 OP A, B, C AdB OP C 2 OP A, B AdA OP B 1 OP ACdAC OP 0 OP Td(T-1) OP AC = accumulator = top stack (T-1)=second element stack A, B, C = memory register locations12.1 / Machine instruction characteristics 419 register, accumulator. multiple- address instructions, common multiple general- purpose registers. allows operations performed solely registers. register references faster memory references, speeds execution. reasons flexibility ability use multiple reg - isters, contemporary machines employ mixture two- three- address instructions. design trade- offs involved choosing number addresses per instruc - tion complicated factors. issue whether address refer - ences memory location register. fewer registers, fewer bits needed register reference. Also, see Chapter 13, machine may offer variety addressing modes, specification mode takes one bits. result processor designs involve variety instruction formats. Instruction Set Design One interesting, analyzed, aspects computer design instruction set design. design instruction set complex affects many aspects computer system. instruction set defines many functions performed processor thus significant effect implementation processor. instruction set programmer’s means controlling processor. Thus, programmer requirements must considered designing instruction set. may surprise know fundamental issues relat - ing design instruction sets remain dispute. Indeed, recent years, level disagreement concerning fundamentals actually grown. important fundamental design issues include following: ■Operation repertoire: many operations provide, complex operations be. ■Data types: various types data upon operations performed. ■Instruction format: Instruction length (in bits), number addresses, size various fields, on. ■Registers: Number processor registers referenced instruc - tions, use. ■Addressing: mode modes address operand specified. issues highly interrelated must considered together design - ing instruction set. book, course, must consider sequence, attempt made show interrelationships. importance topic, much Part Three devoted instruction set design. Following overview section, chapter examines data types operation repertoire. Chapter 13 examines addressing modes (which includes consideration registers) instruction formats. Chapter 15 examines reduced instruction set computer (RISC). RISC architecture calls ques - tion many instruction set design decisions traditionally made commercial computers.420 cha Pter 12 / instruction sets: characteristics Functions 12.2 TYPES OPERANDS Machine instructions operate data. important general categories data ■Addresses ■Numbers ■Characters ■Logical data shall see, discussing addressing modes Chapter 13, addresses are, fact, form data. many cases, calculation must performed operand reference instruction determine main virtual memory address. context, addresses considered unsigned integers. common data types numbers, characters, logical data, briefly examined section. Beyond that, machines define spe - cialized data types data structures. example, may machine opera - tions operate directly list string characters. Numbers machine languages include numeric data types. Even nonnumeric data pro - cessing, need numbers act counters, field widths, forth. important distinction numbers used ordinary mathematics numbers stored computer latter limited. true two senses. First, limit magnitude numbers representable machine second, case floating- point numbers, limit precision. Thus, programmer faced understanding consequences rounding, overflow, underflow. Three types numerical data common computers: ■Binary integer binary fixed point ■Binary floating point ■Decimal examined first two detail Chapter 10. remains say words decimal numbers. Although internal computer operations binary nature, human users system deal decimal numbers. Thus, necessity convert decimal binary input binary decimal output. appli - cations great deal I/O comparatively little, comparatively simple computation, preferable store operate numbers decimal form. common representation purpose packed decimal .1 1Textbooks often refer binary coded decimal (BCD). Strictly speaking, BCD refers encod - ing decimal digit unique 4-bit sequence. Packed decimal refers storage BCD- encoded digits using one byte two digits.12.2 / tyPes oPerands 421 packed decimal, decimal digit represented 4-bit code, obvious way, two digits stored per byte. Thus, 0=000, 1=0001,c, 8=1000, 9=1001. Note rather inefficient code 10 16 possible 4-bit values used. form numbers, 4-bit codes strung together, usually multiples 8 bits. Thus, code 246 0000 0010 0100 0110. code clearly less compact straight binary representation, avoids conversion overhead. Negative numbers represented including 4-bit sign digit either left right end string packed decimal digits. Standard sign values 1100 positive (+) 1101 negative (-). Many machines provide arithmetic instructions performing operations directly packed decimal numbers. algorithms quite similar described Section 9.3 must take account decimal carry operation. Characters common form data text character strings. textual data con - venient human beings, cannot, character form, easily stored trans - mitted data processing communications systems. systems designed binary data. Thus, number codes devised characters represented sequence bits. Perhaps earliest common example Morse code. Today, commonly used character code International Reference Alphabet (IRA), referred United States American Standard Code Information Interchange (ASCII; see Appendix H). char - acter code represented unique 7-bit pattern; thus, 128 different char - acters represented. larger number necessary represent printable characters, patterns represent control characters. control characters controlling printing characters page. Others concerned communications procedures. IRA- encoded charac - ters almost always stored transmitted using 8 bits per character. eighth bit may set 0 used parity bit error detection. latter case, bit set total number binary 1s octet always odd (odd parity) always even (even parity). Note Table H.1 (Appendix H) IRA bit pattern 011XXXX, digits 0 9 represented binary equivalents, 0000 1001, rightmost 4 bits. code packed decimal. facilitates con - version 7-bit IRA 4-bit packed decimal representation. Another code used encode characters Extended Binary Coded Decimal Interchange Code (EBCDIC). EBCDIC used IBM mainframes. 8-bit code. IRA, EBCDIC compatible packed decimal. case EBCDIC, codes 11110000 11111001 represent digits 0 9. Logical Data Normally, word addressable unit (byte, halfword, on) treated single unit data. sometimes useful, however, consider n- bit unit consisting n 1 -bit items data, item value 0 1. data viewed way, considered logical data.422 cha Pter 12 / instruction sets: characteristics Functions two advantages bit- oriented view. First, may sometimes wish store array Boolean binary data items, item take values 1 (true) 0 (false). logical data, memory used efficiently storage. Second, occasions wish manipulate bits data item. example, floating- point operations implemented software, need able shift significant bits operations. Another example: con - vert IRA packed decimal, need extract rightmost 4 bits byte. Note that, preceding examples, data treated sometimes logical times numerical text. “type” unit data deter - mined operation performed it. normally case high- level languages, almost always case machine language. 12.3 INTEL x86 ARM DATA TYPES x86 Data Types x86 deal data types 8 (byte), 16 (word), 32 (doubleword), 64 (quad - word), 128 (double quadword) bits length. allow maximum flexibility data structures efficient memory utilization, words need aligned even- numbered addresses; doublewords need aligned addresses evenly divisible 4; quadwords need aligned addresses evenly divisible 8; on. However, data accessed across 32-bit bus, data transfers take place units doublewords, beginning addresses divisible 4. processor converts request misaligned values sequence requests bus transfer. Intel 80x86 machines, x86 uses little- endian style; is, least significant byte stored lowest address (see Appendix 12A discus - sion endianness). byte, word, doubleword, quadword, double quadword referred general data types. addition, x86 supports impressive array specific data types recognized operated particular instructions. Table 12.2 summarizes types. Figure 12.4 illustrates x86 numerical data types. signed integers twos complement representation may 16, 32, 64 bits long. floating- point type actually refers set types used floating- point unit operated floating- point instructions. floating- point representations conform IEEE 754 standard. packed SIMD ( single- instruction- multiple- data) data types intro - duced x86 architecture part extensions instruction set optimize performance multimedia applications. extensions include MMX (multimedia extensions) SSE (streaming SIMD extensions). basic concept multiple operands packed single referenced memory item multiple operands operated parallel. data types follows: ■Packed byte packed byte integer: Bytes packed 64-bit quadword 128-bit double quadword, interpreted bit field integer. ■Packed word packed word integer: 16-bit words packed 64-bit quad - word 128-bit double quadword, interpreted bit field integer.12.3 / inteL x86 arM data tyPes 423 ■Packed doubleword packed doubleword integer: 32-bit doublewords packed 64-bit quadword 128-bit double quadword, interpreted bit field integer. ■Packed quadword packed quadword integer: Two 64-bit quadwords packed 128-bit double quadword, interpreted bit field integer. ■Packed single- precision floating- point packed double- precision floating - point: Four 32-bit floating- point two 64-bit floating- point values packed 128-bit double quadword. ARM Data Types ARM processors support data types 8 (byte), 16 (halfword), 32 (word) bits length. Normally, halfword access halfword aligned word accesses word aligned. nonaligned access attempts, architecture supports three alternatives. ■Default case: – address treated truncated, address bits[1:0] treated zero word accesses, address bit[0] treated zero halfword accesses.Table 12.2 x86 Data Types Data Type Description General Byte, word (16 bits), doubleword (32 bits), quadword (64 bits), double quadword (128 bits) locations arbitrary binary contents. Integer signed binary value contained byte, word, doubleword, using twos complement representation. Ordinal unsigned integer contained byte, word, doubleword. Unpacked binary coded decimal (BCD)A representation BCD digit range 0 9, one digit byte. Packed BCD Packed byte representation two BCD digits; value range 0 99. Near pointer 16-bit, 32-bit, 64-bit effective address represents offset within segment. Used pointers nonsegmented memory references within segment segmented memory. Far pointer logical address consisting 16-bit segment selector offset 16, 32, 64 bits. Far pointers used memory references segmented memory model identity segment accessed must specified explicitly. Bit field contiguous sequence bits position bit considered independent unit. bit string begin bit position byte contain 32 bits. Bit string contiguous sequence bits, containing zero 223-1 bits. Byte string contiguous sequence bytes, words, doublewords, containing zero 223-1 bytes. Floating point See Figure 12.4. Packed SIMD (single instruction, multiple data)Packed 64-bit 128-bit data types.424 cha Pter 12 / instruction sets: characteristics Functions – Load single word ARM instructions architecturally defined rotate right word- aligned data transferred non word- aligned address one, two, three bytes depending value two least significant address bits. ■Alignment checking: appropriate control bit set, data abort sig - nal indicates alignment fault attempting unaligned access. ■Unaligned access: option enabled, processor uses one memory accesses generate required transfer adjacent bytes transpar - ently programmer. three data types (byte, halfword, word) unsigned interpretation supported, value represents unsigned, nonnegative integer. three data types also used twos complement signed integers. majority ARM processor implementations provide floating- point hardware, saves power area. floating- point arithmetic required processors, must implemented software. ARM support optional floating- point coprocessor supports single- double- precision floating point data types defined IEEE 754.sign bitsign bitsign bit integer bit exponent signif icandexp signif icandexp signif icandtwos comp sign bitsign bitsign bitByte unsigned integer Word unsigned integer Doubleword unsigned integer Quadword unsigned integer Byte signed integer (twos complement) Word signed integer (twos complement) Doubleword signed integer (twos complement) Quadward unsigned integer (twos complement) Single precision ﬂoating point Double precision ﬂoating point Double extended precision ﬂoating point0 7 70 15 150 31 31 31 220 63 63 63 63 790 0 sign bitHalf precision ﬂoating point15 00 0 0 0 51 0sign bit 9exp signif. Figure 12.4 x86 Numeric Data Formats12.4 / tyPes oPerations 425 endian support state bit ( E- bit) system control register set cleared program control using SETEND instruction. E- bit defines endian load store data. Figure 12.5 illustrates functionality associated E- bit word load store operation. mechanism enables efficient dynamic data load/store system designers know need access data structures opposite endianness OS/environment. Note address data byte fixed memory. However, byte lane register different. 12.4 TYPES OPERATIONS number different opcodes varies widely machine machine. However, general types operations found machines. useful typical categorization following: ■Data transfer ■Arithmetic ■Logical ■Conversion ■I/O ■System control ■Transfer control Table 12.3 (based [HAYE98]) lists common instruction types cat - egory. section provides brief survey various types operations, together brief discussion actions taken processor execute particular type operation (summarized Table 12.4). latter topic exam - ined detail C hapter 14.Byte 3Data bytes memory (ascending addr ess values byte 0 byte 3) ARM r egister Program status register E-bit = 0P rogram status register E-bit = 1ARM registerByte 2 Byte 1 Byte 00 31 0 31 Byte 1 Byte 2 Byte 3 Byte 0 Byte 1 Byte 2 Byte 3Byte 0 Figure 12.5 ARM Endian Support— Word Load/Store E- BitTable 12.3 Common Instruction Set Operations Type Operation Name Description Data transferMove (transfer) Transfer word block source destination Store Transfer word processor memory Load (fetch) Transfer word memory processor Exchange Swap contents source destination Clear (reset) Transfer word 0s destination Set Transfer word 1s destination Push Transfer word source top stack Pop Transfer word top stack destination ArithmeticAdd Compute sum two operands Subtract Compute difference two operands Multiply Compute product two operands Divide Compute quotient two operands Absolute Replace operand absolute value Negate Change sign operand Increment Add 1 operand Decrement Subtract 1 operand LogicalAND Perform logical Perform logical (complement) Perform logical Exclusive- Perform logical XOR Test Test specified condition; set flag(s) based outcome Compare Make logical arithmetic comparison two operands; set flag(s) based outcome Set Control VariablesClass instructions set controls protection purposes, interrupt handling, timer control, etc. Shift Left (right) shift operand, introducing constants end Rotate Left (right) shift operand, wraparound end Transfer controlJump (branch) Unconditional transfer; load PC specified address Jump Conditional Test specified condition; either load PC specified address nothing, based condition Jump Subroutine Place current program control information known location; jump specified address Return Replace contents PC register known location Execute Fetch operand specified location execute instruc- tion; modify PC Skip Increment PC skip next instruction Skip Conditional Test specified condition; either skip nothing based condition Halt Stop program execution Wait (hold) Stop program execution; test specified condition repeatedly; resume execution condition satisfied operation operation performed, program execution continued 42612.4 / tyPes oPerations 427 Data Transfer fundamental type machine instruction data transfer instruction. data transfer instruction must specify several things. First, location source destination operands must specified. location could memory, register, top stack. Second, length data transferred must indicated. Third, instructions operands, mode addressing operand must specified. latter point discussed Chapter 13. choice data transfer instructions include instruction set exem - plifies kinds trade- offs designer must make. example, general location (memory register) operand indicated either specifica - tion opcode operand. Table 12.5 shows examples common IBM EAS/390 data transfer instructions. Note variants indicate Type Operation Name Description Input/outputInput (read) Transfer data specified I/O port device destination (e.g., main memory processor register) Output (write) Transfer data specified source I/O port device Start I/O Transfer instructions I/O processor initiate I/O operation Test I/O Transfer status information I/O system specified destination ConversionTranslate Translate values section memory based table correspondences Convert Convert contents word one form another (e.g., packed decimal binary) Table 12.4 Processor Actions Various Types Operations Data transferTransfer data one location another memory involved: Determine memory address Perform virtual- to- actual- memory address transformation Check cache Initiate memory read/write ArithmeticMay involve data transfer, and/or Perform function ALU Set condition codes flags Logical arithmetic ConversionSimilar arithmetic logical. May involve special logic perform conversion Transfer controlUpdate program counter. subroutine call/return, manage parameter passing linkage I/OIssue command I/O module memory- mapped I/O, determine memory- mapped address428 cha Pter 12 / instruction sets: characteristics Functions amount data transferred (8, 16, 32, 64 bits). Also, different instructions register register, register memory, memory register, memory memory transfers. contrast, VAX move (MOV) instruction variants different amounts data moved, specifies whether operand register memory part operand. VAX approach - easier programmer, fewer mnemonics deal with. However, also somewhat less compact IBM EAS/390 approach loca - tion (register versus memory) operand must specified separately instruction. return distinction discuss instruction formats Chapter 13. terms processor action, data transfer operations perhaps simplest type. source destination registers, processor simply causes data transferred one register another; operation internal processor. one operands memory, processor must per - form following actions: 1. Calculate memory address, based address mode (discussed Chapter 13). 2. address refers virtual memory, translate virtual real memory address. 3. Determine whether addressed item cache. 4. not, issue command memory module.Table 12.5 Examples IBM EAS/390 Data Transfer Operations Operation Mnemonic NameNumber Bits Transferred Description L Load 32 Transfer memory register LH Load Halfword 16 Transfer memory register LR Load 32 Transfer register register LER Load (short) 32 Transfer floating- point register floating- point register LE Load (short) 32 Transfer memory floating- point register LDR Load (long) 64 Transfer floating- point register floating- point register LD Load (long) 64 Transfer memory floating- point register ST Store 32 Transfer register memory STH Store Halfword 16 Transfer register memory STC Store Character 8 Transfer register memory STE Store (short) 32 Transfer floating- point register memory STD Store (long) 64 Transfer floating- point register memory12.4 / tyPes oPerations 429 Arithmetic machines provide basic arithmetic operations add, subtract, multi - ply, divide. invariably provided signed integer ( fixed- point) numbers. Often also provided floating- point packed decimal numbers. possible operations include variety single- operand instructions; example, ■Absolute: Take absolute value operand. ■Negate: Negate operand. ■Increment: Add 1 operand. ■Decrement: Subtract 1 operand. execution arithmetic instruction may involve data transfer oper - ations position operands input ALU, deliver output ALU. Figure 3.5 illustrates movements involved data transfer arithmetic operations. addition, course, ALU portion processor per - forms desired operation. Logical machines also provide variety operations manipulating individual bits word addressable units, often referred “bit twiddling.” based upon Boolean operations (see Chapter 11). basic logical operations performed Boolean binary data shown Table 12.6. operation inverts bit. AND, OR, Exclusive- (XOR) common logical functions two oper - ands. EQUAL useful binary test. logical operations applied bitwise n- bit logical data units. Thus, two registers contain data (R1)=10100101 (R2)=00001111 (R1) (R2)=00000101 Table 12.6 Basic Logical Operations P Q P P Q P Q P XOR Q P=Q 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1430 cha Pter 12 / instruction sets: characteristics Functions notation (X) means contents location X. Thus, operation used mask selects certain bits word zeros remaining bits. another example, two registers contain (R1)=10100101 (R2)=11111111 (R1) XOR (R2)=01011010 one word set 1s, XOR operation inverts bits word (ones complement). addition bitwise logical operations, machines provide variety shifting rotating functions. basic operations illustrated Fig - ure 12.6. logical shift , bits word shifted left right. one end, bit shifted lost. end, 0 shifted in. Logical shifts useful primarily isolating fields within word. 0s shifted word dis - place unwanted information shifted end.    (a) Logical right shift0 0    (e) Right rotate   (c) Arithmetic right shiftS   (b) Logical left shift    (f) Left rotate0    (d) Arithmetic left shiftS Figure 12.6 Shift Rotate Operations12.4 / tyPes oPerations 431 example, suppose wish transmit characters data I/O device 1 character time. memory word 16 bits length contains two characters, must unpack characters sent. send two characters word; 1. Load word register. 2. Shift right eight times. shifts remaining character right half register. 3. Perform I/O. I/O module reads lower- order 8 bits data bus. preceding steps result sending left- hand character. send right- hand character; 1. Load word register. 2. 0000000011111111. masks character left. 3. Perform I/O. arithmetic shift operation treats data signed integer shift sign bit. right arithmetic shift, sign bit replicated bit position right. left arithmetic shift, logical left shift performed bits sign bit, retained. operations speed certain arithmetic operations. numbers twos complement notation, right arithme - tic shift corresponds division 2, truncation odd numbers. arithmetic left shift logical left shift correspond multiplication 2 overflow. overflow occurs, arithmetic logical left shift operations produce different results, arithmetic left shift retains sign number. potential overflow, many processors include instruc - tion, including PowerPC Itanium. Others, IBM EAS/390, offer instruction. Curiously, x86 architecture includes arithmetic left shift defines identical logical left shift. Rotate , cyclic shift, operations preserve bits operated on. One use rotate bring bit successively leftmost bit, identified testing sign data (treated number). arithmetic operations, logical operations involve ALU activity may involve data transfer operations. Table 12.7 gives examples shift rotate operations discussed subsection. Table 12.7 Examples Shift Rotate Operations Input Operation Result 10100110 Logical right shift (3 bits) 00010100 10100110 Logical left shift (3 bits) 00110000 10100110 Arithmetic right shift (3 bits) 11110100 10100110 Arithmetic left shift (3 bits) 10110000 10100110 Right rotate (3 bits) 11010100 10100110 Left rotate (3 bits) 00110101432 cha Pter 12 / instruction sets: characteristics Functions Conversion Conversion instructions change format operate format data. example converting decimal binary. example com - plex editing instruction EAS/390 Translate (TR) instruction. instruction used convert one 8-bit code another, takes three operands: TR R1 (L), R2 operand R2 contains address start table 8-bit codes. L bytes starting address specified R1 translated, byte replaced contents table entry indexed byte. example, translate EBCDIC IRA, first create 256-byte table storage locations, say, 1000-10FF hexadecimal. table contains characters IRA code sequence binary representation EBCDIC code; is, IRA code placed table relative location equal binary value EBCDIC code character. Thus, locations 10F0 10F9 contain val - ues 30 39, F0 EBCDIC code digit 0, 30 IRA code digit 0, digit 9. suppose EBCDIC digits 1984 starting location 2100 wish translate IRA. Assume following: ■Locations 2100–2103 contain F1 F9 F8 F4. ■R1 contains 2100. ■R2 contains 1000. Then, execute TR R1 (4), R2 locations 2100–2103 contain 31 39 38 34. Input/Output Input/output instructions discussed detail Chapter 7 . saw, variety approaches taken, including isolated programmed I/O, memory- mapped programmed I/O, DMA, use I/O processor. Many implemen - tations provide I/O instructions, specific actions specified parameters, codes, command words. System Control System control instructions executed processor certain privileged state executing program special privileged area memory. Typically, instructions reserved use operating system. examples system control operations follows. system con - trol instruction may read alter control register; discuss control registers Chapter 14. Another example instruction read modify storage protec - tion key, used EAS/390 memory system. Yet another example access process control blocks multiprogramming system.12.4 / tyPes oPerations 433 Transfer Control operation types discussed far, next instruction performed one immediately follows, memory, current instruction. However, significant fraction instructions program function chang - ing sequence instruction execution. instructions, operation per - formed processor update program counter contain address instruction memory. number reasons transfer- of- control operations required. Among important following: 1. practical use computers, essential able execute instruction perhaps many thousands times. may require thousands perhaps millions instructions implement applica - tion. would unthinkable instruction written sep - arately. table list items processed, program loop needed. One sequence instructions executed repeatedly process data. 2. Virtually programs involve decision making. would like computer one thing one condition holds, another thing another condition holds. example, sequence instructions computes square root num - ber. start sequence, sign number tested. number negative, computation performed, error condition reported. 3. compose correctly large even medium- size computer program exceedingly difficult task. helps mechanisms breaking task smaller pieces worked one time. turn discussion common transfer- of- control opera - tions found instruction sets: branch, skip, procedure call . branch instructions branch instruction, also called jump instruction, one operands address next instruction executed. often, instruction conditional branch instruction. is, branch made (update program counter equal address specified operand) certain condition met. Otherwise, next instruction sequence executed (increment program counter usual). branch instruction branch always taken unconditional branch . two common ways generating condition tested con - ditional branch instruction. First, machines provide 1-bit multiple- bit con - dition code set result operations. code thought short user- visible register. example, arithmetic operation (ADD, SUBTRACT, on) could set 2-bit condition code one following four values: 0, positive, negative, overflow. machine, could four different conditional branch instructions: BRP X Branch location X result positive. BRN X Branch location X result negative. BRZ X Branch location X result zero. BRO X Branch location X overflow occurs.434 cha Pter 12 / instruction sets: characteristics Functions cases, result referred result recent oper - ation set condition code. Another approach used three- address instruction format perform comparison specify branch instruction. example, BRE R1, R2, X Branch X contents R1=contents R2. Figure 12.7 shows examples operations. Note branch either forward (an instruction higher address) backward (lower address). example shows unconditional conditional branch used create repeating loop instructions. instructions locations 202 210 executed repeatedly result subtracting X 0. skip instructions Another form transfer- of- control instruction skip instruction. skip instruction includes implied address. Typically, skip implies one instruction skipped; thus, implied address equals address next instruction plus one instruction length. skip instruction require destination address field, free things. typical example increment- and- skip- if- zero (ISZ) instruction. Consider following program fragment: 301 f 309ISZR1 310BR301 311 fragment, two transfer- of- control instructions used implement iterative loop. R1 set negative number iterations performed. end loop, R1 incremented. 0, program branches back beginning loop. Otherwise, branch skipped, program continues next instruction end loop.Memory addr ess Unconditional branchInstruction 200 SUB X,Y BRZ 211 BR 202Conditional branch Conditional branchBRE R1, R2, 235201 202 203 210 211 225 235 Figure 12.7 Branch Instructions12.4 / tyPes oPerations 435 procedure call instructions Perhaps important innovation development programming languages procedure. procedure self- contained computer program incorporated larger program. point program procedure may invoked, called. processor instructed go execute entire procedure return point call took place. two principal reasons use procedures economy mod - ularity. procedure allows piece code used many times. important economy programming effort making efficient use storage space system (the program must stored). Procedures also allow large programming tasks subdivided smaller units. use modularity greatly eases programming task. procedure mechanism involves two basic instructions: call instruction branches present location procedure, return instruction returns procedure place called. forms branching instructions. Figure 12.8a illustrates use procedures construct program. example, main program starting location 4000. program includes call procedure PROC1, starting location 4500. call instruction encountered, processor suspends execution main program begins exe - cution PROC1 fetching next instruction location 4500. Within PROC1, two calls PROC2 location 4800. case, execution PROC1 CALL Pr oc1Main memory Main program Procedur e Proc1 Procedur e Proc2Addr esses 4000 4100 4101 4500 48004600 4601 4650 4651CALL Pr oc2 CALL Pr oc2 RETURN RETURN (a) Calls returns (b) Ex ecution sequence Figure 12.8 Nested Procedures436 cha Pter 12 / instruction sets: characteristics Functions suspended PROC2 executed. RETURN statement causes processor go back calling program continue execution instruction corresponding CALL instruction. behavior illustrated Figure 12.8b. Three points worth noting: 1. procedure called one location. 2. procedure call appear procedure. allows nesting proce - dures arbitrary depth. 3. procedure call matched return called program. would like able call procedure variety points, processor must somehow save return address return take place appropriately. three common places storing return address: ■Register ■Start called procedure ■Top stack Consider machine- language instruction CALL X, stands call procedure location X. register approach used, CALL X causes following actions: RNdPC+∆ PCdX RN register always used purpose, PC program counter, ∆ instruction length. called procedure save contents RN used later return. second possibility store return address start procedure. case, CALL X causes XdPC+∆ PCdX+1 quite handy. return address stored safely away. preceding approaches work used. limita - tion approaches complicate use reentrant procedures. reentrant procedure one possible several calls open time. recursive procedure (one calls itself) example use feature (see Appendix M). parameters passed via registers memory reentrant procedure, code must responsible saving parameters registers memory space available procedure calls. general powerful approach use stack (see Appendix discussion stacks). processor executes call, places return address stack. executes return, uses address stack. Figure 12.9 illustrates use stack. addition providing return address, also often necessary pass parameters procedure call. passed registers. Another possi - bility store parameters memory CALL instruction. case, return must location following parameters. Again, 12.4 / tyPes oPerations 437 approaches drawbacks. registers used, called program calling program must written assure registers used properly. storing parameters memory makes difficult exchange variable number parameters. approaches prevent use reentrant procedures. flexible approach parameter passing stack. pro - cessor executes call, stacks return address, stacks parameters passed called procedure. called procedure access parameters stack. Upon return, return parameters also placed stack. entire set parameters, including return address, stored procedure invocation referred stack frame. example provided Figure 12.10. example refers procedure P local variables x1 x2 declared, procedure Q, P call local variables y1 y2 declared. figure, return (a) Initial stack contents4101 (b) CALL Proc141014601 (c) Initial CALL Proc24101 (d) RETURN41014651 (e) CALL Proc24101 (f) RETURN (g) RETURN Figure 12.9 Use Stack Implement Nested Subroutines Figure 12.8 Return pointOld frame pointerStack pointer x1x2 P:Frame pointer Return pointOld frame pointerReturn pointStack pointery2 y1 x2 x1 P:Q:Frame pointerOld frame pointer (a) P active (b) P called Q Figure 12.10 Stack Frame Growth Using Sample Procedures P Q438 cha Pter 12 / instruction sets: characteristics Functions point procedure first item stored corresponding stack frame. Next stored pointer beginning previous frame. needed number length parameters stacked variable. 12.5 INTEL x86 ARM OPERATION TYPES x86 Operation Types x86 provides complex array operation types, including number special - ized instructions. intent provide tools compiler writer produce optimized machine language translation high- level language programs. conventional instructions found machine instruction sets, several types instructions tailored x86 architecture particular interest. Appendix [CART06] lists x86 instructions, together oper - ands effect instruction condition codes. Appendix B NASM assembly language manual [NASM12] provides detailed descrip - tion x86 instruction. documents available box.com/COA10e. call/return instructions x86 provides four instructions support procedure call/return: CALL, ENTER, LEAVE, RETURN. instructive look support provided instructions. Recall Figure 12.10 common means implementing procedure call/return mechanism via use stack frames. new procedure called, following must performed upon entry new procedure: ■Push return point stack. ■Push current frame pointer stack. ■Copy stack pointer new value frame pointer. ■Adjust stack pointer allocate frame. CALL instruction pushes current instruction pointer value onto stack causes jump entry point procedure placing address entry point instruction pointer. 8088 8086 machines, typical procedure began sequence PUSH EBP MOV EBP, ESP SUB ESP, space_for_locals EBP frame pointer ESP stack pointer. 80286 later machines, ENTER instruction performs aforementioned operations single instruction. ENTER instruction added instruction set provide direct sup - port compiler. instruction also includes feature support called nested procedures languages Pascal, COBOL, Ada (not found C FORTRAN). turns better ways handling nested pro - cedure calls languages. Furthermore, although ENTER instruction 12.5 / inteL x86 arM oPeration tyPes 439 saves bytes memory compared PUSH, MOV, SUB sequence (4 bytes versus 6 bytes), actually takes longer execute (10 clock cycles versus 6 clock cycles). Thus, although may seemed good idea instruction set designers add feature, complicates implementation processor providing little benefit. see that, contrast, RISC approach processor design would avoid complex instructions ENTER might produce efficient implementation sequence simpler instructions. memory management Another set specialized instructions deals memory segmentation. privileged instructions executed operating system. allow local global segment tables (called descriptor tables) loaded read, privilege level segment checked altered. special instructions dealing on- chip cache discussed Chapter 4. status flags condition codes Status flags bits special registers may set certain operations used conditional branch instructions. term condition code refers settings one status flags. x86 many architectures, status flags set arithmetic compare operations. compare operation languages subtracts two operands, subtract operation. difference compare operation sets status flags, whereas subtract operation also stores result subtraction destination operand. architectures also set status flags data transfer instructions. Table 12.8 lists status flags used x86. flag, combinations flags, tested conditional jump. Table 12.9 shows condition codes (combinations status flag values) conditional jump opcodes defined. Several interesting observations made list. First, may wish test two operands determine one number bigger another. depend whether numbers signed unsigned. example, 8-bit number 11111111 bigger 00000000 two numbers interpreted Table 12.8 x86 Status Flags Status Bit Name Description C Carry Indicates carrying borrowing left- bit position following arithmetic operation. Also modified shift rotate operations. P Parity Parity least- significant byte result arithmetic logic operation. 1 indicates even parity; 0 indicates odd parity. Auxiliary Carry Represents carrying borrowing half- bytes 8-bit arithmetic logic operation. Used binary- coded decimal arithmetic. Z Zero Indicates result arithmetic logic operation 0. Sign Indicates sign result arithmetic logic operation. Overflow Indicates arithmetic overflow addition subtraction twos complement arithmetic.440 cha Pter 12 / instruction sets: characteristics Functions Table 12.9 x86 Condition Codes Conditional Jump SETcc Instructions Symbol Condition Tested Comment A, NBE C=0 Z=0 Above; equal (greater than, unsigned) AE, NB, NC C=0 equal; (greater equal, unsigned); carry B, NAE, C C=1 Below; equal (less than, unsigned); Carry set BE, NA C=1 Z=1 equal; (less equal, unsigned) E, Z Z=1 Equal; Zero (signed unsigned) G, NLE [(S=1 O=1) (S=0 O=0)]AND[Z = 0]Greater than; less equal (signed) GE, NL (S=1 O=1) (S=0 O=0)Greater equal; less (signed) L, NGE (S=1 O=0) (S=0 O=0)Less than; greater equal (signed) LE, NG (S=1 O=0) (S=0 O=1) (Z=1)Less equal; greater (signed) NE, NZ Z=0 equal; zero (signed unsigned) O=0 overflow NS S=0 sign (not negative) NP, PO P=0 parity; Parity odd O=1 Overflow P P=1 Parity; Parity even S=1 Sign (negative) unsigned integers (25570) less considered 8-bit twos com - plement numbers (-160). Many assembly languages therefore introduce two sets terms distinguish two cases: comparing two numbers signed integers, use terms less greater ; comparing unsigned integers, use terms above. second observation concerns complexity comparing signed integers. signed result greater equal zero (1) sign bit zero overflow (S=0 O=0), (2) sign bit one overflow. study Figure 10.4 convince conditions tested vari - ous signed operations appropriate. x86 simd instructions 1996, Intel introduced MMX technology Pentium product line. MMX set highly optimized instructions multimedia tasks. 57 new instructions treat data SIMD ( single- instruction, multiple- data) fashion, makes possible perform operation, addition multiplication, multiple data elements once. instruction typically takes single clock cycle execute. proper application, fast parallel operations yield speedup two eight times comparable algorithms use MMX instructions [ATKI96]. introduction 64-bit x86 architecture, Intel expanded extension include double 12.5 / inteL x86 arM oPeration tyPes 441 quadword (128 bits) operands floating- point operations. subsection, describe MMX features. focus MMX multimedia programming. Video audio data typically composed large arrays small data types, 8 16 bits, whereas conventional instructions tailored operate 32- 64-bit data. examples: graphics video, single scene consists array pixels,2 8 bits pixel 8 bits pixel color component (red, green, blue). Typical audio samples quantized using 16 bits. 3D graph - ics algorithms, 32 bits common basic data types. provide parallel oper - ation data lengths, three new data types defined MMX. data type 64 bits length consists multiple smaller data fields, holds fixed- point integer. types follows: ■Packed byte: Eight bytes packed one 64-bit quantity. ■Packed word: Four 16-bit words packed 64 bits. ■Packed doubleword: Two 32-bit doublewords packed 64 bits. Table 12.10 lists MMX instruction set. instructions involve parallel operation bytes, words, doublewords. example, PSLLW instruction performs left logical shift separately four words packed word operand; PADDB instruction takes packed byte operands input performs parallel additions byte position independently produce packed byte output. One unusual feature new instruction set introduction satura- tion arithmetic byte 16-bit word operands. ordinary unsigned arith - metic, operation overflows (i.e., carry significant bit), extra bit truncated. referred wraparound, effect truncation be, example, produce addition result smaller two input operands. Consider addition two words, hexadecimal, F000h 3000h. sum would expressed F000h=1111 0000 0000 0000 +3000h=0011 0000 0000 0000 10010 0000 0000 0000=2000h two numbers represented image intensity, result addition make combination two dark shades turn lighter. typically intended. saturation arithmetic, addition results overflow subtraction results underflow, result set largest smallest value rep - resentable. preceding example, saturation arithmetic, F000h=1111 0000 0000 0000 +3000h=0011 0000 0000 0000 10010 0000 0000 0000 1111 1111 1111 1111=FFFFh 2A pixel, picture element, smallest element digital image assigned gray level. Equivalently, pixel individual dot dot- matrix representation picture.442 cha Pter 12 / instruction sets: characteristics Functions Table 12.10 MMX Instruction Set Category Instruction Description ArithmeticPADD [B, W, D] Parallel add packed eight bytes, four 16-bit words, two 32-bit doublewords, wraparound. PADDS [B, W] Add saturation. PADDUS [B, W] Add unsigned saturation. PSUB [B, W, D] Subtract wraparound. PSUBS [B, W] Subtract saturation. PSUBUS [B, W] Subtract unsigned saturation. PMULHW Parallel multiply four signed 16-bit words, high- order 16 bits 32-bit result chosen. PMULLW Parallel multiply four signed 16-bit words, low- order 16 bits 32-bit result chosen. PMADDWD Parallel multiply four signed 16-bit words; add together adjacent pairs 32-bit results. ComparisonPCMPEQ [B, W, D] Parallel compare equality; result mask 1s true 0s false. PCMPGT [B, W, D] Parallel compare greater than; result mask 1s true 0s false. ConversionPACKUSWB Pack words bytes unsigned saturation. PACKSS [WB, DW] Pack words bytes, doublewords words, signed saturation. PUNPCKH [BW, WD, DQ] Parallel unpack (interleaved merge) high- order bytes, words, doublewords MMX register. PUNPCKL [BW, WD, DQ] Parallel unpack (interleaved merge) low- order bytes, words, doublewords MMX register. LogicalPAND 64-bit bitwise logical PNDN 64-bit bitwise logical POR 64-bit bitwise logical PXOR 64-bit bitwise logical XOR ShiftPSLL [W, D, Q] Parallel logical left shift packed words, doublewords, quadword amount specified MMX register immedi - ate value. PSRL [W, D, Q] Parallel logical right shift packed words, doublewords, quadword. PSRA [W, D] Parallel arithmetic right shift packed words, double- words, quadword. Data transfer MOV [D, Q] Move doubleword quadword to/from MMX register. Statemgt EMMS Empty MMX state (empty FP registers tag bits). Note : instruction supports multiple data types [byte (B), word (W), doubleword (D), quadword (Q)], data types indicated brackets. provide feel use MMX instructions, look example, taken [PELE97]. common video application fade- out, fade- effect, one scene gradually dissolves another. Two images combined weighted average:12.5 / inteL x86 arM oPeration tyPes 443 Result_pixel=A_pixel*fade+B_pixel*(1-fade) calculation performed pixel position B. series video frames produced gradually changing fade value 1 0 (scaled appropriately 8-bit integer), result fade image image B. Figure 12.11 shows sequence steps required one set pixels. 8-bit pixel components converted 16-bit elements accommodate MMX 16-bit multiply capability. images use 640*480 resolution, dissolve technique uses 255 possible values fade value, total number RGBAlpha Image ARGBAlpha Image Ar3Ar2Ar1Ar0 r3 r2 r1 r0Ar3 Ar2 Ar1 SubtractAr0 r3 r2 r1 r0 fade ++ ++fade fade fade fade×r3fade×r2fade×r1fade×r0Br3Br2Br1Br0 Br3 Br2 Br1 Br0 newr3 newr2 newr1 newr0Br3 Br2 Br1 Br0 1. Unpack byte R pixel components fr om images B 2. Subtract image B fr om image 3. Multiply r esult fade value 4. Add image B pixels 5. Pack new composite pixels back bytes MMX code sequence perf orming operation:×× ×× pxor mm7, mm7 ;zer mm7 movq mm3, fad_val ;load fade value r eplicated 4 times movd mm0, imageA ;load 4 r ed pixel components fr om image movd mm1, imageB ;load 4 r ed pixel components fr om image B punpckblw mm0, mm7 ;unpack 4 pixels 16 bits punpckblw mm1, mm7 ;unpack 4 pixels 16 bits psubw mm0, mm1 ;subtract image B fr om image pmulhw mm0, mm3 ;multiply subtract r esult fade values paddd w mm0, mm1 ;add r esult image B packuswb mm0, mm7 ;pack 16-bit r esults back bytes Figure 12.11 Image Compositing Color Plane Representation444 cha Pter 12 / instruction sets: characteristics Functions instructions executed using MMX 535 million. calculation, performed without MMX instructions, requires 1.4 billion instruction executions [INTE98]. ARM Operation Types ARM architecture provides large collection operation types. following principal categories: ■Load store instructions: ARM architecture, load store instructions access memory locations; arithmetic logical instructions performed registers immediate values encoded instruction. limitation characteristic RISC design explored Chapter 15. ARM architecture supports two broad types instruction load store value single register, pair registers, memory: (1) load store 32-bit word 8-bit unsigned byte, (2) load store 16-bit unsigned halfword, load sign extend 16-bit halfword 8-bit byte. ■Branch instructions: ARM supports branch instruction allows condi - tional branch forwards backwards 32 MB. subroutine call performed variant standard branch instruction. well allow - ing branch forward backward 32 MB, Branch Link (BL) instruction preserves address instruction branch (the return address) LR (R14). Branches determined 4-bit condition field instruction. ■ Data- processing instructions: category includes logical instructions (AND, OR, XOR), add subtract instructions, test compare instructions. ■Multiply instructions: integer multiply instructions operate word halfword operands produce normal long results. example, multiply instruction takes two 32-bit operands produces 64-bit result. ■Parallel addition subtraction instructions: addition normal data processing multiply instructions, set parallel addition subtraction instructions, portions two operands operated parallel. example, ADD16 adds top halfwords two registers form top halfword result adds bottom halfwords two registers form bottom halfword result. instructions useful image processing applications, similar x86 MMX instructions. ■Extend instructions: several instructions unpacking data sign zero extending bytes halfwords words, halfwords words. ■Status register access instructions: ARM provides ability read also write portions status register. condition codes ARM architecture defines four condition flags stored program status register: N, Z, C, V (Negative, Zero, Carry oVerflow), meanings essentially S, Z, C, V flags 12.5 / inteL x86 arM oPeration tyPes 445 x86 architecture. four flags constitute condition code ARM. Table 12.11 shows combination conditions conditional execution defined. two unusual aspects use condition codes ARM: 1. instructions, branch instructions, include condition code field, means virtually instructions may conditionally executed. combination flag settings except 1110 1111 instruction’s condition code field signifies instruction executed condition met. 2. data processing instructions (arithmetic, logical) include bit signi - fies whether instruction updates condition flags. use conditional execution conditional setting condition flags helps design shorter programs use less memory. hand, instructions include 4 bits condition code, trade- fewer bits 32-bit instruction available opcode operands. ARM RISC design relies heavily register addressing, seems reasonable trade- off.Table 12.11 ARM Conditions Conditional Instruction Execution Code Symbol Condition Tested Comment 0000 EQ Z=1 Equal 0001 NE Z=0 equal 0010 CS/HS C=1 Carry set/unsigned higher 0011 CC/LO C=0 Carry clear/unsigned lower 0100 MI N=1 Minus/negative 0101 PL N=0 Plus/positive zero 0110 VS V=1 Overflow 0111 VC V=0 overflow 1000 HI C=1 Z=0 Unsigned higher 1001 LS C=0 Z=1 Unsigned lower 1010 GE N=V [(N=1 V=1) (N=0 V=0)]Signed greater equal 1011 LT N≠V [(N=1 V=0) (N=0 V=1)]Signed less 1100 GT (Z=0) (N=V) Signed greater 1101 LE (Z=1) (N≠V) Signed less equal 1110 AL — Always (unconditional) 1111 — — instruction executed unconditionally446 cha Pter 12 / instruction sets: characteristics Functions 12.6 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms accumulator address arithmetic shift bi- endian big endian branch conditional branch instruction setjump little endian logical shift machine instruction operand operation packed decimal popprocedure call procedure return push reentrant procedure rotate skip stack Review Questions 12.1 typical elements machine instruction? 12.2 types locations hold source destination operands? 12.3 instruction contains four addresses, might purpose address? 12.4 List briefly explain five important instruction set design issues. 12.5 types operands typical machine instruction sets? 12.6 relationship IRA character code packed decimal representation? 12.7 difference arithmetic shift logical shift? 12.8 transfer control instructions needed? 12.9 List briefly explain two common ways generating condition tested conditional branch instruction. 12.10 meant term nesting procedures ? 12.11 List three possible places storing return address procedure return . 12.12 reentrant procedure? 12.13 reverse Polish notation ? 12.14 difference big endian little endian? Problems 12.1 Show hex notation: a. packed decimal format 23. b. ASCII characters 23. 12.2 following packed decimal numbers, show decimal value: a. 0111 0011 0000 1001 b. 0101 1000 0010 c. 0100 1010 0110 12.3 given microprocessor words 1 byte. smallest largest integer represented following representations: a. Unsigned. b. Sign- magnitude. c. Ones complement. d. Twos complement.12.6 / Key terMs, review Questions, Prob LeMs 447 e. Unsigned packed decimal. f. Signed packed decimal. 12.4 Many processors provide logic performing arithmetic packed decimal numbers. Although rules decimal arithmetic similar binary operations, decimal results may require corrections individual digits binary logic used. Consider decimal addition two unsigned numbers. number con - sists N digits, 4 N bits number. two numbers added using binary adder. Suggest simple rule correcting result. Perform addition fashion numbers 1698 1786. 12.5 tens complement decimal number X defined 10N-X, N number decimal digits number. Describe use ten’s complement representation perform decimal subtraction. Illustrate procedure subtracting (0326)10 (0736)10. 12.6 Compare zero-, one-, two-, three- address machines writing programs compute X=(A+B*C)/(D-E*F) four machines. instructions available use follows: 0 Address 1 Address 2 Address 3 Address PUSH LOAD MOVE (XdY) MOVE (XdY) POP STORE ADD (XdX+Y) ADD (XdY+Z) ADD ADD SUB (XdX-Y) SUB (XdY-Z) SUB SUB MUL (XdX*Y) MUL (XdY*Z) MUL MUL DIV (XdX/Y) DIV (XdY/Z) DIV DIV 12.7 Consider hypothetical computer instruction set two n- bit instruc - tions. first bit specifies opcode, remaining bits specify one 2n-1 n- bit words main memory. two instructions follows: SUBS X Subtract contents location X accumulator, store result location X accumulator. JUMP X Place address X program counter. word main memory may contain either instruction binary number twos complement notation. Demonstrate instruction repertoire reason - ably complete specifying following operations programmed: a. Data transfer: Location X accumulator, accumulator location X. b. Addition: Add contents location X accumulator. c. Conditional branch. d. Logical OR. e. I/O Operations. 12.8 Many instruction sets contain instruction NOOP , meaning operation, effect processor state incrementing program counter. Suggest uses instruction. 12.9 Section 12.4, stated arithmetic left shift logical left shift correspond multiplication 2 overflow, overflow occurs, arithmetic logical left shift operations produce different results, arithmetic left shift retains sign number. Demonstrate statements true 5-bit twos complement integers.448 cha Pter 12 / instruction sets: characteristics Functions 12.10 way numbers rounded using arithmetic right shift (e.g., round toward +∞, round toward -∞, toward zero, away 0)? 12.11 Suppose stack used processor manage procedure calls returns. program counter eliminated using top stack program counter? 12.12 x86 architecture includes instruction called Decimal Adjust Addition (DAA). DAA performs following sequence instructions: ((AL 0FH) >9) (AF = 1) AL AL + 6; AF 1; else AF 0; endif; (AL > 9FH) (CF = 1) AL AL + 60H; CF 1; else CF 0; endif. “H” indicates hexadecimal. AL 8-bit register holds result addition two unsigned 8-bit integers. AF flag set carry bit 3 bit 4 result addition. CF flag set carry bit 7 bit 8. Explain function performed DAA instruction. 12.13 x86 Compare instruction (CMP) subtracts source operand destina - tion operand; updates status flags (C, P , A, Z, S, O) alter either operands. CMP instruction used determine destination oper - greater than, equal to, less source operand. a. Suppose two operands treated unsigned integers. Show status flags relevant determine relative size two integer values flags correspond greater than, equal to, less than. b. Suppose two operands treated twos complement signed integers. Show status flags relevant determine relative size two integer values flags correspond greater than, equal to, less than. c. CMP instruction may followed conditional Jump (Jcc) Set Con - dition (SETcc) instruction, cc refers one 16 conditions listed Table 12.11. Demonstrate conditions tested signed number compar - ison correct. 12.14 Suppose wished apply x86 CMP instruction 32-bit operands con - tained numbers floating- point format. correct results, requirements met following areas? a. relative position significand, sign, exponent fields. b. representation value zero. c. representation exponent. d. IEEE format meet requirements? Explain. 12.15 Many microprocessor instruction sets include instruction tests condition sets destination operand condition true. Examples include SETcc x86, Scc Motorola MC68000, Scond National NS32000. a. differences among instructions: ■SETcc Scc operate byte, whereas Scond operates byte, word, doubleword operands. ■SETcc Scond set operand integer one true zero false. Scc sets byte binary ones true zeros false. relative advantages disadvantages differences?12.6 / Key terMs, review Questions, Prob LeMs 449 b. None instructions set condition code flags, thus explicit test result instruction required determine value. Discuss whether condition codes set result instruction. c. simple statement a7b implemented using numerical representation method, is, making Boolean value manifest, opposed flow control method, represents value Boolean expression point reached program. compiler might implement a7ssb following x86 code: SUB CX, CX ;set register CX 0 MOV AX, B ;move contents location B register AX CMP AX, ;compare contents register AX location JLE TEST ;jump A…B INC CX ;add 1 contents register CX TEST JCXZ ;jump contents CX equal 0 result (A7B) Boolean value held register available later on, outside context flow code shown. convenient use register CX this, many branch loop opcodes built- test CX. Show alternative implementation using SETcc instruction saves memory execution time. ( Hint : additional new x86 instructions needed, SETcc.) d. consider high- level language statement: A:=(B7C) (D=F) compiler might generate following code: MOV EAX, B ;move contents location B register EAX CMP EAX, C ;compare contents register EAX location C MOV BL, 0 ;0 represents false JLE N1 ;jump (B…C) MOV BL, 1 ;1 represents false N1 MOV EAX, CMP EAX, F MOV BH, 0 JNE N2 MOV BH, 1 N2 BL, BH Show alternative implementation using SETcc instruction saves memory execution time. 12.16 Suppose two registers contain following hexadecimal values: AB0890C2, 4598EE50. result adding using MMX instructions: a. packed byte. b. packed word. Assume saturation arithmetic used.450 cha Pter 12 / instruction sets: characteristics Functions 12.17 Appendix points stack- oriented instructions instruction set stack used processor purposes procedure handling. processor use stack purpose without stack- oriented instructions? 12.18 Mathematical formulas usually expressed known infix notation, binary operator appears operands. alternative technique known reverse Polish , postfix , notation, operator follows two operands. See Appendix details. Convert following formulas reverse Polish infix: a. AB+C+D* b. AB/CD/+ c. ABCDE+**/ d. ABCDE+F/+G-H/*+ 12.19 Convert following formulas infix reverse Polish: a. A+B+C+D+E b. (A+B)*(C+D)+E c. (A*B)+(C*D)+E d. (A-B)*(((C-D*E)/F)/G)*H 12.20 Convert expression A+B-C postfix notation using Dijkstra’s algorithm. Show steps involved. result equivalent (A+B)-C A+(B-C)? matter? 12.21 Using algorithm converting infix postfix defined Appendix I, show steps involved converting expression Figure I.3 postfix. Use presenta - tion similar Figure I.5. 12.22 Show calculation expression Figure I.5, using presentation similar Figure I.4. 12.23 Redraw little- endian layout Figure 12.13 bytes appear numbered big- endian layout. is, show memory 64-bit rows, bytes listed left right, top bottom. 12.24 following data structures, draw big- endian little- endian layouts, using format Figure 12.13, comment results. a. struct { double i; //0x1112131415161718 } s1; b. struct { int i; //0x11121314 int j; //0x15161718 } s2; c. struct { short i; //0x1112 short j; //0x1314 short k; //0x1516 short l; //0x1718 } s3; 12.25 IBM Power architecture specification dictate processor imple - ment little- endian mode. specifies view memory processor must operating little- endian mode. converting data structure big endian little endian, processors free implement true byte- swapping mechanism use sort address modification mechanism. Current Power processors default big- endian machines use address modification treat data little- endian. Consider structure defined Figure 12.13. layout lower- right portion figure shows structure seen processor. fact, struc - tures compiled little- endian mode, layout memory shown Figure 12.12. 12.6 / Key terMs, review Questions, Prob LeMs 451 Explain mapping involved, describe easy way implement mapping, discuss effectiveness approach. 12.26 Write small program determine endianness machine report results. Run program computer available turn output. 12.27 MIPS processor set operate either big- endian little- endian mode. Consider Load Byte Unsigned (LBU) instruction, loads byte mem - ory low- order 8 bits register fills high- order 24 bits register zeros. description LBU given MIPS reference manual using register- transfer language mem LoadMemory(…) byte VirtualAddress 1..0 CONDITION GPR[rt] 024}mem31 – 8 * byte .. 24 – 8 * byte else GPR[rt] 024}mem7 + 8 * byte .. 8 * byte endif byte refers two low- order bits effective address mem refers value loaded memory. manual, instead word CONDITION, one following two words used: BigEndian, LittleEndian. word used? 12.28 Most, all, processors use big- little- endian bit ordering within byte consistent big- little- endian ordering bytes within multibyte scalar. Let us consider Motorola 68030, uses big- endian byte ordering. documen - tation 68030 concerning formats confusing. user’s manual explains bit ordering bit fields opposite bit ordering integers. bit field operations operate one endian ordering, bit field operations require opposite ordering. following description user’s manual describes bit field operations: bit operand specified base address selects one byte memory (the base byte), bit number selects one bit byte. significant bit bit seven. bit field operand specified by: (1) base address selects one byte memory; (2) bit field offset indicates leftmost (base) bit bit field relation significant bit base byte; (3) bit field width determines many bits right base byte bit field. significant bit base byte bit field offset 0, least significant bit base byte bit field offset 7 . instructions use big- endian little- endian bit ordering?21 22 23 24 08 09 0A 0B25 26 27 28 0C 0D 0E 0F00 01 02 03 10 11 12 13 14 15 16 17 18 19 1A 1B 1C 1D 1E 1FLittle-endian addr ess mapping 11 12 13 14 04 05 06 07 61 62 63 64 24 25 26 2731 32 33 34 'D' 'C' 'B''A' 51 52 'F''E' 'G'Byte addr ess 00 08 10 18 20 20 21 22 23 Figure 12.12 Power Architecture Little- Endian Structures Memory452 cha Pter 12 / instruction sets: characteristics Functions APENDIX 12A LITTLE-, BIG-, BI- ENDIAN annoying curious phenomenon relates bytes within word bits within byte referenced represented. look first prob - lem byte ordering consider bits. Byte Ordering concept endianness first discussed literature Cohen [COHE81]. respect bytes, endianness byte ordering multibyte sca - lar values. issue best introduced example. Suppose 32-bit hexadecimal value 12345678 stored 32-bit word byte- addressable memory byte location 184. value consists 4 bytes, least significant byte containing value 78 significant byte containing value 12. two obvious ways store value: Address Value Address Value 184 12 184 78 185 34 185 56 186 56 186 34 187 78 187 12 mapping left stores significant byte lowest numerical byte address; known big endian equivalent left- to- right order writing Western culture languages. mapping right stores least significant byte lowest numerical byte address; known little endian reminiscent right- to- left order arithmetic operations arithmetic units.3 given multibyte scalar value, big endian little endian byte- reversed mappings other. concept endianness arises necessary treat multiple- byte entity single data item single address, even though composed smaller addressable units. machines, Intel 80x86, x86, VAX, Alpha, little- endian machines, whereas others, IBM System 370/390, Motorola 680x0, Sun SPARC, RISC machines, big endian. presents problems data transferred machine one endian type programmer attempts manipulate individual bytes bits within multibyte scalar. property endianness extend beyond individual data unit. machine, aggregates files, data structures, arrays composed multiple data units, endianness. Thus, conversion block memory one style endianness requires knowledge data structure. Figure 12.13 illustrates endianness determines addressing byte order. C structure top contains number data types. memory layout 3The terms big endian little endian come Part I, Chapter 4 Jonathan Swift’s Gulliver’s Travels . refer religious war two groups, one breaks eggs big end breaks eggs little end.aPendi X 12a / LittLe-, biG-, bi- endian 453 lower left results compilation structure big- endian machine, lower right little- endian machine. case, memory depicted series 64-bit rows. big- endian case, memory typically viewed left right, top bottom, whereas little- endian case, memory typically viewed right left, top bottom. Note layouts arbitrary. Either scheme could use either left right right left within row; matter depiction, mem - ory assignment. fact, looking programmer manuals variety machines, bewildering collection depictions found, even within manual. struct{ int a; //0x1112_1314 word int pad; // double b; //0x2122_2324_2526_2728 doubleword char* c; //0x3132_3334 word char d[7]; //'A','B','C','D','E','F','G' byte array short e; //0x5152 halfword int f; //0x6162_6364 word } s; make several observations data structure: ■Each data item address schemes. example, address doubleword hexadecimal value 2122232425262728 08. ■Within given multibyte scalar value, ordering bytes little- endian structure reverse big- endian structure.struct{ int a; //0x1112_1314 word int pad; // double b; //0x2122_2324_2526_2728 doubleword char* c; //0x3132_3334 word char d[7]; //'A','B','C','D','E','F','G' byte array short e; //0x5152 halfword int f; //0x6162_6364 word } s; 21 22 23 24 08 09 0A 0B25 26 27 28 0C 0D 0E 0F11 12 13 14 00 01 02 03 31 32 33 34 10 11 12 13'A' 'B' 'C' 'D' 14 15 16 17 'E' 'F' 'G' 18 19 1A 1B51 52 1C 1D 1E 1F 61 62 63 64 20 21 22 23Big-endian addr ess mapping 21 22 23 24 0F 0E 0D 0C25 26 27 28 0B 0A 09 0807 06 05 04 17 16 15 14 13 12 11 10 1F 1E 1D 1C 1B 1A 19 18Little-endian addr ess mapping 04 05 06 0711 12 13 14 03 02 01 00 61 62 63 64 23 22 21 2031 32 33 34 'D' 'C' 'B' 'A' 51 52 'F' 'E' 'G'Byte addr ess 00 08 10 18 20Byte addr ess 00 08 10 18 20 Figure 12.13 Example C Data Structure Endian Maps454 cha Pter 12 / instruction sets: characteristics Functions ■Endianness affect ordering data items within structure. Thus, four- character word c exhibits byte reversal, seven- character byte array not. Hence, address individual element structures. effect endianness perhaps clearly demonstrated view memory vertical array bytes, shown Figure 12.14. general consensus superior style endianness.4 following points favor big- endian style: ■ Character- string sorting: big- endian processor faster comparing integer- aligned character strings; integer ALU compare multiple bytes parallel. 11 12 13 14 21 22 23 24 25 26 27 28 31 32 33 34 'A' 'B' 'C' 'D' 'E' 'F' 'G' 51 52 61 62 63 6400 08 10 18 2004 0C 14 1C14 13 12 11 28 27 26 25 24 23 22 21 34 33 32 31 'A' 'B' 'C' 'D' 'E' 'F' 'G' 52 51 64 63 62 6100 08 10 18 2004 0C 14 1C (a) Bi g endian (b) Little endian Figure 12.14 Another View Figure 12.13 4The prophet revered groups Endian Wars Gulliver’s Travels say. “All true Believers shall break Eggs convenient End.” much help! ■Decimal/IRA dumps: values printed left right without causing confusion. ■Consistent order: Big- endian processors store integers character strings order (most significant byte comes first). following points favor little- endian style: ■A big- endian processor perform addition converts 32-bit inte - ger address 16-bit integer address, use least significant bytes. ■It easier perform higher- precision arithmetic little- endian style; don’t find least- significant byte move backward. differences minor choice endian style often matter accommodating previous machines anything else. PowerPC bi- endian processor supports big- endian little- endian modes. bi- endian architecture enables software developers choose either mode migrating operating systems applications machines. operating system establishes endian mode processes execute. mode selected, subsequent memory loads stores determined memory- addressing model mode. support hardware feature, 2 bits maintained machine state register (MSR) maintained operating system part process state. One bit specifies endian mode kernel runs; specifies processor’s current operating mode. Thus, mode changed per- process basis. Bit Ordering ordering bits within byte, immediately faced two questions: 1. count first bit bit zero bit one? 2. assign lowest bit number byte’s least significant bit (little endian) bytes significant bit (big endian)? questions answered way machines. Indeed, machines, answers different different circumstances. Furthermore, choice big- little- endian bit ordering within byte always consistent big- little- endian ordering bytes within multibyte scalar. program - mer needs concerned issues manipulating individual bits. Another area concern data transmitted bit- serial line. individual byte transmitted, system transmit significant bit first least significant bit first? designer must make certain incom - ing bits handled properly. discussion issue, see [JAME90].aPendi X 12a / LittLe-, biG-, bi- endian 455456 CHAPTER Instruct Ion sets: Address Ing Modes ForMAts 13.1 Addressing Modes Immediate Addressing Direct Addressing Indirect Addressing Register Addressing Register Indirect Addressing Displacement Addressing Stack Addressing 13.2 x86 ARM Addressing Modes x86 Addressing Modes ARM Addressing Modes 13.3 Instruction Formats Instruction Length Allocation Bits Variable- Length Instructions 13.4 x86 ARM Instruction Formats x86 Instruction Formats ARM Instruction Formats 13.5 Assembly Language 13.6 Key Terms, Review Questions, Problems 13.1 / Addressing Modes 457 Chapter 12, focused instruction set does. Specifically, examined types operands operations may specified machine instructions. chapter turns question specify operands operations instructions. Two issues arise. First, address operand specified, second, bits instruction organized define operand addresses operation instruction? 13.1 ADDRESSING MODES address field fields typical instruction format relatively small. would like able reference large range locations main memory or, systems, virtual memory. achieve objective, variety addressing tech - niques employed. involve trade- address range and/or addressing flexibility, one hand, number memory references instruction and/or complexity address calculation, other. section, examine common addressing techniques, modes: ■Immediate ■Direct ■Indirect ■Register ■Register indirect ■Displacement ■Stack modes illustrated Figure 13.1. section, use following notation: = contents address field instruction R = contents address field instruction refers register EA = actual (effective) address location containing referenced operand (X) = contents memory location X register XLearning Objectives studying chapter, able to: rDescribe various types addressing modes common instruction sets. rPresent overview x86 ARM addressing modes. rSummarize issues trade- offs involved designing instruction format . rPresent overview x86 ARM instruction formats. rUnderstand distinction machine language assembly language.458 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs Table 13.1 indicates address calculation performed addressing mode. beginning discussion, two comments need made. First, virtu - ally computer architectures provide one addressing modes. question arises processor determine address mode used particular instruction. Several approaches taken. Often, dif - ferent opcodes use different addressing modes. Also, one bits instruction format used mode field . value mode field deter - mines addressing mode used. second comment concerns interpretation effective address (EA). system without virtual memory, effective address either main memory address register. virtual memory system, effective address virtual address register. actual mapping physical address function memory management unit (MMU) invisible programmer.(b) DirectMemoryInstruction Operand (a) ImmediateInstruction Operand Registers (d) RegisterInstruction R R(c) IndirectMemoryInstruction Registers (f) DisplacementMemoryInstruction R Registers (e) Register indirectMemoryInstruction Top stack register (g) StackImplicitInstructionOperand Operand OperandOperand Figure 13.1 Addressing Modes13.1 / Addressing Modes 459 Immediate Addressing simplest form addressing immediate addressing , operand value present instruction Operand=A mode used define use constants set initial values variables. Typically, number stored twos complement form; leftmost bit operand field used sign bit. operand loaded data reg - ister, sign bit extended left full data word size. cases, immediate binary value interpreted unsigned nonnegative integer. advantage immediate addressing memory reference instruction fetch required obtain operand, thus saving one mem - ory cache cycle instruction cycle. disadvantage size number restricted size address field, which, instruction sets, small compared word length. Direct Addressing simple form addressing direct addressing, address field con - tains effective address operand: EA=A technique common earlier generations computers com - mon contemporary architectures. requires one memory reference special calculation. obvious limitation provides limited address space. Indirect Addressing direct addressing, length address field usually less word length, thus limiting address range. One solution address field refer address word memory, turn contains full- length address operand. known indirect addressing : EA=(A)Table 13.1 Basic Addressing Modes Mode Algorithm Principal Advantage Principal Disadvantage Immediate Operand=A memory reference Limited operand magnitude Direct EA=A Simple Limited address space Indirect EA=(A) Large address space Multiple memory references Register EA=R memory reference Limited address space Register indirect EA=(R) Large address space Extra memory reference Displacement EA=A+(R) Flexibility Complexity Stack EA=top stack memory reference Limited applicability460 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs defined earlier, parentheses interpreted meaning contents of. obvious advantage approach word length N, address space 2N available. disadvantage instruction execution requires two memory references fetch operand: one get address second get value. Although number words addressed equal 2N, number different effective addresses may referenced one time limited 2K, K length address field. Typically, bur - densome restriction, asset. virtual memory environment, effective address locations confined page 0 process. address field instruction small, naturally produce low- numbered dir - ect addresses, would appear page 0. (The restriction page size must greater equal 2K.) process active, repeated references page 0, causing remain real memory. Thus, indirect memory reference involve, most, one page fault rather two. rarely used variant indirect addressing multilevel cascaded indirect addressing: EA=(c(A)c) case, one bit full- word address indirect flag (I). bit 0, word contains EA. bit 1, another level indirection invoked. appear particular advantage approach, disadvantage three memory references could required fetch operand. Register Addressing Register addressing similar direct addressing. difference address field refers register rather main memory address: EA=R clarify, contents register address field instruction 5, register R5 intended address, operand value contained R5. Typ - ically, address field references registers 3 5 bits, total 8 32 general- purpose registers referenced. advantages register addressing (1) small address field needed instruction, (2) time- consuming memory references required. discussed Chapter 4, memory access time register internal processor much less main memory address. dis - advantage register addressing address space limited. register addressing heavily used instruction set, implies processor registers heavily used. severely limited number registers (compared main memory locations), use fashion makes sense employed efficiently. every operand brought regis - ter main memory, operated once, returned main memory, wasteful intermediate step added. If, instead, operand register remains use multiple operations, real savings achieved. example intermediate result calculation. particular, suppose algorithm 13.1 / Addressing Modes 461 twos complement multiplication implemented software. loca - tion labeled flowchart (Figure 10.12) referenced many times implemented register rather main memory location. programmer compiler decide values remain registers stored main memory. modern processors employ multiple general- purpose registers, placing burden efficient execution assembly- language programmer (e.g., compiler writer). Register Indirect Addressing register addressing analogous direct addressing, register indirect address - ing analogous indirect addressing. cases, difference whether address field refers memory location register. Thus, register indirect address, EA=(R) advantages limitations register indirect addressing basically indirect addressing. cases, address space limitation (limited range addresses) address field overcome field refer word- length location containing address. addition, register indirect addressing uses one less memory reference indirect addressing. Displacement Addressing powerful mode addressing combines capabilities direct addressing register indirect addressing. known variety names depending context use, basic mechanism same. refer displacement addressing : EA=A+(R) Displacement addressing requires instruction two address fields, least one explicit. value contained one address field (value=A) used directly. address field, implicit reference based opcode, refers register whose contents added produce effective address. describe three common uses displacement addressing: ■Relative addressing ■ Base- register addressing ■Indexing relative addressing relative addressing, also called PC- relative addressing, implicitly referenced register program counter (PC). is, next instruction address added address field produce EA. Typically, address field treated twos complement number operation. Thus, effective address displacement relative address instruction. Relative addressing exploits concept locality discussed Chap - ters 4 8. memory references relatively near instruction executed, use relative addressing saves address bits instruction.462 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs base- register addressing base- register addressing , interpretation following: referenced register contains main memory address, address field contains displacement (usually unsigned integer representation) address. register reference may explicit implicit. Base- register addressing also exploits locality memory references. convenient means implementing segmentation, discussed Chap - ter 8. implementations, single segment- base register employed used implicitly. others, programmer may choose register hold base address segment, instruction must reference explicitly. latter case, length address field K number possible registers N, one instruction reference one N areas 2K words. indexing indexing, interpretation typically following: address field references main memory address, referenced register contains positive displacement address. Note usage opposite interpretation base- register addressing. course, matter user interpretation. address field considered memory address indexing, generally contains bits address field comparable base- register instruction. Also, see refinements indexing would useful base- register context. Nevertheless, method calculating EA base- register addressing indexing, cases register reference sometimes explicit sometimes implicit (for different processor types). important use indexing provide efficient mechanism per - forming iterative operations. Consider, example, list numbers stored start - ing location A. Suppose would like add 1 element list. need fetch value, add 1 it, store back. sequence effective addresses need A, A+1, A+2, . . . , last location list. indexing, easily done. value stored instruction’s address field, chosen register, called index register , initialized 0. operation, index register incremented 1. index registers commonly used iterative tasks, typ - ical need increment decrement index register reference it. common operation, systems auto - matically part instruction cycle. known autoindex- ing. certain registers devoted exclusively indexing, autoindexing invoked implicitly automatically. general- purpose registers used, autoindex operation may need signaled bit instruction. Autoindex - ing using increment depicted follows. EA=A+(R) (R)d(R)+1 machines, indirect addressing indexing provided, possible employ instruction. two possibilities: indexing performed either indirection. indexing performed indirection, termed postindexing : EA=(A)+(R)13.2 / x86 nd ArM Addressing Modes 463 First, contents address field used access memory location contain - ing direct address. address indexed register value. tech - nique useful accessing one number blocks data fixed format. example, described Chapter 8 operating system needs employ process control block process. operations performed regardless block manipulated. Thus, addresses instruc - tions reference block could point location (value=A) containing variable pointer start process control block. index register contains displacement within block. preindexing , indexing performed indirection: EA=(A+(R)) address calculated simple indexing. case, however, calcu - lated address contains operand, address operand. example use technique construct multiway branch table. particular point program, may branch one number locations depend - ing conditions. table addresses set starting location A. indexing table, required location found. Typically, instruction set include preindexing postindexing. Stack Addressing final addressing mode consider stack addressing. defined Appendix I, stack linear array locations. sometimes referred pushdown list last- in- first- queue. stack reserved block locations. Items appended top stack that, given time, block par - tially filled. Associated stack pointer whose value address top stack. Alternatively, top two elements stack may processor registers, case stack pointer references third element stack. stack pointer maintained register. Thus, references stack locations memory fact register indirect addresses. stack mode addressing form implied addressing. machine instructions need include memory reference implicitly operate top stack. 13.2 x86 ARM ADDRESSING MODES x86 Addressing Modes Recall Figure 8.21 x86 address translation mechanism produces address, called virtual effective address, offset segment. sum starting address segment effective address produces linear address. paging used, linear address must pass page- translation mechanism produce physical address. follows, ignore last step transparent instruction set programmer. x86 equipped variety addressing modes intended allow efficient execution high- level languages. Figure 13.2 indicates logic 464 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs involved. segment register determines segment subject reference. six segment registers; one used particular refer - ence depends context execution instruction. segment regis - ter holds index segment descriptor table (Figure 8.20), holds starting address corresponding segments. Associated user- visible segment register segment descriptor register (not programmer visible), records access rights segment well starting address limit (length) segment. addition, two registers may used constructing address: base register index register. Table 13.2 lists x86 addressing modes. Let us consider turn. immediate mode , operand included instruction. oper - byte, word, doubleword data. register operand mode , operand located register. general instructions, data transfer, arithmetic, logical instructions, operand one 32-bit general registers (EAX, EBX, ECX, EDX, ESI, EDI, ESP, EBP), one 16-bit general registers (AX, BX, CX, DX, SI, DI, SP, BP), one 8-bit general registers (AH, BH, CH, DH, AL, BL, CL, DL). also instructions reference segment selector registers (CS, DS, ES, SS, FS, GS).Access rights Limit Base AddressSS Access rights Limit Base AddressGS Access rights Limit Base AddressFS Access rights Limit Base AddressES Access rights Limit Base AddressDS Access rights Limit Base AddressCSSelector Selector Selector Selector Selector SelectorSS GS FS ES DS CSSegment registers Descriptor registersBase register Index register Scale 1, 2, 4, 8 Displacement (in instruction; 0, 8, 32 bits) Limit× + +Effective addressLinear addressSegment base address Figure 13.2 x86 Addressing Mode Calculation13.2 / x86 nd ArM Addressing Modes 465 remaining addressing modes reference locations memory. mem - ory location must specified terms segment containing location offset beginning segment. cases, segment specified explicitly; others, segment specified simple rules assign segment default. displacement mode , operand’s offset (the effective address Figure 13.2) contained part instruction 8-, 16-, 32-bit displace - ment. segmentation, addresses instructions refer merely offset segment. displacement addressing mode found machines because, mentioned earlier, leads long instructions. case x86, displace - ment value long 32 bits, making 6-byte instruction. Displacement addressing useful referencing global variables. remaining addressing modes indirect, sense address portion instruction tells processor look find address. base mode specifies one 8-, 16-, 32-bit registers contains effective address. equivalent referred register indirect addressing. base displacement mode , instruction includes displacement added base register, may general- purpose registers. Examples uses mode follows: ■Used compiler point start local variable area. example, base register could point beginning stack frame, contains local variables corresponding procedure. ■Used index array element size 1, 2, 4, 8 bytes therefore cannot indexed using index register. case, displacement points beginning array, base register holds results calculation determine offset specific element within array.Table 13.2 x86 Addressing Modes Mode Algorithm Immediate Operand=A Register Operand LA=R Displacement LA=(SR)+A Base LA=(SR)+(B) Base Displacement LA=(SR)+(B)+A Scaled Index Displacement LA=(SR)+(I)*S+A Base Index Displacement LA=(SR)+(B)+(I)+A Base Scaled Index Displacement LA=(SR)+(I)*S+(B)+A Relative LA=(PC)+A LA=linear address (X)=contents X SR=segment register PC=program counter A=contents address field instructionR=register B=base register I=index register S=scaling factor466 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs ■Used access field record. base register points beginning record, displacement offset field. scaled index displacement mode , instruction includes dis - placement added register, case called index register. index register may general- purpose registers except one called ESP, generally used stack processing. calculating effective address, contents index register multiplied scaling factor 1, 2, 4, 8, added displacement. mode convenient indexing arrays. scaling factor 2 used array 16-bit integers. scaling factor 4 used 32-bit integers floating- point numbers. Finally, scaling factor 8 used array double- precision floating- point numbers. base index displacement mode sums contents base register, index register, displacement form effective address. Again, base register general- purpose register index register general- purpose register except ESP. example, addressing mode could used accessing local array stack frame. mode also used support two- dimensional array; case, displacement points beginning array, register handles one dimension array. based scaled index displacement mode sums contents index register multiplied scaling factor, contents base register, displace - ment. useful array stored stack frame; case, array elements would 2, 4, 8 bytes length. mode also provides efficient indexing two- dimensional array array elements 2, 4, 8 bytes length. Finally, relative addressing used transfer- of- control instructions. displacement added value program counter, points next instruction. case, displacement treated signed byte, word, dou - bleword value, value either increases decreases address pro - gram counter. ARM Addressing Modes Typically, RISC machine, unlike CISC machine, uses simple relatively straightforward set addressing modes. ARM architecture departs somewhat tradition providing relatively rich set addressing modes. modes conveniently classified respect type instruction.1 load /store addressing Load store instructions instructions reference memory. always done indirectly base register plus offset. three alternatives respect indexing (Figure 13.3): ■Offset: addressing method, indexing used. offset value added subtracted value base register form memory address. example Figure 13.3a illustrates method assembly language instruction STRB r0, [r1, #12] . store byte instruction. 1As discussion x86 addressing, ignore translation virtual physical address following discussion.13.2 / x86 nd ArM Addressing Modes 467 0x200 0x2000x20C 0x20C 0xCr1 r1 Original base r egister (b) Preind ex (c) Postinde xDestinatio n register STRUpdated base r egister 0x50x5r0OffsetSTRB r0, [r1, #12]! 0x200 0x2000x20C 0x20C 0xCr1 r1 Original base r egisterDestinatio n register STRUpdated base r egister 0x5 0x5r0OffsetSTRB r0, [r1], #120x200 0x2000x20C 0xC r1 Original base r egister (a) fsetDestinatio n register STR0x50x5r0OffsetSTRB r0, [r1, #12] Figure 13.3 ARM Indexing Methods case base address register r1 displacement imme - diate value decimal 12. resulting address (base plus offset) loca - tion least significant byte r0 stored. ■Preindex: memory address formed way offset address - ing. memory address also written back base register. words, base register value incremented decremented offset value. Figure 13.3b illustrates method assembly language instruc - tion STRB r0, [r1, #12]! . exclamation point signifies preindexing.468 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs ■Postindex: memory address base register value. offset added subtracted base register value result written back base register. Figure 13.3c illustrates method assembly lan - guage instruction STRB r0, [r1], #12 . Note ARM refers base register acts index register preindex postindex addressing. offset value either immediate value stored instruction another register. offset value register, another useful feature available: scaled register addressing. value offset register scaled one shift operators: Logical Shift Left, Log - ical Shift Right, Arithmetic Shift Right, Rotate Right, Rotate Right Extended (which includes carry bit rotation). amount shift specified immediate value instruction. data processing instruction addressing Data processing instructions use either register addressing mixture register immediate addressing. register addressing, value one register operands may scaled using one five shift operators defined preceding paragraph. branch instructions form addressing branch instructions immediate addressing. branch instruction contains 24-bit value. address calculation, value shifted left 2 bits, address word boundary. Thus effective address range {32 MB program counter. load /store multiple addressing Load Multiple instructions load subset (possibly all) general- purpose registers memory. Store Multiple instructions store subset (possibly all) general- purpose registers memory. list registers load store specified 16-bit field instruction bit corresponding one 16 registers. Load Store Multiple addressing modes produce sequential range memory addresses. lowest- numbered register stored lowest memory address highest- numbered register highest memory address. Four addressing modes used (Figure 13.4): increment after, increment before, decrement after, decrement before. base 0x20C 0x2100x214 0x20C (r0)(r1)(r4) (r0)(r1)(r4) (r0)(r1)(r4) (r0)(r1)(r4)0x208 0x204 0x2000x218r10 Base r egisterIncrement (IA)Increment (IB)Decr ement (D A)Decr ement (DB)LDMxx r10, {r0, r1, r4} STMxx r10, {r0, r1, r4} Figure 13.4 ARM Load/Store Multiple Addressing13.3 / insTruCTion MATs 469 register specifies main memory address register values stored loaded ascending (increment) descending (decrement) word locations. Incrementing decrementing starts either first memory access. instructions useful block loads stores, stack operations, procedure exit sequences. 13.3 INSTRUCTION FORMATS instruction format defines layout bits instruction, terms constituent fields. instruction format must include opcode and, implicitly explicitly, zero operands. explicit operand referenced using one addressing modes described Section 13.1. format must, implicitly explicitly, indicate addressing mode operand. instruction sets, one instruction format used. design instruction format complex art, amazing variety designs implemented. examine key design issues, looking briefly designs illustrate points, examine x86 ARM solu - tions detail. Instruction Length basic design issue faced instruction format length. decision affects, affected by, memory size, memory organization, bus structure, pro - cessor complexity, processor speed. decision determines richness flexibility machine seen assembly- language programmer. obvious trade- desire powerful instruc - tion repertoire need save space. Programmers want opcodes, operands, addressing modes, greater address range. opcodes operands make life easier programmer, shorter programs written accomplish given tasks. Similarly, addressing modes give pro - grammer greater flexibility implementing certain functions, table manip - ulations multiple- way branching. And, course, increase main memory size increasing use virtual memory, programmers want able address larger memory ranges. things (opcodes, operands, addressing modes, address range) require bits push direction longer instruction lengths. longer instruction length may wasteful. 64-bit instruction occupies twice space 32-bit instruction probably less twice useful. Beyond basic trade- off, considerations. Either instruc - tion length equal memory- transfer length (in bus system, data - bus length) one multiple other. Otherwise, get integral number instructions fetch cycle. related consideration memory transfer rate. rate kept increases processor speed. Accordingly, memory become bottleneck processor execute instructions faster fetch them. One solution problem use cache memory (see Section 4.3); another use shorter instructions. Thus, 16-bit instructions fetched twice rate 32-bit instructions probably executed less twice rapidly.470 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs seemingly mundane nevertheless important feature instruc - tion length multiple character length, usually 8 bits, length fixed- point numbers. see this, need make use unfor - tunately ill- defined word, word [FRAI83]. word length memory is, sense, “natural” unit organization. size word usually determines size fixed- point numbers (usually two equal). Word size also typ - ically equal to, least integrally related to, memory transfer size. common form data character data, would like word store inte - gral number characters. Otherwise, wasted bits word storing multiple characters, character straddle word boundary. importance point IBM, introduced System/360 wanted employ 8-bit characters, made wrenching decision move 36-bit architecture scientific members 700/7000 series 32-bit architecture. Allocation Bits We’ve looked factors go deciding length instruc - tion format. equally difficult issue allocate bits format. trade- offs complex. given instruction length, clearly trade- number opcodes power addressing capability. opcodes obviously mean bits opcode field. instruction format given length, reduces number bits available addressing. one interesting refinement trade- off, use variable- length opcodes. approach, minimum opcode length but, opcodes, additional operations may specified using additional bits instruction. fixed - length instruction, leaves fewer bits addressing. Thus, feature used instructions require fewer operands and/or less powerful addressing. following interrelated factors go determining use address - ing bits. ■Number addressing modes: Sometimes addressing mode indi - cated implicitly. example, certain opcodes might always call indexing. cases, addressing modes must explicit, one mode bits needed. ■Number operands: seen fewer addresses make longer, awkward programs (e.g., Figure 12.3). Typical instruction formats today’s machines include two operands. operand address instruc - tion might require mode indicator, use mode indicator could limited one address fields. ■Register versus memory: machine must registers data brought processor processing. single user- visible register (usually called accumulator), one operand address implicit con - sumes instruction bits. However, single- register programming awkward requires many instructions. Even multiple registers, bits needed specify register. registers used 13.3 / insTruCTion MATs 471 operand references, fewer bits needed. number studies indicate total 8 32 user- visible registers desirable [LUND77, HUCK83]. contemporary architectures least 32 registers. ■Number register sets: contemporary machines one set general- purpose registers, typically 32 registers set. registers used store data used store addresses displacement addressing. architectures, including x86, collection two specialized sets (such data displacement). One advantage latter approach that, fixed number registers, functional split requires fewer bits used instruction. example, two sets eight registers, 3 bits required identify register; opcode mode register determine set registers referenced. ■Address range: addresses reference memory, range addresses referenced related number address bits. imposes severe limitation, direct addressing rarely used. displacement addressing, range opened length address register. Even so, still convenient allow rather large displacements register address, requires relatively large number address bits instruction. ■Address granularity: addresses reference memory rather registers, another factor granularity addressing. system 16- 32-bit words, address reference word byte designer’s choice. Byte addressing convenient character manipulation requires, fixed- size memory, address bits. Thus, designer faced host factors consider balance. critical various choices clear. example, cite one study [CRAG79] compared various instruction format approaches, including use stack, general- purpose registers, accumulator, memory- to- register approaches. Using consistent set assumptions, significant difference code space execution time observed. Let us briefly look two historical machine designs balance vari - ous factors. pdp-8 One simplest instruction designs general- purpose computer PDP- 8 [BELL78b]. PDP- 8 uses 12-bit instructions operates 12-bit words. single general- purpose register, accumulator. Despite limitations design, addressing quite flexible. memory reference consists 7 bits plus two 1-bit modifiers. memory divided fixed- length pages 27=128 words each. Address calculation based references page 0 current page (page containing instruction) deter - mined page bit. second modifier bit indicates whether direct indirect addressing used. two modes used combination, indirect address 12-bit address contained word page 0 current page. addition, 8 dedicated words page 0 autoindex “registers.” indirect reference made one locations, preindexing occurs. Figure 13.5 shows PDP- 8 instruction format. 3-bit opcode three types instructions. opcodes 0 5, format single- address 472 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs memory reference instruction including page bit indirect bit. Thus, six basic operations. enlarge group operations, opcode 7 defines register reference microinstruction. format, remaining bits used encode additional operations. general, bit defines specific operation (e.g., clear accumulator), bits combined single instruction. microinstruction strategy used far back PDP- 1 DEC is, sense, forerunner today’s microprogrammed machines, discussed Part Four. Opcode 6 I/O operation; 6 bits used select one 64 devices, 3 bits specify particular I/O command. PDP- 8 instruction format remarkably efficient. supports indirect addressing, displacement addressing, indexing. use opcode extension, supports total approximately 35 instructions. Given constraints 12-bit instruction length, designers could hardly done better. PDP- 10 sharp contrast instruction set PDP- 8 PDP- 10. PDP- 10 designed large- scale time- shared system, emphasis making system easy program, even additional hardware expense involved. Among design principles employed designing instruction set following [BELL78c]: ■Orthogonality: Orthogonality principle two variables inde - pendent other. context instruction set, term indicates Memory reference instruction Opcod eD /I Z/CD isplacement 02 34 51 1 Input/output instruction 11 0 Device Opcode 02 38 91 1 Register reference instructions Group 1 microinstruction 11 10 CLA CLL CMA CML RAR RAL BSWI AC 01 23 Group 2 microinstruction 11 10 01 23 Group 3 microinstruction 11 10 01 2345678 91 01 1 CLA SMA SZA SNL RSS OSR HLT 0 45678 91 01 1 CLA MQA 0 MQL 0001 45678 91 01 1 D/I = Direct/Indirect address Z/C = Page 0 Current page CLA = Clear Accumulator CLL = Clear Link CMA = CoMplement Accumulator CML = CoMplement Link RAR = Rotate Accumulator Right RAL = Rotate Accumulator Left BSW = Byte SWapIAC = Increment ACcumulator SMA = Skip Minus Accumulator SZA = Skip Zero Accumulator SNL = Skip Nonzero Link RSS = Reverse Skip Sense OSR = Switch Register HLT = HaLT MQA= Multiplier Quotient Accumulator MQL = Multiplier Quotient Load Figure 13.5 PDP- 8 Instruction Formats13.3 / insTruCTion MATs 473 elements instruction independent (not determined by) opcode. PDP- 10 designers use term describe fact address always computed way, independent opcode. contrast many machines, address mode sometimes depends implicitly operator used. ■Completeness: arithmetic data type (integer, fixed- point, floating- point) complete identical set operations. ■Direct addressing: Base plus displacement addressing, places mem - ory organization burden programmer, avoided favor direct addressing. principles advances main goal ease programming. PDP- 10 36-bit word length 36-bit instruction length. fixed instruction format shown Figure 13.6. opcode occupies 9 bits, allow - ing 512 operations. fact, total 365 different instructions defined. instructions two addresses, one one 16 general- purpose registers. Thus, operand reference occupies 4 bits. operand refer - ence starts 18-bit memory address field. used immedi - ate operand memory address. latter usage, indexing indirect addressing allowed. general- purpose registers also used index registers. 36-bit instruction length true luxury. need clever things get opcodes; 9-bit opcode field adequate. Addressing also straightforward. 18-bit address field makes direct addressing desirable. memory sizes greater 218, indirection provided. ease program - mer, indexing provided table manipulation iterative programs. Also, 18-bit operand field, immediate addressing becomes attractive. PDP- 10 instruction set design accomplish objectives listed ear - lier [LUND77]. eases task programmer compiler expense inefficient utilization space. conscious choice made designers therefore cannot faulted poor design. Variable- Length Instructions examples looked far used single fixed instruction length, implicitly discussed trade- offs context. designer may choose instead provide variety instruction formats different lengths. tactic makes easy provide large repertoire opcodes, different opcode lengths. Addressing flexible, various combinations register memory references plus addressing modes. variable- length instructions, many variations provided efficiently compactly. Index registerMemory addr ess 08 91 21 41 7183 5 = indir ect bitOpcode Register Figure 13.6 PDP- 10 Instruction Format474 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs principal price pay variable- length instructions increase complexity processor. Falling hardware prices, use microprogramming (discussed Part Four), general increase understanding principles processor design contributed making small price pay. However, see RISC superscalar machines exploit use fixed- length instructions provide improved performance. use variable- length instructions remove desirability making instruction lengths integrally related word length. processor know length next instruction fetched, typical strategy fetch number bytes words equal least longest possible instruction. means sometimes multiple instructions fetched. However, shall see Chapter 14, good strategy follow case. PDP- 11 PDP- 11 designed provide powerful flexible instruction set within constraints 16-bit minicomputer [BELL70]. PDP- 11 employs set eight 16-bit general- purpose registers. Two registers additional significance: one used stack pointer special- purpose stack operations, one used program counter, contains address next instruction. Figure 13.7 shows PDP- 11 instruction formats. Thirteen different formats used, encompassing zero-, one-, two- address instruction types. opcode vary 4 16 bits length. Register references 6 bits length. Three bits identify register, remaining 3 bits identify addressing mode. PDP- 11 endowed rich set addressing modes. One advantage linking addressing mode operand rather opcode, sometimes done, addressing mode used opcode. mentioned, independence referred orthogonality. PDP- 11 instructions usually one word (16 bits) long. instruc - tions, one two memory addresses appended, 32-bit 48-bit instruc - tions part repertoire. provides flexibility addressing. PDP- 11 instruction set addressing capability complex. increases hardware cost programming complexity. advantage efficient compact programs developed. vax architectures provide relatively small number fixed instruction formats. cause two problems programmer. First, addressing mode opcode orthogonal. example, given operation, one operand must come register another memory, registers, on. Second, limited number operands accommodated: typically two three. operations inherently require operands, various strategies must used achieve desired result using two instructions. avoid problems, two criteria used designing VAX instruc - tion format [STRE78]: 1. instructions “natural” number operands. 2. operands generality specification.13.3 / insTruCTion MATs 475 result highly variable instruction format. instruction consists 1- 2-byte opcode followed zero six operand specifiers, depending opcode. minimal instruction length 1 byte, instructions 37 bytes constructed. Figure 13.8 gives examples. VAX instruction begins 1-byte opcode. suffices handle VAX instructions. However, 300 different instructions, 8 bits enough. hexadecimal codes FD FF indicate extended opcode, actual opcode specified second byte. remainder instruction consists six operand specifiers. operand specifier is, minimum, 1-byte format leftmost 4 bits address mode specifier. exception rule literal mode, Opcode Opcode Offet 12 3 45 6 7 10 11 12 13 Numbers /f_ields indicate bit length. Sour ce destination contain 3-bit addr essing mode /f_ield 3-bit r egister number. FP indicates one four /f_loating-point r egisters. R indicates one general-purpose r egisters. CC condition code /f_ield.8 9R Sour ce Source Destination Opcode 4 Opcode 8Opcode 10Opcode 12CC 4FP 2Destination 6Destination 6 Opcode 13Opcode 16 Opcode 4Sour ce 6Destination 6Memory Addr ess 16R 3 Opcode 7Source 6 Sour ce 6 Destination 6 Destination 6Memory Addr ess 16 Memory Addr ess 16 Memory Addr ess 16 Memory Addr ess 1 16Memory Addr ess 2 16R 3 Opcode 8FP 2 Opcode 10 Opcode 4Sour ce 678 8 3 66 6 Figure 13.7 Instruction Formats PDP- 11476 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs signaled pattern 00 leftmost 2 bits, leaving space 6-bit literal. exception, total 12 different addressing modes specified. operand specifier often consists one byte, rightmost 4 bits specifying one 16 general- purpose registers. length operand specifier extended one two ways. First, constant value one bytes may immediately follow first byte operand specifier. example displacement mode, 8-, 16-, 32-bit displacement used. Second, index mode addressing may used. case, first byte operand specifier consists 4-bit addressing mode code 0100 4-bit index regis - ter identifier. remainder operand specifier consists base address specifier, may one bytes length. reader may wondering, author did, kind instruction requires six operands. Surprisingly, VAX number instructions. Consider ADDP6 OP1, OP2, OP3, OP4, OP5, OP6Opcode RSBHexadecimal FormatAssembler Notation Description Explanation 08 bits 5 4 5 9 B 0 C 4 6 4 0 1 B 1 9 C 1 0 5 5 0 4 2 FRSB Return subroutine Opcode CLRL Register R9CLRL R9 Clear gister R9 Opcode MO VW Word displacement mode, Register R4 Byte displacement mode, Register R11 25 xadecimal356 xadecimalMOVW 356(R4), 25(R11) Move word address 356 plus contents R4 address 25 plus contents R11 Opcode ADDL3 Short literal 5 Register mode R0 Index pre/f_ix R2 Indirect word relati (displacement PC)ADDL3 #5, R0, @A[R2] Add 5 32-bit inte ger R0 store result location whose address sum 4 times contents R2 Amount displacement PC relati location Figure 13.8 Example VAX Instructions13.4 / x86 nd ArM insTruCTion ForMATs 477 instruction adds two packed decimal numbers. OP1 OP2 specify length starting address one decimal string; OP3 OP4 specify second string. two strings added result stored decimal string whose length starting location specified OP5 OP6. VAX instruction set provides wide variety operations address - ing modes. gives programmer, compiler writer, powerful flexible tool developing programs. theory, lead efficient machine- language compilations high- level language programs and, general, effective efficient use processor resources. penalty paid benefits increased complexity processor compared processor simpler instruction set format. return matters Chapter 15, examine case simple instruction sets. 13.4 x86 ARM INSTRUCTION FORMATS x86 Instruction Formats x86 equipped variety instruction formats. elements described subsection, opcode field always present. Figure 13.9 illustrates general instruction format. Instructions made zero four optional instruction prefixes, 1 - 2-byte opcode, optional address specifier (which con - sists ModR/M byte Scale Index Base byte) optional displacement, optional immediate field. Mod0, 1, 2, 3, 4 bytes 0, 1, 2, 4 bytes 0, 1, 2, 4 bytes 1, 2, 3 bytes0 1 byte0 1 byte0 1 byte0 1 byte0 1 byte 0 1 byte Instruction pr e/f_ixes Opcode 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7ModR/M SIB Displacement ImmediateInstruction pre/f_ixSegment overrideOperand size overrideAddr ess size override Reg/Opcode R/M Scale Index Base Figure 13.9 x86 Instruction Format478 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs Let us first consider prefix bytes: ■Instruction prefixes: instruction prefix, present, consists LOCK prefix one repeat prefixes. LOCK prefix used ensure exclu - sive use shared memory multiprocessor environments. repeat prefixes specify repeated operation string, enables x86 process strings much faster regular software loop. five different repeat prefixes: REP , REPE, REPZ, REPNE, REPNZ. absolute REP prefix present, operation specified instruction executed repeat - edly successive elements string; number repetitions specified register CX. conditional REP prefix causes instruction repeat count CX goes zero condition met. ■Segment override: Explicitly specifies segment register instruction use, overriding default segment- register selection generated x86 instruction. ■Operand size: instruction default operand size 16 32 bits, operand prefix switches 32-bit 16-bit operands. ■Address size: processor address memory using either 16- 32-bit addresses. address size determines displacement size instructions size address offsets generated effective address calculation. One sizes designated default, address size prefix switches 32-bit 16-bit address generation. instruction includes following fields: ■Opcode: opcode field 1, 2, 3 bytes length. opcode may also include bits specify data byte- full- size (16 32 bits depending context), direction data operation (to memory), whether immediate data field must sign extended. ■ModR/M: byte, next, provide addressing information. ModR/M byte specifies whether operand register memory; memory, fields within byte specify addressing mode used. ModR/M byte consists three fields: Mod field (2 bits) combines R/M field form 32 possible values: 8 registers 24 indexing modes; Reg/Opcode field (3 bits) specifies either register num - ber three bits opcode information; R/M field (3 bits) specify register location operand, form part addressing- mode encoding combination Mod field. ■SIB: Certain encoding ModR/M byte specifies inclusion SIB byte specify fully addressing mode. SIB byte consists three fields: Scale field (2 bits) specifies scale factor scaled indexing; Index field (3 bits) specifies index register; Base field (3 bits) specifies base register. ■Displacement: addressing- mode specifier indicates displace - ment used, 8-, 16-, 32-bit signed integer displacement field added. ■Immediate: Provides value 8-, 16-, 32-bit operand. Several comparisons may useful here. x86 format, addressing mode provided part opcode sequence rather operand. 13.4 / x86 nd ArM insTruCTion ForMATs 479 one operand address- mode information, one mem - ory operand referenced instruction. contrast, VAX carries address- mode information operand, allowing memory- to- memory operations. x86 instructions therefore compact. However, memory- to- memory operation required, VAX accomplish single instruction. x86 format allows use 1-byte, also 2-byte 4-byte offsets indexing. Although use larger index offsets results longer instructions, feature provides needed flexibility. example, useful addressing large arrays large stack frames. contrast, IBM S/370 instruc - tion format allows offsets greater 4 Kbytes (12 bits offset information), offset must positive. location reach offset, compiler must generate extra code generate needed address. problem especially apparent dealing stack frames local variables occupying excess 4 Kbytes. [DEWA90] puts it, “generating code 370 pain - ful result restriction even compilers 370 simply chose limit size stack frame 4 Kbytes.” seen, encoding x86 instruction set complex. partly need backward compatible 8086 machine partly desire part designers provide every possible assistance compiler writer producing efficient code. matter debate whether instruction set complex preferable opposite extreme RISC instruction sets. ARM Instruction Formats instructions ARM architecture 32 bits long follow regular format (Figure 13.10). first four bits instruction condition code. dis - cussed Chapter 12, virtually ARM instructions conditionally executed. next three bits specify general type instruction. instructions branch instructions, next five bits constitute opcode and/or modi - fier bits operation. remaining 20 bits operand addressing. reg - ular structure instruction formats eases job instruction decode units. immediate constants achieve greater range immediate values, data processing immediate format specifies immediate value rotate value. 8-bit immediate value expanded 32 bits rotated right number bits equal twice 4-bit rotate value. Several examples shown Figure 13.11. thumb instruction set Thumb instruction set re- encoded subset ARM instruction set. Thumb designed increase performance ARM implementations use 16-bit narrower memory data bus allow better code density provided ARM instruction 16-bit 32-bit processors. Thumb instruction set created analyzing 32-bit ARM instruction set deriving best fit 16-bit instruction set, thus reducing code size. savings achieved following way: 1. Thumb instructions unconditional, condition code field used. Also, Thumb arithmetic logic instructions update condition flags, update- flag bit needed. Savings: 5 bits.480 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs 2. Thumb subset operations full instruction set uses 2-bit opcode field, plus 3-bit type field. Savings: 2 bits. 3. remaining savings 9 bits comes reductions operand specifi - cations. example, Thumb instructions reference registers r0 r7, 3 bits required register references, rather 4 bits. Imme - diate values include 4-bit rotate field.00 0 SR nR Rd shift amoun tshift 0 shift amoun tshift0 cond opcodeData processing immediate shift 01 SR n Rd rotate immediat e 0 cond opcodeData processing immediate 10 LWBUPR nR immediat e 0 condLoad/store immediate fset 11 LWBUPR nR 0 condLoad/store register fset00 1 0 SR nR Rm register list 00 LWSUPR n 1 condLoad/store multiple 24-bit offset 01 L 1 condBranch/branch link = data processing instructions, signi/f_ies instruction updates condition codes = load/store multiple instructions, signi/f_ies whether instruction execution restricted supervisor mode P, U, W = bits distinguish among different types addressing mode B = Distinguishes unsigned b yte (B==1) word (B==0) access L = load/store instructions, distinguishes Load (L==1) Store (L==0) L = branch instructions, determines whether return address stored link register Rd Rs shift 0 cond opcodeData processing register shift0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 Figure 13.10 ARM Instruction Formats 000000000000000000 0 00000 ror #0—range 0 thr ough 0x000000FF—step 0x00000001 0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 000000000000000000000000 ror #8—range 0 thr ough 0xFF000000—step 0x01000000 0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 0000000000000000 00 0 00000 ror #30—range 0 thr ough 0x000003FC—step 0x00000004 0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 Figure 13.11 Examples Use ARM Immediate Constants13.4 / x86 nd ArM insTruCTion ForMATs 481 ARM processor execute program consisting mixture Thumb instructions 32-bit ARM instructions. bit processor control register determines type instruction currently executed. Figure 13.12 shows example. figure shows general format specific instance instruction 16-bit 32-bit formats. thumb - 2 instruction set introduction Thumb instruction set, user required blend instruction sets compiling performance critical code ARM rest Thumb. manual code blending requires additional effort difficult achieve optimal results. overcome problems, ARM developed Thumb- 2 instruction set, instruction set available Cortex- microcontroller products. Thumb- 2 major enhancement Thumb instruction set architecture (ISA). introduces 32-bit instructions intermixed freely older 16-bit Thumb instructions. new 32-bit instructions cover almost functionality ARM instruction set. important difference Thumb ISA ARM ISA 32-bit Thumb instructions unconditional, whereas almost ARM instructions conditional. However, Thumb- 2 introduces new If- (IT) instruction delivers much functionality condition field ARM instructions. Thumb- 2 delivers overall code density comparable Thumb, together performance levels associated ARM ISA. Thumb- 2, developers choose Thumb size ARM performance. [ROBI07] reports analysis Thumb- 2 instruction set compared ARM original Thumb instruction sets. analysis involved compiling executing Embedded Microprocessor Benchmark Consortium (EEMBC) benchmark suite using three instruction sets, following results: ■With compilers optimized performance, Thumb- 2 size 26% smaller ARM, slightly larger original Thumb. ■With compilers optimized space, Thumb- 2 size 32% smaller ARM, slightly smaller original Thumb. 01 10 0 00 1 00 01 01 1 01 1110 0000 01 00 01 1ADD r3, #19 ADDS r3, r3, #19 Data processing immediate format 0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31011001 1 00 01 0 01 1 0Add/subract/compare/move immediate format Always condition codeMajor opcode denoting format 3 move/compare/add/sub immediate valueMinor opcode denoting ADD instruction Destination source registerImmediate value Update condition /f_lagsZero rotation01 Rd/Rnop codeimmediat e 00123456789101112 1413 15 01 SR n Rd rotate immediat e 0 cond opcode Figure 13.12 Expanding Thumb ADD Instruction ARM Equivalent482 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs ■With compilers optimized performance, Thumb- 2 performance benchmark suite 98% ARM performance 125% original Thumb performance. results confirm Thumb- 2 meets design objectives. Figure 13.13 shows new 32-bit Thumb instructions encoded. encoding compatible existing Thumb unconditional branch instructions, bit pattern 11100 five leftmost bits instruction. 16-bit instruction begins pattern 111 three leftmost bits, bit patterns 11101, 11110, 11111 indicate 32-bit Thumb instruction. 13.5 ASSEMBLY LANGUAGE processor understand execute machine instructions. instructions simply binary numbers stored computer. programmer wished program directly machine language, would necessary enter program binary data. Consider simple BASIC statement N=I+J+K Suppose wished program statement machine language initialize I, J, K 2, 3, 4, respectively. shown Figure 13.14a. program starts location 101 (hexadecimal). Memory reserved four variables start - ing location 201. program consists four instructions: 1. Load contents location 201 AC. 2. Add contents location 202 AC. 3. Add contents location 203 AC. 4. Store contents AC location 204. clearly tedious error- prone process. slight improvement write program hexadecimal rather bin - ary notation (Figure 13.14b). could write program series lines. thm hw1 hw2 thm thm hw1 hw2i+2 i+6 i+4 i+8 i+10 Instruction /f_low Halfword1 [15:13] Halfword1 [12:11] Length Functionality 111 xx 16 bits (1 halfword) 16-bit Thumb instruction 111 00 16 bits (1 halfword) 16-bit Thumb unconditional branch instruction 111 00 32 bits (2 halfwords) 32-bit Thumb-2 instruction Figure 13.13 Thumb- 2 Encoding13.5 / Asse Mbly lAnguAge 483 line contains address memory location hexadecimal code bin - ary value stored location. need program accept input, translate line binary number, store specified location. improvement, make use symbolic name mnemonic instruction. results symbolic program shown Figure 13.14c. line input still represents one memory location. line consists three fields, separated spaces. first field contains address location. instruction, second field contains three- letter symbol opcode. memory- referencing instruction, third field contains address. store arbitrary data location, invent pseudoinstruction sym - bol DAT. merely indication third field line contains hexadecimal number stored location specified first field. type input need slightly complex program. program accepts line input, generates binary number based second third (if present) fields, stores location specified first field. use symbolic program makes life much easier still awkward. particular, must give absolute address word. means program data loaded one place memory, must know place ahead time. Worse, suppose wish change program day adding deleting line. change addresses subsequent words. much better system, one commonly used, use symbolic addresses. illustrated Figure 13.14d. line still consists three fields. first field still address, symbol used instead absolute numerical address. lines address, implying address line one Address Contents 101 0010 0010 101 2201 101 2201 102 0001 0010 102 1202 102 1202 103 0001 0010 103 1203 103 1203 104 0011 0010 104 3204 104 3204 201 0000 0000 201 0002 201 0002 202 0000 0000 202 0003 202 0003 203 0000 0000 203 0004 203 0004 204 0000 0000 204 0000 204 0000 (a) Binary program (b) Hexadecimal program Address Instruction Label Operation Operand 101 LDA 201 FORMUL LDA 102 ADD 202 ADD J 103 ADD 203 ADD K 104 STA 204 STA N 201 DAT 2I DATA 2 202 DAT 3J DATA 3 203 DAT 4K DATA 4 204 DAT 0N DATA 0 (c) Symbolic program (d) Assembly programContents Address Figure 13.14 Computation Formula N=I+J+K484 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs address previous line. memory- reference instructions, third field also contains symbolic address. last refinement, assembly language . Programs written assembly language (assembly programs) translated machine language assembler. program must symbolic translation discussed earlier also assign form memory addresses symbolic addresses. development assembly language major milestone evolu - tion computer technology. first step high- level languages use today. Although programmers use assembly language, virtually machines provide one. used, all, systems programs compilers I/O routines. Appendix B provides detailed examination assembly language. 13.6 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms autoindexing base- register addressing direct addressing displacement addressing effective addressimmediate addressing indexing indirect addressing instruction format postindexingpreindexing register addressing register indirect addressing relative addressing word Review Questions 13.1 Briefly define immediate addressing. 13.2 Briefly define direct addressing . 13.3 Briefly define indirect addressing. 13.4 Briefly define register addressing. 13.5 Briefly define register indirect addressing. 13.6 Briefly define displacement addressing. 13.7 Briefly define relative addressing. 13.8 advantage autoindexing? 13.9 difference postindexing preindexing? 13.10 facts go determining use addressing bits instruction? 13.11 advantages disadvantages using variable- length instruction format? Problems 13.1 Given following memory values one- address machine accumulator, values following instructions load accumulator? ■Word 20 contains 40. ■Word 30 contains 50. ■Word 40 contains 60. ■Word 50 contains 70.13.6 / Key Ter Ms, review Ques Tions, Proble Ms 485 a. LOAD IMMEDIATE 20 b. LOAD DIRECT 20 c. LOAD INDIRECT 20 d. LOAD IMMEDIATE 30 e. LOAD DIRECT 30 f. LOAD INDIRECT 30 13.2 Let address stored program counter designated symbol X1. instruction stored X1 address part (operand reference) X2. operand needed execute instruction stored memory word address X3. index register contains value X4. relationship various quantities addressing mode instruction (a) direct; (b) indirect; (c) PC relative; (d) indexed? 13.3 address field instruction contains decimal value 14. correspond - ing operand located a. immediate addressing? b. direct addressing? c. indirect addressing? d. register addressing? e. register indirect addressing? 13.4 Consider 16-bit processor following appears main memory, starting location 200: 200 Load AC Mode 201 500 202 Next instruction first part first word indicates instruction loads value ac - cumulator. Mode field specifies addressing mode and, appropriate, indicates source register; assume used, source register R1, value 400. also base register contains value 100. value 500 location 201 may part address calculation. Assume location 399 contains value 999, location 400 contains value 1000, on. Determine effective address operand loaded following address modes: d. PC relative e. Displacement f. Registerg. Register indirect h. Autoindexing increment, using R1a. Direct b. Immediate c. Indirect 13.5 PC- relative mode branch instruction 3 bytes long. address instruction, decimal, 256028. Determine branch target address signed displacement instruction -31. 13.6 PC- relative mode branch instruction stored memory address 62010. branch made location 53010. address field instruction 10 bits long. binary value instruction? 13.7 many times processor need refer memory fetches executes indirect- address- mode instruction instruction (a) computation requiring single operand; (b) branch? 13.8 IBM 370 provide indirect addressing. Assume address operand main memory. would access operand? 13.9 [COOK82], author proposes PC- relative addressing modes elimi - nated favor modes, use stack. disadvantage proposal?486 CHAPT er 13 / insTruCTion seTs: Addressing Modes MATs 13.10 x86 includes following instruction: IMUL op1, op2, immediate instruction multiplies op2, may either register memory, imme - diate operand value, places result op1, must register. three- operand instruction sort instruction set. possible use instruction? ( Hint : Consider indexing.) 13.11 Consider processor includes base indexing addressing mode. Suppose instruction encountered employs addressing mode specifies displace - ment 1970, decimal. Currently base index register contain decimal numbers 48,022 8, respectively. address operand? 13.12 Define: EA=(X)+ effective address equal contents location X, X incremented one word length effective address calculated; EA=-(X) effective address equal contents location X, X decremented one word length effective address calculated; EA=(X)- effective address equal contents location X, X decremented one word length effective address calculated. Consider following instructions, format (Operation Source Operand, Destination Operand), result operation placed destination operand. a. OP X, (X) b. OP (X), (X)+ c. OP (X)+, (X) d. OP - (X), (X) e. OP - (X), (X)+ f. OP (X)+, (X)+ g. OP(X)-, (X) Using X stack pointer, instructions pop top two elements stack, perform designated operation (e.g., ADD source destination store destination), push result back stack? - struction, stack grow toward memory location 0 opposite direction? 13.13 Assume stack- oriented processor includes stack operations PUSH POP . Arithmetic operations automatically involve top one two stack ele - ments. Begin empty stack. stack elements remain following instructions executed? PUSH 4 PUSH 7 PUSH 8 ADD PUSH 10 SUB MUL 13.14 Justify assertion 32-bit instruction probably much less twice useful 16-bit instruction. 13.15 IBM’s decision move 36 bits 32 bits per word wrenching, whom? 13.16 Assume instruction set uses fixed 16-bit instruction length. Operand spec - ifiers 6 bits length. K two- operand instructions L zero- operand instructions. maximum number one- operand instructions supported? 13.17 Design variable- length opcode allow following encoded 36-bit instruction: ■instructions two 15-bit addresses one 3-bit register number; ■instructions one 15-bit address one 3-bit register number; ■instructions addresses registers.13.6 / Key Ter Ms, review Ques Tions, Proble Ms 487 13.18 Consider results Problem 10.6. Assume 16-bit memory address X, Y, Z either 16-bit addresses 4-bit register numbers. one- address machine uses accumulator, two- three- address machines 16 regis - ters instructions operating combinations memory locations registers. Assuming 8-bit opcodes instruction lengths multiples 4 bits, many bits machine need compute X? 13.19 possible justification instruction two opcodes? 13.20 16-bit Zilog Z8001 following general instruction format: 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 Mode Opcode w/b Operand 2 Operand 1 mode field specifies locate operands operand fields. w/b field used certain instructions specify whether operands bytes 16-bit words. operand 1 field may (depending mode field contents) specify one 16 general- purpose registers. operand 2 field may specify general- purpose registers except register 0. operand 2 field zeros, original opcodes takes new meaning. a. many opcodes provided Z8001? b. Suggest efficient way provide opcodes indicate trade- involved.488CHAPTER Processor structure Function 14.1 Processor Organization 14.2 Register Organization User- Visible Registers Control Status Registers Example Microprocessor Register Organizations 14.3 Instruction Cycle Indirect Cycle Data Flow 14.4 Instruction Pipelining Pipelining Strategy Pipeline Performance Pipeline Hazards Dealing Branches Intel 80486 Pipelining 14.5 x86 Processor Family Register Organization Interrupt Processing 14.6 Arm Processor Processor Organization Processor Modes Register Organization Interrupt Processing 14.7 Key Terms, Review Questions, Problems 14.1 / Processor organization 489 chapter discusses aspects processor yet covered Part Three sets stage discussion RISC superscalar architecture Chapters 15 16. begin summary processor organization. Registers, form internal memory processor, analyzed. position return discussion (begun Section 3.2) instruction cycle. descrip - tion instruction cycle common technique known instruction pipelin - ing complete description. chapter concludes examination aspects x86 ARM organizations. 14.1 PROCESSOR ORGANIZATION understand organization processor, let us consider requirements placed processor, things must do: ■Fetch instruction: processor reads instruction memory (register, cache, main memory). ■Interpret instruction: instruction decoded determine action required. ■Fetch data: execution instruction may require reading data memory I/O module. ■Process data: execution instruction may require performing arithmetic logical operation data. ■Write data: results execution may require writing data memory I/O module. things, clear processor needs store data temporarily. must remember location last instruction know get next instruction. needs store instructions data tem - porarily instruction executed. words, processor needs small internal memory. Figure 14.1 simplified view processor, indicating connection rest system via system bus. similar interface would needed Learning Objectives studying chapter, able to: rDistinguish user- visible control/status registers , discuss purposes registers category. rSummarize instruction cycle . rDiscuss principle behind instruction pipelining works practice. rCompare contrast various forms pipeline hazards. rPresent overview x86 processor structure. rPresent overview ARM processor structure.490 cHaPter 14 / Processor structure Function interconnection structures described Chapter 3. reader recall major components processor arithmetic logic unit (ALU) control unit (CU). ALU actual computation processing data. control unit controls movement data instructions processor controls operation ALU. addition, figure shows minimal internal memory, consisting set storage locations, called registers. Figure 14.2 slightly detailed view processor. data trans - fer logic control paths indicated, including element labeled internal Contr ol busData busAddr ess bus System busALURegisters Contr ol unit Figure 14.1 CPU System Bus • • • Contr ol unitRegisters Arithmetic Boolean logicComplementer Inter nal CPU b usShifterStatus /f_lagsArithmetic logic unit Contr ol paths Figure 14.2 Internal Structure CPU14.2 / register organization 491 processor bus . element needed transfer data various registers ALU ALU fact operates data internal pro - cessor memory. figure also shows typical basic elements ALU. Note similarity internal structure computer whole internal structure processor. cases, small collection major ele - ments (computer: processor, I/O, memory; processor: control unit, ALU, registers) connected data paths. 14.2 REGISTER ORGANIZATION discussed Chapter 4, computer system employs memory hierarchy. higher levels hierarchy, memory faster, smaller, expensive (per bit). Within processor, set registers function level mem - ory main memory cache hierarchy. registers processor perform two roles: ■ User- visible registers: Enable machine- assembly language programmer minimize main memory references optimizing use registers. ■Control status registers: Used control unit control operation processor privileged, operating system programs control execution programs. clean separation registers two categories. example, machines program counter user visible (e.g., x86), many not. purposes following discussion, however, use categories. User- Visible Registers user- visible register one may referenced means machine language processor executes. characterize following categories: ■General purpose ■Data ■Address ■Condition codes General- purpose registers assigned variety functions pro - grammer. Sometimes use within instruction set orthogonal oper - ation. is, general- purpose register contain operand opcode. provides true general- purpose register use. Often, however, restrictions. example, may dedicated registers floating- point stack operations. cases, general- purpose registers used addressing functions (e.g., register indirect, displacement). cases, partial clean sep - aration data registers address registers. Data registers may used hold data cannot employed calculation operand address. 492 cHaPter 14 / Processor structure Function Address registers may somewhat general purpose, may devoted particular addressing mode. Examples include following: ■Segment pointers: machine segmented addressing (see Section 8.3), segment register holds address base segment. may multiple registers: example, one operating system one current process. ■Index registers: used indexed addressing may autoindexed. ■Stack pointer: user- visible stack addressing, typically dedicated register points top stack. allows implicit addressing; is, push, pop, stack instructions need contain explicit stack operand. several design issues addressed here. important issue whether use completely general- purpose registers specialize use. already touched issue preceding chapter affects instruction set design. use specialized registers, generally impli - cit opcode type register certain operand specifier refers to. operand specifier must identify one set specialized registers rather one registers, thus saving bits. hand, specialization limits programmer’s flexibility. Another design issue number registers, either general purpose data plus address, provided. Again, affects instruction set design registers require operand specifier bits. previously discussed, somewhere 8 32 registers appears optimum [LUND77]. Fewer registers result memory references; registers noticeably reduce memory references (e.g., see [WILL90]). However, new approach, finds advantage use hun - dreds registers, exhibited RISC systems discussed Chapter 15. Finally, issue register length. Registers must hold addresses obviously must least long enough hold largest address. Data registers able hold values data types. machines allow two contigu - ous registers used one holding double- length values. final category registers, least partially visible user, holds condition codes (also referred flags ). Condition codes bits set pro - cessor hardware result operations. example, arithmetic operation may produce positive, negative, zero, overflow result. addition result stored register memory, condition code also set. code may subsequently tested part conditional branch operation. Condition code bits collected one registers. Usually, form part control register. Generally, machine instructions allow bits read implicit reference, programmer cannot alter them. Many processors, including based IA- 64 architecture MIPS processors, use condition codes all. Rather, conditional branch instructions specify comparison made act result compari - son, without storing condition code. Table 14.1, based [DERO87], lists key advantages disadvantages condition codes.14.2 / register organization 493 machines, subroutine call result automatic saving user- visible registers, restored return. processor performs saving restoring part execution call return instructions. allows subroutine use user- visible registers independently. machines, responsibility programmer save contents relevant user- visible registers prior subroutine call, including instructions purpose program. Control Status Registers variety processor registers employed control operation processor. these, machines, visible user. may visible machine instructions executed control operating system mode. course, different machines different register organizations use different terminology. list reasonably complete list register types, brief description. Four registers essential instruction execution: ■Program counter (PC): Contains address instruction fetched. ■Instruction register (IR): Contains instruction recently fetched. ■Memory address register (MAR): Contains address location memory. ■Memory buffer register (MBR): Contains word data written memory word recently read. processors internal registers designated MAR MBR, equivalent buffering mechanism needed whereby bits transferred Table 14.1 Condition Codes Advantages Disadvantages 1. condition codes set normal arithmetic data movement instructions, reduce number COMPARE TEST instructions needed. 2. Conditional instructions, BRANCH simplified relative composite instructions, TEST BRANCH. 3. Condition codes facilitate multiway branches. example, TEST instruction followed two branches, one less equal zero one greater zero. 4. Condition codes saved stack subroutine calls along register information.1. Condition codes add complexity, hardware software. Condition code bits often modified different ways different instructions, making life difficult microprogrammer compiler writer. 2. Condition codes irregular; typically part main data path, require extra hardware connections. 3. Often condition code machines must add special non- condition- code instructions special situa - tions anyway, bit checking, loop control, atomic semaphore operations. 4. pipelined implementation, condition codes require special synchronization avoid conflicts.494 cHaPter 14 / Processor structure Function system bus staged bits read data bus temporar - ily stored. Typically, processor updates PC instruction fetch PC always points next instruction executed. branch skip instruc - tion also modify contents PC. fetched instruction loaded IR, opcode operand specifiers analyzed. Data exchanged memory using MAR MBR. bus- organized system, MAR con - nects directly address bus, MBR connects directly data bus. User- visible registers, turn, exchange data MBR. four registers mentioned used movement data processor memory. Within processor, data must presented ALU processing. ALU may direct access MBR user- visible registers. Alternatively, may additional buffering registers boundary ALU; registers serve input output registers ALU exchange data MBR user- visible registers. Many processor designs include register set registers, often known program status word (PSW), contain status information. PSW typic - ally contains condition codes plus status information. Common fields flags include following: ■Sign: Contains sign bit result last arithmetic operation. ■Zero: Set result 0. ■Carry: Set operation resulted carry (addition) borrow (sub - traction) high- order bit. Used multiword arithmetic operations. ■Equal: Set logical compare result equality. ■Overflow: Used indicate arithmetic overflow. ■Interrupt Enable/Disable: Used enable disable interrupts. ■Supervisor: Indicates whether processor executing supervisor user mode. Certain privileged instructions executed supervisor mode, certain areas memory accessed supervisor mode. number registers related status control might found particular processor design. may pointer block memory contain - ing additional status information (e.g., process control blocks). machines using vectored interrupts, interrupt vector register may provided. stack used implement certain functions (e.g., subroutine call), system stack pointer needed. page table pointer used virtual memory system. Finally, regis - ters may used control I/O operations. number factors go design control status register organ - ization. One key issue operating system support. Certain types control infor - mation specific utility operating system. processor designer functional understanding operating system used, register organization extent tailored operating system. Another key design decision allocation control information registers memory. common dedicate first (lowest) hundred 14.2 / register organization 495 thousand words memory control purposes. designer must decide much control information registers much memory. usual trade- cost versus speed arises. Example Microprocessor Register Organizations instructive examine compare register organization comparable systems. section, look two 16-bit microprocessors designed time: Motorola MC68000 [STRI79] Intel 8086 [MORS78]. Figures 14.3a b depict register organization each; purely internal registers, memory address register, shown. MC68000 partitions 32-bit registers eight data registers nine address registers. eight data registers used primarily data manipulation also used addressing index registers. width registers allows 8-, 16-, 32-bit data operations, determined opcode. address registers con - tain 32-bit (no segmentation) addresses; two registers also used stack pointers, one users one operating system, depending current execution mode. registers numbered 7, one used time. MC68000 also includes 32-bit program counter 16-bit status register. Motorola team wanted regular instruction set, special- purpose registers. concern code efficiency led divide registers AX EAX BX EBX CX ECX DX EDX SP ESP BP EBP SI ESI DI Program statusGeneral r egisters EDIAX BX CX DX SP BP SI DI CS DS SS ESFLA GS r egister Instruction pointer (a) MC68000Status r egisterProgram counterProgram statusAddr ess r egistersData r egisters D0 D1 D2 D3 D4 D5 D6 D7 A0 A1 A2 A3 A4 A5 A6 A7´ (b) 8086Instr ptrFlagsExtractStackDataCodeDest indexSour ce indexBase ptrStack ptrDataCountBaseAccumulator Program statusSegmentPointers indexGeneral r egisters (c) 80386 —Pentium 4 Figure 14.3 Example Microprocessor Register Organizations496 cHaPter 14 / Processor structure Function two functional components, saving one bit register specifier. seems reasonable compromise complete generality code compaction. Intel 8086 takes different approach register organization. Every register special purpose, although registers also usable general pur - pose. 8086 contains four 16-bit data registers addressable byte 16-bit basis, four 16-bit pointer index registers. data registers used general purpose instructions. others, registers used implicitly. example, multiply instruction always uses accumulator. four pointer registers also used implicitly number operations; contains segment offset. also four 16-bit segment registers. Three four segment registers used dedicated, implicit fashion, point segment current instruction (useful branch instructions), segment containing data, segment containing stack, respectively. dedicated implicit uses provide compact encoding cost reduced flexibility. 8086 also includes instruction pointer set 1-bit status control flags. point comparison clear. universally accepted philosophy concerning best way organize processor registers [TOON81]. overall instruction set design many processor design issues, still matter judgment taste. second instructive point concerning register organization design illus - trated Figure 14.3c. figure shows user- visible register organization Intel 80386 [ELAY85], 32-bit microprocessor designed exten - sion 8086.1 80386 uses 32-bit registers. However, provide upward compatibility programs written earlier machine, 80386 retains original register organization embedded new organization. Given design constraint, architects 32-bit processors limited flexibility designing register organization. 14.3 INSTRUCTION CYCLE Section 3.2, described processor’s instruction cycle (Figure 3.9). recall, instruction cycle includes following stages: ■Fetch: Read next instruction memory processor. ■Execute: Interpret opcode perform indicated operation. ■Interrupt: interrupts enabled interrupt occurred, save current process state service interrupt. position elaborate somewhat instruction cycle. First, must introduce one additional stage, known indirect cycle. 1Because MC68000 already uses 32-bit registers, MC68020 [MACD84], full 32-bit archi - tecture, uses register organization.14.3 / instruction cycle 497 Indirect Cycle seen, Chapter 13, execution instruction may involve one operands memory, requires memory access. Further, indirect addressing used, additional memory accesses required. think fetching indirect addresses one instruction stages. result shown Figure 14.4. main line activity consists alter- nating instruction fetch instruction execution activities. instruction fetched, examined determine indirect addressing involved. so, required operands fetched using indirect addressing. Following execution, interrupt may processed next instruction fetch. Another way view process shown Figure 14.5, revised version Figure 3.12. illustrates correctly nature instruction cycle. instruction fetched, operand specifiers must identified. input operand memory fetched, process may require indirect addressing. Register- based operands need fetched. opcode exe - cuted, similar process may needed store result main memory. Data Flow exact sequence events instruction cycle depends design processor. can, however, indicate general terms must happen. Let us assume processor employs memory address register (MAR), memory buffer register (MBR), program counter (PC), instruction register (IR). fetch cycle , instruction read memory. Figure 14.6 shows flow data cycle. PC contains address next instruc - tion fetched. address moved MAR placed address bus. control unit requests memory read, result placed data bus copied MBR moved IR. Meanwhile, PC incremented 1, preparatory next fetch. fetch cycle over, control unit examines contents IR determine contains operand specifier using indirect addressing. so, Fetch ExecuteInterrupt Indir ect Figure 14.4 Instruction CycleInstruction address calculationInstruction operation decodingOperand address calculationData OperationOperand address calculationInstruction fetch Instruction complete, fetch next instructionMultiple operands Return string vector data interrupt InterruptOperand fetchIndirection Operand store Interrupt check InterruptMultiple resultsIndirection Figure 14.5 Instruction Cycle State Diagram Addr ess busData busContr ol busPCCPU MAR Contr ol unitMemory MBR MBR = Memory b uffer r egister MAR = Memory addr ess r egister IR = Instruction r egister PC = Program counterIR Figure 14.6 Data Flow, Fetch Cycle 49814.3 / instruction cycle 499 indirect cycle performed. shown Figure 14.7, simple cycle. right- N bits MBR, contain address reference, transferred MAR. control unit requests memory read, get desired address operand MBR. fetch indirect cycles simple predictable. execute cycle takes many forms; form depends various machine instructions IR. cycle may involve transferring data among registers, read write memory I/O, and/or invocation ALU. Like fetch indirect cycles, interrupt cycle simple predictable (Figure 14.8). current contents PC must saved processor resume normal activity interrupt. Thus, contents PC transferred MBR written memory. special memory location reserved purpose loaded MAR control unit. might, example, stack pointer. PC loaded address interrupt routine. result, next instruction cycle begin fetching appropriate instruction. Addr ess busData busContr ol busCPU MAR Contr ol unitMemory MBR Figure 14.7 Data Flow, Indirect Cycle Addr ess busData busContr ol busPCCPU Memory MBRMAR Contr ol Unit Figure 14.8 Data Flow, Interrupt Cycle500 cHaPter 14 / Processor structure Function 14.4 INSTRUCTION PIPELINING computer systems evolve, greater performance achieved taking advan - tage improvements technology, faster circuitry. addition, organiza - tional enhancements processor improve performance. already seen examples this, use multiple registers rather single accumulator, use cache memory. Another organizational approach, quite common, instruction pipelining. Pipelining Strategy Instruction pipelining similar use assembly line manufacturing plant. assembly line takes advantage fact product goes various stages production. laying production process assembly line, products various stages worked simultaneously. process also referred pipelining, because, pipeline, new inputs accepted one end previously accepted inputs appear outputs end. apply concept instruction execution, must recognize that, fact, instruction number stages. Figures 14.5, example, breaks instruc - tion cycle 10 tasks, occur sequence. Clearly, opportunity pipelining. simple approach, consider subdividing instruction processing two stages: fetch instruction execute instruction. times execu - tion instruction main memory accessed. time could used fetch next instruction parallel execution current one. Figure 14.9a depicts approach. pipeline two independent stages. first stage fetches instruction buffers it. second stage free, first stage passes buffered instruction. second stage executing instruction, first stage takes advantage unused memory cycles fetch FetchInstruction Instruction (a) Simpli/f_ied vie wResult Execute FetchInstruction DiscardInstructionNew addr ess Wait Wait (b) Expanded vie wResult Execute Figure 14.9 Two- Stage Instruction Pipeline14.4 / instruction Pi Pelining 501 buffer next instruction. called instruction prefetch fetch overlap . Note approach, involves instruction buffering, requires regis - ters. general, pipelining requires registers store data stages. clear process speed instruction execution. fetch execute stages equal duration, instruction cycle time would halved. However, look closely pipeline (Figure 14.9b), see doubling execution rate unlikely two reasons: 1. execution time generally longer fetch time. Execution involve reading storing operands performance operation. Thus, fetch stage may wait time empty buffer. 2. conditional branch instruction makes address next instruction fetched unknown. Thus, fetch stage must wait receives next instruction address execute stage. execute stage may wait next instruction fetched. Guessing reduce time loss second reason. simple rule following: conditional branch instruction passed fetch execute stage, fetch stage fetches next instruction memory branch instruction. Then, branch taken, time lost. branch taken, fetched instruction must discarded new instruction fetched. factors reduce potential effectiveness two- stage pipe - line, speedup occurs. gain speedup, pipeline must stages. Let us consider following decomposition instruction processing. ■Fetch instruction (FI): Read next expected instruction buffer. ■Decode instruction (DI): Determine opcode operand specifiers. ■Calculate operands (CO): Calculate effective address source oper - and. may involve displacement, register indirect, indirect, forms address calculation. ■Fetch operands (FO): Fetch operand memory. Operands regis - ters need fetched. ■Execute instruction (EI): Perform indicated operation store result, any, specified destination operand location. ■Write operand (WO): Store result memory. decomposition, various stages nearly equal dur - ation. sake illustration, let us assume equal duration. Using assump - tion, Figure 14.10 shows six- stage pipeline reduce execution time 9 instructions 54 time units 14 time units. Several comments order: diagram assumes instruction goes six stages pipeline. always case. example, load instruction need WO stage. However, simplify pipeline hardware, timing set assuming instruction requires six stages. Also, diagram assumes stages performed par - allel. particular, assumed memory conflicts. example, FI, FO, WO stages involve memory access. diagram implies accesses occur simultaneously. memory systems permit that. 502 cHaPter 14 / Processor structure Function However, desired value may cache, FO WO stage may null. Thus, much time, memory conflicts slow pipeline. Several factors serve limit performance enhancement. six stages equal duration, waiting involved various pipe - line stages, discussed two- stage pipeline. Another difficulty conditional branch instruction, invalidate several instruction fetches. similar unpredictable event interrupt. Figure 14.11 illustrates effects conditional branch, using program Figure 14.10. Assume instruc - tion 3 conditional branch instruction 15. instruction executed, way knowing instruction come next. pipeline, example, simply loads next instruction sequence (instruction 4) proceeds. Figure 14.10, branch taken, get full performance benefit enhancement. Figure 14.11, branch taken. determined end time unit 7. point, pipeline must cleared instructions useful. time unit 8, instruction 15 enters pipeline. instructions complete time units 9 12; performance penalty incurred could anticipate branch. Figure 14.12 indicates logic needed pipelining account branches interrupts. problems arise appear simple two- stage organization. CO stage may depend contents register could altered previous instruction still pipeline. register memory con - flicts could occur. system must contain logic account type conflict. clarify pipeline operation, might useful look alterna - tive depiction. Figures 14.10 14.11 show progression time horizontally across figures, row showing progress individual instruction. Figure 14.13 shows sequence events, time progressing vertically 1 Instruction 1Time FI Instruction 2 Instruction 3 Instruction 4 Instruction 5 Instruction 6 Instruction 7 Instruction 8 Instruction 92345678 91 01 11 21 31 4 DI CO FO EI WO WO FI DI CO FO EI FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO Figure 14.10 Timing Diagram Instruction Pipeline Operation14.4 / instruction Pi Pelining 503 figure, row showing state pipeline given point time. Figure 14.13a (which corresponds Figure 14.10), pipeline full time 6, 6 different instructions various stages execution, remains full time 9; assume instruction I9 last instruction executed. Fig - ure 14.13b, (which corresponds Figure 14.11), pipeline full times 6 7. time 7, instruction 3 execute stage executes branch instruction 15. point, instructions I4 I7 flushed pipeline, time 8, two instructions pipeline, I3 I15. preceding discussion, might appear greater number stages pipeline, faster execution rate. IBM S/360 designers pointed two factors frustrate seemingly simple pattern high- performance design [ANDE67a], remain elements designer must still consider: 1. stage pipeline, overhead involved moving data buffer buffer performing various preparation delivery functions. overhead appreciably lengthen total execution time single instruction. significant sequential instructions log - ically dependent, either heavy use branching memory access dependencies. 2. amount control logic required handle memory register depen - dencies optimize use pipeline increases enormously number stages. lead situation logic controlling gating stages complex stages controlled. Another consideration latching delay: takes time pipeline buffers operate adds instruction cycle time.1 Instruction 1Time Instruction 2 Instruction 3 Instruction 4 Instruction 5 Instruction 6 Instruction 7 Instruction 15 Instruction 1623456789 10Branch penalty 11 12 13 14 FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO EI WO FI DI CO FO FI DI CO FI DI FI FI DI CO FO EI WO FI DI CO FO EI WO Figure 14.11 Effect Conditional Branch Instruction Pipeline Operation504 cHaPter 14 / Processor structure Function Instruction pipelining powerful technique enhancing performance requires careful design achieve optimum results reasonable complexity. Pipeline Performance subsection, develop simple measures pipeline performance relative speedup (based discussion [HWAN93]). cycle time instruction pipeline time needed advance set instructions one stage pipeline; column Figures 14.10 14.11 represents one cycle time. cycle time determined t=maxi[ti]+d=tm+d 1…i…kNo YesYes NoFI DI CO FO EI WOCalculate operandsFetch instruction Decode instruction Uncon- ditional branch? Branch interrupt?Write operandsFetch operands Execute instruction Update PC Empty pipe Figure 14.12 Six- Stage CPU Instruction Pipeline14.4 / instruction Pi Pelining 505 ti=time delay circuitry ith stage pipeline tm= maximum stage delay (delay stage experiences largest delay) k=number stages instruction pipeline d= time delay latch, needed advance signals data one stage next general, time delay equivalent clock pulse tmWd. suppose n instructions processed, branches. Let Tk, n total time required pipeline k stages execute n instructions. Tk,n=[k+(n-1)]t (14.1) total k cycles required complete execution first instruc - tion, remaining n-1 instructions require n-1 cycles.2 equation easily verified Figure 14.10. ninth instruction completes time cycle 14: 14=[6+(9-1)] 2We bit sloppy here. cycle time equal maximum value stages full. beginning, cycle time may less first one cycles.I16 I16 I16 I16 I16 I16FIDICOFOEIWO I11 I2I1 2 I3I2I1 3 I4I3I2I1 4 I5I4I3I2I1 I6I5I4I3I2I1 I7I6I5I4I3I2 I8I7I6I5I4I3 I9I8I7I6I5I4 I9I8I7I6I5 I9I8I7I6 I9I8I7 I9I8 I95 6 7 8 9 10 11 12 13 14 (a) branchesFIDICOFO EIWO I11 I2 I1 2 I3 I2 I1 3 I4 I3 I2 I1 4 I5 I4 I3 I2 I1 I6 I5 I4 I3 I2 I1 I7 I6 I5 I4 I3 I2 I15 I15 I15 I15 I15 I15I35 6 7 8 9 10 11 12 13 14 (b) conditional branchTime Figure 14.13 Alternative Pipeline Depiction506 cHaPter 14 / Processor structure Function consider processor equivalent functions pipeline, assume instruction cycle time kt. speedup factor instruction pipeline compared execution without pipeline defined Sk=T1, n Tk, n=nkt [k+(n-1)]t=nk k+(n-1) (14.2) Figure 14.14a plots speedup factor function number instruc - tions executed without branch. might expected, limit (nS∞), k- fold speedup. Figure 14.14b shows speedup factor function number stages instruction pipeline.3 case, speedup factor approaches number instructions fed pipeline without branches. Thus, larger number pipeline stages, greater poten - tial speedup. However, practical matter, potential gains additional 1024681012 0 5 10 15 20024681012142 4 8 Number instructions (log scale)Speedup factor Speedup factor Number stages16k 12 stages n 30 instructions n 20 instructions n 10 instructionsk 9 stages k 6 stages 32 64 128 (a) (b) Figure 14.14 Speedup Factors Instruction Pipelining 3Note x- axis logarithmic Figure 14.14a linear Figure 14.14b.14.4 / instruction Pi Pelining 507 pipeline stages countered increases cost, delays stages, fact branches encountered requiring flushing pipeline. Pipeline Hazards previous subsection, mentioned situations result less optimal pipeline performance. subsection, examine issue systematic way. Chapter 16 revisits issue, detail, introduced complexities found superscalar pipeline organizations. pipeline hazard occurs pipeline, portion pipeline, must stall conditions permit continued execution. pipe - line stall also referred pipeline bubble . three types hazards: resource, data, control. resource hazards resource hazard occurs two (or more) instructions already pipeline need resource. result instructions must executed serial rather parallel portion pipeline. resource hazard sometime referred structural hazard . Let us consider simple example resource hazard. Assume simplified five- stage pipeline, stage takes one clock cycle. Figure 14.15a shows ideal case, new instruction enters pipeline clock cycle. assume main memory single port instruction fetches data reads writes must performed one time. Further, ignore cache. case, operand read write memory cannot performed parallel 1 I1Clock cycle (a) Five-stage pipeline, ideal caseInstructionFI I2 I3 I423456789 DI FO EI WO FI DI FO EI WO FI DI FO EI WO FI DI FO EI WO 1 I1Clock cycle (b) I1 source operand memoryInstructionFI I2 I3 I423456789 DI FO EI WO FI DI FO EI WO FI IdleD OE IW FI DI FO EI WO Figure 14.15 Example Resource Hazard508 cHaPter 14 / Processor structure Function instruction fetch. illustrated Figure 14.15b, assumes source operand instruction I1 memory, rather register. Therefore, fetch instruction stage pipeline must idle one cycle beginning instruction fetch instruction I3. figure assumes operands registers. Another example resource conflict situation multiple instruc - tions ready enter execute instruction phase single ALU. One solutions resource hazards increase available resources, multiple ports main memory multiple ALU units. Reservation Table Analyzer One approach analyzing resource conflicts aiding design pipe - lines reservation table. examine reservation tables Appendix N. data hazards data hazard occurs conflict access operand location. general terms, state hazard form: Two instructions program executed sequence access particular memory register operand. two instructions executed strict sequence, problem occurs. However, instructions executed pipeline, possible operand value updated way produce different result would occur strict sequential execution. words, program produces incorrect result use pipelining. example, consider following x86 machine instruction sequence: ADD EAX, EBX /* EAX = EAX + EBX SUB ECX, EAX /* ECX = ECX – EAX first instruction adds contents 32-bit registers EAX EBX stores result EAX. second instruction subtracts contents EAX ECX stores result ECX. Figure 14.16 shows pipeline behavior. 1 ADD EAX, EB XClock cycle FI SUB ECX, EAX I3 I423456789 10 DI FO EI WO FI DI IdleF OE IW FI DI FO EI WO FI DI FO EI WO Figure 14.16 Example Data Hazard14.4 / instruction Pi Pelining 509 ADD instruction update register EAX end stage 5, occurs clock cycle 5. SUB instruction needs value beginning stage 2, occurs clock cycle 4. maintain correct operation, pipeline must stall two clocks cycles. Thus, absence special hardware spe - cific avoidance algorithms, data hazard results inefficient pipeline usage. three types data hazards: ■Read write (RAW), true dependency: instruction modifies reg - ister memory location succeeding instruction reads data memory register location. hazard occurs read takes place write operation complete. ■Write read (WAR), antidependency: instruction reads register memory location succeeding instruction writes location. haz - ard occurs write operation completes read operation takes place. ■Write write (WAW), output dependency: Two instructions write location. hazard occurs write operations take place reverse order intended sequence. example Figure 14.16 RAW hazard. two hazards best discussed context superscalar organization, discussed Chapter 16. control hazards control hazard, also known branch hazard , occurs pipeline makes wrong decision branch prediction therefore brings instructions pipeline must subsequently discarded. discuss approaches dealing control hazards next. Dealing Branches One major problems designing instruction pipeline assuring steady flow instructions initial stages pipeline. primary impediment, seen, conditional branch instruction. instruction actually executed, impossible determine whether branch taken not. variety approaches taken dealing conditional branches: ■Multiple streams ■Prefetch branch target ■Loop buffer ■Branch prediction ■Delayed branch multiple streams simple pipeline suffers penalty branch instruction must choose one two instructions fetch next may make wrong choice. brute- force approach replicate initial portions pipeline allow pipeline fetch instructions, making use two streams. two problems approach: ■With multiple pipelines contention delays access registers memory.510 cHaPter 14 / Processor structure Function ■Additional branch instructions may enter pipeline (either stream) original branch decision resolved. instruction needs add - itional stream. Despite drawbacks, strategy improve performance. Examples machines two pipeline streams IBM 370/168 IBM 3033. prefetch branch target conditional branch recognized, target branch prefetched, addition instruction following branch. target saved branch instruction executed. branch taken, target already prefetched. IBM 360/91 uses approach. loop buffer loop buffer small, very- high- speed memory maintained instruction fetch stage pipeline containing n recently fetched instructions, sequence. branch taken, hardware first checks whether branch target within buffer. so, next instruction fetched buffer. loop buffer three benefits: 1. use prefetching, loop buffer contain instruction sequentially ahead current instruction fetch address. Thus, instructions fetched sequence available without usual memory access time. 2. branch occurs target locations ahead address branch instruction, target already buffer. useful rather common occurrence IF– IF– THEN– ELSE sequences. 3. strategy particularly well suited dealing loops, iterations; hence name loop buffer . loop buffer large enough contain instructions loop, instructions need fetched memory once, first iteration. subsequent iterations, needed instructions already buffer. loop buffer similar principle cache dedicated instructions. differences loop buffer retains instructions sequence much smaller size hence lower cost. Figure 14.17 gives example loop buffer. buffer contains 256 bytes, byte addressing used, least significant 8 bits used index Loop b uffer (256 bytes)Branch addr ess 8Instruction decoded case hit signi/f_icant addr ess bits compar ed determine hit Figure 14.17 Loop Buffer14.4 / instruction Pi Pelining 511 buffer. remaining significant bits checked determine branch target lies within environment captured buffer. Among machines using loop buffer CDC machines ( Star- 100, 6600, 7600) CRAY- 1. specialized form loop buffer available Motorola 68010, executing three- instruction loop involving DBcc (decrement branch condition) instruction (see Problem 14.14). three- word buffer maintained, processor executes instructions repeatedly loop condition satisfied. Branch Prediction Simulator Branch Target Buffer branch prediction Various techniques used predict whether branch taken. Among common following: ■Predict never taken ■Predict always taken ■Predict opcode ■Taken/not taken switch ■Branch history table first three approaches static: depend execution - tory time conditional branch instruction. latter two approaches dynamic: depend execution history. first two approaches simplest. either always assume branch taken continue fetch instructions sequence, always assume branch taken always fetch branch tar - get. predict- never- taken approach popular branch predic - tion methods. Studies analyzing program behavior shown conditional branches taken 50% time [LILJ88], cost prefetching either path same, always prefetching branch target address give better performance always prefetching sequential path. However, paged machine, prefetching branch target likely cause page fault prefetching next instruction sequence, per - formance penalty taken account. avoidance mechanism may employed reduce penalty. final static approach makes decision based opcode branch instruction. processor assumes branch taken certain branch opcodes others. [LILJ88] reports success rates greater 75% strategy. Dynamic branch strategies attempt improve accuracy prediction recording history conditional branch instructions program. example, one bits associated conditional branch instruction 512 cHaPter 14 / Processor structure Function reflect recent history instruction. bits referred taken/ taken switch directs processor make particular decision next time instruction encountered. Typically, history bits associated instruction main memory. Rather, kept temporary high- speed storage. One possibility associate bits conditional branch instruction cache. instruction replaced cache, - tory lost. Another possibility maintain small table recently executed branch instructions one history bits entry. processor could access table associatively, like cache, using low- order bits branch instruction’s address. single bit, recorded whether last execution instruction resulted branch not. shortcoming using single bit appears case conditional branch instruction almost always taken, loop instruction. one bit history, error predic - tion occur twice use loop: entering loop, exiting. two bits used, used record result last two instances execution associated instruction, record state fashion. Figure 14.18 shows typical approach (see Problem 14.13 Yes YesPredict takenRead next conditional branch instr Branch taken? Predict takenRead next conditional branch instr Branch taken?No Yes YesPredict takenRead next conditional branch instr Branch taken? Predict takenRead next conditional branch instr Branch taken?No Figure 14.18 Branch Prediction Flowchart14.4 / instruction Pi Pelining 513 possibilities). Assume algorithm starts upper- left- hand corner flowchart. long succeeding conditional branch instruction encountered taken, decision process predicts next branch taken. single prediction wrong, algorithm continues predict next branch taken. two successive branches taken algo - rithm shift right- hand side flowchart. Subsequently, algorithm predict branches taken two branches row taken. Thus, algorithm requires two consecutive wrong predictions change prediction decision. decision process represented compactly finite- state machine, shown Figure 14.19. finite- state machine representation com - monly used literature. use history bits, described, one drawback: decision made take branch, target instruction cannot fetched tar - get address, operand conditional branch instruction, decoded. Greater efficiency could achieved instruction fetch could initiated soon branch decision made. purpose, information must saved, known branch target buffer, branch history table. branch history table small cache memory associated instruc - tion fetch stage pipeline. entry table consists three elements: address branch instruction, number history bits record state use instruction, information target instruction. proposals implementations, third field contains address target instruction. Another possibility third field actually contain target instruction. trade- clear: Storing target address yields smaller table greater instruction fetch time compared storing target instruction [RECH98]. Figure 14.20 contrasts scheme predict- never- taken strategy. former strategy, instruction fetch stage always fetches next sequential taken takenNot taken TakenTakenNot taken TakenTaken Predict takenPredict taken Predict takenPredict taken Figure 14.19 Branch Prediction State Diagram514 cHaPter 14 / Processor structure Function address. branch taken, logic processor detects instructs next instruction fetched target address (in addition flushing pipeline). branch history table treated cache. prefetch triggers lookup branch history table. match found, next sequential address used fetch. match found, prediction made based state instruction: Either next sequential address branch target address fed select logic. branch instruction executed, execute stage signals branch history table logic result. state instruction updated reflect correct incorrect prediction. prediction incorrect, select logic Branch miss handling Select E Branch miss handling EMemory SelectMemoryIPFAR IPFAR instruction pre/f_ix addr ess r egisterLookup Update stateAdd new entry Redir ectBranch instruction addr essTarget addr ess State       Next sequential addr ess Next sequential addr ess(a) Predict ne ver taken strate gy (b) Branch history table strate gy Figure 14.20 Dealing Branches14.4 / instruction Pi Pelining 515 redirected correct address next fetch. conditional branch instruction encountered table, added table one existing entries discarded, using one cache replacement algorithms discussed Chapter 4. refinement branch history approach referred two- level correlation- based branch history [YEH91]. approach based assump - tion whereas loop- closing branches, past history particular branch instruction good predictor future behavior, complex control- flow structures, direction branch frequently correlated direction related branches. example if- then- else case structure. num - ber strategies possible. Typically, recent global branch history (i.e., history recent branches branch instruction) used addition history current branch instruction. general structure defined (m, n ) correlator, uses behavior last branches choose 2m n- bit branch predictors current branch instruction. words, n- bit history kept give branch possible combination branches taken recent branches. delayed branch possible improve pipeline performance automatically rearranging instructions within program, branch instructions occur later actually desired. intriguing approach examined Chapter 15. Intel 80486 Pipelining instructive example instruction pipeline Intel 80486. 80486 implements five- stage pipeline: ■Fetch: Instructions fetched cache external memory placed one two 16-byte prefetch buffers. objective fetch stage fill prefetch buffers new data soon old data consumed instruction decoder. instructions variable length (from 1 11 bytes counting prefixes), status prefetcher relative pipeline stages varies instruction instruction. average, five instructions fetched 16-byte load [CRAW90]. fetch stage operates independently stages keep prefetch buffers full. ■Decode stage 1: opcode addressing- mode information decoded D1 stage. required information, well instruction- length informa - tion, included first 3 bytes instruction. Hence, 3 bytes passed D1 stage prefetch buffers. D1 decoder direct D2 stage capture rest instruction (displacement immediate data), involved D1 decoding. ■Decode stage 2: D2 stage expands opcode control signals ALU. also controls computation complex addressing modes. ■Execute: stage includes ALU operations, cache access, register update.516 cHaPter 14 / Processor structure Function ■Write back: stage, needed, updates registers status flags modified preceding execute stage. current instruction updates mem - ory, computed value sent cache bus- interface write buffers time. use two decode stages, pipeline sustain throughput close one instruction per clock cycle. Complex instructions conditional branches slow rate. Figure 14.21 shows examples operation pipeline. Figure 14.21a shows delay introduced pipeline memory access required. However, Figure 14.21b shows, delay values used compute memory addresses. is, value loaded memory register register used base register next instruction, processor stall one cycle. example, processor accesses cache EX stage first instruction stores value retrieved register WB stage. However, next instruction needs register D2 stage. D2 stage lines WB stage previous instruction, bypass signal paths allow D2 stage access data used WB stage writing, saving one pipeline stage. Figure 14.21c illustrates timing branch instruction, assuming branch taken. compare instruction updates condition codes WB stage, bypass paths make available EX stage jump instruction time. parallel, processor runs speculative fetch cycle target jump EX stage jump instruction. processor determines false branch condition, discards prefetch continues execution next sequential instruction (already fetched decoded). D1 D2 EX WB Fetch D1 D2 EX WB Fetch D1 D2 EX MOV Mem2, Reg1 (a) data load delay pipelineMOV Reg1, Reg2MOV Reg1, Mem1 Fetch D1 D2 EX WB Fetch D1 D2 EX Fetch D1 D2 EX Target (c) Branch instruction timingJcc TargetCMP Reg1, ImmFetch D1 D2 EX WB Fetch D1 D2 EX (b) Pointer load delayMOV Reg2, (Reg1)MOV Reg1, Mem1Fetch WB Figure 14.21 80486 Instruction Pipeline Examples14.5 / x86 P rocessor FaMily 517 14.5 x86 PROCESSOR FAMILY x86 organization evolved dramatically years. section examine details recent processor organizations, concen - trating common elements single processors. Chapter 16 looks superscalar aspects x86, Chapter 18 examines multicore organization. - view Pentium 4 processor organization depicted Figure 4.18. Register Organization register organization includes following types registers (Table 14.2): ■General: eight 32-bit general- purpose registers (see Figure 14.3c). may used types x86 instructions; also hold oper - ands address calculations. addition, registers also serve special purposes. example, string instructions use contents ECX, ESI, EDI registers operands without reference regis - ters explicitly instruction. result, number instructions Table 14.2 x86 Processor Registers (a) Integer Unit 32-bit Mode Type Number Length (bits) Purpose General 8 32 General- purpose user registers Segment 6 16 Contain segment selectors EFLAGS 1 32 Status control bits Instruction Pointer 1 32 Instruction pointer (b) Integer Unit 64-bit Mode Type Number Length (bits) Purpose General 16 32 General- purpose user registers Segment 6 16 Contain segment selectors RFLAGS 1 64 Status control bits Instruction Pointer 1 64 Instruction pointer (c) Floating- Point Unit Type Number Length (bits) Purpose Numeric 8 80 Hold floating- point numbers Control 1 16 Control bits Status 1 16 Status bits Tag Word 1 16 Specifies contents numeric registers Instruction Pointer 1 48 Points instruction interrupted exception Data Pointer 1 48 Points operand interrupted exception518 cHaPter 14 / Processor structure Function encoded compactly. 64-bit mode, sixteen 64-bit general- purpose registers. ■Segment: six 16-bit segment registers contain segment selectors, index segment tables, discussed Chapter 8. code segment (CS) register references segment containing instruction executed. stack segment (SS) register references segment containing user- visible stack. remaining segment registers (DS, ES, FS, GS) enable user reference four separate data segments time. ■Flags: 32-bit EFLAGS register contains condition codes various mode bits. 64-bit mode, register extended 64 bits referred RFLAGS. current architecture definition, upper 32 bits RFLAGS unused. ■Instruction pointer: Contains address current instruction. also registers specifically devoted floating- point unit: ■Numeric: register holds extended- precision 80-bit floating- point num - ber. eight registers function stack, push pop oper - ations available instruction set. ■Control: 16-bit control register contains bits control operation floating- point unit, including type rounding control; single, double, extended precision; bits enable disable various exception conditions. ■Status: 16-bit status register contains bits reflect current state floating- point unit, including 3-bit pointer top stack; condition codes reporting outcome last operation; exception flags. ■Tag word: 16-bit register contains 2-bit tag floating- point numeric register, indicates nature contents correspond - ing register. four possible values valid, zero, special (NaN, infinity, denormalized), empty. tags enable programs check contents numeric register without performing complex decoding actual data register. example, context switch made, processor need save floating- point registers empty. use aforementioned registers easily understood. Let us elaborate briefly several registers. eflags register EFLAGS register (Figure 14.22) indicates condition processor helps control operation. includes six condition codes defined Table 12.9 (carry, parity, auxiliary, zero, sign, overflow), report results integer operation. addition, bits register may referred control bits: ■Trap flag (TF): set, causes interrupt execution instruction. used debugging. ■Interrupt enable flag (IF): set, processor recognize external interrupts.14.5 / x86 P rocessor FaMily 519 ■Direction flag (DF): Determines whether string processing instructions incre - ment decrement 16-bit half- registers SI DI (for 16-bit operations) 32-bit registers ESI EDI (for 32-bit operations). ■I/O privilege flag (IOPL): set, causes processor generate exception accesses I/O devices protected- mode operation. ■Resume flag (RF): Allows programmer disable debug exceptions instruction restarted debug exception without immedi - ately causing another debug exception. ■Alignment check (AC): Activates word doubleword addressed nonword nondoubleword boundary. ■Identification flag (ID): bit set cleared, processor supports processorID instruction. instruction provides information vendor, family, model. addition, 4 bits relate operating mode. Nested Task (NT) flag indicates current task nested within another task protected- mode operation. Virtual Mode (VM) bit allows programmer enable disable virtual 8086 mode, determines whether processor runs 8086 machine. Virtual Interrupt Flag (VIF) Virtual Interrupt Pending (VIP) flag used multitasking environment. control registers x86 employs four control registers (register CR1 unused) control various aspects processor operation (Figure 14.23). registers except CR0 either 32 bits 64 bits long, depending whether implementation supports x86 64-bit architecture. CR0 register contains system control flags, control modes indicate states apply generally X ID = Identi/f_ication /f_lag X VIP = Virtual interrupt pending X VIF = Virtual interrupt /f_lag X AC = Alignment check X VM = Virtual 8086 mode X RF = Resume /f_lag X NT = Nested task /f_lag X IOPL = I/O privilege level = Over/f_low /f_lagC DF = Direction /f_lag X = Interrupt enable /f_lag X TF = Trap /f_lag SF = Sign /f_lag ZF = Zero /f_lag AF = Auxiliary carry /f_lag PF = Parity /f_lag CF = Carry /f_lag31302928272625242322212019181716151413121110987654321 0000000000I DV PV FA CV MR F0N TI P LO FD FI FT FS FZ F0A F0P F1C F0 indicates status ﬂag. C indicates control ﬂag. X indicates system ﬂag. Shaded bits reserved. Figure 14.22 x86 EFLAGS Register520 cHaPter 14 / Processor structure Function processor rather execution individual task. flags follows: ■Protection Enable (PE): Enable/disable protected mode operation. ■Monitor Coprocessor (MP): interest running programs ear - lier machines x86; relates presence arithmetic coprocessor. ■Emulation (EM): Set processor floating- point unit, causes interrupt attempt made execute floating- point instructions. ■Task Switched (TS): Indicates processor switched tasks. ■Extension Type (ET): used Pentium later machines; used indicate support math coprocessor instructions earlier machines.OSXSAVE XSAVE enable bit= PCIDE Enables process-context identi/f_iers= OSXMMEXCPT = Support unmasked SIMD FP exceptionsShaded area indicates reserved bits. VME = Virtual 8086 mode extensions PCD = Page-level cache disable PWT = Page-level writes transparent PG = Paging CD = Cache disable NW = write = Alignment mask WP = Write protect NE = Numeric error ET = Extension type TS = Task switched EM = Emulation MP = Monitor coprocessor PE = Protection enableS X ES E PV X EOSXSA OSFXSR CR4V EP V DD EP EP EM C EP G EP C E CR3 (PDBR) CR2Page-directory base Page-fault linear addressP C DP W T0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31(63)PCIDEFSGSBASE OSXMMEXCPT CR0T SE MM PP EE TN EA MN WC DP GW P0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 FSGSBASE Enables segment base instructions= SMXE Enable safer mode extensions= VMXE Enable virtual machine extension = OSFXSR Support FXSAVE, FXSTOR= PCE Performance counter enable= PGE Page global enable= MCE Machine check enable= PAE Physical address extension= PSE Page size extensions= DE Debug extensions= TSD Time stamp disable= PVI Protected mode virtual interrupt= Figure 14.23 x86 Control Registers14.5 / x86 P rocessor FaMily 521 ■Numeric Error (NE): Enables standard mechanism reporting floating- point errors external bus lines. ■Write Protect (WP): bit clear, read- user- level pages written supervisor process. feature useful supporting process creation operating systems. ■Alignment Mask (AM): Enables/disables alignment checking. ■Not Write (NW): Selects mode operation data cache. bit set, data cache inhibited cache write- operations. ■Cache Disable (CD): Enables/disables internal cache fill mechanism. ■Paging (PG): Enables/disables paging. paging enabled, CR2 CR3 registers valid. CR2 regis - ter holds 32-bit linear address last page accessed page fault inter - rupt. leftmost 20 bits CR3 hold 20 significant bits base address page directory; remainder address contains zeros. Two bits CR3 used drive pins control operation external cache. page- level cache disable (PCD) enables disables external cache, page- level writes transparent (PWT) bit controls write external cache. CR4 con - tains additional control bits. mmx registers Recall Section 10.3 x86 MMX capability makes use several 64-bit data types. MMX instructions make use 3-bit register address fields, eight MMX registers supported. fact, processor include specific MMX registers. Rather, processor uses aliasing technique (Figure 14.24). existing floating- point registers used store MMX values. Specifically, low- order 64 bits (mantissa) floating- point register used form eight MMX registers. Thus, older 32-bit x86 architecture easily extended support MMX capability. key characteristics MMX use registers follows: ■Recall floating- point registers treated stack floating- point operations. MMX operations, registers accessed directly. ■The first time MMX instruction executed floating- point operations, FP tag word marked valid. reflects change stack operation direct register addressing. ■The EMMS (Empty MMX State) instruction sets bits FP tag word indicate registers empty. important programmer insert instruction end MMX code block subsequent floating- point operations function properly. ■When value written MMX register, bits [79:64] corresponding FP register (sign exponent bits) set ones. sets value FP register NaN (not number) infinity viewed floating- point value. ensures MMX data value look like valid floating- point value.522 cHaPter 14 / Processor structure Function Interrupt Processing Interrupt processing within processor facility provided support operat - ing system. allows application program suspended, order variety interrupt conditions serviced later resumed. interrupts exceptions Two classes events cause x86 suspend execution current instruction stream respond event: interrupts exceptions. cases, processor saves context current process transfers predefined routine service condition. interrupt generated signal hardware, may occur random times execution program. exception generated software, provoked execution instruction. two sources interrupts two sources exceptions: 1. Interrupts ■Maskable interrupts: Received processor’s INTR pin. processor recognize maskable interrupt unless interrupt enable flag (IF) set. ■Nonmaskable interrupts: Received processor’s NMI pin. Recogni - tion interrupts cannot prevented. 2. Exceptions ■ Processor- detected exceptions: Results processor encounters error attempting execute instruction.0 79 63 63 0 MM00000000000000000 MMX r egistersFloating-point r egistersFloating-point tag MM1MM2MM3MM4MM5MM6MM7 Figure 14.24 Mapping MMX Registers Floating- Point Registers14.5 / x86 P rocessor FaMily 523 ■Programmed exceptions: instructions generate exception (e.g., INTO, INT3, INT, BOUND). interrupt vector table Interrupt processing x86 uses interrupt vector table. Every type interrupt assigned number, number used index interrupt vector table. table contains 256 32-bit interrupt vectors, address (segment offset) interrupt service routine interrupt number. Table 14.3 shows assignment numbers interrupt vector table; shaded entries represent interrupts, nonshaded entries exceptions. NMI hardware interrupt type 2. INTR hardware interrupts assigned numbers range 32 255; INTR interrupt generated, must accom - panied bus interrupt vector number interrupt. remain - ing vector numbers used exceptions. one exception interrupt pending, processor services predictable order. location vector numbers within table reflect priority. Instead, priority among exceptions interrupts organized five classes. descending order priority, ■Class 1: Traps previous instruction (vector number 1) ■Class 2: External interrupts (2, 32–255) ■Class 3: Faults fetching next instruction (3, 14) ■Class 4: Faults decoding next instruction (6, 7) ■Class 5: Faults executing instruction (0, 4, 5, 8, 10–14, 16, 17) interrupt handling transfer execution using CALL instruction, transfer interrupt- handling routine uses system stack store processor state. interrupt occurs recognized processor, sequence events takes place: 1. transfer involves change privilege level, current stack segment register current extended stack pointer (ESP) register pushed onto stack. 2. current value EFLAGS register pushed onto stack. 3. interrupt (IF) trap (TF) flags cleared. disables INTR interrupts trap single- step feature. 4. current code segment (CS) pointer current instruction pointer (IP EIP) pushed onto stack. 5. interrupt accompanied error code, error code pushed onto stack. 6. interrupt vector contents fetched loaded CS IP EIP registers. Execution continues interrupt service routine. return interrupt, interrupt service routine executes IRET instruction. causes values saved stack restored; execution resumes point interrupt.524 cHaPter 14 / Processor structure Function Table 14.3 x86 Exception Interrupt Vector Table Vector Number Description 0 Divide error; division overflow division zero 1 Debug exception; includes various faults traps related debugging 2 NMI pin interrupt; signal NMI pin 3 Breakpoint; caused INT 3 instruction, 1-byte instruction useful debugging 4 INTO- detected overflow; occurs processor executes flag set 5 BOUND range exceeded; BOUND instruction compares register bound- aries stored memory generates interrupt contents register bounds 6 Undefined opcode 7 Device available; attempt use ESC WAIT instruction fails due lack external device 8 Double fault; two interrupts occur instruction cannot handled serially 9 Reserved 10 Invalid task state segment; segment describing requested task initialized valid 11 Segment present; required segment present 12 Stack fault; limit stack segment exceeded stack segment present 13 General protection; protection violation cause another exception (e.g., writing read- segment) 14 Page fault 15 Reserved 16 Floating- point error; generated floating- point arithmetic instruction 17 Alignment check; access word stored odd byte address doubleword stored address multiple 4 18 Machine check; model specific 19–31 Reserved 32–255 User interrupt vectors; provided INTR signal activated Unshaded: exceptions Shaded: interrupts 14.6 ARM PROCESSOR section, look key elements ARM architecture organization. defer discussion complex aspects organization pipelining Chapter 16. discussion section Chapter 16, useful keep mind key characteristics ARM architecture. ARM primar - ily RISC system following notable attributes:14.6 / arM Processor 525 ■A moderate array uniform registers, found CISC systems fewer found many RISC systems. ■A load/store model data processing, operations perform operands registers directly memory. data must loaded registers operation performed; result used processing stored memory. ■A uniform fixed- length instruction 32 bits standard set 16 bits Thumb instruction set. ■To make data processing instruction flexible, either shift rota - tion preprocess one source registers. efficiently support fea - ture, separate arithmetic logic unit (ALU) shifter units. ■A small number addressing modes load/store addressees deter - mined registers instruction fields. Indirect indexed addressing involving values memory used. ■ Auto- increment auto- decrement addressing modes used improve operation program loops. ■Conditional execution instructions minimizes need conditional branch instructions, thereby improving pipeline efficiency, pipeline flushing reduced. Processor Organization ARM processor organization varies substantially one implementation next, particularly based different versions ARM architecture. However, useful discussion section present simplified, generic ARM orga - nization, illustrated Figure 14.25. figure, arrows indicate flow data. box represents functional hardware unit storage unit. Data exchanged processor external memory data bus. value transferred either data item, result load store instruction, instruction fetch. Fetched instructions pass instruction decoder execution, control control unit. latter includes pipe - line logic provides control signals (not shown) hardware elements processor. Data items placed register file, consisting set 32-bit registers. Byte halfword items treated twos- complement numbers sign- extended 32 bits. ARM data processing instructions typically two source registers, Rn Rm, single result destination register, Rd. source register values feed ALU separate multiply unit makes use additional register accumulate partial results. ARM processor also includes hardware unit shift rotate Rm value enters ALU. shift rotate occurs within cycle time instruction increases power flexibility many data processing operations. results operation fed back destination register. Load/store instructions may also use output arithmetic units generate memory address load store.526 cHaPter 14 / Processor structure Function Processor Modes quite common processor support small number processor modes. example, many operating systems make use two modes: user mode kernel mode, latter mode used execute privileged system software. contrast, ARM architecture provides flexible foundation oper - ating systems enforce variety protection policies. ARM architecture supports seven execution modes. application programs execute user mode . processor user mode, program executed unable access protected system resources change mode, causing exception occur. remaining six execution modes referred privileged modes. modes used run system software. two principal advantages defining many different privileged modes: (1) OS tailor use system software variety circumstances, (2) certain registers dedicated use privileged modes, allowing swifter changes context.Memory addr ess r egister Incrementer Barr el shifter Multiply/ accumulateALUR15 (PC) Rn RmRd AccSign extend User Register File (R0−R15)Exter nal memory (cache, main memory) Memory b uffer r egister Instruction r egister Contr ol unitInstruction decoder CPSR Figure 14.25 Simplified ARM Organization14.6 / arM Processor 527 exception modes full access system resources change modes freely. Five modes known exception modes. entered specific exceptions occur. modes dedicated registers substitute user mode registers, used avoid corrupting User mode state information exception occurs. exception modes follows: ■Supervisor mode: Usually OS runs in. entered pro - cessor encounters software interrupt instruction. Software interrupts standard way invoke operating system services ARM. ■Abort mode: Entered response memory faults. ■Undefined mode: Entered processor attempts execute instruc - tion supported neither main integer core one coprocessors. ■Fast interrupt mode: Entered whenever processor receives interrupt signal designated fast interrupt source. fast interrupt cannot interrupted, fast interrupt may interrupt normal interrupt. ■Interrupt mode: Entered whenever processor receives interrupt signal interrupt source (other fast interrupt). interrupt may interrupted fast interrupt. remaining privileged mode System mode . mode entered exception uses registers available User mode. System mode used running certain privileged operating system tasks. System mode tasks may interrupted five exception categories. Register Organization Figure 14.26 depicts user- visible registers ARM. ARM processor total 37 32-bit registers, classified follows: ■ Thirty- one registers referred ARM manual general- purpose registers. fact, these, program counters, special purposes. ■Six program status registers. Registers arranged partially overlapping banks, current pro - cessor mode determining bank available. time, sixteen numbered registers one two program status registers visible, total 17 18 software- visible registers. Figure 14.26 interpreted follows: ■Registers R0 R7 , register R15 (the program counter) current program status register (CPSR) visible shared modes. ■Registers R8 R12 shared modes except fast interrupt, dedicated registers R8_fiq R12_fiq. ■All exception modes versions registers R13 R14. ■All exception modes dedicated saved program status register (SPSR).528 cHaPter 14 / Processor structure Function general - purpose registers Register R13 normally used stack pointer also known SP. exception mode separate R13, exception mode dedicated program stack. R14 known link register (LR) used hold subroutine return addresses exception mode returns. Register R15 program counter (PC). program status registers CPSR accessible processor modes. exception mode also dedicated SPSR used preserve value CPSR associated exception occurs.Modes Privileged modes Exception modes User System Supervisor Abort Unde/f_ined Interrupt Fast interrupt R0 R0 R0 R0 R0 R0 R0 R1 R1 R1 R1 R1 R1 R1 R2 R2 R2 R2 R2 R2 R2 R3 R3 R3 R3 R3 R3 R3 R4 R4 R4 R4 R4 R4 R4 R5 R5 R5 R5 R5 R5 R5 R6 R6 R6 R6 R6 R6 R6 R7 R7 R7 R7 R7 R7 R7 R8 R8 R8 R8 R8 R8 R8_/f_iq R9 R9 R9 R9 R9 R9 R9_/f_iq R10 R10 R10 R10 R10 R10 R10_/f_iq R11 R11 R11 R11 R11 R11 R11_/f_iq R12 R12 R12 R12 R12 R12 R12_/f_iq R13(SP) R13(SP) R13_svc R13_abt R13_und R13_irq R13_/f_iq R14(LR) R14(LR) R14_svc R14_abt R14_und R14_irq R14_/f_iq R15(PC) R15(PC) R15(PC) R15(PC) R15(PC) R15(PC) R15(PC) CPSR CPSR CPSR CPSR CPSR CPSR CPSR SPSR_svc SPSR_abt SPSR_und SPSR_irq SPSR_/f_iq Shading indicates normal gister used User System mode replaced alternati register speci/f_ic e xception mode. SP = stack pointer CPSR = current program status gister LR = link gister SPSR = saved program status gister PC = program counter Figure 14.26 ARM Register Organization14.6 / arM Processor 529 16 significant bits CPSR contain user flags visible User mode, used affect operation program (Figure 14.27). follows: ■Condition code flags: N, Z, C, V flags, discussed Chapter 12. ■Q flag: used indicate whether overflow and/or saturation occurred SIMD- oriented instructions. ■J bit: indicates use special 8-bit instructions, known Jazelle instruc - tions, beyond scope discussion. ■GE[3:0] bits: SIMD instructions use bits [19:16] Greater Equal (GE) flags individual bytes halfwords result. 16 least significant bits CPSR contain system control flags altered processor privileged mode. fields follows: ■E bit: Controls load store endianness data; ignored instruction fetches. ■Interrupt disable bits: bit disables imprecise data aborts set; bit disables IRQ interrupts set; F bit disables FIQ interrupts set. ■T bit: Indicates whether instructions interpreted normal ARM instructions Thumb instructions. ■Mode bits: Indicates processor mode. Interrupt Processing processor, ARM includes facility enables processor interrupt currently executing program deal exception conditions. Exceptions generated internal external sources cause processor handle event. processor state handling exception normally preserved original program resumed exception routine completed. one exception arise time. ARM archi - tecture supports seven types exceptions. Table 14.4 lists types exception processor mode used process type. exception occurs, execution forced fixed memory address corresponding type excep - tion. fixed addresses called exception vectors. one interrupt outstanding, handled priority order. Table 14.4 lists exceptions priority order, highest lowest. exception occurs, processor halts execution current instruction. state processor preserved SPSR corresponds Res JReserve System contr ol /f_lags User /f_lagsGE[3:0] Reserve dE AI FT M[4:0] QVCZN0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31 Figure 14.27 Format ARM CPSR SPSR530 cHaPter 14 / Processor structure Function Table 14.4 ARM Interrupt Vector Exception type ModeNormal entry address Description Reset Supervisor 0x00000000 Occurs system initialized. Data abort Abort 0x00000010 Occurs invalid memory address accessed, physical memory address correct access permission lacking. FIQ (fast interrupt) FIQ 0x0000001C Occurs external device asserts FIQ pin processor. interrupt - interrupted except FIQ. FIQ designed support data transfer channel process, sufficient private registers remove need register saving applications, therefore min - imizing overhead context switching. fast interrupt cannot interrupted. IRQ (interrupt) IRQ 0x00000018 Occurs external device asserts IRQ pin processor. interrupt cannot interrupted except FIQ. Prefetch abort Abort 0x0000000C Occurs attempt fetch instruction results memory fault. exception raised instruction enters execute stage pipeline. Undefined instructions Undefined 0x00000004 Occurs instruction instruction set reaches execute stage pipeline. Software interrupt Supervisor 0x00000008 Generally used allow user mode pro- grams call OS. user program executes SWI instruction argu- ment identifies function user wishes perform. type exception, original program resumed excep - tion routine completed. address instruction processor execute placed link register appropriate processor mode. return handling exception, SPSR moved CPSR R14 moved PC. 14.7 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms branch prediction condition code delayed branchflag instruction cycle instruction pipelineinstruction prefetch program status word (PSW)14.7 / Key terMs, review Questions, Proble Ms 531 Review Questions 14.1 general roles performed processor registers? 14.2 categories data commonly supported user- visible registers? 14.3 function condition codes? 14.4 program status word? 14.5 two- stage instruction pipeline unlikely cut instruction cycle time half, compared use pipeline? 14.6 List briefly explain various ways instruction pipeline deal conditional branch instructions. 14.7 history bits used branch prediction? Problems 14.1 a. last operation performed computer 8-bit word addition two operands 00000010 00000011, would value following flags? ■Carry ■Zero ■Overflow ■Sign ■Even Parity ■ Half- Carry b. Repeat addition -1 (twos complement) +1. 14.2 Repeat Problem 14.1 operation A-B, contains 11110000 B con - tains 0010100. 14.3 microprocessor clocked rate 5 GHz. a. long clock cycle? b. duration particular type machine instruction consisting three clock cycles? 14.4 microprocessor provides instruction capable moving string bytes one area memory another. fetching initial decoding instruction takes 10 clock cycles. Thereafter, takes 15 clock cycles transfer byte. microprocessor clocked rate 10 GHz. a. Determine length instruction cycle case string 64 bytes. b. worst- case delay acknowledging interrupt instruction noninterruptible? c. Repeat part (b) assuming instruction interrupted beginning byte transfer. 14.5 Intel 8088 consists bus interface unit (BIU) execution unit (EU), form 2-stage pipeline. BIU fetches instructions 4-byte instruction queue. BIU also participates address calculations, fetches operands, writes results memory requested EU. requests outstanding bus free, BIU fills vacancies instruction queue. EU completes execution instruction, passes results BIU (destined memory I/O) proceeds next instruction. a. Suppose tasks performed BIU EU take equal time. factor pipelining improve performance 8088? Ignore effect branch instructions. b. Repeat calculation assuming EU takes twice long BIU. 14.6 Assume 8088 executing program probability program jump 0.1. simplicity, assume instructions 2 bytes long.532 cHaPter 14 / Processor structure Function a. fraction instruction fetch bus cycles wasted? b. Repeat instruction queue 8 bytes long. 14.7 Consider timing diagram Figures 14.10. Assume two- stage pipeline (fetch, execute). Redraw diagram show many time units needed four instructions. 14.8 Assume pipeline four stages: fetch instruction (FI), decode instruction cal - culate addresses (DA), fetch operand (FO), execute (EX). Draw diagram sim - ilar Figure 14.10 sequence 7 instructions, third instruction branch taken data dependencies. 14.9 pipelined processor clock rate 2.5 GHz executes program 1.5 mil - lion instructions. pipeline five stages, instructions issued rate one per clock cycle. Ignore penalties due branch instructions out- of- sequence executions. a. speedup processor program compared nonpipe - lined processor, making assumptions used Section 14.4? b. throughput (in MIPS) pipelined processor? 14.10 nonpipelined processor clock rate 2.5 GHz average CPI (cycles per instruction) 4. upgrade processor introduces five- stage pipeline. However, due internal pipeline delays, latch delay, clock rate new processor reduced 2 GHz. a. speedup achieved typical program? b. MIPS rate processor? 14.11 Consider instruction sequence length n streaming instruc - tion pipeline. Let p probability encountering conditional unconditional branch instruction, let q probability execution branch instruction causes jump nonconsecutive address. Assume jump requires pipeline cleared, destroying ongoing instruction processing, emerges last stage. Revise Equations (14.1) (14.2) take probabilities account. 14.12 One limitation multiple- stream approach dealing branches pipeline additional branches encountered first branch resolved. Suggest two additional limitations drawbacks. 14.13 Consider state diagrams Figure 14.28. a. Describe behavior each. b. Compare branch prediction state diagram Section 14.4. Discuss relative merits three approaches branch prediction. 14.14 Motorola 680x0 machines include instruction Decrement Branch Accord - ing Condition, following form: DBcc Dn, displacement cc one testable conditions, Dn general- purpose register, dis - placement specifies target address relative current address. instruction defined follows: (cc = False) begin Dn: = (Dn) -1; Dn Z -1 PC: = (PC) + displacement end else PC: = (PC) + 2; instruction executed, condition first tested determine whether termination condition loop satisfied. so, operation performed execution continues next instruction sequence. condition false, specified data register decremented checked see less zero. 14.7 / Key terMs, review Questions, Proble Ms 533 less zero, loop terminated execution continues next instruction sequence. Otherwise, program branches specified location. consider following assembly- language program fragment: CMPM.L (A0)+, (A1)+ DBNE D1, NOP Two strings addressed A0 A1 compared equality; string pointers incremented reference. D1 initially contains number longwords (4 bytes) compared. a. initial contents registers A0=$00004000, A1=$00005000 D1=$000000FF (the $ indicates hexadecimal notation). Memory $4000 $6000 loaded words $AAAA. foregoing program run, specify number times DBNE loop executed contents three registers NOP instruction reached. b. Repeat (a), assume memory $4000 $4FEE loaded $0000 $5000 $6000 loaded $AAA. 14.15 Redraw Figures 14.19c, assuming conditional branch taken. 14.16 Table 14.5 summarizes statistics [MACD84] concerning branch behavior var - ious classes applications. exception type 1 branch behavior, noticeable difference among application classes. Determine fraction branches go branch target address scientific environment. Repeat commercial systems environments. 14.17 Pipelining applied within ALU speed floating- point operations. Con - sider case floating- point addition subtraction. simplified terms, pipe - line could four stages: (1) Compare exponents; (2) Choose exponent align significands; (3) Add subtract significands; (4) Normalize results. taken takenNot takenTaken Taken takenTakenTaken Predict takenPredict taken Predict takenPredict takenNot taken takenTaken takenTaken taken TakenTaken Predict takenPredict taken Predict takenPredict taken Figure 14.28 Two Branch Prediction State Diagrams534 cHaPter 14 / Processor structure Function pipeline considered two parallel threads, one handling exponents one handling significands, could start like this: RaExponents b RASigni/f_icands B figure, boxes labeled R refer set registers used hold temporary results. Complete block diagram shows top level structure pipeline.Table 14.5 Branch Behavior Sample Applications Occurrence branch classes: Type 1: Branch 72.5% Type 2: Loop control 9.8% Type 3: Procedure call, return 17.7% Type 1 branch: goes Scientific Commercial Systems Unconditional— 100% go target 20% 40% 35% Conditional— went target 43.2% 24.3% 32.5% Conditional— go target (inline) 36.8% 35.7% 32.5% Type 2 branch (all environments) go target 91% go inline 9% Type 3 branch 100% go target535 CHAPTER Reduced InstRuctIon set compute Rs 15.1 Instruction Execution Characteristics Operations Operands Procedure Calls Implications 15.2 Use Large Register File Register Windows Global Variables Large Register File versus Cache 15.3 Compiler- Based Register Optimization 15.4 Reduced Instruction Set Architecture CISC Characteristics Reduced Instruction Set Architectures CISC versus RISC Characteristics 15.5 RISC Pipelining Pipelining Regular Instructions Optimization Pipelining 15.6 MIPS R4000 Instruction Set Instruction Pipeline 15.7 SPARC SPARC Register Set Instruction Set Instruction Format 15.8 RISC versus CISC Controversy 15.9 Key Terms, Review Questions, Problems 536 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs Since development stored- program computer around 1950, remarkably true innovations areas computer organization architecture. following major advances since birth computer: ■The family concept: Introduced IBM System/360 1964, followed shortly thereafter DEC, PDP- 8. family concept decouples architecture machine implementation. set computers offered, different price/performance characteristics, presents architecture user. differences price performance due different implementations architecture. ■Microprogrammed control unit: Suggested Wilkes 1951 introduced IBM S/360 line 1964. Microprogramming eases task design - ing implementing control unit provides support family concept. ■Cache memory: First introduced commercially IBM S/360 Model 85 1968. insertion element memory hierarchy dramatically improves performance. ■Pipelining: means introducing parallelism essentially sequential nature machine- instruction program. Examples instruction pipelining vector processing. ■Multiple processors: category covers number different organizations objectives. ■Reduced instruction set computer (RISC) architecture: focus chapter. appeared, RISC architecture dramatic departure - torical trend processor architecture. analysis RISC architecture brings focus many important issues computer organization architecture.Learning Objectives studying chapter, able to: rProvide overview research results instruction execution characteristics motivated development RISC approach. rSummarize key characteristics RISC machines. rUnderstand design performance implications using large register file. rUnderstand use compiler- based register optimization improve performance. rDiscuss implication RISC architecture pipeline design performance. rList explain key approaches pipeline optimization RISC machine.15.1 / Ins TRuCTIon Ex ECuTIon C HARACTERI sTICs 537 Although RISC architectures defined designed variety ways different groups, key elements shared designs these: ■A large number general- purpose registers, and/or use compiler tech - nology optimize register usage. ■A limited simple instruction set. ■An emphasis optimizing instruction pipeline. Table 15.1 compares several RISC non- RISC systems. begin chapter brief survey results instruction sets, examine three topics listed. followed descrip - tion two best- documented RISC designs. 15.1 INSTRUCTION EXECUTION CHARACTERISTICS One visible forms evolution associated computers pro - gramming languages. cost hardware dropped, relative cost soft - ware risen. Along that, chronic shortage programmers driven software costs absolute terms. Thus, major cost life cycle system software, hardware. Adding cost, inconvenience, element unreliability: common programs, system application, continue exhibit new bugs years operation. response researchers industry develop ever powerful complex high- level programming languages. high- level lan - guages (HLLs) : (1) allow programmer express algorithms concisely; (2) allow compiler take care details important program - mer’s expression algorithms; (3) often support naturally use structured programming and/or object- oriented design. Alas, solution gave rise perceived problem, known seman - tic gap , difference operations provided HLLs pro - vided computer architecture. Symptoms gap alleged include execution inefficiency, excessive machine program size, compiler com - plexity. Designers responded architectures intended close gap. Key features include large instruction sets, dozens addressing modes, var - ious HLL statements implemented hardware. example latter CASE machine instruction VAX. complex instruction sets intended to: ■Ease task compiler writer. ■Improve execution efficiency, complex sequences operations implemented microcode. ■Provide support even complex sophisticated HLLs. Meanwhile, number studies done years determine characteristics patterns execution machine instructions generated HLL programs. results studies inspired researchers look 538 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs Table 15.1 Characteristics CISCs, RISCs, Superscalar Processors Complex Instruction Set (CISC)ComputerReduced Instruction Set (RISC) Computer Characteristic IBM 370/168VAX 11/780Intel 80486SPARC MIPS R4000 Year developed 1973 1978 1989 1987 1991 Number instructions 208 303 235 69 94 Instruction size (bytes) 2–6 2–57 1–11 4 4 Addressing modes 4 22 11 1 1 Number general- purpose registers16 16 8 40–520 32 Control memory size (kbits)420 480 246 — — Cache size (kB) 64 64 8 32 128 Superscalar Characteristic PowerPC Ultra SPARCMIPS R10000 Year developed 1993 1996 1996 Number instructions 225 Instruction size (bytes) 4 4 4 Addressing modes 2 1 1 Number general- purpose registers32 40–520 32 Control memory size (kbits)— — — Cache size (kB) 16–32 32 64 different approach: namely, make architecture supports HLL simpler, rather complex. understand line reasoning RISC advocates, begin brief review instruction execution characteristics. aspects computation interest follows: ■Operations performed: determine functions performed processor interaction memory. ■Operands used: types operands frequency use deter - mine memory organization storing addressing modes accessing them. ■Execution sequencing: determines control pipeline organization.15.1 / Ins TRuCTIon Ex ECuTIon C HARACTERI sTICs 539 remainder section, summarize results number studies high- level- language programs. results based dynamic measurements. is, measurements collected executing program counting number times feature appeared particular property held true. contrast, static measurements merely perform counts source text program. give useful information performance, weighted relative number times statement executed. Operations variety studies made analyze behavior HLL programs. Table 4.7 , discussed Chapter 4, includes key results number studies. quite good agreement results mixture languages appli - cations. Assignment statements predominate, suggesting simple move - ment data high importance. also preponderance conditional statements (IF, LOOP). statements implemented machine language sort compare branch instruction. suggests sequence control mechanism instruction set important. results instructive machine instruction set designer, indicating types statements occur often therefore supported “optimal” fashion. However, results reveal statements use time execution typical program. is, want answer question: Given compiled machine- language program, statements source language cause execution machine- language instructions execution time instructions? get underlying phenomenon, Patterson programs [PATT82a], described Appendix 4A, compiled VAX, PDP- 11, Motorola 68000 determine average number machine instructions memory refer - ences per statement type. second third columns Table 15.2 show rel- ative frequency occurrence various HLL statements variety programs; data obtained observing occurrences running programs rather number times statements occur source code. Hence metrics capture dynamic behavior. obtain data columns four five ( machine- instruction weighted), value second third columns multiplied number machine instructions produced compiler. results normalized columns four five show relative fre - quency occurrence, weighted number machine instructions per HLL statement. Similarly, sixth seventh columns obtained multiplying frequency occurrence statement type relative number memory references caused statement. data columns four seven pro - vide surrogate measures actual time spent executing various statement types. results suggest procedure call/return time- consuming operation typical HLL programs. reader clear significance Table 15.2. table indi - cates relative performance impact various statement types HLL, 540 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs HLL compiled typical contemporary instruction set architecture. architecture could conceivably produce different results. However, study produces results representative contemporary complex instruction set computer (CISC) architectures. Thus, provide guidance looking efficient ways support HLLs. Operands Much less work done occurrence types operands, despite importance topic. several aspects significant. Patterson study already referenced [PATT82a] also looked dynamic frequency occurrence classes variables (Table 15.3). results, consistent Pascal C programs, show references simple scalar variables. Further, 80% scalars local (to procedure) var - iables. addition, reference array structure requires reference index pointer, usually local scalar. Thus, preponder - ance references scalars, highly localized. Patterson study examined dynamic behavior HLL programs, independent underlying architecture. discussed before, necessary deal actual architectures examine program behavior deeply. One study, [LUND77], examined DEC- 10 instructions dynamically found instruction average references 0.5 operand memory 1.4 reg - isters. Similar results reported [HUCK83] C, Pascal, FORTRAN programs S/370, PDP- 11, VAX. course, figures depend highly architecture compiler, illustrate frequency operand accessing.Table 15.2 Weighted Relative Dynamic Frequency HLL Operations [PATT82a] Dynamic Occurrence Machine- Instruction Weighted Memory- Reference Weighted Pascal C Pascal C Pascal C ASSIGN 45% 38% 13% 13% 14% 15% LOOP 5% 3% 42% 32% 33% 26% CALL 15% 12% 31% 33% 44% 45% 29% 43% 11% 21% 7% 13% GOTO — 3% — — — — 6% 1% 3% 1% 2% 1% Table 15.3 Dynamic Percentage Operands Pascal C Average Integer constant 16% 23% 20% Scalar variable 58% 53% 55% Array/Structure 26% 24% 25%15.1 / Ins TRuCTIon Ex ECuTIon C HARACTERI sTICs 541 latter studies suggest importance architecture lends fast operand accessing, operation performed frequently. Patterson study suggests prime candidate optimization mechanism storing accessing local scalar variables. Procedure Calls seen procedure calls returns important aspect HLL pro - grams. evidence (Table 15.2) suggests time- consuming operations compiled HLL programs. Thus, profitable consider ways implementing operations efficiently. Two aspects significant: num - ber parameters variables procedure deals with, depth nesting. Tanenbaum’s study [TANE78] found 98% dynamically called pro - cedures passed fewer six arguments 92% used fewer six local scalar variables. Similar results reported Berkeley RISC team [KATE83], shown Table 15.4. results show number words required per procedure activation large. studies reported ear - lier indicated high proportion operand references local scalar varia - bles. studies show references fact confined relatively variables. Berkeley group also looked pattern procedure calls returns HLL programs. found rare long uninterrupted sequence procedure calls followed corresponding sequence returns. Rather, found program remains confined rather narrow window procedure- invocation depth. illustrated Figure 4.21, discussed Chapter 4. results reinforce conclusion operand references highly localized. Implications number groups looked results reported con - cluded attempt make instruction set architecture close HLLs effective design strategy. Rather, HLLs best supported opti - mizing performance time- consuming features typical HLL programs. Table 15.4 Procedure Arguments Local Scalar Variables Percentage Executed Procedure Calls WithCompiler, Interpreter, TypesetterSmall Nonnumeric Programs > 3 arguments 0–7% 0–5% > 5 arguments 0–3% 0% > 8 words arguments local scalars1–20% 0–6% > 12 words arguments local scalars1–6% 0–3%542 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs Generalizing work number researchers, three elements emerge that, large, characterize RISC architectures. First, use large number registers use compiler optimize register usage. intended optimize operand referencing. studies discussed show several refer - ences per HLL statement high proportion move (assignment) statements. This, coupled locality predominance scalar references, suggests performance improved reducing memory references expense register references. locality references, expanded register set seems practical. Second, careful attention needs paid design instruction pipe - lines. high proportion conditional branch procedure call instructions, straightforward instruction pipeline inefficient. man - ifests high proportion instructions prefetched never executed. Finally, instruction set consisting high- performance primitives indi - cated. Instructions predictable costs (measured execution time, code size, increasingly, energy dissipation) consistent high- performance implementation (which harmonizes predictable execution- time cost). 15.2 USE LARGE REGISTER FILE results summarized Section 15.1 point desirability quick access operands. seen large proportion assignment statements HLL programs, many simple form AdB. Also, significant number operand accesses per HLL statement. couple results fact accesses local scalars, heavy reliance register storage suggested. reason register storage indicated fastest available storage device, faster main memory cache. register file phys - ically small, chip ALU control unit, employs much shorter addresses addresses cache memory. Thus, strategy needed allow frequently accessed operands kept registers minimize register- memory operations. Two basic approaches possible, one based software hardware. software approach rely compiler maximize reg - ister usage. compiler attempt assign registers variables used given time period. approach requires use sophisticated program- analysis algorithms. hardware approach simply use registers variables held registers longer periods time. section, discuss hardware approach. approach pioneered Berkeley RISC group [PATT82a]; used first commer - cial RISC product, Pyramid [RAGA83]; currently used popular SPARC architecture.15.2 / usE LARgE REgIsTER fILE 543 Register Windows face it, use large set registers decrease need access memory. design task organize registers fashion goal realized. operand references local scalars, obvious approach store registers, perhaps registers reserved global vari - ables. problem definition local changes procedure call return, operations occur frequently. every call, local variables must saved registers memory, registers reused called procedure. Furthermore, parameters must passed. return, vari - ables calling procedure must restored (loaded back registers) results must passed back calling procedure. solution based two results reported Section 15.1. First, typical procedure employs passed parameters local variables (Table 15.4). Second, depth procedure activation fluctuates within rela - tively narrow range (Figure 4.21). exploit properties, multiple small sets registers used, assigned different procedure. procedure call auto - matically switches processor use different fixed- size window registers, rather saving registers memory. Windows adjacent procedures - lapped allow parameter passing. concept illustrated Figure 15.1. time, one window reg - isters visible addressable set registers (e.g., addresses 0 N-1). window divided three fixed- size areas. Parameter registers hold parameters passed procedure called current procedure hold results passed back up. Local registers used local variables, assigned compiler. Temporary registers used exchange parameters results next lower level (procedure called current proce - dure). temporary registers one level physically parameter registers next lower level. overlap permits parameters passed - actual movement data. Keep mind that, except overlap, reg - isters two different levels physically distinct. is, parameter local registers level J disjoint local temporary registers level J+1. handle possible pattern calls returns, number register windows would unbounded. Instead, register windows used hold recent procedure activations. Older activations must saved Parameter registersLocal registersTemporary registersLevel J Parameter registersCall/r eturn Local registersTemporary registersLevel J + 1 Figure 15.1 Overlapping Register Windows544 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs memory later restored nesting depth decreases. Thus, actual organization register file circular buffer overlapping windows. Two notable examples approach Sun’s SPARC architecture, described Sec - tion 15.7, IA- 64 architecture used Intel’s Itanium processor. circular organization shown Figure 15.2, depicts circular buffer six windows. buffer filled depth 4 (A called B; B called C; C called D) procedure active. current- window pointer (CWP) points window currently active procedure. Register references machine instruction offset pointer determine actual physical register. saved- window pointer (SWP) identifies window recently saved memory. procedure calls procedure E, arguments E placed D’s tempo - rary registers (the overlap w3 w4) CWP advanced one window. procedure E makes call procedure F, call cannot made current status buffer. F’s window overlaps A’s window. F begins load temporary registers, preparatory call, overwrite parameter registers (A.in). Thus, CWP incremented (modulo 6) becomes equal SWP, interrupt occurs, A’s window saved. Current window pointerSaved window pointerSaveRestore A.param w0 w1 w2 w3 w4w5A.temp = B.param B.temp = C.param C.temp = D.paramA.locB.loc C.loc D.loc (E)(F) Call Return Figure 15.2 Circular- Buffer Organization Overlapped Windows15.2 / usE LARgE REgIsTER fILE 545 first two portions (A.in A.loc) need saved. Then, SWP incremented call F proceeds. similar interrupt occur returns. example, subsequent activation F, B returns A, CWP decremented becomes equal SWP. causes interrupt results restoration A’s window. preceding, seen N- window register file hold N-1 procedure activations. value N need large. men - tioned Appendix 4A, one study [TAMI83] found that, 8 windows, save restore needed 1% calls returns. Berkeley RISC computers use 8 windows 16 registers each. Pyramid computer employs 16 windows 32 registers each. Global Variables window scheme described provides efficient organization storing local scalar variables registers. However, scheme address need store global variables, accessed one procedure. Two options suggest themselves. First, variables declared global HLL assigned memory locations compiler, machine instructions reference variables use memory- reference operands. straightforward, hardware software (compiler) points view. However, frequently accessed global variables, scheme inefficient. alternative incorporate set global registers processor. registers would fixed number available procedures. unified num - bering scheme used simplify instruction format. example, refer - ences registers 0 7 could refer unique global registers, references registers 8 31 could offset refer physical registers current window. increased hardware burden accommodate split regis - ter addressing. addition, linker must decide global variables assigned registers. Large Register File versus Cache register file, organized windows, acts small, fast buffer holding sub - set variables likely used heavily. point view, register file acts much like cache memory, although much faster memory. question therefore arises whether would simpler better use cache small traditional register file. Table 15.5 compares characteristics two approaches. window- based register file holds local scalar variables (except rare case window overflow) recent N-1 procedure activations. cache holds selec - tion recently used scalar variables. register file save time, local scalar variables retained. hand, cache may make efficient use space, reacting situation dynamically. - more, caches generally treat memory references alike, including instructions types data. Thus, savings areas possible cache register file.546 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs register file may make inefficient use space, procedures need full window space allotted them. hand, cache suffers another sort inefficiency: Data read cache blocks. Whereas register file contains variables use, cache reads block data, much used. cache capable handling global well local variables. usually many global scalars, heavily used [KATE83]. cache dynamically discover variables hold them. window- based register file supplemented global registers, hold global sca - lars. However, program modules separately compiled, impossible compiler assign global values registers; linker must perform task. register file, movement data registers memory determined procedure nesting depth. depth usually fluctuates within narrow range, use memory relatively infrequent. cache mem - ories set associative small set size. Thus, danger data instructions compete cache residency. Based discussion far, choice large window- based reg - ister file cache clear- cut. one characteristic, however, register approach clearly superior suggests cache- based sys - tem noticeably slower. distinction shows amount addressing overhead experienced two approaches. Figure 15.3 illustrates difference. reference local scalar window- based register file, “virtual” register number window number used. pass relatively simple decoder select one physical reg - isters. reference memory location cache, full- width memory address must generated. complexity operation depends addressing mode. set associative cache, portion address used read number words tags equal set size. Another portion address compared tags, one words read selected. clear even cache fast register file, access time considerably longer. Thus, point view performance, window- based register file supe - rior local scalars. performance improvement could achieved addition cache instructions only.Table 15.5 Characteristics Large- Register- File Cache Organizations Large Register File Cache local scalars Individual variables Compiler- assigned global variables Save/Restore based procedure nesting depth Register addressing Multiple operands addressed accessed one cycle Recently- used local scalars Blocks memory Recently- used global variables Save/Restore based cache replacement algorithm Memory addressing One operand addressed accessed per cycle15.3 / ComPILER r-­AsEd REgIsTER oPTImI iATIon 547 15.3 COMPILER- BASED REGISTER OPTIMIZATION Let us assume small number (e.g., 16–32) registers available target RISC machine. case, optimized register usage responsibility compiler. program written high- level language has, course, explicit references registers (the C- language keyword register notwithstanding). Rather, program quantities referred symbolically. objective compiler keep operands many computations possible registers rather main memory, minimize load- and- store operations. general, approach taken follows. program quantity candidate residing register assigned symbolic virtual register. compiler maps unlimited number symbolic registers fixed number real registers. Symbolic registers whose usage overlap share real register. If, particular portion program, quantities deal real registers, quantities assigned memory locations. Load- and- store instructions used position quantities registers temporarily computational operations.Data DecoderInstruction Registers (a) Windo w-based gister /f_ile (b) CacheR W# Instruction Tags Data DataSelect Compar e Figure 15.3 Referencing Scalar548 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs essence optimization task decide quantities assigned registers given point program. technique com - monly used RISC compilers known graph coloring, technique bor - rowed discipline topology [CHAI82, CHOW86, COUT86, CHOW90]. graph coloring problem this. Given graph consisting nodes edges, assign colors nodes adjacent nodes different colors, way minimize number different colors. problem adapted compiler problem following way. First, program ana - lyzed build register interference graph. nodes graph symbolic registers. two symbolic registers “live” program fragment, joined edge depict interference. attempt made color graph n colors, n number registers. Nodes share color assigned register. process fully succeed, nodes cannot colored must placed memory, loads stores must used make space affected quantities needed. Figure 15.4 simple example process. Assume program six symbolic registers compiled three actual registers. Figure 15.4a shows time sequence active use symbolic register. dashed horizontal lines indicate successive instruction executions. Figure 15.4b shows register interfer - ence graph (shading stripes used instead colors). possible coloring three colors indicated. symbolic registers interfere, compile assign physical register R1. Similarly, symbolic registers C E assigned register R3. One symbolic register, F, left uncolored must dealt using loads stores. general, trade- use large set registers compiler- based register optimization. example, [BRAD91a] reports study R1 R2 R3 (a) Time sequence acti use gisters (b) gister interference graphB BCSymbolic r egisters Actual r egistersTimeDE EF CFA DD E Figure 15.4 Graph Coloring Approach15.4 / R EduCEd Ins TRuCTIon sET ARCHITECT uRE 549 modeled RISC architecture features similar Motorola 88000 MIPS R2000. researchers varied number registers 16 128, considered use general- purpose registers registers split integer floating- point use. study showed even simple register optimization, little benefit use 64 registers. reasonably sophisticated register optimization techniques, marginal performance improvement 32 registers. Finally, noted small number registers (e.g., 16), machine shared register organi - zation executes faster one split organization. Similar conclusions drawn [HUGU91], reports study primarily concerned optimizing use small number registers rather comparing use large register sets optimization efforts. 15.4 REDUCED INSTRUCTION SET ARCHITECTURE section, look general characteristics motivation reduced instruction set architecture. Specific examples seen later chapter. begin discussion motivations contemporary complex instruction set architectures. CISC noted trend richer instruction sets, include larger number instructions complex instructions. Two principal reasons moti - vated trend: desire simplify compilers desire improve performance. Underlying reasons shift HLLs part programmers; architects attempted design machines provided better support HLLs. intent chapter say CISC designers took wrong direction. Indeed, technology continues evolve archi - tectures exist along spectrum rather two neat categories, black- and- white assessment unlikely ever emerge. Thus, comments follow simply meant point potential pitfalls CISC approach pro - vide understanding motivation RISC adherents. first reasons cited, compiler simplification, seems obvious, not. task compiler writer build compiler generates good (fast, small, fast small) sequences machine instructions HLL programs (i.e., compiler views individual HLL statements context surrounding HLL state - ments). machine instructions resemble HLL statements, task simplified. reasoning disputed RISC researchers ([HENN82], [RADI83], [PATT82b]). found complex machine instructions often hard exploit compiler must find cases exactly fit construct. task optimizing generated code minimize code size, reduce instruction execution count, enhance pipelining much difficult complex instruction set. evidence this, studies cited earlier chap - ter indicate instructions compiled program relatively simple ones.550 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs major reason cited expectation CISC yield smaller, faster programs. Let us examine aspects assertion: programs smaller execute faster. two advantages smaller programs. program takes less memory, savings resource. memory today inex - pensive, potential advantage longer compelling. important, smaller programs improve performance, happen three ways. First, fewer instructions means fewer instruction bytes fetched. Second, paging environment, smaller programs occupy fewer pages, reducing page faults. Third, instructions fit cache(s). problem line reasoning far certain CISC program smaller corresponding RISC program. many cases, CISC program, expressed symbolic machine language, may shorter (i.e., fewer instructions), number bits memory occupied may noticeably smaller. Table 15.6 shows results three studies compared size com - piled C programs variety machines, including RISC I, reduced instruction set architecture. Note little savings using CISC RISC. also interesting note VAX, much complex instruction set PDP- 11, achieves little savings latter. results confirmed IBM researchers [RADI83], found IBM 801 (a RISC) produced code 0.9 times size code IBM S/370. study used set PL/I programs. several reasons rather surprising results. already noted compilers CISCs tend favor simpler instructions, con - ciseness complex instructions seldom comes play. Also, instructions CISC, longer opcodes required, producing longer instructions. Finally, RISCs tend emphasize register rather memory refer - ences, former require fewer bits. example last effect discussed presently. expectation CISC produce smaller programs, atten - dant advantages, may realized. second motivating factor increasingly complex instruction sets instruction execution would faster. seems make sense complex HLL operation execute quickly single machine instruction rather series primitive instructions. However, bias toward use simpler instructions, may so. Table 15.6 Code Size Relative RISC [PATT82a] 11 C Programs[KATE83] 12 C Programs[HEAT84] 5 C Programs RISC 1.0 1.0 1.0 VAX- 11/780 0.8 0.67 M68000 0.9 0.9 Z8002 1.2 1.12 PDP- 11/70 0.9 0.7115.4 / R EduCEd Ins TRuCTIon sET ARCHITECT uRE 551 entire control unit must made complex, and/or microprogram con - trol store must made larger, accommodate richer instruction set. Either factor increases execution time simple instructions. fact, researchers found speedup execution com - plex functions due much power complex machine instructions residence high- speed control store [RADI83]. effect, control store acts instruction cache. Thus, hardware architect position trying determine subroutines functions used frequently assigning control store implementing microcode. results less encouraging. S/390 systems, instructions Translate Extended- Precision- Floating- Point- Divide reside high- speed storage, sequence involved setting procedure calls initiating interrupt handler slower main memory. Thus, far clear trend increasingly complex instruction sets appropriate. led number groups pursue opposite path. Characteristics Reduced Instruction Set Architectures Although variety different approaches reduced instruction set architecture taken, certain characteristics common them: ■One instruction per cycle ■ Register- to- register operations ■Simple addressing modes ■Simple instruction formats Here, provide brief discussion characteristics. Specific examples explored later chapter. first characteristic listed one machine instruction per machine cycle . machine cycle defined time takes fetch two oper - ands registers, perform ALU operation, store result register. Thus, RISC machine instructions complicated than, execute fast as, microinstructions CISC machines (discussed Part Four). simple, one- cycle instructions, little need microcode; machine instructions hardwired. instructions execute faster compa - rable machine instructions machines, necessary access microprogram control store instruction execution. second characteristic operations register register , simple LOAD STORE operations accessing memory. design feature simplifies instruction set therefore control unit. example, RISC instruction set may include one two ADD instructions (e.g., integer add, add carry); VAX 25 different ADD instructions. Another benefit architecture encourages optimization register use, fre - quently accessed operands remain high- speed storage. emphasis register- to- register operations notable RISC designs. Contemporary CISC machines provide instructions also include memory- to- memory mixed register/memory operations. Attempts compare 552 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs approaches made 1970s, appearance RISCs. Figure 15.5a illustrates approach taken. Hypothetical architectures evaluated pro - gram size number bits memory traffic. Results one led one researcher suggest future architectures contain registers [MYER78]. One wonders would thought, time, RISC machine produced Pyramid, contained less 528 registers! missing studies recognition frequent access small number local scalars that, large bank registers opti - mizing compiler, operands could kept registers long periods time. Thus, Figure 15.5b may fairer comparison. third characteristic use simple addressing modes . Almost RISC instructions use simple register addressing. Several additional modes, dis - placement PC- relative, may included. Other, complex modes synthesized software simple ones. Again, design feature simplifies instruction set control unit. final common characteristic use simple instruction formats . Gen - erally, one formats used. Instruction length fixed aligned word boundaries. Field locations, especially opcode, fixed. design fea - ture number benefits. fixed fields, opcode decoding register oper - accessing occur simultaneously. Simplified formats simplify control unit. Instruction fetching optimized word- length units fetched. Alignment word boundary also means single instruction cross page boundaries. Taken together, characteristics assessed determine poten - tial performance benefits RISC approach. certain amount “circumstantial Add8 B16 C16 A16 Add8 B16 C16 A16 Add AC B Sub BD DMemory memory = 56, = 96, = 152 Memory memory = 168, = 288, = 456 = number bytes occupied executed instructions = number bytes occupied data = total memory traf/f_ic = + DRegister memory = 60, = 0, = 60Register memory = 104, = 96, = 200Load Load Add Add AddStoreRB RB RBRBRC RC RC RCB B AR RA RA Sub RD RB RDR A84 4 84 416 (a) B + C (b) B + C; B + C; − B Figure 15.5 Two Comparisons Register- to- Register Memory- to- Memory Approaches15.4 / R EduCEd Ins TRuCTIon sET ARCHITECT uRE 553 evidence” presented. First, effective optimizing compilers devel - oped. more- primitive instructions, opportunities moving functions loops, reorganizing code efficiency, maximizing register utili - zation, forth. even possible compute parts complex instructions compile time. example, S/390 Move Characters (MVC) instruction moves string characters one location another. time executed, move depend length string, whether direction locations overlap, alignment characteristics are. cases, known compile time. Thus, compiler could produce optimized sequence primitive instructions function. second point, already noted, instructions generated com - piler relatively simple anyway. would seem reasonable control unit built specifically instructions using little microcode could execute faster comparable CISC. third point relates use instruction pipelining. RISC researchers feel instruction pipelining technique applied much effectively reduced instruction set. examine point detail presently. final, somewhat less significant, point RISC processors responsive interrupts interrupts checked rather elemen - tary operations. Architectures complex instructions either restrict interrupts instruction boundaries must define specific interruptible points implement mechanisms restarting instruction. case improved performance reduced instruction set architecture strong, one could perhaps still make argument CISC. number studies done, machines comparable technology power. Further, studies attempted separate effects reduced instruction set effects large register file. “circumstantial evidence,” however, suggestive. CISC versus RISC Characteristics initial enthusiasm RISC machines, growing realization (1) RISC designs may benefit inclusion CISC features (2) CISC designs may benefit inclusion RISC features. result recent RISC designs, notably PowerPC, longer “pure” RISC recent CISC designs, notably Pentium II later Pentium models, incorporate RISC characteristics. interesting comparison [MASH95] provides insight issue. Table 15.7 lists number processors compares across number char - acteristics. purposes comparison, following considered typical classic RISC: 1. single instruction size. 2. size typically 4 bytes. 3. small number data addressing modes, typically less five. parameter difficult pin down. table, register literal modes counted different formats different offset sizes counted separately.Table 15.7 Characteristics Processors ProcessorNumber instruction sizesMax instruction size bytesNumber addressing modesIndirect addressingLoad/store combined arithmeticMax number memory operandsUnaligned addressing allowedMax number MMU usesNumber bits integer register specifierNumber bits FP register specifier AMD29000 1 4 1 1 1 8 3a MIPS R2000 1 4 1 1 1 5 4 SPARC 1 4 2 1 1 5 4 MC88000 1 4 3 1 1 5 4 HP PA 1 4 10ano 1 1 5 4 IBM RT/PC 2a4 1 1 1 4a3a IBM RS/6000 1 4 4 1 yes 1 5 5 Intel i860 1 4 4 1 1 5 4 IBM 3090 4 8 2bnob yes 2 yes 4 4 2 Intel 80486 12 12 15 nob yes 2 yes 4 3 3 NSC 32016 21 21 23 yes yes 2 yes 4 3 3 MC68040 11 22 44 yes yes 2 yes 8 4 3 VAX 56 56 22 yes yes 6 yes 24 4 0 Clipper 4a 8a9ano 1 0 2 4a3a Intel 80960 2a 8a9ano 1 yesa— 5 3a Notes : RISC conform characteristic. b CISC conform characteristic. 55415.5 / R IsC PIPELInIng 555 4. indirect addressing requires make one memory access get address another operand memory. 5. operations combine load/store arithmetic (e.g., add mem - ory, add memory). 6. one memory- addressed operand per instruction. 7. support arbitrary alignment data load/store operations. 8. Maximum number uses memory management unit (MMU) data address instruction. 9. Number bits integer register specifier equal five more. means least 32 integer registers explicitly referenced time. 10. Number bits floating- point register specifier equal four more. means least 16 floating- point registers explicitly referenced time. Items 1 3 indication instruction decode complexity. Items 4 8 suggest ease difficulty pipelining, especially presence virtual memory requirements. Items 9 10 related ability take good advantage compilers. table, first eight processors clearly RISC architectures, next five clearly CISC, last two processors often thought RISC fact many CISC characteristics. 15.5 RISC PIPELINING Pipelining Regular Instructions discussed Section 12.4, instruction pipelining often used enhance per - formance. Let us reconsider context RISC architecture. instruc - tions register register, instruction cycle following two stages: ■I: Instruction fetch. ■E: Execute. Performs ALU operation register input output. load store operations, three stages required: ■I: Instruction fetch. ■E: Execute. Calculates memory address. ■D: Memory. Register- to- memory memory- to- register operation. Figure 15.6a depicts timing sequence instructions using pipe - lining. Clearly, wasteful process. Even simple pipelining substan - tially improve performance. Figure 15.6b shows two- stage pipelining scheme, E stages two different instructions performed simultane - ously. two stages pipeline instruction fetch stage, execute/ memory stage executes instruction, including register- to- memory memory- to- register operations. Thus see instruction fetch stage 556 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs second instruction performed parallel first part execute/ memory stage. However, execute/memory stage second instruction must delayed first instruction clears second stage pipeline. scheme yield twice execution rate serial scheme. Two problems prevent maximum speedup achieved. First, assume single- port memory used one memory access possible per stage. requires insertion wait state instructions. Second, branch instruc - tion interrupts sequential flow execution. accommodate mini - mum circuitry, NOOP instruction inserted instruction stream compiler assembler. Pipelining improved permitting two memory accesses per stage. yields sequence shown Figure 15.6c. Now, three instructions overlapped, improvement much factor 3. Again, branch instructions cause speedup fall short maximum possible. Also, note data dependencies effect. instruction needs operand altered preceding instruction, delay required. Again, accom - plished NOOP. pipelining discussed far works best three stages approxi - mately equal duration. E stage usually involves ALU operation, may longer. case, divide two substages: ■E1: Register file read ■E2: ALU operation register write simplicity regularity RISC instruction set, design phasing three four stages easily accomplished. Figure 15.6d shows result four- stage pipeline. four instructions time way, maximum potential speedup factor 4. Note use NOOPs account data branch delays.I E1E2D E1E2 E1E2 E1E2 E1E2D E1E2 E1E2 E1E2 E1E2D NOOP NOOP Branch XI E E E E E E NOOPBranch X NOOP NOOP (d) F our-stage pipelined timing(b) Two-stage pipelined timingI E E E E E Branch X (a) Sequential execution E E E E E E E NOOP Branch X NOOP (c) Three-stage pipelined timingLoad rA Load rB Add rC rA + rB Store rCLoad rA Load rB Add rC rA + rB Store rC Load rA Load rB Add rC rA + rB Store rCLoad rA Load rB Add rC rA + rB Store rC Figure 15.6 Effects Pipelining15.5 / R IsC PIPELInIng 557 Optimization Pipelining simple regular nature RISC instructions, easier hard - ware designer implement simple, fast pipeline. variations instruc - tion execution duration, pipeline tailored reflect this. However, seen data branch dependencies reduce overall execution rate. delayed branch compensate dependencies, code reorganization techniques developed. First, let us consider branching instructions. Delayed branch , way increasing efficiency pipeline, makes use branch take effect execution following instruction (hence term delayed ). instruction location immediately following branch referred delay slot . strange procedure illustrated Table 15.8. column labeled “normal branch,” see normal symbolic instruction machine- language program. 102 executed, next instruction executed 105. regularize pipeline, NOOP inserted branch. However, increased performance achieved instructions 101 102 interchanged. Figure 15.7 shows result. Figure 15.7a shows traditional approach pipelining, type discussed Chapter 14 (e.g., see Figures 14.11 14.12). JUMP instruction fetched time 4. time 5, JUMP instruction executed time instruction 103 (ADD instruction) fetched. JUMP occurs, updates program counter, pipeline must cleared instruc - tion 103; time 6, instruction 105, target JUMP, loaded. Fig - ure 15.7b shows pipeline handled typical RISC organization. timing same. However, insertion NOOP instruction, need special circuitry clear pipeline; NOOP simply executes effect. Figure 15.7c shows use delayed branch. JUMP instruction fetched time 2, ADD instruction, fetched time 3. Note, however, ADD instruction fetched execution JUMP instruction chance alter program counter. Therefore, time 4, ADD instruction executed time instruction 105 fetched. Thus, original semantics program retained two fewer clock cycles required execution. interchange instructions work successfully unconditional branches, calls, returns. conditional branches, procedure cannot blindly applied. condition tested branch altered Table 15.8 Normal Delayed Branch Address Normal Branch Delayed BranchOptimized Delayed Branch 100 LOAD X, rA LOAD X, rA LOAD X, rA 101 ADD 1, rA ADD 1, rA JUMP 105 102 JUMP 105 JUMP 106 ADD 1, rA 103 ADD rA, rB NOOP ADD rA, rB 104 SUB rC, rB ADD rA, rB SUB rC, rB 105 STORE rA, Z SUB rC, rB STORE rA, Z 106 STORE rA, Z558 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs immediately preceding instruction, compiler must refrain interchange instead insert NOOP. Otherwise, compiler seek insert useful instruction branch. experience Berkeley RISC IBM 801 systems majority conditional branch instructions optimized fashion ([PATT82a], [RADI83]). delayed load similar sort tactic, called delayed load , used LOAD instructions. LOAD instructions, register target load locked processor. processor continues execution instruction stream reaches instruction requiring register, point idles load complete. compiler rearrange instructions useful work done load pipeline, efficiency increased. Loop Unrolling Simulator(a) Traditional pipeline100 LOAD X, rATime 101 ADD 1, rA 102 JUMP 105 103 ADD rA, rB 105 STORE rA, Z (b) RISC pipeline inserted NOOP100 LOAD X, rA1 101 ADD 1, rA 102 JUMP 106 103 NOOP 106 STORE rA, Z (c) Reversed instructions100 LOAD X, Ar 101 JUMP 105 102 ADD 1, rA 105 STORE rA, Z2 3 4 5 6 78 IE IE IE IED IE 1 2 3 4 5 6 78 IE IE IE IED IE 1 2 3 4 5 6 IE IE ED IE Figure 15.7 Use Delayed Branch15.6 / mIPs R4000 559 loop unrolling Another compiler technique improve instruction parallelism loop unrolling [BACO94]. Unrolling replicates body loop number times called unrolling factor ( u) iterates step u instead step 1. Unrolling improve performance ■reducing loop overhead ■increasing instruction parallelism improving pipeline performance ■improving register, data cache, TLB locality Figure 15.8 illustrates three improvements example. Loop overhead cut half two iterations performed test branch end loop. Instruction parallelism increased sec - ond assignment performed results first stored loop variables updated. array elements assigned registers, register locality improve a[ i] a[i+1] used twice loop body, reducing number loads per iteration three two. final note, point design instruction pipeline carried isolation optimization techniques applied system. example, [BRAD91b] shows scheduling instructions pipeline dynamic allocation registers considered together achieve greatest efficiency. 15.6 MIPS R4000 One first commercially available RISC chip sets developed MIPS Technology Inc. system inspired experimental system, also using name MIPS, developed Stanford [HENN84]. section look MIPS i=2, n−1 a[i] = a[i] + a[i−1] * a[i+1] end (a) Original loop i=2, n−2, 2 a[i] = a[i] + a[i−1] * a[i+1] a[i+1] = a[i+1] + a[i] * a[i+2] end (mod(n−2, 2) = i) a[n−1] = a[n−1] + a[n−2] * a[n] end (b) Loop unrolled twice Figure 15.8 Loop Unrolling560 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs R4000. substantially architecture instruction set earlier MIPS designs: R2000 R3000. significant difference R4000 uses 64 rather 32 bits internal external data paths addresses, registers, ALU. use 64 bits number advantages 32-bit architecture. allows bigger address space— large enough operating system map terabyte files directly virtual memory easy access. 1-tera - byte larger disk drives common, 4-gigabyte address space 32-bit machine becomes limiting. Also, 64-bit capacity allows R4000 process data IEEE double- precision floating- point numbers character strings, eight characters single action. R4000 processor chip partitioned two sections, one containing CPU containing coprocessor memory management. pro - cessor simple architecture. intent design system instruction execution logic simple possible, leaving space available logic enhance performance (e.g., entire memory- management unit). processor supports thirty- two 64-bit registers. also provides 128 Kbytes high- speed cache, half instructions data. relatively large cache (the IBM 3090 provides 128 256 Kbytes cache) enables system keep large sets program code data local processor, off- loading main memory bus avoiding need large register file accompa - nying windowing logic. Instruction Set MIPS R series instructions encoded single 32-bit word format. data operations register register; memory references pure load/store operations. R4000 makes use condition codes. instruction generates con - dition, corresponding flags stored general- purpose register. avoids need special logic deal condition codes, affect pipelining mechanism reordering instructions compiler. Instead, mecha - nisms already implemented deal register- value dependencies employed. Further, conditions mapped onto register files subject compile- time optimizations allocation reuse values stored registers. RISC- based machines, MIPS uses single 32-bit instruction length. single instruction length simplifies instruction fetch decode, also simplifies interaction instruction fetch virtual memory man - agement unit (i.e., instructions cross word page boundaries). three instruction formats (Figure 15.9) share common formatting opcodes register references, simplifying instruction decode. effect complex instructions synthesized compile time. simplest frequently used memory- addressing mode implemented hardware. memory references consist 16-bit offset 32-bit register. example, “load word” instruction form lw r2, 128(r3) /* load word address 128 offset register 3 register 215.6 / mIPs R4000 561 32 general- purpose registers used base register. One reg - ister, r0, always contains 0. compiler makes use multiple machine instructions synthesize typical addressing modes conventional machines. example [CHOW87], uses instruction lui (load upper immediate). instruction loads upper half register 16-bit immediate value, setting lower half zero. Consider assembly- language instruction uses 32-bit immediate argument lw r2, #imm(r4) /* load word address using 32-bit immediate offset #imm /* offset register 4 register 2 instruction compiled following MIPS instructions lui r1, # imm- hi /* # imm- hi high- order 16 bits #imm addu r1, r1, r4 /* add unsigned # imm- hi r4 put r1 lw r2, # imm- lo(r1) /* # imm- lo low- order 16 bits #imm Instruction Pipeline simplified instruction architecture, MIPS achieve efficient pipe - lining. instructive look evolution MIPS pipeline, illustrates evolution RISC pipelining general. initial experimental RISC systems first generation commercial RISC processors achieve execution speeds approach one instruction per system clock cycle. improve performance, two classes processors evolved Operation Operation Operation code rs Sour ce register speci/f_ier rt Sour ce/destination r egister speci/f_ier Immediate Immediate, branch, addr ess displacement Target Jump target addr ess rd Destination r egister speci/f_ier Shift Shift amount Function ALU/shift function speci/f_ierI-type (immediate)rs65 51 6 rt Immediate OperationJ-type (jump)6 26 Target OperationR-type (register)rs65 5 5 rt rd56 Shift Function Figure 15.9 MIPS Instruction Formats562 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs offer execution multiple instructions per clock cycle: superscalar super - pipelined architectures. essence, superscalar architecture replicates pipeline stages two instructions stage pipeline processed simultaneously. superpipelined architecture one makes use more, fine- grained, pipeline stages. stages, instruc - tions pipeline time, increasing parallelism. approaches limitations. superscalar pipelining, dependencies instructions different pipelines slow system. Also, over- head logic required coordinate dependencies. superpipelining, overhead associated transferring instructions one stage next. Chapter 16 devoted study superscalar architecture. MIPS R4000 good example RISC- based superpipeline architecture. MIPS R3000 Five-Stage Pipeline Simulator Figure 15.10a shows instruction pipeline R3000. R3000, pipeline advances per clock cycle. MIPS compiler able reorder instructions fill delay slots code 70 90% time. instructions fol - low sequence five pipeline stages: ■Instruction fetch; ■Source operand fetch register file; ■ALU operation data operand address generation; ■Data memory reference; ■Write back register file. illustrated Figure 15.10a, parallelism due pipelining also parallelism within execution single instruction. 60-ns clock cycle divided two 30-ns stages. external instruction data access oper - ations cache require 60 ns, major internal operations (OP, DA, IA). Instruction decode simpler operation, requiring single 30-ns stage, overlapped register fetch instruction. Calculation address branch instruction also overlaps instruction decode register fetch, branch instruction address ICACHE access instruction i+2. Sim - ilarly, load instruction fetches data immediately used OP instruction i+1, ALU/shift result gets passed directly instruction i+1 delay. tight coupling instructions makes highly efficient pipeline. detail, then, clock cycle divided separate stages, denoted f1 f2. functions performed stage summarized Table 15.9. R4000 incorporates number technical advances R3000. use advanced technology allows clock cycle time cut half, Clock Cycle CycleIF = Instruction fetch RD = Read MEM = Memory access WB = Write back r egister /f_ile I-Cache = Instruction cache access RF = Fetch operand fr om register D-Cache = Data cache access ITLB = Instruction addr ess translation IDEC = Instruction decode IA = Compute instruction addr ess DA = Calculate data virtual addr ess DTLB = Data addr ess translation TC = Data cache tag checkI-Cache (a) Detailed R3000 pipeline (b) Modi/f_ied R3000 pipeline reduced latenciesRF IDEC DA DTLB ITLB ITLBCycle I-Cache ALU DTLB D-CacheCycle Cycle Cycle Cycle RF WB Cycle (c) Optimized R3000 pipeline parallel TLB cache accessesITLBCycle ALU D-Cache TCCycle Cycle Cycle RF WBIAD-Cache WB ALU OPRD ALU MEMW B1/uni03D5 1/uni03D5 1/uni03D5 1/uni03D5 1/uni03D5 2/uni03D5 2/uni03D5 2/uni03D5 2/uni03D5 2/uni03D5 Figure 15.10 Enhancing R3000 Pipeline Table 15.9 R3000 Pipeline Stages Pipeline Stage Phase Function f1 Using TLB, translate instruction virtual address physical address (after branching decision). f2 Send physical address instruction address. RD f1 Return instruction instruction cache. Compare tags validity fetched instruction. RD f2 Decode instruction. Read register file. branch, calculate branch target address. ALU f1+f2 register- to- register operation, arithmetic logical operation performed. ALU f1 branch, decide whether branch taken not. memory reference (load store), calculate data virtual address. ALU f2 memory reference, translate data virtual address physical using TLB. MEM f1 memory reference, send physical address data cache. MEM f2 memory reference, return data data cache, check tags. WB f1 Write register file. 563564 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs 30 ns, access time register file cut half. addition, greater density chip, enables instruction data caches incorporated chip. looking final R4000 pipeline, let us con - sider R3000 pipeline modified improve performance using R4000 technology. Figure 15.10b shows first step. Remember cycles figure half long Figure 15.10a. chip, instruc - tion data cache stages take half long; still occupy one clock cycle. Again, speedup register file access, register read write still occupy half clock cycle. R4000 caches on- chip, virtual- to- physical address trans - lation delay cache access. delay reduced implementing virtually indexed caches going parallel cache access address translation. Fig - ure 15.10c shows optimized R3000 pipeline improvement. compression events, data cache tag check performed separately next cycle cache access. check determines whether data item cache. superpipelined system, existing hardware used several times per cycle inserting pipeline registers split pipe stage. Essentially, superpipe - line stage operates multiple base clock frequency, multiple depending degree superpipelining. R4000 technology speed density permit superpipelining degree 2. Figure 15.11a shows optimized R3000 pipeline using superpipelining. Note essentially dynamic structure Figure 15.10c. improvements made. R4000, much larger spe - cialized adder designed. makes possible execute ALU operations Clock Cycle IC1 = Instruction fetch /f_irst half = Instruction fetch second half RF = Fetch operands fr om register EX = Instruction execute IC = Instruction cacheDC = Data cache DF = Data cache /f_irst half DS = Data cache second half TC = Tag check WB = Write back r egister /f_ile(a) Superpipelined implementation optimized R3000 pipelineRF ALU DC2 TC2 IC2 ALU DC1 TC1W B IC1 RF ALU DC2 TC2 IC2 ALU DC1 TC1 WB Clock Cycle (b) R4000 pipelineRF DFT C EX DSW B RF DFT C EX DSW B1/uni03D5 2/uni03D5 2/uni03D52/uni03D5 2/uni03D5 2/uni03D5 1/uni03D5 1/uni03D5 1/uni03D5 Figure 15.11 Theoretical R3000 Actual R4000 Superpipelines15.7 / sPARC 565 twice rate. improvements allow execution loads stores twice rate. resulting pipeline shown Figure 15.11b. R4000 eight pipeline stages, meaning many eight instruc - tions pipeline time. pipeline advances rate two stages per clock cycle. eight pipeline stages follows: ■Instruction fetch first half: Virtual address presented instruction cache translation lookaside buffer. ■Instruction fetch second half: Instruction cache outputs instruction TLB generates physical address. ■Register file: Three activities occur parallel: — Instruction decoded check made interlock conditions (i.e., instruction depends result preceding instruction). —Instruction cache tag check made. —Operands fetched register file. ■Instruction execute: One three activities occur: — instruction register- to- register operation, ALU performs arithmetic logical operation. —If instruction load store, data virtual address calculated. — instruction branch, branch target virtual address calculated branch conditions checked. ■Data cache first: Virtual address presented data cache TLB. ■Data cache second: TLB generates physical address, data cache outputs data. ■Tag check: Cache tag checks performed loads stores. ■Write back: Instruction result written back register file. 15.7 SPARC SPARC (Scalable Processor Architecture) refers architecture defined Sun Microsystems. Sun developed SPARC implementation also licenses architecture vendors produce SPARC- compatible machines. SPARC architecture inspired Berkeley RISC machine, instruction set register organization based closely Berkeley RISC model. SPARC Register Set Berkeley RISC, SPARC makes use register windows. win - dow gives addressability 24 registers, total number windows imple - mentation dependent ranges 2 32 windows. Figure 15.12 illustrates implementation supports 8 windows, using total 136 physical registers; discussion Section 15.2 indicates, seems reasonable number win - dows. Physical registers 0 7 global registers shared procedures. 566 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs procedure sees logical registers 0 31. Logical registers 24 31, referred ins, shared calling (parent) procedure; logical registers 8 15, referred outs, shared called (child) procedure. two portions overlap windows. Logical registers 16 23, referred locals , shared overlap windows. Again, dis - cussion Section 12.1 indicates, availability 8 registers parameter passing adequate cases (e.g., see Table 15.4). Figure 15.13 another view register overlap. calling procedure places parameters passed outs registers; called procedure treats physical registers ins registers. processor maintains current window pointer (CWP), located processor status register (PSR), points window currently executing procedure. window invalid mask (WIM), also PSR, indicates windows invalid.Physical registers 135                        128InsLogical r egisters Procedur e AP rocedur e BP rocedur e C 127 120Locals 119 112Outs/Ins 111 104Locals 103 96Outs/Ins 95 88Locals 87 80Outs    7 0Globals           Ins Locals Outs        Ins Locals Outs        Ins LocalsR31 C R24 C R23 C R16 C R15 C R8C R31 B R24 B R23 B R16 B R15 B R8BR31 R24 R23 R16 R15 R8A Outs    R7 R0Globals     R7 R0Globals     R7 R0Globals Figure 15.12 SPARC Register Window Layout Three Procedures15.7 / sPARC 567 SPARC register architecture, usually necessary save restore registers procedure call. compiler simplified compiler need concerned allocating local registers procedure effi - cient manner need concerned register allocation procedures. Instruction Set SPARC instructions reference register operands. Register- to- register instructions three operands expressed form RdSRS1 op S2 Rd RS1 register references; S2 refer either register 13-bit immediate operand. Register zero (R0) hardwired value 0. form well suited typical programs, high proportion local scalars constants. available ALU operations grouped follows: ■Integer addition (with without carry). ■Integer subtraction (with without carry). ■Bitwise Boolean AND, OR, XOR negations. ■Shift left logical, right logical, right arithmetic.w4 localsw2 localsw0 locals w6 locals w6 insw6 outsw0 outs w2 outs w4 outsw4 ins w5 localsw5 outs w5 insw77 localsCWP WIM w7 insw1 locals w1 outsw7 outsw1 ins w3 locals w3 outsw3 insw2 insw0 ins Figure 15.13 Eight Register Windows Forming Circular Stack SPARC568 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs instructions, except shifts, optionally set four condi - tion codes (ZERO, NEGATIVE, OVERFLOW, CARRY). Signed integers represented 32-bit twos complement form. simple load store instructions reference memory. separate load store instructions word (32 bits), doubleword, halfword, byte. latter two cases, instructions loading quantities signed unsigned numbers. Signed numbers sign extended fill 32-bit destina - tion register. Unsigned numbers padded zeros. available addressing mode, register, displacement mode. is, effective address (EA) operand consists displacement address contained register: EA=(RS1)+S2 EA =(RS1)+(RS2) depending whether second operand immediate register reference. perform load store, extra stage added instruction cycle. second stage, memory address calculated using ALU; load store occurs third stage. single addressing mode quite versatile used synthesize addressing modes, indicated Table 15.10. instructive compare SPARC addressing capability MIPS. MIPS makes use 16-bit offset, compared 13-bit offset SPARC. hand, MIPS permit address con - structed contents two registers. Instruction Format MIPS R4000, SPARC uses simple set 32-bit instruction formats (Figure 15.14). instructions begin 2-bit opcode. instructions, extended additional opcode bits elsewhere format. Call instruc - tion, 30-bit immediate operand extended two zero bits right form 32-bit PC- relative address twos complement form. Instructions aligned 32-bit boundary form addressing suffices. Branch instruction includes 4-bit condition field corresponds four standard condition code bits, combination conditions tested. 22-bit PC- relative address extended two zero bits right Table 15.10 Synthesizing Addressing Modes SPARC Addressing Modes Instruction Type Addressing Mode Algorithm SPARC Equivalent Register- to- register Immediate operand=A S2 Load, store Direct EA=A R0+S2 Register- to- register Register EA=R RS1, SS2 Load, store Register Indirect EA=(R) RS1+0 Load, store Displacement EA=(R)+A RS1+S2 Note : S2=either register operand 13-bit immediate operand.15.7 / sPARC 569 form 24-bit twos complement relative address. unusual feature Branch instruction annul bit. annul bit set, instruction branch always executed, regardless whether branch taken. typical delayed branch operation found many RISC machines described Section 15.5 (see Figure 15.7). However, annul bit set, instruction following branch executed branch taken. processor sup - presses effect instruction even though already pipeline. annul bit useful makes easier compiler fill delay slot following conditional branch. instruction target branch always put delay slot, branch taken, instruction annulled. reason technique desirable conditional branches generally taken half time. SETHI instruction special instruction used form 32-bit constant. feature needed form large data constants; example, used form large offset load store instruction. SETHI instruction sets 22 high- order bits register 22-bit immediate operand, zeros low- order 10 bits. immediate constant 13 bits specified one general formats, instruction could used fill remaining 10 bits register. load store instruction also used achieve direct Op Call f ormat PC-r elative displacement23 0 Branch formatOpaCond Op2 PC-r elative displacement OpSETHI format Floating- point format2 Dest5 Op23 Immediate constant2221 43 22 25 69 55 Op Dest Op3 FP-op Src-1 Src-2 General formats2 5 6 Op Dest Op38 Ignor ed51 Src-15 Src-2 0 Op Dest Op3 Immediate constant Src-1 1 Figure 15.14 SPARC Instruction Formats570 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs addressing mode. load value location K memory, could use fol - lowing SPARC instructions: sethi %hi(K), %r8 ;load high- order 22 bits address location ;K register r8 Ld [,r8+,lo(K)], %r8 ;load contents location K r8 macros %hi %lo used define immediate operands consisting appropriate address bits location. use SETHI similar use lui instruction MIPS. floating- point format used floating- point operations. Two source one destination registers designated. Finally, operations, including loads, stores, arithmetic, logical operations use one last two formats shown Figure 15.14. One formats makes use two source registers destination register, uses one source register, one 13-bit immediate operand, one destination register. 15.8 RISC VERSUS CISC CONTROVERSY many years, general trend computer architecture organization toward increasing processor complexity: instructions, addressing modes, specialized registers, on. RISC movement represents fun - damental break philosophy behind trend. Naturally, appearance RISC systems, publication papers proponents extolling RISC virtues, led reaction involved design CISC architectures. work done assessing merits RISC approach grouped two categories: ■Quantitative: Attempts compare program size execution speed pro - grams RISC CISC machines use comparable technology. ■Qualitative: Examines issues high- level language support opti - mum use VLSI real estate. work quantitative assessment done working RISC systems [PATT82b, HEAT84, PATT84], been, large, favorable RISC approach. Others examined issue come away unconvinced [COLW85a, FLYN87, DAVI87]. several problems attempting comparisons [SERL86]: ■There pair RISC CISC machines comparable life- cycle cost, level technology, gate complexity, sophistication compiler, operating system support, on. ■No definitive test set programs exists. Performance varies program. ■It difficult sort hardware effects effects due skill compiler writing. ■Most comparative analysis RISC done “toy” machines rather commercial products. Furthermore, commercially available 15.9 / K Ey TERms, R EvIEw Qu EsTIons, PRo­LEms 571 machines advertised RISC possess mixture RISC CISC character - istics. Thus, fair comparison commercial, “ pure- play” CISC machine (e.g., VAX, Pentium) difficult. qualitative assessment is, almost definition, subjective. Several research - ers turned attention assessment [COLW85a, WALL85], results are, best, ambiguous, certainly subject rebuttal [PATT85b] and, course, counterrebuttal [COLW85b]. recent years, RISC versus CISC controversy died great extent. gradual convergence tech - nologies. chip densities raw hardware speeds increase, RISC systems become complex. time, effort squeeze maximum per - formance, CISC designs focused issues traditionally associated RISC, increased number general- purpose registers increased emphasis instruction pipeline design. 15.9 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms complex instruction set com- puter (CISC) delayed branch delayed load high- level language (HLL) reduced instruction set computer (RISC) register fileregister window SPARC Review Questions 15.1 typical distinguishing characteristics RISC organization? 15.2 Briefly explain two basic approaches used minimize register- memory opera - tions RISC machines. 15.3 circular register buffer used handle local variables nested procedures, describe two approaches handling global variables. 15.4 typical characteristics RISC instruction set architecture? 15.5 delayed branch? Problems 15.1 Considering call- return pattern Figure 4.21, many overflows - flows (each causes register save/restore) occur window size a. 5? b. 8? c. 16? 15.2 discussion Figure 15.2, stated first two portions win - dow saved restored. necessary save temporary registers? 15.3 wish determine execution time given program using various pipe - lining schemes discussed Section 15.5. Let572 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs N=number executed instructions D=number memory accesses J=number jump instructions simple sequential scheme (Figure 15.6a), execution time 2N+D stages. Derive formulas two- stage, three- stage, four- stage pipelining. 15.4 Reorganize code sequence Figure 15.6d reduce number NOOPs. 15.5 Consider following code fragment high- level language: 1…100 loop + Q(I). VAL end loop; Assume Q array 32-byte records VAL field first 4 bytes record. Using x86 code, compile program fragment follows: MOV ECX,1 ;use register ECX hold LP: IMUL EAX, ECX, 32 ;get offset EAX MOV EBX, Q[EAX] ;load VAL field ADD S, EBX ;add INC ECX ;increment CMP ECX, 101 :compare 101 JNE LP ;loop I=100 program makes use IMUL instruction, multiplies second oper - immediate value third operand places result first operand (see Problem 10.13). RISC advocate would like demonstrate clever compiler eliminate unnecessarily complex instructions IMUL. Pro - vide demonstration rewriting x86 program without using IMUL instruction. 15.6 Consider following loop: := 0; K:=1 100 S:=S-K; straightforward translation generic assembly language would look something like this: LD R1, 0 ;keep value R1 LD R2,1 ;keep value K R2 LP SUB R1, R1, R2 ;S:=S-K BEQ R2, 100, EXIT ;done K=100 ADD R2, R2, 1 ;else increment K JMP LP ;back start loop compiler RISC machine introduce delay slots code processor employ delayed branch mechanism. JMP instruction easy deal with, instruction always followed SUB instruction; therefore, 15.9 / K Ey TERms, R EvIEw Qu EsTIons, PRo­LEms 573 simply place copy SUB instruction delay slot JMP . BEQ presents difficulty. can’t leave code is, ADD instruction would executed one many times. Therefore, NOP instruction needed. Show resulting code. 15.7 RISC machine’s compiler may mapping symbolic registers actual registers rearrangement instructions pipeline efficiency. interesting question arises order two operations done. Consider following program fragment: LD SR1, ;load symbolic register 1 LD SR2, B ;load B symbolic register 2 ADD SR3, SR1, SR2 ;add contents SR1 SR2 store SR3 LD SR4, C LD SR5, ADD SR6, SR4, SR5 a. First register mapping possible instruction reordering. many machine registers used? pipeline improvement? b. Starting original program, instruction reordering possible mapping. many machine registers used? pipeline improvement? 15.8 Add entries following processors Table 15.7: a. Pentium II b. ARM 15.9 many cases, common machine instructions listed part MIPS instruction set synthesized single MIPS instruction. Show following: a. Register- to- register move b. Increment, decrement c. Complement d. Negate e. Clear 15.10 SPARC implementation K register windows. number N physical registers? 15.11 SPARC lacking number instructions commonly found CISC machines. easily simulated using either register R0, always set 0, constant operand. simulated instructions called pseudoinstructions recognized SPARC assembler. Show simulate following pseudoin - structions, single SPARC instruction. these, src dst refer registers. ( Hint : store R0 effect.) a. MOV src, dst b. COMPARE src1, src2 c. TEST src1d. dst e. NEG dst f. INC dstg. DEC dst h. CLR dst i. NOP 15.12 Consider following code fragment: K > 10 L := K + 1 else L := K – 1574 CHAPTER 15 / R EduCEd Ins TRuCTIon sET Com PuTERs straightforward translation statement SPARC assembler could take following form: sethi %hi(K), %r8 ;load high- order 22 bits address location ;K register r8 ld [,r8+,lo(K)], %r8 ;load contents location K r8 cmp %r8, 10 ;compare contents r8 10 ble L1 ;branch (r8)…10 nop sethi %hi(K), %r9 ld [,r9+,lo(K)], %r9 ;load contents location K r9 inc %r9 ;add 1 (r9) sethi %hi(L), %r10 st %r9, [,r10+,lo(L)];store (r9) location L b L2 nop L1: sethi %hi(K), %r11 ld [,r11+,lo(K)], %r12 ;load contents location K r12 dec %r12 ;subtract 1 (r12) sethi %hi(L), %r13 st %r12, [,r13+,lo(L)];store (r12) location L L2: code contains nop branch instruction permit delayed branch operation. a. Standard compiler optimizations nothing RISC machines generally effective able perform two transformations foregoing code. Notice two loads unnecessary two stores merged store moved different place code. Show program making two changes. b. possible perform optimizations peculiar SPARC. nop ble replaced moving another instruction delay slot setting annul bit ble instruction (expressed ble,a L1). Show program change. c. two unnecessary instructions. Remove show resulting program.575CHAPTER Instruct Ion-LeveL ParaLLeLIsm suPersca Lar Processors 16.1 Overview Superscalar versus Superpipelined Constraints 16.2 Design Issues Instruction-Level Parallelism Machine Parallelism Instruction Issue Policy Register Renaming Machine Parallelism Branch Prediction Superscalar Execution Superscalar Implementation 16.3 Intel Core Microarchitecture Front End Out-of-Order Execution Logic Integer Floating-Point Execution Units 16.4 Arm Cortex-A8 Instruction Fetch Unit Instruction Decode Unit Integer Execute Unit SIMD Floating-Point Pipeline 16.5 ARM Cortex-M3 Pipeline Structure Dealing Branches 16.6 Key Terms, Review Questions, Problems 576 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS superscalar implementation processor architecture one common instructions—integer floating-point arithmetic, loads, stores, conditional branches—can initiated simultaneously executed independently. imple - mentations raise number complex design issues related instruction pipeline. Superscalar design arrived scene hard heels RISC architec - ture. Although simplified instruction set architecture RISC machine lends readily superscalar techniques, superscalar approach used either RISC CISC architecture. Whereas gestation period arrival commercial RISC machines beginning true RISC research IBM 801 Berkeley RISC seven eight years, first superscalar machines became commer - cially available within year two coining term superscalar . superscalar approach become standard method implementing high-performance microprocessors. chapter, begin overview superscalar approach, con - trasting superpipelining. Next, present key design issues associated superscalar implementation. look several important examples superscalar architecture. 16.1 OVERVIEW term superscalar , first coined 1987 [AGER87], refers machine designed improve performance execution scalar instructions. applications, bulk operations scalar quantities. Accordingly, superscalar approach represents next step evolution high-performance general-purpose processors. essence superscalar approach ability execute instructions independently concurrently different pipelines. concept exploited allowing instructions executed order different program order. Figure 16.1 compares, general terms, scalar superscalar approaches. traditional scalar organization, single pipelined func - tional unit integer operations one floating-point operations. Parallelism achieved enabling multiple instructions different stages pipeline Learning Objectives studying chapter, able to: rExplain difference superscalar superpipelined approaches. rDefine instruction-level parallelism. rDiscuss dependencies resource conflicts limitations instruction-level parallelism rPresent overview design issues involved instruction-level parallelism. rCompare contrast techniques improving pipeline performance RISC machines superscalar machines.16.1 / VERVIE w 577 one time. superscalar organization, multiple functional units, implemented pipeline. individual functional unit provides degree parallelism virtue pipelined structure. use multiple functional units enables processor execute streams instructions parallel, one stream pipeline. responsibility hardware, conjunction com - piler, assure parallel execution violate intent program. Many researchers investigated superscalar-like processors, research indicates degree performance improvement possible. Table 16.1 presents reported performance advantages. differences Integer r egister /f_ile Pipelined integer functional unitMemory Floating-point register /f_ile (a) Scalar ganizationPipelined /f_loating- point functional unit Integer r egister /f_ile Pipelined integer functional unitsMemory Floating-point register /f_ile (b) Superscalar ganizationPipelined /f_loating- point functional units Figure 16.1 Superscalar Organization Compared Ordinary Scalar Organization Table 16.1 Reported Speedups Superscalar-Like Machines Reference Speedup [TJAD70] 1.8 [KUCK77] 8 [WEIS84] 1.58 [ACOS86] 2.7 [SOHI90] 1.8 [SMIT89] 2.3 [JOUP89b] 2.2 [LEE91] 7578 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS results arise differences hardware simulated machine applications simulated. Superscalar versus Superpipelined alternative approach achieving greater performance referred super - pipelining, term first coined 1988 [JOUP88]. Superpipelining exploits fact many pipeline stages perform tasks require less half clock cycle. Thus, doubled internal clock speed allows performance two tasks one external clock cycle. seen one example approach MIPS R4000. Figure 16.2 compares two approaches. upper part diagram illus - trates ordinary pipeline, used base comparison. base pipeline issues Ifetch 01234 5Successive instructions 67 8 Time base cycles9Key: DecodeExecute Write Superpipelined SuperscalarSimple 4-stage pipeline Figure 16.2 Comparison Superscalar Superpipeline Approaches16.1 / VERVIE w 579 one instruction per clock cycle perform one pipeline stage per clock cycle. pipeline four stages: instruction fetch; operation decode; operation execu - tion; result write back. execution stage crosshatched clarity. Note although several instructions executing concurrently, one instruction execution stage one time. next part diagram shows superpipelined implementation capable performing two pipeline stages per clock cycle. alternative way looking functions performed stage split two nonoverlapping parts execute half clock cycle. superpipeline implementation behaves fashion said degree 2. Finally, lowest part diagram shows superscalar implementation capable execut - ing two instances stage parallel. Higher-degree superpipeline super - scalar implementations course possible. superpipeline superscalar implementations depicted Fig - ure 16.2 number instructions executing time steady state. superpipelined processor falls behind superscalar processor start program branch target. Constraints superscalar approach depends ability execute multiple instructions parallel. term instruction-level parallelism refers degree which, average, instructions program executed parallel. combination compiler-based optimization hardware techniques used maximize instruction-level parallelism. examining design techniques used super - scalar machines increase instruction-level parallelism, need look fun - damental limitations parallelism system must cope. [JOHN91] lists five limitations: ■True data dependency; ■Procedural dependency; ■Resource conflicts; ■Output dependency; ■Antidependency. examine first three limitations remainder section. discussion last two must await developments next section. true data dependency Consider following sequence:1 ADD EAX, ECX ;load register EAX con- ;tents ECX plus contents ;of EAX MOV EBX, EAX ;load EBX contents EAX second instruction fetched decoded cannot execute first instruction executes. reason second instruction needs data 1For Intel x86 assembly language, semicolon starts comment field.580 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS produced first instruction. situation referred true data depen - dency (also called flow dependency read write [RAW] dependency ). Figure 16.3 illustrates dependency superscalar machine degree 2. dependency, two instructions fetched executed paral - lel. data dependency first second instructions, second instruction delayed many clock cycles required remove dependency. general, instruction must delayed input values produced. simple pipeline, illustrated upper part Figure 16.2, aforementioned sequence instructions would cause delay. However, consider following, one loads memory rather register: MOV EAX, eff ;load register EAX contents effective memory address eff MOV EBX, EAX ;load EBX contents EAXi0 i1 i0 i1 i0 i1/branch i2 i3 i4 i5 i0 i1Ifetch 01234567 8 Time base cycles9Key: DecodeExecute Write dependency Data dependency (i1 uses data computed i0) Procedural dependency Resour ce con/f_lict (i0 i1 use functional unit) Figure 16.3 Effect Dependencies16.2 / ESIgN ISSUES 581 typical RISC processor takes two cycles perform load memory load cache hit. take tens even hundreds cycles cache miss cache levels, delay off-chip memory access. One way compensate delay compiler reorder instructions one subsequent instructions depend memory load begin flowing pipeline. scheme less effective case superscalar pipeline: independent instructions executed load likely executed first cycle load, leaving processor noth - ing load completes. procedural dependencies discussed Chapter 14, presence branches instruction sequence complicates pipeline operation. instructions following branch (taken taken) procedural dependency branch cannot executed branch executed. Figure 16.3 illustrates effect branch superscalar pipeline degree 2. seen, type procedural dependency also affects scalar pipe - line. consequence superscalar pipeline severe, greater magnitude opportunity lost delay. variable-length instructions used, another sort procedural dependency arises. length particular instruction known, must least partially decoded following instruction fetched. prevents simultaneous fetching required superscalar pipeline. one reasons superscalar techniques readily applicable RISC RISC-like architecture, fixed instruction length. resource conflict resource conflict competition two instructions resource time. Examples resources include memories, caches, buses, register-file ports, functional units (e.g., ALU adder). terms pipeline, resource conflict exhibits similar behavior data dependency (Figure 16.3). differences, however. one thing, resource conflicts overcome duplication resources, whereas true data depend - ency cannot eliminated. Also, operation takes long time complete, resource conflicts minimized pipelining appropriate functional unit. 16.2 DESIGN ISSUES Instruction-Level Parallelism Machine Parallelism [JOUP89a] makes important distinction two related concepts instruction-level parallelism machine parallelism. Instruction-level parallelism exists instructions sequence independent thus executed parallel overlapping. example concept instruction-level parallelism, consider following two code fragments [JOUP89b]: Load R1 R2 Add R3 R3, “1” Add R3 R3, “1” Add R4 R3, R2 Add R4 R4, R2 Store [R4] R0582 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS three instructions left independent, theory three could executed parallel. contrast, three instructions right cannot exe - cuted parallel second instruction uses result first, third instruction uses result second. degree instruction-level parallelism determined frequency true data dependencies procedural dependencies code. factors, turn, dependent instruction set architecture application. Instruction-level parallelism also determined [JOUP89a] refers operation latency: time result instruction available use operand subsequent instruction. latency determines much delay data procedural dependency cause. Machine parallelism measure ability processor take advan - tage instruction-level parallelism. Machine parallelism determined num - ber instructions fetched executed time (the number parallel pipelines) speed sophistication mechanisms processor uses find independent instructions. instruction-level machine parallelism important factors enhancing performance. program may enough instruction-level parallel - ism take full advantage machine parallelism. use fixed-length instruc - tion set architecture, RISC, enhances instruction-level parallelism. hand, limited machine parallelism limit performance matter nature program. Instruction Issue Policy mentioned, machine parallelism simply matter multiple instances pipeline stage. processor must also able identify instruc - tion-level parallelism orchestrate fetching, decoding, execution instructions parallel. [JOHN91] uses term instruction issue refer process initiating instruction execution processor’s functional units term instruction issue policy refer protocol used issue instructions. general, say instruction issue occurs instruction moves decode stage pipeline first execute stage pipeline. essence, processor trying look ahead current point execu - tion locate instructions brought pipeline executed. Three types orderings important regard: ■The order instructions fetched; ■The order instructions executed; ■The order instructions update contents register memory locations. sophisticated processor, less bound strict relation - ship orderings. optimize utilization various pipeline ele - ments, processor need alter one orderings respect ordering found strict sequential execution. one constraint processor result must correct. Thus, processor must accommo - date various dependencies conflicts discussed earlier.16.2 / ESIgN ISSUES 583 general terms, group superscalar instruction issue policies following categories: ■In-order issue in-order completion. ■In-order issue out-of-order completion. ■Out-of-order issue out-of-order completion. in-order issue in-order completion simplest instruction issue policy issue instructions exact order would achieved sequential execution ( in-order issue ) write results order ( in-order completion ). even scalar pipelines follow simple-minded policy. However, useful consider policy baseline comparing sophisticated approaches. Figure 16.4a gives example policy. assume superscalar pipeline capable fetching decoding two instructions time, three separate functional units (e.g., two integer arithmetic one floating-point arithmetic), two instances write-back pipeline stage. example assumes following constraints six-instruction code fragment: ■I1 requires two cycles execute. ■I3 I4 conflict functional unit. ■I5 depends value produced I4. ■I5 I6 conflict functional unit. Instructions fetched two time passed decode unit. instructions fetched pairs, next two instructions must wait pair decode pipeline stages cleared. guarantee in-order completion , conflict functional unit functional unit requires one cycle generate result, issuing instructions temporarily stalls. example, elapsed time decoding first instruction writing last results eight cycles. in-order issue out-of-order completion Out-of-order completion used scalar RISC processors improve performance instructions require multiple cycles. Figure 16.4b illustrates use superscalar processor. Instruction I2 allowed run completion prior I1. allows I3 completed earlier, net result savings one cycle. out-of-order completion, number instructions may exe - cution stage one time, maximum degree machine parallelism across functional units. Instruction issuing stalled resource conflict, data dependency, procedural dependency. addition aforementioned limitations, new dependency, referred earlier output dependency (also called write write [WAW] dependency ), arises. following code fragment illustrates dependency ( op represents operation): I1: R3 R3 op R5 I2: R4 R3 + 1 I3: R3 R5 + 1 I4: R7 R3 op R4584 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS Instruction I2 cannot execute instruction I1, needs result register R3 produced I1; example true data dependency, described Section 16.1. Similarly, I4 must wait I3, uses result produced I3. relationship I1 I3? data dependency here, defined it. However, I3 executes completion prior I1, wrong value contents R3 fetched execution I4. Consequently, I3 must complete I1 produce correct output values. ensure this, issuing third instruction must stalled result might later overwritten older instruction takes longer complete. Out-of-order completion requires complex instruction issue logic in-order completion. addition, difficult deal instruction inter - rupts exceptions. interrupt occurs, instruction execution current Decode Execute Writ eC ycle I1 I2 1 I3 I4 I1 I2 2 I3 I4 I1 3 I4 I3 I1 I2 4 I5 I6 I4 5 I6 I5 I3 I4 6 I6 7 I5 I6 8 (a) In-order issue in-order co mpletion Decode Execute Writ eC ycle I1 I2 1 I3 I4 I1 I2 2 I4 I1 I3 I2 3 I5 I6 I4 I1 I3 4 I6 I5 I4 5 I6 I5 6 I6 7 (b) In-order issue out-of-order co mpletion Decode Windo xecute Writ eC ycle I1 I2 1 I3 I4 I1,I2 I1 I2 2 I5 I6 I3,I4 I1 I3 I2 3 I4,I5,I6 I6 I4 I1 I3 4 I5 I5 I4 I6 5 I5 6 (c) Out-of-order issue out-of-order co mpletion Figure 16.4 Superscalar Instruction Issue Completion Policies16.2 / ESIgN ISSUES 585 point suspended, resumed later. processor must assure resump - tion takes account that, time interruption, instructions ahead instruction caused interrupt may already completed. out-of-order issue out-of-order completion in-order issue, processor decode instructions point dependency conflict. additional instructions decoded conflict resolved. result, processor cannot look ahead point conflict subsequent instructions may independent already pipeline may usefully introduced pipeline. allow out-of-order issue , necessary decouple decode execute stages pipeline. done buffer referred instruction win - dow. organization, processor finished decoding instruction, placed instruction window. long buffer full, processor continue fetch decode new instructions. functional unit becomes available execute stage, instruction instruction window may issued execute stage. instruction may issued, provided (1) needs particular functional unit available, (2) conflicts dependencies block instruction. Figure 16.5 suggests organization. result organization processor lookahead capability, allowing identify independent instructions brought execute stage. Instructions issued instruction window little regard original program order. before, constraint program execution behaves correctly. Figures 16.4c illustrates policy. first three cycles, two instructions fetched decode stage. cycle, subject constraint buffer size, two instructions move decode stage instruction window. example, possible issue instruction I6 ahead I5 (recall I5 depends I4, I6 not). Thus, one cycle saved execute write-back stages, end-to-end savings, compared Figure 16.4b, one cycle. Fetch Issue Register r ead Execute Write backDecode Rename Dispatch CommitBuffer instructions In-order fr ont end Out-of-order execution Figure 16.5 Organization Out-of-Order Issue Out-of- Order Completion586 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS instruction window depicted Figure 16.4c illustrate role. - ever, window additional pipeline stage. instruction window simply implies processor sufficient information instruction decide issued. out-of-order issue, out-of-order completion policy subject constraints described earlier. instruction cannot issued violates depend - ency conflict. difference instructions available issuing, reducing probability pipeline stage stall. addition, new dependency, referred earlier antidependency (also called write read [WAR] dependency ), arises. code fragment considered earlier illus - trates dependency: I1: R3 R3 op R5 I2: R4 R3 + 1 I3: R3 R5 + 1 I4: R7 R3 op R4 Instruction I3 cannot complete execution instruction I2 begins execu - tion fetched operands. I3 updates register R3, source operand I2. term antidependency used constraint similar true data dependency, reversed: Instead first instruc - tion producing value second instruction uses, second instruction destroys value first instruction uses. Reorder Buffer Simulator Tomasulo’s Algorithm Simulator Alternative Simulation Tomasulo’s Algorithm One common technique used support out-of-order completion reorder buffer. reorder buffer temporary storage results completed order committed register file program order. related con - cept Tomasulo’s algorithm. Appendix N examines concepts. Register Renaming out-of-order instruction issuing and/or out-of-order instruction completion allowed, seen gives rise possibility WAW dependencies WAR dependencies. dependencies differ RAW data dependencies resource conflicts, reflect flow data program sequence execution. WAW dependencies WAR dependencies, hand, arise values registers may longer reflect sequence values dictated program flow. instructions issued sequence complete sequence, pos - sible specify contents register point execution. out-of-order techniques used, values registers cannot fully known point time consideration sequence instructions dictated 16.2 / ESIgN ISSUES 587 program. effect, values conflict use registers, pro - cessor must resolve conflicts occasionally stalling pipeline stage. Antidependencies output dependencies examples storage con - flicts. Multiple instructions competing use register locations, generating pipeline constraints retard performance. problem made acute register optimization techniques used (as discussed Chapter 15), compiler techniques attempt maximize use registers, hence maximizing number storage conflicts. One method coping types storage conflicts based traditional resource-conflict solution: duplication resources. context, technique referred register renaming . essence, registers allocated dynamically processor hardware, associated values needed instructions various points time. new register value cre - ated (i.e., instruction executes register destination oper - and), new register allocated value. Subsequent instructions access value source operand register must go renaming process: register references instructions must revised refer register containing needed value. Thus, original register reference several different instructions may refer different actual registers, different values intended. Let us consider register renaming could used code fragment examining: I1: R3b R3a op R5a I2: R4b R3b + 1 I3: R3c R5a + 1 I4: R7b R3c op R4b register reference without subscript refers logical register ref - erence found instruction. register reference subscript refers hardware register allocated hold new value. new allocation made particular logical register, subsequent instruction references logical register source operand made refer recently allocated hardware regis - ter (recent terms program sequence instructions). example, creation register R3c instruction I3 avoids WAR dependency second instruction WAW first instruction, interfere correct value accessed I4. result I3 issued immediately; without renaming, I3 cannot issued first instruction complete second instruction issued. Scoreboarding Simulator alternative register renaming scoreboarding. essence, scoreboard - ing bookkeeping technique allows instructions execute whenever dependent previous instructions structural hazards present. See Appendix N discussion.588 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS Machine Parallelism preceding discussion, looked three hardware techniques used superscalar processor enhance performance: duplication resources, out-of- order issue, renaming. One study illuminates relationship among techniques reported [SMIT89]. study made use simulation mod - eled machine characteristics MIPS R2000, augmented various superscalar features. number different program sequences simulated. Figure 16.6 shows results. graphs, vertical axis corre - sponds mean speedup superscalar machine scalar machine. horizontal axis shows results four alternative processor organizations. base machine duplicate functional units, issue instructions order. second configuration duplicates load/store func - tional unit accesses data cache. third configuration duplicates ALU, fourth configuration duplicates load/store ALU. graph, results shown instruction window sizes 8, 16, 32 instructions, dictates amount lookahead processor do. difference two graphs that, second, register renaming allowed. equivalent saying first graph reflects machine limited dependencies, whereas second graph corresponds machine limited true dependencies. two graphs, combined, yield important conclusions. first probably worthwhile add functional units without register renaming. base +ld/st +alu +bothSpeedupWithout r enaming base +ld/st +alu +bothSpeedupWith renaming81 63 2 Window size (construction) 01234 01234 Figure 16.6 Speedups Various Machine Organizations without Procedural Dependencies16.2 / ESIgN ISSUES 589 slight improvement performance, cost increased hardware complexity. register renaming, eliminates antidependencies - put dependencies, noticeable gains achieved adding functional units. Note, however, significant difference amount gain achievable using instruction window 8 versus larger instruction window. indicates instruction window small, data dependencies prevent effective utilization extra functional units; processor must able look quite far ahead find independent instructions utilize hardware fully. Pipeline Static vs. Dynamic Scheduling—Simulator Branch Prediction high-performance pipelined machine must address issue dealing branches. example, Intel 80486 addressed problem fetching next sequential instruction branch speculatively fetching branch tar - get instruction. However, two pipeline stages prefetch execution, strategy incurs two-cycle delay branch gets taken. advent RISC machines, delayed branch strategy explored. allows processor calculate result conditional branch instructions unusable instructions prefetched. method, pro - cessor always executes single instruction immediately follows branch. keeps pipeline full processor fetches new instruction stream. development superscalar machines, delayed branch strategy less appeal. reason multiple instructions need execute delay slot, raising several problems relating instruction dependencies. Thus, supersca - lar machines returned pre-RISC techniques branch prediction . Some, like PowerPC 601, use simple static branch prediction technique. sophis - ticated processors, PowerPC 620 Pentium 4, use dynamic branch prediction based branch history analysis. Superscalar Execution position provide overview superscalar execution pro - grams; illustrated Figure 16.7 . program executed consists linear sequence instructions. static program written pro - grammer generated compiler. instruction fetch stage, includes branch prediction, used form dynamic stream instructions. stream examined dependencies, processor may remove artificial dependencies. processor dispatches instructions window execution. window, instructions longer form sequential stream structured accord - ing true data dependencies. processor executes instruction order determined true data dependencies hardware resource availabil - ity. Finally, instructions conceptually put back sequential order results recorded.590 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS final step mentioned preceding paragraph referred commit - ting, retiring , instruction. step needed following reason. use parallel, multiple pipelines, instructions may complete order dif - ferent shown static program. Further, use branch prediction speculative execution means instructions may complete execution must abandoned branch represent taken. Therefore, permanent storage program-visible registers cannot updated immediately instructions complete execution. Results must held sort tempor - ary storage usable dependent instructions made permanent determined sequential model would executed instruction. Superscalar Implementation Based discussion far, make general comments pro - cessor hardware required superscalar approach. [SMIT95] lists following key elements: ■Instruction fetch strategies simultaneously fetch multiple instructions, often predicting outcomes of, fetching beyond, conditional branch instructions. functions require use multiple pipeline fetch decode stages, branch prediction logic. ■Logic determining true dependencies involving register values, mech - anisms communicating values needed execution. ■Mechanisms initiating, issuing, multiple instructions parallel. ■Resources parallel execution multiple instructions, including multiple pipelined functional units memory hierarchies capable simultaneously servicing multiple memory references. ■Mechanisms committing process state correct order.Static programInstruction fetch branch predictionInstruction dispatch Window executionInstruction issue Instruction executionInstruction reorder commit Figure 16.7 Conceptual Depiction Superscalar Processing16.3 / NTEL CORE MICROARCHITECTURE 591 16.3 INTEL CORE MICROARCHITECTURE Although concept superscalar design generally associated RISC architecture, superscalar principles applied CISC machine. Per - haps notable example Intel x86 architecture. evolution superscalar concepts Intel line interesting note. 386 traditional CISC nonpipelined machine. 486 introduced first pipelined x86 processor, reducing average latency integer operations two four cycles one cycle, still limited executing single instruction cycle, superscalar elements. original Pentium modest superscalar component, consisting use two separate integer execution units. Pentium Pro intro - duced full-blown superscalar design out-of-order execution. Subsequent x86 models refined enhanced superscalar design. Figure 16.8 shows current version x86 pipeline architecture. Intel refers pipeline architecture microarchitecture . microarchitecture Instruc tion fetch predecod e Scheduler/Rese rvation statio n Memor ordering buffe rRetirement unit (Re-order buffer)Rename/AllocatorDecodeInstruc tion queue Integer AL U branch MMX/SSE FPmo vePort 0 Integer AL U FPAdd MMX/SSE FPmo veInteger AL U FPMul MMX/SSE FPm oveLoad unit Store UnitMicrocod e ROMBranch predi ction unit Shared L2 cache 10.7 Gbps FSBShared bus inter face unit L1 data cache DTLBL1 instruc tion cach e Port 1 Port 2 Port 3 Port 4 Figure 16.8 Intel Core Microarchitecture592 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS underlies implements machine’s instruction set architecture. microar - chitecture referred Intel Core Microarchitecture. implemented processor core Intel Core 2 Intel Xeon processor families. also Enhanced Intel Core Microarchitecture. One key difference two microarchitectures Enhanced Intel Core Microarchitecture provides third level cache. Table 16.2 shows parameters performance characteristics cache architecture. caches use writeback update policy. instruction reads data memory location, processor looks cache line contains data caches main memory following order: 1. L1 data cache initiating core 2. L1 data cache cores L2 cache 3. System memory cache line taken L1 data cache another core modified, ignoring cache line availability state L2 cache. Table 16.2b Table 16.2 Cache/Memory Parameters Performance Processors Based Intel Core Microarchitecture (a) Cache Parameters Cache Level Capacity Associativity (ways)Line Size (bytes)Writeback Update Policy L1 data 32 kB 8 64 Writeback L1 instruction 32 kB 8 N/A N/A L2 (shared)1 2, 4 MB 8 16 64 Writeback L2 (shared)2 3, 6 MB 12 24 64 Writeback L3 (shared)2 8, 12, 16 MB 15 64 Writeback Notes: 1. Intel Core Microarchitecture 2. Enhanced Intel Core Microarchitecture (b) Load/Store Performance Data Locality Load Store Latency Throughput Latency Throughput L1 data cache 3 clock cycles 1 clock cycle 2 clock cycles 3 clock cycles L1 data cache core modified state14 clock cycles+ 5.5 bus cycles14 clock cycles+ 5.5 bus cycles14 clock cycles+ 5.5 bus cyclesN/A L2 cache 14 3 14 3 Memory 14 clock cycles+5.5 bus cycles+memory latencyDepends bus read protocol14 clock cycles+5.5 bus cycles+memory latencyDepends bus read protocol16.3 / NTEL CORE MICROARCHITECTURE 593 shows characteristics fetching first four bytes different localities memory cluster. latency column provides estimate access latency. However, actual latency vary depending load cache, memory com - ponents, parameters. pipeline Intel Core microarchitecture contains: ■An in-order issue front end fetches instruction streams memory, four instruction decoders supply decoded instructions out-of-order execution core. instruction translated one fixed-length RISC instructions, known micro-operations , micro-ops . ■An out-of-order superscalar execution core issue six micro-ops per cycle reorder micro-ops execute soon sources ready execution resources available. ■An in-order retirement unit ensures results execution micro- ops processed architectural states processor's register set updated according original program order. effect, Intel Core Microarchitecture implements CISC instruction set architecture RISC microarchitecture. inner RISC micro-ops pass pipeline least 14 stages; cases, micro-op requires multiple exe- cution stages, resulting even longer pipeline. contrasts five-stage pipeline (Figure 14.21) used earlier Intel x86 processors Pentium. Front End front end needs supply decoded instructions (micro-ops) sustain stream six-issue wide out-of-order engine. consists three major components: branch prediction unit (BPU), instruction fetch predecode unit, instruction queue decode unit. branch prediction unit unit helps instruction fetch unit fetch likely instruction executed predicting various branch types: conditional, indirect, direct, call, return. BPU uses dedicated hardware branch type. Branch prediction enables processor begin executing instructions long branch outcome decided. microarchitecture uses dynamic branch prediction strategy based history recent executions branch instructions. branch target buffer (BTB) maintained caches information recently encountered branch instructions. Whenever branch instruction encountered instruction stream, BTB checked. entry already exists BTB, instruction unit guided history information entry determining whether predict branch taken. branch predicted, branch destination address associ - ated entry used prefetching branch target instruction. instruction executed, history portion appropriate entry updated reflect result branch instruction. instruction represented BTB, address instruction loaded entry BTB; necessary, older entry deleted. description preceding two paragraphs fits, general terms, branch prediction strategy used original Pentium model, well later 594 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS Pentium models, including current Intel models. However, case Pen - tium, relatively simple 2-bit history scheme used. later models much longer pipelines (14 stages Intel Core Microarchitecture compared 5 stages Pentium) therefore penalty misprediction greater. Accordingly, later models use elaborate branch prediction scheme history bits reduce misprediction rate. Conditional branches history BTB predicted using static prediction algorithm, according following rules: ■For branch addresses instruction pointer (IP) relative, predict taken branch return taken otherwise. ■For IP-relative backward conditional branches, predict taken. rule reflects typical behavior loops. ■For IP-relative forward conditional branches, predict taken. instruction fetch predecode unit instruction fetch unit comprises instruction translation lookaside buffer (ITLB), instruction prefetcher, instruction cache, predecode logic. Instruction fetch performed L1 instruction cache. L1 cache miss occurs, in-order front end feeds new instructions L1 cache L2 cache 64 bytes time. default, instructions fetched sequentially, L2 cache line fetch includes next instruction fetched. Branch prediction via branch prediction unit may alter sequential fetch operation. ITLB translates linear IP address given physical addresses needed access L2 cache. Static branch prediction front end used determine instructions fetch next. predecode unit accepts sixteen bytes instruction cache prefetch buffers carries following tasks: ■Determine length instructions. ■Decode prefixes associated instructions. ■Mark various properties instructions decoders (for example, “is branch”). predecode unit write six instructions per cycle instruction queue. fetch contains six instructions, predecoder continues decode six instructions per cycle instructions fetch written instruction queue. Subsequent fetches enter predecoding current fetch completes. instruction queue decode unit Fetched instructions placed instruction queue. there, decode unit scans bytes determine instruction boundaries; necessary operation variable length x86 instructions. decoder translates machine instruction one four micro-ops, 118-bit RISC instruction. Note comparison pure RISC machines instruction length 32 bits. longer micro-op length required accommodate complex x86 instructions. Nevertheless, micro-ops easier manage original instructions derive.16.3 / NTEL CORE MICROARCHITECTURE 595 instructions require four micro-ops. instructions transferred microcode ROM, contains series micro-ops (five more) associated complex machine instruction. example, string instruction may translate large (even hundreds), repetitive sequence micro-ops. Thus, microcode ROM microprogrammed control unit sense discussed Part Six. resulting micro-op sequence delivered rename/allocator module. Out-of-Order Execution Logic part processor reorders micro-ops allow execute quickly input operands ready. allocate allocate stage allocates resources required execution. performs following functions: ■If needed resource, register, unavailable one three micro-ops arriving allocator clock cycle, allocator stalls pipeline. ■The allocator allocates reorder buffer (ROB) entry, tracks com - pletion status one 126 micro-ops could process time.2 ■The allocator allocates one 128 integer floating-point register entries result data value micro-op, possibly load store buffer used track one 48 loads 24 stores machine pipeline. ■The allocator allocates entry one two micro-op queues front instruction schedulers. ROB circular buffer hold 126 micro-ops also con - tains 128 hardware registers. buffer entry consists following fields: ■State: Indicates whether micro-op scheduled execution, dis - patched execution, completed execution ready retirement. ■Memory Address: address Pentium instruction generated micro-op. ■Micro-op: actual operation. ■Alias Register: micro-op references one 16 architectural registers, entry redirects reference one 128 hardware registers. Micro-ops enter ROB order. Micro-ops dispatched ROB Dispatch/Execute unit order. criterion dispatch appropriate execution unit necessary data items required microop available. Finally, micro-ops retired ROB order. accomplish in-order retirement, micro-ops retired oldest first micro-op designated ready retirement. register renaming rename stage remaps references 16 architectural registers (8 floating-point registers, plus EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP) set 128 physical registers. stage removes false dependencies 2See Appendix N discussion reorder buffers.596 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS caused limited number architectural registers preserving true data dependencies (reads writes). micro -op queuing resource allocation register renaming, micro- ops placed one two micro-op queues, held room schedulers. One two queues memory operations (loads stores) micro-ops involve memory references. queue obeys FIFO (first-in-first-out) discipline, order maintained queues. is, micro-op may read one queue order respect micro-ops queue. provides greater flexibility schedulers. micro -op scheduling dispatching schedulers responsible retrieving micro-ops micro-op queues dispatching execution. scheduler looks micro-ops whose status indicates micro-op operands. execution unit needed micro-op available, scheduler fetches micro-op dispatches appropriate execution unit. six micro-ops dispatched one cycle. one micro-op available given execution unit, scheduler dispatches sequence queue. sort FIFO discipline favors in-order execution, time instruction stream rearranged dependencies branches substantially order. Four ports attach schedulers execution units. Port 0 used integer floating-point instructions, exception simple integer opera - tions handling branch mispredictions, allocated Port 1. addition, MMX execution units allocated two ports. remain - ing ports memory loads stores. Integer Floating-Point Execution Units integer floating-point register files source pending operations execution units. execution units retrieve values register files well L1 data cache. separate pipeline stage used compute flags (e.g., zero, negative); typically input branch instruction. subsequent pipeline stage performs branch checking. function com - pares actual branch result prediction. branch prediction turns wrong, micro-operations various stages processing must removed pipeline. proper branch destination pro - vided Branch Predictor drive stage, restarts whole pipeline new target address. 16.4 ARM CORTEX-A8 Recent implementations ARM architecture seen introduction superscalar techniques instruction pipeline. section, focus ARM Cortex-A8, provides good example RISC-based superscalar design.16.4 / ARM C ORTE x-A8 597 Cortex-A8 ARM family processors ARM refers application processors. ARM application processor embedded processor running complex operating systems wireless, consumer imaging applica - tions. Cortex-A8 targets wide variety mobile consumer applications including mobile phones, set-top boxes, gaming consoles automotive naviga - tion/entertainment systems. Figure 16.9 shows logical view Cortex-A8 architecture, emphasiz - ing flow instructions among functional units. main instruction flow three functional units implement dual, in-order-issue, 13-stage pipe - line. Cortex designers decided stay in-order issue keep additional Prefetch branch predictionDecode & sequencerDependency check issueL1 cache interface TLBL1 cache interface TLBInstruction fetch Instruction decode13-stage integer pipeline 10-stage SIMD pipeline2 stages 3 stages 1 stage 6 stages5 stages 6 stages Instruction execute Load/Stor e NEON r egister writebackReplayBranch mispr edict NEON instruction decode Load stor e data queueNEON unit NEON r egister /f_ileArchitectural register /f_ile Load/stor e permute pipeIEEE /f_loating-point enginenon-IEEE FP MUL pipenon-IEEE FP ADD pipeLoad/stor e pipe 0 1ALU pipe 1MUL pipe 0ALU pipe Integer shift pipeInteger MUL pipeInteger ALU pipe ArbitrationL2 cache pipeline contr ol Write bufferBus interface unit (BIU)Fill e viction queueInstruction, data, NEON pr eload engine b uffersL2 cache L2 cache data RAML2 cache tag RAMI-side L1 RAMD-side L1 RAMInstruction r egister writeback Figure 16.9 Architectural Block Diagram ARM Cortex-A8598 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS power required minimum. Out-of-order issue retire require extensive amounts logic consuming extra power. Figure 16.10 shows details main Cortex-A8 pipeline. separate unit SIMD (single-instruction-multiple-data) unit implements 10-stage pipeline. Instruction Fetch Unit instruction fetch unit predicts instruction stream, fetches instructions L1 instruction cache, places fetched instructions buffer con - sumption decode pipeline. instruction fetch unit also includes L1 AGUF0 F1 F2 D0 E0 E1 E2 E3 E4 E5D1 D2 D3 D4 Branch mispr edict Branch mispr edictDecode /seqDec queue read/ writeScore board + issue logicFinal decode Decode Pending replay queue (a) Instruction fetch pipeline (b) Instruction decode pipeline (c) Instruction execute load/store pipelineEarly decode Early decode ShiftALU/ multiply pipe 0 MUL 1ALU MUL 2RAM + TLB BTB GHB RS12- entry fetch queue ReplayReplay SAT MUL 3BP ACCWB WB ShiftINST 0 INST 1 ALU pipe 1ALU SAT BP WB AGULoad/stor e pipe 0 1WBArchitectural register /f_ile RAM + TLBL2 updateFormat forward Figure 16.10 ARM Cortex-A8 Integer Pipeline16.4 / ARM C ORTE x-A8 599 instruction cache. several unresolved branches pipeline, instruction fetches speculative, meaning guarantee exe - cuted. branch exceptional instruction code stream cause pipeline flush, discarding currently fetched instructions. instruction fetch unit fetch four instructions per cycle, goes following stages: F0: address generation unit (AGU) generates new virtual address. - mally, address next address sequentially preceding fetch address. address also branch target address provided branch prediction previous instruction. F0 counted part 13-stage pipeline, ARM processors traditionally defined instruction cache access first stage. F1: calculated address used fetch instructions L1 instruc - tion cache. parallel, fetch address used access branch predic - tion arrays determine next fetch address based branch prediction. F3: Instruction data placed instruction queue. instruction results branch prediction, new target address sent address gen - eration unit. minimize branch penalties typically associated deeper pipeline, Cortex-A8 processor implements two-level global history branch predictor, consisting branch target buffer (BTB) global history buffer (GHB). data structures accessed parallel instruction fetches. BTB indicates whether current fetch address return branch instruction branch target address. contains 512 entries. hit BTB branch pre - dicted GHB accessed. GHB consists 4096 2-bit counters encode strength direction information branches. GHB indexed 10-bit - tory direction last ten branches encountered 4 bits PC. add - ition dynamic branch predictor, return stack used predict subroutine return addresses. return stack eight 32-bit entries store link register value r14 ARM Thumb state calling function. return-type instruc - tion predicted taken, return stack provides last pushed address state. instruction fetch unit fetch queue 12 instructions. issues instructions decode unit two time. queue enables instruction fetch unit prefetch ahead rest integer pipeline build backlog instructions ready decoding. Instruction Decode Unit instruction decode unit decodes sequences ARM Thumb instructions. dual pipeline structure, called pipe0 pipe1 , two instructions prog - ress unit time. two instructions issued instruction decode pipeline, pipe0 always contain older instruction program order. means instruction pipe0 cannot issue, instruction pipe1 issue. issued instructions progress order execution pipeline results written back register file end execution pipeline. in-or - der instruction issue retire prevents WAR hazards keeps tracking WAW 600 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS hazards recovery flush conditions straightforward. Thus, main concern instruction decode pipeline prevention RAW hazards. instruction goes five stages processing. D0: Thumb instructions decompressed 32-bit ARM instructions. preliminary decode function performed. D1: instruction decode function completed. D2: stage writes instructions read instructions pending/ replay queue structure. D3: stage contains instruction scheduling logic. scoreboard predicts register availability using static scheduling techniques.3 Hazard checking also done stage. D4: Performs final decode control signals required inte - ger execute load/store units. first two stages, instruction type, source destination oper - ands, resource requirements instruction determined. less commonly used instructions referred multicycle instructions. D1 stage breaks instructions multiple instruction opcodes sequenced individually execution pipeline. pending queue serves two purposes. First, prevents stall signal D3 rippling pipeline. Second, buffering instructions, always two instructions available dual pipeline. case one instruction issued, pending queue enables two instructions proceed pipeline together, even originally sent fetch unit different cycles. replay operation designed deal effects memory system instruction timing. Instructions statically scheduled D3 stage based prediction source operand available. stall mem - ory system result minimum 8-cycle delay. 8-cycle delay mini - mum balanced minimum number possible cycles receive data L2 cache case L1 load miss. Table 16.3 gives common cases result instruction replay memory system stall. deal stalls, recovery mechanism used flush subsequent instructions execution pipeline reissue (replay) them. support replay, instructions copied replay queue issued removed write back results retire. replay signal issued instructions retrieved replay queue reenter pipeline. decode unit issues two instructions parallel execution unit, unless encounters issue restriction. Table 16.4 shows common restriction cases. Integer Execute Unit instruction execute unit consists two symmetric arithmetic logic unit (ALU) pipelines, address generator load store instructions, multiply pipeline. execute pipelines also perform register write back. instruction execute unit: 3See Appendix N discussion scoreboarding.16.4 / ARM C ORTE x-A8 601 ■Executes integer ALU multiply operations, including flag generation. ■Generates virtual addresses loads stores base write-back value, required. ■Supplies formatted data stores forwards data flags. ■Processes branches changes instruction stream evaluates instruction condition codes. ALU instructions, either pipeline used, consisting following stages: E0: Access register file. six registers read register file two instructions. E1: barrel shifter (see Figure 14.25) performs function, needed. E2: ALU unit (see Figure 14.25) performs function. E3: needed, stage completes saturation arithmetic used ARM data processing instructions. E4: change control flow, including branch misprediction, exceptions, memory system replays prioritized processed. E5: Results ARM instructions written back register file.Table 16.3 Cortex-A8 Memory System Effects Instruction Timings Replay Event Delay Description Load data miss 8 cycles 1. load instruction misses L1 data cache. 2. request made L2 data cache. 3. miss also occurs L2 data cache, second replay occurs. number stall cycles depends external system memory timing. minimum time required receive critical word L2 cache miss approx- imately 25 cycles, much longer L3 memory latencies. Data TLB miss 24 cycles 1. table walk miss L1 TLB causes 24-cycle delay, assuming translation table entries found L2 cache. 2. translation table entries present L2 cache, number stall cycles depends external system memory timing. Store buffer full 8 cycles plus latency drain fill buffer1. store instruction miss result stalls unless store buffer full. 2. case full store buffer, delay least eight cycles. delay takes longer drain entries store buffer. Unaligned load store request8 cycles 1. load instruction address unaligned full access contained within 128-bit boundary, 8-cycle penalty. 2. store instruction address unaligned full access contained within 64-bit boundary, 8-cycle penalty.602 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS Instructions invoke multiply unit (see Figure 14.25) routed pipe0; multiply operation performed stages E1 E3, multi - ply accumulate operation stage E4. load/store pipeline runs parallel integer pipeline. stages follows: E1: memory address generated base index register. E2: address applied cache arrays. E3: case load, data returned formatted forwarding ALU MUL unit. case store, data formatted ready written cache. E4: Performs updates L2 cache, required. E5: Results ARM instructions written back register file. Table 16.5 shows sample code segment indicates processor might schedule it.Table 16.4 Cortex-A8 Dual-Issue Restrictions Restric- tion Type Description Example Cycle Restriction Load/store resource hazardThere one LS pipeline. one LS instruction issued per cycle. pipeline 0 pipeline 1.LDR r5, [r6] STR r7, [r8] MOV r9, r101 2 2Wait LS unit Dual issue possible Multiply resource hazardThere one multiply pipeline, avail- able pipeline 0.ADD r1, r2, r3 MUL r4, r5, r6 MUL r7, r8, r91 2 3Wait pipeline 0 Wait multiply unit Branch resource hazardThere one branch per cycle. pipeline 0 pipeline 1. branch instruction changes PC.BX r1 BEQ 0x1000 ADD r1, r2, r31 2 2Wait branch Dual issue possible Data out- put hazardInstructions des- tination cannot issued cycle. happen conditional code.MOVEQ r1, r2 MOVNE r1, r3 LDR r5, [r6]1 2 2Wait output dependency Dual issue possible Data source hazardInstructions cannot issued data available. See scheduling tables source requirements stages results.ADD r1, r2, r3 ADD r4, r1, r6 LDR r7, [r4]1 2 4Wait r1 Wait two cycles r4 Multi-cycle instructionsMulti-cycle instructions must issue pipeline 0 dual issue last iteration.MOV r1, r2 LDM r3, {r4-r7} LDM (cycle 2) LDM (cycle 3) ADD r8, r9, r101 2 3 4 4Wait pipeline 0, transfer r4 Transfer r5, r6 Transfer r7 Dual issue possible last transfer16.4 / ARM C ORTE x-A8 603 SIMD Floating-Point Pipeline SIMD floating-point instructions pass integer pipeline pro - cessed separate 10-stage pipeline (Figure 16.11). unit, referred NEON unit, handles packed SIMD instructions, provides two types floating-point sup - port. implemented, vector floating-point (VFP) coprocessor performs floating-point operations compliance IEEE 754. coprocessor present, sepa - rate multiply add pipelines implement floating-point operations .Table 16.5 Cortex-A8 Example Dual Issue Instruction Sequence Integer Pipeline Cycle Program Counter Instruction Timing Description 1 0x00000ed0 BX r14 Dual issue pipeline 0 1 0x00000ee4 CMP r0,#0 Dual issue pipeline 1 2 0x00000ee8 MOV r3,#3 Dual issue pipeline 0 2 0x00000eec MOV r0,#0 Dual issue pipeline 1 3 0x00000ef0 STREQ r3,[r1,#0] Dual issue pipeline 0, r3 needed E3 3 0x00000ef4 CMP r2,#4 Dual issue pipeline 1 4 0x00000ef8 LDRLS pc,[pc,r2,LSL #2] Single issue pipeline 0, +1 cycle load pc, extra cycle shift since LSL #2 5 0x00000f2c MOV r0,#1 Dual issue 2nd iteration load pipeline 1 6 0x00000f30 B 5pc6+8 #0xf38 dual issue pipeline 0 6 0x00000f38 STR r0,[r1,#0] Dual issue pipeline 1 7 0x00000f3c: LDR pc,[r13],#4 Single issue pipeline 0, +1 cycle load pc 8 0x0000017c ADD r2,r4,#0xc Dual issue 2nd iteration load pipeline 1 9 0x00000180 LDR r0,[r6,#4] Dual issue pipeline 0 9 0x00000184 MOV r1,#0xa Dual issue pipeline 1 12 0x00000188 LDR r0,[r0,#0] Single issue pipeline 0: r0 produced E3, required E1, +2 cycle stall 13 0x0000018c STR r0,[r4,#0] Single issue pipeline 0 due LS resource hazard, extra delay r0 since produced E3 consumed E3 14 0x00000190 LDR r0,[r4,#0xc] Single issue pipeline 0 due LS resource hazard 15 0x00000194 LDMFD r13!,{r4-r6,r14} Load multiple: loads r4 1st cycle, r5 r6 2nd cycle, r14 3rd cycle, 3 cycles total 17 0x00000198 B 5pc6+0xda8 #0xf40 dual issue pipeline 1 3rd cycle LDM 18 0x00000f40 ADD r0,r0,#2 ARM Single issue pipeline 0 19 0x00000f44 ADD r0,r1,r0 ARM Single issue pipeline 0, dual issue due hazard r0 produced E2 required E2604 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS 16.5 ARM CORTEX-M3 preceding section looked rather complex pipeline organization Cortex-A8, application processor. useful contrast, section examines considerably simpler pipeline organization Cortex-M3. Cortex-M series designed microcontroller domain. such, Cortex-M processors need simple efficient possible. Figure 16.12 provides block diagram overview Cortex-M3 processor. figure provides detail shown Figure 1.16. Key elements include: ■Processor core: Includes three-stage pipeline, register bank, memory interface. ■Memory protection unit: Protects critical data used operating system user applications, separating processing tasks disallowing access other’s data, disabling access memory regions, allowing memory regions defined read-only, detecting unexpected memory accesses could potentially break system. ■Nested vectored interrupt controller (NVIC): Provides configurable inter - rupt handling abilities processor. facilitates low-latency exception interrupt handling, controls power management. ■Wake-up interrupt controller (NVIC): Provides configurable interrupt han - dling abilities processor. facilitates low-latency exception inter - rupt handling, controls power management. ■Flash patch breakpoint unit: Implements breakpoints code patches.Integer ALU, MAC, SHIFT pipes Non-IEEE FMUL pipe Non-IEEE FADD pipe Load/stor e permuteLoad stor e alignmentInstruction decodeNEON r egister writeback IEEE single/double precision VFPWB WB WBShift 3 ABSShift 2 ALUShift 1 FMT WB WBFMUL 2 FADD 2FMUL 1FMUL 4FMUL 3 FADD 1FADD 4FADD 3FDUP FFMT WBStore AlignPERM 28-entry store queuePERM 1Load AlignMux NRFMux L1/ MCRWB VFPACC 2ACC 1MUL 2MUL 1DUP REg read + M3 fwding muxesScor e- board + Issue logicDec queue + Rd/Wr check16-entry Inst queue + Inst Dec 8-Entry store queue Figure 16.11 ARM Cortex-A8 NEON Floating-Point Pipeline16.5 / ARM C ORTE x-M3 605 ■Data watchpoint trace (DWT): Implements watchpoints, data tracing, system profiling. ■Serial wire viewer: export stream software-generated messages, data trace, profiling information single pin. ■Debug access port: Provides interface external debug access processor. ■Embedded trace macrocell: application-driven trace source supports printf() style debugging trace operating system application events, generates diagnostic system information. ■Bus matrix: Connects core debug interfaces external buses microcontroller. Pipeline Structure Cortex-M3 pipeline three stages (Figure 16.12). examine turn. fetch stage, one 32-bit word fetched time loaded 3-word buffer. 32-bit word may consist of: ■two Thumb instructions, ■one word-aligned Thumb-2 instruction, or‡ Optional componentCortex-M3 processor Embedded trace macrocellNested vectored interrupt controllerWake-up interrupt controller‡‡Decode Register bank Memo ry interfaceFetchE xecuteCortex-M3 processor core Debug access portMemory protection unit Serial wire viewer‡‡ ‡Flash patch breakpointData watchpoint trace‡‡ Bus matrix Code interfaceSRAM peripheral interface Figure 16.12 ARM Cortex-M3 Block Diagram606 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS ■the upper/lower halfword halfword-aligned Thumb-2 instruction — one Thumb instruction, — lower/upper halfword another halfword-aligned Thumb-2 instruction. fetch addresses core word aligned. Thumb-2 instruction halfword aligned, two fetches necessary fetch Thumb-2 instruction. - ever, three-entry prefetch buffer ensures stall cycle necessary first halfword Thumb-2 instruction fetched. decode stage performs three key functions: ■Instruction decode register read: Decodes Thumb Thumb-2 instructions. ■Address generation: address generation unit (AGU) generates main memory addresses load/store unit. ■Branch: Performs branch based immediate offset branch instruction return based contents link register (register R14). Finally, single execute stage instruction execution, includes ALU, load/store, branch instructions. Dealing Branches keep processor simple possible, Cortex-M3 processor use branch prediction, instead use simple techniques branch forwarding branch speculation, defined follows: ■Branch forwarding: term forwarding refers presenting instruction address fetched memory. processor forwards certain branch types, memory transaction branch presented least one cycle earlier opcode reaches execute. Branch forwarding increases performance core, branches significant part embedded controller applications. Branches affected PC relative immediate offset, use link register (LR) target register. ■Branch speculation: conditional branches, instruction address pre - sented speculatively, instruction fetched memory known instruction executed. Cortex-M3 processor prefetches instruction ahead execution using fetch buffer. also speculatively prefetches branch target addresses. Spe - cifically, conditional branch instruction encountered, decode stage also includes speculative instruction fetch could lead faster execution. processor fetches branch destination instruction decode stage itself. Later, execute stage, branch resolved known instruction executed next. branch taken, next sequential instruction already avail - able. branch taken, branch instruction made available time decision made, restricting idle time one cycle.16.5 / ARM C ORTE x-M3 607 Figure 16.13 clarifies manner branches handled, described follows: 1. decode stage forwards addresses unconditional branches spec - ulatively forwards addresses conditional branches possible calculate address. 2. ALU determines branch taken, information fed back empty instruction cache. 3. load instruction program counter results branch address forwarded fetching. seen, manner branches handled considerably simpler Cortex-M Cortex-A, requiring less processor logic processing. Instruction decode register readData phase load/ store branch ShiftFetchFetch Decode Execute AGU AGU = address generation unitBranch Branch forwarding speculation ALU branch forwarded/speculated LSU branch resultALU branchWRMultiply divideAddress phase write back Figure 16.13 ARM Cortex-M3 Pipeline608 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS 16.6 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms Review Questions 16.1 essential characteristic superscalar approach processor design? 16.2 difference superscalar superpipelined approaches? 16.3 instruction-level parallelism? 16.4 Briefly define following terms: ■True data dependency ■Procedural dependency ■Resource conflicts ■Output dependency ■Antidependency 16.5 distinction instruction-level parallelism machine parallelism? 16.6 List briefly define three types superscalar instruction issue policies. 16.7 purpose instruction window? 16.8 register renaming purpose? 16.9 key elements superscalar processor organization? Problems 16.1 out-of-order completion used superscalar processor, resumption exe - cution interrupt processing complicated, exceptional condition may detected instruction produced result order. program cannot restarted instruction following exceptional instruction, subsequent instructions already completed, would cause instructions executed twice. Suggest mechanism mechanisms deal - ing situation. 16.2 Consider following sequence instructions, syntax consists opcode followed destination register followed one two source registers: 0 ADD R3, R1, R2 1 LOAD R6, [R3] 2 R7, R5, 3 3 ADD R1, R6, R7 4 SRL R7, R0, 8antidependency branch prediction commit flow dependency in-order completion in-order issue instruction issue instruction-level parallelism instruction windowmachine parallelism micro-operations micro-ops out-of-order completion out-of-order issue output dependency procedural dependency read-write dependencyregister renaming resource conflict retire superpipelined superscalar true data dependency write-read dependency write-write dependency16.6 / K Ey TERMS , REVIEw QUESTIONS , PRObLEMS 609 5 R2, R4, R7 6 SUB R5, R3, R4 7 ADD R0, R1, 10 8 LOAD R6, [R5] 9 SUB R2, R1, R6 10 R3, R7, 15 Assume use four-stage pipeline: fetch, decode/issue, execute, write back. Assume pipeline stages take one clock cycle except execute stage. simple integer arithmetic logical instructions, execute stage takes one cycle, LOAD memory, five cycles consumed execute stage. simple scalar pipeline allow out-of-order execution, construct following table execution first seven instructions: Instruction Fetch Decode Execute Write Back 0 0 1 2 3 1 1 2 4 9 2 2 3 5 6 3 3 4 10 11 4 4 5 6 7 5 5 6 8 10 6 6 7 9 12 entries four pipeline stages indicate clock cycle instruction begins phase. program, second ADD instruction (instruc - tion 3) depends LOAD instruction (instruction 1) one operands, r6. LOAD instruction takes five clock cycles, issue logic encounters dependent ADD instruction two clocks, issue logic must delay ADD instruction three clock cycles. out-of-order capability, processor stall instruction 3 clock cycle 4, move issue following three inde - pendent instructions, enter execution clocks 6, 8, 9. LOAD finishes execution clock 9, dependent ADD launched execution clock 10. a. Complete preceding table. b. Redo table assuming out-of-order capability. savings using capability? c. Redo table assuming superscalar implementation handle two instructions time stage. 16.3 Consider following assembly language program: I1: Move R3, R7 /R3 (R7)/ I2: Load R8, (R3) /R8 Memory (R3)/ I3: Add R3, R3, 4 /R3 (R3) + 4/ I4: Load R9, (R3) /R9 Memory (R3)/ I5: BLE R8, R9, L3 /Branch (R9) > (R8)/ program includes WAW, RAW, WAR dependencies. Show these. 16.4 a. Identify RAW, WAR, WAW dependencies following instruction sequence: I1: R1 = 100 I2: R1 = R2 + R4 I3: R2 = r4 - 25610 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS I4: R4 = R1 + R3 I5: R1 = R1 + 30 b. Rename registers part (a) prevent dependency problems. Identify ref - erences initial register values using subscript “a” register reference. 16.5 Consider “in-order-issue/in-order-completion” execution sequence shown Figure 16.14. a. Identify likely reason I2 could enter execute stage fourth cycle. “in-order issue/out-of-order completion” “out-of-order issue/ out-of-order completion” fix this? so, which? b. Identify reason I6 could enter write stage nineth cycle. “in-order issue/out-of-order completion” “out-of-order issue/out-of-order completion” fix this? so, which? 16.6 Figure 16.15 shows example superscalar processor organization. processor issue two instructions per cycle resource conflict data depen - dence problem. essentially two pipelines, four processing stages (fetch, decode, execute, store). pipeline fetch decode store unit. Four functional units (multiplier, adder, logic unit, load unit) available use execute stage shared two pipelines dynamic basis. two store units dynamically used two pipelines, depending availability particular cycle. lookahead window fetch decoding logic. window used instruction lookahead out-of-order instruction issue. Consider following program executed processor: I1: Load R1, /R1 Memory (A)/ I2: Add R2, R1 /R2 (R2) + R(1)/ I3: Add R3, R4 /R3 (R3) + R(4)/ I4: Mul R4, R5 /R4 (R4) + R(5)/ I5: Comp R6 /R6 (R6)/ I6: Mul R6, R7 /R6 (R6) * R(7)/ a. dependencies exist program? b. Show pipeline activity program processor Figure 16.15 using in-order issue in-order completion policies using presentation similar Figure 16.2. b. Repeat in-order issue out-of-order completion. c. Repeat out-of-order issue out-of-order completion. 16.7 Figure 16.16 paper superscalar design. Explain three parts fig - ure, define w, x, y, z. 16.8 Yeh’s dynamic branch prediction algorithm, used Pentium 4, two-level branch prediction algorithm. first level history last n branches. Decode Execute Writ eC ycle I1 I2 1 I2 I1 2 I2 I1 3 I3 I4 I2 4 I5 I6 I4 I3 I1 I2 5 I5 I6 I5 I3 6 I5 I6 I3 I4 7 8 I5 I6 9 Figure 16.14 In-Order Issue, In-Order-Completion Execution Sequence16.6 / K Ey TERMS , REVIEw QUESTIONS , PRObLEMS 611 second level branch behavior last occurrences unique pattern last n branches. conditional branch instruction program, entry Branch History Table (BHT). entry consists n bits corresponding last n executions branch instruction, 1 branch taken 0 branch not. BHT entry indexes Pattern Table (PT) 2 n entries, one possible pattern n bits. PT entry consists bits used branch prediction, described Chapter 14 (e.g., Figure 14.19). conditional branch encountered instruction fetch decode, address instruction used retrieve appropriate BHT entry, shows recent history instruction. Then, BHT entry used retrieve appropriate PT entry branch prediction. branch executed, BHT entry updated, appropriate PT entry updated.f1Fetch stageDecode stageExecute stage Store (write back) d1m1 a1AdderMultiplier Logic Loadm2 m3 a2 e1 e2f2 d2 f3 Lookahead windo wd3s1 s2 Figure 16.15 Dual-Pipeline Superscalar Processor wTo x zFrom w (a) (b)To x, y, z w (c)To zTo yTo x Figure 16.16 Figure Problem 16.7612 CHAPTER 16 / INSTRUCTION-LEVEL PARALLELISM & SUPERSCALAR PROCESSORS a. testing performance scheme, Yeh tried five different prediction schemes, illustrated Figure 16.17 . Identify three schemes cor - respond shown Figures 14.19 14.28. Describe remaining two schemes. b. algorithm, prediction based recent history particular branch instruction. Rather, based recent history pat - terns branches match n-bit pattern BHT entry instruc - tion. Suggest rationale strategy.(a)1/TT NN 0/N (b)3/TT TN N 1/T2/T TT NN 0/N (c)3/TT 1/N2/T TNNN 0/NTN (d)3/TT 1/NT2/T NN 0/N (e)3/TT 1/N2/T TNNN 0/NTN TNTN Figure 16.17 Figure Problem 16.8613 CHAPTER Parallel Processing 17.1 Multiple Processor Organizations Types Parallel Processor Systems Parallel Organizations 17.2 Symmetric Multiprocessors Organization Multiprocessor Operating System Design Considerations 17.3 Cache Coherence MESI Protocol Software Solutions Hardware Solutions MESI Protocol 17.4 Multithreading Chip Multiprocessors Implicit Explicit Multithreading Approaches Explicit Multithreading 17.5 Clusters Cluster Configurations Operating System Design Issues Cluster Computer Architecture Blade Servers Clusters Compared SMP 17.6 Nonuniform Memory Access Motivation Organization NUMA Pros Cons 17.7 Cloud Computing Cloud Computing Elements Cloud Computing Reference Architecture 17.8 Key Terms, Review Questions, Problems Part Five Parallel organization614 CHAPTER 17 / P ARAllEl PRoCEssing Traditionally, computer viewed sequential machine. computer programming languages require programmer specify algorithms sequences instructions. Processors execute programs executing machine instructions sequence one time. instruction executed sequence operations (fetch instruction, fetch operands, perform operation, store results). view computer never entirely true. micro- operation level, multiple control signals generated time. Instruction pipelining, least extent overlapping fetch execute operations, around long time. examples performing independent operations parallel. approach taken superscalar organization, exploits instruction- level parallelism. superscalar machine, multiple execution units within single processor, may execute multiple instructions program parallel. computer technology evolved, cost computer hard - ware dropped, computer designers sought opportunities parallelism, usually enhance performance and, cases, increase availability. overview, chapter looks prominent approaches parallel organization. First, examine symmetric multiproces - sors (SMPs), one earliest still common example paral - lel organization. SMP organization, multiple processors share common memory. organization raises issue cache coherence, sep - arate section devoted. Next, chapter examines multithreaded processors chip multiprocessors. describe clusters, consist multiple independent computers organized cooperative fashion. Clusters become increasingly common support workloads beyond capacity single SMP. Another approach use multiple processors examine nonuniform memory access (NUMA) machines. NUMA approach relatively new yet proven marketplace, often considered alternative SMP cluster approach. Finally, chapter looks cloud computing architecture.Learning Objectives studying chapter, able to: rSummarize types parallel processor organizations . rPresent overview design features symmetric multiprocessors . rUnderstand issue cache coherence multiple processor system. rExplain key features MESI protocol . rExplain difference implicit explicit multithreading . rSummarize key design issues clusters . rExplain concept nonuniform memory access. rPresent overview cloud computing concepts17.1 / Mul TiPlE PRoCEssoR oRgAnizATions 615 17.1 MULTIPLE PROCESSOR ORGANIZATIONS Types Parallel Processor Systems taxonomy first introduced Flynn [FL YN72] still common way cat - egorizing systems parallel processing capability. Flynn proposed following categories computer systems: ■Single instruction, single data (SISD) stream: single processor executes single instruction stream operate data stored single memory. Unipro - cessors fall category. ■Single instruction, multiple data (SIMD) stream: single machine instruction controls simultaneous execution number processing elements lockstep basis. processing element associated data memory, instructions executed different sets data different processors. Vec - tor array processors fall category, discussed Section 18.7. ■Multiple instruction, single data (MISD) stream: sequence data trans - mitted set processors, executes different instruction sequence. structure commercially implemented. ■Multiple instruction, multiple data (MIMD) stream: set processors simul - taneously execute different instruction sequences different data sets. SMPs, clusters, NUMA systems fit category. MIMD organization, processors general purpose; able process instructions necessary perform appropriate data trans - formation. MIMDs subdivided means processors communicate (Figure 17.1). processors share common memory, processor accesses programs data stored shared memory, processors communicate via memory. common form system known symmetric multiprocessor (SMP) , examine Sec - tion 17.2. SMP, multiple processors share single memory pool mem - ory means shared bus interconnection mechanism; distinguishing feature memory access time region memory approximately processor. recent development nonuniform mem - ory access (NUMA) organization, described Section 17.5. name suggests, memory access time different regions memory may differ NUMA processor. collection independent uniprocessors SMPs may interconnected form cluster . Communication among computers either via fixed paths via network facility. Parallel Organizations Figure 17 .2 illustrates general organization taxonomy Figure 17 .1. Figure 17 .2a shows structure SISD. sort control unit (CU) provides instruction stream (IS) processing unit (PU). processing 616 CHAPTER 17 / P ARAllEl PRoCEssing Processor organizations Single instruction, single data str eam (SISD)Single instruction, multiple data str eam (SIMD)Multiple instruction, single data str eam (MISD)Multiple instruction, multiple data str eam (MIMD) Vector processor ClustersUnipr ocessor Array processor Symmetric multipr ocessor (SMP)Nonunif orm memory access (NUMA)Shar ed memory (tightly coupled)Distrib uted memory (loosely coupled) Figure 17.1 Taxonomy Parallel Processor Architectures LMnDSLM1 LM2DS DSIS ISCU PUn LMnDSPU1 LM1 PU2 LM 2DS DS   IS (b) SIMD (with distributed memory)CUIS (a) SISDPU MUDS CU1 CU2 CUn PUnIS DS (c) MIMD (with shared memory)PU1 PU2DS DS   CU 1 CU 2 CUn PUnPU 1 PU 2    Interconnection networkShared memory (d) MIMD (with distributed memor y)CU = Contr ol unit = Instruction str eam PU = Processing unit DS = Data str eam MU = Memory unit LM = Local memorySISD = Single instruction, = single data str eam SIMD = Single instruction, multiple data str eam MIMD = Multiple instruction, multiple data str eam Figure 17.2 Alternative Computer Organizations17.2 / syMMETR iC Mul TiPRoCEssoRs 617 unit operates single data stream (DS) memory unit (MU). SIMD, still single control unit, feeding single instruction stream multiple PUs. PU may dedicated memory (illustrated Figure 17 .2b), may shared memory. Finally, MIMD, multiple control units, feeding separate instruction stream PU. MIMD may shared- memory multiprocessor (Figure 17 .2c) distributed-memory multicom - puter (Figure 17 .2d). design issues relating SMPs, clusters, NUMAs complex, involv - ing issues relating physical organization, interconnection structures, interprocessor communication, operating system design, application software techniques. concern primarily organization, although touch briefly operating system design issues. 17.2 SYMMETRIC MULTIPROCESSORS fairly recently, virtually single- user personal computers worksta - tions contained single general- purpose microprocessor. demands perfor - mance increase cost microprocessors continues drop, vendors introduced systems SMP organization. term SMP refers computer hardware architecture also operating system behavior reflects architecture. SMP defined standalone computer system fol - lowing characteristics: 1. two similar processors comparable capability. 2. processors share main memory I/O facilities inter - connected bus internal connection scheme, memory access time approximately processor. 3. processors share access I/O devices, either channels different channels provide paths device. 4. processors perform functions (hence term symmetric ). 5. system controlled integrated operating system provides interaction processors programs job, task, file, data element levels. Points 1 4 self- explanatory. Point 5 illustrates one contrasts loosely coupled multiprocessing system, cluster. latter, physical unit interaction usually message complete file. SMP, indi - vidual data elements constitute level interaction, high degree cooperation processes. operating system SMP schedules processes threads across processors. SMP organization number potential advantages uniprocessor organization, including following: ■Performance: work done computer organized portions work done parallel, system multiple processors yield greater performance one single processor type (Figure 17 .3).618 CHAPTER 17 / P ARAllEl PRoCEssing ■Availability: symmetric multiprocessor, processors per - form functions, failure single processor halt machine. Instead, system continue function reduced performance. ■Incremental growth: user enhance performance system add - ing additional processor. ■Scaling: Vendors offer range products different price per - formance characteristics based number processors configured system. important note potential, rather guaranteed, benefits. operating system must provide tools functions exploit parallelism SMP system. attractive feature SMP existence multiple processors transparent user. operating system takes care scheduling threads processes individual processors synchronization among processors. Organization Figure 17 .4 depicts general terms organization multiprocessor system. two processors. processor self- contained, including con - trol unit, ALU, registers, and, typically, one levels cache. processor access shared main memory I/O devices form inter - connection mechanism. processors communicate memory (messages status information left common data areas). may also possible processors exchange signals directly. memory often organized Process 1 Process 2 Process 3 (a) Interleaving (multiprogramming, one processor) Process 1 Process 2 Process 3 (b) Interleaving overlapping (multiprocessing, two processors) Blocked Runnin gTime Figure 17.3 Multiprogramming Multiprocessing17.2 / syMMETR iC Mul TiPRoCEssoRs 619 multiple simultaneous accesses separate blocks memory possible. configurations, processor may also private main memory I/O channels addition shared resources. common organization personal computers, workstations, servers time- shared bus. time- shared bus simplest mechanism constructing multiprocessor system (Figure 17.5). structure interfaces basically single- processor system uses bus interconnection. bus consists control, address, data lines. facilitate DMA transfers I/O subsystems processors, following features provided: ■Addressing: must possible distinguish modules bus deter - mine source destination data. ■Arbitration: I/O module temporarily function “master.” mech - anism provided arbitrate competing requests bus control, using sort priority scheme. ■ Time- sharing: one module controlling bus, modules locked must, necessary, suspend operation bus access achieved. uniprocessor features directly usable SMP organization. latter case, multiple processors well multiple I/O processors attempting gain access one memory modules via bus.Processor Main memory     Inter connection networkProcessor Processor I/O I/O I/O Figure 17.4 Generic Block Diagram Tightly Coupled Multiprocessor620 CHAPTER 17 / P ARAllEl PRoCEssing bus organization several attractive features: ■Simplicity: simplest approach multiprocessor organization. physical interface addressing, arbitration, time- sharing logic processor remain single- processor system. ■Flexibility: generally easy expand system attaching proces - sors bus. ■Reliability: bus essentially passive medium, failure attached device cause failure whole system. main drawback bus organization performance. memory ref - erences pass common bus. Thus, bus cycle time limits speed system. improve performance, desirable equip processor cache memory. reduce number bus accesses dramatically. Typi - cally, workstation PC SMPs two levels cache, L1 cache internal (same chip processor) L2 cache either internal external. processors employ L3 cache well. use caches introduces new design considerations. local cache contains image portion memory, word altered one L1 cacheProcessor Main memory I/O subsystemShar ed bus I/O adapterProcessor Processor   L1 cache L1 cache L2 cache L2 cache L2 cache I/O adapter I/O adapter Figure 17.5 Symmetric Multiprocessor Organization17.3 / C ACHE CoHERE nCE MEsi PRoToCol 621 cache, could conceivably invalidate word another cache. prevent this, processors must alerted update taken place. problem known cache coherence problem typically addressed hardware rather operating system. address issue Section 17.4. Multiprocessor Operating System Design Considerations SMP operating system manages processor computer resources user perceives single operating system controlling system resources. fact, configuration appear single- processor multiprogramming system. SMP uniprocessor cases, multiple jobs processes may active one time, responsibility operating system schedule execu - tion allocate resources. user may construct applications use multiple processes multiple threads within processes without regard whether single processor multiple processors available. Thus, multiprocessor operating system must provide functionality multiprogramming system plus addi - tional features accommodate multiple processors. Among key design issues: ■Simultaneous concurrent processes: OS routines need reentrant allow several processors execute code simultaneously. multiple processors executing different parts OS, OS tables man - agement structures must managed properly avoid deadlock invalid operations. ■Scheduling: processor may perform scheduling, conflicts must avoided. scheduler must assign ready processes available processors. ■Synchronization: multiple active processes potential access shared address spaces shared I/O resources, care must taken provide effective synchronization. Synchronization facility enforces mutual exclusion event ordering. ■Memory management: Memory management multiprocessor must deal issues found uniprocessor machines, discussed Chapter 8. addition, operating system needs exploit available hardware parallelism, multiported memories, achieve best per - formance. paging mechanisms different processors must coordi - nated enforce consistency several processors share page segment decide page replacement. ■Reliability fault tolerance: operating system provide graceful degradation face processor failure. scheduler portions operating system must recognize loss processor restructure management tables accordingly. 17.3 CACHE COHERENCE MESI PROTOCOL contemporary multiprocessor systems, customary one two levels cache associated processor. organization essential achieve reason - able performance. does, however, create problem known cache coherence 622 CHAPTER 17 / P ARAllEl PRoCEssing problem. essence problem this: Multiple copies data exist different caches simultaneously, processors allowed update copies freely, inconsistent view memory result. Chapter 4 defined two common write policies: ■Write back: Write operations usually made cache. Main mem - ory updated corresponding cache line evicted cache. ■Write through: write operations made main memory well cache, ensuring main memory always valid. clear write- back policy result inconsistency. two caches contain line, line updated one cache, cache unknowingly invalid value. Subsequent reads invalid line produce invalid results. Even write- policy, inconsistency occur unless caches monitor memory traffic receive direct notification update. section, briefly survey various approaches cache coher - ence problem focus approach widely used: MESI (modified/exclusive/shared/invalid) protocol. version protocol used x86 architecture. cache coherence protocol, objective let recently used local variables get appropriate cache stay numerous reads write, using protocol maintain consistency shared variables might multiple caches time. Cache coherence approaches generally divided software hardware approaches. implementa - tions adopt strategy involves software hardware elements. Never - theless, classification software hardware approaches still instructive commonly used surveying cache coherence strategies. Software Solutions Software cache coherence schemes attempt avoid need additional hard - ware circuitry logic relying compiler operating system deal problem. Software approaches attractive overhead detecting potential problems transferred run time compile time, design com - plexity transferred hardware software. hand, compile- time software approaches generally must make conservative decisions, leading ineffi - cient cache utilization. Compiler- based coherence mechanisms perform analysis code determine data items may become unsafe caching, mark items accordingly. operating system hardware prevents noncacheable items cached. simplest approach prevent shared data variables cached. conservative, shared data structure may exclusively used periods may effectively read- periods. periods least one process may update variable least one process may access variable cache coherence issue.17.3 / C ACHE CoHERE nCE MEsi PRoToCol 623 efficient approaches analyze code determine safe periods shared variables. compiler inserts instructions generated code enforce cache coherence critical periods. number techniques developed performing analysis enforcing results; see [LILJ93] [STEN90] surveys. Hardware Solutions Hardware- based solutions generally referred cache coherence protocols. solutions provide dynamic recognition run time potential inconsistency conditions. problem dealt actually arises, effective use caches, leading improved performance software approach. addition, approaches transparent programmer compiler, reducing software development burden. Hardware schemes differ number particulars, including state information data lines held, information organized, coher - ence enforced, enforcement mechanisms. general, hardware schemes divided two categories: directory protocols snoopy protocols . directory protocols Directory protocols collect maintain information copies lines reside. Typically, centralized controller part main memory controller, directory stored main memory. directory contains global state information contents various local caches. individual cache controller makes request, centralized controller checks issues necessary commands data transfer memory caches caches. also responsible keeping state information date; therefore, every local action affect global state line must reported central controller. Typically, controller maintains information processors copy lines. processor write local copy line, must request exclusive access line controller. granting exclusive access, controller sends message processors cached copy line, forcing processor invalidate copy. receiving acknowledgments back processor, controller grants exclusive access requesting processor. another processor tries read line exclusively granted another processor, send miss notification controller. controller issues command processor holding line requires processor write back main memory. line may shared reading original processor requesting processor. Directory schemes suffer drawbacks central bottleneck overhead communication various cache controllers central controller. However, effective large- scale systems involve multiple buses complex interconnection scheme. snoopy protocols Snoopy protocols distribute responsibility maintaining cache coherence among cache controllers multipro- cessor. cache must recognize line holds shared 624 CHAPTER 17 / P ARAllEl PRoCEssing caches. update action performed shared cache line, must announced caches broadcast mechanism. cache controller able “snoop” network observe broadcasted notifications, react accordingly. Snoopy protocols ideally suited bus- based multiprocessor, shared bus provides simple means broadcasting snooping. However, one objectives use local caches avoid bus accesses, care must taken increased bus traffic required broadcasting snooping cancel gains use local caches. Two basic approaches snoopy protocol explored: write invali - date write update (or write broadcast). write- invalidate protocol, multiple readers one writer time. Initially, line may shared among several caches reading purposes. one caches wants per - form write line, first issues notice invalidates line caches, making line exclusive writing cache. line exclusive, owning processor make cheap local writes processor requires line. write- update protocol, multiple writers well multiple readers. processor wishes update shared line, word updated distributed others, caches containing line update it. Neither two approaches superior circum - stances. Performance depends number local caches pattern memory reads writes. systems implement adaptive protocols employ write- invalidate write- update mechanisms. write- invalidate approach widely used commercial multi - processor systems, x86 architecture. marks state every cache line (using two extra bits cache tag) modified, exclusive, shared, invalid. reason, write- invalidate protocol called MESI. remainder section, look use among local caches across multiprocessor. simplicity presentation, examine mechanisms involved coor - dinating among level 1 level 2 locally well time coordinat - ing across distributed multiprocessor. would add new principles would greatly complicate discussion. MESI Protocol provide cache consistency SMP , data cache often supports protocol known MESI. MESI, data cache includes two status bits per tag, line one four states: ■Modified: line cache modified (different main mem - ory) available cache. ■Exclusive: line cache main memory present cache. ■Shared: line cache main memory may present another cache. ■Invalid: line cache contain valid data.17.3 / C ACHE CoHERE nCE MEsi PRoToCol 625 Table 17.1 summarizes meaning four states. Figure 17.6 displays state diagram MESI protocol. Keep mind line cache state bits therefore realization state diagram. Figure 17.6a shows transitions occur due actions initiated processor attached cache. Figure 17.6b shows transitions occur due events snooped common bus. presentation separate state diagrams processor- initiated bus- initiated actions helps clarify logic MESI Dirty line copyback Invalidate transaction Read-with-intent-to-modify Cache line /f_illRH Read hit RMS Read miss, shar ed RME Read miss, exclusive WH Write hit WM Write miss SHR Snoop hit r ead SHW Snoop hit write read-with-intent-to-modify= = = = = = =Invalid Shar ed Modi/f_ied (a) Line cache initiating processorRH WHRHRH ExclusiveRMS WHSHW SHWRME SHRInvalid Shar ed Modi/f_ied (b) Line snooping cacheExclusive SHRSHWWMSHR WH Figure 17.6 MESI State Transition DiagramTable 17.1 MESI Cache Line States ModifiedE ExclusiveS SharedI Invalid cache line valid? Yes Yes Yes memory copy … date valid valid — Copies exist caches? Maybe Maybe write line … go busdoes go busgoes bus updates cachegoes directly bus626 CHAPTER 17 / P ARAllEl PRoCEssing protocol. time cache line single state. next event attached processor, transition dictated Figure 17.6a next event bus, transition dictated Figure 17.6b. Let us look transitions detail. read miss read miss occurs local cache, processor initiates memory read read line main memory containing missing address. processor inserts signal bus alerts processor/cache units snoop transaction. number possible outcomes: ■If one cache clean (unmodified since read memory) copy line exclusive state, returns signal indicating shares line. responding processor transitions state copy exclu - sive shared, initiating processor reads line main memory transitions line cache invalid shared. ■If one caches clean copy line shared state, signals shares line. initiating processor reads line transitions line cache invalid shared. ■If one cache modified copy line, cache blocks memory read provides line requesting cache shared bus. responding cache changes line modified shared.1 line sent requesting cache also received processed memory controller, stores block memory. ■If cache copy line (clean modified), signals returned. initiating processor reads line transitions line cache invalid exclusive. read hit read hit occurs line currently local cache, processor simply reads required item. state change: state remains modified, shared, exclusive. write miss write miss occurs local cache, processor initiates memory read read line main memory containing missing address. purpose, processor issues signal bus means read- with- intent- to- modify (RWITM). line loaded, immediately marked modified. respect caches, two possible scenarios precede loading line data. First, cache may modified copy line (state=modify). case, alerted processor signals initiating processor another pro - cessor modified copy line. initiating processor surrenders bus waits. processor gains access bus, writes modified cache 1In implementations, cache modified line signals initiating processor retry. Mean - while, processor modified copy seizes bus, writes modified line back main memory, transitions line cache modified shared. Subsequently, requesting processor tries finds one processors clean copy line shared state, described preceding point.17.3 / C ACHE CoHERE nCE MEsi PRoToCol 627 line back main memory, transitions state cache line invalid (because initiating processor going modify line). Subsequently, initiating processor issue signal bus RWITM read line main memory, modify line cache, mark line modified state. second scenario cache modified copy requested line. case, signal returned, initiating processor proceeds read line modify it. Meanwhile, one caches clean copy line shared state, cache invalidates copy line, one cache clean copy line exclusive state, invalidates copy line. write hit write hit occurs line currently local cache, effect depends current state line local cache: ■Shared: performing update, processor must gain exclusive - ership line. processor signals intent bus. processor shared copy line cache transitions sector shared invalid. initiating processor performs update transitions copy line shared modified. ■Exclusive: processor already exclusive control line, simply performs update transitions copy line exclusive modified. ■Modified: processor already exclusive control line line marked modified, simply performs update. l1-l2 cache consistency far described cache coherency protocols terms cooperate activity among caches connected bus SMP interconnection facility. Typically, caches L2 caches, processor also L1 cache connect directly bus therefore cannot engage snoopy protocol. Thus, scheme needed maintain data integrity across levels cache across caches SMP configuration. strategy extend MESI protocol (or cache coherence protocol) L1 caches. Thus, line L1 cache includes bits indicate state. essence, objective following: line present L2 cache corresponding L1 cache, L1 line state track state L2 line. simple means adopt write- policy L1 cache; case write L2 cache memory. L1 write- policy forces modification L1 line L2 cache therefore makes visible L2 caches. use L1 write- policy requires L1 content must subset L2 content. turn suggests associativity L2 cache equal greater L1 associativity. L1 write- policy used IBM S/390 SMP. L1 cache write- back policy, relationship two caches complex. several approaches maintaining, topic beyond scope.628 CHAPTER 17 / P ARAllEl PRoCEssing 17.4 MULTITHREADING CHIP MULTIPROCESSORS important measure performance processor rate executes instructions. expressed MIPS rate=f*IPC f processor clock frequency, MHz, IPC (instructions per cycle) average number instructions executed per cycle. Accordingly, designers pursued goal increased performance two fronts: increasing clock fre - quency increasing number instructions executed or, properly, number instructions complete processor cycle. seen earlier chapters, designers increased IPC using instruction pipeline using multiple parallel instruction pipelines superscalar architec - ture. pipelined multiple- pipeline designs, principal problem max - imize utilization pipeline stage. improve throughput, designers created ever complex mechanisms, executing instructions different order way occur instruction stream beginning exe - cution instructions may never needed. discussed Section 2.2, approach may reaching limit due complexity power consumption concerns. alternative approach, allows high degree instruction- level parallelism without increasing circuit complexity power consumption, called multithreading. essence, instruction stream divided several smaller streams, known threads, threads executed parallel. variety specific multithreading designs, realized commercial systems experimental systems, vast. section, give brief survey major concepts. Implicit Explicit Multithreading concept thread used discussing multithreaded processors may may concept software threads multiprogrammed operating system. useful define terms briefly: ■Process: instance program running computer. process embod - ies two key characteristics: — Resource ownership: process includes virtual address space hold process image; process image collection program, data, stack, attributes define process. time time, process may allocated control ownership resources, main memory, I/O channels, I/O devices, files. — Scheduling/execution: execution process follows execution path (trace) one programs. execution may interleaved processes. Thus, process execution state (Run - ning, Ready, etc.) dispatching priority entity sched - uled dispatched operating system.17.4 / Mul TiTHREA ding C HiP Mul TiPRoCEssoRs 629 ■Process switch: operation switches processor one process another, saving process control data, registers, information first replacing process information second.2 ■Thread: dispatchable unit work within process. includes processor context (which includes program counter stack pointer) data area stack (to enable subroutine branching). thread executes sequen - tially interruptible processor turn another thread. ■Thread switch: act switching processor control one thread another within process. Typically, type switch much less costly process switch. Thus, thread concerned scheduling execution, whereas process concerned scheduling/execution resource ownership. multiple threads within process share resources. thread switch much less time consuming process switch. Traditional operating systems, earlier versions unix, support threads. modern operating systems, Linux, versions unix, Windows, support thread. distinction made user- level threads, visible application program, kernel- level threads, visible operating system. may referred explicit threads, defined software. commercial processors experimental processors far used explicit multithreading. systems concurrently execute instruc - tions different explicit threads, either interleaving instructions dif - ferent threads shared pipelines parallel execution parallel pipelines. Implicit multithreading refers concurrent execution multiple threads extracted single sequential program. implicit threads may defined either statically compiler dynamically hardware. remainder section consider explicit multithreading. Approaches Explicit Multithreading minimum, multithreaded processor must provide separate program counter thread execution executed concurrently. designs differ amount type additional hardware used support concurrent thread exe - cution. general, instruction fetching takes place thread basis. processor treats thread separately may use number techniques optimizing single- thread execution, including branch prediction, register renaming, super - scalar techniques. achieved thread- level parallelism, may provide greatly improved performance married instruction- level parallelism. Broadly speaking, four principal approaches multithreading: ■Interleaved multithreading: also known fine- grained multithread - ing. processor deals two thread contexts time, switching one thread another clock cycle. thread blocked 2The term context switch often found OS literature textbooks. Unfortunately, although literature uses term mean called process switch, sources use mean thread switch. avoid ambiguity, term used book.630 CHAPTER 17 / P ARAllEl PRoCEssing data dependencies memory latencies, thread skipped ready thread executed. ■Blocked multithreading: also known coarse- grained multithreading . instructions thread executed successively event occurs may cause delay, cache miss. event induces switch another thread. approach effective in- order processor would stall pipeline delay event cache miss. ■Simultaneous multithreading (SMT): Instructions simultaneously issued multiple threads execution units superscalar processor. combines wide superscalar instruction issue capability use multiple thread contexts. ■Chip multiprocessing: case, multiple cores implemented single chip core handles separate threads. advantage approach available logic area chip used effectively without depending ever- increasing complexity pipeline design. referred multi - core; examine topic separately Chapter 18. first two approaches, instructions different threads exe - cuted simultaneously. Instead, processor able rapidly switch one thread another, using different set registers context information. results better utilization processor’s execution resources avoids large penalty due cache misses latency events. SMT approach involves true simultaneous execution instructions different threads, using replicated execution resources. Chip multiprocessing also enables simultaneous execution instructions different threads. Figure 17.7, based one [UNGE02], illustrates possible pipe - line architectures involve multithreading contrasts approaches use multithreading. horizontal row represents potential issue slot slots single execution cycle; is, width row corresponds maximum number instructions issued single clock cycle.3 vertical dimension represents time sequence clock cycles. empty (shaded) slot represents unused execution slot one pipeline. no- op indi - cated N. first three illustrations Figure 17.7 show different approaches scalar (i.e., single- issue) processor: ■ Single- threaded scalar: simple pipeline found traditional RISC CISC machines, multithreading. ■Interleaved multithreaded scalar: easiest multithreading approach implement. switching one thread another clock cycle, pipeline stages kept fully occupied, close fully occupied. hardware must capable switching one thread context another cycles. 3Issue slots position instructions issued given clock cycle. Recall Chapter 16 instruction issue process initiating instruction execution processor’s func - tional units. occurs instruction moves decode stage pipeline first execute stage pipeline.17.4 / Mul TiTHREA ding C HiP Mul TiPRoCEssoRs 631 ■Blocked multithreaded scalar: case, single thread executed latency event occurs would stop pipeline, time processor switches another thread. Figure 17.7c shows situation time perform thread switch one cycle, whereas Figure 17.7b shows thread switching occurs zero cycles. AA AA AA Thread switchesA B C BBCDThread switchesA DB DA B AA B C BBCD Thread switchesA DB DA B AAN N NN NN NNNNN B C BBCDThread switchesA NBA B NN NAN N B B CBCD AD AA DAA B C ABB BB ABC AD ACB AA B DD DBCD BB BB AA AADDD CC C C CCBCDThread switchesA BA B Issue band widthLatency cycleCycles (a) Single-threaded scalar (g) VLIW (h) Interlea ved multithreading VLIW (i) Blocked multithreading VLIW(j) Simultaneous multithreading (SMT)(k) Chip multiprocessor (multicore)(b) Interlea ved multithreading scalar(c) Blocked multithreading scalar(d) Superscalar (e) Interlea ved multithreading superscalar(f) Blocked multithreading superscalarIssue slot B B CBCDA Thread switchesA B BBCD AA AA AAAAA AA N AAN N AAN N NA AAN N NN NADA BDBD DDB BB BDD Figure 17.7 Approaches Executing Multiple Threads632 CHAPTER 17 / P ARAllEl PRoCEssing case interleaved multithreading, assumed control data dependencies threads, simplifies pipeline design - fore allow thread switch delay. However, depending specific design implementation, block multithreading may require clock cycle per - form thread switch, illustrated Figure 17.7. true fetched instruction triggers thread switch must discarded pipeline [UNGE03]. Although interleaved multithreading appears offer better processor uti - lization blocked multithreading, sacrifice single- thread performance. multiple threads compete cache resources, raises probability cache miss given thread. opportunities parallel execution available processor issue multiple instructions per cycle. Figures 17.7d 17.7i illustrate number variations among processors hardware issuing four instructions per cycle. cases, instructions single thread issued single cycle. following alternatives illustrated: ■Superscalar: basic superscalar approach multithreading. relatively recently, powerful approach providing parallelism within processor. Note cycles, available issue slots used. cycles, less maximum num - ber instructions issued; referred horizontal loss . instruction cycles, issue slots used; cycles instructions issued; referred vertical loss . ■Interleaved multithreading superscalar: cycle, many instruc - tions possible issued single thread. technique, potential delays due thread switches eliminated, previously discussed. - ever, number instructions issued given cycle still limited dependencies exist within given thread. ■Blocked multithreaded superscalar: Again, instructions one thread may issued cycle, blocked multithreading used. ■Very long instruction word (VLIW): VLIW architecture, IA- 64, places multiple instructions single word. Typically, VLIW constructed compiler, places operations may executed parallel word. simple VLIW machine (Figure 17.7g), possible com - pletely fill word instructions issued parallel, no- ops used. ■Interleaved multithreading VLIW: approach provide similar efficiencies provided interleaved multithreading superscalar architecture. ■Blocked multithreaded VLIW: approach provide similar efficien - cies provided blocked multithreading superscalar architecture. final two approaches illustrated Figure 17.7 enable parallel, simul - taneous execution multiple threads: ■Simultaneous multithreading: Figure 17 .7j shows system capable issuing 8 instructions time. one thread high degree instruction- level parallelism, may cycles able fill horizontal slots. cycles, instructions two threads may issued. sufficient 17.5 / Clus TERs 633 threads active, usually possible issue maximum number instructions cycle, providing high level efficiency. ■Chip multiprocessor (multicore): Figure 17.7k shows chip containing four cores, two- issue superscalar processor. core assigned thread, issue two instructions per cycle. discuss multicore computers Chapter 18. Comparing Figures 17.7j 17.7k, see chip multiprocessor instruction issue capability SMT cannot achieve degree instruction- level parallelism. chip multiprocessor able hide latencies issuing instructions threads. hand, chip multiprocessor outperform superscalar processor instruction issue capability, horizontal losses greater superscalar processor. addition, possible use multithreading within cores chip multiprocessor, done contemporary machines. 17.5 CLUSTERS important relatively recent development computer system design clustering. Clustering alternative symmetric multiprocessing approach providing high performance high availability particularly attractive server appli - cations. define cluster group interconnected, whole computers work - ing together unified computing resource create illusion one machine. term whole computer means system run own, apart cluster; literature, computer cluster typically referred node . [BREW97] lists four benefits achieved clustering. also thought objectives design requirements: ■Absolute scalability: possible create large clusters far surpass power even largest standalone machines. cluster tens, hun - dreds, even thousands machines, multiprocessor. ■Incremental scalability: cluster configured way possible add new systems cluster small increments. Thus, user start modest system expand needs grow, without go major upgrade existing small system replaced larger system. ■High availability: node cluster standalone computer, failure one node mean loss service. many products, fault tol - erance handled automatically software. ■Superior price/performance: using commodity building blocks, possible put together cluster equal greater computing power single large machine, much lower cost. Cluster Configurations literature, clusters classified number different ways. Perhaps sim - plest classification based whether computers cluster share access disks. Figure 17 .8a shows two- node cluster interconnection 634 CHAPTER 17 / P ARAllEl PRoCEssing means high- speed link used message exchange coordi - nate cluster activity. link LAN shared computers part cluster link dedicated interconnection facility. latter case, one computers cluster link LAN WAN connection server cluster remote client systems. Note figure, computer depicted multiprocessor. necessary enhance performance availability. simple classification depicted Figure 17.8, alternative shared- disk cluster. case, generally still message link nodes. addition, disk subsystem directly linked multiple com - puters within cluster. figure, common disk subsystem RAID sys - tem. use RAID similar redundant disk technology common clusters high availability achieved presence multiple computers compromised shared disk single point failure. clearer picture range cluster options gained looking functional alternatives. Table 17.2 provides useful classification along functional lines, discuss.P P High-speed message link High-speed message linkM I/O I/OP P I/O I/O (a) Standby serv er shared disk P P RAIDM I/O I/OP P I/O I/O (b) Shared DiskI/O I/O Figure 17.8 Cluster Configurations17.5 / Clus TERs 635 common, older method, known passive standby , simply one computer handle processing load computer remains inactive, standing take event failure primary. coord - inate machines, active, primary, system periodically sends “heartbeat” message standby machine. messages stop arriving, standby assumes primary server failed puts operation. approach increases availability improve performance. Further, information exchanged two systems heartbeat message, two systems share common disks, standby provides functional backup access databases managed primary. passive standby generally referred cluster. term cluster reserved multiple interconnected computers actively pro - cessing maintaining image single system outside world. term active secondary often used referring configuration. Three classifi - cations clustering identified: separate servers, shared nothing, shared memory. one approach clustering, computer separate server disks disks shared systems (Figure 17.8a). arrange - ment provides high performance well high availability. case, type management scheduling software needed assign incoming client requests servers load balanced high utilization achieved. desir - able failover capability, means computer fails exe - cuting application, another computer cluster pick complete Table 17.2 Clustering Methods: Benefits Limitations Clustering Method Description Benefits Limitations Passive Standby secondary server takes case primary server failure.Easy implement. High cost secondary server unavailable processing tasks. Active Secondary: secondary server also used processing tasks.Reduced cost secondary servers used processing.Increased complexity. Separate Servers Separate servers disks. Data continuously copied primary second- ary server.High availability. High network server overhead due copying operations. Servers Connected DisksServers cabled disks, server owns disks. one server fails, disks taken server.Reduced network server overhead due elimination copying operations.Usually requires disk mirroring RAID tech - nology compensate risk disk failure. Servers Share Disks Multiple servers simul- taneously share access disks.Low network server overhead. Reduced risk downtime caused disk failure.Requires lock manager software. Usually used disk mirroring RAID technology.636 CHAPTER 17 / P ARAllEl PRoCEssing application. happen, data must constantly copied among systems system access current data systems. - head data exchange ensures high availability cost performance penalty. reduce communications overhead, clusters consist servers connected common disks (Figure 17.8b). one variation approach, called shared nothing , common disks partitioned volumes, volume owned single computer. computer fails, cluster must reconfigured computer ownership volumes failed computer. also possible multiple computers share disks time (called shared disk approach), computer access volumes disks. approach requires use type locking facility ensure data accessed one computer time. Operating System Design Issues Full exploitation cluster hardware configuration requires enhancements single- system operating system. failure management failures managed cluster depends clustering method used (Table 17.2). general, two approaches taken dealing failures: highly available clusters fault- tolerant clusters. highly available cluster offers high probability resources service. failure occurs, system goes disk volume lost, queries progress lost. lost query, retried, serviced different computer cluster. However, cluster operating system makes guarantee state partially executed transactions. would need handled application level. fault- tolerant cluster ensures resources always available. achieved use redundant shared disks mechanisms backing uncommitted transactions committing completed transactions. function switching applications data resources failed system alternative system cluster referred failover . related function restoration applications data resources original system fixed; referred failback . Failback automated, desirable problem truly fixed unlikely recur. not, auto - matic failback cause subsequently failed resources bounce back forth computers, resulting performance recovery problems. load balancing cluster requires effective capability balancing load among available computers. includes requirement cluster incrementally scalable. new computer added cluster, load- balancing facility automatically include computer scheduling applications. Middleware mechanisms need recognize services appear different members cluster may migrate one member another. parallelizing computation cases, effective use cluster requires executing software single application parallel. [KAPP00] lists three general approaches problem:17.5 / Clus TERs 637 ■Parallelizing compiler: parallelizing compiler determines, compile time, parts application executed parallel. split assigned different computers cluster. Performance depends nature problem well compiler designed. gen - eral, compilers difficult develop. ■Parallelized application: approach, programmer writes appli - cation outset run cluster, uses message passing move data, required, cluster nodes. places high burden programmer may best approach exploiting clusters applications. ■Parametric computing: approach used essence appli - cation algorithm program must executed large number times, time different set starting conditions parameters. good example simulation model, run large number differ - ent scenarios develop statistical summaries results. approach effective, parametric processing tools needed organize, run, manage jobs effective manner. Cluster Computer Architecture Figure 17 .9 shows typical cluster architecture. individual computers con - nected high- speed LAN switch hardware. computer capable operating independently. addition, middleware layer software installed computer enable cluster operation. cluster middleware provides unified system image user, known single- system image. middleware also responsible providing high availability, means load balancing Figure 17.9 Cluster Computer Architecture [BUYY99]Net. interface HWComm SWPC/workstation Net. interface HWPC/workstation Net. interface HWPC/workstatio n Net. interface HWPC/workstatio n Net. interface HWPC/workstatio nCluster middlewar e (Single system image availability infrastructu re)Sequential applications High-speed network/switchParallel applications Parallel pr ogramming en vironment Comm SW Comm SW Comm SW Comm SW638 CHAPTER 17 / P ARAllEl PRoCEssing responding failures individual components. [HWAN99] lists following desirable cluster middleware services functions: ■Single entry point: user logs onto cluster rather individual computer. ■Single file hierarchy: user sees single hierarchy file directories root directory. ■Single control point: default workstation used cluster manage - ment control. ■Single virtual networking: node access point cluster, even though actual cluster configuration may consist multiple intercon - nected networks. single virtual network operation. ■Single memory space: Distributed shared memory enables programs share variables. ■Single job- management system: cluster job scheduler, user sub - mit job without specifying host computer execute job. ■Single user interface: common graphic interface supports users, regard - less workstation enter cluster. ■Single I/O space: node remotely access I/O peripheral disk device without knowledge physical location. ■Single process space: uniform process- identification scheme used. process node create communicate process remote node. ■Checkpointing: function periodically saves process state inter - mediate computing results, allow rollback recovery failure. ■Process migration: function enables load balancing. last four items preceding list enhance availability cluster. remaining items concerned providing single system image. Returning Figure 17.9, cluster also include software tools enabling efficient execution programs capable parallel execution. Blade Servers common implementation cluster approach blade server. blade server server architecture houses multiple server modules (“blades”) single chassis. widely used data centers save space improve system management. Either self- standing rack mounted, chassis provides power supply, blade processor, memory, hard disk. example application shown Figure 17.10. trend large data centers, substantial banks blade servers, deployment 10-Gbps ports individual servers handle massive multimedia traffic provided servers. arrangements stressing on- site Ethernet switches needed interconnect large numbers servers. 100-Gbps rate pro - vides bandwidth required handle increased traffic load. 100-Gbps 17.5 / Clus TERs 639 N 100GbE 100GbE 10GbE & 40GbEEth switchEth switch Eth switchEth switchAdditional blade serve r racks Eth switch Eth switch Eth switch Eth switch Figure 17.10 Example 100-Gbps Ethernet Configuration Massive Blade Server Site Ethernet switches deployed switch uplinks inside data center well providing interbuilding, intercampus, wide area connections enterprise networks. Clusters Compared SMP clusters symmetric multiprocessors provide configuration multiple processors support high- demand applications. solutions commercially available, although SMP schemes around far longer. main strength SMP approach SMP easier manage configure cluster. SMP much closer original single- processor model nearly applications written. principal change required going uniprocessor SMP scheduler function. Another ben - efit SMP usually takes less physical space draws less power comparable cluster. final important benefit SMP products well established stable. long run, however, advantages cluster approach likely result clusters dominating high- performance server market. Clusters far superior SMPs terms incremental absolute scalability. Clusters also superior terms availability, components system readily made highly redundant.640 CHAPTER 17 / P ARAllEl PRoCEssing 17.6 NONUNIFORM MEMORY ACCESS terms commercial products, two common approaches providing multiple- processor system support applications SMPs clusters. years, another approach, known nonuniform memory access (NUMA), subject research commercial NUMA products available. proceeding, define terms often found NUMA literature. ■Uniform memory access (UMA): processors access parts main memory using loads stores. memory access time processor regions memory same. access times experienced different processors same. SMP organization discussed Sections 17 .2 17 .3 UMA. ■Nonuniform memory access (NUMA): processors access parts main memory using loads stores. memory access time proces - sor differs depending region main memory accessed. last statement true processors; however, different processors, memory regions slower faster differ. ■ Cache- coherent NUMA ( CC- NUMA): NUMA system cache coherence maintained among caches various processors. NUMA system without cache coherence less equivalent clus - ter. commercial products received much attention recently CC- NUMA systems, quite distinct SMPs clusters. Usually, unfortunately always, systems fact referred commercial literature CC- NUMA systems. section concerned CC- NUMA systems. Motivation SMP system, practical limit number processors used. effective cache scheme reduces bus traffic one proces - sor main memory. number processors increases, bus traffic also increases. Also, bus used exchange cache- coherence signals, adding burden. point, bus becomes performance bottleneck. Perfor - mance degradation seems limit number processors SMP configuration somewhere 16 64 processors. example, Silicon Graphics’ Power Challenge SMP limited 64 R10000 processors single system; beyond number performance degrades substantially. processor limit SMP one driving motivations behind development cluster systems. However, cluster, node private main memory; applications see large global memory. effect, coherency maintained software rather hardware. memory granularity affects performance and, achieve maximum performance, software must tai - lored environment. One approach achieving large- scale multiprocessing retaining flavor SMP NUMA.17.6 / nonunifo RM MEMoRy ACCEss 641 objective NUMA maintain transparent system wide mem - ory permitting multiple multiprocessor nodes, bus internal interconnect system. Organization Figure 17 .11 depicts typical CC- NUMA organization. multiple indepen - dent nodes, is, effect, SMP organization. Thus, node con - tains multiple processors, L1 L2 caches, plus main memory. node basic building block overall CC- NUMA organization. example, Silicon Graphics Origin node includes two MIPS R10000 processors; L1 CacheProcessor 1-1 Main Memory 1Processor 1-m L1 Cache L2 Cache L2 Cache Directory I/O I/O L1 CacheProcessor N-1 Main memory NProcessor N-m L1 Cache L2 Cache L2 Cache DirectoryL1 CacheProcessor 2-1 Main Memory 2Processor 2-m L1 Cache L2 Cache L2 Cache Directory I/OInter connect Network Figure 17.11 CC- NUMA Organization642 CHAPTER 17 / P ARAllEl PRoCEssing Sequent NUMA- Q node includes four Pentium II processors. nodes interconnected means communications facility, could switch - ing mechanism, ring, networking facility. node CC- NUMA system includes main memory. point view processors, however, single addressable memory, location unique system wide address. processor initiates memory access, requested memory location processor’s cache, L2 cache initiates fetch operation. desired line local portion main memory, line fetched across local bus. desired line remote portion main memory, automatic request sent fetch line across interconnection network, deliver local bus, deliver requesting cache bus. activity automatic transparent processor cache. configuration, cache coherence central concern. Although imple - mentations differ details, general terms say node must maintain sort directory gives indication location vari - ous portions memory also cache status information. see scheme works, give example taken [PFIS98]. Suppose processor 3 node 2 (P2-3) requests memory location 798, memory node 1. following sequence occurs: 1. P2-3 issues read request snoopy bus node 2 location 798. 2. directory node 2 sees request recognizes location node 1. 3. Node 2’s directory sends request node 1, picked node 1’s directory. 4. Node 1’s directory, acting surrogate P2-3, requests contents 798, processor. 5. Node 1’s main memory responds putting requested data bus. 6. Node 1’s directory picks data bus. 7. value transferred back node 2’s directory. 8. Node 2’s directory places data back node 2’s bus, acting surrogate memory originally held it. 9. value picked placed P2-3’s cache delivered P2-3. preceding sequence explains data read remote mem - ory using hardware mechanisms make transaction transparent pro - cessor. top mechanisms, form cache coherence protocol needed. Various systems differ exactly done. make general remarks here. First, part preceding sequence, node 1’s directory keeps record remote cache copy line containing location 798. Then, needs cooperative protocol take care modifications. example, modification done cache, fact broadcast nodes. node’s directory receives broadcast determine local cache line and, so, cause purged. actual mem - ory location node receiving broadcast notification, node’s 17.7 / Cloud Co MPuTing 643 directory needs maintain entry indicating line memory invalid remains write back occurs. another processor (local remote) requests invalid line, local directory must force write back update memory providing data. NUMA Pros Cons main advantage CC- NUMA system deliver effective perfor - mance higher levels parallelism SMP , without requiring major software changes. multiple NUMA nodes, bus traffic individual node lim - ited demand bus handle. However, many memory accesses remote nodes, performance begins break down. reason believe performance breakdown avoided. First, use L1 L2 caches designed minimize memory accesses, including remote ones. much software good temporal locality, remote memory accesses excessive. Second, software good spatial locality, virtual memory use, data needed application reside limited num - ber frequently used pages initially loaded memory local running application. Sequent designers report spatial locality appear representative applications [LOVE96]. Finally, virtual memory scheme enhanced including operating system page migration mechanism move virtual memory page node frequently using it; Silicon Graphics designers report success approach [WHIT97]. Even performance breakdown due remote access addressed, two disadvantages CC- NUMA approach [PFIS98]. First, CC- NUMA transparently look like SMP; software changes required move operating system applications SMP CC- NUMA sys - tem. include page allocation, already mentioned, process allocation, load balancing operating system. second concern availability. rather complex issue depends exact implementation CC- NUMA system; interested reader referred [PFIS98]. Vector Processor Simulator 17.7 CLOUD COMPUTING Cloud computing introduced Chapter 1, three service models discussed. go greater detail. Cloud Computing Elements NIST SP- 800-145 ( NIST Definition Cloud Computing ) specifies cloud computing composed five essential characteristics, three service models, 644 CHAPTER 17 / P ARAllEl PRoCEssing four deployment models. Figure 17 .12 illustrates relationship among con - cepts. essential characteristics cloud computing include following: ■Broad network access: Capabilities available network accessed standard mechanisms promote use heterogeneous thin thick client platforms (e.g., mobile phones, laptops, tablets) well traditional cloud- based software services. ■Rapid elasticity: Cloud computing gives ability expand reduce resources according specific service requirement. example, may need large number server resources duration specific task. release resources upon completion task. ■Measured service: Cloud systems automatically control optimize resource use leveraging metering capability level abstraction appro - priate type service (e.g., storage, processing, bandwidth, active user accounts). Resource usage monitored, controlled, reported, providing transparency provider consumer utilized service. ■ On- demand self- service: consumer unilaterally provision computing capabilities, server time network storage, needed automatically Broad network access Resource poolingRapid elasticityEssential characteristicsService modelsDeployment modelsMeasured serviceOn-demand self-service Public Private Hybrid CommunitySoftware service (SaaS) Platform service (PaaS) Infrastructure service (IaaS) Figure 17.12 Cloud Computing Elements17.7 / Cloud Co MPuTing 645 without requiring human interaction service provider. service demand, resources permanent parts infrastructure. ■Resource pooling: provider’s computing resources pooled serve multiple consumers using multi- tenant model, different physical virtual resources dynamically assigned reassigned according consumer demand. degree location independence customer gen - erally control knowledge exact location provided resources, may able specify location higher level abstraction (e.g., country, state, datacenter). Examples resources include storage, processing, memory, network bandwidth, virtual machines. Even private clouds tend pool resources different parts organization. NIST defines three service models , viewed nested service alternatives (Figure 17.13). defined Chapter 1, briefly summarized follows: ■Software service (SaaS): Provides service customers form soft - ware, specifically application software, running accessible cloud. (a) SaaSCloud infrastructur e (visible pr ovider)Cloud platform (visible pr ovider)Cloud application softwa (provided cloud, visible subscriber) (b) PaaSCloud infrastructur e (visible pr ovider)Cloud platform (visible subscriber)Cloud application softwa (developed subscriber) (c) IaaSCloud infrastructur e (visible subscriber)Cloud platform (visible subscriber)Cloud application softwar e (developed subscriber) Figure 17.13 Cloud Service Models646 CHAPTER 17 / P ARAllEl PRoCEssing ■Platform service (PaaS): Provides service customers form platform customer's applications run. ■Infrastructure service (IaaS): Provides customer access - lying cloud infrastructure. NIST defines four deployment models : ■Public cloud: cloud infrastructure made available general public large industry group owned organization selling cloud ser - vices. cloud provider responsible cloud infrastructure control data operations within cloud. major advantage public cloud cost. subscribing organization pays services resources needs adjust needed. Further, subscriber greatly reduced management overhead. principal concern security. However, number public cloud providers demonstrated strong security controls and, fact, providers may resources expertise devote security would available private cloud. ■Private cloud: private cloud cloud infrastructure implemented within internal environment organization. organization may choose manage cloud house contract management function third party. Additionally, cloud servers storage devices may exist prem - ise premise. key motivation opting private cloud security. private cloud infrastructure offers tighter controls geographic loca - tion data storage aspects security. ■Community cloud: community cloud shares characteristics private public clouds. Like private cloud, community cloud open sub - scriber. Like public cloud, cloud resources shared among number independent organizations. organizations share community cloud similar requirements and, typically, need exchange data other. One example industry employing community cloud concept health care industry. community cloud implemented comply government privacy regulations. community participants exchange data controlled fashion. cloud infrastruc - ture may managed participating organizations third party may exist premise premise. deployment model, costs spread fewer users public cloud (but private cloud), cost savings potential cloud computing realized. ■Hybrid cloud: cloud infrastructure composition two clouds (pri - vate, community, public) remain unique entities bound together standardized proprietary technology enables data application porta - bility (e.g., cloud bursting load balancing clouds). hybrid cloud solution, sensitive information placed private area cloud, less sensitive data take advantage cost benefits public cloud. Figure 17.14 illustrates typical cloud service context. enterprise main - tains workstations within enterprise LAN set LANs, connected router network Internet cloud service provider. cloud ser - vice provider maintains massive collection servers, manages variety 17.7 / Cloud Co MPuTing 647 network management, redundancy, security tools. figure, cloud infra - structure shown collection blade servers, common architecture. Cloud Computing Reference Architecture NIST SP 500-292 ( NIST Cloud Computing Reference Architecture ) establishes ref - erence architecture, described follows: NIST cloud computing reference architecture focuses requirements “what” cloud services provide, “how to” design solution implementation. reference architecture intended facilitate understanding operational intricacies cloud computing. represent system architecture specific cloud computing system; instead tool describing, discussing, developing system- specific architecture using common framework reference. Network InternetRouter Router ServersLAN switch LAN switchEnterprise cloud user Cloud service provider Figure 17.14 Cloud Computing Context648 CHAPTER 17 / P ARAllEl PRoCEssing NIST developed reference architecture following objectives mind: ■To illustrate understand various cloud services context overall cloud computing conceptual model. ■To provide technical reference consumers understand, discuss, cat - egorize, compare cloud services. ■To facilitate analysis candidate standards security, interoperability, portability reference implementations. reference architecture, depicted Figure 17.15, defines five major actors terms roles responsibilities: ■Cloud consumer: person organization maintains business relation - ship with, uses service from, cloud providers. ■Cloud provider (CP): person, organization, entity responsible making service available interested parties. ■Cloud auditor: party conduct independent assessment cloud ser - vices, information system operations, performance, security cloud implementation. ■Cloud broker: entity manages use, performance, deliv - ery cloud services, negotiates relationships CPs cloud consumers. ■Cloud carrier: intermediary provides connectivity transport cloud services CPs cloud consumers. Cloud consumer Cloud auditorService intermediation Service aggr egation Service arbitrageCloud brokerCloud pr ovider Security audit Performance auditPrivacy impact auditSaaSService layerService chestration Cloud service management PaaS Hardwar ePhysical resour ce layer FacilityResou rce abstraction contr ol layerIaaSBusiness support Provisioning/ con/f_iguration Portability/ inter operability Security Privacy Cloud carrier Figure 17.15 NIST Cloud Computing Reference Architecture17.7 / Cloud Co MPuTing 649 roles cloud consumer provider already discussed. summarize, cloud provider provide one cloud services meet business requirements cloud consumers . three service models (SaaS, PaaS, IaaS), CP provides storage processing facilities needed support service model, together cloud interface cloud service consumers. SaaS, CP deploys, configures, maintains, updates operation software applications cloud infrastructure services provisioned expected service levels cloud con - sumers. consumers SaaS organizations provide members access software applications, end users directly use software applica - tions, software application administrators configure applications end users. PaaS, CP manages computing infrastructure platform runs cloud software provides components platform, runtime software execution stack, databases, middleware components. Cloud consumers PaaS employ tools execution resources provided CPs develop, test, deploy, manage applications hosted cloud environment. IaaS, CP acquires physical computing resources underlying service, including servers, networks, storage, hosting infrastructure. IaaS cloud consumer turn uses computing resources, virtual com - puter, fundamental computing needs. cloud carrier networking facility provides connectivity transport cloud services cloud consumers CPs. Typically, CP set service level agreements (SLAs) cloud carrier provide services consistent level SLAs offered cloud consumers, may require cloud carrier provide dedicated secure connections cloud consum - ers CPs. cloud broker useful cloud services complex cloud con - sumer easily manage. cloud broker offer three areas support: ■Service intermediation: value- added services, identity man - agement, performance reporting, enhanced security. ■Service aggregation: broker combines multiple cloud services meet consumer needs specifically addressed single CP, optimize per - formance minimize cost. ■Service arbitrage: similar service aggregation except ser - vices aggregated fixed. Service arbitrage means broker flexibility choose services multiple agencies. cloud broker, example, use credit- scoring service measure select agency best score. cloud auditor evaluate services provided CP terms secur - ity controls, privacy impact, performance, on. auditor independent entity assure CP conforms set standards.650 CHAPTER 17 / P ARAllEl PRoCEssing 17.8 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms Review Questions 17.1 List briefly define three types computer system organization. 17.2 chief characteristics SMP? 17.3 potential advantages SMP compared uniprocessor? 17.4 key OS design issues SMP? 17.5 difference software hardware cache coherent schemes? 17.6 meaning four states MESI protocol? 17.7 key benefits clustering? 17.8 difference failover failback? 17.9 differences among UMA, NUMA, CC- NUMA? 17.10 cloud computing reference architecture? Problems 17.1 Let percentage program code executed simultaneously n processors computer system. Assume remaining code must executed sequentially single processor. processor execution rate x MIPS. a. Derive expression effective MIPS rate using system exclu - sive execution program, terms n, a, x. b. n=16 x=4 MIPS, determine value yield system per - formance 40 MIPS. 17.2 multiprocessor eight processors 20 attached tape drives. large number jobs submitted system require maximum four tape drives complete execution. Assume job starts running three tape drives long period requiring fourth tape drive short period toward end operation. Also assume endless supply jobs. a. Assume scheduler OS start job unless four tape drives available. job started, four drives assigned immediately released job finishes. maximum number jobs progress once? maximum minimum number tape drives may left idle result policy?active standby cache coherence cluster cloud auditor cloud broker cloud carrier cloud computing cloud consumer cloud provider community cloud directory protocolfailback failover hybrid cloud infrastructure service (IaaS) MESI protocol multiprocessor nonuniform memory access (NUMA) passive standby platform service (PaaS)private cloud public cloud service aggregation service arbitrage service intermediation snoopy protocol software service (SaaS) symmetric multiprocessor (SMP) uniform memory access (UMA) uniprocessor17.8 / K Ey TERMs, REviEw Qu EsTions, PRoblEMs 651 b. Suggest alternative policy improve tape drive utilization time avoid system deadlock. maximum number jobs progress once? bounds number idling tape drives? 17.3 foresee problem write- cache approach bus- based mul - tiprocessors? so, suggest solution. 17.4 Consider situation two processors SMP configuration, time, require access line data main memory. processors cache use MESI protocol. Initially, caches invalid copy line. Figure 17 .16 depicts consequence read line x Processor P1. start sequence accesses, draw subsequent figures following sequence: 1. P2 reads x. 2. P1 writes x (for clarity, label line P1’s cache x′). 3. P1 writes x (label line P1’s cache x″). 4. P2 reads x. 17.5 Figure 17 .17 shows state diagrams two possible cache coherence protocols. Deduce explain protocol, compare MESI. 17.6 Consider SMP L1 L2 caches using MESI protocol. explained Section 17 .3, one four states associated line L2 cache. four states also needed line L1 cache? so, why? not, explain state states eliminated. 17.7 earlier version IBM mainframe, S/390 G4, used three levels cache. z990, first level processor chip [called processor unit (PU)]. L2 cache also similar z990. L3 cache separate chip acted memory controller, interposed L2 caches memory cards. Table 17 .3 shows performance three- level cache arrangement IBM S/390. purpose problem determine whether inclusion third level cache seems worthwhile. Determine access penalty (average number PU cycles) system L1 cache, normalize value 1.0. determine normalized access penalty L1 L2 cache x xMain memory Cache Processor 1Cache SnoopMemory access Processor 2 IE Figure 17.16 MESI Example: Processor 1 Reads Line x652 CHAPTER 17 / P ARAllEl PRoCEssing used, access penalty three caches used. Note amount improvement case state opinion value L3 cache. 17.8 a. Consider uniprocessor separate data instruction caches, hit ratios Hd Hi, respectively. Access time processor cache c clock cycles, transfer time block memory cache b clock cycles. Let fi fraction memory accesses instructions, fd fraction dirty lines data cache among lines replaced. Assume write- back policy deter - mine effective memory access time terms parameters defined. b. assume bus- based SMP processor characteristics part (a). Every processor must handle cache invalidation addition memory reads writes. affects effective memory access time. Let finv fraction data references cause invalidation signals sent data caches. processor sending signal requires clock cycles complete invalida - tion operation. processors involved invalidation operation. Determine effective memory access time. 17.9 organizational alternative suggested illustrations Figure 17 .18? 17.10 Figure 17 .7 , diagrams show horizontal rows partially filled. cases, rows completely blank. represent two different types loss efficiency. Explain. 17.11 Consider pipeline depiction Figure 14.13b, redrawn Figure 17 .19a, fetch decode stages ignored, represent execution thread A. Invalid ValidR(i) R(i) R(j)R(j) W(i)W(i) W(j) W(j) Z(j) Z(i)Invalid ExclusiveShar edR(i) R(i)R(i) R(j) R(j)R(j) Z(j) W(i) W(i)W(i)W(j) W(j) W(j)Z(j) W(i) = Write line pr ocessor R(i) = Read line pr ocessor Z(i) = Displace line cache W(j) = Write line pr ocessor j (j ﬁ i) R(j) = Read line pr ocessor j (j ﬁ i) Z(j) = Displace line cache j (j ﬁ i) Note: State diagrams ar e given line cache Z(j)Z(i) Z(i) Figure 17.17 Two Cache Coherence Protocols Table 17.3 Typical Cache Hit Rate S/390 SMP Configuration [MAK97] Memory SubsystemAccess Penalty (PU cycles) Cache Size Hit Rate (%) L1 cache 1 32 KB 89 L2 cache 5 256 KB 5 L3 cache 14 2 MB 3 Memory 32 8 GB 317.8 / K Ey TERMs, REviEw Qu EsTions, PRoblEMs 653 Figure 17 .19b illustrates execution separate thread B. cases, simple pipelined processor used. a. Show instruction issue diagram, similar Figure 17 .7a, two threads. b. Assume two threads executed parallel chip multipro - cessor, two cores chip using simple pipeline. Show instruction issue diagram similar Figure 17 .7k. Also show pipeline execution diagram style Figure 17 .19. c. Assume two- issue superscalar architecture. Repeat part (b) interleaved multithreading superscalar implementation, assuming data dependencies. (a) (b) (c) (d) Figure 17.18 Diagram Problem 17 .9 B7 B7 B71 2 3 4 5 6 7 8 9 10 11 12 (a)COFO EIWO 1 2B1 3B2B1 4B3B2B1 B4B3B2B1 B5 B5 B5 B5B4 B4 B4B3B2 B6B7B6 B6 B6B3 A16 A16 A16 A16CO FO EIWO A1 A2A1 A3A2A1 A4A3A2A1 A5A4A3A2 A15 A15 A15 A15A35 6 7 8 9 10 11 12 (b)Cycle Figure 17.19 Two Threads Execution654 CHAPTER 17 / P ARAllEl PRoCEssing Note: unique answer; need make assumptions latency priority. d. Repeat part (c) blocked multithreading superscalar implementation. e. Repeat four- issue SMT architecture. 17.12 application program executed nine- computer cluster. benchmark pro - gram took time cluster. Further, found 25% time application running simultaneously nine computers. remain - ing time, application run single computer. a. Calculate effective speedup aforementioned condition compared executing program single computer. Also calculate a, percentage code parallelized (programmed compiled use cluster mode) preceding program. b. Suppose able effectively use 17 computers rather 9 computers parallelized portion code. Calculate effective speedup achieved. 17.13 following FORTRAN program executed computer, parallel version executed 32-computer cluster. L1: 10 = 1, 1024 L2: SUM(I) = 0 L3: 20J = 1,I L4: 20 SUM(I) = SUM(I) + L5: 10 CONTINUE Suppose lines 2 4 take two machine cycle times, including processor memory- access activities. Ignore overhead caused software loop control statements (lines 1, 3, 5) system overhead resource conflicts. a. total execution time (in machine cycle times) program single computer? b. Divide I- loop iterations among 32 computers follows: Computer 1 exe - cutes first 32 iterations ( I=1 32), processor 2 executes next 32 itera - tions, on. execution time speedup factor compared part (a)? (Note computational workload, dictated J- loop, unbal - anced among computers.) c. Explain modify parallelizing facilitate balanced parallel execution computational workload 32 computers. balanced load meant equal number additions assigned computer respect loops. d. minimum execution time resulting parallel execution 32 computers? resulting speedup single computer? 17.14 Consider following two versions program add two vectors: L1: 10 = 1, N L2: A(I) = B(I) + C(I) L3: 10 CONTINUE L4: SUM = 0 L5: 20J = 1, N L6: SUM = SUM + A(J) L7: 20 CONTINUE DOALL K = 1, 10 = L( K- 1)+1, KL A(I) = B(I)+C(I) 10 CONTINUE SUM(K) = 0 20 J = 1, L SUM(K) = SUM(K) + A(L( K- 1)+J) 20 CONTINUE ENDALL a. program left executes uniprocessor. Suppose line code L2, L4, L6 takes one processor clock cycle execute. simplicity, ignore time required lines code. Initially arrays already loaded main memory short program fragment instruction cache. many clock cycles required execute program?17.8 / K Ey TERMs, REviEw Qu EsTions, PRoblEMs 655 b. program right written execute multiprocessor proces - sors. partition looping operations sections L=N/M elements per section. DOALL declares sections executed parallel. result program produce partial sums. Assume k clock cycles needed interprocessor communication operation via shared memory therefore addition partial sum requires k cycles. l- level binary adder tree merge partial sums, l= log 2M. many cycles needed produce final sum? c. Suppose N=220 elements array M=256. speedup achieved using multiprocessor? Assume k=200. percentage theoretical speedup factor 256?656Multicore coMputers 18.1 Hardware Performance Issues Increase Parallelism Complexity Power Consumption 18.2 Software Performance Issues Software Multicore Application Example: Valve Game Software 18.3 Multicore Organization Levels Cache Simultaneous Multithreading 18.4 Heterogeneous Multicore Organization Different Instruction Set Architectures Equivalent Instruction Set Architectures Cache Coherence MOESI Model 18.5 Intel Core i7-990X 18.6 ARM Cortex- A15 MPCore Interrupt Handling Cache Coherency L2 Cache Coherency 18.7 IBM zEnterprise EC12 Mainframe Organization Cache Structure 18.8 Key Terms, Review Questions, Problems CHAPTER18.1 / Hardware Performance Issues 657 multicore processor , also known chip multiprocessor , combines two processor units (called cores) single piece silicon (called die). Typically, core consists components independent processor, registers, ALU, pipeline hardware, control unit, plus L1 instruction data caches. addition multiple cores, contemporary multicore chips also include L2 cache and, increasingly, L3 cache. highly integrated multicore processors, known systems chip (SoCs), also include memory peripheral controllers. chapter provides overview multicore systems. begin look hardware performance factors led development multicore com - puters software challenges exploiting power multicore system. Next, look multicore organization. Finally, examine three examples multicore products, covering personal computer workstation systems (Intel), embedded systems (ARM), mainframes (IBM). 18.1 HARDWARE PERFORMANCE ISSUES discuss Chapter 2, microprocessor systems experienced steady increase execution performance decades. increase due number factors, including increase clock frequency, increase transistor density, refinements organization processor chip. Increase Parallelism Complexity organizational changes processor design primarily focused exploiting ILP , work done clock cycle. changes include, chronological order (Figure 18.1): ■Pipelining: Individual instructions executed pipeline stages one instruction executing one stage pipeline, another instruction executing another stage pipeline. ■Superscalar: Multiple pipelines constructed replicating execution resources. enables parallel execution instructions parallel pipelines, long hazards avoided.Learning Objectives studying chapter, able to: rUnderstand hardware performance issues driven move multicore computers. rUnderstand software performance issues posed use multi- threaded multicore computers. rPresent overview two principal approaches heterogeneous multi- core organization . rHave appreciation use multicore organization embedded systems, PCs servers, mainframes.658 cHaPTer 18 / mulTIcore comPuTers ■Simultaneous multithreading (SMT): Register banks expanded multiple threads share use pipeline resources. innovations, designers years attempted increase performance system adding complexity. case pipelin - ing, simple three- stage pipelines replaced pipelines five stages. Intel’s Pentium 4 “Prescott” core 31 stages instructions. practical limit far trend taken, stages, need logic, interconnections, control signals. superscalar organization, increased performance achieved increasing number parallel pipelines. Again, diminishing returns Instruction fetch unitIssue logic Program counter Execution units queues L1 instruction cache L2 cache (a) SuperscalarL1 data cacheSingle-thr ead r egister /f_ile Instruction fetch unitIssue logic Execution units queues L1 instruction cache L2 cache (b) Simultaneous multithreadingL1 data cachePC 1 PC n Register 1 Registers nL1-I L1-D L2 cacheCore 1 (superscalar SMT) (c) MulticoreL1-I L1-DCore 2 (superscalar SMT) L1-I L1-DCore 3 (superscalar SMT) L1-I L1-DCore n (superscalar SMT) Figure 18.1 Alternative Chip Organizations18.1 / Hardware Performance Issues 659 number pipelines increases. logic required manage hazards stage instruction resources. Eventually, single thread execution reaches point hazards resource dependencies prevent full use multiple pipelines available. Also, compiled binary code rarely exposes enough ILP take advantage six parallel pipelines. point diminishing returns reached SMT, complexity managing multiple threads set pipelines limits number threads number pipelines effectively utilized. SMT’s advantage lies fact two (or more) program streams searched available ILP. related set problems dealing design fabrication computer chip. increase complexity deal logical issues related long pipelines, multiple superscalar pipelines, multiple SMT register banks means increasing amounts chip area occupied coordinating signal transfer logic. increases difficulty designing, fab - ricating, debugging chips. increasingly difficult engineering challenge related processor logic one reasons increasing fraction processor chip devoted simpler memory logic. Power issues, discussed next, provide another reason. Power Consumption maintain trend higher performance number transistors per chip rises, designers resorted elaborate processor designs (pipelining, super - scalar, SMT) high clock frequencies. Unfortunately, power requirements grown exponentially chip density clock frequency risen. shown Figure 2.2. One way control power density use chip area cache memory. Memory transistors smaller power density order magnitude lower logic (see Figure 18.2). chip transistor density increased, percentage chip area devoted memory grown, often half chip area. Even so, still considerable amount chip area devoted processing logic. Featur e size ( µm)Logic MemoryPower density (watts/cm2) 0.25110100 0.18 0.13 0.10 Figure 18.2 Power Memory Considerations660 cHaPTer 18 / mulTIcore comPuTers use logic transistors key design issue. discussed earlier section, limits effective use techniques superscalar SMT. general terms, experience recent decades encapsu - lated rule thumb known Pollack’s rule [POLL99], states per - formance increase roughly proportional square root increase complexity. words, double logic processor core, delivers 40% performance. principle, use multiple cores potential provide near- linear performance improvement increase number cores— software take advantage. Power considerations provide another motive moving toward mul - ticore organization. chip huge amount cache memory, becomes unlikely one thread execution effectively use memory. Even SMT, multithreading done relatively limited fashion cannot therefore fully exploit gigantic cache, whereas number relatively inde - pendent threads processes greater opportunity take full advantage cache memory. 18.2 SOFTWARE PERFORMANCE ISSUES detailed examination software performance issues related multicore organization beyond scope. section, first provide overview issues, look example application designed exploit mul - ticore capabilities. Software Multicore potential performance benefits multicore organization depend abil - ity effectively exploit parallel resources available application. Let us focus first single application running multicore system. Recall Chap - ter 2 Amdahl’s law states that: Speed up=time execute program single processor time execute program N parallel processors =1 (1--f) + f N (18.1) law assumes program fraction (1--f) execution time involves code inherently sequential fraction f involves code infinitely parallelizable scheduling overhead. law appears make prospect multicore organization attrac - tive. Figure 18.3a shows, even small amount serial code noticeable impact. 10% code inherently serial (f=0.9), running program multicore system eight processors yields performance gain factor 4.7. addition, software typically incurs overhead result communi - cation distribution work among multiple processors result cache 18.2 / sofTware Performance Issues 661 coherence overhead. overhead results curve performance peaks begins degrade increased burden overhead using multiple processors (e.g., coordination OS management). Figure 18.3b, [MCDO05], representative example. However, software engineers addressing problem numerous applications possible effectively exploit multicore system. [MCDO05] analyzes effectiveness multicore systems set data - base applications, great attention paid reducing serial fraction within hardware architectures, operating systems, middleware, database Relative speedup Relative speedup02468 2 1 Number pr ocessors (a) Speedup 0%, 2%, 5%, 10% sequential portions3 4 5 60% 2% 5% 10% 10%5% 15% 20%7 8 00.51.01.52.02.5 2 1 Number pr ocessors (b) Speedup overheads3 4 5 6 7 8 Figure 18.3 Performance Effect Multiple Cores662 cHaPTer 18 / mulTIcore comPuTers application software. Figure 18.4 shows result. example shows, database management systems database applications one area multicore systems used effectively. Many kinds servers also effectively use parallel multicore organization, servers typically handle numerous rela - tively independent transactions parallel. addition general- purpose server software, number classes applica - tions benefit directly ability scale throughput number cores. [MCDO06] lists following examples: ■Multithreaded native applications ( thread- level parallelism): Multithreaded applications characterized small number highly threaded processes. ■Multiprocess applications ( process- level parallelism): Multiprocess applica - tions characterized presence many single- threaded processes. ■Java applications: Java applications embrace threading fundamental way. Java language greatly facilitate multithreaded applications, Java Virtual Machine multithreaded process provides sched - uling memory management Java applications. ■ Multi- instance applications ( application- level parallelism): Even individ - ual application scale take advantage large number threads, still possible gain multicore architecture running multiple instances application parallel. multiple application instances require degree isolation, virtualization technology (for hardware operating system) used provide separate secure domain. 0016324864 16 32 Number CPUsScaling 48 64Perfect scalingOracle DSS 4-way join TMC data mining DB2 DSS scan & aggs Oracle ad hoc insurance OL TP Figure 18.4 Scaling Database Workloads Multiple- Processor Hardware18.2 / sofTware Performance Issues 663 turning example, elaborate topic thread- level par - allelism introducing concept threading granularity , defined minimal unit work beneficially parallelized. general, finer granularity system enables, less constrained programmer parallelizing program. Consequently, finer grain threading systems allow paralleli - zation situations coarse- grained ones. choice target gran - ularity architecture involves inherent tradeoff. one hand, finer grain systems preferable flexibility afford program - mer. hand, finer threading granularity, significant part execution taken threading system overhead. Application Example: Valve Game Software Valve entertainment technology company developed number popular games well Source engine, one widely played game engines available. Source animation engine used Valve games licensed game developers. Valve reprogrammed Source engine software use multithreading exploit scalability multicore processor chips Intel AMD [REIM06]. revised Source engine code provides powerful support Valve games Half Life 2. Valve’s perspective, threading granularity options defined follows [HARR06]: ■ Coarse- grained threading: Individual modules, called systems, assigned individual processors. Source engine case, means putting rendering one processor, AI (artificial intelligence) another, physics another, on. straightforward. essence, major module single threaded principal coordination involves synchronizing threads timeline thread. ■ Fine- grained threading: Many similar identical tasks spread across multiple processors. example, loop iterates array data split number smaller parallel loops individual threads scheduled parallel. ■Hybrid threading: involves selective use fine- grain threading systems single threading systems. Valve found coarse threading, could achieve twice per - formance across two processors compared executing single processor. performance gain could achieved contrived cases. real- world game - play, improvement order factor 1.2. Valve also found effec - tive use fine- grain threading difficult. time per work unit variable, managing timeline outcomes consequences involved complex programming. Valve found hybrid threading approach promising would scale best multicore systems eight sixteen processors became available. Valve identified systems operate effectively assigned single processor permanently. example sound mixing, little user interaction, constrained frame configuration windows, works 664 cHaPTer 18 / mulTIcore comPuTers set data. modules, scene rendering, organized number threads module execute single processor achieve greater performance spread processors. Figure 18.5 illustrates thread structure rendering module. hierarchical structure, higher- level threads spawn lower- level threads needed. rendering module relies critical part Source engine, world list, database representation visual elements game’s world. first task determine areas world need rendered. next task determine objects scene viewed multiple angles. comes processor- intensive work. rendering module work rendering object multiple points view, player’s view, view TV monitors, point view reflections water. key elements threading strategy rendering module listed [LEON07] include following: ■Construct scene- rendering lists multiple scenes parallel (e.g., world reflection water). ■Overlap graphics simulation. ■Compute character bone transformations characters scenes parallel. ■Allow multiple threads draw parallel. Render Skybox Main view Scene list object Particles Sim draw Bone setup DrawCharacter Etc.Monitor Etc. Figure 18.5 Hybrid Threading Rendering Module18.3 / mulTIcore organ IzaTIon 665 designers found simply locking key databases, world list, thread inefficient. 95% time, thread trying read data set, 5% time spent writing data set. Thus, concurrency mechanism known single- writer- multiple- readers model works effectively. 18.3 MULTICORE ORGANIZATION top level description, main variables multicore organization follows: ■The number core processors chip ■The number levels cache memory ■How cache memory shared among cores ■Whether simultaneous multithreading (SMT) employed ■The types cores explore last considerations section, deferring discussion types cores next section. Levels Cache Figure 18.6 shows four general organizations multicore systems. Figure 18.6a organization found earlier multicore computer chips still seen embedded chips. organization, on- chip cache L1 cache, core dedicated L1 cache. Almost invariably, L1 cache divided instruction data caches performance reasons, L2 higher- level caches unified. example organization ARM11 MPCore. organization Figure 18.6b also one on- chip cache sharing. this, enough area available chip allow L2 cache. example organization AMD Opteron. Figure 18.6c shows similar allocation chip space memory, use shared L2 cache. Intel Core Duo organization. Finally, amount cache memory available chip continues grow, performance considerations dictate splitting separate, shared L3 cache (Figure 18.6d), dedicated L1 L2 caches core processor. Intel Core i7 example organization. use shared higher- level cache chip several advantages exclusive reliance dedicated caches: 1. Constructive interference reduce overall miss rates. is, thread one core accesses main memory location, brings line containing referenced location shared cache. thread another core soon thereafter accesses memory block, memory locations already available shared on- chip cache. 2. related advantage data shared multiple cores replicated shared cache level.666 cHaPTer 18 / mulTIcore comPuTers 3. proper line replacement algorithms, amount shared cache allo - cated core dynamic, threads less locality (larger working sets) employ cache. 4. Inter- core communication easy implement, via shared memory locations. 5. use shared higher- level cache confines cache coherency problem lower cache levels, may provide additional performance advantage. potential advantage dedicated L2 caches chip core enjoys rapid access private L2 cache. advantageous threads exhibit strong locality. amount memory available number cores grow, use shared L3 cache combined dedicated percore L2 caches seems likely provide better performance simply massive shared L2 cache large dedicated L2 caches on- chip L3. example latter arrangement Xeon E5-2600/4600 chip processor (Figure 7.1) shown arrangement L1s local core, L2s shared among 2 4 cores, L3 global across cores. arrangement likely become common time.CPU Cor e 1 L1-D L2 cache L2 cacheL1-ICPU Co n L1-D L1-I Main memory (b) Dedicated L2 cacheI/O CPU Cor e 1 L1-D L2 cache L3 cacheL2 cacheL1-ICPU Co n L1-D L1-I Main memory (d ) Shared L3 cacheI/OCPU Cor e 1 L1-D L2 cacheL1-ICPU Cor e n L1-D L1-I Main memory (c) Shared L2 cacheI/OCPU Cor e 1 L1-D L1-ICPU Cor e n L1-D L1-I L2 cache Main memory (a) Dedicated L1 cacheI/O Figure 18.6 Multicore Organization Alternatives18.4 / Terogeneous mulTIcore organ IzaTIon 667 Simultaneous Multithreading Another organizational design decision multicore system whether indi - vidual cores implement simultaneous multithreading (SMT) . example, Intel Core Duo uses pure superscalar cores, whereas Intel Core i7 uses SMT cores. SMT effect scaling number hardware- level threads multicore system supports. Thus, multicore system four cores SMT supports four simultaneous threads core appears appli - cation level multicore system 16 cores. software developed fully exploit parallel resources, SMT approach appears attractive purely superscalar approach. 18.4 HETEROGENEOUS MULTICORE ORGANIZATION quest make optimal use silicon real estate processor chip never ending. clock speeds logic densities increase, designers must balance many design elements attempts maximize performance minimize power con - sumption. far examined number approaches, including following: 1. Increase percentage chip devoted cache memory. 2. Increase number levels cache memory. 3. Change length (increase decrease) functional components instruction pipeline. 4. Employ simultaneous multithreading. 5. Use multiple cores. typical case use multiple cores chip multiple identical cores, known homogenous multicore organization . achieve better results, terms performance and/or power consumption, increasingly popular design choice heterogeneous multicore organization , refers processor chip includes one kind core. section, look two approaches heterogeneous multicore organization. Different Instruction Set Architectures approach received industry attention use cores distinct ISAs. Typically, involves mixing conventional cores, referred context CPUs, specialized cores optimized certain types data applications. often, additional cores optimized deal vector matrix data processing. cpu/gpu multicore prominent trend terms heterogeneous multicore design use CPUs graphics processing units (GPUs) chip. GPUs discussed detail following chapter. Briefly, GPUs characterized ability support thousands parallel execution threads. Thus, GPUs well matched applications process large amounts 668 cHaPTer 18 / mulTIcore comPuTers vector matrix data. Initially aimed improving performance graphics applications, thanks easy- to- adopt programming models CUDA (Compute Unified Device Architecture), new processors increasingly applied improve performance general- purpose scientific applications involve large numbers repetitive operations structured data. deal diversity target applications today’s computing environ - ment, multicore containing GPUs CPUs potential enhance per - formance. heterogeneous mix, however, presents issues coordination correctness. Figure 18.7 typical multicore processor organization. Multiple CPUs GPUs share on- chip resources, last- level cache (LLC), interconnection network, memory controllers. critical way cache manage - ment policies provide effective sharing LLC. differences cache sensitiv - ity memory access rate CPUs GPUs create significant challenges efficient sharing LLC. Table 18.1 illustrates potential performance benefit combining CPUs GPUs scientific applications. table shows basic operating param - eters AMD chip, A10 5800K [ALTS12]. floating- point calculations, CPU’s performance 121.6 GFLOPS dwarfed GPU, offers 614 GFLOPS applications utilize resource effectively. Whether scientific applications traditional graphics processing, key leveraging added GPU processors consider time needed transfer block data GPU, process it, return results main application thread. earlier implementations chips incorporated GPUs, physical mem- ory partitioned CPU GPU. application thread running CPU demands GPU processing, CPU explicitly copies data GPU memory. GPU completes computation copies result back CPU memory. Issues cache coherence across CPU GPU memory caches arise memory partitioned. hand, physical hand - ing data back forth results performance penalty. number research development efforts underway improve per - formance described preceding paragraph, notable CacheCPU CacheCPU On-chip inter connection networkCacheGPU CacheGPU Last- level cacheLast- level cacheDRAM contr ollerDRAM contr oller Figure 18.7 Heterogenous Multicore Chip Elements18.4 / Terogeneous mulTIcore organ IzaTIon 669 initiative Heterogeneous System Architecture (HSA) Foundation. Key features HSA approach include following: 1. entire virtual memory space visible CPU GPU. CPU GPU access allocate location system’s virtual memory space. 2. virtual memory system brings pages physical main memory needed. 3. coherent memory policy ensures CPU GPU caches see up- to- date view data. 4. unified programming interface enables users exploit parallel capabilities GPUs within programs rely CPU execution well. overall objective allow programmers write applications exploit serial power CPUs parallel- processing power GPUs seam - lessly efficient coordination OS hardware level. mentioned, ongoing area research development. cpu/dsp multicore Another common example heterogeneous multicore chip mixture CPUs digital signal processors (DSPs). DSP provides ultra- fast instruction sequences (shift add; multiply add), commonly used math- intensive digital signal processing applications. DSPs used process analog data sources sound, weather satellites, earthquake monitors. Signals converted digital data analyzed using various algorithms Fast Fourier Transform. DSP cores widely used myriad devices, including cellphones, sound cards, fax machines, modems, hard disks, digital TVs. good representative example, Figure 18.8 shows recent version Texas Instruments (TI) K2H SoC platform [TI12]. heterogeneous multicore processor delivers power- efficient processing solutions high- end imaging appli - cations. TI lists performance delivering 352 GMACS, 198 GFLOPS, 19,600 MIPS. GMACS stands giga (billions of) multiply- accumulate opera - tions per second, common measure DSP performance. Target applications systems include industrial automation, video surveillance, high- end inspection systems, industrial printers/scanners, currency/counterfeit detection.Table 18.1 Operating Parameters AMD 5100K Heterogeneous Multicore Processor CPU GPU Clock frequency (GHz) 3.8 0.8 Cores 4 384 FLOPS/core 8 2 GFLOPS 121.6 614.4 FLOPS=floating@point operations per second. FLOPS/core=number parallel floating- point operations performed.670 cHaPTer 18 / mulTIcore comPuTers TI chip includes four ARM Cortex- A15 cores eight TI C66x DSP cores. DSP core contains 32 kB L1 data cache 32 kB L1 program (instruction) cache. addition, DSP 1 MB dedicated SRAM memory configured L2 cache, main memory, mix two. portion configured main memory functions “local” main memory, referred simply SRAM . local main memory used temporary data, avoid - ing need traffic cache off- chip memory. L2 cache 32-kB L1 D-cache 1MB L2 cache32-kB L1 P-cacheC66x DSP 32-kB L1 P-cache32-kB L1 D-cache32-kB L1 P-cache32-kB L1 D-cache 32-kB L1 P-cache32-kB L1 D-cache32-kB L1 P-cache32-kB L1 D-cacheARM Cortex-A15Memory subsystem Multicor e navigator Networ k copr ocessorARM Cortex-A15 ARM Cortex-A15ARM Cortex-A1572-bit DDR3 EMIF 72-bit DDR3 EMIF6-MB MSM SRAM Debug & trace Boot ROM Semaphor e Power management PLL EDMA EMIF16 USB 3.0GPIO x32 PCIe x2 SRIO x43x I2C 2x UART 3x SPI 1GBE 1GBE 1GBE 1GBE5-port Ether net switchSecurity accelerator Packet accelerator KeyboardPacket DMAQueu e managerTeraNet 2x HyperLink5x5x8x 8 CSSx DSP cor es @ 1.2 GHz 4 ARM cor es @ 1.4 Ghz4MB L2 cacheMSMC Figure 18.8 Texas Instruments 66AK2H12 Heterogenous Multicore Chip18.4 / Terogeneous mulTIcore organ IzaTIon 671 eight DSP cores dedicated rather shared DSP cores. typical multicore DSP organization: DSP works separate block data parallel, little need data sharing. ARM Cortex- A15 CPU core 32-kB L1 data program caches, four cores share 4-MB L2 cache. 6-MB multicore shared memory (MSM) always configured SRAM. is, behaves like main memory rather cache. config - ured feed directly L1 DSP CPU caches, feed L2 DSP CPU caches. configuration decision depends expected application profile. multicore shared memory controller (MSMC) manages traffic among ARM cores, DSP, DMA, mastering peripherals, external memory interface (EMIF). MSMC controls access MSM, accessible cores mastering peripherals device. Equivalent Instruction Set Architectures Another recent approach heterogeneous multicore organization use multiple cores equivalent ISAs vary performance power effi - ciency. leading example ARM’s big.Little architecture, exam - ine section. Figure 18.9 illustrates architecture. figure shows multicore pro - cessor chip containing two high- performance Cortex- A15 cores two lower- performance, lower- power- consuming Cortex- A7 cores. A7 cores handle less computation- intense tasks, background processing, playing music, sending texts, making phone calls. A15 cores invoked high intensity tasks, video, gaming, navigation. big.Little architecture aimed smartphone tablet market. devices whose performance demands users increasing much faster rate capacity batteries power savings semiconductor process advances. usage pattern smartphones tablets quite dynamic. Periods processing- intense tasks, gaming web browsing, alternate Cortex-A15 coreCortex-A15 core L2Cortex-A7 coreCortex-A7 core L2I/O coher ent masterGIC-400 global interrupt cont roller Interrupts Memory contr oller ports System portCCI-400 (cache coher ent inter connect)Interrupts Figure 18.9 big.Little Chip Components672 cHaPTer 18 / mulTIcore comPuTers typically longer periods low processing- intensity tasks, texting, e- mail, audio. big.Little architecture takes advantage variation required performance. A15 designed maximum performance within mobile power budget. A7 processor designed maximum efficiency high enough performance address intense periods work. a7 a15 characteristics A7 far simpler less powerful A15. simplicity requires far fewer transistors A15’s complexity— fewer transistors require less energy operate. differences A7 A15 cores seen clearly examining instruction pipelines, shown Figure 18.10. (b) Corte x A-15 Pipeline (a) Cort ex A-7 PipelineInteger Write back Multiply Floating-point/NEON Decode Fetch Fetch Loop cacheDecode, Rename, & Dispatch Queue Issue Integer Integer Multiply Floating-point/NEON Branch Load StoreWrite backIssue Dual issue Load/Stor e Figure 18.10 Cortex A- 7 A- 15 Pipelines18.4 / Terogeneous mulTIcore organ IzaTIon 673 A7 in- order CPU pipeline length 8 10 stages. single queue execution units, two instructions sent five execution units per clock cycle. A15, hand, -of- order pro - cessor pipeline length 15 24 stages. eight execution units multi stage queue, three instructions processed per clock cycle. energy consumed execution instruction partially related number pipeline stages must traverse. Therefore, significant difference energy consumption Cortex- A15 Cortex- A7 comes different pipeline complexity. Across range benchmarks, Cortex- A15 delivers roughly twice performance Cortex- A7 per unit MHz, Cortex- A7 roughly three times energy efficient Cortex- A15 completing workloads [JEFF12]. performance tradeoff illustrated Figure 18.11 [STEV13]. software processing models big.Little architecture configured use one two software processing models: migration multiprocessing (MP). software models differ mainly way allocate work big Little cores runtime execution workload. migration model, big Little cores paired. OS kernel scheduler, big/Little pair visible single core. Power management software responsible migrating software contexts two cores. model natural extension dynamic voltage frequency scaling (DVFS) operating points provided current mobile platforms allow OS match perfor - mance platform performance required application. today’s smartphone SoCs, DVFS drivers like cpu_freq sample OS performance reg - ular frequent intervals, DVFS governor decides whether shift higher lower operating point remain current operating point. shown Figure 18.11, A7 A15 execute four distinct operating PerformancePower Lowest Cortex-A7 operating pointLowest Cortex-A15 operating point Highest Cortex-A7 operating pointHighest Cortex-A15 operating point Figure 18.11 Cortex- A7 A15 Performance Comparison674 cHaPTer 18 / mulTIcore comPuTers points. DVFS software effectively dial one operating points curve, setting specific CPU clock frequency voltage level. operating points affect voltage frequency single CPU clus - ter; however, big.Little system two CPU clusters independent voltage frequency domains. allows big cluster act logical exten - sion DVFS operating points provided Little processor cluster. big.Little system migration mode control, Cortex- A7 executing, DVFS driver tune performance CPU cluster higher levels. Cortex- A7 highest operating point, performance required, task migration invoked picks OS applications moves Cortex- A15. today’s smartphone SoCs, DVFS drivers like cpu_freq sample OS performance regular frequent intervals, DVFS gov - ernor decides whether shift higher lower operating point remain current operating point. migration model simple requires one CPUs pair always idle. MP model allows mixture A15 A7 cores powered executing simultaneously. Whether big processor needs powered determined performance requirements tasks currently executing. demanding tasks, big processor powered execute them. Low demand tasks execute Little processor. Finally, processors used powered down. ensures cores, big Little, active needed, appropriate core used execute given workload. MP model somewhat complicated implement also efficient resources. assigns tasks appropriately enables cores running simultaneously demand warrants it. Cache Coherence MOESI Model Typically, heterogeneous multicore processor feature dedicated L2 cache assigned different processor types. see general depiction CPU/GPU scheme Figure 18.7 . CPU GPU engaged quite different tasks, makes sense L2 cache, shared among simi - lar CPUs. also see big.Little architecture (Figure 18.9), A7 cores share L2 cache A15 cores share separate L2 cache. multiple caches exist, need cache- coherence scheme avoid access invalid data. Cache coherency may addressed software- based techniques. case cache contains stale data, cached copy may invalidated reread memory needed again. memory contains stale data due write- back cache containing dirty data, cache may cleaned forcing write back memory. cached copies may exist caches must invalidated. software burden consumes many resources SoC chip, leading use hardware cache- coherent implementations, especially heterogeneous multicore processors. described Chapter 17, two main approaches hardware- implemented cache coherence: directory protocols snoopy protocols. ARM developed hardware coherence capability called ACE ( Advanced Extensible 18.4 / Terogeneous mulTIcore organ IzaTIon 675 Interface Coherence Extensions) configured implement either direc - tory snoopy approach, even combination. ACE designed sup - port wide range coherent masters differing capabilities. ACE supports coherency dissimilar processors Cortex- A15 Cortex- A7 processors, enabling ARM big.Little technology. supports I/O coherency un- cached masters, supports masters differing cache line sizes, differing inter - nal cache state models, masters write- back write- caches. another example, ACE implemented memory subsystem memory control - ler (MSMC) TI SoC chip Figure 18.8. MSMC supports hardware cache coherence ARM CorePac L1/L2 caches EDMA/IO peripherals shared SRAM DDR spaces. feature allows sharing MSMC SRAM DDR data spaces masters chip, without use explicit software cache maintenance techniques. ACE makes use five- state cache model. cache, line either Valid Invalid. line Valid, one four states, defined two dimensions. line may contain data Shared Unique. Shared line con - tains data region external (main) memory potentially sharable. Unique line contains data region memory dedicated core owning cache. line either Clean Dirty, generally meaning either memory contains latest, up- to- date data cache line merely copy memory, it’s Dirty cache line latest, up- to- date data must written back memory stage. one exception description multiple caches share line it’s dirty. case, caches must contain latest data value times, one may Shared/ Dirty state, others held Shared/Clean state. Shared/Dirty state thus used indicate cache responsibility writing data back memory, Shared/Clean accurately described meaning data shared need write back memory. ACE states correspond cache coherency model five states, known MOESI (Figure 18.12). Table 18.2 compares MOESI model MESI model described Chapter 17. Modi/f_iedUnique Owned Invalid Exclusive Shar edShar ed InvalidClean Dirty Figure 18.12 ARM ACE Cache Line States676 cHaPTer 18 / mulTIcore comPuTers 18.5 INTEL CORE i7-990X Intel introduced number multicore products recent years. section, look Intel Core i7-990X. general structure Intel Core i7-990X shown Figure 18.13. core dedicated L2 cache six cores share 12-MB L3 cache . One mechanism Intel uses make caches effective prefetching, hardware examines memory access patterns attempts fill caches specula - tively data that’s likely requested soon. Core i7-990X chip supports two forms external communications chips. DDR3 memory controller brings memory controller DDR main memory1 onto chip. interface supports three channels 8 bytes wide total bus width 192 bits, aggregate data rate 32 GB/s. memory controller chip, Front Side Bus eliminated. QuickPath Interconnect (QPI) cache- coherent, point- to- point link- based electrical interconnect specification Intel processors chipsets. ena - bles high- speed communications among connected processor chips. QPI link operates 6.4 GT/s (transfers per second). 16 bits per transfer, adds 12.8 GB/s, since QPI links involve dedicated bidirectional pairs, total band - width 25.6 GB/s. Section 3.5 covers QPI detail.Table 18.2 Comparison States Snoop Protocols (a) MESIM Modified Exclusive Shared Invalid Clean/Dirty Dirty Clean Clean N/A Unique? Yes Yes N/A write? Yes Yes N/A forward? Yes Yes Yes N/A Comments Must write back share replaceTransitions writeShared implies clean, forwardCannot read (b) MOESI Modified Owned Exclusive Shared Invalid Clean/Dirty Dirty Dirty Clean Either N/A Unique? Yes Yes Yes N/A write? Yes Yes Yes N/A forward? Yes Yes Yes N/A Comments share without write backMust write back transitionTransitions writeShared, dirty cleanCannot read 1The DDR synchronous RAM memory discussed Chapter 5.18.6 / arm corTex- a15 mPcore 677 18.6 ARM CORTEX- A15 MPCORE already seen two examples heterogeneous multicore processors using ARM cores, Section 18.4: big.Little architecture, uses combination ARM Cortex- A7 Cortex- A15 cores; Texas Instruments DSP SoC archi - tecture, combines Cortex- A15 cores TI DSP cores. section, introduce Cortex- A15 MPCore multicore chip, homogeneous mul - ticore processor using multiple A15 cores. A15 MPCore high- performance chip targeted applications including mobile computing, high- end digital home servers, wireless infrastructure. Figure 18.14 presents block diagram Cortex- A15 MPCore. key elements system follows: ■Generic interrupt controller (GIC): Handles interrupt detection interrupt prioritization. GIC distributes interrupts individual cores. ■Debug unit interface: debug unit enables external debug host to: stop program execution; examine alter process coprocessor state; examine alter memory input/output peripheral state; restart processor. ■Generic timer: core private timer generate interrupts. ■Trace: Supports performance monitoring program trace tools. ■Core: single ARM Cortex- 15 core. ■L1 cache: core dedicated L1 data cache L1 instruction cache. ■L2 cache: shared L2 memory system services L1 instruction data cache misses core. ■Snoop control unit (SCU): Responsible maintaining L1/L2 cache coherency.Core 0 32 kB L1-I32 kB L1-D32 kB L1-I32 kB L1-D32 kB L1-I32 kB L1-D32 kB L1-I32 kB L1-D32 kB L1-I32 kB L1-D32 kB L1-I32 kB L1-D 256 kB L2 CacheCore 1 256 kB L2 CacheCore 2 256 kB L2 CacheCore 3 256 kB L2 CacheCore 4 256 kB L2 CacheCore 5 256 kB L2 Cache 12 MB L3 Cache DDR3 Memory Contr ollersQuickPath Inter connect 3 × 8B @ 1.33 GT/s 4 × 20B @ 6.4 GT/s Figure 18.13 Intel Core i7-990X Block Diagram678 cHaPTer 18 / mulTIcore comPuTers Interrupt Handling GIC collates interrupts large number sources. provides ■Masking interrupts ■Prioritization interrupts ■Distribution interrupts target A15 cores ■Tracking status interrupts ■Generation interrupts software GIC single functional unit placed system alongside A15 cores. enables number interrupts supported system inde - pendent A15 core design. GIC memory mapped; is, control reg - isters GIC defined relative main memory base address. GIC accessed A15 cores using private interface SCU.Snoop contr ol unit (SCU)L1 cacheCPU/VFPTimer CPU inter- face Wdog L1 cacheCPU/VFP L1 cacheCPU/VFP L1 cacheCPU/VFPTimer CPU inter- face WdogTimer CPU inter - face WdogTimer CPU inter - face WdogGeneric interrupt contr ollerCon/f_igurable number hard ware interrupt lines Instruction data 64-bit busCoher ency contr ol bitsInstruction data 64-bit bus Read/write 64-bit busIRQ IRQ IRQ IRQPer CPU private fast interrupt (FIQ) lines Optional 2nd R/W 64-bit busCoher ency contr ol bitsInstruction data 64-bit busCoher ency contr ol bitsInstruction data 64-bit busCoher ency contr ol bits Figure 18.14 ARM Cortex- A15 MPCore Chip Block Diagram18.6 / arm corTex- a15 mPcore 679 GIC designed satisfy two functional requirements: ■Provide means routing interrupt request single CPU multiple CPUs, required. ■Provide means interprocessor communication thread one CPU cause activity thread another CPU. example makes use requirements, consider multithreaded application threads running multiple processors. Suppose applica - tion allocates virtual memory. maintain consistency, operating system must update memory translation tables processors. OS could update tables processor virtual memory allocation took place, issue interrupt processors running application. processors could use interrupt’s ID determine need update memory translation tables. GIC route interrupt one CPUs following three ways: ■An interrupt directed specific processor only. ■An interrupt directed defined group processors. MPCore views first processor accept interrupt, typically least loaded, best positioned handle interrupt. ■An interrupt directed processors. point view software running particular CPU, OS generate interrupt self, self, specific CPUs. commu - nication threads running different CPUs, interrupt mechanism typically combined shared memory message passing. Thus, thread interrupted interprocessor communication interrupt, reads appro - priate block shared memory retrieve message thread triggered interrupt. total 16 interrupt IDs per CPU available interprocessor communication. point view A15 core, interrupt be: ■Inactive: Inactive interrupt one nonasserted, multi - processing environment completely processed CPU still either Pending Active CPUs targeted, might cleared interrupt source. ■Pending: Pending interrupt one asserted, processing started CPU. ■Active: Active interrupt one started CPU, pro - cessing complete. Active interrupt pre- empted new interrupt higher priority interrupts A15 core interrupt processing. Interrupts come following sources: ■Interprocessor interrupts (IPIs): CPU private interrupts, ID0-ID15, triggered software. priority IPI depends receiving CPU, sending CPU.680 cHaPTer 18 / mulTIcore comPuTers ■Private timer and/or watchdog interrupts: use interrupt IDs 29 30. ■Legacy FIQ line: legacy IRQ mode, legacy FIQ pin, per CPU basis, bypasses Interrupt Distributor logic directly drives interrupt requests CPU. ■Hardware interrupts: Hardware interrupts triggered programmable events associated interrupt input lines. CPUs support 224 inter - rupt input lines. Hardware interrupts start ID32. Figure 18.15 block diagram GIC. GIC configurable sup - port 0 255 hardware interrupt inputs. GIC maintains list inter - rupts, showing priority status. Interrupt Distributor transmits CPU Interface highest Pending interrupt interface. receives back information interrupt acknowledged, change status corresponding interrupt. CPU Interface also transmits End Interrupt (EOI) information, enables Interrupt Distributor update status interrupt Active Inactive. Cache Coherency MPCore’s Snoop Control Unit (SCU) designed resolve tra - ditional bottlenecks related access shared data scalability limitation introduced coherence traffic. Interrupt interfacePriorityDecoder Interrupt list StatusPrivate bus read/writeCore acknowledge end interrupt (EOI) inf ormation CPU interface Prioritization selectionIRQ r equest CPU interfaceA15 Co 0Top priority interrupts Priority Interrupt number A15 Co 1Priority Interrupt number A15 Co 2Priority Interrupt number A15 Co 3Priority Interrupt number Figure 18.15 Generic Interrupt Controller Block Diagram18.6 / arm corTex- a15 mPcore 681 l1 cache coherency L1 cache coherency scheme based MESI protocol described Chapter 17. SCU monitors operations shared data optimize MESI state migration. SCU introduces three types optimization: direct data intervention, duplicated tag RAMs, migratory lines. Direct data intervention (DDI) enables copying clean data one CPU L1 data cache another CPU L1 data cache without accessing external memory. reduces read read activity Level 1 cache Level 2 cache. Thus, local L1 cache miss resolved remote L1 cache rather access shared L2 cache. Recall main memory location line within cache identified tag line. tags implemented separate block RAM length number lines cache. SCU, duplicated tag RAMs duplicated versions L1 tag RAMs used SCU check data availability sending coherency commands relevant CPUs. Coherency commands sent CPUs must update coherent data cache. reduces power consumption performance impact snooping manipulating processor’s cache memory update. tag data available locally lets SCU limit cache manipulations processors cache lines common. migratory lines feature enables moving dirty data one CPU another without writing L2 reading data back external memory. operation described follows. typical MESI protocol, one proces - sor modified line another processor attempts read line, follow - ing actions occur: 1. line contents transferred modified line processor initiated read. 2. line contents written back main memory. 3. line put shared state caches. L2 Cache Coherency SCU uses hybrid MESI MOESI protocols maintain coherency individual L1 data caches L2 cache. L2 memory system contains snoop tag array duplicate copy L1 data cache directories. snoop tag array reduces amount snoop traffic L2 memory system L1 memory system. line resides snoop tag array Mod - ified/Exclusive state belongs L1 memory system. access hits line state must serviced L1 memory system passed L2 memory system. line invalid shared state snoop tag array, L2 cache supply data. SCU contains buffers handle direct cache- to- cache transfers cores without reading writing data ACE. Lines migrate back forth without change MOESI state line L2 cache. Shareable transactions ACP also coherent, snoop tag arrays queried result ACP transactions. reads shareable line resides one L1 data caches Modified/Exclusive state, line transferred L1 memory system L2 memory system passed back ACP .682 cHaPTer 18 / mulTIcore comPuTers 18.7 IBM zENTERPRISE EC12 MAINFRAME section, look mainframe computer organization uses multicore processor chips. example use IBM zEnterprise EC12 mainframe com - puter [SHUM13, DOBO13], began shipping late 2010. Section 7 .8 provides general overview EC12, together discussion I/O structure. Organization principal building block mainframe multichip module (MCM). MCM 103-layer glass ceramic substrate (size 96–96 mm) containing eight chips 7356 connections. total number transistors 23 billion. MCM plugs card part book packaging. book plugged mid- plane system board provide interconnectivity among books. key components MCM shown Figure 18.16: PU1 (6 cor es)PU2 (6 cor es)HCA2 MCU2 HCA1 MCU1 HCA0 MCU0 PU0 (6 cor es) SC1MCM FBC1 SC0 PU4 (6 cor es)PU3 (6 cor es)PU5 (6 cor es) HCA3 MCU3 HCA4 MCU4 HCA5 MCU5FBC2 FBC = fabric book connectivity HCA = host channel adapter MCM = multichip moduleMCU = memory contr ol unit PU = pr ocessor unit SC = storage contr olFBC0 FBC 1 FBC 2FBC 0 Figure 18.16 IBM EC12 Processor Node Structure18.7 / IB zenTerPrIse ec12 maInframe 683 ■Processor unit (PU): six 5.5-GHz processor PU chips, con - taining four processor cores plus three levels cache. PUs external connections main memory via memory control units I/O via host channel adapters. Thus, MCM includes 24 cores. ■Storage control (SC): two SC chips contain additional level cache plus interconnection logic connecting three MCMs. microprocessor core features wide superscalar, out- of- order pipeline decode three z/Architecture CISC instructions per clock cycle (60.18 ns) execute seven operations per cycle. instruction execution path predicted branch direction target prediction logic. core includes two integer units, two load/store units, one binary floating- point unit, one decimal floating- point unit. Cache Structure EC12 incorporates four- level cache structure. look level turn (Figure 18.17). core dedicated 160-kB L1 cache , divided 96-kB data cache 64-kB instruction cache. L1 cache designed write- cache L2, is, altered data also stored next level memory. caches 8-way set associative. core also dedicated 2-MB L2, split equally 1-MB data cache 1-MB instruction cache. L2 caches write- L3, 8-way set associative. 4-core processor unit chip includes 24-MB L3 cache shared six cores. L1 L2 caches write- through, L3 cache must process every DCore L3 48 MB L4 192 MBPU0 SC0 SC1Core L1: 64-kB I-cache, 96-kB D-cache L2: 1-MB I-cache, 1-MB D-cache6 cor es L2L1 L2L1DI DI DI L2L1 L2L1DI DI DIDCorePU5 Core L4 192 MBMCM L3 48 MB6 cor es Figure 18.17 IBM EC12 Cache Hierarchy684 cHaPTer 18 / mulTIcore comPuTers store generated six cores chip. feature maintains data availability core failure. L3 cache 12-way set associative. EC12 implements embedded DRAM (eDRAM) L3 cache memory chip. eDRAM memory slower static RAM (SRAM) normally used implement cache memory, put lot onto given area. many workloads, memory closer core important fast memory. Finally, 6 PUs MCM share 160-MB L4 cache , split one 92-MB cache SC chip. principal motivation incorporating level 4 cache high clock speed core processors results significant mismatch main memory speed. fourth cache layer needed keep cores running efficiently. large shared L3 L4 caches suited transaction- processing workloads exhibiting high degree data sharing task swapping. L4 cache 24-way set associative. SC chip, houses L4 cache, also acts cross- point switch L4- to- L4 traffic three remote books2 three bidi - rectional data buses. L4 cache coherence manager, meaning mem - ory fetches must L4 cache data used processor. four caches use line size 256 bytes. EC12 interesting study design trade- offs difficulty exploiting increasingly powerful processors available current technology. large L4 cache intended drive need access main memory bare minimum. However, distance off- chip L4 cache costs num - ber instruction cycles. Thus, on- chip area devoted cache large possible, even point fewer cores possible chip. L1 caches small, minimize distance core ensure access occur one cycle. L2 cache dedicated single core, attempt maximize amount cached data accessed without resort shared cache. L3 cache shared four cores chip large possible, minimize need go L4 cache. books zEnterprise 196 share workload, four L4 caches four books form single pool L4 cache memory. Thus, access L4 means going off- chip perhaps off- book, increasing access delay. means relatively large distances exist higher- level caches pro - cessors L4 cache content. Still, accessing L4 cache data another book faster accessing DRAM book, L4 caches work way. overcome delays inherent book design save cycles access off- book L4 content, designers try keep instructions data close cores possible directing much work possible given logical partition workload cores located book L4 cache. achieved system resource manager/scheduler z/OS dispatcher work together keep much work possible within boundaries cores L4 cache space (which best within book boundary) achieved without affecting throughput response times. Preventing resource manager/ scheduler dispatcher assigning workloads processors might run less efficiently contributes overcoming latency high- frequency pro - cessor design EC12. 2Recall Chapter 7 EC12 book consists MCM, memory cards, I/O cage connections.18.8 / Key Terms, revIew Ques TIons, Pro Blems 685 18.8 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms Amdahl’s law chip multiprocessor coarse- grained threading fine- grained threading heterogeneous multicore organizationhomogenous multicore organization hybrid threading MOESI protocol multicore processor pipeliningPollack’s rule simultaneous multithreading (SMT) superscalar threading granularity Review Questions 18.1 Summarize differences among simple instruction pipelining, superscalar, simultaneous multithreading. 18.2 Give several reasons choice designers move multicore organization rather increase parallelism within single processor. 18.3 trend toward giving increasing fraction chip area cache memory? 18.4 List examples applications benefit directly ability scale throughput number cores. 18.5 top level, main design variables multicore organization? 18.6 List advantages shared L2 cache among cores compared separate dedi - cated L2 caches core. Problems 18.1 Consider following problem. designer chip available must decide fraction chip devoted cache memory (L1, L2, L3). remainder chip devoted one complex superscalar and/or SMT cores. Define following parameters: ■n=maximum number cores contained chip. ■k=actual number cores implemented (1…k…n, wherer=n/k integer). ■perf(r)=sequential performance gain using resources equivalent r cores form single processor, perf(1)=1. ■f=fraction software parallelizable across multiple cores. Thus, construct chip n cores, expect core provide sequential performance 1 n cores able exploit parallelism degree n parallel threads. Similarly, chip k cores, core exhibit performance perf(r) chip able exploit parallelism degree k parallel threads. modify Amdhal’s law (Equation 18.1) reflect situation follows: Speedup=1 1--f perf(r)+f*r perf(r)*n686 cHaPTer 18 / mulTIcore comPuTers a. Justify modification Amdahl’s law. b. Using Pollack’s rule, set perf(r)=2r. Let n=16. want plot speedup function r f=0.5; f=0.9; f=0.975; f=0.99; f=0.999. results available document book’s Premium Content site ( multicore- performance.pdf). conclusions draw? c. Repeat part (b) n=256. 18.2 technical reference manual Cortex- A15 says GIC memory mapped. is, core processors use memory mapped I/O communicate GIC. Recall Chapter 7 memory mapped I/O , single address space memory locations I/O devices. processor treats status data registers I/O modules memory locations uses machine instructions access memory I/O devices. Based information, path block diagram Figure 18.15 used core processors com - municate GIC? 18.3 question analyze performance following C program multi - threaded architecture. assume arrays A, B, C overlap memory. (i=0; i<328; i++) { A[i] = A[i]*B[i]; C[i] = C[i]+A[i]; } ■Our machine single- issue, in- order processor. switches different thread every cycle using fixed round robin scheduling. N threads executes one instruction every N cycles. allocate code threads every thread executes every Nth iteration original C code. ■Integer instructions take 1 cycle execute, floating- point instructions take 4 cycles memory instructions take 3 cycles. execution units fully pipelined. instruction cannot issue data yet available, inserts bubble pipeline, retries cycles. ■Below program assembly code machine single thread execut- ing entire loop. loop: ld f1, 0 (r1) ;f1 = A[i] ld f2, 0 (r2) ;f2 = B[i] fmul f4, f2, f1 ;f4 = f1*f2 st f4 0(r1) ;A[i] = f4 ld f3, 0(r3) ;f3 = C[i] fadd f5, f4, f3 ;f5 = f4 + f3 st f5 0(r3) ;C[i] = f5 add r1, r1, 4 ;i++ add r2, r2, 4 add r3, r3, 4 add r4, r4, −1 bnez r4, loop ;loop a. allocate assembly code loop N threads every thread executes every Nth iteration original loop. Write assembly code one N threads would execute multithreaded machine. b. minimum number threads machine needs remain fully uti - lized issuing instruction every cycle program? c. Could reach peak performance running program using fewer threads rearranging instructions? Explain briefly. d. peak performance flops/cycle program?18.8 / Key Terms, revIew Ques TIons, Pro Blems 687 18.4 MOESI protocol, consider pair caches. Use following matrix indicate states permitted given cache line; use X forbidden checkmark permitted. E E 18.5 Draw state transition diagram, including labels transitions, MOESI protocol, similar Figure 17 .6. 18.6 directory cache coherence protocols, based MESI MOESI, silent transition one cache line transitions one state another without reporting change central controller. a. state MESI protocol, indicate target states, any, silent transition possible. b. Repeat MOESI.688 General - PurPose GraPhic Processin G units Contributed Peter Zeno Ph.D. Candidate, University Bridgeport 19.1 CUDA Basics 19.2 GPU versus CPU Basic Differences CPU GPU Architectures Performance Performance per Watt Comparison 19.3 GPU Architecture Overview Baseline GPU Architecture Full Chip Layout Streaming Multiprocessor Architecture Details Importance Knowing Programming Memory Types 19.4 Intel’s Gen8 GPU 19.5 Use GPU Coprocessor 19.6 Key Terms Review Questions CHAPTER19.1 / CUDA B AsiCs 689 graphics processor unit (GPU) designed specifically optimized fast three- dimensional (3D) graphics rendering video processing. GPUs found almost today’s workstations, laptops, tablets, smartphones [OWEN08]. GPU comes many sizes. larger units several hundred thousands parallel processor cores single integrated circuit (IC). found separate coprocessor cards, usually PCIe- based, workstations, gaming systems, even supercomputers [SLA V12]. smallest GPUs found embedded systems, tablets smartphones, GPU composed single- digit number cores, typically combined number conven - tional cores, referred central processing units (CPUs) silicon IC. past several years, GPU found way massively parallel programming environments wide range applications, bioinformat - ics, molecular dynamics, oil gas exploration, computational finance, signal audio processing, statistical modeling, computer vision, medical imaging. term general- purpose computing using GPU (GPGPU) derived from. main reasons migration highly parallelizable applications GPU due advent programmer friendly GPGPU languages, NVIDIA’s CUDA Khronos Group’s OpenCL, slight modifications GPU architecture facilitate general- purpose computing [SAND10] (from known GPGPU architecture), along low cost high perform - ance GPUs. example, $200, one purchase GPU 960 parallel processor cores workstation (e.g., NVIDIA’s GeForce GTX 660). begin chapter overview CUDA model, essen - tial understanding design use GPUs. Next, chapter contrasts GPUs CPUs. followed detailed look GPU architecture. Then, Intel’s GPU examined. Finally, chapter discusses use GPU coprocessor. 19.1 CUDA BASICS CUDA (Compute Unified Device Architecture) parallel computing platform programming model created NVIDIA implemented graphics process - ing units (GPUs) produce. adequately describe GPGPU architecture, several CUDA software terms concepts need covered first. means comprehensive introduction CUDA programming language, particu - larly since focus chapter book computer architecture. However, Learning Objectives studying chapter, able to: rPresent overview CUDA. rUnderstand difference GPU CPU. rDescribe basic elements typical GPU architecture. rDiscuss use GPU coprocessor.690 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs difficult describe hardware portion GPGPU system without first laying foundation CUDA software terminology programming framework. concepts carry GPU/GPGPU architecture domain. CUDA C C/C ++ based language. CUDA program divided three general sections: (1) code run host (CPU); (2) code run device (GPU); (3) code related transfer data host device. code run host course serial code can’t, isn’t worth, parallelizing. data- parallel code run GPU called kernel , thread single instance kernel function. kernel typi - cally branching statements. Branching statements kernel result serial execution threads GPU hardware. covered Section 19.3. programmer defines number threads launched kernel function called. total number threads defined typically thousands maximize utilization GPU processor cores (also known CUDA cores ), well maximize available speedup. Additionally, programmer specifies threads bundled. specific, threads uni - formly bundled blocks , number blocks (also known thread blocks ) per kernel launch called grid (see Figure 19.1). Table 19.1 gives summary CUDA terms defined. Thread (0, 0)Grid Block (1,1) Thread (1, 0) Thread (2, 0) Thread (3, 0) Thread (0, 1) Thread (1, 1) Thread (2, 1) Thread (3, 1) Thread (0, 2) Thread (1, 2) Thread (2, 2) Thread (3, 2)Block(0, 0) Block(1, 0) Block(2, 0) Block(0, 1) Block(1, 1) Block(2, 1) Figure 19.1 Relationship among Threads, Blocks, Grid19.2 / ­PU vERsUs CPU 691 Figure 19.1 illustrates two- dimensional grid two- dimensional thread blocks. grid block dimensions either one, two, three dimen - sions. need dimensions. example, grid could set one dimension, thread block could set three dimensions. - ever, see shortly, configuration can’t fully utilize GPU processors, block assigned one several GPU streaming multiproces - sors (SMs) . block never split SMs. Thus, one set GPU proces - sor cores idle, one SM bearing full processing load. Additionally, maximum number threads SM accept. number sur - passed, code won’t compile. Therefore, programmer use specification data GPU used, distribute load uniformly possible. minimum, number thread blocks launched less number SMs GPU. However, finding optimum configuration time consuming daunting process. 19.2 GPU VERSUS CPU section compares complementary architectures GPU CPU. GPU CPU orthogonally optimized one another, combination heterogeneous GPGPU system provides superior cost performance gains certain applications, compared pure CPU approach. Basic Differences CPU GPU Architectures GPU CPU designed optimized two significantly dif - ferent types applications, architectures differ significantly. seen comparing relative amount die area (transistor count) dedicated cache, control logic, processing logic two types processor technologies (see Figure 19.2). CPU, discussed Chapter 18, control logic cache memory make majority CPU’s real estate. expected architecture tuned process sequential code quickly possible. hand, GPU uses massively parallel SIMD (single instruction multiple data) architecture perform mainly mathematical operations. such, GPU doesn’t require complex capabilities CPU’s control logic (i.e., order execution, branch prediction, data hazards, etc.). require large amounts cache memory. GPUs simply run thread code large amounts data Table 19.1 CUDA Terms GPU’s Hardware Components Equivalence Mapping CUDA Term DefinitionEquivalent GPU Hardware Component Kernel Parallel code form function run GPUNot applicable Thread instance kernel GPU GPU/CUDA processor core Block group threads assigned particular SM CUDA multiprocessor (SM) Grid GPU GPU692 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs able hide memory latency managing execution threads available processor cores. Performance Performance per Watt Comparison video game market driven need ever- increasing real- time graph - ics realism. translates parallel GPU processor cores greater floating- point capabilities. result, GPU designed maximize num - ber floating- point operations per second (FLOPs) perform. Additionally, newer NVIDIA architectures, Kepler Maxwell architectures, focused increasing performance per watt ratio (FLOPs/watt) previous GPU architectures decreasing power required GPU processor core. accomplished Kepler decreasing processor cores’ clock, increasing number on- chip transistors (following Moore’s Law) allowing positive net gain 3x performance per watt Fermi architecture. Addi - tionally, Maxwell architecture improved execution efficiency. trend increasing FLOPs GPU perform versus multicore CPU diverged exponential rate (see Figure 19.3 [NVID14]), thus creating large performance gap. Similar said performance per watt gap two dif - ferent processing technologies. 19.3 GPU ARCHITECTURE OVERVIEW historical evolution GPU architecture divided three major phases eras. first phase would cover early days GPU architecture (early 1980s late 1990s), GPU composed fixed, nonprogram - mable, specialized processing stages (e.g., vertex, raster, shader, etc.). Additionally, continued technology advancements period, allowing dramatic decrease size cost graphics system, turn brought graphics proces - sors PC mid- late- 1990s. second phase would cover iterative modification resulting Phase GPU architecture fixed, specialized, hardware pipeline fully programmable processor (approximately early mid- 2000s). general, final modification, introduced NVIDIA 2006, facilitated use new GPGPU language, CUDA. third phase picks second one leaves covers GPU/GPGPU architec - ture makes excellent affordable highly parallelized SIMD coprocessor Contr ol Cache DRAM CPUDRAM GPUALUA LU ALUA LU Figure 19.2 CPU versus GPU Silicon Area/Transistor Dedication19.3 / ­PU ARCHiTECTURE pvERviEw 693 accelerating run times nongraphics- related programs, along GPGPU language (CUDA case) maps architecture. focus chapter follows third phase era GPU. first NVIDIA GPU added GPGPU support hardware GeForce 8800 GTX. enable GPU used programmers general- purpose parallel computing applications, true cache hierarchy user- addressable shared memory added. Additionally, arrays programmable GPU processor cores equally divided scalable SMs. benefit architecture scalability GPU processor cores, well SMs new gen - erations different models GPUs without requiring modification CUDA programming language. Baseline GPU Architecture previously mentioned, NVIDIA progressed several generations GPU processing technologies (i.e., Tesla, Fermi, Kepler, Maxwell), small moderate difference microarchitecture predecessor. naming convention SM slightly modified newer generations 5001000150020002500300035004000450050005500 Sep-02Theor etical GFLOPS Jan-04 May-05 Oct-06 Feb-08 Jul-09 Nov-10 Apr-12 Aug-13NVIDIA GPU single pr ecision NVIDIA GPU double pr ecision Intel CPU single pr ecision Intel CPU double pr ecision Figure 19.3 Floating- Point Operations per Second CPU GPU694 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs GPU technologies, SMX Kepler SMM Maxwell. helps signify relatively significant change SM architecture predecessor (it also helps new product’s promotional marketing!). said, CUDA programming perspective, processing technologies still identical top- level architectures. remainder chapter, use NVIDIA’s Fermi architecture example baseline architecture. Fermi architecture chosen due fairly representative GPU architecture lower CUDA core/SM count, simplifies mapping GPU hardware CUDA software. example architecture composed 16 SMs, SM contains group 32 CUDA cores. Therefore, Fermi GPU total 16 SMs * 32 CUDA cores/ SM, 512 CUDA cores. Full Chip Layout Figure 19.4 illustrates general layout NVIDIA Fermi architecture GPU. seen figure, L2 cache centrally located 16 SMs (8 SMs below). SM represented 2 adjacent columns 16 rows rectangles (GPU processor cores), along column 16 load/store units column 4 special function units (SFUs). detailed illustration SM module shown Figure 19.5 [NIVD09]. rectangles head foot SMs Figure 19.4 registers L1/shared memory located. six DRAM I/O interfaces 64-bit memory interface (the DRAM interface circuitry show dark blue rectangles outermost left right sides). Thus, collectively, 384-bit interface GPU’s GDDR5 (graphic double data DRAM DRAM GigaThr ead Host interfaceDRAM DRAM DRAM DRAML2 cache Figure 19.4 NVIDIA Fermi Architecture19.3 / ­PU ARCHiTECTURE pvERviEw 695 rate, DDR memory designed specifically graphic processing) DRAM, allowing support total 6 GB SM off- chip memory (i.e., global, constant, texture, local). specifics different memory types dis - cussed next section. Also, illustrated Figure 19.4 host interface, found left- hand side GPU layout diagram. host interface allows PCIe connectivity GPU CPU. Lastly, GigaThread global scheduler, orange located next host interface, responsible distribution thread blocks SM’s warp schedulers (see Figure 19.5). Streaming Multiprocessor Architecture Details right- hand side Figure 19.5 breaks NVIDIA Fermi architecture basic components single SM. components ■GPU processor cores (total 32 CUDA cores) ■Warp scheduler dispatch portCore Core Core Core Core Core Core CoreCore Core Core Core Core Core Core CoreCoreRegister /f_ile (32k /multiply.bold 32-bit)Instruction cache Dispatch unit Dispatch unit Core Core Core Core Core Core CoreCoreLd/St SFU SFU SFU SFULd/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/St Ld/StCore Core Core Core Core Core CoreWarp scheduler Warp scheduler Inter connect network 64-kB shar ed memory/L1 cache Uniform cacheOperand collector Result queueDispatch portCUD co FP unitInt unit Figure 19.5 Single SM Architecture696 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs ■Sixteen load/store units ■Four SFUs ■32k * 32-bit registers ■Shared memory L1 cache (64 kB total) dual warp scheduler covered previously, GigaThread global scheduler unit GPU chip distributes thread blocks SMs. dual warp scheduler break thread block processing warps , warp bundle 32 threads start starting address thread IDs consecutive. warp issued, thread instruction address counter register set. allows independent branching execution thread SM. GPU efficient processing many warps possible keep CUDA cores maximally utilized. illustrated Figure 19.6, maximum SM hardware utilization occur dual warp schedulers instruction dispatch units able issue two warps every two clock cycles (Fermi architec - ture). explained next, structural hazards main source SM falling short achieving maximum processing rate, off- chip memory access latency easily hidden. divided column 16 CUDA cores (* 2), 16 load/store units, 4 SFUs (see Figure 19.5) eligible assigned half warp (16 threads) process two warp scheduler/dispatch units per clock cycle, given compo - nent column isn’t experiencing structural hazard. Structural hazards caused limited SFUs, double- precision multiplication, branching. However, warp schedulers built- scoreboard track warps available execu - tion, well structural hazards. allows SM work around structural hazards help hide off- chip memory access latency optimally possible. TimeWARP scheduler Instruction dispatch unit Warp 8 instruction 11 Warp 2 instruction 42 Warp 14 instruction 95 Warp 8 instruction 12 Warp 14 instruction 96 Warp 2 instruction 43 WARP scheduler Instruction dispatch unit Warp 9 instruction 11 Warp 3 instruction 33 Warp 15 instruction 95 Warp 9 instruction 12 Warp 3 instruction 34 Warp 15 instruction 96 Figure 19.6 Dual Warp Schedulers Instruction Dispatch Units Run Example19.3 / ­PU ARCHiTECTURE pvERviEw 697 Therefore, important programmer set thread block size greater total number CUDA cores SM, less maximum allowable threads per block, make sure thread block size (in x and/ dimensions) multiple 32 (warp size) achieve near- optimal utilization SMs. cuda cores mentioned CUDA Basics section, NVIDIA GPU processor cores also known CUDA cores (see Figure 19.5). Also defined earlier, seen Figure 19.4, total 32 CUDA cores dedicated SM Fermi architecture. CUDA core two separate pipelines data paths: integer (INT) unit pipeline floating- point (FP) unit pipeline (see Figure 19.5). one data paths used single clock period. INT unit capable 32-bit, 64-bit, extended precision integer logic/bitwise operations. FP unit perform single- precision FP operation, double- precision FP operation requires two CUDA cores. Therefore, threads perform double- precision FP operations take twice long run compared single- precision FP thread. performance impact double- precision FP arithmetic addressed Kepler architecture inclusion dedicated double- precision units SM, well majority single- precision units. Fortunately, management thread- level FP single- double- precision operations hidden CUDA programmer. However, programmer aware potential performance impact incurred using two precision types based GPU used. Fermi architecture added improvement CUDA core’s FP unit predecessors. upgraded IEEE 754-1985 floating- point arithme - tic standard IEEE 754-2008 standard. accomplished improving accuracy multiply- add instruction (MAD) fused multiply- add (FMA) instruction. FMA instruction valid single- double- precision arithmetic. Fermi architecture performs single rounding end FMA instruction. accuracy result improved, also performing FMA instruction compressed single processor clock cycle. Therefore, 32 single- precision 16 double- precision FMA operations occur single processor clock cycle per SM. special function units SM four SFUs. SFU performs transcendental operations, cosine, sine, reciprocal, square root, single clock cycle. Since 4 SFUs SM 32 parallel threads single instruction warp, takes 8 clock cycles complete warp requires SFUs. However, CUDA processors, along load store units, still utilized time. load store units 16 load store units SM calculates source destination addresses single thread per clock cycle. addresses cache DRAM threads wish write data to, read data from. registers , shared memory , l1 cache illustrated Figure 19.5, SM ( on- chip) dedicated set registers shared memory/L1 cache block. Details benefits low latency, on- chip memories described below.698 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs Although Fermi architecture impressive 32k * 32-bit registers per SM, thread maximum 64 * 32-bit registers allocated defined CUDA compute capability version 2.x, function maximum number active warps allowed per SM, well number registers per SM. shown Table 19.2, registers, along shared memory, fastest access times several nanoseconds (ns). temporary register spillage, data first get moved L1 cache sent L2 cache, long access latency local memory (see Figure 19.7a). use L1 cache helps prevent data read/write hazards occurring. lifetime data registers assigned thread therefore long life thread. addressable, on- chip shared memory dedicated GPU processor cores SM unique configuration compared contemporary multicore microprocessors, CPU. contemporary architectures, covered Chapter 18 illustrated Figure 18.6, dedicated on- chip L1 cache set registers per core. However, typically on- chip addressable mem - ory. Instead, dedicated memory management hardware regulates movement data cache main memory without control programmer. significantly different GPU architecture (see Figure 19.5). discussed beginning chapter, shared memory added GPU architecture specifically assist GPGPU applications. Optimizing use shared memory significantly improve speedup performance GPGPU application eliminating unneeded long latency accesses off- chip memory. Despite shared memory small size SM (48 kB maximum configuration), low access latency 100*to 150*less global memory (see Table 19.2). Thus, three major ways shared memory accelerate parallel processing tasks: (1) multiple repeated use shared memory data threads block (e.g., blocks data used matrix– matrix multiplication); (2) select threads block (based specific IDs) used transfer data global memory shared memory, thus redundant Table 19.2 GPU’s Memory Hierarchy Attributes Memory Type Relative Access Times Access Type Scope Data Lifetime Registers Fastest. On- chip R/W Single thread Thread Shared Fast. On- chip R/W threads block Block Local 100*to 150*slower shared register. Off- chipR/W Single thread Thread Global 100*to 150*slower shared register. Off- chip.R/W threads host Application Constant 100*to 150*slower shared register. Off- chipR threads host Application Texture 100*to 150*slower shared register. Off- chipR threads host Application19.3 / ­PU ARCHiTECTURE pvERviEw 699 reads writes memory locations removed; (3) user optimize data accesses global memory making sure accesses coalesced, possible. points also aid reducing off- chip memory bandwidth constraint issues. lifetime data SM’s shared memory long life thread block processed it. So, threads block completed, data SM’s shared memory longer valid. Although use shared memory give optimum run times, applications memory accesses known programming phase. L1 cache available (maximum setting 48 kB) give optimal results. Additionally, L1 cache helps aiding register spills, (a) SM memory ar chitectu (b) Overall memory ar chitectu re128 kB register /f_ile 768 kB L2 cache DRAMto/from L2 cache L2 cachex kB shared memor y(64 – x) kB L1 data cache64 kB L1 instruc tion cacheCore 0 SM 0 SM 1 SM 15Core 1 Core 31 Figure 19.7 Fermi Memory Architecture700 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs instead going straight local ( off- chip) DRAM memory. two- level cache hierarchy— single L1 cache per SM, across chip, SM shared L2 cache— gives benefits found conventional multicore microprocessors. Importance Knowing Programming Memory Types important programmer understand nuances various GPU memories, particularly sizes available memory type, relative access times, accessibility limitations, enable correct efficient code development using CUDA. one see CUDA Basics section covered begin - ning chapter, SM level memories covered, terminology parameters listed Table 19.2, much different approach required GPGPU programming program development targeted CPU, specific data storage hardware used (other file I/O) hidden programmer. example, GPU architecture, thread assigned CUDA core set registers, one thread cannot access another thread’s registers, whether SM not. way threads within particular SM cooperate (via data sharing) shared memory (see Figure 19.8). typically accomplished programmer assigning certain threads SM write specific locations shared memory, thus preventing write hazards wasted cycles (e.g., many threads reading data Registers Thread (0,0)Shar ed memoryBlock (0,0)(Device) Grid Registers Thread (1,0)Registers Thread (0,0)Shar ed memoryBlock (1,0) Registers Thread (1,0) Global memory Constant memoryHost Figure 19.8 CUDA Representation GPU’s Basic Architecture19.4 / ieTEa ’s ­Ee8 ­PU 701 global memory writing shared memory address). threads particular SM allowed read shared memory written to, synchronization threads SM needs take place prevent read- after- write (RAW) data hazard.1 19.4 INTEL’S GEN8 GPU another example GPGPU architecture, section provides overview Gen8 processor graphics architecture [INTE14, PEDD14]. fundamental building block Gen8 architecture execution unit (EU) shown Figure 19.9. EU simultaneous multithreading (SMT) archi - tecture seven threads. Recall Chapters 17 18 SMT archi - tecture, register banks expanded multiple threads share use pipeline resources. EU seven threads implemented superscalar pipeline architecture. thread includes 128 general- purpose registers. Within EU, primary computation units two SIMD floating- point units sup - port floating point integer computation. SIMD FPU complete simultaneous add multiply floating- point instructions every cycle. also branch unit dedicated branch instructions send unit memory operations. register stores 32 bytes, accessible SIMD 8-element vector 32-bit data elements. Thus Gen8 thread 4 kB general- purpose register file (GRF), total 28 kB GRF per EU. Flexible addressing modes permit reg - isters addressed together build effectively wider registers, even rep - resent strided rectangular block data structures.2 Per thread architectural state maintained separate dedicated architecture register file (ARF). 1See Chapter 16 discussion RAW hazards.EU: Execution unit Send Branch SIMD FPU SIMD FPUInstruction fetch Thread arbiterSuperscalar pipeline Superscalar pipeline Superscalar pipeline Superscalar pipeline Superscalar pipeline Superscalar pipeline Superscalar pipeline Figure 19.9 Intel Gen8 Execution Unit 2The term strided refers sequence memory reads writes addresses, sepa - rated last constant interval called stride length . Strided references often generated loops array, (if data large enough access- time significant) worthwhile tune better locality inverting double loops partially unrolling outer loop loop nest.702 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs EU issue four different instructions simultaneously dif - ferent threads. thread arbiter dispatches instruction one four functional units execution. EUs organized subslice (Figure 19.10), may contain eight EUs. subslice contains local thread dispatcher unit supporting instruction caches. Thus, single subslice dedicated hardware resources register files total 56 simultaneous threads. subslice also includes unit called sampler, local L1 L2 cache. sampler used sampling texture image surfaces. sam - pler includes logic support dynamic decompression block compression texture formats. sampler also includes fixed- function logic enables address conver - sion image ( u,v) coordinates address clamping modes mirror, wrap, border, clamp. sampler supports variety sampling filtering modes point, bilinear, trilinear, anisotropic. data port provides efficient read/ write operations attempt take advantage cache line size consolidate read operations different threads. create product variants, subslices may clustered groups called slices (Figure 19.11). Currently, three subslices may organized single slice total 24 EUs. addition subslices, slice includes logic thread dispatch routing, function logic optimize graphic data processing, shared EUEUEUEU EUEUEUEUInstruction cache SamplerLocal thr ead dispatcher L1L2 sampler cacheData portSubslice: 8 EUs Figure 19.10 Intel Gen8 Subslice19.4 / ieTEa ’s ­Ee8 ­PU 703 L3 cache, smaller shared local memory structure. latter visible (address - able memory) EUs useful sharing temporary variables. enhance performance technique known cache banking used shared L3 data cache. achieve high bandwidth, cache divided equal- size memory modules, called banks, accessed simultaneously. memory read write request made n addresses fall n distinct memory banks therefore serviced simultaneously, yielding overall bandwidth n times high bandwidth single module. However, two addresses memory request fall memory bank, bank conflict access serialized. hardware splits memory request bank con - flicts many separate conflict- free requests necessary, decreasing - put factor equal number separate memory requests. number separate memory requests n, initial memory request said cause n- way bank conflicts. get maximum performance, therefore important - stand memory addresses map memory banks order schedule mem - ory requests minimize bank conflicts. Finally, SoC product architect create product families specific product within family placing single slice multiple slices SoC chip. slices combined additional front- end logic manage command Slice: 24 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal thr ead dispatcher L1L2 sampler cacheData portSubslice: 8 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal th read dispatcher L1L2 sampler cacheData portSubslice: 8 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal th read dispatcher L1L2 sampler cacheData portSubslice: 8 EUsFixed-function units L3 data cacheShar ed local memoryFunction logic Figure 19.11 Intel Gen8 Slice704 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs submission, well fixed- function logic support 3D rendering media pipe - lines. Additionally, entire Gen8 compute architecture interfaces rest SoC components via dedicated unit called graphics technology interface (GTI). example SoC Intel Core Processor Intel HD Graphics 5300 Gen8 (Figure 19.12). addition GPU portion, chip con - tains multiple CPU cores, LLC cache system agent. system agent includes controllers DRAM memory, display, PCIe devices. Processor Graphics Gen8, CPUs, LLC cache, system agent interconnected ring structure, saw Xeon processor (Figure 7.16). 19.5 USE GPU COPROCESSOR end chapter brief discussion determining candidate GPGPU appli - cations software design perspective, well related software tools assist process. differentiates program would benefit running portion code GPU (thus, heterogeneous computing platform) versus program wouldn’t? illustrated discussed chapter, GPU made hundreds thousands processor cores SIMD archi - tecture. Therefore, programs highly parallelizable portion(s) code, replicated thousands lightweight threads work large data sets concurrently, best candidates accelerating run time GPGPU system. Here, lightweight thread defined instance relatively small, massively parallelizable snippet code, little branch - ing. Typically, original serial code form large iteration for- loop, several embedded for- loops, perform calculations equations data dependency iterations (e.g., matrix arithmetic). Additionally, initially profiling entire program tools similar GNU command line based gprof NVIDIA’s nvprof visual based profiler (either profiler prefer - ably run typical representative data), section(s) parallelized must make fair percentage program’s total run time. requirement maximize speedup obtained (Amdahl’s law) minimize impact data transfer time CPU GPU overall speedup. candidate massively parallelizable code segment identified, needs converted serial code parallel code CUDA kernel. parallelizing compiler available could automatically conver - sion without input user also give near- optimal, correct solution, would save great deal time, money, effort. Unfortunately, tool yet exist. leaves two options: (1) convert code complex planning programming CUDA, OpenCL, similar; (2) use compiler directive language, OpenACC, hiCUDA, similar. Although using com - piler directive language place parallelizing “hints” code compiler save great deal programming time, still iterative process optimum run time obtained guaranteed. However, method seen Intel Pr ocessor Graphics Gen8Intel Cor e Pr ocessor Slice: 24 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal thr ead dispatcher L1L2 sampler cacheData portSubslice: 8 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal thr ead dispatcher L1L2 sampler cacheData portSubslice: 8 EUs EUEUEUEU EUEUEUEUInstruction cache SamplerLocal thr ead dispatcher L1L2 sampler cacheData portSubslice: 8 EUsFixed function units L3 data cacheShared local memoryAtomics, Barriers GTICPU coreCPU core LLC cache sliceLLC cache sliceDisplay contr ollerSystem agent SoC ring inter connectMemory contr oller PCIe Figure 19.12 Intel Core Processor SoC 705706 CHAPTER 19 / ­ EeERAal-PURP psE ­RAPHiC PRpCEs sie­ UeiTs growing interest past several years, newer versions CUDA compiler support OpenACC language. Yet, well- planned/engineered coded CUDA program almost always give best runtimes date. 19.6 KEY TERMS REVIEW QUESTIONS Key Terms block cache banking central processing unit (CPU) Compute Unified Device Architecture (CUDA) CUDA core general- purpose computing using GPU (GPGPU) GPU processor core graphic processing unit (GPU) gridkernel streaming multiprocessors (SMs) thread thread block warp Review Questions 19.1 Define CUDA. 19.2 List basic differences CPU GPU architectures. 19.3 differences kernel, thread, block? 19.4 Define warp. 19.5 special function units?707 Part Six ConTrol UniT CHAPTER ConTrol UniT opera Tion 20.1 Micro- Operations Fetch Cycle Indirect Cycle Interrupt Cycle Execute Cycle Instruction Cycle 20.2 Control Processor Functional Requirements Control Signals Control Signals Example Internal Processor Organization Intel 8085 20.3 Hardwired Implementation Control Unit Inputs Control Unit Logic 20.4 Key Terms, Review Questions, Problems 708 CHAPTER 20 / Con TRol Uni oPERAT ion Chapter 12, pointed machine instruction set goes long way toward defining processor. know machine instruction set, including - standing effect opcode understanding addressing modes, know set user- visible registers, know functions processor must perform. complete picture. must know exter - nal interfaces, usually bus, interrupts handled. line reasoning, following list things needed specify function processor emerges: 1. Operations (opcodes) 2. Addressing modes 3. Registers 4. I/O module interface 5. Memory module interface 6. Interrupts list, though general, rather complete. Items 1 3 defined instruction set. Items 4 5 typically defined specifying system bus. Item 6 defined partially system bus partially type support processor offers operating system. list six items might termed functional requirements pro - cessor. determine processor must do. occupied us Parts Two Four. Now, turn question functions performed or, specifically, various elements processor controlled provide functions. Thus, turn discussion control unit, controls operation processor. 20.1 MICRO- OPERATIONS seen operation computer, executing program, consists sequence instruction cycles, one machine instruction per cycle. course, must remember sequence instruction cycles necessarily written sequence instructions make program, existence branching instructions. referring execution time sequence instructions.Learning Objectives studying chapter, able to: rExplain concept micro- operations define principal instruction cycle phases terms micro- operations. rDiscuss micro- operations organized control processor. rUnderstand hardwired control unit organization.20.1 / ­ iCRo o-oPERATion n 709 seen instruction cycle made number smaller units. One subdivision found convenient fetch, indirect, execute, interrupt, fetch execute cycles always occurring. design control unit, however, need break description further. discussion pipelining Chapter 14, began see fur - ther decomposition possible. fact, see smaller cycles involves series steps, involves processor registers. refer steps micro- operations . prefix micro refers fact step simple accomplishes little. Figure 20.1 depicts relationship among various concepts discussing. summarize, execution program consists sequential execution instructions. instruction executed instruction cycle made shorter subcycles (e.g., fetch, indirect, execute, interrupt). execution subcycle involves one shorter operations, is, micro- operations. Micro- operations functional, atomic, operations processor. section, examine micro- operations gain understanding events instruction cycle described sequence micro- operations. simple example used. remainder chapter, show concept micro- operations serves guide design control unit. Fetch Cycle begin looking fetch cycle, occurs beginning instruc - tion cycle causes instruction fetched memory. purposes discussion, assume organization depicted Figure 14.6 ( Data Flow , Fetch Cycle ). Four registers involved: ■Memory address register (MAR): connected address lines sys - tem bus. specifies address memory read write operation. ■Memory buffer register (MBR): connected data lines system bus. contains value stored memory last value read memory. Program execution Instruction cycle Instruction cycle Instruction cycle Indir ect Execute Interrupt Fetch /uni03BCOP /uni03BCOP /uni03BCOP /uni03BCOP /uni03BCOP Figure 20.1 Constituent Elements Program Execution710 CHAPTER 20 / Con TRol Uni oPERAT ion ■Program counter (PC): Holds address next instruction fetched. ■Instruction register (IR): Holds last instruction fetched. Let us look sequence events fetch cycle point view effect processor registers. example appears Figure 20.2. beginning fetch cycle, address next instruction executed program counter (PC); case, address 1100100. first step move address memory address register (MAR) register connected address lines system bus. second step bring instruction. desired address (in MAR) placed address bus, control unit issues READ command control bus, result appears data bus copied memory buffer register (MBR). also need increment PC instruction length get ready next instruction. two actions (read word memory, increment PC) inter - fere other, simultaneously save time. third step move contents MBR instruction register (IR). frees MBR use possible indirect cycle. Thus, simple fetch cycle actually consists three steps four micro- operations. micro- operation involves movement data register. long movements interfere one another, several take place one step, saving time. Symbolically, write sequence events follows: t1: MAR (PC) t2: MBR Memory PC (PC) + t3: IR (MBR) instruction length. need make several comments sequence. assume clock available timing purposes emits reg - ularly spaced clock pulses. clock pulse defines time unit. Thus, time units tMAR MBR PC IR AC (a) ginning (before t1)0000000001 100100MAR MBR PC IR AC (b) /f_irst step0000000001 10010 00000000001 10010 0 MAR MBR PC IR AC (c) second step0000000001 1001010000000001 100100 0001000000100000 000100000010000 0000100000010000 0MAR MBR PC IR AC (d) third step0000000001 10010 10000000001 10010 0 Figure 20.2 Sequence Events, Fetch Cycle20.1 / ­ iCRo o-oPERATion n 711 equal duration. micro- operation performed within time single time unit. notation (t 1, t2, t3) represents successive time units. words, ■First time unit: Move contents PC MAR. ■Second time unit: Move contents memory location specified MAR MBR. Increment contents PC. ■Third time unit: Move contents MBR IR. Note second third micro- operations take place second time unit. third micro- operation could grouped fourth - affecting fetch operation: t1: MAR (PC) t2: MBR Memory t3: PC (PC) + IR (MBR) groupings micro- operations must follow two simple rules: 1. proper sequence events must followed. Thus (MARd(PC)) must precede (MBRdMemory) memory read operation makes use address MAR. 2. Conflicts must avoided. One attempt read write register one time unit, results would unpredictable. example, micro- operations (MBRdMemory) (IRdMBR) occur time unit. final point worth noting one micro- operations involves addition. avoid duplication circuitry, addition could performed ALU. use ALU may involve additional micro- operations, depending functionality ALU organization processor. defer discussion point later chapter. useful compare events described following subsections Figure 3.5 ( Example Program Execution ). Whereas micro- operations ignored figure, discussion shows micro- operations needed perform subcycles instruction cycle. Indirect Cycle instruction fetched, next step fetch source operands. Continuing simple example, let us assume one- address instruction format, direct indirect addressing allowed. instruction specifies indirect address, indirect cycle must precede execute cycle. data flow differs somewhat indicated Figure 14.7 ( Data Flow , Indirect Cycle ) includes following micro- operations: t1: MAR (IR(Address)) t2: MBR Memory t3: IR(Address) (MBR(Address)) address field instruction transferred MAR. used fetch address operand. Finally, address field IR updated MBR, contains direct rather indirect address.712 CHAPTER 20 / Con TRol Uni oPERAT ion IR state indirect addressing used, ready execute cycle. skip cycle moment, consider interrupt cycle. Interrupt Cycle completion execute cycle, test made determine whether enabled interrupts occurred. so, interrupt cycle occurs. nature cycle varies greatly one machine another. present simple sequence events, illustrated Figure 14.8 ( Data Flow, Indirect Cycle ). t1: MBR (PC) t2: MAR Save_Address PC Routine_Address t3: Memory (MBR) first step, contents PC transferred MBR, saved return interrupt. MAR loaded address contents PC saved, PC loaded address start interrupt- processing routine. two actions may single micro- operation. However, processors provide multiple types and/or levels interrupts, may take one additional micro- operations obtain Save_Address Routine_Address transferred MAR PC, respectively. case, done, final step store MBR, contains old value PC, memory. processor ready begin next instruction cycle. Execute Cycle fetch, indirect, interrupt cycles simple predictable. involves small, fixed sequence micro- operations and, case, micro- operations repeated time around. true execute cycle. variety opcodes, number different sequences micro- operations occur. control unit examines opcode generates sequence micro- operations based value opcode. referred instruction decoding. Let us consider several hypothetical examples. First, consider add instruction: ADD R1, X adds contents location X register R1. following sequence micro- operations might occur: t1: MAR (IR(address)) t2: MBR Memory t3: R1 (R1) + (MBR) begin IR containing ADD instruction. first step, address portion IR loaded MAR. referenced memory location read. Finally, contents R1 MBR added ALU. Again, simplified example. Additional micro- operations may required extract 20.1 / ­ iCRo o-oPERATion n 713 register reference IR perhaps stage ALU inputs outputs intermediate registers. Let us look two complex examples. common instruction incre - ment skip zero: ISZ X content location X incremented 1. result 0, next instruction skipped. possible sequence micro- operations t1: MAR (IR(address)) t2: MBR Memory t3: MBR (MBR) + 1 t4: Memory (MBR) ((MBR) = 0) (PC (PC) + I) new feature introduced conditional action. PC incre - mented (MBR)=0. test action implemented one micro- operation. Note also micro- operation performed time unit updated value MBR stored back memory. Finally, consider subroutine call instruction. example, consider branch- and- save- address instruction: BSA X address instruction follows BSA instruction saved location X, execution continues location X+I. saved address later used return. straightforward technique supporting subroutine calls. following micro- operations suffice: t1: MAR (IR(address)) MBR (PC) t2: PC (IR(address)) Memory (MBR) t3: PC (PC) + address PC start instruction address next instruction sequence. saved address designated IR. latter address also incremented provide address instruction next instruction cycle. Instruction Cycle seen phase instruction cycle decomposed sequence elementary micro- operations. example, one sequence fetch, indirect, interrupt cycles, and, execute cycle, one sequence micro- operations opcode. complete picture, need tie sequences micro- operations together, done Figure 20.3. assume new 2-bit register called instruction cycle code (ICC). ICC designates state processor terms portion cycle in: 00: Fetch 01: Indirect714 CHAPTER 20 / Con TRol Uni oPERAT ion 10: Execute 11: Interrupt end four cycles, ICC set appropriately. indirect cycle always followed execute cycle. interrupt cycle always followed fetch cycle (see Figure 14.4, Instruction Cycle ). fetch execute cycles, next cycle depends state system. Thus, flowchart Figure 20.3 defines complete sequence micro- operations, depending instruction sequence interrupt pattern. course, simplified example. flowchart actual processor would complex. case, reached point discussion operation processor defined performance sequence micro- operations. consider control unit causes sequence occur. 20.2 CONTROL PROCESSOR Functional Requirements result analysis preceding section, decomposed behavior functioning processor elementary operations, called micro- operations. reducing operation processor fundamental level, able define exactly control unit must cause happen. Thus, define functional requirements control unit: functions control unit must perform. definition functional requirements basis design implementation control unit.ICC = 00 ICC = 00 ICC = 11ICC = 10 ICC = 10 ICC = 01ICC? Setup interruptOpcodeRead addr essFetch instruction Indir ect addr essing? Interrupt enabled interrupt?11 (interrupt) 00 (fetch) 10 (execute) 01 indir ect Execute instruction YesN oNo Yes Figure 20.3 Flowchart Instruction Cycle20.2 / Con TRol PRoCEnnoR 715 information hand, following three- step process leads char - acterization control unit: 1. Define basic elements processor. 2. Describe micro- operations processor performs. 3. Determine functions control unit must perform cause micro- operations performed. already performed steps 1 2. Let us summarize results. First, basic functional elements processor following: ■ALU ■Registers ■Internal data paths ■External data paths ■Control unit thought convince complete list. ALU functional essence computer. Registers used store data internal processor. registers contain status information needed manage instruction sequencing (e.g., program status word). Others contain data go come ALU, memory, I/O modules. Internal data paths used move data registers register ALU. External data paths link registers memory I/O modules, often means system bus. control unit causes operations happen within processor. execution program consists operations involving pro - cessor elements. seen, operations consist sequence micro- operations. Upon review Section 20.1, reader see micro- operations fall one following categories: ■Transfer data one register another. ■Transfer data register external interface (e.g., system bus). ■Transfer data external interface register. ■Perform arithmetic logic operation, using registers input output. micro- operations needed perform one instruction cycle, including micro- operations execute every instruction instruction set, fall one categories. somewhat explicit way control unit functions. control unit performs two basic tasks: ■Sequencing: control unit causes processor step series micro- operations proper sequence, based program executed. ■Execution: control unit causes micro- operation performed. preceding functional description control unit does. key control unit operates use control signals.716 CHAPTER 20 / Con TRol Uni oPERAT ion Control Signals defined elements make processor (ALU, registers, data paths) micro- operations performed. control unit perform function, must inputs allow determine state system outputs allow control behavior system. external specifications control unit. Internally, control unit must logic required perform sequencing execution functions. defer discussion internal operation control unit Section 20.3 Chapter 21. remainder section concerned interaction control unit elements processor. Figure 20.4 general model control unit, showing inputs outputs. inputs are: ■Clock: control unit “keeps time.” control unit causes one micro- operation (or set simultaneous micro- operations) performed clock pulse. sometimes referred processor cycle time, clock cycle time. ■Instruction register: opcode addressing mode current instruc - tion used determine micro- operations perform exe - cute cycle. ■Flags: needed control unit determine status processor outcome previous ALU operations. example, increment- and- skip- if- zero (ISZ) instruction, control unit increment PC zero flag set. ■Control signals control bus: control bus portion system bus provides signals control unit. Contr ol unitInstruction r egister Flags ClockContr ol signals within CPU Contr ol signals contr ol bus Contr ol signals contr ol bus Contr ol bus Figure 20.4 Block Diagram Control Unit20.2 / Con TRol PRoCEnnoR 717 outputs follows: ■Control signals within processor: two types: cause data moved one register another, activate specific ALU functions. ■Control signals control bus: also two types: control signals memory, control signals I/O modules. Three types control signals used: activate ALU function; activate data path; signals external system bus external interface. signals ultimately applied directly binary inputs individual logic gates. Let us consider fetch cycle see control unit maintains control. control unit keeps track instruction cycle. given point, knows fetch cycle performed next. first step transfer contents PC MAR. control unit activating control signal opens gates bits PC bits MAR. next step read word memory MBR incre - ment PC. control unit sending following control signals simultaneously: ■A control signal opens gates, allowing contents MAR onto address bus; ■A memory read control signal control bus; ■A control signal opens gates, allowing contents data bus stored MBR; ■Control signals logic add 1 contents PC store result back PC. Following this, control unit sends control signal opens gates MBR IR. completes fetch cycle except one thing: control unit must decide whether perform indirect cycle execute cycle next. decide this, examines IR see indirect memory reference made. indirect interrupt cycles work similarly. execute cycle, control unit begins examining opcode and, basis that, decides sequence micro- operations perform execute cycle. Control Signals Example illustrate functioning control unit, let us examine simple example. Figure 20.5 illustrates example. simple processor single accu - mulator (AC). data paths elements indicated. control paths signals emanating control unit shown, terminations control signals labeled C indicated circle. control unit receives inputs clock, IR, flags. clock cycle, control unit 718 CHAPTER 20 / Con TRol Uni oPERAT ion reads inputs emits set control signals. Control signals go three separate destinations: ■Data paths: control unit controls internal flow data. example, instruction fetch, contents memory buffer register transferred IR. path controlled, switch (indicated circle figure). control signal control unit temporarily opens gate let data pass. ■ALU: control unit controls operation ALU set control signals. signals activate various logic circuits gates within ALU. ■System bus: control unit sends control signals onto control lines system bus (e.g., memory READ). control unit must maintain knowledge instruction cycle. Using knowledge, reading inputs, control unit emits sequence control signals causes micro- operations occur. uses clock pulses time sequence events, allowing time events sig - nal levels stabilize. Table 20.1 indicates control signals needed micro- operation sequences described earlier. simplicity, data control paths incrementing PC loading fixed addresses PC MAR shown. worth pondering minimal nature control unit. control unit engine runs entire computer. based knowing instructions executed nature results arithmetic logical operations (e.g., positive, overflow, etc.). never gets see data pro - cessed actual results produced. controls everything control signals points within processor control signals system bus.M B R RPCAC ClockIR Contr ol unit Contr ol signalsFlagsContr ol signalsALUC3 C2C4C10C5 C8 C1 C0C12 C13C7 C6C9C11 Figure 20.5 Data Paths Control Signals20.2 / Con TRol PRoCEnnoR 719 Table 20.1 Micro- operations Control Signals Micro- operations Active Control Signals Fetch:t1: MARd(PC) C2 t2: MBRdMemory PCd(PC)+1C5, CR t3: IRd(MBR) C4 Indirect:t1: MARd(IR(Address)) C8 t2: MBRdMemory C5, CR t3: IR(Address)d (MBR(Address)) C4 Interrupt:t1: MBRd(PC) C1 t2: MAR Save@address PCdRoutine@address t3: Memoryd(MBR) C12, CW CR=Read control signal system bus. CW=Write control signal system bus. Internal Processor Organization Figure 20.5 indicates use variety data paths. complexity type organization clear. typically, sort internal bus arrangement, suggested Figure 14.2 ( Internal Structure CPU ), used. Using internal processor bus, Figure 20.5 rearranged shown Figure 20.6. single internal bus connects ALU processor registers. Gates control signals provided movement data onto bus register. Additional control signals control data transfer system (external) bus operation ALU. Two new registers, labeled Z, added organization. needed proper operation ALU. operation involv - ing two operands performed, one obtained internal bus, must obtained another source. AC could used pur - pose, limits flexibility system would work proces - sor multiple general- purpose registers. Register provides temporary storage input. ALU combinatorial circuit (see Chapter 11) internal storage. Thus, control signals activate ALU function, input ALU transformed output. Therefore, output ALU cannot directly connected bus, output would feed back input. Register Z provides temporary output storage. arrangement, operation add value memory AC would following steps: t1: MAR (IR(address)) t2: MBR Memory t3: (MBR) t4: Z (AC) + (Y) t5: AC (Z) organizations possible, but, general, sort internal bus set internal buses used. use common data paths simplifies 720 CHAPTER 20 / Con TRol Uni oPERAT ion interconnection layout control processor. Another practical reason use internal bus save space. Intel 8085 illustrate concepts introduced thus far chapter, let us consider Intel 8085. organization shown Figure 20.7 . Several key components may self- explanatory are: ■Incrementer/decrementer address latch: Logic add 1 subtract 1 contents stack pointer program counter. saves time avoiding use ALU purpose. ■Interrupt control: module handles multiple levels interrupt signals. ■Serial I/O control: module interfaces devices communicate 1 bit time. Table 20.2 describes external signals 8085. linked external system bus. signals interface 8085 processor rest system (Figure 20.8).Contr ol unit Addr ess lines Data lines ALUIR PC MAR MBR AC Z Inter nal CPU bus Figure 20.6 CPU Internal Bus20.2 / Con TRol PRoCEnnoR 721 control unit identified two components labeled (1) instruc - tion decoder machine cycle encoding (2) timing control. discussion first component deferred next section. essence control unit timing control module. module includes clock accepts inputs current instruction external control signals. output consists control signals components processor plus control signals external system bus. timing processor operations synchronized clock controlled control unit control signals. instruction cycle divided one five machine cycles ; machine cycle turn divided three five states. state lasts one clock cycle. state, processor performs one set simultaneous micro- operations determined control signals. number machine cycles fixed given instruction varies one instruction another. Machine cycles defined equivalent bus accesses. Thus, number machine cycles instruction depends number times processor must communicate external devices. example, instruction consists two 8-bit portions, two machine cycles required fetch instruction. instruction involves 1-byte memory I/O operation, third machine cycle required execution.8-bit inter nal data busInterrupt cont rolSerial I/O contr olINTR ClkOutPower supply+5V GND X1 X2 HLDA Reset ALE S0S1 ReadyINTA Hold Reset inRST 6.5 TRAP RST 5.5 RST 7.5 SID SOD (8) Accumulator(8) temp. reg.(8) /f_lags(8) instruction register instruction decoder machine cycle encodingALU(8) B reg.(8) C reg. (8) reg.(8) E reg. (8) H reg.(8) L reg. (16) stack pointer (16) program counter (8) addr ess buffer(8) addr ess buffer AD7 – AD0 addr ess/data busA15 – A8 addr ess busincrementer/ (16) decrementer addr ess latchregister array RDWR IO/MClk Gen Contr ol StatusTiming contr ol DMA Reset Figure 20.7 Intel 8085 CPU Block Diagram722 CHAPTER 20 / Con TRol Uni oPERAT ion Table 20.2 Intel 8085 External Signals Address Data Signals High Address (A15–A8) high- order 8 bits 16-bit address. Address/Data (AD7–AD0) lower- order 8 bits 16-bit address 8 bits data. multiplexing saves pins. Serial Input Data (SID) single- bit input accommodate devices transmit serially (one bit time). Serial Output Data (SOD) single- bit output accommodate devices receive serially. Timing Control Signals CLK (OUT) system clock. CLK signal goes peripheral chips synchronizes timing. X1, X2 signals come external crystal device drive internal clock generator. Address Latch Enabled (ALE) Occurs first clock state machine cycle causes peripheral chips store address lines. allows address module (e.g., memory, I/O) recognize addressed. Status (S0, S1) Control signals used indicate whether read write operation taking place. IO/M Used enable either I/O memory modules read write operations. Read Control (RD) Indicates selected memory I/O module read data bus available data transfer. Write Control (WR) Indicates data data bus written selected memory I/O location. Memory I/O Initiated Symbols Hold Requests CPU relinquish control use external system bus. CPU complete execution instruction presently IR enter hold state, signals inserted CPU control, address, data buses. hold state, bus may used DMA operations. Hold Acknowledge (HOLDA) control unit output signal acknowledges HOLD signal indicates bus available. READY Used synchronize CPU slower memory I/O devices. addressed device asserts READY, CPU may proceed input (DBIN) output (WR) operation. Otherwise, CPU enters wait state device ready. Interrupt- Related Signals TRAP Restart Interrupts (RST 7.5, 6.5, 5.5) Interrupt Request (INTR) five lines used external device interrupt CPU. CPU honor request hold state interrupt disabled. interrupt honored completion instruction. interrupts descending order priority. Interrupt Acknowledge Acknowledges interrupt.20.2 / Con TRol PRoCEnnoR 723 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 251 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 24 17 23 18 22 19 21 20X1 X2 Reset SOD SID Trap RST 7.5 RST 6.5 RST 5.5 INTR INTA AD0 AD1 AD2 AD3 AD4Vcc HOLD HLDA CLK (out) Reset Ready IO/M S1 Vpp RD WR S0 A15 A14 A13 A12 AD5A11 AD6A10 AD7A9 Vss A8 Figure 20.8 Intel 8085 Pin ConfigurationCPU Initialization RESET Causes contents PC set zero. CPU resumes execution location zero. RESET Acknowledges CPU reset. signal used reset rest system. Voltage Ground VCC +5-volt power supply VSS Electrical ground Figure 20.9 gives example 8085 timing, showing value external control signals. course, time, control unit generates internal con - trol signals control internal data transfers. diagram shows instruction cycle instruction. Three machine cycles (M1, 2, 3) needed. Dur - ing first, instruction fetched. second machine cycle fetches second half instruction, contains number I/O device selected output. third cycle, contents AC written selected device data bus. Address Latch Enabled ( ALE ) pulse signals start machine cycle control unit. ALE pulse alerts external circuits. timing state T1 machine cycle M1, control unit sets IO/M signal indicate memory operation. Also, control unit causes contents PC 724 CHAPTER 20 / Con TRol Uni oPERAT ion placed address bus ( A15 A8) address/data bus ( AD 7 AD 0). falling edge ALE pulse, modules bus store address. timing state T2, addressed memory module places contents addressed memory location address/data bus. control unit sets Read Control (RD) signal indicate read, waits T3 copy data bus. gives memory module time put data bus signal levels stabilize. final state, T4, bus idle state processor decodes instruction. remaining machine cycles proceed similar fashion. 20.3 HARDWIRED IMPLEMENTATION discussed control unit terms inputs, output, functions. turn topic control unit implementation. wide variety techniques used. fall one two categories: ■Hardwired implementation ■Microprogrammed implementation hardwired implementation , control unit essentially state machine circuit. input logic signals transformed set output logic signals, T1 A15 – A8M1OUT Byte M2 M3 PC outT2 PC+1 PCT3 PCH PCH IO PO RT3-MHz CLK ALET4 XT1 PC outT2 T3 T1 WZ outT2 T3 PC+1 PC byte Z,W P ort INSTR IRAD7 – AD0INSTR INSTR INSTR INSTR ACCUM PCH RD WR IO/M Instruction fetch Memory r ead Output write Figure 20.9 Timing Diagram Intel 8085 Instruction20.3 / H ARdwiREd i­PlE­EnTATion 725 control signals. approach examined section. Microprogrammed implementation subject Chapter 21. Control Unit Inputs Figure 20.4 depicts control unit far discussed it. key inputs IR, clock, flags, control bus signals. case flags control bus signals, individual bit typically meaning (e.g., overflow). two inputs, however, directly useful control unit. First consider IR. control unit makes use opcode per - form different actions (issue different combination control signals) different instructions. simplify control unit logic, unique logic input opcode. function performed decoder , takes encoded input produces single output. general, decoder n binary inputs 2n binary outputs. 2n different input patterns activate single unique output. Table 20.3 example n =4. decoder control unit typi - cally complex that, account variable- length opcodes. example digital logic used implement decoder presented Chapter 11. clock portion control unit issues repetitive sequence pulses. useful measuring duration micro- operations. Essentially, period clock pulses must long enough allow propagation signals along Table 20.3 Decoder 4 Inputs 16 Outputs I1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 I2 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 I3 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 I4 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 O1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 O2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 O3 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 O4 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 O5 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 O6 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 O7 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 O8 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 O9 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 O10 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 O11 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 O12 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 O13 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 O14 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 O15 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 O16 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0726 CHAPTER 20 / Con TRol Uni oPERAT ion data paths processor circuitry. However, seen, control unit emits different control signals different time units within single instruction cycle. Thus, would like counter input control unit, different control signal used T1,T2, forth. end instruction cycle, control unit must feed back counter reinitialize T1. two refinements, control unit depicted Figure 20.10. Control Unit Logic define hardwired implementation control unit, remains dis - cuss internal logic control unit produces output control signals function input signals. Essentially, must done is, control signal, derive Boolean expression signal function inputs. best explained example. Let us consider simple example illustrated Figure 20.5. saw Table 20.1 micro- operation sequences control signals needed con - trol three four phases instruction cycle. Let us consider single control signal, C5. signal causes data read external data bus MBR. see used twice Table 20.1. Let us define two new control signals, P Q, following interpretation: PQ=00 Fetch Cycle PQ=01 Indirect Cycle PQ=10 Execute Cycle PQ=11 Interrupt Cycle following Boolean expression defines C5: C5=P•Q•T2+P•Q•T2 Instruction registe r Decode r Control unit FlagsTimin g generator TnClockT2T1I0I1 Ik C0C1 Cm Figure 20.10 Control Unit Decoded Inputs20.4 / K Ey TER­n , REviEw QUEnT ionn, PRoblE­n 727 is, control signal C5 asserted second time unit fetch indirect cycles. expression complete. C5 also needed execute cycle. simple example, let us assume three instructions read memory: LDA, ADD, AND. define C5 C5=P•Q•T2+P•Q•T2+P•Q•(LDA+ADD+AND)•T2 process could repeated every control signal generated pro - cessor. result would set Boolean equations define behavior control unit hence processor. tie everything together, control unit must control state instruction cycle. mentioned, end subcycle (fetch, indirect, execute, interrupt), control unit issues signal causes timing generator reinitialize issue T1. control unit must also set appropriate values P Q define next subcycle performed. reader able appreciate modern complex processor, number Boolean equations needed define control unit large. task implementing combinatorial circuit satisfies equations becomes extremely difficult. result far simpler approach, known microprogramming , usually used. subject next chapter. 20.4 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms Review Questions 20.1 Explain distinction written sequence time sequence instruction. 20.2 relationship instructions micro- operations? 20.3 overall function processor’s control unit? 20.4 Outline three- step process leads characterization control unit. 20.5 basic tasks control unit perform? 20.6 Provide typical list inputs outputs control unit. 20.7 List three types control signals. 20.8 Briefly explain meant hardwired implementation control unit. Problems 20.1 ALU add two input registers, logically complement bits either input register, cannot subtract. Numbers stored twos com - plement representation. List micro- operations control unit must perform cause subtraction.control bus control pathcontrol signal control unithardwired implementation micro- operations728 CHAPTER 20 / Con TRol Uni oPERAT ion 20.2 Show micro- operations control signals fashion Table 20.1 processor Figure 20.5 following instructions: ■Load Accumulator ■Store Accumulator ■Add Accumulator ■AND Accumulator ■Jump ■Jump AC=0 ■Complement Accumulator 20.3 Assume propagation delay along bus ALU Figure 20.6 20 100 ns, respectively. time required register copy data bus 10 ns. time must allowed a. data one register another? b. program counter? 20.4 Write sequence micro- operations required bus structure Figure 20.6 add number AC number a. immediate operand; b. direct- address operand; c. indirect- address operand. 20.5 stack implemented shown Figure 20.11 (see Appendix discussion stacks). Show sequence micro- operations a. popping; b. stack. Block reserve stackMain memoryProcessor registers FreeStack limit Stack pointer Stack base use Descending addr esses Figure 20.11 Typical Stack Organization (full/descending)729CHAPTER Microprogra MMed control 21.1 Basic Concepts Microinstructions Microprogrammed Control Unit Wilkes Control Advantages Disadvantages 21.2 Microinstruction Sequencing Design Considerations Sequencing Techniques Address Generation LSI-11 Microinstruction Sequencing 21.3 Microinstruction Execution Taxonomy Microinstructions Microinstruction Encoding LSI-11 Microinstruction Execution IBM 3033 Microinstruction Execution 21.4 TI 8800 Microinstruction Format Microsequencer Registered ALU 21.5 Key Terms, Review Questions, Problems 730 CHAPTER 21 / Mi CRoPRogRAMME Con TRol term microprogram first coined M. V . Wilkes early 1950s [WILK51]. Wilkes proposed approach control unit design organized system - atic avoided complexities hardwired implementation. idea intrigued many researchers appeared unworkable would require fast, rela - tively inexpensive control memory. state microprogramming art reviewed Datamation February 1964 issue. microprogrammed system wide use time, one papers [HILL64] summarized then-popular view future microprogramming “is somewhat cloudy. None major manufacturers evidenced interest technique, although presumably examined it.” situation changed dramatically within months. IBM’s Sys - tem/360 announced April, largest models micropro - grammed. Although 360 series predated availability semiconductor ROM, advantages microprogramming compelling enough IBM make move. Microprogramming became popular technique imple - menting control unit CISC processors. recent years, microprogram - ming become less used remains tool available computer designers. example, seen Pentium 4, machine instructions con - verted RISC-like format, executed without use microprogramming. However, instructions executed using microprogramming. 21.1 BASIC CONCEPTS Microinstructions control unit seems reasonably simple device. Nevertheless, implement con - trol unit interconnection basic logic elements easy task. design must include logic sequencing micro-operations, executing micro-operations, interpreting opcodes, making decisions based ALU flags. difficult design test piece hardware. Furthermore, design relatively inflexi - ble. example, difficult change design one wishes add new machine instruction. alternative, used many CISC processors, imple - ment microprogrammed control unit .Learning Objectives studying chapter, able to: rPresent overview basic concepts microprogrammed control. rUnderstand difference hardwired control microprogrammed control. rDiscuss basic categories sequencing techniques. rPresent overview taxonomy microinstructions.21.1 / B AsiC Con CEPT 731 Consider Table 21.1. addition use control signals, micro- operation described symbolic notation. notation looks suspiciously like programming language. fact language, known microprogramming language . line describes set micro-operations occurring one time known microinstruction . sequence instructions known micropro- gram , firmware . latter term reflects fact microprogram midway hardware software. easier design firmware hardware, difficult write firmware program software program. use concept microprogramming implement control unit? Consider micro-operation, control unit allowed generate set control signals. Thus, micro-operation, con - trol line emanating control unit either off. condition can, course, represented binary digit control line. could construct control word bit represents one control line. micro-oper - ation would represented different pattern 1s 0s control word. Suppose string together sequence control words represent sequence micro-operations performed control unit. Next, must rec - ognize sequence micro-operations fixed. Sometimes indirect cycle; sometimes not. let us put control words memory, word unique address. add address field control word, indicating location next control word executed certain condition true (e.g., indirect bit memory-reference instruction 1). Also, add bits specify condition. Table 21.1 Machine Instruction Set Wilkes Example Order Effect Order n C(Acc)+C(n) Acc1 n C(Acc)-C(n) Acc1 H n C(n) Acc2 V n C(Acc2)*C(n) Acc, C(n)Ú0 n C(Acc1) n, 0 Acc U n C(Acc1) n R n C(Acc)*2(n+1) Acc L n C(Acc)*2n+1 Acc G n C(Acc)60, transfer control n; C(Acc)Ú0, ignore (i.e., proceed serially) n Read next character input mechanism n n Send C(n) output mechanism Notation: Acc=accumulator Acc1=most significant half accumulator Acc2=least significant half accumulator n=storage location n C(X)=contents X(X=register storage location)732 CHAPTER 21 / Mi CRoPRogRAMME Con TRol result known horizontal microinstruction , example shown Figure 21.1a. format microinstruction control word follows. one bit internal processor control line one bit system bus control line. condition field indicating condition branch, field address micro - instruction executed next branch taken. microinstruction interpreted follows: 1. execute microinstruction, turn control lines indicated 1 bit; leave control lines indicated 0 bit. resulting control signals cause one micro-operations performed. 2. condition indicated condition bits false, execute next micro - instruction sequence. 3. condition indicated condition bits true, next microinstruc - tion executed indicated address field. Figure 21.2 shows control words microinstructions could arranged control memory . microinstructions routine exe - cuted sequentially. routine ends branch jump instruction indicating go next. special execute cycle routine whose purpose signify one machine instruction routines (AND, ADD, on) executed next, depending current opcode. control memory Figure 21.2 concise description complete operation control unit. defines sequence micro-operations Microinstruction addres Jump condition —Unconditiona l —Zero —Over/f_low —Indirect bi System bus control signals Internal CPU control signal Microinstruction addres Jump condition Function codes(a) Horizontal microinstruction (b) Vertical microinstruction Figure 21.1 Typical Microinstruction Formats21.1 / B AsiC Con CEPT 733 performed cycle (fetch, indirect, execute, interrupt), specifies sequencing cycles. nothing else, notation would useful device documenting functioning control unit particular computer. that. also way implementing control unit. Microprogrammed Control Unit control memory Figure 21.2 contains program describes behavior control unit. follows could implement control unit simply executing program. Figure 21.3 shows key elements implementation. set microinstructions stored control memory . control address register con- tains address next microinstruction read. microinstruction read control memory, transferred control buffer register . left- hand portion register (see Figure 21.1a) connects control lines emanat - ing control unit. Thus, reading microinstruction control memory executing microinstruction. third element shown figure sequencing unit loads control address register issues read command.Jump indir ect executeFetch cycle routine Indirect cycle routine Interrupt cycle routine r outine ADD r outine IOF r outineExecute cycle beginningJump execute Jump fetch Jump fetch interrupt Jump fetch interrupt Jump fetch interruptJump opcode r outine Figure 21.2 Organization Control Memory734 CHAPTER 21 / Mi CRoPRogRAMME Con TRol Let us examine structure greater detail, depicted Figure 21.4. Com - paring Figure 21.3, see control unit still inputs (IR, ALU flags, clock) outputs (control signals). control unit functions follows: 1. execute instruction, sequencing logic unit issues READ command control memory. 2. word whose address specified control address register read control buffer register. 3. content control buffer register generates control signals next-address information sequencing logic unit. 4. sequencing logic unit loads new address control address register based next-address information control buffer register ALU flags. happens one clock pulse. last step listed needs elaboration. conclusion micro - instruction, sequencing logic unit loads new address control address register. Depending value ALU flags control buffer register, one three decisions made: ■Get next instruction: Add 1 control address register. ■Jump new routine based jump microinstruction: Load address field control buffer register control address register. ■Jump machine instruction routine: Load control address register based opcode IR. Figure 21.4 shows two modules labeled decoder . upper decoder trans - lates opcode IR control memory address. lower decoder used horizontal microinstructions used vertical microinstructions (Figure 21.1b). mentioned, horizontal microinstruction every bit Sequencing logic Read Contr ol addr ess register Cont rol buffer registerContr ol memory Figure 21.3 Control Unit Microarchitecture21.1 / B AsiC Con CEPT 735 control field attaches control line. vertical microinstruction, code used action performed [e.g., MARd(PC)], decoder translates code individual control signals. advantage vertical microinstruc - tions compact (fewer bits) horizontal microinstructions, expense small additional amount logic time delay. Wilkes Control mentioned, Wilkes first proposed use microprogrammed control unit 1951 [WILK51]. proposal subsequently elaborated detailed design [WILK53]. instructive examine seminal proposal. configuration proposed Wilkes depicted Figure 21.5. heart system matrix partially filled diodes. machine cycle, one row matrix activated pulse. generates signals points diode present (indicated dot diagram). first part row generates con - trol signals control operation processor. second part generates Sequencing logicCont rol unitDecoder Decoder Contr ol signals system busContr ol signals within CPUALU Flags Clock Read Next addr ess contr olContr ol addr ess registerInstruction r egister Contr ol buffer registerContr ol memory Figure 21.4 Functioning Microprogrammed Control Unit736 CHAPTER 21 / Mi CRoPRogRAMME Con TRol address row pulsed next machine cycle. Thus, row matrix one microinstruction, layout matrix control memory. beginning cycle, address row pulsed contained Register I. address input decoder, which, activated clock pulse, activates one row matrix. Depending control signals, either opcode instruction register second part pulsed row passed Register II cycle. Register II gated Register clock pulse. Alternating clock pulses used activate row matrix transfer Register II Register I. two-register arrangement needed decoder simply combinatorial circuit; one register, output would become input cycle, causing unstable condition. scheme similar horizontal microprogramming approach described earlier (Figure 21.1a). main difference this: previous descrip - tion, control address register could incremented one get next address. Wilkes scheme, next address contained microinstruc - tion. permit branching, row must contain two address parts, controlled conditional signal (e.g., flag), shown figure. proposed scheme, Wilkes provides example use imple - ment control unit simple machine. example, first known design microprogrammed processor, worth repeating illustrates many contemporary principles microprogramming. processor hypothetical machine (the example machine Wilkes) includes following registers:Register II Register Addr ess decoder Contr ol signalsContr ol signalsClockFrom instruction register Conditional signal Figure 21.5 Wilkes’s Microprogrammed Control Unit21.1 / B AsiC Con CEPT 737 Multiplicand B Accumulator (least significant half) C Accumulator (most significant half) Shift register addition, three registers two 1-bit flags accessible con - trol unit. registers follows: E Serves memory address register (MAR) temporary storage F Program counter G Another temporary register; used counting Table 21.1 lists machine instruction set example. Table 21.2 complete set microinstructions, expressed symbolic form, implements control unit. Thus, total 38 microinstructions required define system completely. first full column gives address (row number) microinstruction. addresses corresponding opcodes labeled. Thus, opcode add instruction (A) encountered, microinstruction location 5 exe - cuted. Columns 2 3 express actions taken ALU control unit, respectively. symbolic expression must translated set control signals (microinstruction bits). Columns 4 5 setting use two flags (flip-flops). Column 4 specifies signal sets flag. example, (1)C means flag number 1 set sign bit number reg - ister C. column 5 contains flag identifier, columns 6 7 contain two alternative microinstruction addresses used. Otherwise, column 6 specifies address next microinstruction fetched. Instructions 0 4 constitute fetch cycle. Microinstruction 4 presents opcode decoder, generates address microinstruction corre - sponding machine instruction fetched. reader able deduce complete functioning control unit careful study Table 21.2. Advantages Disadvantages principal advantage use microprogramming implement control unit simplifies design control unit. Thus, cheaper less error prone implement. hardwired control unit must contain complex logic sequencing many micro-operations instruction cycle. hand, decoders sequencing logic unit microprogrammed control unit simple pieces logic. principal disadvantage microprogrammed unit - slower hardwired unit comparable technology. Despite this, micro - programming dominant technique implementing control units pure CISC architectures, due ease implementation. RISC processors, simpler instruction format, typically use hardwired control units. examine microprogrammed approach greater detail.738 CHAPTER 21 / Mi CRoPRogRAMME Con TRol Table 21.2 Microinstructions Wilkes Example Notations: A, B, C, . . . stand various registers arithmetical control register units. C indicates switching circuits connect output register C input register D; (D+A) C indicates output register connected one input adding unit (the output permanently connected input), output adder register C. numerical symbol n quotes (e.g., “ n”) stands source whose output number n units least significant digit. Arithmetical UnitControl Register UnitConditional Flip-FlopNext Microinstruction Set Use 0 1 0 F G E 1 1 (G “1”) F 2 2 Store G 3 3 G E 4 4 E decoder — 5 C 16 6 C 17 H 7 Store B 0 V 8 Store 27 9 C Store 25 U 10 C Store 0 R 11 B E G 19 L 12 C E G 22 G 13 E G (1)C5 18 14 Input Store 0 15 Store Output 0 16 (D+Store) C 0 17 (D-Store) C 0 18 1 0 1 19 B (R)* (G-1) E 20 20 C (1)E5 21 21 C (R) 1 11 0 22 C (L)† (G-1) E 23 23 B (1)E5 24 24 B (L) 1 12 0 25 “0” B 26 26 B C 0 27 “0” C “18” E 28 28 B E G (1)B1 29 29 B (R) (G - “1”) E 30 30 C (R) (2)E5 1 31 3221.2 / Mi CRoins TRuCTion sEquEnCing 739 21.2 MICROINSTRUCTION SEQUENCING two basic tasks performed microprogrammed control unit follows: ■Microinstruction sequencing: Get next microinstruction control memory. ■Microinstruction execution: Generate control signals needed execute microinstruction. designing control unit, tasks must considered together, affect format microinstruction timing control unit. section, focus sequencing say little possible format timing issues. issues examined detail next section. Design Considerations Two concerns involved design microinstruction sequencing technique: size microinstruction address-generation time. first concern obvious; minimizing size control memory reduces cost com - ponent. second concern simply desire execute microinstructions fast possible. executing microprogram, address next microinstruction executed one categories: ■Determined instruction register ■Next sequential address ■BranchArithmetical UnitControl Register UnitConditional Flip-FlopNext Microinstruction Set Use 0 1 31 C 2 28 33 32 (D+A) C 2 28 33 33 B (1)B1 34 34 B (R) 35 35 C (R) 1 36 37 36 C 0 37 (D-A) C 0 * Right shift. switching circuits arithmetic unit arranged least significant digit register C placed significant place register B right shift micro-operations, significant digit register C (sign digit) repeated (thus making correction negative numbers). † Left shift. switching circuits similarly arranged pass significant digit register B least significant place register C left shift micro-operations.740 CHAPTER 21 / Mi CRoPRogRAMME Con TRol first category occurs per instruction cycle, instruction fetched. second category common designs. However, design cannot optimized sequential access. Branches, conditional unconditional, necessary part microprogram. Furthermore, microin - struction sequences tend short; one every three four microinstructions could branch [SIEW82]. Thus, important design compact, time-efficient techniques microinstruction branching. Sequencing Techniques Based current microinstruction, condition flags, contents instruction register, control memory address must generated next micro - instruction. wide variety techniques used. group three general categories, illustrated Figures 21.6 21.8. categories based format address information microinstruction: Contr ol addr ess register Addr ess decoder Addr ess selectionFlagsContr ol buffer registerAddr ess 1Addr ess 2Cont rolCont rol memory Branch logicMultiplexer Instruction register Figure 21.6 Branch Control Logic: Two Address Fields21.2 / Mi CRoins TRuCTion sEquEnCing 741 ■Two address fields ■Single address field ■Variable format simplest approach provide two address fields microinstruc - tion. Figure 21.6 suggests information used. multiplexer pro - vided serves destination address fields plus instruction register. Based address-selection input, multiplexer transmits either opcode one two addresses control address register (CAR). CAR subsequently decoded produce next microinstruction address. address- selection signals provided branch logic module whose input consists con - trol unit flags plus bits control portion microinstruction. Although two-address approach simple, requires bits microinstruction approaches. additional logic, savings achieved. common approach single address field (Figure 21.7). approach, options next address follows: ■Address field ■Instruction register code ■Next sequential addressAddr ess decoder Addr ess selectionFlagsContr ol buffer registerAddr ess Contr olContr ol memory Branch logicMultiplexerContr ol addr ess register+1 Instruction register Figure 21.7 Branch Control Logic: Single Address Field742 CHAPTER 21 / Mi CRoPRogRAMME Con TRol address-selection signals determine option selected. approach reduces number address fields one. Note, however, address field often used. Thus, inefficiency microinstruction coding scheme. Another approach provide two entirely different microinstruction formats (Figure 21.8). One bit designates format used. one format, remaining bits used activate control signals. - mat, bits drive branch logic module, remaining bits provide address. first format, next address either next sequential address address derived instruction register. second format, either conditional unconditional branch specified. One disadvantage approach one entire cycle consumed branch microinstruction. approaches, address generation occurs part cycle control signal generation, minimizing control mem - ory accesses. approaches described general. Specific implementations often involve variation combination techniques.Addr ess decoder Addr ess selectionAddr ess /f_ieldBranch contr ol /f_ieldEntir e /f_ield FlagsCont rol buffer registerCont rol memory Branch logicGate function logic Multiplexer Instruction registerContr ol addr ess register+1 Figure 21.8 Branch Control Logic: Variable Format21.2 / Mi CRoins TRuCTion sEquEnCing 743 Address Generation looked sequencing problem point view format con - siderations general logic requirements. Another viewpoint consider various ways next address derived computed. Table 21.3 lists various address generation techniques. divided explicit techniques, address explicitly available microinstruction, implicit techniques, require additional logic generate address. essentially dealt explicit techniques. two-field approach, two alternative addresses available microinstruction. Using either single address field variable format, various branch instructions implemented. conditional branch instruction depends following types information: ■ALU flags ■Part opcode address mode fields machine instruction ■Parts selected register, sign bit ■Status bits within control unit Several implicit techniques also commonly used. One these, mapping, required virtually designs. opcode portion machine instruction must mapped microinstruction address. occurs per instruc - tion cycle. common implicit technique one involves combining adding two portions address form complete address. approach taken IBM S/360 family [TUCK67] used many S/370 models. use IBM 3033 example. control address register IBM 3033 13 bits long illustrated Figure 21.9. Two parts address distinguished. highest-order 8 bits (00–07) normally change one microinstruction cycle next. execution microinstruction, 8 bits copied directly 8-bit field microinstruction (the BA field) highest-order 8 bits control address register. defines block 32 microinstructions control memory. remaining 5 bits control address register set specify specific address microinstruction fetched next. bits determined 4-bit field (except one 7-bit field) current microinstruc - tion; field specifies condition setting corresponding bit. example, bit control address register might set 1 0 depending whether carry occurred last ALU operation. Table 21.3 Microinstruction Address Generation Techniques Explicit Implicit Two-field Mapping Unconditional branch Addition Conditional branch Residual control744 CHAPTER 21 / Mi CRoPRogRAMME Con TRol final approach listed Table 21.3 termed residual control . approach involves use microinstruction address previously saved temporary storage within control unit. example, microin - struction sets come equipped subroutine facility. internal register stack registers used hold return addresses. example approach taken LSI-11, examine. LSI-11 Microinstruction Sequencing LSI-11 microcomputer version PDP-11, main components system residing single board. LSI-11 implemented using micropro - grammed control unit [SEBE76]. LSI-11 makes use 22-bit microinstruction control memory 2K 22-bit words. next microinstruction address determined one five ways: ■Next sequential address: absence instructions, control unit’s control address register incremented 1. ■Opcode mapping: beginning instruction cycle, next microin - struction address determined opcode. ■Subroutine facility: Explained presently. ■Interrupt testing: Certain microinstructions specify test interrupts. interrupt occurred, determines next microinstruction address. ■Branch: Conditional unconditional branch microinstructions used. one-level subroutine facility provided. One bit every microinstruction dedicated task. bit set, 11-bit return register loaded updated contents control address register. subsequent microinstruction specifies return cause control address register loaded return register. return one form unconditional branch instruction. Another form unconditional branch causes bits control address register loaded 11 bits microinstruction. conditional branch instruction makes use 4-bit test code within microinstruction. code specifies testing various ALU condition codes determine branch decision. condition true, next sequential address selected. true, 8 lowest-order bits control address register loaded 8 bits microinstruction. allows branching within 256-word page memory.12 11 10 09 08 07 00 BA(8)BB(4)BC(4) BD(4)BE(4) BF(7) Figure 21.9 IBM 3033 Control Address Register21.3 / Mi CRoins TRuCTion Ex ECuTion 745 seen, LSI-11 includes powerful address sequencing facility within control unit. allows microprogrammer considerable flexibility ease microprogramming task. hand, approach requires control unit logic simpler capabilities. 21.3 MICROINSTRUCTION EXECUTION microinstruction cycle basic event microprogrammed processor. cycle made two parts: fetch execute. fetch portion determined generation microinstruction address, dealt preceding section. section deals execution microinstruction. Recall effect execution microinstruction generate control signals. signals control points internal processor. remaining signals go external control bus external interface. incidental function, address next microinstruction determined. preceding description suggests organization control unit shown Figure 21.10. slightly revised version Figure 21.4 emphasizes focus section. major modules diagram clear. sequencing logic module contains logic perform functions discussed preceding section. generates address next microinstruction, using inputs instruction register, ALU flags, control address register (for incrementing), control buffer register. last may provide actual address, control bits, both. module driven clock determines timing microin - struction cycle. control logic module generates control signals function bits microinstruction. clear format content microinstruction determines complexity control logic module. Taxonomy Microinstructions Microinstructions classified variety ways. Distinctions com - monly made literature include following: ■Vertical/horizontal ■Packed/unpacked ■Hard/soft microprogramming ■Direct/indirect encoding bear format microinstruction. None terms used consistent, precise way literature. However, examination pairs qualities serves illuminate microinstruction design alterna - tives. following paragraphs, first look key design issue underlying pairs characteristics, look concepts suggested pair. original proposal Wilkes [WILK51], bit microinstruc - tion either directly produced control signal directly produced one bit next address. seen, preceding section, complex address 746 CHAPTER 21 / Mi CRoPRogRAMME Con TRol sequencing schemes, using fewer microinstruction bits, possible. schemes require complex sequencing logic module. similar sort trade-off exists portion microinstruction concerned control signals. encoding control information, subsequently decoding produce control signals, con - trol word bits saved. encoding done? answer that, consider total K different internal external control signals driven con - trol unit. Wilkes’s scheme, K bits microinstruction would dedicated purpose. allows 2 K possible combinations control signals generated instruction cycle. better observe possible combinations used. Examples include following: ■Two sources cannot gated destination (e.g., C2 C8 Fig ure 21.5). ■A register cannot source destination (e.g., C5 C12 Figure 21.5). ■Only one pattern control signals presented ALU time. ■Only one pattern control signals presented external control bus time.Sequencing logicInstruction register ALU Flags Clock Internal contr ol signalsExternal contr ol signalsContr ol logicContr ol addr ess r egister Contr ol buffer registerContr ol memory Figure 21.10 Control Unit Organization21.3 / Mi CRoins TRuCTion Ex ECuTion 747 So, given processor, possible allowable combinations control signals could listed, giving number Q < 2K possibilities. could encoded minimum log 2 Q bits, (log 2 Q) < K. would tightest possible form encoding preserves allowable combinations control signals. practice, form encoding used, two reasons: ■It difficult program pure decoded (Wilkes) scheme. point discussed presently. ■It requires complex therefore slow control logic module. Instead, compromises made. two kinds: ■More bits strictly necessary used encode possible combinations. ■Some combinations physically allowable possible encode. latter kind compromise effect reducing number bits. net result, however, use log 2 Q bits. next subsection, discuss specific encoding techniques. remainder subsection deals effects encoding various terms used describe it. Based preceding, see control signal portion microinstruction format falls spectrum. one extreme, one bit control signal; extreme, highly encoded format used. Table 21.4 shows characteristics microprogrammed control unit also fall along spectrum spectra are, large, determined degree-of-en - coding spectrum. second pair items table rather obvious. pure Wilkes scheme require bits. also apparent extreme presents detailed view hardware. Every control signal individually controllable Table 21.4 Microinstruction Spectrum Characteristics Unencoded Highly encoded Many bits bits Detailed view hardware Aggregated view hardware Difficult program Easy program Concurrency fully exploited Concurrency fully exploited Little control logic Complex control logic Fast execution Slow execution Optimize performance Optimize programming Terminology Unpacked Packed Horizontal Vertical Hard Soft748 CHAPTER 21 / Mi CRoPRogRAMME Con TRol microprogrammer. Encoding done way aggregate functions resources, microprogrammer viewing processor higher, less detailed level. Furthermore, encoding designed ease microprogram - ming burden. Again, clear task understanding orches - trating use control signals difficult one. mentioned, one consequences encoding, typically, prevent use certain otherwise allowable combinations. preceding paragraph discusses microinstruction design micro - programmer’s point view. degree encoding also viewed hardware effects. pure unencoded format, little decode logic needed; bit generates particular control signal. compact aggre - gated encoding schemes used, complex decode logic needed. This, turn, may affect performance. time needed propagate signals gates complex control logic module. Thus, execution encoded microinstructions takes longer execution unencoded ones. Therefore, characteristics listed Table 21.4 fall along spectrum design strategies. general, design falls toward left end spec - trum intended optimize performance control unit. Designs toward right end concerned optimizing process microprogramming. Indeed, microinstruction sets near right end spectrum look much like machine instruction sets. good example LSI-11 design, described later section. Typically, objective simply implement control unit, design near left end spectrum. IBM 3033 design, discussed presently, category. shall discuss later, systems permit variety users construct different microprograms using microinstruction facil - ity. latter cases, design likely fall near right end spectrum. deal terminology introduced earlier. Table 21.4 indi - cates three pairs terms relate microinstruction spectrum. essence, pairs describe thing emphasize different design characteristics. degree packing relates degree identification given control task specific microinstruction bits. bits become packed , given number bits contains information. Thus, packing connotes encoding. terms horizontal vertical relate relative width microinstructions. [SIEW82] suggests rule thumb vertical microinstructions lengths range 16 40 bits horizontal microinstructions lengths range 40 100 bits. terms hard soft microprogramming used sug - gest degree closeness underlying control signals hardware layout. Hard microprograms generally fixed committed read-only memory. Soft microprograms changeable suggestive user microprogramming. pair terms mentioned beginning subsection refers direct versus indirect encoding, subject turn. Microinstruction Encoding practice, microprogrammed control units designed using pure unen - coded horizontal microinstruction format. least degree encoding used reduce control memory width simplify task microprogramming.21.3 / Mi CRoins TRuCTion Ex ECuTion 749 basic technique encoding illustrated Figure 21.11a. microin - struction organized set fields. field contains code, which, upon decoding, activates one control signals. Let us consider implications layout. microinstruction executed, every field decoded generates control signals. Thus, N fields, N simultaneous actions specified. action results activation one control signals. Generally, always, want design format control signal activated one field. Clearly, however, must possible control signal activated least one field. consider individual field. field consisting L bits contain one 2L codes, encoded different control signal pattern. one code appear field time, codes mutually exclu - sive, and, therefore, actions cause mutually exclusive. Contr ol signals (a) Direct encoding (b) Indirect encodingDecode logicDecode logicDecode logic Decode logicDecode logic Contr ol signalsDecode logicField Field Field Field Field Field Decode logic Figure 21.11 Microinstruction Encoding750 CHAPTER 21 / Mi CRoPRogRAMME Con TRol design encoded microinstruction format stated simple terms: ■Organize format independent fields. is, field depicts set actions (pattern control signals) actions different fields occur simultaneously. ■Define field alternative actions specified field mutually exclusive. is, one actions specified given field could occur time. Two approaches taken organizing encoded microinstruction fields: functional resource. functional encoding method identifies func - tions within machine designates fields function type. example, var - ious sources used transferring data accumulator, one field designated purpose, code specifying different source. Resource encoding views machine consisting set independent resources devotes one field (e.g., I/O, memory, ALU). Another aspect encoding whether direct indirect (Figure 21.11b). indirect encoding, one field used determine interpretation another 0 0123456789 101112131415161110 0 ACC Register + 1 171801101 1 Register ACC01101 0 ACC Register01100 1 ACC ACC – Register01100 0 ACC ACC + Register01001 0 Skip01000 1 CSAR Constant (in next byte)01000 0 CSAR Decoded MDR 001001 Write001000 Read000010 Register selectMAR Register Memory operationsSpecial sequencing operations ALU operationsSimple r egister transfers 000001 Register MDR000000 MDR Register Register select Field Field de/f_inition 1 - register transfer 4 - ALU operation 2 - memory operation 5 - register selection 3 - sequencing operation 6 - constant(a) Vertical microinstruction format (b) Horizontal microinstruction format1 2 3 4 5 6 Figure 21.12 Alternative Microinstruction Formats Simple Machine21.3 / Mi CRoins TRuCTion Ex ECuTion 751 field. example, consider ALU capable performing eight different arithmetic operations eight different shift operations. 1-bit field could used indicate whether shift arithmetic operation used; 3-bit field would indicate operation. technique generally implies two levels decod - ing, increasing propagation delays. Figure 21.12 simple example concepts. Assume processor single accumulator several internal registers, program counter tem - porary register ALU input. Figure 21.12a shows highly vertical format. first 3 bits indicate type operation, next 3 encode operation, final 2 select internal register. Figure 21.12b horizontal approach, although encoding still used. case, different functions appear different fields. LSI-11 Microinstruction Execution LSI-11 [SEBE76] good example vertical microinstruction approach. look first organization control unit, microinstruction format. lsi-11 control unit organization LSI-11 first member PDP-11 family offered single-board processor. board contains three LSI chips, internal bus known microinstruction bus (MIB), additional interfacing logic. Figure 21.13 depicts, simplified form, organization LSI-11 pro - cessor. three chips data, control, control store chips. data chip contains 8-bit ALU, twenty-six 8-bit registers, storage several condition Contr ol store Cont rol chip Bus logicBus cont rol processor board logicData chipMicroinstruction bus LSI-11 system bus1611 1641822 22 number indicated, path multiple signals Figure 21.13 Simplified Block Diagram LSI-11 Processor752 CHAPTER 21 / Mi CRoPRogRAMME Con TRol codes. Sixteen registers used implement eight 16-bit general- purpose registers PDP-11. Others include program status word, memory address register (MAR), memory buffer register. ALU deals 8 bits time, two passes ALU required implement 16-bit PDP-11 arithmetic operation. controlled microprogram. control store chip chips contain 22-bit-wide control memory. control chip contains logic sequencing executing microinstructions. contains control address register, control data register, copy machine instruction register. MIB ties components together. microinstruction fetch, control chip generates 11-bit address onto MIB. Control store accessed, producing 22-bit microinstruction, placed MIB. low-order 16 bits go data chip, low-order 18 bits go control chip. high-order 4 bits control special processor board functions. Figure 21.14 provides still simplified detailed look LSI-11 control unit: figure ignores individual chip boundaries. address sequencing scheme described Section 21.2 implemented two modules. Overall sequence control provided microprogram sequence control module, capable Contr ol data r egister Contr ol store Translation arrayMicr oprogram sequence contr olContr ol addr ess r egister Retur n register Instruction r egisterINT Figure 21.14 Organization LSI-11 Control Unit21.3 / Mi CRoins TRuCTion Ex ECuTion 753 incrementing microinstruction address register performing unconditional branches. forms address calculation carried separate trans - lation array. combinatorial circuit generates address based microinstruction, machine instruction, microinstruction program counter, interrupt register. translation array comes play following occasions: ■The opcode used determine start microroutine. ■At appropriate times, address mode bits microinstruction tested perform appropriate addressing. ■Interrupt conditions periodically tested. ■Conditional branch microinstructions evaluated. lsi-11 microinstruction format LSI-11 uses extremely vertical microinstruction format, 22 bits wide. microinstruction set strongly resembles PDP-11 machine instruction set implements. design intended optimize performance control unit within constraint vertical, easily programmed design. Table 21.5 lists LSI-11 microinstructions. Figure 21.15 shows 22-bit LSI-11 microinstruction format. high-order 4 bits control special functions processor board. translate bit enables translation array check pending interrupts. load return register bit used end microroutine cause next microinstruction address loaded return register. remaining 16 bits used highly encoded micro-operations. - mat much like machine instruction, variable-length opcode one operands. Table 21.5 LSI-11 Microinstructions Arithmetic Operations General Operations Add word (byte, literal) Test word (byte, literal) Increment word (byte) 1 Increment word (byte) 2 Negate word (byte) Conditionally increment (decrement) byte Conditionally add word (byte) Add word (byte) carry Conditionally add digits Subtract word (byte) Compare word (byte, literal) Subtract word (byte) carry Decrement word (byte) 1 Logical Operations word (byte, literal) Test word (byte) word (byte) Exclusive-OR word (byte) Bit clear word (byte) Shift word (byte) right (left) (without) carry Complement word (byte)MOV word (byte) Jump Return Conditional jump Set (reset) flags Load G low Conditionally MOV word (byte) Input/Output Operations Input word (byte) Input status word (byte) Read Write Read (write) increment word (byte) 1 Read (write) increment word (byte) 2 Read (write) acknowledge Output word (byte, status)754 CHAPTER 21 / Mi CRoPRogRAMME Con TRol PA AB AC AD AE AF AG AH AJ AK AL A, B, C, r egisters0 35 Arithmetic Shift PB AB C BB BD BF BH Next addr ess36 71 Storage addr ess Storage addr essPB H CA CB CC CD CE CF CG CH Shift contr olLocal storageMiscellaneous cont rols72 107 P DA DB DC DD DE Testing condition code setting108 125 Figure 21.16 IBM 3033 Microinstruction Format(a) F ormat full LSI-11 microinstruction (b) F ormat encoded part LSI-11 microinstruction51 1 Opcode Jump addr ess Unconditional jump micr oinstruction f ormat 48 Opcode4 Test code Jump addr ess Conditional jump micr oinstruction f ormat48 Opcode4 register Literal value Literal micr oinstruction f ormat 84 Opcode B register4 register Register jump micr oinstruction f ormatSpecial functions TranslateLoad r eturn register41 11 6 Encoded micr o-operations Figure 21.15 LSI-11 Microinstruction Format IBM 3033 Microinstruction Execution standard IBM 3033 control memory consists 4K words. first half (0000–07FF) contain 108-bit microinstructions, remainder (0800–0FFF) used store 126-bit microinstructions. format depicted Figure 21.16. 21.4 / 8800 755 Table 21.6 IBM 3033 Microinstruction Control Fields ALU Control Fields AA(3) Load register one data registers AB(3) Load B register one data registers AC(3) Load C register one data registers AD(3) Load register one data registers AE(4) Route specified bits ALU AF(4) Route specified B bits ALU AG(5) Specifies ALU arithmetic operation input AH(4) Specifies ALU arithmetic operation B input AJ(1) Specifies B input ALU B side AK(4) Route arithmetic output shifter CA(3) Load F register CB(1) Activate shifter CC(5) Specifies logical carry functions CE(7) Specifies shift amount Sequencing Branching Fields AL(1) End operation perform branch BA(8) Set high-order bits (00–07) control address register BB(4) Specifies condition setting bit 8 control address register BC(4) Specifies condition setting bit 9 control address register BD(4) Specifies condition setting bit 10 control address register BE(4) Specifies condition setting bit 11 control address register BF(7) Specifies condition setting bit 12 control address register Although rather horizontal format, encoding still extensively used. key fields format summarized Table 21.6. ALU operates inputs four dedicated, non-user-visible registers, A, B, C, D. microinstruction format contains fields loading reg - isters user-visible registers, performing ALU function, specifying user-visible register storing result. also fields loading stor - ing data registers memory. sequencing mechanism IBM 3033 discussed Section 21.2. 21.4 TI 8800 Texas Instruments 8800 Software Development Board (SDB) micropro - grammable 32-bit computer card. system writable control store, imple - mented RAM rather ROM. system achieve speed 756 CHAPTER 21 / Mi CRoPRogRAMME Con TRol density microprogrammed system ROM control store. However, useful developing prototypes educational purposes. 8800 SDB consists following components (Figure 21.17): ■Microcode memory ■Microsequencer ■32-bit ALU ■Floating-point integer processor ■Local data memory Two buses link internal components system. DA bus provides data microinstruction data field ALU, floating-point processor, microsequencer. latter case, data consists address used branch instruction. bus also used ALU microsequencer Micr ocode memory 32K × 128 bits Micr oinstruction pipeline r egisterMicr oinstructionNext micr ocode addr ess Contr ol microinstruction DA31-D A00 System busACT8832 register ed ALU PC/A interfaceACT8847 /f_loating-point integer pr ocessor Local data memory 32K × 32 bitsACT8818 microsequencer 16323215 128 96 Figure 21.17 TI 8800 Block Diagram21.4 / 8800 757 provide data components. system bus connects ALU float - ing-point processor local memory external modules via PC interface. board fits IBM PC-compatible host computer. host computer provides suitable platform microcode assembly debug. Microinstruction Format microinstruction format 8800 consists 128 bits broken 30 functional fields, indicated Table 21.7 . field consists one bits, fields grouped five major categories: ■Control board ■8847 floating-point integer processor chip ■8832 registered ALU ■8818 microsequencer ■WCS data field indicated Figure 21.17, 32 bits WCS data field fed DA bus provided data ALU, floating-point processor, microsequencer. 96 bits (fields 1–27) microinstruction control signals fed directly appropriate module. simplicity, connections shown Figure 21.17. first six fields deal operations pertain control board, rather controlling individual component. Control operations include following: ■Selecting condition codes sequencer control. first bit field 1 indi - cates whether condition flag set 1 0, remaining 4 bits indicate flag set. ■Sending I/O request PC/AT. ■Enabling local data memory read/write operations. ■Determining unit driving system bus. One four devices attached bus (Figure 21.17) selected. last 32 bits data field, contain information specific par - ticular microinstruction. remaining fields microinstruction best discussed con - text device control. remainder section, discuss microsequencer registered ALU. floating-point unit introduces new concepts skipped. Microsequencer principal function 8818 microsequencer generate next microin - struction address microprogram. 15-bit address provided micro - code memory (Figure 21.17). next address selected one five sources: 1. microprogram counter (MPC) register, used repeat (reuse address) continue (increment address 1) instructions.758 CHAPTER 21 / Mi CRoPRogRAMME Con TRol Table 21.7 TI 8800 Microinstruction Format Field Number Number Bits Description Control Board 1 5 Select condition code input 2 1 Enable/disable external I/O request signal 3 2 Enable/disable local data memory read/write operations 4 1 Load status/do load status 5 2 Determine unit driving bus 6 2 Determine unit driving DA bus 8847 Floating-Point Integer Processing Chip 7 1 C register control: clock, clock 8 1 Select significant least significant bits bus 9 1 C register data source: ALU, multiplexer 10 4 Select IEEE FAST mode ALU MUL 11 8 Select sources data operands: RA registers, RB regis- ters, P register, 5 register, C register 12 1 RB register control: clock, clock 13 1 RA register control: clock, clock 14 2 Data source confirmation 15 2 Enable/disable pipeline registers 16 11 8847 ALU function 8832 Registered ALU 17 2 Write enable/disable data output selected register: significant half, least significant half 18 2 Select register file data source: DA bus, DB bus, ALU MUX output, system bus 19 3 Shift instruction modifier 20 1 Carry in: force, force 21 2 Set ALU configuration mode: 32, 16, 8 bits 22 2 Select input 5 multiplexer: register file, DB bus, MQ register 23 1 Select input R multiplexer: register file, DA bus 24 6 Select register file C write 25 6 Select register file B read 26 6 Select register file write 27 8 ALU function 8818 Microsequencer 28 12 Control input signals 8818 WCS Data Field 29 16 significant bits writable control store data field 30 16 Least significant bits writable control store data field21.4 / 8800 759 2. stack, supports microprogram subroutine calls well iterative loops returns interrupts. 3. DRA DRB ports, provide two additional paths exter - nal hardware microprogram addresses generated. two ports connected significant least significant 16 bits DA bus, respectively. allows microsequencer obtain next instruction address WCS data field current microinstruction result calculated ALU. 4. Register counters RCA RCB, used additional address storage. 5. external input onto bidirectional port support external interrupts. Figure 21.18 logical block diagram 8818. device consists following principal functional groups: ■A 16-bit microprogram counter (MPC) consisting register incrementer. ■Two register counters, RCA RCB, counting loops iterations, stor - ing branch addresses, driving external devices. ■A 65-word 16-bit stack, allows microprogram subroutine calls interrupts. ■An interrupt return register output enable interrupt processing microinstruction level. ■A output multiplexer next address selected MPC, RCA, RCB, external buses DRA DRB, stack. registers /counters registers RCA RCB may loaded DA bus, either current microinstruction output ALU. values may used counters control flow execution may automatically decremented accessed. values may also used microinstruction addresses supplied output multiplexer. Independent control registers single microinstruction cycle supported exception simultaneous decrement registers. stack stack allows multiple levels nested calls interrupts, used support branching looping. Keep mind operations refer control unit, overall processor, addresses involved microinstructions control memory. Six stack operations possible: 1. Clear, sets stack pointer zero, emptying stack; 2. Pop, decrements stack pointer; 3. Push, puts contents MPC, interrupt return register, DRA bus onto stack increments stack pointer; 4. Read, makes address indicated read pointer available output multiplexer;760 CHAPTER 21 / Mi CRoPRogRAMME Con TRol 5. Hold, causes address stack pointer remain unchanged; 6. Load stack pointer, inputs seven least significant bits DRA stack pointer. control microsequencer microsequencer controlled primarily 12-bit field current microinstruction, field 28 (Table 21.7). field consists following subfields: ■OSEL (1 bit): Output select. Determines value placed - put multiplexer feeds DRA bus (upper-left-hand corner DA31-D A16 (DRA)DA15-D A00 (DRA) Dual registers/countersMUX Stack B3-B0 Micr oprogram counter/ incrementerInterrupt return registerY output multiplexer Next micr ode addr ess Figure 21.18 TI 8818 Microsequencer21.4 / 8800 761 Figure 21.18). output selected come either stack reg - ister RCA. DRA serves input either output multiplexer register RCA. ■SELDR (1 bit): Select DR bus. set 1, bit selects external DA bus input DRA/DRB buses. set 0, selects output DRA multiplexer DRA bus (controlled OSEL) contents RCB DRB bus. ■ZEROIN (1 bit): Used indicate conditional branch. behavior microsequencer depend condition code selected field 1 (Table 21.7). ■RC2–RC0 (3 bits): Register controls. bits determine change contents registers RCA RCB. register either remain same, decrement, load DRA/DRB buses. ■S2–S0 (3 bits): Stack controls. bits determine stack operation performed. ■MUX2–MUX0: Output controls. bits, together condition code used, control output multiplexer therefore next microinstruc - tion address. multiplexer select output stack, DRA, DRB, MPC. bits set individually programmer. However, typically done. Rather, programmer uses mnemonics equate bit patterns would normally required. Table 21.8 lists 15 mnemonics field 28. microcode assembler converts appropriate bit patterns. Table 21.8 TI 8818 Microsequencer Microinstruction Bits (Field 28) Mnemonic Value Description RST8818 000000000110 Reset Instruction BRA88181 011000111000 Branch DRA Instruction BRA88180 010000111110 Branch DRA Instruction INC88181 000000111110 Continue Instruction INC88180 001000001000 Continue Instruction CAL88181 010000110000 Jump Subroutine Address Specified DRA CAL88180 010000101110 Jump Subroutine Address Specified DRA RET8818 000000011010 Return Subroutine PUSH8818 000000110111 Push Interrupt Return Address onto Stack POP8818 100000010000 Return Interrupt LOADDRA 000010111110 Load DRA Counter DA Bus LOADDRB 000110111110 Load DRB Counter DA Bus LOADDRAB 000110111100 Load DRA/DRB DECRDRA 010001111100 Decrement DRA Counter Branch Zero DECRDRB 010101111100 Decrement DRB Counter Branch Zero762 CHAPTER 21 / Mi CRoPRogRAMME Con TRol example, instruction INC88181 used cause next microin - struction sequence selected, currently selected condition code 1. Table 21.8, INC88181=000000111110 decodes directly ■OSEL=0: Selects RCA output DRA output MUX; case selection irrelevant. ■SELDR=0: defined previously; again, irrelevant instruction. ■ZEROIN=0: Combined value MUX, indicates branch taken. ■R=000: Retain current value RA RC. ■S=111: Retain current state stack. ■MUX=110: Choose MPC condition code=1, DRA condition code=0. Registered ALU 8832 32-bit ALU 64 registers configured operate four 8-bit ALUs, two 16-bit ALUs, single 32-bit ALU. 8832 controlled 39 bits make fields 17 27 microinstruction (Table 21.7); supplied ALU control signals. addition, indicated Figure 21.17, 8832 external connections 32-bit DA bus 32-bit system bus. Inputs DA provided simultaneously input data 64-word register file ALU logic mod - ule. Input system bus provided ALU logic module. Results ALU shift operations output DA bus system bus. Results also fed back internal register file. Three 6-bit address ports allow two-operand fetch operand write performed within register file simultaneously. MQ shifter MQ regis - ter also configured function independently implement double-precision 8-bit, 16-bit, 32-bit shift operations. Fields 17 26 microinstruction control way data flows within 8832 8832 external environment. fields follows: 17. Write Enable. two bits specify write 32 bits, 16 significant bits, 16 least significant bits, write register file. destination register defined field 24. 18. Select Register File Data Source. write occur register file, two bits specify source: DA bus, DB bus, ALU output, system bus. 19. Shift Instruction Modifier. Specifies options concerning supplying end fill bits reading bits shifted shift instructions. 20. Carry In. bit indicates whether bit carried ALU operation.21.4 / 8800 763 21. ALU Configuration Mode. 8832 configured operate single 32-bit ALU, two 16-bit ALUs, four 8-bit ALUs. 22. Input. ALU logic module inputs provided two internal multi - plexers referred R multiplexers. field selects input provided multiplexer: register file, DB bus, MQ register. source register defined field 25. 23. R Input. Selects input provided R multiplexer: register file DA bus. 24. Destination Register. Address register register file used destination operand. 25. Source Register. Address register register file used source operand, provided multiplexer. 26. Source Register. Address register register file used source operand, provided R multiplexer. Finally, field 27 8-bit opcode specifies arithmetic logical func - tion performed ALU. Table 21.9 lists different operations performed. example coding used specify fields 17 27, consider instruction add contents register 1 register 2 place result regis - ter 3. symbolic instruction CONT11 [17], WELH, SELRYFYMX, [24], R3, R2, R1, PASS + ADD assembler translate appropriate bit pattern. individual components instruction described follows: ■CONT11 basic NOP instruction. ■Field [17] changed WELH (write enable, low high), 32-bit register written into. ■Field [18] changed SELRFYMX select feedback ALU MUX output. ■Field [24] changed designate register R3 destination register. ■Field [25] changed designate register R2 one source registers. ■Field [26] changed designate register R1 one source registers. ■Field [27] changed specify ALU operation ADD. ALU shifter instruction PASS; therefore, ALU output shifted shifter. Several points made symbolic notation. necessary specify field number consecutive fields. is, CONT11 [17],WELH,[18],SELRFYMX written CONT11 [17],WELH,SELRFYMX SELRFYMX field 18. ALU instructions Group 1 Table 21.9 must always used con - junction Group 2. ALU instructions Groups 3 5 must used Group 2.764 CHAPTER 21 / Mi CRoPRogRAMME Con TRol Table 21.9 TI 8832 Registered ALU Instruction Field (Field 27) Group 1 Function ADD H#01 R+S+Cn SUBR H#02 (NOT R)+S+Cn SUBS H#03 R=(NOT S)+Cn INSC H#04 S+Cn INCNS H#05 (NOT S)+Cn INCR H#06 R+Cn INCNR H#07 (NOT R)+Cn XOR H#09 R XOR H#0A R H#0B R NAND H#0C R NAND H#0D R ANDNR H#0E (NOT R) Group 2 Function SRA H#00 Arithmetic right single precision shift SRAD H#10 Arithmetic right double precision shift SRL H#20 Logical right single precision shift SRLD H#30 Logical right double precision shift SLA H#40 Arithmetic left single precision shift SLAD H#50 Arithmetic left double precision shift SLC H#60 Circular left single precision shift SLCD H#70 Circular left double precision shift SRC H#80 Circular right single precision shift SRCD H#90 Circular right double precision shift MQSRA H#A0 Arithmetic right shift MQ register MQSRL H#B0 Logical right shift MQ register MQSLL H#C0 Logical left shift MQ register MQSLC H#D0 Circular left shift MQ register LOADMQ H#E0 Load MQ register PASS H#F0 Pass ALU (no shift operation) Group 3 Function SET1 H#08 Set bit 1 Set0 H#18 Set bit 0 TB1 H#28 Test bit 1 TB0 H#38 Test bit 0 ABS H#48 Absolute value SMTC H#58 Sign magnitude/twos-complement21.4 / 8800 765 Group 3 Function ADDI H#68 Add immediate SUBI H#78 Subtract immediate BADD H#88 Byte add R BSUBS H#98 Byte subtract R BSUBR H#A8 Byte subtract R BINCS H#B8 Byte increment BINCNS H#C8 Byte increment negative BXOR H#D8 Byte XOR R BAND H#E8 Byte R BOR H#F8 Byte R Group 4 Function CRC H#00 Cyclic redundancy character accum. SEL H#10 Select R SNORM H#20 Single length normalize DNORM H#30 Double length normalize DIVRF H#40 Divide remainder fix SDIVQF H#50 Signed divide quotient fix SMULI H#60 Signed multiply iterate SMULT H#70 Signed multiply terminate SDIVIN H#80 Signed divide initialize SDIVIS H#90 Signed divide start SDIVI H#A0 Signed divide iterate UDIVIS H#B0 Unsigned divide start UDIVI H#C0 Unsigned divide iterate UMULI H#D0 Unsigned multiply iterate SDIVIT H#E0 Signed divide terminate UDIVIT H#F0 Unsigned divide terminate Group 5 Function LOADFF H#0F Load divide/BCD flip-flops CLR H#1F Clear DUMPFF H#5F Output divide/BCD flip-flops BCDBIN H#7F BCD binary EX3BC H#8F Excess (3 byte correction EX3C H#9F Excess (3 word correction SDIVO H#AF Signed divide overflow test BINEX3 H#DF Binary excess -3 NOP32 H#FF operation766 CHAPTER 21 / Mi CRoPRogRAMME Con TRol 21.5 KEY TERMS, REVIEW QUESTIONS, PROBLEMS Key Terms Review Questions 21.1 difference hardwired implementation microprogrammed implementation control unit? 21.2 horizontal microinstruction interpreted? 21.3 purpose control memory? 21.4 typical sequence execution horizontal microinstruction? 21.5 difference horizontal vertical microinstructions? 21.6 basic tasks performed microprogrammed control unit? 21.7 difference packed unpacked microinstructions? 21.8 difference hard soft microprogramming? 21.9 difference functional resource encoding? 21.10 List common applications microprogramming. Problems 21.1 Describe implementation multiply instruction hypothetical machine designed Wilkes. Use narrative flowchart. 21.2 Assume microinstruction set includes microinstruction following symbolic form: (AC0=1) CARd(C0-6) ELSE CARd(CAR)+1 AC0 sign bit accumulator C0-6 first seven bits microinstruction. Using microinstruction, write microprogram implements Branch Register Minus (BRM) machine instruction, branches AC negative. Assume bits C1 C n microinstruction specify parallel set micro-operations. Express program symbolically. 21.3 simple processor four major phases instruction cycle: fetch, indirect, execute, interrupt. Two 1 -bit flags designate current phase hardwired implementation. a. flags needed? b. needed microprogrammed control unit? 21.4 Consider control unit Figure 21.7 . Assume control memory 24 bits wide. control portion microinstruction format divided two fields. micro-operation field 13 bits specifies micro-operations performed. address selection field specifies condition, based flags, cause microinstruction branch. eight flags.control memory control word firmware hard microprogramming horizontal microinstructionmicroinstruction encoding microinstruction execution microinstruction sequencing microinstructions microprogrammicroprogrammed control unit microprogramming language soft microprogramming unpacked microinstruction vertical microinstruction21.5 / K Ey TERMs, REviEw quEsTions, PRoBlEMs 767 a. many bits address selection field? b. many bits address field? c. size control memory? 21.5 unconditional branching done circumstances previous problem? branching avoided; is, describe microinstruction specify branch, conditional unconditional. 21.6 wish provide 8 control words machine instruction routine. Machine instruction opcodes 5 bits, control memory 1024 words. Suggest map - ping instruction register control address register. 21.7 encoded microinstruction format used. Show 9-bit micro-operation field divided subfields specify 46 different actions. 21.8 processor 16 registers, ALU 16 logic 16 arithmetic functions, shifter 8 operations, connected internal processor bus. Design micro - instruction format specify various micro-operations processor.768Appendix Projects teaching comPuter organization architecture A.1 Interactive Simulations A.2 Research Projects A.3 Simulation Projects SimpleScalar SMPCache A.4 Assembly Language Projects A.5 Reading/Report Assignments A.6 Writing Assignments A.7 Test BankA.1 / Inter ActIve SImulAtIonS 769 Many instructors believe research implementation projects crucial clear understanding concepts computer organization architecture. Without projects, may difficult students grasp basic concepts interactions among components. Projects reinforce concepts introduced book, give students greater appreciation inner workings processors computer systems, motivate students give confidence mastered material. text, tried present concepts computer organization architecture clearly possible provided numerous homework problems reinforce concepts. Many instructors wish supplement material projects. appendix provides guidance regard describes support material available Instructor’s Resource Center (IRC) book, accessible instructors online Pearson. support material covers six types projects student exercises: ■■Interactive simulations ■■Research projects ■■Simulation projects ■■Assembly language projects ■■Reading/report assignments ■■Writing assignments ■■Test bank A.1 Inter ActIve SImulAtIonS Interactive simulations provide powerful tool understanding complex design features modern computer system. Today’s students want able visualize various complex computer systems mechanisms computer screen. total 20 simulations used illustrate key functions algorithms computer organization architecture design. Table A.1 lists simulations chapter. relevant point book, icon indicates relevant interac - tive simulation available online student use. simulations enable user set initial conditions, serve basis student assignments. IRC book includes set assign - ments, one set interactive simulations. assignment includes several specific problems assigned students. interactive simulations developed direction Profes - sor Israel Koren, University Massachusetts Department Electrical Computer Engineering. Aswin Sreedhar University Massachusetts developed interactive simulation assignments. access animations, click rotating globe book’s web site http://williamstallings.com/ ComputerOrganization.770 Append Ix / project teAchIng computer orgAnIzAtIon Table A.1 Computer Organization Architecture— Interactive Simulations Chapter Chapter 4—Cache Memory Cache Simulator Emulates small- sized caches based user- input cache model displays cache contents end sim- ulation cycle based input sequence entered user, randomly generated selected. Cache Time Analysis Demonstrates Average Memory Access Time analysis cache parameters specify. Multitask Cache Demonstrator Models cache system supports multitasking. Selective Victim Cache Simulator Compares three different cache policies. Chapter 5—Internal Memory Interleaved Memory Simulator Demonstrates effect interleaving memory. Chapter 6—External Memory RAID Determine storage efficiency reliability. Chapter 7—Input/Output I/O System Design Tool Evaluates comparative cost performance different I/O systems. Chapter 8—OS Support Page Replacement Algorithms Compares LRU, FIFO, Optimal. Page Replacement Algorithms Compares number policies. Chapter 14—CPU Structure Function Reservation Table Analyzer Evaluates reservation tables. way representing task flow pattern pipelined system. Branch Prediction Demonstrates three different branch prediction schemes. Branch Target Buffer Combined branch predictor/branch target buffer simulator. Chapter 15—Reduced Instruction Set Computers MIPS 5-Stage Pipeline Simulates pipeline. Loop Unrolling Simulates loop unrolling software technique exploiting instruction- level parallelism. Chapter 16— Instruction- Level Parallelism Superscalar Processors Pipeline Static vs. Dynamic Scheduling complex simulation MIPS pipeline. Reorder Buffer Simulator Simulates instruction reordering RISC pipeline. Scoreboarding Technique Dynamic SchedulingSimulation instruction scheduling technique used number processors. Tomasulo’s Algorithm Simulation another instruction scheduling technique. Alternative Simulation Tomasulo’s AlgorithmAnother simulation Tomasulo’s algorithm. Chapter 17—Parallel Processing Vector Processor Simulation Demonstrates execution vector processing instructions.A.3 / ImulAtIon project 771 A.2 reSeArch Project effective way reinforcing basic concepts course teaching stu - dents research skills assign research project. project could involve literature search well Web search vendor products, research lab activities, standardization efforts. Projects could assigned teams or, smaller proj - ects, individuals. case, best require sort project proposal early term, giving instructor time evaluate proposal appropriate topic appropriate level effort. Student handouts research projects include ■■A format proposal ■■A format final report ■■A schedule intermediate final deadlines ■■A list possible project topics students select one listed topics devise comparable project. IRC includes suggested format proposal final report well list possible research topics. A.3 SImulAtIon Project excellent way obtain grasp internal operation processor study appreciate design trade- offs performance implications simulating key elements processor. Two tools useful pur - pose SimpleScalar SMPCache. Compared actual hardware implementation, simulation provides two advantages research educational use: ■■With simulation, easy modify various elements organization, vary performance characteristics various components, ana - lyze effects modifications. ■■Simulation provides detailed performance statistics collection, used understand performance trade- offs. SimpleScalar SimpleScalar [BURG97 , MANJ01a, MANJ01b] set tools used simulate real programs range modern processors systems. tool set includes compiler, assembler, linker, simulation visualization tools. Simple - Scalar provides processor simulators range extremely fast functional simulator detailed out- of- order issue, superscalar processor simulator sup - ports nonblocking caches speculative execution. instruction set architecture organizational parameters may modified create variety experiments. IRC book includes concise introduction SimpleScalar students, instructions load get started SimpleScalar. manual also includes suggested project assignments.772 Append Ix / project teAchIng computer orgAnIzAtIon SimpleScalar portable software package runs UNIX plat - forms. SimpleScalar software downloaded SimpleScalar Web site. available cost noncommercial use. SMPCache SMPCache trace- driven simulator analysis teaching cache mem - ory systems symmetric multiprocessors [RODR01]. simulation based model built according architectural basic principles systems. simulator full graphic friendly interface. parameters studied simulator are: program locality; influence number pro - cessors, cache coherence protocols, schemes bus arbitration, mapping, replace - ment policies, cache size (blocks cache), number cache sets (for set associative caches), number words block (memory block size). IRC book includes concise introduction SMPCache stu - dents, instructions load get started SMPCache. manual also includes suggested project assignments. SMPCache portable software package runs PC systems Win - dows. SMPCache software downloaded SMPCache Web site. available cost noncommercial use. A.4 ASSembly lAnguAge Project Assembly language programming often used teach students low- level hardware components computer architecture basics. CodeBlue simplified assembly language program developed U.S. Air Force Academy. goal work develop teach assembly language concepts using visual simulator students learn single class. developers also wanted students find language motivational fun use. CodeBlue language much simpler simplified architecture instruction sets SC123. Still allows students develop interesting assembly level programs compete tournaments, similar far complex SPIMbot simulator. important, CodeBlue programming, students learn fundamental computer architecture concepts instructions data co- residence memory, control structure implementation, addressing modes. provide basis projects, developers built visual develop - ment environment allows students create program, see representation memory, step program’s execution, simulate battle competing programs visual memory environment. Projects built around concept Core War tournament. Core War programming game introduced public early 1980s, popular period 15 years so. Core War four main components: mem - ory array 8000 addresses, simplified assembly language Redcode, execu - tive program called MARS (an acronym Memory Array Redcode Simulator), set contending battle programs. Two battle programs entered memory array randomly chosen positions; neither program knows A.7 / teSt BAnk 773 one is. MARS executes programs simple version time- sharing. two programs take turns: single instruction first program executed, single instruction second, on. battle program execution cycles allotted entirely programmer. aim destroy program ruining instructions. CodeBlue environment substi - tutes CodeBlue Redcode provides interactive execution interface. IRC includes CodeBlue environment, user’s manual students, supporting material, suggested assignments. A.5 reAdIng/rePort SSIgnment Another excellent way reinforce concepts course give students research experience assign papers literature read analyzed. IRC includes suggested list papers assigned, organized chapter. Premium Content Web site provides copy papers. IRC also includes suggested assignment wording. A.6 WrItIng SSIgnment Writing assignments powerful multiplier effect learning process technical discipline computer organization architecture. Adherents Writing Across Curriculum (WAC) movement ( http://wac.colostate.edu/ ) report substantial benefits writing assignments facilitating learning. Writing assignments lead detailed complete thinking particular topic. addition, writing assignments help overcome tendency students pursue subject minimum personal engagement, learning facts problem- solving techniques without obtaining deep understanding subject matter. IRC contains number suggested writing assignments, organized chapter. Instructors may ultimately find important part approach teaching material. would greatly appreciate feedback area suggestions additional writing assignments. A.7 teSt bAnk test bank book available IRC site book. chapter, test bank includes true/false, multiple choice, fill- in- the- blank questions. test bank effective way assess student comprehension material.774 Appendix B Assembly lAnguAge RelAted topics B.1 Assembly Language Assembly Language Elements Type Assembly Language Statements Example: Greatest Common Divisor Program B.2 Assemblers Two-Pass Assembler One-Pass Assembler Example: Prime Number Program B.3 Loading Linking Relocation Loading Linking B.4 Key Terms, Review Questions, ProblemsB.1 / Assem Bly lAnguAge 775 topic assembly language briefly introduced Chapter 13. appendix provides detail also covers number related topics. number reasons worthwhile study assembly language programming (as com - pared programming higher-level language), including following: 1. clarifies execution instructions. 2. shows data represented memory. 3. shows program interacts operating system, processor, I/O system. 4. clarifies program accesses external devices. 5. Understanding assembly language programmers makes students better high- level language (HLL) programmers, giving better idea target language HLL must translated into. begin chapter study basic elements assembly lan - guage, using x86 architecture examples.1 Next, look operation assembler. followed discussion linkers loaders. Table B.1 defines key terms used appendix. B.1 Assem Bly lAnguAge Assembly language programming language one step away machine language. Typically, assembly language instruction translated one machine instruction assembler. Assembly language hardware dependent, different assembly language type processor. particular, assem - bly language instructions make reference specific registers processor, include opcodes processor, reflect bit length various registers processor operands machine language. assembly lan - guage programmer must therefore understand computer’s architecture. Programmers rarely use assembly language applications even systems programs. HLLs provide expressive power conciseness greatly eases programmer’s tasks. disadvantages using assembly language rather HLL include following [FOG08]: 1. Development time. Writing code assembly language takes much longer writing high-level language. 2. Reliability security. easy make errors assembly code. assem - bler checking calling conventions register save conventions obeyed. Nobody checking number PUSH POP instruc - tions possible branches paths. many possibili - ties hidden errors assembly code affects reliability security project unless systematic approach testing verifying. 1There number assemblers x86 architecture. examples use NASM (Netwide Assem - bler), open source assembler. copy NASM manual book’s Premium Content site.776 Appendix B / Assem Bly lAnguAge Rel Ated topics 3. Debugging verifying. Assembly code difficult debug verify possibilities errors high-level code. 4. Maintainability. Assembly code difficult modify maintain language allows unstructured spaghetti code kinds tricks difficult others understand. Thorough documentation consistent programming style needed. 5. Portability. Assembly code platform-specific. Porting different platform difficult.Table B.1 Key Terms Appendix Assembler program translates assembly language machine code. Assembly Language symbolic representation machine language specific processor, augmented additional types statements facilitate program writing provide instructions assembler. Compiler program converts another program source language (or programming language) machine language (object code). compilers output assembly language con- verted machine language separate assembler. compiler distinguished assembler fact input statement not, general, correspond single machine instruc- tion fixed sequence instructions. compiler may support features automatic allocation variables, arbitrary arithmetic expressions, control structures loops, variable scope, input/output operations, higher-order functions portability source code. Executable Code machine code generated source code language processor assembler compiler. software form run computer. Instruction Set collection possible instructions particular computer; is, collection machine language instructions particular processor understands. Linker utility program combines one files containing object code separately compiled program modules single file containing loadable executable code. Loader program routine copies executable program memory execution. Machine Language, Machine Code binary representation computer program actually read interpreted computer. program machine code consists sequence machine instructions (possibly interspersed data). Instructions binary strings may either size (e.g., one 32-bit word many modern RISC microprocessors) different sizes. Object Code machine language representation programming source code. Object code created compiler assembler turned executable code linker.B.1 / Assem Bly lAnguAge 777 6. System code use intrinsic functions instead assembly. best modern C++ compilers intrinsic functions accessing system control registers system instructions. Assembly code longer needed device drivers system code intrinsic functions available. 7. Application code use intrinsic functions vector classes instead assembly. best modern C++ compilers intrinsic functions vector operations special instructions previously required assembly programming. 8. Compilers improved lot recent years. best compilers quite good. takes lot expertise experience optimize better best C++ compiler. Yet still advantages occasional use assembly lan - guage, including following [FOG08a]: 1. Debugging verifying. Looking compiler-generated assembly code disassembly window debugger useful finding errors checking well compiler optimizes particular piece code. 2. Making compilers. Understanding assembly coding techniques necessary making compilers, debuggers, development tools. 3. Embedded systems. Small embedded systems fewer resources PCs mainframes. Assembly programming necessary optimizing code speed size small embedded systems. 4. Hardware drivers system code. Accessing hardware, system control regis - ters, may sometimes difficult impossible high level code. 5. Accessing instructions accessible high-level language. Cer- tain assembly instructions high-level language equivalent. 6. Self-modifying code. Self-modifying code generally profitable interferes efficient code caching. may, however, advantageous, example, include small compiler math programs user-defined function calculated many times. 7. Optimizing code size. Storage space memory cheap nowadays worth effort use assembly language reducing code size. However, cache size still critical resource may useful cases optimize critical piece code size order make fit code cache. 8. Optimizing code speed. Modern C++ compilers generally optimize code quite well cases. still cases compilers perform poorly dramatic increases speed achieved careful assembly programming. 9. Function libraries. total benefit optimizing code higher function libraries used many programmers. 10. Making function libraries compatible multiple compilers operating systems. possible make library functions multiple entries compatible different compilers different operating systems. requires assembly programming.778 Appendix B / Assem Bly lAnguAge Rel Ated topics terms assembly language machine language sometimes, erro - neously, used synonymously. Machine language consists instructions directly executable processor. machine language instruction binary string containing opcode, operand references, perhaps bits related execu - tion, flags. convenience, instead writing instruction bit string, written symbolically, names opcodes registers. assembly lan - guage makes much greater use symbolic names, including assigning names spe - cific main memory locations specific instruction locations. Assembly language also includes statements directly executable serve instructions assembler produces machine code assembly language program. Assembly Language Elements statement typical assembly language form shown Figure B.1. con - sists four elements: label, mnemonic, operand, comment. label label present, assembler defines label equivalent address first byte object code generated instruction loaded. programmer may subsequently use label address data another instruction’s address field. assembler replaces label assigned value creating object program. Labels frequently used branch instructions. example, program fragment: L2: SUB EAX, EDX ;subtract contents register EDX ;contents EAX store result EAX JG L2 ;jump L2 result subtraction ;positive program continue loop back location L2 result zero negative. Thus, jg instruction executed, result positive, processor places address equivalent label L2 program counter. Reasons using label include following; 1. label makes program location easier find remember. 2. label easily moved correct program. assembler auto - matically change address instructions use label program reassembled. 3. programmer calculate relative absolute memory addresses, uses labels needed. Label Mnemonic Operand(s) ;comment Optiona lO pcode name directi name macro nameZero Optional Figure B.1 Assembly-Language Statement StructureB.1 / Assem Bly lAnguAge 779 mnemonic mnemonic name operation function assembly language statement. discussed subsequently, statement correspond machine instruction, assembler directive, macro. case machine instruction, mnemonic symbolic name associated particular opcode. Table 12.8 lists mnemonic, instruction name, many x86 instruc - tions. Appendix [CART06] lists x86 instructions, together oper - ands effect instruction condition codes. Appendix B NASM manual provides detailed description x86 instruction. documents available book’s Premium Content site. operand (s) assembly language statement includes zero operands. operand identifies immediate value, register value, memory location. Typically, assembly language provides conventions distinguishing among three types operand references, well conventions indicating addressing mode. x86 architecture, assembly language statement may refer regis - ter operand name. Figure B.2 illustrates general-purpose x86 registers, symbolic name bit encoding. assembler translate sym - bolic name binary identifier register. 0 AX AH AL BH BL CH CL DH DLBX CX DXEAX (000) EBX (011) ECX (001) EDX (010)16-bit 32-bit ESI (110) EDI (111) EBP (101) ESP (100)31General-purpose registers Segment registers0 CS DS SS ES FS GS15 Figure B.2 Intel x86 Program Execution Registers780 Appendix B / Assem Bly lAnguAge Rel Ated topics discussed Section 11.2, x86 architecture rich set addressing modes, must expressed symbolically assembly language. cite common examples. register addressing , name register used instruction. example, MOV ECX , EBX copies contents register EBX register ECX. Immediate addressing indicates value encoded instruction. example, MOV EAX , 100H copies hexadeci - mal value 100 register EAX. immediate value expressed binary number suffix B decimal number suffix. Thus, equivalent state - ments preceding one MOV EAX , 100000000B MOV EAX , 256. Direct addressing refers memory location expressed displacement DS segment register. best explained example. Assume 16-bit data segment register DS contains value 1000H. following sequence occurs: MOV AX, 1234H MOV [3518H], AX First 16-bit register AX initialized 1234H. Then, line two, contents AX moved logical address DS:3518H. address formed shifting contents DS left 4 bits adding 3518H form 32-bit logical address 13518H. comment assembly languages allow placement comments program. comment either occur right-hand end assembly statement occupy entire text line. either case, comment begins special character signals assembler rest line comment ignored assembler. Typically, assembly languages x86 architecture use semicolon (;) special character. Type Assembly Language Statements Assembly language statements one four types: instruction, directive, macro definition, comment. comment statement simply statement consists entirely comment. remaining types briefly described section. instructions bulk noncomment statements assembly language program symbolic representations machine language instructions. Almost invariably, one-to-one relationship assembly language instruction machine instruction. assembler resolves symbolic references translates assembly language instruction binary string comprises machine instruction. directives Directives, also called pseudo-instructions , assembly language statements directly translated machine language instructions. Instead, directives instruction assembler perform specified actions assembly process. Examples include following: ■Define constants ■Designate areas memory data storage ■Initialize areas memory ■Place tables fixed data memory ■Allow references programsB.1 / Assem Bly lAnguAge 781 Table B.2 lists NASM directives. example, consider following sequence statements: (b) Directives Name Description Example DB, DW, DD, DQ, DTInitialize locations L6 DD 1A92H ;doubleword L6 initialized 1A92H RESB, RESW, RESD, RESQ, RESTReserve uninitialized locationsBUFFER RESB 64 ;reserve 64 bytes starting BUFFER INCBIN Include binary file outputINCBIN “file.dat” ; include file EQU Define symbol given constant valueMSGLEN EQU 25 ;the constant MSGLEN equals decimal 25 TIMES Repeat instruction multiple timesZEROBUF TIMES 64 DB 0 ;initialize 64-byte buffer zerosTable B.2 NASM Assembly-Language Directives (a) Letters RES x x Directives Unit Letter byte B word (2 bytes) W double word (4 bytes) quad word (8 bytes) Q ten bytes L2 DB “A” ;byte initialized ASCII code (65) MOV AL, [L1] ;copy byte L1 AL MOV EAX, L1 ;store address byte L1 EAX MOV [L1], AH ;copy contents AH byte L1 plain label used, interpreted address (or offset) data. label placed inside square brackets, interpreted data address. macro definitions macro definition similar subroutine several ways. subroutine section program written once, used multiple times calling subroutine point program. program compiled assembled, subroutine loaded once. call subroutine transfers control subroutine return instruction subroutine returns control point call. Similarly, macro definition section code programmer writes once, use many times. main difference assembler encounters macro call, replaces macro call macro itself. process called macro expansion . So, macro defined 782 Appendix B / Assem Bly lAnguAge Rel Ated topics assembly language program invoked 10 times, 10 instances macro appear assembled code. essence, subroutines handled hardware run time, whereas macros handled assembler assembly time. Macros provide advantage subroutines terms modular programming, without runtime overhead subroutine call return. tradeoff macro approach uses space object code. NASM many assemblers, distinction made sin - gle-line macro multi-line macro. NASM, single-line macros defined using %DEFINE directive. example multiple single-line macros expanded. First, define two macros: %DEFINE B(X) = 2*X %DEFINE A(X) = 1 + B(X) point assembly language program, following statement appears: MOV AX, A(8) assembler expands statement to: MOV AX, 1+2*8 assembles machine instruction move immediate value 17 register AX. Multiline macros defined using mnemonic %MACRO. example multiline macro definition: %MACRO PROLOGUE 1 PUSH EBP ;push contents EBP onto stack ;pointed ESP ;decrement contents ESP 4 MOV EBP, ESP ;copy contents ESP EBP SUB ESP, %1 ;subtract first parameter value ESP number 1 macro name %MACRO line defines number parameters macro expects receive. use %1 inside macro definition refers first parameter macro call. macro call MYFUNC: PROLOGUE 12 expands following lines code: MYFUNC: PUSH EBP MOV EBP, ESP SUB ESP, 12 Example: Greatest Common Divisor Program example use assembly language, look program compute greatest common divisor two integers. define greatest common divisor integers b follows:B.2 / Assem BleRs 783 gcd(a, b)=max[k, k divides k divides b] say k divides remainder. Euclid’s algorithm greatest common divisor based following theorem. nonnegative integers b, gcd(a, b)=gcd(b, mod b) C language program implements Euclid’s algorithm: unsigned int gcd (unsigned int a, unsigned int b) { (a == 0 && b == 0) b = 1; else (b == 0) b = a; else (a != 0) (a != b) (a < b) b -= a; else -= b; return b; } Figure B.3 shows two assembly language versions preceding program. program left done C compiler; program right programmed hand. latter program uses number programmer’s tricks produce tighter, efficient implementation. B.2 Assem Blers assembler software utility takes assembly program input pro - duces object code output. object code binary file. assembler views file block memory starting relative location 0. two general approaches assemblers: two-pass assembler one-pass assembler. Two-Pass Assembler look first two-pass assembler, common somewhat easier understand. assembler makes two passes source code (Figure B.4): first pass first pass, assembler concerned label definitions. first pass used construct symbol table contains list labels associated location counter (LC) values. first byte object code LC value 0. first pass examines assembly statement. Although assembler yet ready translate instructions, must examine 784 Appendix B / Assem Bly lAnguAge Rel Ated topics instruction sufficiently determine length corresponding machine instruction therefore much increment LC. may require examining opcode also looking operands addressing modes. Directives DQ REST (see Table B.2) cause location counter adjusted according much storage specified. assembler encounters statement label, places label symbol table, along current LC value. assembler continues read assembly language statements. second pass second pass reads program beginning. instruction translated appropriate binary machine code. Translation includes following operations: 1. Translate mnemonic binary opcode. 2. Use opcode determine format instruction location length various fields instruction. 3. Translate operand name appropriate register memory code. 4. Translate immediate value binary string. 5. Translate references labels appropriate LC value using symbol table. 6. Set bits instruction needed, including addressing mode indicators, condition code bits, on. Figure B.3 Assembly Programs Greatest Common Divisor (a) Compiled program (b) Written directly assembly languagegcd: mov ebx,eax gcd: neg eax mov eax,edx je L3 test ebx,ebx L1: neg eax jne L1 xchg eax,edx test edx,edx L2: sub eax,edx jne L1 jg L2 mov eax,1 jne L1 ret L3: add eax,edx L1: test eax,eax jne L4 jne L2 inc eax mov eax,ebx L4: ret ret L2: test ebx,ebx je L5 L3: cmp ebx,eax je L5 jae L4 sub eax,ebx jmp L3 L4: sub ebx,eax jmp L3 L5: ret B.2 / Assem BleRs 785 simple example, using ARM assembly language, shown Figure B.5. ARM assembly language instruction ADDS r3, r3, #19 translated binary machine instruction 1110 0010 0101 0011 0011 0000 0001 0011. zeroth pass assembly language includes ability define macros. macros present additional pass assembler must make first pass. Typically, assembly language requires macro definitions must appear beginning program.Pass 1 Pass 2Read line sour ce /f_ile eof? Label de/f_ined? Determine size instruction LC = LC + size Write sour ce line & fo intermediate /f_ileClose sou rce /f_ile r ewind intermediate /f_ile Store name value symbol table1 YesYes 1Pass 2 Stop eof? Assemble instructionRead next line fr om intermediate /f_ile Write object instruction object /f_ile Write sour ce & object lines listing /f_ileYes 22 Figure B.4 Flowchart Two-Pass Assembler786 Appendix B / Assem Bly lAnguAge Rel Ated topics assembler begins “zeroth pass” reading macro definitions. macros recognized, assembler goes source code expands macros associated parameters whenever macro call encountered. macro processing pass generates new version source code macro expansions place macro definitions removed. One-Pass Assembler possible implement assembler makes single pass source code (not counting macro processing pass). main difficulty trying assemble program one pass involves forward references labels. Instruction operands may symbols yet defined source program. Therefore, assembler know relative address insert trans - lated instruction. essence, process resolving forward references works follows. assembler encounters instruction operand symbol yet defined, assembler following: 1. leaves instruction operand field empty (all zeros) assembled bin - ary instruction. 2. symbol used operand entered symbol table. table entry flagged indicate symbol undefined. 3. address operand field instruction refers undefined symbol added list forward references associated symbol table entry. symbol definition encountered LC value asso - ciated it, assembler inserts LC value appropriate entry symbol table. forward reference list associated symbol, assembler inserts proper address instruction previously generated forward reference list. Example: Prime Number Program look example includes directives. example looks program finds prime numbers. Recall prime numbers evenly divisible 1 themselves. formula this. basic method program uses find factors odd numbers given limit. factor 01 10 0 00 1 00 01 01 1 01 1110 0000 01 00 011 ADDS r3, r3, #19 Data pr ocessing immediate f ormat 0123456789101112 1413 15 1716 18 2019 2221 2423 2625 2827 3029 31Always condition codeUpdate condition /f_lagsZero rotation instr formatSR n Rd rotate immediate cond opcode Figure B.5 Translating ARM Assembly Instruction Binary Machine InstructionB.3 / loAding linking 787 found odd number, prime. Figure B.6 shows basic algorithm written C. Figure B.7 shows algorithm written NASM assembly language. B.3 loAding linking first step creation active process load program main memory create process image (Figure B.8). Figure B.9 depicts scenario typi - cal systems. application consists number compiled assembled modules object-code form. linked resolve references modules. time, references library routines resolved. library routines may incorporated program referenced shared code must supplied operating system run time. section, summarize key features linkers loaders. First, discuss concept relocation. Then, clarity presentation, describe loading task single program module involved; linking required. look linking loading functions whole. Relocation multiprogramming system, available main memory generally shared among number processes. Typically, possible programmer know advance programs resident main memory time exe - cution program. addition, would like able swap active processes main memory maximize processor utilization providing large pool ready processes execute. program swapped disk, would quite limiting declare next swapped back in, must placed main memory region before. Instead, may need relocate process different area memory.unsigned guess; /* current guess prime */ unsigned factor; /* possible factor guess */ unsigned limit; /* find primes value */ printf (“Find primes : ”); scanf(“%u”, &limit); printf (“2\n”); /* treat first two primes */ printf (“3\n”); /* special case */ guess = 5; /* initial guess */ (guess < = limit) { /* look factor guess */ factor = 3; (factor * factor < guess && guess% factor != 0) factor + = 2; (guess % factor != 0) printf (“%d\n”, guess); guess += 2; /* look odd numbers */ } Figure B.6 C Program Testing Primality788 Appendix B / Assem Bly lAnguAge Rel Ated topics %include “asm_io.inc” segment .data Message db “Find primes to: ”, 0 segment .bss Limit resd 1 ; find primes limit Guess resd 1 ; current guess prime segment .text global _asm_main _asm_main: enter 0,0 ; setup routine pusha mov eax, Message call print_string call read_int ; scanf(“%u”, & limit); mov [Limit], eax mov eax, 2 ; printf(“2\n”); call print_int call print_nl mov eax, 3 ; printf(“3\n”); call print_int call print_nl mov dword [Guess], 5 ; Guess = 5; while_limit: ; (Guess <= Limit) mov eax, [Guess] cmp eax, [Limit] jnbe end_while_limit ; use jnbe since numbers unsigned mov ebx, 3 ; ebx factor = 3; while_factor: mov eax,ebx mul eax ; edx:eax = eax*eax jo end_while_factor ; answer won’t fit eax alone cmp eax, [Guess] jnb end_while_factor ; !(factor*factor < guess) mov eax,[Guess] mov edx,0 div ebx ; edx = edx:eax% ebx cmp edx, 0 je end_while_factor ; !(guess% factor != 0) add ebx,2; factor += 2; jmp while_factor end_while_factor: je end_if ; !(guess% factor != 0) mov eax,[Guess] ; printf(“%u\n”) call print_int call print_nl end_if: add dword [Guess], 2 ; guess += 2 jmp while_limit end_while_limit: popa mov eax, 0 ; return back C leave ret Figure B.7 Assembly Program Testing PrimalityB.3 / loAding linking 789 Thus, cannot know ahead time program placed, must allow program may moved main memory due swap - ping. facts raise technical concerns related addressing, illustrated Figure B.10. figure depicts process image. simplicity, let us assume process image occupies contiguous region main memory. Clearly, Process contr ol block Program Data Stack Process image main memoryProgram Data Object code Figure B.8 Loading Function Main memoryLoader Run-time linker/ loaderx Load moduleLinker Module 2Module 1 Module nStatic libraryDynamic library Dynamic library Figure B.9 Linking Loading Scenario790 Appendix B / Assem Bly lAnguAge Rel Ated topics operating system need know location process control information execution stack, well entry point begin execution program process. operating system managing memory respon - sible bringing process main memory, addresses easy come by. addition, however, processor must deal memory references within program. Branch instructions contain address reference instruction executed next. Data reference instructions contain address byte word data referenced. Somehow, processor hardware operating system software must able translate memory references found code program actual physical memory addresses, reflecting current location program main memory. Loading Figure B.9, loader places load module main memory starting location x. loading program, addressing requirement illustrated Figure B.10 must satisfied. general, three approaches taken: ■Absolute loading ■Relocatable loading ■Dynamic run-time loading absolute loading absolute loader requires given load module always loaded location main memory. Thus, load module presented loader, address references must specific, absolute, main Process contr ol block Program Data StackCurr ent top stackEntry point pr ogramProcess contr ol information Increasing addr ess valuesBranch instructio n Refer ence data Figure B.10 Addressing Requirements ProcessB.3 / loAding linking 791 memory addresses. example, x Figure B.9 location 1024, first word load module destined region memory address 1024. assignment specific address values memory references within program done either programmer compile assembly time (Table B.3a). several disadvantages former approach. First, every programmer would know intended assignment strategy placing modules main memory. Second, modifications made program involve inser - tions deletions body module, addresses altered. Accordingly, preferable allow memory references within programs expressed symbolically resolve symbolic references time compilation assembly. illustrated Figure B.11. Every reference instruction item data initially represented symbol. preparing module input absolute loader, assembler compiler convert references specific addresses (in example, module loaded starting location 1024), shown Figure B.11b. Table B.3 Address Binding (a) Loader Binding Time Function Programming time actual physical addresses directly specified programmer program itself. Compile assembly time program contains symbolic address references, converted actual physical addresses compiler assembler. Load time compiler assembler produces relative addresses. loader translates absolute addresses time program loading. Run time loaded program retains relative addresses. converted dynami- cally absolute addresses processor hardware. (b) Linker Linkage Time Function Programming time external program data references allowed. programmer must place program source code subprograms referenced. Compile assembly time assembler must fetch source code every subroutine refer- enced assemble unit. Load module creation object modules assembled using relative addresses. mod- ules linked together references restated relative origin final load module. Load time External references resolved load module loaded main memory. time, referenced dynamic link modules appended load module, entire package loaded main virtual memory. Run time External references resolved external call executed processor. time, process interrupted desired module linked calling program.792 Appendix B / Assem Bly lAnguAge Rel Ated topics relocatable loading disadvantage binding memory references specific addresses prior loading resulting load module placed one region main memory. However, many programs share main memory, may desirable decide ahead time region memory particular module loaded. better make decision load time. Thus need load module located anywhere main memory. satisfy new requirement, assembler compiler produces actual main memory addresses (absolute addresses) addresses relative known point, start program. technique illustrated Figure B.11c. start load module assigned relative address 0, memory references within module expressed relative begin - ning module. memory references expressed relative format, becomes simple task loader place module desired location. module loaded beginning location x, loader must simply add x memory reference loads module memory. assist task, load module must include information tells loader address references interpreted (usually relative program origin, also pos - sibly relative point program, current location). set information prepared compiler assembler usually referred relocation dictionary. dynamic run-time loading Relocatable loaders common provide obvious benefits relative absolute loaders. However, multiprogramming Symbolic addr esses JUMP X X YPROGRAM DATA (a) Object moduleLOAD YAbsolute addr esses JUMP 1424 14241024 0 2224PROGRAM DATA (b) Absolute load moduleLOAD 2224Relative addr esses JUMP 400 400 1200PROGRAM DATA (c) Relat ive load moduleLOAD 1200xMain memory addresses JUMP 400 400 + x 1200 + xPROGRAM DATA (d) Relati load module loaded main memory starting location xLOAD 1200 Figure B.11 Absolute Relocatable Load ModulesB.3 / loAding linking 793 environment, even one depend virtual memory, relocatable loading scheme inadequate. referred need swap process images main memory maximize utilization processor. maximize main memory utilization, would like able swap process image back different locations different times. Thus, program, loaded, may swapped disk swapped back different location. would impossible memory references bound absolute addresses initial load time. alternative defer calculation absolute address actually needed run time. purpose, load module loaded main memory memory references relative form (Figure B.11c). instruction actually executed absolute address calculated. assure function degrade performance, must done special proces- sor hardware rather software. hardware described Chapter 8. Dynamic address calculation provides complete flexibility. program loaded region main memory. Subsequently, execution pro - gram interrupted program swapped main memory, later swapped back different location. Linking function linker take input collection object modules pro - duce load module, consisting integrated set program data modules, passed loader. object module, may address references locations modules. reference expressed symbolically unlinked object module. linker creates single load module contiguous joining object modules. intramodule reference must changed symbolic address reference location within overall load module. example, module Figure B.12a contains procedure invocation module B. modules combined load module, symbolic reference module B changed specific reference location entry point B within load module. linkage editor nature address linkage depend type load module created linkage occurs (Table B.3b). If, usually case, relocatable load module desired, linkage usually done following fashion. compiled assembled object module created references relative beginning object module. modules put together single relocatable load module references relative origin load module. module used input relocatable loading dynamic run-time loading. linker produces relocatable load module often referred link - age editor. Figure B.12 illustrates linkage editor function. dynamic linker loading, possible defer linkage functions. term dynamic linking used refer practice deferring linkage external modules load module created. Thus, load module contains unresolved references programs. references resolved either load time run time.794 Appendix B / Assem Bly lAnguAge Rel Ated topics load-time dynamic linking (involving upper dynamic library Figure B.9), following steps occur. load module (application module) loaded read memory. reference external module (target module) causes loader find target module, load it, alter reference relative address memory beginning application module. several advan - tages approach might called static linking: ■It becomes easier incorporate changed upgraded versions target module, may operating system utility general- purpose routine. static linking, change supporting module would require relinking entire application module. inefficient, may impossible circumstances. example, personal computer field, commercial software released load module form; source object versions released. ■Having target code dynamic link file paves way automatic code sharing. operating system recognize one application using target code loaded linked code. use information load single copy target code link applications, rather load one copy application.0Relative addr esses JSR “ L” Retur n Retur n Retur nL – 1 L L + – 1 L + L + + N– 1Module Module B (b) Load moduleJSR “ L + M” Module CCALL B;Exter nal reference module BLength L Retur nModule (a) Object modulesCALL C; Length MModule B Retur n Length N Retur nModule C Figure B.12 Linking FunctionB.4 / key teRms, Review Questions, pRoBlems 795 ■It becomes easier independent software developers extend function - ality widely used operating system Linux. developer come new function may useful variety applications package dynamic link module. run-time dynamic linking (involving lower dynamic library Figure B.9), linking postponed execution time. External references target modules remain loaded program. call made absent module, operating system locates module, loads it, links calling module. modules typically shareable. Windows environment, called dynamic-link libraries (DLLs) Thus, one process already making use dynam - ically linked shared module, module main memory new process simply link already-loaded module. use DLLs lead problem commonly referred DLL hell . DLL hell occurs two processes sharing DLL module expect dif - ferent versions module. example, application system function might re-installed bring older version DLL file. seen dynamic loading allows entire load module moved around; however, structure module static, unchanged throughout execution process one execution next. However, cases, possible determine prior execution object modules required. situation typified transaction-processing applications, airline reservation system banking application. nature transaction dictates program modules required, loaded appropriate linked main program. advantage use dynamic linker necessary allocate memory program units unless units referenced. capability used support segmentation systems. One additional refinement possible: application need know names modules entry points may called. example, charting program may written work variety plotters, driven different driver package. application learn name plotter currently installed system another process looking configuration file. allows user application install new plotter exist time application written. B.4 key Terms, review Ques Tions, Pro Blems Key Terms Assembler assembly language comment directive dynamic linker instructionlabel linkage editor linking load-time dynamic linking loading macromnemonic one-pass assembler operand relocation run-time dynamic linking two-pass assembler796 Appendix B / Assem Bly lAnguAge Rel Ated topics Review Questions B.1 List reasons worthwhile study assembly language programming. B.2 assembly language? B.3 List disadvantages assembly language compared high-level languages. B.4 List advantages assembly language compared high-level languages. B.5 typical elements assembly language statement? B.6 List briefly define four different kinds assembly language statements. B.7 difference one-pass assembler two-pass assembler? Problems B.1 Core War programming game introduced public early 1980s [DEWD84], popular period 15 years so. Core War four main components: memory array 8000 addresses; simplified assembly language Redcode; executive program called MARS (an acronym Memory Array Red - code Simulator); set contending battle programs. Two battle programs entered memory array randomly chosen positions; neither program knows one is. MARS executes programs simple version time-shar - ing. two programs take turns; single instruction first program executed, single instruction second, on. battle program execution cycles allotted entirely programmer. aim destroy program ruining instructions. problem next several, use even simpler language, called CodeBlue, explore Core War concepts. CodeBlue contains five assembly language statements uses three ad - dressing modes (Table B.4). Addresses wrap around, last location memory, relative address +1 refers first location memory. example, ADD #4 , 6 adds 4 contents relative location 6 stores results loca - tion 6; JUMP @5 transfers execution memory address contained location five slots past location current JUMP instruction. a. program Imp single instruction COPY 0 , 1. do? b. program Dwarf following sequence instructions: ADD #4, 3 COPY 2, @2 JUMP –2 DATA 0 do? c. Rewrite Dwarf using symbols, looks like typical assembly lan - guage program. B.2 happens pit Imp Dwarf? B.3 Write “carpet bombing” program CodeBlue zeros memory (with possible exception program locations). B.4 would previous program fare Imp? B.5 a. value C status flag following sequence: mov al, 3 add al, 4 b. value C status flag following sequence: mov al, 3 sub al, 4B.4 / key teRms, Review Questions, pRoBlems 797 B.6 Consider following NAMS instruction: cmp vleft, vright signed integers, three status flags relevant. vleft=vright, ZF set. vleft7vright, ZF unset (set 0) SF=OF. vleft6vright, ZF unset SF≠OF. SF=OF vleft7vright? B.7 Consider following NASM code fragment: mov al, 0 cmp al, al je next Write equivalent program consisting single instruction. B.8 Consider following C program: /* simple C program average 3 integers */ main () { int avg; int i1 = 20; int i2 = 13; int i3 = 82; avg = (i1 + i2 + i3)/3; } Write NASM version program.(b) Addressing Modes Mode Format Meaning Literal # followed value immediate mode, operand value instruction. Relative Value value represents offset current location, contains operand. Indirect @ followed value value represents offset current location; offset location contains relative address location contains operand. Loop COPY #0, −1 JUMP −1 Hint : Remember instruction execution alternates two opposing programs.Table B.4 CodeBlue Assembly Language (a) Instruction Set Format Meaning DATA <value> <value> set current location COPY A, B copies source destination B ADD A, B adds B, putting result B JUMP transfer execution JUMPZ A, B B=0, transfer A798 Appendix B / Assem Bly lAnguAge Rel Ated topics a. 2-pass assembler handle future symbols instruction therefore use future symbol operand. always true directives. EQU directive, example, cannot use future symbol. directive “ EQU B+1” easy execute B previously defined, impossible B future symbol. What’s reason this? B.9 Consider following C code fragment: (EAX == 0) EBX = 1; else EBX = 2; Write equivalent NASM code fragment. B.10 initialize data directives used initialize multiple locations. example, db 0x55,0x56,0x57 reserves three bytes initializes values. NASM supports special token $ allow calculations involve current - sembly position. is, $ evaluates assembly position beginning line containing expression. preceding two facts mind, consider following sequence directives: message db ‘hello, world’ msglen equ $-message value assigned symbol msglen? B.11 Assume three symbolic variables V1, V2, V3 contain integer values. Write NASM code fragment moves smallest value integer ax. Use instructions mov, cmp, jbe. B.12 Describe effect instruction: cmp eax , 1 Assume immediately pre - ceding instruction updated contents eax. B.13 xchg instruction used exchange contents two registers. Suppose x86 instruction set support instruction. a. Implement xchg ax , bx using push pop instructions. b. Implement xchg ax , bx using xor instruction (do involve registers). B.14 following program, assume a, b, x, symbols main memory loca - tions. program do? answer question writing equiva - lent logic C. mov eax,a mov ebx,b xor eax,x xor ebx,y eax,ebx jnz L2 L1: ;sequence instructions… jmp L3 L2: ;another sequence instructions… L3: B.15 Section B.1 includes C program calculates greatest common divisor two integers. a. Describe algorithm words show program implement Euclid algorithm approach calculating greatest common divisor. b. Add comments assembly program Figure B.3a clarify imple - ments logic C program. c. Repeat part (b) program Figure B.3b. B.16 B.4 / key teRms, Review Questions, pRoBlems 799 b. Suggest way assembler eliminate limitation source line could use future symbols. B.17 Consider symbol directive MAX following form: symbol MAX list expressions label mandatory assigned value largest expression operand field. Example: MSGLEN MAX A, B, C ;where A, B, C defined symbols MAX executed Assembler pass?800 RefeRences Abbrevi Ations ACM Association Computing Machinery IEEE Institute Electrical Electronics Engineers NIST National Institute Standards Technology AGAR89 Agarwal, A. Analysis Cache Performance Operating Systems Multiprogram - ming . Boston: Kluwer Academic Publishers, 1989. AGER87 Agerwala, T., Cocke, J. High Performance Reduced Instruction Set Processors . Technical Report RC12434 (#55845). Yorktown, NY: IBM Thomas J. Watson Research Center, January 1987 . ALLA13 Allan, G. “DDR4 Bank Groups Embedded Applications.” Chip Design , August 26, 2013. chipdesignmag.com ALTS12 Alschuler, F., Gallmeier, J. “Heterogeneous System Architecture: Multicore Image Processing Use Mix CPU GPU Elements.” Embedded Computing Design , December 6, 2012. AMDA67 Amdahl, G. “Validity Single- Processor Approach Achieving Large- Scale Computing Capability.” Proceedings AFIPS Conference , 1967 . AMDA13 Amdahl, G. “Computer Architecture Amdahl’s Law.” Computer , December 2013. ANDE67a Anderson, D., Sparacio, F., Tomasulo, F. “The IBM System/360 Model 91: Machine Philosophy Instruction Handling.” IBM Journal Research Devel - opment , January 1967 . ANDE67b Anderson, S., et al. “The IBM System/360 Model 91: Floating- Point Execution Unit.” IBM Journal Research Development , January 1967 . Reprinted [SWAR90, Volume 1]. ANTH08 Anthes, G. “What’s Next x86?” ComputerWorld , June 16, 2008. AROR12 Arora, M., et al. “Redefining Role CPU Era CPU- GPU Integra - tion.” IEEE Micro , November/December 2012. ATKI96 Atkins, M. “PC Software Performance Tuning.” IEEE Computer , August 1996. AZIM92 Azimi, M., Prasad, B., Bhat, K. “Two Level Cache Architectures.” Proceedings, COMPCON ’92 , February 1992. BACO94 Bacon, F., Graham, S., Sharp, O. “Compiler Transformations High-Performance Computing.” ACM Computing Surveys , December 1994. BAIL93 Bailey, D. “RISC Microprocessors Scientific Computing.” Proceedings , Supercom- puting’93 , 1993. BELL70 Bell, C., Cady, R., McFarland, H., Delagi, B., O’Loughlin, J., Noonan, R. “A New Architecture Minicomputers— DEC PDP- 11.” Proceedings , Spring Joint Computer Conference , 1970. BELL71 Bell, C., Newell, A. Computer Structures: Readings Examples . New York: McGraw- Hill, 1971. BELL78a Bell, C., Mudge, J., McNamara, J. Computer Engineering: DEC View Hard - ware Systems Design. Bedford, MA: Digital Press, 1978. BELL78b Bell, C., Newell, A., Siewiorek, D. “Structural Levels PDP- 8.” [BELL78a]. BELL78c Bell, C., Kotok, A., Hastings, T., Hill, R. “The Evolution DEC System- 10.” Communications ACM , January 1978. BENH92 Benham, J. “A Geometric Approach Presenting Computer Representations Inte - gers.” SIGCSE Bulletin , December 1992.RefeRences 801 BOOT51 Booth, A. “A Signed Binary Multiplication Technique.” Quarterly Journal Mechanics Applied Mathematics. Vol. 4, No. 2, 1951. BORK03 Borkar, S. “Getting Gigascale Chips: Challenges Opportunities Continuing Moore’s Law.” ACM Queue , October 2003. BRAD91a Bradlee, D., Eggers, S., Henry, R. “The Effect RISC Performance Register Set Size Structure versus Code Generation Strategy.” Proceedings , 18th Annual International Symposium Computer Architecture , May 1991. BRAD91b Bradlee, D., Eggers, S., Henry, R. “Integrating Register Allocation Instruction Scheduling RISCs.” Proceedings , Fourth International Conference Architectural Support Programming Languages Operating Systems , April 1991. BREW97 Brewer, E. “Clustering: Multiply Conquer.” Data Communications , July 1997 . BURG97 Burger, D., Austin, T. “The SimpleScalar Tool Set, Version 2.0.” Computer Archi - tecture News , June 1997 . BURK46 Burks, A., Goldstine, H., von Neumann, J. Preliminary Discussion Logical Design Electronic Computer Instrument. Report prepared U.S. Army Ord - nance Department, 1946, reprinted [BELL71]. BUYY99 Buyya, R. High Performance Cluster Computing: Architectures Systems . Upper Saddle River, NJ: Prentice Hall, 1999. CANT01 Cantin, J., Hill, H. “Cache Performance Selected SPEC CPU2000 Bench - marks.” Computer Architecture News , September 2001. CART06 Carter, P . PC Assembly Language . July 23, 2006. http://www.drpaulcarter.com/pcasm/. CEKL97 Cekleov, M., Dubois, M. “ Virtual- Address Caches, Part 1: Problems Solutions Uniprocessors.” IEEE Micro , September/October 1997 . CHAI82 Chaitin, G. “Register Allocation Spilling via Graph Coloring.” Proceedings , SIG- PLAN Symposium Compiler Construction , June 1982. CHOW86 Chow, F., Himmelstein, M., Killian, E., Weber, L. “Engineering RISC Compiler System.” Proceedings , COMPCON Spring ’86 , March 1986. CHOW87 Chow, F., Correll, S., Himmelstein, M., Killian, E., Weber, L. “How Many Address - ing Modes Enough?” Proceedings , Second International Conference Architec - tural Support Programming Languages Operating Systems , October 1987 . CHOW90 Chow, F., Hennessy, J. “The Priority-Based Coloring Approach Register Alloca - tion.” ACM Transactions Programming Languages , October 1990. CITR06 Citron, D., Hurani, A., Gnadrey, A. “The Harmonic Geometric Mean: Really Matter?” Computer Architecture News , September 2006. CLAR85 Clark, D., Emer, J. “Performance VAX- 11/780 Translation Buffer: Simu - lation Measurement.” ACM Transactions Computer Systems , February 1985. COHE81 Cohen, D. “On Holy Wars Plea Peace.” Computer , October 1981. COOK82 Cook, R., Dande, N. “An Experiment Improve Operand Addressing.” Proceed- ings, Symposium Architecture Support Programming Languages Operating Systems , March 1982. COL W85a Colwell, R., Hitchcock, C., Jensen, E., Brinkley-Sprunt, H., Kollar, C. “Computers, Complexity, Controversy.” Computer , September 1985. COL W85b Colwell, R., Hitchcock, C., Jensen, E., Brinkley-Sprunt, H., Kollar, C. “More Con - troversy ‘Computers, Complexity, Controversy.’ ” Computer , December 1985. COON81 Coonen, J. “Underflow Denormalized Numbers.” IEEE Computer , March 1981. COUT86 Coutant, D., Hammond, C., Kelley, J. “Compilers New Generation Hewlett-Packard Computers.” Proceedings , COMPCON Spring ’86 , March 1986. CRAG79 Cragon, H. “An Evaluation Code Space Requirements Performance Various Architectures.” Computer Architecture News , February 1979. CRAW90 Crawford, J. “The i486 CPU: Executing Instructions One Clock Cycle.” IEEE Micro , February 1990.802 RefeRences CURR11 Curran, B., et al. “The zEnterprise 196 System Microprocessor.” IEEE Micro , March/April 2011. DATT93 Dattatreya, G. “A Systematic Approach Teaching Binary Arithmetic First Course.” IEEE Transactions Education , February 1993. DA VI87 Davidson, J., Vaughan, R. “The Effect Instruction Set Complexity Program Size Memory Performance.” Proceedings , Second International Conference Architec - tural Support Programming Languages Operating Systems , October 1987 . DENN68 Denning, P . “The Working Set Model Program Behavior.” Communications ACM , May 1968. DERO87 DeRosa, J., Levy, H. “An Evaluation Branch Architectures.” Proceedings , Fourteenth Annual International Symposium Computer Architecture , 1987 . DEWA90 Dewar, R., Smosna, M. Microprocessors: Programmer’s View. New York: McGraw- Hill, 1990. DEWD84 Dewdney, A. “In Game Called Core War Hostile Programs Engage Battle Bits.” Scientific American , May 1984. DOBO13 Dobos, I., et al. IBM zEnterprise EC12 Technical Guide . IBM Redbook SG24-8049-01, December 2013. DOWD98 Dowd, K., Severance, C. High Performance Computing . Sebastopol, CA: O’Reilly, 1998. EISC07 Eischen, C. “RAID 6 Covers Bases.” Network World , April 9, 2007 . ELA Y85 El- Ayat, K., Agarwal, R. “The Intel 80386—Architecture Implementation.” IEEE Micro , December 1985. FATA08 Fatahalian, K., Houston, M. “A Closer Look GPUs.” Communications ACM , October 2008. FEIT15 Feitelson, D. Workload Modeling Computer Systems Performance Evaluation. Cambridge, UK: Cambridge University Press, 2015. FLEM86 Fleming, P ., Wallace, J. “How Lie Statistics: Correct Way Sum - marize Benchmark Results.” Communications ACM , March 1986. FL YN72 Flynn, M. “Some Computer Organizations Effectiveness.” IEEE Transac - tions Computers , September 1972. FL YN87 Flynn, M., Mitchell, C., Mulder, J. “And Case Complex Instruction Sets.” Computer , September 1987 . FOG08 Fog, A. Optimizing Subroutines Assembly Language: Optimization Guide x86 Platforms. Copenhagen University College Engineering, 2008. http://www.agner .org/optimize/ FRAI83 Frailey, D. “Word Length Computer Architecture: Definitions Applications.” Computer Architecture News , June 1983. GENU04 Genu, P . Cache Primer . Application Note AN2663. Freescale Semiconductor, Inc., 2004. (available Premium Content Document section) GHAI98 Ghai, S., Joyner, J., John, L. Investigating Effectiveness Third Level Cache. Technical Report TR- 980501 -01, Laboratory Computer Architecture, University Texas Austin, 1998. GIBB04 Gibbs, W. “A Split Core.” Scientific American , November 2004. GIFF87 Gifford, D., Spector, A. “Case Study: IBM’s System/360-370 Architecture.” Com- munications ACM , April 1987 . GILA95 Giladi, R., Ahituv, N. “SPEC Performance Evaluation Measure.” Computer , August 1995. GOER12 Goering, R. “New Memory Technologies Challenge NAND Flash DRAM.” Cadence Industry Insight Blogs , August 22, 2012. http://community.cadence.com/ cadence_blogs_8/b/ii/archive/2012/08/22/ keynote- new- memory- technologies-challenge- nand-flash-and-dramRefeRences 803 GOLD54 Goldstine, H., Pomerene, J., Smith, C. Final Progress Report Physical Real - ization Electronic Computing Instrument. Princeton: Institute Advanced Study Electronic Computer Project, 1954. GSOE08 Gsoedl, J. “Solid State: New Frontier Storage.” Storage , July 2008. GUST88 Gustafson, J. “Reevaluating Amdahl’s Law.” Communications ACM , May 1988. HAND98 Handy, J. Cache Memory Book. San Diego: Academic Press, 1998. HARR06 Harris, W. “ Multi- Core Source Engine.” bit- tech.net technical paper , Novem - ber 2, 2006. HA YE98 Hayes, J. Computer Architecture Organization. New York: McGraw- Hill, 1998. HEAT84 Heath, J. “ Re- Evaluation RISC 1.” Computer Architecture News , March 1984. HENN07 Henning, J. “SPEC CPU Suite Growth: Historical Perspective.” Computer Archi - tecture News , March 2007 . HENN12 Hennessy, J., Patterson, D. Computer Architecture: Quantitative Approach . Waltham, MA: Morgan Kaufman, 2012. HENN82 Hennessy, J., et al. “Hardware/Software Tradeoffs Increased Performance.” Pro- ceedings , Symposium Architectural Support Programming Languages Oper - ating Systems , March 1982. HENN84 Hennessy, J. “VLSI Processor Architecture.” IEEE Transactions Computers , December 1984. HILL64 Hill, R. “Stored Logic Programming Applications.” Datamation , February 1964. HILL89 Hill, M. “Evaluating Associativity CPU Caches.” IEEE Transactions Computers , December 1989. HUCK83 Huck, T. Comparative Analysis Computer Architectures . Stanford University Tech - nical Report No. 83-243, May 1983. HUGG05 Huggahalli, R., Iyer, R., Tetrick, S. “Direct Cache Access High Bandwidth Network I/O.” Proceedings, 32nd Annual International Symposium Computer Architecture , 2005. HUGU91 Huguet, M., Lang, T. “Architectural Support Reduced Register Saving/ Restoring Single-Window Register Files.” ACM Transactions Computer Systems , February 1991. HWAN93 Hwang, K. Advanced Computer Architecture . New York: McGraw- Hill, 1993. HWAN99 Hwang, K, et al. “Designing SSI Clusters Hierarchical Checkpointing Single I/O Space.” IEEE Concurrency , January– March 1999. INTE98 Intel Corp. Pentium Pro Pentium II Processors Related Products . Aurora, CO, 1998. INTE04 Intel Research Development. Architecting Era Tera . Intel White Paper, February 2004. INTE08 Intel Corp. Integrated Network Acceleration Features Intel I/O Acceleration Technol - ogy Microsoft Windows Server 2008. Intel White Paper, February 2004. INTE12 Intel Corp. Intel Data Direct I/O Technology (Intel DDIO): Primer . Intel White Paper, February 2012. INTE14 Intel Corp. Computer Architecture Intel Processor Graphics Gen8 . Intel White Paper, September 2014. ITRS14 International Technology Roadmap Semiconductors, 2013 Edition , 2014. http:// www.itrs.net JACO95 Jacob, B., Mudge, T. “Notes Calculating Computer Performance.” University Michigan Tech Report CSE- TR- 231-95 , March 1995. JACO08 Jacob, B., Ng, S., Wang, D. Memory Systems: Cache , DRAM , Disk. Boston: Mor - gan Kaufmann, 2008. JAIN91 Jain, R. Art Computer System Performance Analysis. New York: Wiley, 1991.804 RefeRences JAME90 James, D. “Multiplexed Buses: Endian Wars Continue.” IEEE Micro , September 1983. JEFF12 Jeff, B. Advances big.L ITTLE Technology Power Energy Savings . ARM White Paper, September 2012. JOHN91 Johnson, M. Superscalar Microprocessor Design . Englewood Cliffs, NJ: Prentice Hall, 1991. JOHN04 John, L. “More finding Single Number indicate Overall Performance Benchmark Suite.” Computer Architecture News , March 2004. JOUP88 Jouppi, N. “Superscalar versus Superpipelined Machines.” Computer Architecture News , June 1988. JOUP89a Jouppi, N., Wall, D. “Available Instruction- Level Parallelism Superscalar Superpipelined Machines.” Proceedings , Third International Conference Architec - tural Support Programming Languages Operating Systems , April 1989. JOUP89b Jouppi, N. “The Nonuniform Distribution Instruction- Level Machine Parallel - ism Effect Performance.” IEEE Transactions Computers , December 1989. KAPP00 Kapp, C. “Managing Cluster Computers.” Dr. Dobb’s Journal , July 2000. KATE83 Katevenis, M. Reduced Instruction Set Computer Architectures VLSI . Ph.D. Disser - tation, Computer Science Department, University California Berkeley, October 1983. Reprinted MIT Press, Cambridge, MA, 1985. KATZ89 Katz, R., Gibson, G., Patterson, D. “Disk System Architecture High Perfor - mance Computing.” Proceedings IEEE , December 1989. KNUT71 Knuth, D. “An Empirical Study FORTRAN Programs.” Software Practice Experience , Vol. 1, 1971. KUCK77 Kuck, D., Parker, D., Sameh, A. “An Analysis Rounding Methods Floating- Point Arithmetic.” IEEE Transactions Computers , July 1977 . KULT13 Kulrursay, E., et al. “Evaluating STT- RAM Energy- Efficient Main Memory Alternative.” IEEE International Symposium Performance Analysis Systems Software (ISPASS) , 2013. KUMA07 Kumar, A., Huggahalli, R. “Impact Cache Coherence Protocols Pro - cessing Network Traffic.” 40th IEEE/ACM International Symposium Microar - chitecture , 2007 . LEE91 Lee, R., Kwok, A., Briggs, F. “The Floating Point Performance Superscalar SPARC Processor.” Proceedings , Fourth International Conference Architectural Support Programming Languages Operating Systems , April 1991. LEE10 Lee, B., et al. “ Phase- Change Technology Future Main Memory.” IEEE Micro , January/February 2010. LEAN06 Lean, E., Maccabe, A. “Reducing Memory Bandwidth Chip- Multiprocessors using Cache Injection.” 15th IEEE Symposium High- Performance Interconnects , August 2007 . LEON07 Leonard, T. “Dragged Kicking Screaming: Source Multicore.” Proceedings , Game Developers Conference 2007 , March 2007 . LILJ88 Lilja, D. “Reducing Branch Penalty Pipelined Processors.” Computer , July 1988. LILJ93 Lilja, D. “Cache Coherence Large- Scale Shared- Memory Multiprocessors: Issues Comparisons.” ACM Computing Surveys , September 1993. LILJ00 Lilja, D. Measuring Computer Performance: Practitioner’s Guide. Cambridge, UK: Cambridge University Press, 2000. LITT61 Little, J. “A Proof Queuing Formula: L = λW.” Operations Research , May– June 1961. LITT11 Little, J. “Little’s Law Viewed 50th Anniversary.” Operations Research , May– June 2011.RefeRences 805 LOVE96 Lovett, T., Clapp, R. “Implementation Performance CC- NUMA System.” Proceedings , 23rd Annual International Symposium Computer Architecture , May 1996. LUND77 Lunde, A. “Empirical Evaluation Features Instruction Set Processor Architectures.” Communications ACM , March 1977 . MACD84 MacDougall, M. “ Instruction- level Program Process Modeling.” IEEE Computer , July 1984. MANJ01a Manjikian, N. “More Enhancements SimpleScalar Tool Set.” Computer Archi - tecture News , September 2001. MANJ01b Manjikian, N. “Multiprocessor Enhancements SimpleScalar Tool Set.” Com- puter Architecture News , March 2001. MASH04 Mashey, J. “War Benchmark Means: Time Truce.” Computer Architecture News , September 2004. MASH95 Mashey, J. “CISC vs. RISC (or RISC really).” USENET comp.arch newsgroup , article 46782 , February 1995. MAK97 Mak, P ., et al. “Shared-Cache Clusters System Fully Shared Memory.” IBM Journal Research Development , July/September 1997 . YB84 Mayberry, W., Efland, G. “Cache Boosts Multiprocessor Performance.” Computer Design , November 1984. MCDO05 McDougall, R. “Extreme Software Scaling.” ACM Queue , September 2005. MCDO06 McDougall, R., Laudon, J. “ Multi- Core Microprocessors Here.” ; login , October 2006. MCMA93 McMahon, F., “L.L.N.L Fortran Kernels Test.” Source , October 1993. www.netlib.org/ benchmark/livermore MOOR65 Moore, G. “Cramming Components Onto Integrated Circuits.” Electronics Mag - azine , April 19, 1965. Reprinted Proceedings IEEE , January 1998. MORR74 Morris, M. “Kiviat Graphs— Conventions Figures Merit.” ACM SIGMETRICS Performance Evaluation Review , October 1974. MORS78 Morse, S., Pohlman, W., Ravenel, B. “The Intel 8086 Microprocessor: 16-bit Evolution 8080.” Computer , June 1978. MYER78 Myers, G. “The Evaluation Expressions Storage-to-Storage Architecture.” Com- puter Architecture News , June 1978. NASM12 NASM Development Team. NASM— Netwide Assembler . http://nasm.us/, 2012. NOVI93 Novitsky, J., Azimi, M., Ghaznavi, R. “Optimizing Systems Performance Based Pentium Processors.” Proceedings, COMPCON ’92 , February 1993. NVID09 NVIDIA, “NVIDIA’s Next Generation CUDA Compute Architecture: Fermi.” NVIDIA White Paper , August 2009. NVID14 NVIDIA, “CUDA C Programming Guide.” NVIDIA Documentation , 2014. OWEN08 Owens, J., et al. “GPU Computing.” Proceedings IEEE , May 2008. PADE81 Padegs, A. “System/360 Beyond.” IBM Journal Research Development , September 1981. PARH10 Parhami, B. Computer Arithmetic: Algorithms Hardware Design . Oxford: Oxford University Press, 2010. PATT82a Patterson, D., Sequin, C. “A VLSI RISC.” Computer , September 1982. PATT82b Patterson, D., Piepho, R. “Assessing RISCs High- Level Language Support.” IEEE Micro , November 1982. PATT84 Patterson, D. “RISC Watch.” Computer Architecture News , March 1984. PATT85a Patterson, D. “Reduced Instruction Set Computers.” Communications ACM. January 1985. PATT85b Patterson, D., Hennessy, J. “Response ‘Computers, Complexity, Contro - versy.’” Computer , November 1985.806 RefeRences PATT88 Patterson, D., Gibson, G., Katz, R. “A Case Redundant Arrays Inexpensive Disks (RAID).” Proceedings , ACM SIGMOD Conference Management Data , June 1988. PEDD14 Peddle, J. “Inside Intel’s Gen 8 GPU.” EE Times , September 22, 2014. PEIR99 Peir, J., Hsu, W., Smith, A. “Functional Implementation Techniques CPU Cache Memories.” IEEE Transactions Computers , February 1999. PELE97 Peleg, A., Wilkie, S., Weiser, U. “Intel MMX Multimedia PCs.” Communica- tions ACM , January 1997 . PFIS98 Pfister, G. Search Clusters. Upper Saddle River, NJ: Prentice Hall, 1998. PHAN07 Phanslkar, A., Joshi, A., John, L. “Analysis Redundancy Application Bal - ance SPEC CPU2006 Benchmark Suite.” ACM International Symposium Computer Architecture, ISCA’07 , 2007 . POLL99 Pollack, F. “New Microarchitecture Challenges Coming Generations CMOS Process Technologies” (keynote address). Proceedings 32nd Annual ACM/IEEE International Symposium Microarchitecture , 1999. PRES01 Pressel, D. “Fundamental Limitations Use Prefetching Stream Buffers Scientific Applications.” Proceedings , ACM Symposium Applied Computing , March 2001. PROP11 Prophet, G. “Use GPUs Boost Acceleration.” IDN , December 2, 2011. PRZY88 Przybylski, S., Horowitz, M., Hennessy, J. “Performance Trade- offs Cache Design.” Proceedings , 15th Annual International Symposium Computer Architec - ture, June 1988. PRZY90 Przybylski, S. “The Performance Impact Block Size Fetch Strategies.” Proceed- ings, 17th Annual International Symposium Computer Architecture , May 1990. RADI83 Radin, G. “The 801 Minicomputer.” IBM Journal Research Development , May 1983. RAGA83 Ragan-Kelley, R., Clark, R. “Applying RISC Theory Large Computer.” Com- puter Design , November 1983. RAOU09 Raouk, S., et al. “ Phase- Change Random Access Memory: Scalable Technology.” IBM Journal Research Development , July/September 2008. RECH98 Reches, S., Weiss, S. “Implementation Analysis Path History Dynamic Branch Prediction Schemes.” IEEE Transactions Computers , August 1998. REDD76 Reddi, S., Feustel, E. “A Conceptual Framework Computer Architecture.” Computing Surveys , June 1976. REIM06 Reimer, J. “Valve Goes Multicore.” ars technica , November 5, 2006. arstechnica.com/ articles/paedia/cpu/ valve- multicore.ars ROBI07 Robin, P . “Experiment Linux ARM Thumb- 2 ISA.” Embedded Linux Con - ference , 2007 . RODR01 Rodriguez, M., Perez, J., Pulido, J. “An Educational Tool Testing Caches Symmetric Multiprocessors.” Microprocessors Microsystems , June 2001. SAND10 Sanders, J., Kandrot, E. CUDA Example: Introduction General- Purpose GPU Programming. Reading, MA: Addison- Wesley Professional, 2010. SATY81 Satyanarayanan, M., Bhandarkar, D. “Design Trade- Offs VAX- 11 Translation Buffer Organization.” Computer , December 1981. SEBE76 Sebern, M. “A Minicomputer- compatible Microcomputer System: DEC LSI- 11.” Proceedings IEEE , June 1976. SERL86 Serlin, O. “MIPS, Dhrystones, Tales.” Datamation , June 1, 1986. SHAN38 Shannon, C. “Symbolic Analysis Relay Switching Circuits.” AIEE Transactions , Vol. 57 , 1938. SHAR03 Sharma, A. Advanced Semiconductor Memories: Architectures , Designs , Applica - tions. New York: IEEE Press, 2003.RefeRences 807 SHUM13 Shum, C., Susaba, F., Jacobi, C. “IBM zEC12: Third- Generation High- Frequency Mainframe Microprocessor.” IEEE Micro , March/April 2013. SIEW82 Siewiorek, D., Bell, C., Newell, A. Computer Structures: Principles Exam - ples. New York: McGraw- Hill, 1982. SIMO96 Simon, H. Sciences Artificial. Cambridge, MA: MIT Press, 1996. SLA V12 Slavici, V ., et al. “Adapting Irregular Computations Large CPU- GPU Clusters MADNESS Framework.” IEEE International Conference Cluster Computing , 2012. SMIT82 Smith, A. “Cache Memories.” ACM Computing Surveys , September 1982. SMIT87 Smith, A. “Line (Block) Size Choice CPU Cache Memories.” IEEE Transactions Communications , September 1987 . SMIT88 Smith, J. “Characterizing Computer Performance Single Number.” Communi- cations ACM , October 1988. SMIT89 Smith, M., Johnson, M., Horowitz, M. “Limits Multiple Instruction Issue.” Proceedings , Third International Conference Architectural Support Program - ming Languages Operating Systems , April 1989. SMIT95 Smith, J., Sohi, G. “The Microarchitecture Superscalar Processors.” Proceed- ings IEEE , December 1995. SOHI90 Sohi, G. “Instruction Issue Logic High-Performance Interruptable, Multiple Func - tional Unit, Pipelined Computers.” IEEE Transactions Computers , March 1990. STAL14a Stallings, W. “Gigabit Wi- Fi.” Internet Protocol Journal , September 2014. STAL14b Stallings, W. “Gigabit Ethernet.” Internet Protocol Journal , December 2014. STAL15 Stallings, W. Operating Systems , Internals Design Principles , Eighth Edition. Upper Saddle River, NJ: Pearson, 2015. STEN90 Stenstrom, P . “A Survey Cache Coherence Schemes Multiprocessors.” Computer , June 1990. STEV64 Stevens, W. “The Structure System/360, Part II: System Implementation.” IBM Sys - tems Journal , Vol. 3, No. 2, 1964. Reprinted [SIEW82]. STEV13 Stevens, A. Introduction AMBS 4 ACE big.Little Processing Technology . ARM White Paper, July 29, 2013. STRE78 Strecker, W. “ VAX- 11/780: Virtual Address Extension DEC PDP- 11 Family.” Proceedings , National Computer Conference , 1978. STRE83 Strecker, W. “Transient Behavior Cache Memories.” ACM Transactions Com - puter Systems , November 1983. STRI79 Stritter, E., Gunter, T. “A Microprocessor Architecture Changing World: Motorola 68000.” Computer , February 1979. TAMI83 Tamir, Y., Sequin, C. “Strategies Managing Register File RISC.” IEEE Transactions Computers , November 1983. TANE78 Tanenbaum, A. “Implications Structured Programming Machine Architecture.” Communications ACM , March 1978. TI12 Texas Instruments. 66AK2H12/06 Multicore DSP+ARM KeyStone II System- on- Chip (SoC). Data Manual SPRS866, November 2012. TJAD70 Tjaden, G., Flynn, M. “Detection Parallel Execution Independent Instruc - tions.” IEEE Transactions Computers, October 1970. TOON81 Toong, H., Gupta, A. “An Architectural Comparison Contemporary 16-Bit Microprocessors.” IEEE Micro , May 1981. TUCK67 Tucker, S. “Microprogram Control System/360.” IBM Systems Journal , No. 4, 1967 . UNGE02 Ungerer, T., Rubic, B., Silc, J. “Multithreaded Processors.” Computer Journal , No. 3, 2002. UNGE03 Ungerer, T., Rubic, B., Silc, J. “A Survey Processors Explicit Multithread - ing.” ACM Computing Surveys , March 2003.808 RefeRences VANC14 Vance, A. “99% World’s Mobile Devices Contain ARM Chip.” Business Week , February 10, 2014. VONN45 Von Neumann, J. First Draft Report EDVAC. Moore School, University Pennsylvania, 1945. Reprinted IEEE Annals History Computing , No. 4, 1993. VRAN80 Vranesic, Z., Thurber, K. “Teaching Computer Structures.” Computer , June 1980. WALL85 Wallich, P . “Toward Simpler, Faster Computers.” IEEE Spectrum , August 1985. WANG99 Wang, G., Tafti, D. “Performance Enhancement Microprocessors Hierar - chical Memory Systems Solving Large Sparse Linear Systems.” International Jour - nal Supercomputing Applications , Vol. 13, 1999. WEIC90 Weicker, R. “An Overview Common Benchmarks.” Computer , December 1990. WEIN75 Weinberg, G. Introduction General Systems Thinking. New York: Wiley, 1975. WEIS84 Weiss, S., Smith, J. “Instruction Issue Logic Pipelined Supercomputers.” IEEE Transactions Computers, November 1984. WHIT97 Whitney, S., et al. “The SGI Origin Software Environment Application Perfor - mance.” Proceedings , COMPCON Spring ’97, February 1997 . WILK51 Wilkes, M. “The Best Way Design Automatic Calculating Machine.” Proceedings, Manchester University Computer Inaugural Conference , July 1951. WILK53 Wilkes, M., Stringer, J. “Microprogramming Design Control Cir - cuits Electronic Digital Computer.” Proceedings Cambridge Philosophical Society , April 1953. Reprinted [SIEW82]. WILL90 Williams, F., Steven, G. “Address Data Register Separation M68000 Family.” Computer Architecture News , June 1990. YEH91 Yeh, T., Patt, N. “ Two- Level Adapting Training Branch Prediction.” Proceedings , 24th Annual International Symposium Microarchitecture , 1991. ZHOU09 Zhou, P ., et al. “A Durable Energy Efficient Main Memory Using Phase Change Memory Technology.” ACM International Symposium Computer Architecture, ISCA’09 , 2009.809Index Absolute address, 483 Absolute scalability, 633 Access control, 313–314 Access time (latency), 123 Accumulator (AC), 14, 85, 418 ACE (Advanced Extensible Interface Coherence Extensions), 674–675 Acorn RISC Machine (ARM), 34. See also ARM architecture Active secondary clustering method, 635 Adders, 392–396 4-bit, 394 implementation an, 395 multiple- bit, 394–395 single- bit, 394 Addition, 337–340 binary, 392 overflow rule, 337–338 twos complement, 338–339 Addressable units, 122 Address bus, 101 Address generation sequencing, 743–744 Addressing modes, 457–463 ARM, 466–469, 526–527 autoindexing, 462 base- register, 462 basic, 459 direct, 459 displacement, 461–463 effective address (EA), 458 immediate, 459 indexing, 462–463 indirect, 459–460 Intel x86, 463–466 MIPS R4000, 560–561 mode field, 458 PC- relative, 461 postindexing, 462–463 preindexing, 463 register, 460–461 register indirect, 461 relative, 461 SPARC, 568 stack, 463 Address lines, 101 Address modify instructions, 17 Address registers, 492 Address space, 304–305 Advanced RISC Machines. See ARM architectureAlignment check (AC), 519 Alignment Mask (AM), 521 Allocation, Pentium 4 processor, 517 Amdahl, Gene, 53 Amdahl’s law, 53–55, 660 American Standard Code Information Interchange (ASCII), 232, 421, 422 gate, 389 operation, 430 Antidependency, 509, 586 Application- level parallelism, 662 Application processors, 31–32 Application programming interface (API), 42 Arithmetic logic unit (ALU), 490, 494, 542 addition, 337–340 ARM Cortex- A8, 600–601 division, 347–350 flag values, 329–330 floating- point notation, 350–358 IAS computer, 11, 13, 16 IBM system/360, 22 IBM 3033 microinstruction execution, 755 inputs outputs, 330 integers, 330–350 multicore computer, 8 multiplication, 340–347 operands for, 329 single- processor computer, 6 SPARC architecture, 567 subtraction, 337–340 Texas Instruments 8800 Software Development Board (SDB), 762–765 Arithmetic instructions, 416, 421, 429 Arithmetic mean, 60, 62 Arithmetic operations, 429, 431 Arithmetic shift, 345, 431 ARM addressing modes, 466–469, 526–527 abort mode, 527 branch instruction, 468 data processing instructions, 468 exception modes, 526, 527 fast interrupt mode, 527 indexing methods, 466–467 interrupt mode, 527 load store, 466–468 load/store multiple addressing, 468–469 offset value, 466–467 postindexing, 468 preindexing, 467 privileged modes, 526 supervisor mode, 527 809810 Index system mode, 527 undefined mode, 527 user mode, 526 ARM architecture, 33–39 ACE cache line states, 675 alignment checking, 424 branch instructions, 444 data- processing instructions, 444 data types, 423–425 Endian support, 425 evolution, 34 extend instructions, 444 instruction set, 34–35 instructions of, 417 load store instructions, 444 multiply instructions, 444 nonaligned access, 423 parallel addition subtraction instructions, 444 products, 35–39 SETEND instruction, 425 status register access instructions, 444 unaligned access, 424 use condition codes in, 444–445 VLSI, 34 ARM Cortex- A8, 596–604 address generation unit (AGU), 599 branch target buffer (BTB), 599 dual- issue restrictions, 602 flow instructions, block diagram, 597 global history buffer (GHB), 599 in- order issue, 597–598 instruction decode unit, 599–600 instruction fetch unit, 598–599 integer execute unit, 600–603 integer pipeline, 598 load/store pipeline, 602 memory system effects instruction timings, 601 SIMD floating- point instructions, 603–604 ARM Cortex- A15 core, 670–673 ACE cache line states, 675 energy consumption, 673 pipelines, 672 ARM Cortex- A15 MPCore, 677–681 active interrupt, 679 block diagram of, 677–678 cache coherency, 680–681 core, 677 CPU interface, 680 debug unit interface, 677 direct data intervention (DDI), 681 duplicated tag RAMs, 681 generic interrupt controller (GIC), 677 generic timer, 677 hardware interrupts, 680inactive interrupt, 679 interprocessor interrupts (IPIs), 679 interrupt handling, 678–680 L1 cache coherency, 681 L2 cache coherency, 681 legacy FIQ line, 680 migratory lines, 681 pending interrupt, 679 private timer and/or watchdog interrupts, 680 program trace, 677 snoop control unit (SCU), 677 , 680–681 ARM Cortex- A7 core, 671–673 ACE cache line states, 675 energy consumption, 673 pipelines, 672 ARM Cortex- M3, 604–607 branch forwarding, 606 branch speculation, 606 bus matrix, 605 data watchpoint trace (DWT), 605 dealing branches, 606–607 debug access port, 605 decode stage, 606 embedded trace macrocell, 605 flash patch breakpoint unit, 604 memory protection unit, 604 nested vectored interrupt controller (NVIC), 604 pipeline, 607 pipeline structure, 605–606 processor core, 604 serial wire viewer, 605 Thumb- 2 instruction, 605–606 wake- interrupt controller (NVIC), 604 ARM instruction format, 479–482 immediate constants, 479 Thumb instruction set, 479–481 Thumb- 2 instruction set, 481–482 ARM memory management, 309–314 access control, 313–314 Domain Access Control Register, 314 formats, 310–313 organization memory, 309–310 parameters, 313 translation lookaside buffer (TLB), 309–310 virtual memory address translation, 310–311 ARM processor, 524–530 attributes, 525 interrupt processing, 529–530 processor organization, 525 registers, 527–529 Array processor, 615 Assemblers, 761, 763 Assembly language, 413, 415, 482–484. See also Instruction formats BASIC statement, 482ARM addressing modes ( continued )Index 811 pseudoinstruction, 483 symbolic program in, 483 Asserting, signal, 377 Associative access, 123 Associative mapping, 138–140 Associative memory, 123 Autoindexing, 462 Auxiliary memory, 127 B Backward compatibility, 29 Balanced transmission, 105 Bank groups, 184 Base, 307 Base address, 297 Base digit, 319 Base- register addressing, 462 Batch system, 280 Bell Labs, 17 Benchmark programs, 68 BFU (binary floating- point unit), 10 Biased representation, 351 Big endian ordering, 452 Big.Little Chip, 671 Binary adder, 339 Binary addition, 392 Binary Coded Decimal (BCD), 384 Binary system, 321 Bit- interleaved parity disk performance (RAID level 3), 210–211 Bit length conversion, 332 Bit ordering, endian, 455 Blade servers, 638–639 Blocked multithreaded scalar, 631 Blocked multithreaded superscalar, 632 Blocked multithreaded VLIW, 632 Blocked multithreading, 630 Block- level distributed parity disk performance (RAID level 5), 212 Block- level parity disk performance (RAID level 4), 211–212 Block multiplexor, 262 Blocks, 122, 690 Booth’s algorithm, 346–347 cache, 160 I/O, 408 logic, 408 m, 129, 134–135 memory, 133, 137 , 140–142, 619 packets protocol, 257 process control, 494 SDRAMs, 182 SPLD, 406 tape, 222 thread, 690–691, 696 Blu- ray DVD, 217 , 221 Boole, George, 373Boolean algebra, 373–375, 392 operation, 374 basic identities of, 375 Boolean operators, 375 exclusive- (XOR) operation, 374 NAND function, 374 operation, 374 operation, 374 Boolean functions, implementation algebraic simplification, 381 canonical form, 381 Karnaugh maps, 381–386 NAND gates, 388 Quine– McCluskey method, 384–387 rules simplification, 382–383 sum products (SOP) form, 379, 380 three combinations, 379 Boolean (logic) instructions, 416 Booth’s algorithm, 344–347 Branches conditional instructions, 509–515 control hazard (branch hazard), 508–509 correlator, 515 Cortex- M3 processor, 606–607 delayed, 515, 557–558 dynamic strategies, 51–512 history approach, 513–515 history table, 513 instruction fetch stage, 513–514 loop buffer for, 510–511 loop- closing, 515 microinstructions, 744 multiple streams for, 509–510 pipelining and, 509–515 prediction, 511–515, 589, 593–594 prefetched branch target, 510 Branch prediction, 47–48 Branch target buffer (BTB), 511, 513, 593 British Broadcasting Corporation (BBC), 34 Buffers, 83 Bus arbitration technique, I/O, 243 Bus interconnection, 100–102 Bus master, 146 Bus watching approach, 146 Bus width, 25–27 Byte, 111 Byte multiplexor, 262 Byte ordering, endian, 452 C Cache, 6 banking, 703 Cortex- R, 35 injection, 259 miss, 130, 146, 152, 258–259, 261, 310, 581, 594, 630, 632, 677 , 681812 Index Cache coherence, 621–624 directory protocols, 623 hardware- based solutions, 623–624 multicore computers, 674–675 snoopy protocols, 623–624 software, 622–623 write- invalidate approach, 624 write policies, 622 write- update protocol, 624 Cache- coherent nonuniform memory access ( CC- NUMA), 640 advantages disadvantages, 643 organization, 641–642 Cache Disable (CD), 521 Cache hit, 130, 148 Cache line, 133 Cache memory, 128–149, 536 addresses, 131–133 high- performance computing (HPC), 131 lines, 129 line size, 129, 147 logical cache, 132 mapping function, 133–144 multilevel cache, 147–149 number caches, 147–149 physical cache, 132–133 read operation, 129–130 replacement algorithms, 145 sizes, 133, 134 split cache, 149 structure of, 128, 129 tag, 129 unified cache, 149 virtual address, 133 virtual cache, 132 write policy, 145–147 Cache miss, 130 Cache set, 140 Call/return instructions, 438–439 Capacitors, 20 Carry lookahead, 395 CD- ROM, 217 CD- RW, 217 Central processing unit (CPU), 83, 689 general- purpose microcomputer, 25 Intel 8085, 721 interconnection, 6 internal structure, 490 involvement I/O channels, 261–262 memory and, 83 multicore computer, 6, 667–671 performance performance per watt, 692 second generation computers, 18 single- processor computer, 4 vs. GPU, 691–692 system bus, 490Chaining, 301 Character data operands, 470 Characteristic table, 397 Chip multiprocessing, 630 Chip multiprocessor (multicore), 628–633, 657 Chips, 7–8, 21 ARM, 34 control store, 752 DDR, 183 DRAM memory, 172–173 EPROM package of, 172–173 four- core, 52 high- speed, 50 integrated circuit, 21, 24 Intel Quad- Core Xeon processor, 8–9 I/O controller, 8 LSI, 751 memory, 8, 9, 25, 47–48, 172–173 microcontroller, 32 microprocessor, 32 multicore, 102, 268, 657 , 663, 665, 668, 682 PU, 683 RAM, 390 semiconductor memory, 170–172 two- core, 52 ultra- large- scale integration (ULSI), 24 Chipset, PCI Express, 108 Clock (bus) cycle, 57 Clocked S– R flip- flop, 397–399 Clock rate, 57 Clock speed, 57 Clock tick, 57 Cloud auditor, 648–649 Cloud broker, 648–649 Cloud carrier, 648–649 Cloud computing, 39–42 actors, 648–649 broad network access, 644 community cloud, 646 computing, 39 deployment models, 646 elements, 643–647 essential characteristics of, 644–645 hybrid cloud, 646 infrastructure service (IaaS), 42 measured service, 644 networking, 40 on- demand self- service, 644–645 platform service (PaaS), 41 private cloud, 646 public cloud, 646 rapid elasticity, 644 reference architecture, 647–649 resource pooling, 645 service models (SaaS, PaaS, IaaS), 645–646, 649Index 813 software service (SaaS), 40–41 storage, 40 Cloud consumers, 649 Cloud provider, 648–649 Clusters, 615, 633–639 active secondary, 635 benefits limitations, 633, 635 blade servers, 638–639 compared SMP , 639 computer architecture, 637–638 configurations, 633–636 load balancing, 636 middleware services functions, 638 operating system design, 636–637 parallelizing computation, 636–637 passive standby, 635 separate server, 635 server, 634 shared- disk, 634 shared disk approach, 636 shared nothing approach, 636 single- system image, 637 Coarse- grained threading, 663 Combinational circuit Boolean equations, 378–388 decoders, 390–392 defined, 378 graphical symbols, 378 multiplexers, 388–390 read- memory (ROM), 392 sequential circuits, 396–405 truth table of, 378 Commercial computers, 11 Committing (retiring) instructions, 590 Communication devices, 231 Community cloud, 646 Compact disk (CD), 217–220 CD recordable ( CD- R), 219–220 CD rewritable ( CD- RW), 220 CD- ROM (compact disk read- memory), 217–219 CD- R optical disk, 220 Compaction, I/O memory, 296 Compiler- based register optimization, 547–549 Complex instruction set computer (CISC), 27 , 540 characteristics, 538 motivations contemporary, 549–551 vs. RISC design, 553–555, 570–571 Complex PLDs (CPLDs), 406, 408 Computer architecture, 2 Computer instruction, 413 Computer chip, 32 Computer organization, 2 Computersarchitecture, 2 components, 81–83 family concept, 536 function, 83–98 fundamental elements of, 11 generations, 17 generation- to- generation compatibility of, 2 history of, 11–27 instruction, fetch execute function, 84–89 instruction set architecture (ISA), 2 interconnection structures, 99–100 organization, 2 structure function, 3–11 Computer system performance Amdahl’s law, 53–55 benchmark principles, 67–68 calculating mean value, 59–67 clock speed, 57 designing for, 46–52 following improvements chip organization architecture, 50–52 general- purpose computing GPUs (GPGPU), 52–53 graphics processing units (GPUs), 52–53 instruction execution rate, 58–59 Little’s law, 55–56 many integrated core (MIC), 52 microprocessor speed, 47–48 multiple processors, 52 performance balance, 48–49 SPEC benchmarks, 68–74 Conditional branch instructions, 433 Conditional jump, 439 Condition codes, 492, 744, 757 advantages disadvantages, 493 ARM architecture, 444–445 EFLAGS register, 518 Intel x86, 438–440 program status word (PSW), 495 RISC- based machines, 560 Constant angular velocity (CA V), 198, 218 Constant linear velocity (CL V), 198, 218 Control, 85 access, 313–314 interrupt, 720 I/O modules, 231, 232–233 lines, 101–102 logical, 13 machine instructions, 415 storage control (SC), 683 timing, 232–233 Control hazard (branch hazard), pipelining, 508–509 Control hazards, pipelining, 509814 Index Controllers cache, 146, 623 disk, 107 disk drive, 231 fanouts, 269 I/O, 108, 121, 235, 236, 262 mass storage, 35 memory peripheral, 657 , 668 microcontrollers, 32, 187 network interface, 107 Control lines, 101 Control registers, 519–521 Control signals, 716–719 Control unit (CU), 4, 6, 490 characterization of, 715 control signals, 716–719 execute cycle, 712–713 fetch cycle, 709–711 functional requirements, 714–715 hardwired implementation, 724–727 IAS computer, 11, 13 indirect cycle, 711–712 inputs outputs, 716–717 instruction cycle, 713–714 internal processor organization and, 719–720 interrupt cycle, 712 micro- operations, 708–714 processor, 714–724 COP (dedicated co- processor), 11 Core i7 EE 4960X microprocessor, 29 Cortex- Cortex- A50, 35 Cortex- series processors, 35–39 analog interfaces, 38 bus matrix, 38 clock management, 38 core, 38 debug access port (DAP), 36 debug logic, 36 embedded trace macrocell (ETM) module, 36 energy management, 38 ICode interface, 38 memory, 38 memory protection unit, 38 nested vector interrupt controller (NVIC), 36 parallel I/O ports, 38 peripheral bus, 39 security, 38 serial interfaces, 38 SRAM & peripheral interface, 38 32-bit bus, 39 timers triggers, 38 Cortex- R, 35 Counters, 402–405 ripple, 402–403 synchronous, 403–404Texas Instruments 8800 Software Development Board (SDB), 759 C programming, 159 CRA C90, 122 CUDA (Compute Unified Device Architecture), 689–691 cores, 690, 696, 697 CUDA core/SM count, 694 programming language, 689, 690 Current program status registers (CPSR), ARM, 527 Cycles per instruction (CPI) program, 58 Cycle stealing, 249 Cycle time, 57–58, 525, 562, 620 instruction, 18, 501, 503, 716 memory, 18, 58, 123 pipeline, 504–506 processor, 58 Cyclic redundancy check (CRC), 106 Daisy chain technique, I/O, 243 Database scaling, 618 Data buffering, I/O modules, 233 Data bus, 101 Data cache, 152 Data channel, 18 Data communication, 4 Data exchanges, 636 Data flow, instruction cycles, 497–499 Data flow analysis, 48 Data formatting, magnetic disks, 196–199 Data hazards, pipelining, 508–509 Data (bus) lines, 101 Data- L2, 11 Data movement, 4 Data processing, 4, 20, 85, 416, 421, 444, 601, 667 ARM, 525 instruction addressing, 468 load/store model of, 525 machine instructions, 415 Data processing instruction addressing, 468 Data registers, 491 Data storage, 4, 20, 40, 42, 124, 167 , 265, 416 machine instructions, 415 Data transfer, 427–428 IAS computer, 16 instructions, 427–428 I/O modules, 231 packetized, 103 Data types ARM architecture, 423–425 IEEE 754 standard, 424 Intel x86 architecture, 422–423 packed SIMD, 422 Debug access port (DAP), 36Index 815 Debug logic, 36 Decimal system, 319–320 Decode instruction unit, Cortex- A8 processor, 599 Decoders, 390–392, 595 demultiplexer, 390, 392 DEC P DP- 8, 23–24 Dedicated processor, 32 Deeply embedded systems, 32–33 Delayed branch, pipelining, 557–558 Delayed load, pipelining, 558–559 Delay slot, 557 Demand paging, 299–300 DeMorgan’s theorem, 375, 377 , 388 Device communication, I/O modules, 233 flip- flop, 399, 401 DFU (decimal floating- point unit), 10 Differential signaling, 105 Digital computer, 20 Digital Equipment Corporation (DEC), PDP series computers, 23 Digital logic Boolean algebra, 373–375 combinational circuits, 378–396 gates, 376–378 programmable logic device (PLD), 405–409 sequential circuits, 396–405 Digital versatile disk (DVD), 217 , 220–221 Direct access, 122–123 Direct- access device, 223 Direct address, 463 Direct addressing, 459, 473 Direct cache access (DCA), 254–261 performance issue benefits, 257–259 strategies, 259 Direct Data I/O, 254 cache write operation, 260 comparison DMA with, 260 packet input, 259–261 packet output, 259–261 strategy, 261 TCP/IP protocol handler, 261 write- back strategy, 260 write- strategy, 260 Direction flag (DF), 519 Directives, 704 Direct mapping technique, 134–138 Direct memory access (DMA), 98 comparison DDIO with, 260 control/command registers Intel 8237 , 253–254 8237 DMA usage system bus, 252 fly- DMA controller, 253 function, 249–251 interrupt breakpoints instruction cycle, 250programmed interrupt- driven I/O, 248–249 SMPs, 619 using shared last- level cache, 255–257 Directory protocols, 623 Dirty (use) bit, 146 Disabled interrupt, 95 Discrete components, 20–21 Disk cache memory, 158 Disk drive, I/O, 232 Dispatcher, 288 Displacement addressing, 461–463 mode, 465 Distributed arbitration, 118 Dividend, 347 Division, 347–350 flowchart unsigned binary, 348 partial remainder, 347–349 twos complement, 349 Divisor, 347 Double data rate, 183 Double- data- rate DRAM (DDR RAM), 183–184 Double- sided disks, 200 Drive, Pentium 4 processor, 517 Dual redundancy disk performance (RAID level 6), 212 DVD, 217 DVD- R, 217 DVD- ROM, 217 DVD- RW, 217 Dynamic access random memory (DRAM) technology, 104 Dynamic RAM (DRAM), 147 , 167–168, 171–172, 187 DDR SDRAM, 183–184 pin configuration, 172 synchronous DRAM (SDRAM), 181–182 E EAS/390 memory system, 432 Edge- triggered flip- flop, 403 EDVAC (Electronic Discrete Variable Computer), 11 Effective address (EA), 458, 460 EFLAGS register, Intel x86 processors, 518–519 Electrically erasable programmable read- memory (EEPROM), 170 Embedded Microprocessor Benchmark Consortium (EEMBC) benchmark, 482 Embedded systems, 29–33 deeply, 32–33 operating system (OS), 31 organization, 29–30 Embedded trace macrocell (ETM) module, 36 Emulation (EM), 520816 Index Enabled interrupt, 95, 712 Encoded microinstruction format, 748–751 Erasable programmable read- memory (EPROM), 170, 172 Error control function, 106 Error- correcting codes, 175 Error correction, 216–217 semiconductor memory, 174–180 Error detection, I/O modules, 234 ESCON (Enterprise Systems Connection), 269 Ethernet, 265–266 Exceptions, interrupts and, 522–523, 529 Excitation table, 403 Execute cycle, 84, 87 , 92 micro- operations ( micro- ops), 712–713 Execution. See also Program execution fetch instruction, 496–497 fetched instruction, 85 IBM 3033 microinstruction, 743, 754–755 instruction execution rate, 58–59 I/O program, 89, 91 loads stores MIPS R4000 microprocessor, 565 LSI- 11 microinstruction, 751–754 microprogramming, 745–755 multithreading, 628 RISC instruction, 537–542 speculative, 48 superscalar, 48, 589–590 Expansion boards, 7 Exponent overflow, 358 Exponent value, 351 Extended Binary Coded Decimal Interchange Code (EBCDIC), 421, 432 Extension Type (ET), 520 External interface standards, 263–266 External memory, 39, 121–122, 127 , 185, 187 magnetic disk, 195–203 magnetic tape, 222–224 optical- disk systems, 217–222 RAID, 204–213 solid state drives (SSDs), 212–216 F Failback, 636 Failover, 636 Failure management, clusters, 636 Family concept, 536 Fanouts, 269 Fetch cycle, 15, 84, 85, 87 , 92, 93, 469, 497–498, 709–711 micro- operations ( micro- ops), 709–711 Fetched code bits, 175 Fetch instruction unit, 489, 496 Cortex- A8 processor, 599 execution of, 85Fetch overlap, pipelining, 501 Field- programmable gate array (FPGA), 406–409 I/O blocks, 408 logic block, 409 structure, 408 Fine- grained threading, 663 FireWire Serial Bus, 264 Firmware, 107 , 215, 731 First generation computers. See IAS computer First- first- (FIFO) algorithm, 145 Fixed- head disk, 199 Fixed- point representation, 335 Fixed- size partitions, 294–295 Flag, register organization, 527–528 Flags. See Condition codes Flash memory, 170, 185–187 NAND, 186–187 operation, 185–186 Flip- flops, 396–400 basic, 400 clocked S– R, 397–399 D, 399, 401 edge- triggered, 403 J– K, 399–400, 402–403 Flit, 104 Floating- point arithmetic, 358–367 , 424, 576, 583, 697 addition, 359–361 division, 361 exponent overflow, 358 exponent underflow, 358 IEEE standard binary, 365–367 minus infinity, 365 multiplication, 361–362 normalization, 361 precision considerations, 362–365 rounding plus, 365 round nearest, 364 round toward zero, 365 significand overflow, 359 significand underflow, 359 subtraction, 359–361 Floating- point notation, 350–358 base, 351 biased representation, 351 binary numbers, 350–352 exponent value, 351 IBM S/390 architecture, 353–354 IEEE standard binary, 354–358 negative overflow, 353 negative underflow, 353 normal number, 351–352 positive overflow, 353 positive underflow, 353Index 817 principles, 350–354 significand, 351–352 sign of, 351 Floating- point operations per second (FLOPs), 692 Floppy disk, 200 Floppy (contact) magnetic disks, 196, 199 Flow control function, 104, 106, 109, 115 Flow dependency, 580 FORTRAN programs, 159, 282, 540 Fractions, 322–324 Frames, I/O memory, 269 Front end, Pentium 4 processor, 593–594 Fully nested interrupt mode, 243 Functional encoding, 750 Functional mean, 60 Functions, 276–280 I/O, 98, 232–234 FXU ( fixed- point unit), 10 G Gaps, magnetic disks, 197 Gates, 20, 376–378 delay, 376 functionally complete sets of, 377 NAND, 377 NOR, 377–378 GeForce 8800 GTX, 693 General- purpose computing using GPU (GPGPU), 52–53, 689 General purpose register, 460–462, 466, 491–492, 517–518, 528 Geometric mean, 60, 64–67 Gigabit Ethernet, 107 Global history buffer (GHB), 599 Gradual underflow, 367 Graphical symbol, 376, 378 Graphics processing units (GPUs), 52–53, 689 architecture overview, 692–701 coprocessor, 704–706 CUDA cores, 696–697 dual warp scheduler, 696–697 Fermi, 694 floating- point operations per second for, 693 floating- point (FP) unit pipeline, 697 GDDR5 (graphic double data rate), 694–695 Gen8 architecture, 701–704 grid block dimensions, 691 hardware components equivalence mapping, 691 integer (INT) unit pipeline, 697 load store units, 697 L1 cache, 697–700 memory hierarchy attributes, 698 memory types, 700–701 multicore computers, 667–669NVIDIA, 693–694 performance performance per watt, 692 processor cores, 690 read- after- write (RAW) data hazard, 701 registers, 697–700 shared memory, 697–700 special function units (SFU), 694, 697 streaming multiprocessor architecture, 695–700 streaming multiprocessors (SMs), 691 vs. CPU, 691–692 Graphics technology interface (GTI), 704 Guard bits, 362 H Hamming, Richard, 176 Hamming code, 176 Hard disk, 199, 201 Hard disk drives (HDDs), 212, 214 parameters, 201 Hard failure, 174 Hardware cache coherence, 623–624 Hardware transparency approach, 146 Hardwired implementation, 724–727 control unit inputs, 725–726 control unit logic, 726–727 Hardwired programs, 82 Harmonic mean, 60, 62–64 Hash functions, 300 Hashing technique, 301 Heterogeneous System Architecture (HSA) Foundation, 669 Hexadecimal, 324–326 Hexadecimal digits, 325 Hexadecimal notation, 324–326 High- definition optical disks (HD DVD), 221–222 High- performance computing (HPC), 131 Hit ratio, 138, 140, 144 Horizontal loss, 632 Host channel adapter (HCA), 269 Human- readable devices, 230 Hybrid cloud, 646 Hybrid threading, 663 IAS computer, 11 arithmetic logic unit (ALU), 11, 14, 16 computation addresses, 17 conditional branch instruction, 17 control unit, 12, 14 data transfer, 16 execute cycle, 16 fetch cycle, 15 flowchart of, 15 input– output (I/O) equipment, 12818 Index instruction cycle, 15 instruction groups, 16–17 logical control, 13 memory of, 11, 14–15 operation code (opcode) instruction, 14, 16 registers, 14–15 storage locations, 14 structure of, 12 unconditional branch instruction, 16 von Neumann’s earlier proposal, 12–14 IA- 64 architecture, 492 IBM 801 system, 558 IBM 7094, 18, 19 configuration, 18 Instruction Backup Register, 18 IBM system/360, 22–23 ALU, 23 CPU, 23 third generation computers, 22–23 IBM 370/168, pipeline streams of, 510 IBM 360/91, pipeline streams of, 510 IBM 3033, pipeline streams of, 510 IBM 3033 microinstruction execution, 743, 754–755 IBM zEnterprise EC12 I/O channel path, 268 channels, 268 channel structure, 266–268 channel subsystems (CSS), 267 hardware system area (HSA), 267 I/O frames– front view, 269 I/O system organization, 268–270 logical partition, 267 subchannel, 268 system assist processor (SAP), 267 Z frame, 268 IBM zEnterprise EC12 mainframe computer, 9 cache structure, 683–684 embedded DRAM (eDRAM), 684 multichip module (MCM), 682 organization, 682–683 processor node structure, 682 processor unit (PU), 683 storage control (SC), 683 I- cache, 11 ICode interface, 38 Identification flag (ID), 519 IDU (instruction decode unit), 10 If- (IT) instruction, 481 IFU (instruction fetch unit), 9 Immediate address, 459 Immediate addressing mode, 459 Immediate constants, ARM, 479–480 Incremental scalability, 633 Indexed address, 492Indexing, 462–463 Index registers, 462–463, 492 Indirect addressing, 459–460 Indirect cycle, 711–712 Indirect instruction cycle, 458 InfiniBand, 263, 265, 269 Infinity, IEEE interpretation, 365 Infinity arithmetic, 365 Information technology (IT), 31 Infrastructure service (IaaS), 42, 646 In- order completion, 583 In- order issue, 583–585 Input– output (I/O) process, 4–5 Institute Electrical Electronics Engineers (IEEE) standards binary floating- point arithmetic, 365–367 double- precision floating- point numbers, 560 802.11 Wi- Fi, 266–267 802.3, 265 802.3 ethernet, 265 floating- point representations, 422 1394 FireWire, 264 rounding, 364 754 Subnormal Numbers, 366–367 754-1985 floating- point arithmetic standard, 697 Instr- L2, 11 Instruction address register, 87–88 Instruction buffer register (IBR), 14 Instruction cache, Pentium 4, 150 Instruction cycle, 84, 85, 87 , 496–499, 713–714 data operation (do), 88 execute cycle, 496, 498 fetch instruction execution activities, 496–497 fetch cycle, 496–498 instruction address calculation (iac), 87–88 instruction fetch (if), 88 instruction operation decoding (iod), 88 interrupts and, 91–96 interrupt stage, 496 operand address calculation (oac), 88 operand fetch (of), 88 operand store (os), 88 Instruction cycle code (ICC), 713 Instruction execution rate, 58–59 Instruction formats. See also Assembly language ADD instruction, 557 addressing bits, 470–471 allocation bits, 470–473 ARM, 479–482 DEC- 10 instructions, 540 granularity addressing, 471 high- level language (HLL), 537 , 539–542, 545 If- (IT) instruction, 481 Intel x86, 477–479IAS computer ( continued )Index 819 JUMP instruction, 557 length, 469–470 memory- transfer length, 469, 470 MIPS R4000 microprocessor, 560–561 multiple instructions per cycle, 632 NOOP instruction, 557 operand address, 470 Patterson programs, 539 PDP- 8, 471–472 PDP- 11, 474 PDP- 10, 472–473 range addresses, 471 reduced instruction set architectures, 551–553 register vs. memory address, 470–471 SETHI instruction, 569 set registers, 471 SPARC (Scalable Processor Architecture), 568–569 S/390 Move Characters (MVC) instruction, 553 32-bit Thumb instructions, 482 variable- length instructions, 473–477 VAX, 474–477 , 479, 537 , 539, 540 Instruction issue, 582–583 Instruction pipelining, 500–516, 536, 576, 596, 628, 672 branch prediction, 511–515 control hazard (branch hazard), 508–509 data hazard, 508–509 dealing conditional branches, 509–515, 516 delayed branch, 515, 557–558 delayed load, 558 Intel x86 architecture, 593 loop buffer, 510–511 loop unrolling, 559 measures pipeline performance, 504–507 MIPS R4000 microprocessor, 561–565 multiple streams, 509–510 optimization of, 557–559 pipeline bubble, 507 prefetched branch target, 510 reduced instruction set computer (RISC), 555–559 regular instructions, 555–556 resource hazard, 507–508 strategy, 500–504 Instruction prefetch (fetch overlap), 501 Instruction register (IR), 14, 85, 493, 497 , 710 Instruction set architecture (ISA), 2, 58, 278, 482, 667 , 671 ARM, 35, 481 Thumb- 2, 35, 481 Instruction sets. See Addressing modes Instruction window, 585 Integers, 321–322addition, 337–340 division, 347–350 fixed- point, 335 negation, 336–337 nonnegative, 330, 424 overflow rule, 337–338 packed byte packed byte, 422 packed doubleword packed doubleword, 423 packed quadword packed qaudword, 423 packed single- precision floating- point packed double- precision floating- point, 423 packed word packed word, 422 radix point, 330 range extension, 333–335 signed, 424, 568 sign magnitude, 331 subtraction, 337–340 twos complement operation of, 331–333, 336, 342–347 unsigned, 330 Integrated circuit (IC), 7 , 20–22 pattern, 21 Integrated memory controller (IMC), 255 Intel cache evolution, 150 Intel Core i7-990X, 676–677 Intel Core microarchitecture, 592 Intel 82C55A programmable peripheral interface, 245–248 Intel 82C59A interrupt controller, 243–244 Interrupt Acknowledge (INTA) of, 243 Interrupt Request (INTR) of, 243 responsibility of, 243 Intel 3420 chipset, 9 Intel 8085, 720–724 Address Latch Enabled (ALE) pulse signals, 723 control unit, 721 CPU block diagram, 721 external signals, 722 incrementer/decrementer address latch, 720 interrupt control, 720 machine cycles, 721 instruction, 723–724 pin configuration, 723 serial I/O control, 720 Intel 80386 interrupt modes of, 243–244 multiple I/O modules of, 243 user- visible register organization for, 496 Intel 80486 pipelining condition codes in, 516 decoding, 515 execute cycle, 515 fetch cycle, 515 write back stage, 516820 Index Intel 8237A DMA controller, 251–253 DMA registers, 254 Intel 8255A programmable peripheral interface architecture operation, 245–247 keyboard/display terminal, 247–248 operating modes configurations, 246–247 pin layout, 245–246 Intel Gen8 architecture, 701–704 execution unit (EU), 701 memory modules, 703 registers, 701 SIMD floating- point units, 701 simultaneous multithreading (SMT) architecture, 701 subslices, 702 Intel HD Graphics 5300 Gen8, 704 Intel microprocessors Core Processor, 704 present times, 27 1970s, 26 1980s, 26 1990s, 26 Intel Quad- Core Xeon processor chips, 8–9 Intel x86 addressing modes, 463–466 based scaled index displacement mode, 466 base mode, 465 base displacement mode, 465–466 base index displacement mode, 466 displacement mode, 465 immediate mode, 464 mode calculation, 464 register operand mode, 464 relative addressing, 466 scaled index displacement mode, 466 segment registers for, 464 Intel x86 architecture, 27–29 allocate stage, 595 branch prediction strategy, 593–594 branch target buffer (BTB), 593–594 cache/memory parameters, 592 control registers, 519–521 Core series microprocessor, 28 data hazards, 508 data types, 422–423 decode unit, 594–595 dispatching, 596 8080 microprocessor, 28 8086 microprocessor, 28 80286 microprocessor, 28 80386 microprocessor, 28 80486 microprocessor, 28 evolution of, 28 front ends, 593–595 hardware registers, 595instruction fetch unit, 594 instruction queue unit, 594–595 instruction set, 28 instruction translation lookaside buffer (ITLB), 594 integer floating- point register files, 596 interrupt processing, 522–524 microarchitecture, 591–596 micro- op queuing, 596 micro- op scheduling, 596 out- of- order execution logic, 595–596 Pentium series microprocessor, 28 pipelining, 593 predecode unit, 594 register organization, 517–522 register renaming, 595–596 reorder buffer (ROB) entry, 595 static prediction algorithm, 594 Intel x86 instruction format, 477–479 address size, 478 displacement field, 478 instruction prefixes, 478 ModR/M byte, 478 opcode field, 478 operand size, 478 segment override, 478 SIB byte, 478 Intel x86 memory management, 304–309 address spaces, 304–305 4-Gbyte linear memory space, 308 logical address in, 305 OS design implementation, 305 parameters, 307 privilege level access attribute, 305 requested privilege level (RPL), 306 segmented paged memory, 305 segmented unpaged memory, 304 segment number, 306 table indicator (TI), 305 unsegmented paged memory, 304 unsegmented unpaged memory, 304 virtual memory in, 305 Intel x86 operation types call/return mechanism, 438–439 memory management, 439 MMX instructions, 440–442 SIMD instructions, 440–444 status flags condition codes, 439–440 Intel x86 processor family exception interrupt vector table, 524 exceptions, 522–523 interrupt- handling routine, 523–524 interrupt processing, 522–524 register organization, 517–522 Intel Xeon processors direct cache access strategies, 259Index 821 E5-2600/4600, 255–257 multicore processors, 255 Interconnection structures, 99–100 bus interconnection, 100–102 point- to- point, 100, 102–107 Interconnection transfers I/O memory, 100 I/O processor, 100 memory processor, 100 processor I/O, 100 processor memory, 100 Interleaved memory, 173–174 Interleaved multithreaded scalar, 630–631 Interleaved multithreading, 629–630 Interleaved multithreading superscalar, 632 Interleaved multithreading VLIW, 632 Intermediate queues, 293 Internal processor bus, 490–491 International Reference Alphabet (IRA), 232, 421 Internet things (IoT), 30–31 Interrecord gaps, 222 Interrupt- driven I/O, 239–248 bus arbitration, 243 daisy- chain configuration, 243 design issues, 241–243 Intel 82C59A interrupt controller, 243–244 interrupt- handler program, 241 interrupt processing, 239–241 multiple interrupt lines, 242 software poll, 242 TESTI/O, 242 vectored interrupt, 243 Interrupt enable flag (IF), 518 Interrupts, 89–98 classes, 89 control lines, 102 cycle, 92, 498, 712 disabled, 95 handler, 91, 93 instruction cycle and, 91–96 multiple, 95–98 nested interrupt processing, 97 point view user program, 92 program flow control without with, 90 sequential interrupt processing, 97 Interrupt service routine (ISR), 95 Intertrack gaps, 197 Inverted page table, 301 I/O address register (I/OAR), 83 I/O buffer (I/OBR) register, 83 I/O channels, 261–263 architecture, 263 block multiplexor, 262 byte multiplexor, 262 characteristics of, 262function, 261–262 IBM zEnterprise EC12 I/O, 268–270 multiplexor channel, 262 selector channel, 262 I/O command, 235 I/O components, 83 I/O controllers, 108, 121, 235, 236, 262 I/O devices disk drive, 232 external, 230–232 human- readable devices, 230 keyboard/monitor arrangement, 231–232 machine- readable devices, 230 I/O driver software, 214 I/O functions, 98 I/O hub (IOH), 103–104 I/ O- memory transfer, 98 I/O modules, 715 address recognition, 233 command decoding, 233 control function, 231, 232–233 control lines, 101–102 data buffering, 233 data transfer, 231 device communication, 231, 233 error detection, 234 field- programmable logic array, 408 functions requirements for, 232–234 interconnection structures, 100 interconnection transfers, 100 interface to, 231 I/O requests RAID schemes, 211 machine instructions, 414 PCIe TLP transaction types, 113 processor communication, 233 QPI connections, 103–104 read- write operation, 145–146 registers and, 494 semiconductor memory, 173 status reporting, 233 structure, 234–235 timing, 203, 232–233 transducer, role of, 231 I/O privilege flag (IOPL), 519 I/O processor, 235 I/O program execution of, 89, 91 time required for, 94 IPC (instructions per cycle), 628 Isolated I/O, 237 ISU (instruction sequence unit), 9 J Java applications, 662 Java Virtual Machine, 662 JEDEC Solid State Technology Association, 183822 Index J– K flip- flop, 399–400, 402–403 Job control language (JCL), 282 Job program, 280–282 Jump instruction, 433 K Karnaugh maps, 381–386 Kernel (nucleus), 279 Khronos Group’s OpenCL, 689 K- way set associative cache organization, 140–142 L Lands, compact disks, 218 Lane, 104 Large- scale integration (LSI), 24 Last- in- first- (LIFO) queue, 463 L1 cache, 128 L3 cache, 128 L2 cache, 128 L2 control, 11 Least- frequently used (LFU) algorithm, 132, 145 Least- recently used (LRU) algorithm, 132, 145, 299 Least significant digit, 319 Linear tape- open (LTO) system, 224 Linear tape- open (LTO) tape drives, 224 Linking, 40, 281, 474 Link layer, 105–107 , 115 Links, InfiniBand, 265 Linux, 18 Little endian ordering, 455 Little’s law, 55–56 Load balancing, clusters, 636 Load/store addressing, ARM, 466–468 Load/store multiple addressing, ARM, 468–469 Locality reference, 125, 128, 158 Local variable, 437 Locked operation, 113 Logical address, 297 Logical cache, 132 Logical data operands, 421–422 Logical operations (opcode), 429 Logical shift, 430 Logic block, 406, 408 Logic (Boolean) instructions, 417 Logic- memory performance balance, 48–50 Long- term data storage function, 4 Long- term scheduling, 287–288 Lookup table, 408 Loop buffer, pipelining, 510–511 Loop unrolling, pipelining, 559 Low- voltage differential signaling (L VDS), 105 LSI- 11 microinstruction execution, 751–754 LSU ( load- store unit), 10M Machine cycles, 721 Machine instructions. See also Instruction cycle; Instruction formats addresses, 417–419 arithmetic instructions, 416 ARM architecture, 417 BASIC instruction, 416 branch instructions, 433–434 conditional branch instruction, 433 conversion instructions, 432 data transfer instructions, 427–428 elements of, 413–414 high- level language, 416 increment- and- skip- if- zero(ISZ) instruction, 434 input/output instructions, 432 instruction register (IR), 415 instruction set design, 419 I/O instructions, 416 logic (Boolean) instructions, 416 memory instructions, 416 MMX instructions, 440–442 multiple- address instructions, 419 next instruction reference, 414 operands, 420–422 operations (opcode), 413 reduced instruction set computer (RISC), 419 result operand reference, 414 SETEND instruction, 425 skip instructions, 434 source result operands, 414 source operand reference, 413 stacks and, 418 symbolic representation, 415 system control instructions, 432 test instructions, 416 transfer- of- control instructions, 433–438 unconditional branch instruction, 434 zero- address instructions, 418 Machine parallelism, 581–582, 588–589 Machine- readable devices, 230 Magnetic- core memory, 24 Magnetic disk access time, 201 contemporary rigid, 196 cylinder, 200 data organization formatting, 196–199 double- sided disks, 200 intertrack gaps, 197 multiple platters, 200 multiple zone recording (MZR), 198 performance parameters, 201–203 physical characteristics, 199–201 read write mechanisms, 195–196Index 823 rotational delay, 201–202 rotational positional sensing (RPS), 202 sectors, 197 seek time, 201, 202 sequential organization, 203 single- sided disks, 200 timing, 203 transfer time, 202 Magnetic RAM (MRAM), 189 Magnetic tapes, 222–224 Magnetic tunneling junction (MTJ), 189 Magnetoresistive (MR) sensor, 196 Mainframe computers, 23, 47 Mantissa, 351 Many integrated core (MIC), 52 Mapping function cache memory, 133–144 associative, 138–140 direct, 134–138 k- way set associative cache organization, 140–142 set- associative, 140–144 Mask, 430 Medium- term scheduling, 288 Memory, 83. See also Cache memory access time (latency), 123 associative access, 123 auxiliary, 127 bank, 173 capacity, 121 characteristics, 121–127 concepts internal, 121–122 control lines, 102 cycle time, 123 direct access, 122–123 hierarchy, 124–127 instructions, 416 interconnection structures, 99–100 interconnection transfers, 100 levels of, 125 locality reference, 125 method accessing units, 122–123 “natural” unit organization of, 122 noncacheable, 146 PCIe TLP transaction types, 113 performance parameters, 123 physical types of, 123 random access, 123 read- memory (ROM), 124 real, 300 secondary, 127 sequential access, 122 transfer rate, 123 two- level, 157–164 Memory address register (MAR), 14, 83, 493–494, 497 , 709–710Memory bank, 173 Memory buffer register (MBR), 14, 83, 493–494, 497 , 499, 709–710, 712–713 Memory cell, 20 Memory controller hub (MCH), 255–256 Memory cycle time, 18, 123 Memory hierarchy, 124–127 Memory instructions, 416 Memory management ARM, 309–314 base addresses, 297 compaction, 296 Intel x86, 304–309 intermediate queue, 293 logical addresses, 297 page frames, 297 page table, 298 paging, 297 , 308–309 partitioning, 294–297 physical addresses, 297 segmentation, 303–306 SMP , 621 swapping, 293–294 time- consuming procedure, 296 translation lookaside buffer (TLB), 301–303 virtual memory, 299–301 Memory management unit (MMU), 35, 132, 310, 458 Cortex- Cortex- A50, 35 Cortex- R, 35 Memory- mapped I/O, 237–238 Memory modules, 83, 84, 99 Memory protection, OS, 289 Memory Protection Unit (MPU), 35 MESI (modified/exclusive/shared/invalid) protocol, 621–627 line states, 625 L1 -L2 cache consistency, 627 read hit, 626 read miss, 626 read- with- intent- to- modify (RWITM), 626 state transition diagram, 625 write hit, 627 write miss, 626–627 Metallization, 20 Microcomputers, 3, 24 Microcontroller chip, 32–33 Microelectronics, 19–23 control unit, 20 data movement, 20 data processing, 20 data storage, 20 development of, 20–22 Microinstruction bus (MIB), 751 Microinstruction spectrum, 747824 Index Micro- operations ( micro- ops), 152, 708–714 execute cycle, 712–713 fetch cycle, 709–711 indirect cycle, 711–712 instruction cycle, 713–714 instruction set, 715 interrupt cycle, 712 rules, 711 sequencing, 715 time units, 711 Microprocessor chips, 32 Microprocessor register organizations, 495–496 Microprocessors, 25–26 Microprogrammed control units, 536, 733–735 Microprogrammed implementation, 6 Microprogramming, 727 , 730 address generation techniques, 743–744 advantages, 737 design considerations, 739–740 disadvantages, 737 encoding, 748–751 execution, 745–755 hard, 748 horizontal, 748 interrupt testing, 744 LSI- 11 microinstruction execution, 751–754 LSI- 11 microinstruction sequencing, 744–745 microinstructions, 730–733 microprogrammed control unit, 733–735 next sequential address, 744 opcode mapping, 744 sequencing techniques, 740–742 soft, 748 subroutine facility, 744 taxonomy, 745–748 vertical, 748 Wilkes control, 735–739 Microprogramming language, 731 Migratory lines, 681 Millions floating- point operations per second (MFLOPS) rate, 59 Millions instructions per second (MIPS) rate, 59 Minuend, 338 MIPS rate, 59 MIPS R4000 microprocessor, 559–565 enhancing pipelining, 563 execution loads stores, 565 instruction set, 560–561 partitioning chip, 560 pipelining instructions, 561–565 Miss, 126, 138 MMX (multimedia task) instructions, 440–442, 444, 521 registers, 521–522 Mnemonics, 415, 761Monitor (simple batch OS), 281 Monitor arrangement, I/O, 231 Monitor Coprocessor (MP), 520 Moore, Gordon, 21 Moore’s law, 21, 47 , 51, 692 consequences of, 21–22 significant digit, 319 Motherboard, 7 Motorola MC68000 microprocessor registers, 495 Movable- head disk, 199 Multicore computers, 6–8 arithmetic logic unit (ALU), 8 cache coherence, 674–675 cache memory, 6 central processing unit (CPU), 6, 667–671 cores, 6, 8 digital signal processors (DSPs), 669–671 equivalent instruction set architectures, 671–674 external memory interface (EMIF), 671 graphics processing units (GPUs), 667–669 hardware performance, 657–660 heterogeneous multicore organization, 667–675 homogenous multicore organization, 667 instruction logic, 8 levels cache, 665–666 load/store logic, 8 memory subsystem memory controller (MSMC), 675 MOESI model, 675 motherboard, 7–8 multicore shared memory (MSM), 671 multicore shared memory controller (MSMC), 671 organization, 665–667 power consumption, 659–660 printed circuit board (PCB), 7 processor, 6, 8 simplified view major elements of, 7 software performance, 660–665 Multicore processors, 6, 8, 657 Multilane distribution, 105 Multilevel cache memory, 147–149 Multiple- bit adders, 394–395 Multiple instruction, multiple data (MIMD) stream, 615 Multiple instruction, single data (MISD) stream, 615 Multiple interrupt lines, I/O, 242 Multiple parallel processing, 628 Multiple platters, magnetic disks, 200 Multiple streams, pipelining, 509–510 Multiplexers, 388–390 digital circuits control signal data routing, 389Index 825 4- to- 1, 388–389 using AND, OR, gates, 389 Multiplexor, 18 Multiplexor channel, 262 Multiple zone recording (MZR), 198, 218 Multiplicand, 340–341 Multiplication arithmetic shift, 345 Booth’s algorithm, 344–347 flowchart unsigned binary, 342 hardware implementation unsigned binary, 341 twos complement, 342–347 unsigned integers, 330 Multiplier quotient (MQ), 14 Multiprocessor OS design, SMP considerations for, 284 Multithreading, 628–633 blocked, 630–632 coarse- grained, 630 fine- grained, 629 implicit explicit, 628–629 interleaved, 629–632 principal approaches, 629–630 process, 628–629 process switch, 629 resource ownership, 628 scheduling/execution, 628 simultaneous (SMT), 630, 632–633, 667 thread, 629 thread switch, 629 N NAND flash memory, 186–187 , 188, 214 NAND gate, 377 , 388 NaNs, IEEE standards, 365–366 N- disk array, 212 Negation, integers, 336–337 Negative overflow, 353 Negative underflow, 353 Nested Task (NT) flag, 519 Nested vector interrupt controller (NVIC), 36 Neumann, John von, 11, 81 Nibble, 324 NIST SP- 800-145, 39 NIST SP 500-292 (NIST Cloud Computing Reference Architecture) , 647–648 Noncacheable memory approach, 146 Nonredundant disk performance (RAID level 0), 205 Nonremovable disk, 199 Nonuniform memory access (NUMA) machines, 614, 615, 640–643 advantages disadvantages, 643 motivation, 640–641 organization, 641–642processor 3 node 2 (P2-3) requests, 642 Nonvolatile memory, 124, 127 Nonvolatile RAM technologies, 188, 190 flash memory, 186–188 gate, 377 Normalized numbers, 67 S– R latch, 398 operation, 429 Write (NW), 521 Number system base digit, 319 binary system, 321 converting binary decimal, 321–324 decimal system, 319–320 fractions, 322–324 hexadecimal notation, 324–326 integers, 321–322 least significant digit, 319 significant digit, 319 nibble, 324 positional number system, 320 radix point, 320 Numeric Error (NE), 521 NVIDIA’s CUDA, 689 Offset addressing, ARM, 467 Omnibus, 24 Operands, 420–422 bit- oriented view, 422 characters, 421 logical data, 421–422 numbers, 420–421 packed decimal, 420–421 Operating system (OS), 494 batch system, 280 functions, 276–280 interactive, 280 interrupt- driven I/O DMA operations, 285–286 interrupts, 283 memory management, 286 memory protection, 283 Multics OS, 287 multiprogramming batch, 283–286 objectives, 276–280 privileged instructions, 283 scheduling, 280, 287–293 setup time, 280 simple batch, 281–283 symmetric multiprocessors (SMPs), 617–621 timer, 283 time- sharing, 286–287 types of, 280–287 uniprogramming, 286826 Index Operational technology (OT), 31 Operations (opcode), 425–438 AND, 430 arithmetic shift operation, 431 ARM architecture, 444–445 basic arithmetic, 429 common instruction set, 426–427 conversion, 432 data transfer, 427–428 IBM EAS/390 data transfer operations, 428 input/output, 432 Intel x86 operation types, 438–444 logical, 429–431 nested procedures, 435, 436 NOT, 429 procedure call instructions, 435–438 process actions various, 427 reentrant procedure, 436 rotate cyclic shift, 430–431 stack frame, 437 system control, 432 transfer- of- control, 433–438 XOR, 430 Optical memory, 195 characteristics, 222 compact disk (CD), 217–220 high- definition optical disks, 221 gate, 376 Original equipment manufacturers (OEMs), 24 Orthogonality, 472–473 Out- of- order execution, 595–596 Out- of- order issue, 585–586 Output dependency, 509, 579, 583 Overflow, 337 P Packed decimal representation, 421 Packets, data, 109 Page fault, 299 Page frame, 297 Page- level cache disable (PCD), 521 Page- level writes transparent (PWT) bit controls, 521 Page replacement, 300 Pages, 297 Page tables, 298, 300–301 Paging, 297–298, 303–304, 521 demand, 299–300 virtual memory, 158 x86, 308–309, 463 Parallelism, 576 application- level, 662 fundamental limitations to, 579–581 instruction- level, 579, 581–582 machine- level, 581–582, 588–589 multicore computers, 657–659procedural dependency and, 581 process- level, 662 resource conflict and, 581 thread- level, 662 true data dependency and, 579–581 Parallelized application, 637 Parallelizing compiler, 637 Parallel organizations, 615–617 Parallel processing cache coherence, 621–624 chip multiprocessing, 630 cloud computing, 643–649 clusters, 633–639 MESI (modified/exclusive/shared/invalid) protocol, 624–627 multiple instruction, multiple data (MIMD) stream, 615, 617 multiple instruction, single data (MISD) stream, 615 multiple processor organizations, 615–617 multithreading, 628–633 nonuniform memory access (NUMA), 640–643 single instruction, multiple data (SIMD) stream, 615, 617 single instruction, single data (SISD) stream, 615 symmetric multiprocessors (SMP), 617–621 write policies, 622 Parallel recording, 222 Parallel register, 401 Parameters, magnetic disks, 201–203 Parametric computing, 637 Parity bits, 176 Partial product, 341 Partial remainder, 347–349 Partitioning, I/O memory management, 294–297 Pascal, 159 Passive standby clustering method, 635 Patterson programs, 539 PCI Express (PCIe), 104, 107–115, 214, 265, 704 address spaces transaction types, 113–114 data link layer packets, 115 devices implement, 108–109 I/O device controller, 108 I/O drawers, 270 legacy endpoint category, 109 multilane distribution, 110 ordered set block, 111 physical layer, 109–111 protocol architecture, 109 root complex, 108 TLP packet assembly, 114–115 transaction layer (TL), 112–115 transaction layer packet processing, 115 Type 0 Type 1 configuration cycles, 114Index 827 PCI Special Interest Group (SIG), 107 PC- relative addressing, 461 PDP- 8 Bus Structure, main memory, 24 PDP- 8 instruction format, 471–472 PDP- 8 instruction format design, 471–472 PDP- 11 instruction format design, 474 PDP- 11 processor, 87 PDP- 10 instruction format, 472–473 PDP- 10 instruction format design, 472–473 Pentium 4 cache, 149–152 execution unit, 152 fetch/decode unit, 150 instruction cache, 152 memory subsystem, 152 operating modes, 152 out- of- order execution logic, 150 write- back policy, 152 Peripheral component interconnect (PCI), 107 Peripheral (external) devices, I/O, 233 Personal technology, 31 Phase change disk, 220 Phase- change RAM (PCRAM), 188, 189 SET RESET operation, 189 Phit (physical unit), 104 Physical address, 297 Physical cache, 133 Physical characteristics data storage, 124 Physical layer, 104–105 Physical records, 222 Physical types memory, 123 Pipelining, 47 . See also Instruction pipelining Pit, 218 Platform service (PaaS), 41, 646 Platters, 195, 200 Point- to- point interconnection structures, 24, 100, 102–107 QPI link layer, 105–107 QPI physical layer, 104–105 QPI protocol layer, 107 QPI routing layer, 107 Point- to- point interfaces, 255 Polarization- current- induced magnetization switching, 189 Pollack’s rule, 660 Polycarbonates, 217 POP stack operation, 469, 474 Positional number system, 320 Positive overflow, 353 Positive underflow, 353 Postindexing, 462–463 Power consumption, 659–660 Power density, 50 Preindexing, 463 Printed circuit board (PCB), 7Printers, 230 Private cloud, 646 Privileged instructions, 283 Procedural dependency, parallelism, 581 Procedure return, 438 Process block, 107 , 489, 560 control block, 289 multithreading, 628–633 resource ownership, 628 scheduling, 287–293 states, 288–290 switch, 629 Process- level parallelism, 662 Processor organization, 489–491 common fields flags, 494 functional elements of, 715 requirements, 489 Processors interconnection structures, 100 interconnection transfers, 100 1970s, 26 1980s, 26 1990s, 26 present times, 27 Product sums (POS), 380 Program counter (PC), 14, 84, 289, 389–390, 493, 497 , 499, 710 Program execution example, 86 execute cycle, 84 fetch cycle, 84, 87 fetched instruction, execution of, 85 instruction cycle, 84, 85, 87 interrupts, 89–98 I/O program, 89, 91 Programmable array logic (PAL), 406 Programmable logic array (PLA), 405–406 Programmable logic device (PLD), 405–409 complex PLDs (CPLDs), 408 field- programmable logic array, 406–409 programmable logic array (PLA), 405–406 simple PLD (SPLD), 406 terminology, 406 Programmable read- memory (PROM), 169, 170 Programmed I/O commands, 236, 238 instructions, 236–238 interrupt- driven I/O and, 239–248 isolated, 237 memory- mapped, 237 memory- mapped I/O, 237–238 overview of, 236 techniques, 235828 Index Programming, 83 Program status word (PSW), 494 Protection Enable (PE), 520 Pseudoinstruction, 483 Public cloud, 646 Pushdown list, 463 Q Queues, 55 I/O operations, 267 QuickPath Interconnect (QPI), 102–107 balanced transmission, 105 differential signaling, 105 direct connections, 103 error control function, 106 flow control function, 106 layered protocol architecture, 103 multiple direct connections, 103 packetized data transfer, 103 physical Interface, 105 QPI link layer, 105–107 QPI physical layer, 104–105 QPI protocol layer, 107 QPI routing layer, 107 use multicore computer, 103 Quiet NaN, 365–366 Quine- McCluskey method, 384–388 R Radix point, 320, 330 RAID (Redundant Array Independent Disks), 195, 204–213 comparison, 213 RAID level 5, 212 RAID level 4, 211–212 RAID level 1, 209–210 RAID level 6, 212 RAID level 3, 210–211 RAID level 2, 210 RAID level 0, 205–209 Random access, 123 Random- access memory (RAM), 167 Rate metric measures, 71, 73 Read hit/miss, 626 Read mechanisms, magnetic disks, 196 Read- mostly memory, 170 Read- memory (ROM), 124, 169–170, 392 truth table for, 393 Read- with- intent- to- modify (RWITM), 626 Read- write dependency, 509 Real memory, 300 Recordable ( CD- R), 219 Reduced instruction set computer (RISC), 3, 27 , 536 architecture, 549–555 Berkeley study, 541–542, 565cache, 545–546 characteristics, 538 classic, 553–555 compiler- based register optimization, 547–549 complex instruction sets, 537 conditional statements, 539 elements design, 537 global variables, 545 high- level language (HLL) and, 537 , 539–542, 545 instruction execution, 537–542 large register file, 545–546 line reasoning of, 538 one machine instruction per machine cycle, 551 operands, 540–541 operations, 539–540 pipelining, 555–559 procedure calls, 541 qualitative assessment, 570–571 quantitative assessment, 570–571 referencing local scalar, 546–547 register register operations, 551–552 register windows, 543–545 simple addressing modes, 552 simple instruction formats, 552 vs. CISC design, 553–555, 570–571 window- based register file, 546–547 Redundant disk performance via Hamming code (RAID level 2), 210 Reentrant procedure, 436 Register addressing, 460–461, 551–552 Register file, instruction pipe line, 542–547 Register indirect addressing, 461 Register organization, 491–496 Register renaming, 586–587 Registers, 401–402, 490 address, 492 ARM, 527–529 control status, 491, 493–495, 518, 519–521 control I/O operations, 494 current program status register (CPSR), 527–529 data, 491 devoted floating- point unit, 518 EFLAGS RFLAGS, 518–519 general purpose, 491–492, 517–518, 528 graphics processor unit (GPU), 697–700 index, 492 instruction register (IR), 493 instruction set design, 419 Intel x86, 517–524 memory address register (MAR), 493–494, 497 memory buffer register (MBR), 493–494, 497 , 499Index 829 microprocessor register organizations, 495–496 MMX, 521–522 numeric, 518 program status, 527 , 528 reduced instruction set computer (RISC), 543–545, 551–552 saved program status register (SPSR), 527–529 segment, 518 16-bit data, 496 software- visible, 527 tags, 518 Texas Instruments 8800 Software Development Board (SDB), 759 user- visible, 491–493, 496 Register- to- register organization, 551 Register window, 543–545 Relative address, 298 Relative addressing, 461 Removable disk, 199 Replacement algorithms, cache memory, 145 Resident monitor, 281 Resistive- capacitive (RC) delay, 50 Resistive RAM (ReRAM), 188, 189 Resource conflict, parallelism, 581 Resource encoding, 750 Resource hazard (structural hazard), pipelining, 507–508 Resource ownership process, 628 Resume flag (RF), 519 Retire, 598–600 Ripple counters, 402–403 Root complex, 108 Rotate (cyclic shift) operation, 431 Rotating interrupt mode, 244 Rotational delay (latency), magnetic disks, 201 Rotational positional sensing (RPS), 202 Rounding, 364–365 Rounding, IEEE standards, 364 RU (recovery unit), 10 Saturation arithmetic, 441 Scalar values, 452 Scheduling, 287–293 I/O queue, 292 long- term, 287–288 long- term queue, 292 medium- term, 288 process control block, 289–290 process states, 288–290 queuing diagram representation processor, 292 short- term, 288–293 short- term queue, 292techniques, 290–293 time- sharing system, 288 Secondary (auxiliary) memory, 127 Second generation computers, 17–18 CPU, 18 data channel, 18 multiplexor schedules, 18 Sectors, magnetic disks, 197 Seek time, magnetic disks, 202 Segmentation, Pentium II processor, 303–304 Segment pointers, 492 Selector channel, 262 Semantic gap, 537 Semiconductor memory, 24–25, 167 , 174 address lines, 171 arrangement cells array, 170 chip logic, 170–172 chip packaging, 172–173 dynamic RAM (DRAM), 167–168 electrically erasable programmable read- memory (EEPROM), 170 erasable programmable read- memory (EPROM), 170 error correction in, 174–180 flash memory, 170 interleaved memory, 173–174 I/O module, 173 organization, 166 programmable ROM (PROM), 169, 170 random- access memory (RAM), 167 read- mostly memory, 170 read- memory (ROM), 169–170 SRAM vs. DRAM, 169 static RAM (SRAM), 168–169 trade- offs among speed, density, cost, 170 types, 167 write enable (WE) output enable (OE) pins, 172, 173 Semiconductors, 127 , 185, 214 Sensor/actuator technology, 31 Sequencing, 739–745 Sequential access, 122 Sequential- access device, 223 Sequential circuits, 396–405 counters, 402–405 flip- flops, 396–400 registers, 401–402 Sequential organization, magnetic disks, 203 Serial ATA (SATA) sockets, 9 Serial ATA (Serial Advanced Technology Attachment), 265 Serial recording, 222 Serpentine recording, 222 Server clustering approaches, 635 Set- associative mapping, 140–144830 Index Setup time, operating system (OS) efficiency, 280–281 Shannon, Claude, 373 Shift registers, 401–402 Short- term data storage function, 4 Short- term scheduling, 288–290 Signaling NaN, 365–366 Signal lines, PCI, 99 Sign bit, 331 Sign extension, 334 Significand, 359 overflow, 359 underflow, 359 Sign- magnitude representation, 331 Silicon, 20 Simple PLD (SPLD), 406 Simultaneous multithreading (SMT), 630, 667 Single- error- correcting, double- error- detecting ( SEC- DED) code, 179–180 Single error- correcting (SEC) code, 179 Single instruction, multiple data (SIMD) stream, 615 Single instruction, single data (SISD) stream, 615 Single large expensive disk (SLEP), 204 Single- processor computer, 4–6 arithmetic logic unit (ALU), 6 central processing unit (CPU), 4 internal structure of, 9 main memory, 4 processor, 4 registers, 6 system bus, 5 system interconnection, 5 Single- sided disks, 200 Single- system image, 637 Single- threaded scalar, 630–631 Skip instructions, 434 Small Computer System Interface (SCSI), 264 Small- scale integration (SSI), 21, 405 Snoop control unit (SCU), 677 Snoopy protocols, cache coherence, 623–624 Soft errors, 175 Software, 18, 83 cache coherence solutions, 622–623 dynamic voltage frequency scaling (DVFS), 673–674 I/O driver, 214 multicore computer performance, 660–665 poll, 242 processing models, 673–674 software service (SaaS) model, 40–41 Valve game threading, 663–665 Software service (SaaS), 40–41, 645 Software poll technique, I/O, 242 Solid- state component, 17 , 20 Solid state drives (SSDs), 17 , 187 , 212–216compared HDD, 214 organization, 214–216 practical issues, 216 SPARC (Scalable Processor Architecture), 542 addressing modes, 568 ALU operations, 567 branch instruction, 568–569 current window pointer (CWP), 566 effective address (EA) operand, 568 instruction format, 568–570 instruction set, 567–568 processor status register (PSR), 566 register set, 565–567 register window layout, 566 Sun SPARC, 452 UltraSPARC, 71, 300 window invalid mask (WIM), 566 Spatial locality, 159, 160 SPEC documentation base metric, 71 benchmark, 71 peak metric, 71 rate metric, 71 reference machine, 71 speed metric, 71 system test, 71 Special interest group (SIG), PCI, 107 Special mask interrupt mode, 244 Speculative execution, 48 Speed metric measures, 71 Speedup factor, 506–507 Speedup system, 53–55, 660–661 Spin- transfer torque RAM ( STT- RAM), 188, 189 Split cache, 149 memory, 147 S– R Latch, 396–398 Stack addressing, 463 Stack pointer, 492 Standard Performance Evaluation Corporation (SPEC) benchmarks floating- point benchmarks, 70 integer benchmarks, 69, 72 SPEC CPU2006, 68–71 SPECint_base2006, 72 SPECint_rate_base2006, 72 SPECint_rate2006, 72 SPECint2006, 72 SPECjbb2013 (Java Business Benchmark), 68 SPECjvm2008, 68 SPECsfs2008, 68 SPECviewperf, 68 SPECvirt_sc2013, 68 SPECwpc, 68 State diagrams, instruction cycles, 414 State process, 288–290 Static RAM (SRAM), 36, 38, 148, 168–169, 187Index 831 Status flags, 439 Status registers, 493–495 Status signals, I/O, 231–232 Stored- program concept, 11 Streaming multiprocessors (SMs), 691 Stripe, 205, 211, 212 Striped data, 211 Striped disk performance (RAID level 0), 205–209 Structured programming (SAL), 159 Subnormal numbers, 366–367 Substrate, 195 Subtraction, 337–340 rule, 338 twos complement, 338–339 Subtrahend, 338 Sum products (SOP), 379 Superpipelined approach, 578–579 Superpipelined processor, 578–579 Superscalar, 9, 28, 51, 149, 474, 632 branch prediction, 589 committing retiring instruction, 590 dependency in, 579–581 execution, 48 execution programs, 589–590 implementation, 590 in- order completion, 583 instruction fetch stage, 589 instruction issue policy, 582–586 instruction- level parallelism in, 581–582 machine parallelism in, 581–582, 588–589 organization, 577 out- of- order completion, 583–586 overview, 576–581 pipelining scheduling techniques, 152, 507 processors, characteristics, 538 register renaming, 586–587 reported speedups, 577 types orderings, 582 vs. superpipelining, 578–579 SuperSpeed, 264 Swapping, I/O memory management, 293–294 Switch, 108 Symmetric multiprocessors (SMPs), 614, 615, 617–621 availability, 618 bus organization, 620 characteristics, 617 DMA transfers, 619 existence multiple processors, 618 incremental growth, 618 memory I/O channels, 619 memory management, 621 operating system of, 617–621 performance, 617 reliability fault tolerance, 621 scaling, 618scheduling, 621 simultaneous concurrent processes, 621 synchronization, 621 SYNCH byte, 199 Synchronous counter, 403–405 Synchronous DRAM (SDRAM), 181–182 DDR SDRAM, 183–184 Syndrome words, 176 System buses, 5, 101 System control operations, 432 System interconnection (bus), 5 System Performance Evaluation Corporation (SPEC), 68. See also SPEC documentation System software, 17 Tags, cache memory, 140 Task Switched (TS), 520 Temporal locality, 159–160 Test instructions, 416 Texas Instruments (TI) K2H SoC platform, 669–670 Texas Instruments 8800 Software Development Board (SDB), 755–765 block diagram, 756 components, 756 control operations, 757 counters, 759 external environment, 762–763 microinstruction format, 757–758 microsequencer, 757–762 microsequencer microinstruction bits, 761 registered ALU, 762–765 registered ALU instruction field, 764–765 registers, 759 stack operations, 759–760 subfields, 760, 761 Third generation computers, 18–24 DEC P DP- 8, 23–24 IBM system/360, 22–23 microelectronics, 19–22 32-bit Thumb instructions, 482 Thrashing, 138, 299 Thread, 629, 690 Thread blocks, 690 Threading granularity, 663 Threading strategy coarse- grained, 663 fine- grained, 663 hybrid, 663 simultaneous multithreading (SMT), 667 Valve game threading, 663–665 Thread- level parallelism, 662 Throughput, 71 Thumb instruction set, ARM, 479–481 Thunderbolt, 263, 265 Time- sharing operating systems (OS), 296–297832 Index Timing I/O modules, 203, 232–233 magnetic disk, 203 memory system effects instruction, 601 TinyOS, 31 TLP packet assembly, 114–115 Data field, 115 end- to- end CRC field, 115 Header field, 115 Tracks, magnetic disks, 196–197 Transaction layer, 112–114 Transducer, I/O, 231 Transfer control operations, 433 Transfer rate, 123 Transfer time, magnetic disks, 201–202 Transistors, 17–18 Translation lookaside buffer (TLB), 301–303 Trap flag (TF), 518 True data (flow) dependency, parallelism, 579–581 Truth table, 374, 378, 403 binary addition, 394 read- memory (ROM), 393 64-bit, 393 Turing, Alan, 11 Two- level cache memory, 157–164 characteristics of, 158 locality, 158–160 operation of, 160–161 performance parameters, 161–164 relative dynamic frequency high- level language operations, 159 Twos complement operation integers, 331–333, 336, 342–347 U Ultra Enterprise 2, 71 Ultra- large- scale integration (ULSI), 24 UltraSPARC II processor, 71 Unary operator, 417 Unconditional branch instructions, 482 Unconditional jump, 754 Underflow, 353, 358 Unified cache memory, 149 Uniform memory access (UMA), 640 Uniprocessors, 615–617 , 619, 621 Uniprogramming, operating systems (OS), 280 Unit transfer, 122 Universal Serial Bus (USB), 263–264 Upward compatible, 496 Use bit, 146 User/computer interfacing, OS, 276–278 User- visible registers, 491–493 Utilities, OS, 277 Utility program, 277V Vacuum tubes, development of, 11–17 Valve game threading, 663–665 Variable- length instruction formats, 473–477 Variable- sized partitions, 295–296 VAX architecture, 300 VAX instruction format design, 474–477 , 479, 537 Vector, 243 Vector floating- point (VFP) unit, 603 Vertical loss, 632 Very- large- scale integration (VLSI), 24 long instruction word (VLIW), 632 Video display terminals (VDTs), 230 Virtual address fields, 305 Virtual cache memory, 132 Virtual Interrupt Flag (VIF), 519 Virtual memory, 299–301, 494 demand paging, 299 page fault, 299 page replacement, 299 page table, 300–301 thrashing, 299 Virtual Mode (VM) bit, 519 Volatile memory, 32, 124 Von Neumann architecture, 81–82 Von Neumann machines, 13 W Wafer, silicon, 21 Warps, 696 Watchdog, 680 Wi- Fi, 266 Wilkes control, 735–739, 746 Winchester disk format, 199 Windows, 18 Words, 14 memory, 85, 101, 167 , 174, 495 packed, 441 Write read (WAR) dependency, 509 Write write (WAW) dependency, 509 Write back technique, 132, 146, 260, 516, 562, 565 Write hit/miss, 627 Write mechanisms, magnetic disks, 195–196 Write policy, cache memory, 145–147 Write Protect (WP), 521 Write technique, 145, 260, 622 Write- update protocol, 624 X X86 ARM data types, 422–425 Xeon E5-2600/4600, 255–257 XOR operations, 430 XU (translation unit), 10 Z Zero- address instructions, 418 Zones, defined, 198833Credits Page 4: “There remarkably . . . time design” based Siewiorek, D., Bell, C., Newell, A. Computer Structures: Principles Examples. New York: McGraw- Hill, 1982. pp. 12–13: “2.2 First: Since device primarily computer. . . . seen best make transfers (by O) R, never directly C” based Von Neumann, J. First Draft Report EDVAC. Moore School, University Pennsylvania, 1945. p. 39: Excerpt from: NIST Definition Cloud Computing (42 words). Grance, T., Mell, P . “The NIST Definition Cloud Computing.” NIST SP- 800-145. National Institute Standard Technology. p. 57: Figure 2.5: System Clock. Image courtesy Computer Language Company Inc., www .computerlanguage.com p. 269: Figure 7.20: IBM zEC12 I/O Frames– Front View IBM, Reprinted Permission. IBM zEnterprise EC12 Technical Guide, SG24-8049. http://www.redbooks.ibm.com/abstracts/sg248049 .html? p. 540: Table 15.2: Weighted Relative Dynamic Frequency HLL Operations based Patterson, D., Dequin, C. “A VLSI RISC.” Computer, September 1982. p. 634: Figure 17.8: Cluster Configurations based Buyya, R. High Performance Cluster Computing: Architectures Systems. Upper Saddle River, NJ: Prentice Hall, 1999. p. 638: “Lists following desirable cluster middleware services functions . . .” based Hwang, K., et al. “Designing SSI Clusters Hierarchical Checkpointing Single I/O Space.” IEEE Concurrency, January– March 1999. p. 652: Table 17.3: Typical Cache Hit Rate S/390 SMP Configuration. MAK97. p. 670: Figure 18.8: Texas Instruments 66AK2H12 Heterogenous Multicore Chip. Courtesy Texas Instruments. p. 693: Figure 19.3: Floating- Point Operations per Second CPU GPU. Image courtesy NVIDIA Corporation. p. 695: Figure 19.5: Single SM Architecture. Image courtesy NVIDIA Corporation. p. 703: Figure 19.11: Intel Gen8 Slice adapted Intel Corp. Computer Architecture Intel Processor Graphics Gen8. Intel White Paper, September 2014. 833This page intentionally left blank digital resources students new textbook provides 12-month access digital resources may include VideoNotes (step-by-step video tutorials programming concepts), source code, web chapters, quizzes, more. Refer preface textbook detailed list resources. Follow instructions register Companion Website Stallings’ Computer Organization Architecture, Tenth Edition. 1. Go www.pearsonhighered.com/cs-resources2. Enter title textbook browse author name.3. Click Companion Website.4. Click Register follow on-screen instructions create login name password. Use coin scratch coating reveal access code. use sharp knife sharp object may damage code. Use login name password created registration start using digital resources accompany textbook. Important: access code used once. subscription valid 12 months upon activation transferable. access code already revealed may longer valid. case purchase subscription login page Companion Website. technical support go http://247pearsoned.custhelp.com page intentionally left blank WILLIAM STALLINGS BOOKS COMPUTER DATA COMMUNICATIONS TECHNOLOGY DATA COMPUTER COMMUNICATIONS, TENTH EDITION comprehensive survey become standard field, covering (1) data communications, including transmission, media, signal encoding, link control, multiplexing; (2) communication networks, including circuit- packet-switched, frame relay, ATM, LANs; (3) TCP/IP protocol suite, including IPv6, TCP, MIME, HTTP, well detailed treatment network security. Received 2007 Text Academic Authors Association (TAA) award best Computer Science Engineering Textbook year. WIRELESS COMMUNICATION NETWORKS SYSTEMS (with Cory Beard) comprehensive, state-of-the art survey. Covers fundamental wireless communications topics, including antennas propagation, signal encoding techniques, spread spectrum, error correction techniques. Examines satellite, cellular, wireless local loop networks wireless LANs, including Bluetooth 802.11. Covers wireless mobile networks applications. COMPUTER SECURITY, THIRD EDITION (with Lawrie Brown) comprehensive treatment computer security technology, including algorithms, protocols, applications. Covers cryptography, authentication, access control, database security, cloud security, intrusion detection prevention, malicious software, denial service, firewalls, software security, physical security, human factors, auditing, legal ethical aspects, trusted systems. Received 2008 TAA award best Computer Science Engineering Textbook year. OPERATING SYSTEMS, EIGHTH EDITION state-of-the art survey operating system principles. Covers fundamental technology well contemporary design issues, threads, SMPs, multicore, real-time systems, multiprocessor scheduling, embedded OSs, distributed systems, clusters, security, object-oriented design. Third, fourth sixth editions received TAA award best Computer Science Engineering Textbook year. CRYPTOGRAPHY NETWORK SECURITY, SIXTH EDITION tutorial survey network security technology. basic building blocks network security, including conventional public-key cryptography, authentication, digital signatures, covered. Provides thorough mathematical background algorithms AES RSA. book covers important network security tools applications, including S/MIME, IP Security, Kerberos, SSL/TLS, network access control, Wi-Fi security. addition, methods countering hackers viruses explored. Second edition received TAA award best Computer Science Engineering Textbook 1999. NETWORK SECURITY ESSENTIALS, FIFTH EDITION tutorial survey network security technology. book covers important network security tools applications, including S/MIME, IP Security, Kerberos, SSL/TLS, network access control, Wi-Fi security. addition, methods countering hackers viruses explored. BUSINESS DATA COMMUNICATIONS, SEVENTH EDITION (with Tom Case) comprehensive presentation data communications telecommunications business perspective. Covers voice, data, image, video communications applications technology includes number case studies. Topics covered include data communications, TCP/IP, cloud computing, Internet protocols applications, LANs WANs, network security, network management. MODERN NETWORKING SDN QOE FRAMEWORK comprehensive unified survey modern networking technology applications. Covers basic infrastructure technologies software defined networks, OpenFlow, Network Function Virtualization (NVF), essential tools providing Quality Service (QoS) Quality Experience, applications cloud computing big data. COMPUTER NETWORKS INTERNET PROTOCOLS TECHNOLOGY up-to-date survey developments area Internet-based protocols algorithms. Using top-down approach, book covers applications, transport layer, Internet QoS, Internet routing, data link layer computer networks, security, network management.THE WILLIAM STALLINGS BOOKS COMPUTER DATA COMMUNICATIONS TECHNOLOGY DATA COMPUTER COMMUNICATIONS, TENTH EDITION comprehensive survey become standard field, covering (1) data communications, including transmission, media, signal encoding, link control, multiplexing; (2) communication networks, including circuit- packet-switched, frame relay, ATM, LANs; (3) TCP/IP protocol suite, including IPv6, TCP, MIME, HTTP, well detailed treatment network security. Received 2007 Text Academic Authors Association (TAA) award best Computer Science Engineering Textbook year. WIRELESS COMMUNICATION NETWORKS SYSTEMS (with Cory Beard) comprehensive, state-of-the art survey. Covers fundamental wireless communications topics, including antennas propagation, signal encoding techniques, spread spectrum, error correction techniques. Examines satellite, cellular, wireless local loop networks wireless LANs, including Bluetooth 802.11. Covers wireless mobile networks applications. COMPUTER SECURITY, THIRD EDITION (with Lawrie Brown) comprehensive treatment computer security technology, including algorithms, protocols, applications. Covers cryptography, authentication, access control, database security, cloud security, intrusion detection prevention, malicious software, denial service, firewalls, software security, physical security, human factors, auditing, legal ethical aspects, trusted systems. Received 2008 TAA award best Computer Science Engineering Textbook year. OPERATING SYSTEMS, EIGHTH EDITION state-of-the art survey operating system principles. Covers fundamental technology well contemporary design issues, threads, SMPs, multicore, real-time systems, multiprocessor scheduling, embedded OSs, distributed systems, clusters, security, object-oriented design. Third, fourth sixth editions received TAA award best Computer Science Engineering Textbook year. CRYPTOGRAPHY NETWORK SECURITY, SIXTH EDITION tutorial survey network security technology. basic building blocks network security, including conventional public-key cryptography, authentication, digital signatures, covered. Provides thorough mathematical background algorithms AES RSA. book covers important network security tools applications, including S/MIME, IP Security, Kerberos, SSL/TLS, network access control, Wi-Fi security. addition, methods countering hackers viruses explored. Second edition received TAA award best Computer Science Engineering Textbook 1999. NETWORK SECURITY ESSENTIALS, FIFTH EDITION tutorial survey network security technology. book covers important network security tools applications, including S/MIME, IP Security, Kerberos, SSL/TLS, network access control, Wi-Fi security. addition, methods countering hackers viruses explored. BUSINESS DATA COMMUNICATIONS, SEVENTH EDITION (with Tom Case) comprehensive presentation data communications telecommunications business perspective. Covers voice, data, image, video communications applications technology includes number case studies. Topics covered include data communications, TCP/IP, cloud computing, Internet protocols applications, LANs WANs, network security, network management. MODERN NETWORKING SDN QOE FRAMEWORK comprehensive unified survey modern networking technology applications. Covers basic infrastructure technologies software defined networks, OpenFlow, Network Function Virtualization (NVF), essential tools providing Quality Service (QoS) Quality Experience, applications cloud computing big data. COMPUTER NETWORKS INTERNET PROTOCOLS TECHNOLOGY up-to-date survey developments area Internet-based protocols algorithms. Using top-down approach, book covers applications, transport layer, Internet QoS, Internet routing, data link layer computer networks, security, network management.